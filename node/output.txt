/home/gustav/code/nano/rsnano-node/core/src/account.rs:
    1|       |use super::PublicKey;
    2|       |use crate::u256_struct;
    3|       |use anyhow::Result;
    4|       |use blake2::{
    5|       |    digest::{Update, VariableOutput},
    6|       |    Blake2bVar,
    7|       |};
    8|       |use primitive_types::U512;
    9|       |use serde::de::{Unexpected, Visitor};
   10|       |
   11|       |u256_struct!(Account);
   12|       |
   13|       |impl Account {
   14|      2|    pub fn encode_account(&self) -> String {
   15|      2|        let mut number = U512::from_big_endian(&self.0);
   16|      2|        let check = U512::from_little_endian(&self.account_checksum());
   17|      2|        number <<= 40;
   18|      2|        number |= check;
   19|      2|
   20|      2|        let mut result = String::with_capacity(65);
   21|       |
   22|    122|        for _i in 0..60 {
                          ^120
   23|    120|            let r = number.byte(0) & 0x1f_u8;
   24|    120|            number >>= 5;
   25|    120|            result.push(account_encode(r));
   26|    120|        }
   27|      2|        result.push_str("_onan"); // nano_
   28|      2|        result.chars().rev().collect()
   29|      2|    }
   30|       |
   31|    432|    fn account_checksum(&self) -> [u8; 5] {
   32|    432|        let mut check = [0u8; 5];
   33|    432|        let mut blake = Blake2bVar::new(check.len()).unwrap();
   34|    432|        blake.update(&self.0);
   35|    432|        blake.finalize_variable(&mut check).unwrap();
   36|    432|
   37|    432|        check
   38|    432|    }
   39|       |
   40|    430|    pub fn decode_account(source: impl AsRef<str>) -> Result<Account> {
   41|    430|        EncodedAccountStr(source.as_ref()).to_u512()?.to_account()
                                                                  ^0
   42|    430|    }
   43|       |
   44|    396|    pub fn as_key(&self) -> PublicKey {
   45|    396|        PublicKey::from_bytes(self.0)
   46|    396|    }
   47|       |}
   48|       |
   49|       |impl serde::Serialize for Account {
   50|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
   51|      0|    where
   52|      0|        S: serde::Serializer,
   53|      0|    {
   54|      0|        serializer.serialize_str(&self.encode_account())
   55|      0|    }
   56|       |}
   57|       |
   58|       |impl<'de> serde::Deserialize<'de> for Account {
   59|    258|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
   60|    258|    where
   61|    258|        D: serde::Deserializer<'de>,
   62|    258|    {
   63|    258|        let value = deserializer.deserialize_str(AccountVisitor {})?;
                                                                                 ^0
   64|    258|        Ok(value)
   65|    258|    }
   66|       |}
   67|       |
   68|       |struct AccountVisitor {}
   69|       |
   70|       |impl<'de> Visitor<'de> for AccountVisitor {
   71|       |    type Value = Account;
   72|       |
   73|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
   74|      0|        formatter
   75|      0|            .write_str("an account in the form \"nano_...\" or a node ID in the form \"node_...\"")
   76|      0|    }
   77|       |
   78|    258|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
   79|    258|    where
   80|    258|        E: serde::de::Error,
   81|    258|    {
   82|    258|        Account::decode_account(v).map_err(|_| {
   83|      0|            serde::de::Error::invalid_value(
   84|      0|                Unexpected::Str(v),
   85|      0|                &"an account in the form \"nano_...\"",
   86|      0|            )
   87|    258|        })
   88|    258|    }
   89|       |}
   90|       |
   91|       |struct EncodedAccountU512(U512);
   92|       |
   93|       |impl EncodedAccountU512 {
   94|    430|    fn account_bytes(&self) -> [u8; 32] {
   95|    430|        let bytes_512 = (self.0 >> 40).to_big_endian();
   96|    430|        let mut bytes_256 = [0u8; 32];
   97|    430|        bytes_256.copy_from_slice(&bytes_512[32..]);
   98|    430|        bytes_256
   99|    430|    }
  100|       |
  101|    430|    fn checksum_bytes(&self) -> [u8; 5] {
  102|    430|        [
  103|    430|            self.0.byte(0),
  104|    430|            self.0.byte(1),
  105|    430|            self.0.byte(2),
  106|    430|            self.0.byte(3),
  107|    430|            self.0.byte(4),
  108|    430|        ]
  109|    430|    }
  110|       |
  111|    430|    fn to_account(&self) -> Result<Account> {
  112|    430|        let account = Account::from_bytes(self.account_bytes());
  113|    430|        if account.account_checksum() == self.checksum_bytes() {
  114|    430|            Ok(account)
  115|       |        } else {
  116|      0|            Err(anyhow!("invalid checksum"))
  117|       |        }
  118|    430|    }
  119|       |}
  120|       |
  121|       |struct EncodedAccountStr<'a>(&'a str);
  122|       |impl<'a> EncodedAccountStr<'a> {
  123|    430|    fn is_valid(&self) -> bool {
  124|    430|        self.0.len() > 4
  125|    430|            && self.has_valid_prefix()
  126|    430|            && self.is_length_valid()
  127|    430|            && self.is_first_digit_valid()
  128|    430|    }
  129|       |
  130|    430|    fn has_valid_prefix(&self) -> bool {
  131|    430|        self.has_xrb_prefix() || self.has_nano_prefix() || self.has_node_id_prefix()
                                               ^300                      ^0
  132|    430|    }
  133|       |
  134|  1.72k|    fn has_xrb_prefix(&self) -> bool {
  135|  1.72k|        self.0.starts_with("xrb_") || self.0.starts_with("xrb-")
                                                    ^1.20k
  136|  1.72k|    }
  137|       |
  138|    730|    fn has_nano_prefix(&self) -> bool {
  139|    730|        self.0.starts_with("nano_") || self.0.starts_with("nano-")
                                                     ^130
  140|    730|    }
  141|       |
  142|      0|    fn has_node_id_prefix(&self) -> bool {
  143|      0|        self.0.starts_with("node_")
  144|      0|    }
  145|       |
  146|    430|    fn is_length_valid(&self) -> bool {
  147|    430|        if self.has_xrb_prefix() && self.0.chars().count() != 64 {
                                                  ^130
  148|      0|            return false;
  149|    430|        }
  150|    430|        if self.has_nano_prefix() && self.0.chars().count() != 65 {
                                                   ^300
  151|      0|            return false;
  152|    430|        }
  153|    430|        true
  154|    430|    }
  155|       |
  156|    860|    fn prefix_len(&self) -> usize {
  157|    860|        if self.has_xrb_prefix() {
  158|    260|            4
  159|       |        } else {
  160|    600|            5
  161|       |        }
  162|    860|    }
  163|       |
  164|    430|    fn first_digit(&self) -> Option<char> {
  165|    430|        self.0.chars().nth(self.prefix_len())
  166|    430|    }
  167|       |
  168|    430|    fn is_first_digit_valid(&self) -> bool {
  169|    430|        matches!(self.first_digit(), Some('1') | Some('3'))
                      ^0
  170|    430|    }
  171|       |
  172|    430|    fn chars_after_prefix(&'_ self) -> impl Iterator<Item = char> + '_ {
  173|    430|        self.0.chars().skip(self.prefix_len())
  174|    430|    }
  175|       |
  176|    430|    fn to_u512(&self) -> Result<EncodedAccountU512> {
  177|    430|        if !self.is_valid() {
  178|      0|            bail!("invalid account string");
  179|    430|        }
  180|    430|
  181|    430|        let mut number = U512::default();
  182|  25.8k|        for character in self.chars_after_prefix() {
                                       ^430
  183|  25.8k|            match self.decode_byte(character) {
  184|  25.8k|                Some(byte) => {
  185|  25.8k|                    number <<= 5;
  186|  25.8k|                    number = number + byte;
  187|  25.8k|                }
  188|      0|                None => bail!("invalid hex string"),
  189|       |            }
  190|       |        }
  191|    430|        Ok(EncodedAccountU512(number))
  192|    430|    }
  193|       |
  194|  25.8k|    fn decode_byte(&self, character: char) -> Option<u8> {
  195|  25.8k|        if character.is_ascii() {
  196|  25.8k|            let character = character as u8;
  197|  25.8k|            if (0x30..0x80).contains(&character) {
  198|  25.8k|                let byte: u8 = account_decode(character);
  199|  25.8k|                if byte != b'~' {
  200|  25.8k|                    return Some(byte);
  201|      0|                }
  202|      0|            }
  203|      0|        }
  204|       |
  205|      0|        None
  206|  25.8k|    }
  207|       |}
  208|       |
  209|       |const ACCOUNT_LOOKUP: &[char] = &[
  210|       |    '1', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',
  211|       |    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'w', 'x', 'y', 'z',
  212|       |];
  213|       |
  214|       |const ACCOUNT_REVERSE: &[char] = &[
  215|       |    '~', '0', '~', '1', '2', '3', '4', '5', '6', '7', '~', '~', '~', '~', '~', '~', '~', '~', '~',
  216|       |    '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~',
  217|       |    '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '~', '8', '9', ':', ';', '<', '=', '>', '?',
  218|       |    '@', 'A', 'B', '~', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', '~', 'L', 'M', 'N', 'O', '~',
  219|       |    '~', '~', '~', '~',
  220|       |];
  221|       |
  222|    120|fn account_encode(value: u8) -> char {
  223|    120|    ACCOUNT_LOOKUP[value as usize]
  224|    120|}
  225|       |
  226|  25.8k|fn account_decode(value: u8) -> u8 {
  227|  25.8k|    let mut result = ACCOUNT_REVERSE[(value - 0x30) as usize] as u8;
  228|  25.8k|    if result != b'~' {
  229|  25.8k|        result -= 0x30;
  230|  25.8k|    }
                   ^0
  231|  25.8k|    result
  232|  25.8k|}
  233|       |
  234|       |impl From<Account> for PublicKey {
  235|    396|    fn from(value: Account) -> Self {
  236|    396|        value.as_key()
  237|    396|    }
  238|       |}
  239|       |
  240|       |impl From<&Account> for PublicKey {
  241|      0|    fn from(value: &Account) -> Self {
  242|      0|        Self::from_bytes(*value.as_bytes())
  243|      0|    }
  244|       |}
  245|       |
  246|       |impl From<PublicKey> for Account {
  247|      0|    fn from(value: PublicKey) -> Self {
  248|      0|        Self::from_bytes(*value.as_bytes())
  249|      0|    }
  250|       |}
  251|       |
  252|       |impl From<&PublicKey> for Account {
  253|     33|    fn from(value: &PublicKey) -> Self {
  254|     33|        Self::from_bytes(*value.as_bytes())
  255|     33|    }
  256|       |}
  257|       |
  258|       |#[cfg(test)]
  259|       |mod tests {
  260|       |    use super::*;
  261|       |
  262|       |    // original test: account.encode_zero
  263|       |    #[test]
  264|       |    fn encode_zero() {
  265|       |        let account = Account::zero();
  266|       |        let encoded = account.encode_account();
  267|       |        assert_eq!(
  268|       |            encoded,
  269|       |            "nano_1111111111111111111111111111111111111111111111111111hifc8npp"
  270|       |        );
  271|       |        let copy = Account::decode_account(&encoded).expect("decode failed");
  272|       |        assert_eq!(account, copy);
  273|       |    }
  274|       |
  275|       |    // original test: account.encode_all
  276|       |    #[test]
  277|       |    fn encode_all() {
  278|       |        let account = Account::from_bytes([0xFF; 32]);
  279|       |        let encoded = account.encode_account();
  280|       |        assert_eq!(
  281|       |            encoded,
  282|       |            "nano_3zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzc3yoon41"
  283|       |        );
  284|       |        let copy = Account::decode_account(&encoded).expect("decode failed");
  285|       |        assert_eq!(account, copy);
  286|       |    }
  287|       |
  288|       |    // original test: account.encode_fail
  289|       |    #[test]
  290|       |    fn encode_fail() {
  291|       |        let account = Account::zero();
  292|       |        let mut encoded = account.encode_account();
  293|       |        encoded.replace_range(16..17, "x");
  294|       |        assert!(Account::decode_account(&encoded).is_err());
  295|       |    }
  296|       |
  297|       |    #[test]
  298|       |    fn encode_real_account() {
  299|       |        let account =
  300|       |            Account::decode_hex("E7F5F39D52AC32ADF978BBCF6EA50C7A5FBBDDCADE965C542808ADAE9DEF6B20")
  301|       |                .unwrap();
  302|       |        let encoded = account.encode_account();
  303|       |        assert_eq!(
  304|       |            encoded,
  305|       |            "nano_3szoyggo7d3koqwqjgyhftkirykzqhgwoqnpdjc4i47fotgyyts1j8ab3mti"
  306|       |        );
  307|       |        assert_eq!(
  308|       |            Account::decode_account(&encoded).expect("could not decode"),
  309|       |            account
  310|       |        );
  311|       |    }
  312|       |
  313|       |    #[test]
  314|       |    fn decode_xrb_variant() {
  315|       |        assert_eq!(
  316|       |            Account::decode_account(
  317|       |                "xrb_3szoyggo7d3koqwqjgyhftkirykzqhgwoqnpdjc4i47fotgyyts1j8ab3mti"
  318|       |            )
  319|       |            .unwrap(),
  320|       |            Account::decode_hex("E7F5F39D52AC32ADF978BBCF6EA50C7A5FBBDDCADE965C542808ADAE9DEF6B20")
  321|       |                .unwrap()
  322|       |        );
  323|       |    }
  324|       |
  325|       |    #[test]
  326|       |    fn decode_less_than_64_chars() {
  327|       |        let account = Account::decode_hex("AA").unwrap();
  328|       |        assert_eq!(
  329|       |            *account.as_bytes(),
  330|       |            [
  331|       |                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  332|       |                0, 0, 0, 0xAA
  333|       |            ]
  334|       |        )
  335|       |    }
  336|       |
  337|       |    #[test]
  338|       |    fn decode_invalid_checksum() {
  339|       |        assert_eq!(
  340|       |            Account::decode_account(
  341|       |                "nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtd1"
  342|       |            )
  343|       |            .unwrap_err()
  344|       |            .to_string(),
  345|       |            "invalid checksum"
  346|       |        );
  347|       |    }
  348|       |
  349|       |    #[test]
  350|       |    fn serde_serialize() {
  351|       |        let serialized = serde_json::to_string_pretty(&Account::from(123)).unwrap();
  352|       |        assert_eq!(
  353|       |            serialized,
  354|       |            "\"nano_111111111111111111111111111111111111111111111111115uwdgas549\""
  355|       |        );
  356|       |    }
  357|       |
  358|       |    #[test]
  359|       |    fn serde_deserialize() {
  360|       |        let deserialized: Account = serde_json::from_str(
  361|       |            "\"nano_111111111111111111111111111111111111111111111111115uwdgas549\"",
  362|       |        )
  363|       |        .unwrap();
  364|       |        assert_eq!(deserialized, Account::from(123));
  365|       |    }
  366|       |}

/home/gustav/code/nano/rsnano-node/core/src/account_info.rs:
    1|       |use std::mem::size_of;
    2|       |
    3|       |use crate::{
    4|       |    utils::{
    5|       |        BufferWriter, Deserialize, FixedSizeSerialize, MutStreamAdapter, Serialize, Stream,
    6|       |        StreamExt, UnixTimestamp,
    7|       |    },
    8|       |    Account, Amount, PublicKey,
    9|       |};
   10|       |use anyhow::Result;
   11|       |use num_traits::FromPrimitive;
   12|       |
   13|       |use super::{BlockHash, Epoch};
   14|       |
   15|       |/// Latest information about an account
   16|       |#[derive(PartialEq, Eq, Clone, Default, Debug)]
   17|       |pub struct AccountInfo {
   18|       |    pub head: BlockHash,
   19|       |    pub representative: PublicKey,
   20|       |    pub open_block: BlockHash,
   21|       |    pub balance: Amount,
   22|       |    /** Seconds since posix epoch */
   23|       |    pub modified: UnixTimestamp,
   24|       |    pub block_count: u64,
   25|       |    pub epoch: Epoch,
   26|       |}
   27|       |
   28|       |impl AccountInfo {
   29|     59|    pub fn to_bytes(&self) -> [u8; 129] {
   30|     59|        let mut buffer = [0; 129];
   31|     59|        let mut stream = MutStreamAdapter::new(&mut buffer);
   32|     59|        self.serialize(&mut stream);
   33|     59|        buffer
   34|     59|    }
   35|       |
   36|      0|    pub fn new_test_instance() -> Self {
   37|      0|        Self {
   38|      0|            head: BlockHash::from(1),
   39|      0|            representative: PublicKey::from(2),
   40|      0|            open_block: BlockHash::from(3),
   41|      0|            balance: Amount::raw(42),
   42|      0|            modified: 4.into(),
   43|      0|            block_count: 5,
   44|      0|            epoch: Epoch::Epoch2,
   45|      0|        }
   46|      0|    }
   47|       |}
   48|       |
   49|       |impl Serialize for AccountInfo {
   50|     59|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   51|     59|        self.head.serialize(stream);
   52|     59|        self.representative.serialize(stream);
   53|     59|        self.open_block.serialize(stream);
   54|     59|        self.balance.serialize(stream);
   55|     59|        stream.write_u64_ne_safe(self.modified.as_u64());
   56|     59|        stream.write_u64_ne_safe(self.block_count);
   57|     59|        stream.write_u8_safe(self.epoch as u8)
   58|     59|    }
   59|       |}
   60|       |
   61|       |impl FixedSizeSerialize for AccountInfo {
   62|      0|    fn serialized_size() -> usize {
   63|      0|        BlockHash::serialized_size()  // head
   64|      0|        + Account::serialized_size() // representative
   65|      0|        + BlockHash::serialized_size() // open_block
   66|      0|        + Amount::serialized_size() // balance
   67|      0|        + size_of::<u64>() // modified
   68|      0|        + size_of::<u64>() // block_count
   69|      0|        + size_of::<Epoch>()
   70|      0|    }
   71|       |}
   72|       |
   73|       |impl Deserialize for AccountInfo {
   74|       |    type Target = Self;
   75|    210|    fn deserialize(stream: &mut dyn Stream) -> Result<AccountInfo> {
   76|    210|        Ok(Self {
   77|    210|            head: BlockHash::deserialize(stream)?,
                                                              ^0
   78|    210|            representative: PublicKey::deserialize(stream)?,
                                                                        ^0
   79|    210|            open_block: BlockHash::deserialize(stream)?,
                                                                    ^0
   80|    210|            balance: Amount::deserialize(stream)?,
                                                              ^0
   81|    210|            modified: stream.read_u64_ne()?.into(),
                                                        ^0
   82|    210|            block_count: stream.read_u64_ne()?,
                                                           ^0
   83|    210|            epoch: Epoch::from_u8(stream.read_u8()?).ok_or_else(|| anyhow!("invalid epoch"))?,
                                                                ^0               ^0                       ^0
   84|       |        })
   85|    210|    }
   86|       |}

/home/gustav/code/nano/rsnano-node/core/src/amount.rs:
    1|       |use crate::utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream};
    2|       |use anyhow::Result;
    3|       |use serde::de::{Unexpected, Visitor};
    4|       |use std::{fmt::Debug, iter::Sum};
    5|       |
    6|       |#[derive(Clone, Copy, PartialEq, Eq, Default, Hash)]
    7|       |pub struct Amount {
    8|       |    raw: u128, // native endian!
    9|       |}
   10|       |
   11|       |impl Amount {
   12|       |    pub const MAX: Amount = Amount::raw(u128::MAX);
   13|       |
   14|   133k|    pub const fn raw(value: u128) -> Self {
   15|   133k|        Self { raw: value }
   16|   133k|    }
   17|       |
   18|       |    /// 10^24 raw or 0.000001 nano
   19|      9|    pub const fn micronano(value: u128) -> Self {
   20|      9|        Self {
   21|      9|            raw: value * 10u128.pow(24),
   22|      9|        }
   23|      9|    }
   24|       |
   25|       |    /// 10^27 raw or 0.001 nano
   26|      0|    pub const fn millinano(value: u128) -> Self {
   27|      0|        Self {
   28|      0|            raw: value * 10u128.pow(27),
   29|      0|        }
   30|      0|    }
   31|       |
   32|       |    /// 10^30 raw
   33|     56|    pub const fn nano(value: u128) -> Self {
   34|     56|        Self {
   35|     56|            raw: value * 10u128.pow(30),
   36|     56|        }
   37|     56|    }
   38|       |
   39|  66.0k|    pub fn zero() -> Self {
   40|  66.0k|        Self::raw(0)
   41|  66.0k|    }
   42|       |
   43|     74|    pub fn is_zero(&self) -> bool {
   44|     74|        *self == Self::zero()
   45|     74|    }
   46|       |
   47|      0|    pub fn from_be_bytes(bytes: [u8; 16]) -> Self {
   48|      0|        Self {
   49|      0|            raw: u128::from_be_bytes(bytes),
   50|      0|        }
   51|      0|    }
   52|       |
   53|      0|    pub fn from_le_bytes(bytes: [u8; 16]) -> Self {
   54|      0|        Self {
   55|      0|            raw: u128::from_le_bytes(bytes),
   56|      0|        }
   57|      0|    }
   58|       |
   59|  49.3k|    pub fn to_be_bytes(self) -> [u8; 16] {
   60|  49.3k|        self.raw.to_be_bytes()
   61|  49.3k|    }
   62|       |
   63|      0|    pub fn to_le_bytes(self) -> [u8; 16] {
   64|      0|        self.raw.to_le_bytes()
   65|      0|    }
   66|       |
   67|      0|    pub unsafe fn copy_bytes(&self, target: *mut u8) {
   68|      0|        let target_slice = std::slice::from_raw_parts_mut(target, 16);
   69|      0|        target_slice.copy_from_slice(&self.to_be_bytes());
   70|      0|    }
   71|       |
   72|      0|    pub fn encode_hex(&self) -> String {
   73|      0|        format!("{:032X}", self.raw)
   74|      0|    }
   75|       |
   76|      9|    pub fn decode_hex(s: impl AsRef<str>) -> Result<Self> {
   77|      9|        let value = u128::from_str_radix(s.as_ref(), 16)?;
                                                                      ^0
   78|      9|        Ok(Amount::raw(value))
   79|      9|    }
   80|       |
   81|    140|    pub fn decode_dec(s: impl AsRef<str>) -> Result<Self> {
   82|    140|        Ok(Self::raw(s.as_ref().parse::<u128>()?))
                                                             ^0
   83|    140|    }
   84|       |
   85|      5|    pub fn to_string_dec(self) -> String {
   86|      5|        self.raw.to_string()
   87|      5|    }
   88|       |
   89|     48|    pub fn number(&self) -> u128 {
   90|     48|        self.raw
   91|     48|    }
   92|       |
   93|      3|    pub fn format_balance(&self, precision: usize) -> String {
   94|      3|        let precision = std::cmp::min(precision, 30);
   95|      3|        let nano_ratio = Amount::nano(1).number();
   96|      3|        if self.raw == 0 || self.raw >= nano_ratio / num_traits::pow(10, precision) {
                                          ^0
   97|      3|            let whole = self.raw / nano_ratio;
   98|      3|            let decimals = self.raw % nano_ratio;
   99|      3|            let mut buf = num_format::Buffer::default();
  100|      3|            buf.write_formatted(&whole, &num_format::Locale::en);
  101|      3|            let mut result = buf.to_string();
  102|      3|            if decimals != 0 && precision > 0 {
                                              ^0
  103|      0|                result.push('.');
  104|      0|                let decimals_string = format!("{:030}", decimals);
  105|      0|                let trimmed = decimals_string.trim_end_matches('0');
  106|      0|                let decimals_count = std::cmp::min(
  107|      0|                    precision,
  108|      0|                    trimmed[..std::cmp::min(precision, trimmed.len())].len(),
  109|      0|                );
  110|      0|                result.push_str(&decimals_string[..decimals_count]);
  111|      3|            }
  112|      3|            result
  113|      0|        } else if precision == 0 {
  114|      0|            "< 1".to_owned()
  115|       |        } else {
  116|      0|            format!("< 0.{:0width$}", 1, width = precision)
  117|       |        }
  118|      3|    }
  119|       |
  120|    115|    pub fn wrapping_add(&self, other: Amount) -> Amount {
  121|    115|        self.raw.wrapping_add(other.raw).into()
  122|    115|    }
  123|       |
  124|     28|    pub fn wrapping_sub(&self, other: Amount) -> Amount {
  125|     28|        self.raw.wrapping_sub(other.raw).into()
  126|     28|    }
  127|       |}
  128|       |
  129|       |impl From<u128> for Amount {
  130|    911|    fn from(value: u128) -> Self {
  131|    911|        Amount::raw(value)
  132|    911|    }
  133|       |}
  134|       |
  135|       |impl Serialize for Amount {
  136|    120|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  137|    120|        stream.write_bytes_safe(&self.raw.to_be_bytes());
  138|    120|    }
  139|       |}
  140|       |
  141|       |impl FixedSizeSerialize for Amount {
  142|      2|    fn serialized_size() -> usize {
  143|      2|        std::mem::size_of::<u128>()
  144|      2|    }
  145|       |}
  146|       |
  147|       |impl Deserialize for Amount {
  148|       |    type Target = Self;
  149|  65.8k|    fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
  150|  65.8k|        let mut buffer = [0u8; 16];
  151|  65.8k|        let len = buffer.len();
  152|  65.8k|        stream.read_bytes(&mut buffer, len)?;
                                                         ^0
  153|  65.8k|        Ok(Amount::raw(u128::from_be_bytes(buffer)))
  154|  65.8k|    }
  155|       |}
  156|       |
  157|       |impl Debug for Amount {
  158|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  159|      0|        std::fmt::Debug::fmt(&self.raw, f)
  160|      0|    }
  161|       |}
  162|       |
  163|       |impl std::ops::AddAssign for Amount {
  164|     15|    fn add_assign(&mut self, rhs: Self) {
  165|     15|        self.raw += rhs.raw;
  166|     15|    }
  167|       |}
  168|       |
  169|       |impl std::ops::Add for Amount {
  170|       |    type Output = Self;
  171|       |
  172|     96|    fn add(self, rhs: Self) -> Self::Output {
  173|     96|        Amount::raw(self.raw + rhs.raw)
  174|     96|    }
  175|       |}
  176|       |
  177|       |impl std::ops::Sub for Amount {
  178|       |    type Output = Self;
  179|       |
  180|    244|    fn sub(self, rhs: Self) -> Self::Output {
  181|    244|        Amount::raw(self.raw - rhs.raw)
  182|    244|    }
  183|       |}
  184|       |
  185|       |impl std::ops::Div<u128> for Amount {
  186|       |    type Output = Self;
  187|       |
  188|     36|    fn div(self, rhs: u128) -> Self::Output {
  189|     36|        Amount::raw(self.number() / rhs)
  190|     36|    }
  191|       |}
  192|       |
  193|       |impl std::ops::Mul<u128> for Amount {
  194|       |    type Output = Self;
  195|       |
  196|      0|    fn mul(self, rhs: u128) -> Self::Output {
  197|      0|        Amount::raw(self.number() * rhs)
  198|      0|    }
  199|       |}
  200|       |
  201|       |impl std::ops::SubAssign<u128> for Amount {
  202|      0|    fn sub_assign(&mut self, rhs: u128) {
  203|      0|        self.raw -= rhs;
  204|      0|    }
  205|       |}
  206|       |
  207|       |impl std::cmp::PartialOrd for Amount {
  208|    880|    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
  209|    880|        Some(self.cmp(other))
  210|    880|    }
  211|       |}
  212|       |
  213|       |impl std::cmp::Ord for Amount {
  214|    992|    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
  215|    992|        self.raw.cmp(&other.raw)
  216|    992|    }
  217|       |}
  218|       |
  219|       |impl Sum for Amount {
  220|      0|    fn sum<I: Iterator<Item = Self>>(iter: I) -> Self {
  221|      0|        let mut sum = Amount::zero();
  222|      0|        for i in iter {
  223|      0|            sum += i;
  224|      0|        }
  225|      0|        sum
  226|      0|    }
  227|       |}
  228|       |
  229|       |impl serde::Serialize for Amount {
  230|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
  231|      0|    where
  232|      0|        S: serde::Serializer,
  233|      0|    {
  234|      0|        serializer.serialize_str(&self.to_string_dec())
  235|      0|    }
  236|       |}
  237|       |
  238|       |impl<'de> serde::Deserialize<'de> for Amount {
  239|      0|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
  240|      0|    where
  241|      0|        D: serde::Deserializer<'de>,
  242|      0|    {
  243|      0|        let value = deserializer.deserialize_str(AmountVisitor {})?;
  244|      0|        Ok(value)
  245|      0|    }
  246|       |}
  247|       |
  248|       |struct AmountVisitor {}
  249|       |
  250|       |impl<'de> Visitor<'de> for AmountVisitor {
  251|       |    type Value = Amount;
  252|       |
  253|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
  254|      0|        formatter.write_str("an 128 bit amount in decimal")
  255|      0|    }
  256|       |
  257|      0|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  258|      0|    where
  259|      0|        E: serde::de::Error,
  260|      0|    {
  261|      0|        let value = v.parse::<u128>().map_err(|_| {
  262|      0|            serde::de::Error::invalid_value(Unexpected::Str(v), &"a 128bit decimal string")
  263|      0|        })?;
  264|      0|        Ok(Amount::from(value))
  265|      0|    }
  266|       |}
  267|       |
  268|       |#[cfg(test)]
  269|       |mod tests {
  270|       |    use super::*;
  271|       |
  272|       |    #[test]
  273|       |    fn construct_amount_in_nano() {
  274|       |        assert_eq!(
  275|       |            Amount::nano(1).to_string_dec(),
  276|       |            "1000000000000000000000000000000"
  277|       |        );
  278|       |    }
  279|       |
  280|       |    #[test]
  281|       |    fn decode_dec_happy_path() {
  282|       |        assert_eq!(Amount::decode_dec("0").unwrap(), Amount::zero());
  283|       |        assert_eq!(Amount::decode_dec("01").unwrap(), Amount::raw(1));
  284|       |        let amount = Amount::decode_dec("1230000000000000000000000000000").unwrap();
  285|       |        assert_eq!(amount, Amount::raw(1230000000000000000000000000000));
  286|       |        let amount = Amount::decode_dec("340282366920938463463374607431768211455").unwrap();
  287|       |        assert_eq!(amount, Amount::MAX);
  288|       |    }
  289|       |
  290|       |    #[test]
  291|       |    fn decode_dec_failures() {
  292|       |        let err = Amount::decode_dec("-1").unwrap_err();
  293|       |        assert_eq!(err.to_string(), "invalid digit found in string");
  294|       |        assert_eq!(
  295|       |            Amount::decode_dec("").unwrap_err().to_string(),
  296|       |            "cannot parse integer from empty string"
  297|       |        );
  298|       |        let err = Amount::decode_dec("340282366920938463463374607431768211456").unwrap_err();
  299|       |        assert_eq!(err.to_string(), "number too large to fit in target type");
  300|       |    }
  301|       |
  302|       |    #[test]
  303|       |    fn format_balance() {
  304|       |        assert_eq!("0", Amount::raw(0).format_balance(2));
  305|       |        assert_eq!(
  306|       |            "340,282,366",
  307|       |            Amount::decode_hex("FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF")
  308|       |                .unwrap()
  309|       |                .format_balance(0)
  310|       |        );
  311|       |        assert_eq!(
  312|       |            "340,282,366.920938463463374607431768211455",
  313|       |            Amount::decode_hex("FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF")
  314|       |                .unwrap()
  315|       |                .format_balance(64)
  316|       |        );
  317|       |        assert_eq!(
  318|       |            "340,282,366",
  319|       |            Amount::decode_hex("FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE")
  320|       |                .unwrap()
  321|       |                .format_balance(0)
  322|       |        );
  323|       |        assert_eq!(
  324|       |            "340,282,366.920938463463374607431768211454",
  325|       |            Amount::decode_hex("FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE")
  326|       |                .unwrap()
  327|       |                .format_balance(64)
  328|       |        );
  329|       |        assert_eq!(
  330|       |            "170,141,183",
  331|       |            Amount::decode_hex("7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE")
  332|       |                .unwrap()
  333|       |                .format_balance(0)
  334|       |        );
  335|       |        assert_eq!(
  336|       |            "170,141,183.460469231731687303715884105726",
  337|       |            Amount::decode_hex("7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE")
  338|       |                .unwrap()
  339|       |                .format_balance(64)
  340|       |        );
  341|       |        assert_eq!(
  342|       |            "1",
  343|       |            Amount::decode_dec("1000000000000000000000000000000")
  344|       |                .unwrap()
  345|       |                .format_balance(2)
  346|       |        );
  347|       |        assert_eq!(
  348|       |            "1.2",
  349|       |            Amount::decode_dec("1200000000000000000000000000000")
  350|       |                .unwrap()
  351|       |                .format_balance(2)
  352|       |        );
  353|       |        assert_eq!(
  354|       |            "1.23",
  355|       |            Amount::decode_dec("1230000000000000000000000000000")
  356|       |                .unwrap()
  357|       |                .format_balance(2)
  358|       |        );
  359|       |        assert_eq!(
  360|       |            "1.2",
  361|       |            Amount::decode_dec("1230000000000000000000000000000")
  362|       |                .unwrap()
  363|       |                .format_balance(1)
  364|       |        );
  365|       |        assert_eq!(
  366|       |            "1",
  367|       |            Amount::decode_dec("1230000000000000000000000000000")
  368|       |                .unwrap()
  369|       |                .format_balance(0)
  370|       |        );
  371|       |        assert_eq!("< 0.01", Amount::micronano(10).format_balance(2));
  372|       |        assert_eq!("< 0.1", Amount::micronano(10).format_balance(1));
  373|       |        assert_eq!("< 1", Amount::micronano(10).format_balance(0));
  374|       |        assert_eq!("< 0.01", Amount::micronano(9999).format_balance(2));
  375|       |        assert_eq!("< 0.001", Amount::raw(1).format_balance(3));
  376|       |        assert_eq!("0.01", Amount::micronano(10000).format_balance(2));
  377|       |        assert_eq!("123,456,789", Amount::nano(123456789).format_balance(2));
  378|       |        assert_eq!(
  379|       |            "123,456,789.12",
  380|       |            (Amount::nano(123456789) + Amount::millinano(123)).format_balance(2)
  381|       |        );
  382|       |    }
  383|       |
  384|       |    #[test]
  385|       |    fn serde_serialize() {
  386|       |        let serialized = serde_json::to_string_pretty(&Amount::MAX).unwrap();
  387|       |        assert_eq!(serialized, "\"340282366920938463463374607431768211455\"");
  388|       |    }
  389|       |
  390|       |    #[test]
  391|       |    fn serde_deserialize() {
  392|       |        let deserialized: Amount = serde_json::from_str("\"123\"").unwrap();
  393|       |        assert_eq!(deserialized, Amount::raw(123));
  394|       |    }
  395|       |
  396|       |    #[test]
  397|       |    fn implements_debug() {
  398|       |        let formatted = format!("{:?}", Amount::raw(123));
  399|       |        assert_eq!(formatted, "123");
  400|       |    }
  401|       |}

/home/gustav/code/nano/rsnano-node/core/src/block_hash.rs:
    1|       |use super::Account;
    2|       |use crate::serialize_32_byte_string;
    3|       |use crate::u256_struct;
    4|       |use blake2::digest::Update;
    5|       |use blake2::digest::VariableOutput;
    6|       |use blake2::Blake2bVar;
    7|       |use rand::thread_rng;
    8|       |use rand::Rng;
    9|       |
   10|       |u256_struct!(BlockHash);
   11|       |serialize_32_byte_string!(BlockHash);
   12|       |
   13|       |impl BlockHash {
   14|      5|    pub fn random() -> Self {
   15|      5|        BlockHash::from_bytes(thread_rng().gen())
   16|      5|    }
   17|       |}
   18|       |
   19|       |impl From<&Account> for BlockHash {
   20|      0|    fn from(account: &Account) -> Self {
   21|      0|        Self::from_bytes(*account.as_bytes())
   22|      0|    }
   23|       |}
   24|       |
   25|       |impl From<Account> for BlockHash {
   26|      0|    fn from(account: Account) -> Self {
   27|      0|        Self::from_bytes(*account.as_bytes())
   28|      0|    }
   29|       |}
   30|       |
   31|       |pub struct BlockHashBuilder {
   32|       |    blake: Blake2bVar,
   33|       |}
   34|       |
   35|       |impl Default for BlockHashBuilder {
   36|  65.8k|    fn default() -> Self {
   37|  65.8k|        Self {
   38|  65.8k|            blake: Blake2bVar::new(32).unwrap(),
   39|  65.8k|        }
   40|  65.8k|    }
   41|       |}
   42|       |
   43|       |impl BlockHashBuilder {
   44|  65.8k|    pub fn new() -> Self {
   45|  65.8k|        Default::default()
   46|  65.8k|    }
   47|       |
   48|   345k|    pub fn update(mut self, data: impl AsRef<[u8]>) -> Self {
   49|   345k|        self.blake.update(data.as_ref());
   50|   345k|        self
   51|   345k|    }
   52|       |
   53|  65.8k|    pub fn build(self) -> BlockHash {
   54|  65.8k|        let mut hash_bytes = [0u8; 32];
   55|  65.8k|        self.blake.finalize_variable(&mut hash_bytes).unwrap();
   56|  65.8k|        BlockHash::from_bytes(hash_bytes)
   57|  65.8k|    }
   58|       |}
   59|       |
   60|       |#[cfg(test)]
   61|       |mod tests {
   62|       |    use super::*;
   63|       |
   64|       |    #[test]
   65|       |    fn serde_serialize() {
   66|       |        let serialized = serde_json::to_string_pretty(&BlockHash::from(123)).unwrap();
   67|       |        assert_eq!(
   68|       |            serialized,
   69|       |            "\"000000000000000000000000000000000000000000000000000000000000007B\""
   70|       |        );
   71|       |    }
   72|       |
   73|       |    #[test]
   74|       |    fn serde_deserialize() {
   75|       |        let deserialized: BlockHash = serde_json::from_str(
   76|       |            "\"000000000000000000000000000000000000000000000000000000000000007B\"",
   77|       |        )
   78|       |        .unwrap();
   79|       |        assert_eq!(deserialized, BlockHash::from(123));
   80|       |    }
   81|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/block_details.rs:
    1|       |use crate::{
    2|       |    utils::{BufferWriter, Serialize, Stream},
    3|       |    Epoch,
    4|       |};
    5|       |use anyhow::Result;
    6|       |use num::FromPrimitive;
    7|       |
    8|       |use super::BlockSubType;
    9|       |
   10|       |#[derive(Debug, PartialEq, Eq, Clone)]
   11|       |pub struct BlockDetails {
   12|       |    pub epoch: Epoch,
   13|       |    pub is_send: bool,
   14|       |    pub is_receive: bool,
   15|       |    pub is_epoch: bool,
   16|       |}
   17|       |
   18|       |impl BlockDetails {
   19|  82.1k|    pub fn new(epoch: Epoch, is_send: bool, is_receive: bool, is_epoch: bool) -> Self {
   20|  82.1k|        Self {
   21|  82.1k|            epoch,
   22|  82.1k|            is_send,
   23|  82.1k|            is_receive,
   24|  82.1k|            is_epoch,
   25|  82.1k|        }
   26|  82.1k|    }
   27|       |
   28|     26|    pub const fn serialized_size() -> usize {
   29|     26|        1
   30|     26|    }
   31|       |
   32|  49.1k|    pub fn deserialize(stream: &mut dyn Stream) -> Result<BlockDetails> {
   33|  49.1k|        BlockDetails::unpack(stream.read_u8()?)
                                                           ^0
   34|  49.1k|    }
   35|       |
   36|     33|    pub fn packed(&self) -> u8 {
   37|     33|        let mut result = self.epoch as u8;
   38|     33|        if self.is_send {
   39|     28|            result |= 0b1000_0000;
   40|     28|        }
                       ^5
   41|     33|        if self.is_receive {
   42|      4|            result |= 0b0100_0000;
   43|     29|        }
   44|     33|        if self.is_epoch {
   45|      0|            result |= 0b0010_0000;
   46|     33|        }
   47|       |
   48|     33|        result
   49|     33|    }
   50|       |
   51|  49.1k|    pub fn unpack(value: u8) -> Result<Self> {
   52|  49.1k|        let epoch_mask = 0b0001_1111u8;
   53|  49.1k|        let epoch_value = value & epoch_mask;
   54|  49.1k|        let epoch = match FromPrimitive::from_u8(epoch_value) {
   55|  49.1k|            Some(e) => e,
   56|      0|            None => bail!("unknown epoch value: {}", epoch_value),
   57|       |        };
   58|       |
   59|  49.1k|        Ok(BlockDetails {
   60|  49.1k|            epoch,
   61|  49.1k|            is_send: (0b1000_0000 & value) != 0,
   62|  49.1k|            is_receive: (0b0100_0000 & value) != 0,
   63|  49.1k|            is_epoch: (0b0010_0000 & value) != 0,
   64|  49.1k|        })
   65|  49.1k|    }
   66|       |
   67|      0|    pub fn subtype(&self) -> BlockSubType {
   68|      0|        if self.is_send {
   69|      0|            BlockSubType::Send
   70|      0|        } else if self.is_receive {
   71|      0|            BlockSubType::Receive
   72|      0|        } else if self.is_epoch {
   73|      0|            BlockSubType::Epoch
   74|       |        } else {
   75|      0|            BlockSubType::Change
   76|       |        }
   77|      0|    }
   78|       |
   79|      0|    pub fn subtype_str(&self) -> &'static str {
   80|      0|        self.subtype().as_str()
   81|      0|    }
   82|       |}
   83|       |
   84|       |impl Serialize for BlockDetails {
   85|     33|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   86|     33|        stream.write_u8_safe(self.packed())
   87|     33|    }
   88|       |}
   89|       |
   90|       |#[cfg(test)]
   91|       |mod test {
   92|       |    use crate::utils::MemoryStream;
   93|       |
   94|       |    use super::*;
   95|       |
   96|       |    #[test]
   97|       |    fn test_block_details() {
   98|       |        let details_send = BlockDetails::new(Epoch::Epoch0, true, false, false);
   99|       |        assert_eq!(details_send.is_send, true);
  100|       |        assert_eq!(details_send.is_receive, false);
  101|       |        assert_eq!(details_send.is_epoch, false);
  102|       |        assert_eq!(details_send.epoch, Epoch::Epoch0);
  103|       |
  104|       |        let details_receive = BlockDetails::new(Epoch::Epoch1, false, true, false);
  105|       |        assert_eq!(details_receive.is_send, false);
  106|       |        assert_eq!(details_receive.is_receive, true);
  107|       |        assert_eq!(details_receive.is_epoch, false);
  108|       |        assert_eq!(details_receive.epoch, Epoch::Epoch1);
  109|       |
  110|       |        let details_epoch = BlockDetails::new(Epoch::Epoch2, false, false, true);
  111|       |        assert_eq!(details_epoch.is_send, false);
  112|       |        assert_eq!(details_epoch.is_receive, false);
  113|       |        assert_eq!(details_epoch.is_epoch, true);
  114|       |        assert_eq!(details_epoch.epoch, Epoch::Epoch2);
  115|       |
  116|       |        let details_none = BlockDetails::new(Epoch::Unspecified, false, false, false);
  117|       |        assert_eq!(details_none.is_send, false);
  118|       |        assert_eq!(details_none.is_receive, false);
  119|       |        assert_eq!(details_none.is_epoch, false);
  120|       |        assert_eq!(details_none.epoch, Epoch::Unspecified);
  121|       |    }
  122|       |
  123|       |    #[test]
  124|       |    fn test_pack_and_unpack() {
  125|       |        let details_send = BlockDetails::new(Epoch::Epoch0, true, false, false);
  126|       |        assert_eq!(details_send.packed(), 0b1000_0010);
  127|       |        assert_eq!(
  128|       |            BlockDetails::unpack(details_send.packed()).unwrap(),
  129|       |            details_send
  130|       |        );
  131|       |
  132|       |        let details_receive = BlockDetails::new(Epoch::Epoch1, false, true, false);
  133|       |        assert_eq!(details_receive.packed(), 0b0100_0011);
  134|       |        assert_eq!(
  135|       |            BlockDetails::unpack(details_receive.packed()).unwrap(),
  136|       |            details_receive
  137|       |        );
  138|       |
  139|       |        let details_epoch = BlockDetails::new(Epoch::Epoch2, false, false, true);
  140|       |        assert_eq!(details_epoch.packed(), 0b0010_0100);
  141|       |        assert_eq!(
  142|       |            BlockDetails::unpack(details_epoch.packed()).unwrap(),
  143|       |            details_epoch
  144|       |        );
  145|       |
  146|       |        let details_none = BlockDetails::new(Epoch::Unspecified, false, false, false);
  147|       |        assert_eq!(details_none.packed(), 0b0000_0001);
  148|       |        assert_eq!(
  149|       |            BlockDetails::unpack(details_none.packed()).unwrap(),
  150|       |            details_none
  151|       |        );
  152|       |    }
  153|       |
  154|       |    #[test]
  155|       |    fn serialize() {
  156|       |        let details = BlockDetails::new(Epoch::Epoch2, false, true, false);
  157|       |        let mut stream = MemoryStream::new();
  158|       |        details.serialize(&mut stream);
  159|       |        let deserialized = BlockDetails::deserialize(&mut stream).unwrap();
  160|       |        assert_eq!(deserialized, details);
  161|       |    }
  162|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/block_priority.rs:
    1|       |use crate::{utils::UnixTimestamp, Amount, SavedBlock};
    2|       |use std::cmp::max;
    3|       |
    4|      0|pub fn block_priority(
    5|      0|    block: &SavedBlock,
    6|      0|    previous_block: Option<&SavedBlock>,
    7|      0|) -> (Amount, UnixTimestamp) {
    8|      0|    let previous_balance = previous_block
    9|      0|        .as_ref()
   10|      0|        .map(|b| b.balance())
   11|      0|        .unwrap_or_default();
   12|       |
   13|       |    // Handle full send case nicely where the balance would otherwise be 0
   14|      0|    let priority_balance = max(
   15|      0|        block.balance(),
   16|      0|        if block.is_send() {
   17|      0|            previous_balance
   18|       |        } else {
   19|      0|            Amount::zero()
   20|       |        },
   21|       |    );
   22|       |
   23|       |    // Use previous block timestamp as priority timestamp for least recently used
   24|       |    // prioritization within the same bucket
   25|       |    // Account info timestamp is not used here because it will get out of sync when
   26|       |    // rollbacks happen
   27|      0|    let priority_timestamp = previous_block
   28|      0|        .map(|b| b.timestamp())
   29|      0|        .unwrap_or(block.timestamp());
   30|      0|
   31|      0|    (priority_balance, priority_timestamp)
   32|      0|}
   33|       |
   34|       |#[cfg(test)]
   35|       |mod tests {
   36|       |    use super::*;
   37|       |    use crate::{PrivateKey, SavedBlockLatticeBuilder};
   38|       |
   39|       |    #[test]
   40|       |    fn open_block() {
   41|       |        let mut lattice = SavedBlockLatticeBuilder::new();
   42|       |        let key = PrivateKey::from(42);
   43|       |        let send = lattice.genesis().send(&key, 1);
   44|       |        lattice.advance_time();
   45|       |        let open = lattice.account(&key).receive(&send);
   46|       |
   47|       |        let (prio_balance, prio_time) = block_priority(&open, None);
   48|       |
   49|       |        assert_eq!(prio_balance, open.balance());
   50|       |        assert_eq!(prio_time, open.timestamp());
   51|       |    }
   52|       |
   53|       |    #[test]
   54|       |    fn receive_block() {
   55|       |        let mut lattice = SavedBlockLatticeBuilder::new();
   56|       |        let key = PrivateKey::from(42);
   57|       |        let send1 = lattice.genesis().send(&key, 1);
   58|       |        lattice.advance_time();
   59|       |        let send2 = lattice.genesis().send(&key, 1);
   60|       |        lattice.advance_time();
   61|       |        let open = lattice.account(&key).receive(&send1);
   62|       |        lattice.advance_time();
   63|       |        let receive = lattice.account(&key).receive(&send2);
   64|       |
   65|       |        let (prio_balance, prio_time) = block_priority(&receive, Some(&open));
   66|       |
   67|       |        assert_eq!(prio_balance, receive.balance());
   68|       |        assert_eq!(prio_time, open.timestamp());
   69|       |    }
   70|       |
   71|       |    #[test]
   72|       |    fn send_block() {
   73|       |        let mut lattice = SavedBlockLatticeBuilder::new();
   74|       |        let send1 = lattice.genesis().send(42, Amount::nano(100));
   75|       |        lattice.advance_time();
   76|       |        let send2 = lattice.genesis().send(42, Amount::nano(50));
   77|       |
   78|       |        let (prio_balance, prio_time) = block_priority(&send2, Some(&send1));
   79|       |
   80|       |        assert_eq!(prio_balance, send1.balance());
   81|       |        assert_eq!(prio_time, send1.timestamp());
   82|       |    }
   83|       |
   84|       |    #[test]
   85|       |    fn full_send() {
   86|       |        let mut lattice = SavedBlockLatticeBuilder::new();
   87|       |        let send1 = lattice.genesis().send(42, Amount::nano(100));
   88|       |        lattice.advance_time();
   89|       |        let send2 = lattice.genesis().send_max(42);
   90|       |
   91|       |        let (prio_balance, prio_time) = block_priority(&send2, Some(&send1));
   92|       |
   93|       |        assert_eq!(prio_balance, send1.balance());
   94|       |        assert_eq!(prio_time, send1.timestamp());
   95|       |    }
   96|       |
   97|       |    #[test]
   98|       |    fn change_block() {
   99|       |        let mut lattice = SavedBlockLatticeBuilder::new();
  100|       |        let send = lattice.genesis().send(42, Amount::nano(100));
  101|       |        lattice.advance_time();
  102|       |        let change = lattice.genesis().change(12345);
  103|       |
  104|       |        let (prio_balance, prio_time) = block_priority(&change, Some(&send));
  105|       |
  106|       |        assert_eq!(prio_balance, change.balance());
  107|       |        assert_eq!(prio_time, send.timestamp());
  108|       |    }
  109|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/block_sideband.rs:
    1|       |use crate::{
    2|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream, UnixTimestamp},
    3|       |    Account, Amount, BlockDetails, BlockHash, BlockType, Epoch,
    4|       |};
    5|       |use num::FromPrimitive;
    6|       |
    7|       |#[derive(Debug, Clone, PartialEq, Eq)]
    8|       |pub struct BlockSideband {
    9|       |    pub height: u64,
   10|       |    pub timestamp: UnixTimestamp,
   11|       |    /// Successor to the current block
   12|       |    pub successor: BlockHash,
   13|       |    pub account: Account,
   14|       |    pub balance: Amount,
   15|       |    pub details: BlockDetails,
   16|       |    pub source_epoch: Epoch,
   17|       |}
   18|       |
   19|       |impl BlockSideband {
   20|     28|    pub fn serialized_size(block_type: BlockType) -> usize {
   21|     28|        let mut size = BlockHash::serialized_size(); // successor
   22|     28|
   23|     28|        if block_type != BlockType::State && block_type != BlockType::LegacyOpen {
                                                           ^2
   24|      0|            size += Account::serialized_size(); // account
   25|     28|        }
   26|       |
   27|     28|        if block_type != BlockType::LegacyOpen {
   28|     26|            size += std::mem::size_of::<u64>(); // height
   29|     26|        }
                       ^2
   30|       |
   31|     28|        if block_type == BlockType::LegacyReceive
   32|     28|            || block_type == BlockType::LegacyChange
   33|     28|            || block_type == BlockType::LegacyOpen
   34|      2|        {
   35|      2|            size += Amount::serialized_size(); // balance
   36|     26|        }
   37|       |
   38|     28|        size += std::mem::size_of::<u64>(); // timestamp
   39|     28|
   40|     28|        if block_type == BlockType::State {
   41|     26|            // block_details must not be larger than the epoch enum
   42|     26|            const_assert!(std::mem::size_of::<Epoch>() == BlockDetails::serialized_size());
   43|     26|            size += BlockDetails::serialized_size() + std::mem::size_of::<Epoch>();
   44|     26|        }
                       ^2
   45|       |
   46|     28|        size
   47|     28|    }
   48|       |
   49|     61|    pub fn serialize(&self, stream: &mut dyn BufferWriter, block_type: BlockType) {
   50|     61|        self.successor.serialize(stream);
   51|     61|
   52|     61|        if block_type != BlockType::State && block_type != BlockType::LegacyOpen {
                                                           ^28
   53|      0|            self.account.serialize(stream);
   54|     61|        }
   55|       |
   56|     61|        if block_type != BlockType::LegacyOpen {
   57|     33|            stream.write_bytes_safe(&self.height.to_be_bytes());
   58|     33|        }
                       ^28
   59|       |
   60|     61|        if block_type == BlockType::LegacyReceive
   61|     61|            || block_type == BlockType::LegacyChange
   62|     61|            || block_type == BlockType::LegacyOpen
   63|     28|        {
   64|     28|            self.balance.serialize(stream);
   65|     33|        }
   66|       |
   67|     61|        stream.write_bytes_safe(&self.timestamp.to_be_bytes());
   68|     61|
   69|     61|        if block_type == BlockType::State {
   70|     33|            self.details.serialize(stream);
   71|     33|            stream.write_u8_safe(self.source_epoch as u8);
   72|     33|        }
                       ^28
   73|     61|    }
   74|       |
   75|  65.5k|    pub fn from_stream(stream: &mut dyn Stream, block_type: BlockType) -> anyhow::Result<Self> {
   76|  65.5k|        let mut result = Self {
   77|  65.5k|            height: 0,
   78|  65.5k|            timestamp: UnixTimestamp::ZERO,
   79|  65.5k|            successor: BlockHash::zero(),
   80|  65.5k|            account: Account::zero(),
   81|  65.5k|            balance: Amount::zero(),
   82|  65.5k|            details: BlockDetails::new(Epoch::Epoch0, false, false, false),
   83|  65.5k|            source_epoch: Epoch::Epoch0,
   84|  65.5k|        };
   85|  65.5k|        result.deserialize(stream, block_type)?;
                                                            ^0
   86|  65.5k|        Ok(result)
   87|  65.5k|    }
   88|       |
   89|  65.5k|    pub fn deserialize(
   90|  65.5k|        &mut self,
   91|  65.5k|        stream: &mut dyn Stream,
   92|  65.5k|        block_type: BlockType,
   93|  65.5k|    ) -> anyhow::Result<()> {
   94|  65.5k|        self.successor = BlockHash::deserialize(stream)?;
                                                                     ^0
   95|       |
   96|  65.5k|        if block_type != BlockType::State && block_type != BlockType::LegacyOpen {
                                                           ^16.4k
   97|      0|            self.account = Account::deserialize(stream)?;
   98|  65.5k|        }
   99|       |
  100|  65.5k|        let mut buffer = [0u8; 8];
  101|  65.5k|        if block_type != BlockType::LegacyOpen {
  102|  49.1k|            stream.read_bytes(&mut buffer, 8)?;
                                                           ^0
  103|  49.1k|            self.height = u64::from_be_bytes(buffer);
  104|  16.4k|        } else {
  105|  16.4k|            self.height = 1;
  106|  16.4k|        }
  107|       |
  108|  65.5k|        if block_type == BlockType::LegacyReceive
  109|  65.5k|            || block_type == BlockType::LegacyChange
  110|  65.5k|            || block_type == BlockType::LegacyOpen
  111|       |        {
  112|  16.4k|            self.balance = Amount::deserialize(stream)?;
                                                                    ^0
  113|  49.1k|        }
  114|       |
  115|  65.5k|        stream.read_bytes(&mut buffer, 8)?;
                                                       ^0
  116|  65.5k|        self.timestamp = UnixTimestamp::from_be_bytes(buffer);
  117|  65.5k|
  118|  65.5k|        if block_type == BlockType::State {
  119|  49.1k|            self.details = BlockDetails::deserialize(stream)?;
                                                                          ^0
  120|  49.1k|            self.source_epoch = FromPrimitive::from_u8(stream.read_u8()?)
                                                                                     ^0
  121|  49.1k|                .ok_or_else(|| anyhow!("invalid epoch value"))?;
                                             ^0                             ^0
  122|  16.4k|        }
  123|       |
  124|  65.5k|        Ok(())
  125|  65.5k|    }
  126|       |
  127|      0|    pub fn new_test_instance() -> Self {
  128|      0|        Self {
  129|      0|            height: 42,
  130|      0|            timestamp: UnixTimestamp::new(1000),
  131|      0|            successor: BlockHash::from(3),
  132|      0|            account: Account::from(1),
  133|      0|            balance: Amount::raw(42),
  134|      0|            details: BlockDetails {
  135|      0|                epoch: Epoch::Epoch2,
  136|      0|                is_send: true,
  137|      0|                is_receive: false,
  138|      0|                is_epoch: false,
  139|      0|            },
  140|      0|            source_epoch: Epoch::Epoch2,
  141|      0|        }
  142|      0|    }
  143|       |}
  144|       |
  145|       |#[cfg(test)]
  146|       |mod tests {
  147|       |    use super::*;
  148|       |    use crate::utils::MemoryStream;
  149|       |
  150|       |    #[test]
  151|       |    fn serialize() {
  152|       |        let details = BlockDetails::new(Epoch::Epoch0, false, false, false);
  153|       |        let sideband = BlockSideband {
  154|       |            height: 4,
  155|       |            timestamp: UnixTimestamp::new(5),
  156|       |            successor: 2.into(),
  157|       |            account: 1.into(),
  158|       |            balance: 3.into(),
  159|       |            details,
  160|       |            source_epoch: Epoch::Epoch0,
  161|       |        };
  162|       |        let mut stream = MemoryStream::new();
  163|       |        sideband.serialize(&mut stream, BlockType::LegacyReceive);
  164|       |        let deserialized =
  165|       |            BlockSideband::from_stream(&mut stream, BlockType::LegacyReceive).unwrap();
  166|       |        assert_eq!(deserialized, sideband);
  167|       |    }
  168|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/change.rs:
    1|       |use crate::work::WorkPool;
    2|       |use crate::{work::STUB_WORK_POOL, BlockHash};
    3|       |use crate::{Account, Block, ChangeBlockArgs, PrivateKey, PublicKey};
    4|       |
    5|       |pub struct TestLegacyChangeBlockBuilder {
    6|       |    account: Option<Account>,
    7|       |    representative: Option<PublicKey>,
    8|       |    previous: Option<BlockHash>,
    9|       |    prv_key: Option<PrivateKey>,
   10|       |    work: Option<u64>,
   11|       |}
   12|       |
   13|       |impl TestLegacyChangeBlockBuilder {
   14|      0|    pub(super) fn new() -> Self {
   15|      0|        Self {
   16|      0|            account: None,
   17|      0|            representative: None,
   18|      0|            previous: None,
   19|      0|            prv_key: None,
   20|      0|            work: None,
   21|      0|        }
   22|      0|    }
   23|       |
   24|      0|    pub fn previous(mut self, previous: BlockHash) -> Self {
   25|      0|        self.previous = Some(previous);
   26|      0|        self
   27|      0|    }
   28|       |
   29|      0|    pub fn account(mut self, account: Account) -> Self {
   30|      0|        self.account = Some(account);
   31|      0|        self
   32|      0|    }
   33|       |
   34|      0|    pub fn representative(mut self, representative: PublicKey) -> Self {
   35|      0|        self.representative = Some(representative);
   36|      0|        self
   37|      0|    }
   38|       |
   39|      0|    pub fn sign(mut self, keypair: &PrivateKey) -> Self {
   40|      0|        self.prv_key = Some(keypair.clone());
   41|      0|        self
   42|      0|    }
   43|       |
   44|      0|    pub fn work(mut self, work: u64) -> Self {
   45|      0|        self.work = Some(work);
   46|      0|        self
   47|      0|    }
   48|       |
   49|      0|    pub fn build(self) -> Block {
   50|      0|        let previous = self.previous.unwrap_or(BlockHash::from(1));
   51|      0|        let prv_key = self.prv_key.unwrap_or_default();
   52|      0|        let representative = self.representative.unwrap_or(PublicKey::from(2));
   53|      0|        let work = self
   54|      0|            .work
   55|      0|            .unwrap_or_else(|| STUB_WORK_POOL.generate_dev2(previous.into()).unwrap());
   56|      0|
   57|      0|        ChangeBlockArgs {
   58|      0|            key: &prv_key,
   59|      0|            previous,
   60|      0|            representative,
   61|      0|            work,
   62|      0|        }
   63|      0|        .into()
   64|      0|    }
   65|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/mod.rs:
    1|       |mod change;
    2|       |mod open;
    3|       |mod receive;
    4|       |mod saved_account_chain;
    5|       |mod saved_block_lattice_builder;
    6|       |mod send;
    7|       |mod state;
    8|       |mod unsaved_block_lattice_builder;
    9|       |
   10|       |pub use change::TestLegacyChangeBlockBuilder;
   11|       |pub use open::TestLegacyOpenBlockBuilder;
   12|       |pub use receive::TestLegacyReceiveBlockBuilder;
   13|       |pub use saved_account_chain::SavedAccountChain;
   14|       |pub use saved_block_lattice_builder::*;
   15|       |pub use send::TestLegacySendBlockBuilder;
   16|       |pub use state::TestStateBlockBuilder;
   17|       |pub use unsaved_block_lattice_builder::*;
   18|       |
   19|       |pub struct TestBlockBuilder {}
   20|       |
   21|       |impl TestBlockBuilder {
   22|      1|    pub fn state() -> TestStateBlockBuilder {
   23|      1|        TestStateBlockBuilder::new()
   24|      1|    }
   25|       |
   26|      1|    pub fn legacy_open() -> TestLegacyOpenBlockBuilder {
   27|      1|        TestLegacyOpenBlockBuilder::new()
   28|      1|    }
   29|       |
   30|      0|    pub fn legacy_receive() -> TestLegacyReceiveBlockBuilder {
   31|      0|        TestLegacyReceiveBlockBuilder::new()
   32|      0|    }
   33|       |
   34|      0|    pub fn legacy_send() -> TestLegacySendBlockBuilder {
   35|      0|        TestLegacySendBlockBuilder::new()
   36|      0|    }
   37|       |
   38|      0|    pub fn legacy_change() -> TestLegacyChangeBlockBuilder {
   39|      0|        TestLegacyChangeBlockBuilder::new()
   40|      0|    }
   41|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/open.rs:
    1|       |use crate::{
    2|       |    blocks::open_block::OpenBlockArgs,
    3|       |    utils::UnixTimestamp,
    4|       |    work::{WorkPool, STUB_WORK_POOL},
    5|       |    Account, Block, BlockDetails, BlockHash, BlockSideband, Epoch, PrivateKey, PublicKey,
    6|       |    SavedBlock,
    7|       |};
    8|       |
    9|       |pub struct TestLegacyOpenBlockBuilder {
   10|       |    account: Option<Account>,
   11|       |    representative: Option<PublicKey>,
   12|       |    source: Option<BlockHash>,
   13|       |    prv_key: Option<PrivateKey>,
   14|       |    work: Option<u64>,
   15|       |}
   16|       |
   17|       |impl TestLegacyOpenBlockBuilder {
   18|      1|    pub(super) fn new() -> Self {
   19|      1|        Self {
   20|      1|            account: None,
   21|      1|            representative: None,
   22|      1|            source: None,
   23|      1|            prv_key: None,
   24|      1|            work: None,
   25|      1|        }
   26|      1|    }
   27|       |
   28|      1|    pub fn source(mut self, source: BlockHash) -> Self {
   29|      1|        self.source = Some(source);
   30|      1|        self
   31|      1|    }
   32|       |
   33|      0|    pub fn representative(mut self, representative: PublicKey) -> Self {
   34|      0|        self.representative = Some(representative);
   35|      0|        self
   36|      0|    }
   37|       |
   38|      1|    pub fn sign(mut self, prv_key: &PrivateKey) -> Self {
   39|      1|        self.prv_key = Some(prv_key.clone());
   40|      1|        self
   41|      1|    }
   42|       |
   43|      0|    pub fn work(mut self, work: u64) -> Self {
   44|      0|        self.work = Some(work);
   45|      0|        self
   46|      0|    }
   47|      1|    pub fn build(self) -> Block {
   48|      1|        let source = self.source.unwrap_or(BlockHash::from(1));
   49|      1|        let prv_key = self.prv_key.unwrap_or_default();
   50|      1|        let account = self.account.unwrap_or_else(|| prv_key.account());
   51|      1|        let representative = self.representative.unwrap_or(PublicKey::from(2));
   52|      1|        let work = self
   53|      1|            .work
   54|      1|            .unwrap_or_else(|| STUB_WORK_POOL.generate_dev2(account.into()).unwrap());
   55|      1|
   56|      1|        OpenBlockArgs {
   57|      1|            key: &prv_key,
   58|      1|            source,
   59|      1|            representative,
   60|      1|            work,
   61|      1|        }
   62|      1|        .into()
   63|      1|    }
   64|       |
   65|      0|    pub fn build_saved(self) -> SavedBlock {
   66|      0|        let block = self.build();
   67|      0|
   68|      0|        let details = BlockDetails {
   69|      0|            epoch: Epoch::Epoch0,
   70|      0|            is_send: false,
   71|      0|            is_receive: true,
   72|      0|            is_epoch: false,
   73|      0|        };
   74|      0|
   75|      0|        let sideband = BlockSideband {
   76|      0|            height: 1,
   77|      0|            timestamp: UnixTimestamp::new(2),
   78|      0|            successor: BlockHash::zero(),
   79|      0|            account: block.account_field().unwrap(),
   80|      0|            balance: 5.into(),
   81|      0|            details,
   82|      0|            source_epoch: Epoch::Epoch0,
   83|      0|        };
   84|      0|
   85|      0|        SavedBlock::new(block, sideband)
   86|      0|    }
   87|       |}
   88|       |
   89|       |#[cfg(test)]
   90|       |mod tests {
   91|       |    use super::*;
   92|       |    use crate::{work::WORK_THRESHOLDS_STUB, Amount, BlockBase, Signature, TestBlockBuilder};
   93|       |
   94|       |    #[test]
   95|       |    fn create_open_block() {
   96|       |        let block = TestBlockBuilder::legacy_open().build_saved();
   97|       |        let Block::LegacyOpen(open) = &*block else {
   98|       |            panic!("not an open block")
   99|       |        };
  100|       |        assert_eq!(open.source(), BlockHash::from(1));
  101|       |        assert_eq!(open.representative(), PublicKey::from(2));
  102|       |        assert_ne!(open.account(), Account::zero());
  103|       |        assert_eq!(WORK_THRESHOLDS_STUB.validate_entry_block(&block), true);
  104|       |        assert_ne!(*open.signature(), Signature::new());
  105|       |
  106|       |        assert!(block.successor().is_none());
  107|       |        assert_eq!(block.balance(), Amount::raw(5));
  108|       |        assert_eq!(block.height(), 1);
  109|       |        assert_eq!(block.timestamp(), UnixTimestamp::new(2));
  110|       |        assert_eq!(block.source_epoch(), Epoch::Epoch0);
  111|       |    }
  112|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/receive.rs:
    1|       |use crate::{
    2|       |    blocks::receive_block::ReceiveBlockArgs,
    3|       |    work::{WorkPool, STUB_WORK_POOL},
    4|       |    Block, BlockHash, PrivateKey,
    5|       |};
    6|       |
    7|       |pub struct TestLegacyReceiveBlockBuilder {
    8|       |    previous: Option<BlockHash>,
    9|       |    source: Option<BlockHash>,
   10|       |    key_pair: Option<PrivateKey>,
   11|       |    work: Option<u64>,
   12|       |}
   13|       |
   14|       |impl TestLegacyReceiveBlockBuilder {
   15|      0|    pub(super) fn new() -> Self {
   16|      0|        Self {
   17|      0|            previous: None,
   18|      0|            source: None,
   19|      0|            key_pair: None,
   20|      0|            work: None,
   21|      0|        }
   22|      0|    }
   23|       |
   24|      0|    pub fn previous(mut self, previous: BlockHash) -> Self {
   25|      0|        self.previous = Some(previous);
   26|      0|        self
   27|      0|    }
   28|       |
   29|      0|    pub fn source(mut self, source: BlockHash) -> Self {
   30|      0|        self.source = Some(source);
   31|      0|        self
   32|      0|    }
   33|       |
   34|      0|    pub fn sign(mut self, key_pair: &PrivateKey) -> Self {
   35|      0|        self.key_pair = Some(key_pair.clone());
   36|      0|        self
   37|      0|    }
   38|       |
   39|      0|    pub fn work(mut self, work: u64) -> Self {
   40|      0|        self.work = Some(work);
   41|      0|        self
   42|      0|    }
   43|       |
   44|      0|    pub fn build(self) -> Block {
   45|      0|        let key = self.key_pair.unwrap_or_default();
   46|      0|        let previous = self.previous.unwrap_or(BlockHash::from(1));
   47|      0|        let source = self.source.unwrap_or(BlockHash::from(2));
   48|      0|        let work = self
   49|      0|            .work
   50|      0|            .unwrap_or_else(|| STUB_WORK_POOL.generate_dev2(previous.into()).unwrap());
   51|      0|
   52|      0|        ReceiveBlockArgs {
   53|      0|            key: &key,
   54|      0|            previous,
   55|      0|            source,
   56|      0|            work,
   57|      0|        }
   58|      0|        .into()
   59|      0|    }
   60|       |}
   61|       |
   62|       |#[cfg(test)]
   63|       |mod tests {
   64|       |    use crate::{work::WORK_THRESHOLDS_STUB, Block, BlockBase, BlockHash, TestBlockBuilder};
   65|       |
   66|       |    #[test]
   67|       |    fn receive_block() {
   68|       |        let block = TestBlockBuilder::legacy_receive().build();
   69|       |        let Block::LegacyReceive(receive) = &block else {
   70|       |            panic!("not a receive block!")
   71|       |        };
   72|       |        assert_eq!(receive.previous(), BlockHash::from(1));
   73|       |        assert_eq!(receive.source(), BlockHash::from(2));
   74|       |        assert_eq!(WORK_THRESHOLDS_STUB.validate_entry_block(&block), true);
   75|       |    }
   76|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/saved_account_chain.rs:
    1|       |use crate::{
    2|       |    epoch_v1_link, epoch_v2_link, utils::UnixTimestamp, Account, AccountInfo, Amount, Block,
    3|       |    BlockDetails, BlockHash, BlockSideband, Epoch, PrivateKey, PublicKey, SavedBlock,
    4|       |    TestBlockBuilder, TestLegacyChangeBlockBuilder, TestLegacyOpenBlockBuilder,
    5|       |    TestLegacyReceiveBlockBuilder, TestLegacySendBlockBuilder, TestStateBlockBuilder,
    6|       |    DEV_GENESIS_KEY,
    7|       |};
    8|       |
    9|       |/// Builds blocks with sideband data as if they were saved in the ledger
   10|       |pub struct SavedAccountChain {
   11|       |    priv_key: PrivateKey,
   12|       |    account: Account,
   13|       |    balance: Amount,
   14|       |    representative: PublicKey,
   15|       |    blocks: Vec<SavedBlock>,
   16|       |    epoch: Epoch,
   17|       |}
   18|       |
   19|       |impl SavedAccountChain {
   20|      0|    pub fn new() -> Self {
   21|      0|        Self::with_priv_key(PrivateKey::new())
   22|      0|    }
   23|       |
   24|      1|    pub fn genesis() -> Self {
   25|      1|        let mut result = Self::with_priv_key(DEV_GENESIS_KEY.clone());
   26|      1|        result.balance = Amount::MAX;
   27|      1|        result.add_block(
   28|      1|            TestBlockBuilder::legacy_open()
   29|      1|                .source(BlockHash::zero())
   30|      1|                .sign(&result.priv_key)
   31|      1|                .build(),
   32|      1|            Epoch::Epoch0,
   33|      1|        );
   34|      1|        result
   35|      1|    }
   36|       |
   37|      0|    pub fn new_opened_chain() -> Self {
   38|      0|        let mut result = Self::new();
   39|      0|        result.add_random_open_block();
   40|      0|        result
   41|      0|    }
   42|       |
   43|      0|    pub fn add_random_open_block(&mut self) {
   44|      0|        assert_eq!(self.height(), 0);
   45|      0|        self.balance = Amount::nano(1);
   46|      0|        self.add_block(
   47|      0|            TestBlockBuilder::legacy_open()
   48|      0|                .source(BlockHash::from(123))
   49|      0|                .sign(&self.priv_key)
   50|      0|                .build(),
   51|      0|            Epoch::Epoch0,
   52|      0|        );
   53|      0|    }
   54|       |
   55|      1|    pub fn with_priv_key(key: PrivateKey) -> Self {
   56|      1|        Self {
   57|      1|            account: key.account(),
   58|      1|            balance: Amount::zero(),
   59|      1|            blocks: Vec::new(),
   60|      1|            representative: PublicKey::zero(),
   61|      1|            priv_key: key,
   62|      1|            epoch: Epoch::Epoch0,
   63|      1|        }
   64|      1|    }
   65|       |
   66|      2|    pub fn height(&self) -> u64 {
   67|      2|        self.blocks.len() as u64
   68|      2|    }
   69|       |
   70|      1|    pub fn open(&self) -> BlockHash {
   71|      1|        self.blocks[0].hash()
   72|      1|    }
   73|       |
   74|      1|    pub fn frontier(&self) -> BlockHash {
   75|      1|        self.blocks.last().map(|b| b.hash()).unwrap_or_default()
   76|      1|    }
   77|       |
   78|      1|    pub fn account(&self) -> Account {
   79|      1|        self.account
   80|      1|    }
   81|       |
   82|      1|    pub fn blocks(&self) -> &[SavedBlock] {
   83|      1|        &self.blocks
   84|      1|    }
   85|       |
   86|      0|    pub fn block(&self, height: u64) -> &SavedBlock {
   87|      0|        &self.blocks[height as usize - 1]
   88|      0|    }
   89|       |
   90|      0|    pub fn try_get_block(&self, height: u64) -> Option<&SavedBlock> {
   91|      0|        if height == 0 {
   92|      0|            return None;
   93|      0|        }
   94|      0|        self.blocks.get(height as usize - 1)
   95|      0|    }
   96|       |
   97|      0|    pub fn latest_block(&self) -> &SavedBlock {
   98|      0|        self.blocks.last().unwrap()
   99|      0|    }
  100|       |
  101|      0|    pub fn add_legacy_change(&mut self, representative: impl Into<PublicKey>) -> &SavedBlock {
  102|      0|        let block = self
  103|      0|            .new_legacy_change_block()
  104|      0|            .representative(representative.into())
  105|      0|            .build();
  106|      0|        self.add_block(block, Epoch::Epoch0)
  107|      0|    }
  108|       |
  109|      0|    pub fn add_legacy_open_from_account(
  110|      0|        &mut self,
  111|      0|        sender_chain: &SavedAccountChain,
  112|      0|    ) -> &SavedBlock {
  113|      0|        self.add_legacy_open_from_account_block(sender_chain, sender_chain.height())
  114|      0|    }
  115|       |
  116|      0|    pub fn add_legacy_open_from_account_block(
  117|      0|        &mut self,
  118|      0|        sender_chain: &SavedAccountChain,
  119|      0|        height: u64,
  120|      0|    ) -> &SavedBlock {
  121|      0|        let send_block = sender_chain.block(height);
  122|      0|        let amount = sender_chain.amount_of_block(height);
  123|      0|        assert_eq!(self.height(), 0);
  124|      0|        assert!(amount > Amount::zero());
  125|      0|        assert_eq!(send_block.destination_or_link(), self.account);
  126|      0|        self.balance = amount;
  127|      0|        let open_block = TestBlockBuilder::legacy_open()
  128|      0|            .source(send_block.hash())
  129|      0|            .sign(&self.priv_key)
  130|      0|            .build();
  131|      0|        self.add_block(open_block, send_block.epoch())
  132|      0|    }
  133|       |
  134|      0|    pub fn add_legacy_receive_from_account(
  135|      0|        &mut self,
  136|      0|        sender_chain: &SavedAccountChain,
  137|      0|    ) -> &SavedBlock {
  138|      0|        self.add_legacy_receive_from_account_block(sender_chain, sender_chain.height())
  139|      0|    }
  140|       |
  141|      0|    pub fn add_legacy_receive_from_self(&mut self) -> &SavedBlock {
  142|      0|        let send_block = self.block(self.height());
  143|      0|        let amount = self.amount_of_block(self.height());
  144|      0|        assert_eq!(send_block.destination_or_link(), self.account);
  145|      0|        self.add_legacy_receive(send_block.hash(), amount, send_block.epoch())
  146|      0|    }
  147|       |
  148|      0|    pub fn add_legacy_receive_from_account_block(
  149|      0|        &mut self,
  150|      0|        sender: &SavedAccountChain,
  151|      0|        height: u64,
  152|      0|    ) -> &SavedBlock {
  153|      0|        let send_block = sender.block(height);
  154|      0|        let amount = sender.amount_of_block(height);
  155|      0|        assert_eq!(send_block.destination_or_link(), self.account);
  156|      0|        self.add_legacy_receive(send_block.hash(), amount, send_block.epoch())
  157|      0|    }
  158|       |
  159|      0|    fn add_legacy_receive(
  160|      0|        &mut self,
  161|      0|        source: BlockHash,
  162|      0|        amount: Amount,
  163|      0|        source_epoch: Epoch,
  164|      0|    ) -> &SavedBlock {
  165|      0|        assert!(amount > Amount::zero());
  166|      0|        let block_builder = TestBlockBuilder::legacy_receive()
  167|      0|            .previous(self.frontier())
  168|      0|            .source(source)
  169|      0|            .sign(&self.priv_key);
  170|      0|        self.balance += amount;
  171|      0|        self.add_block(block_builder.build(), source_epoch)
  172|      0|    }
  173|       |
  174|      0|    pub fn add_legacy_send(&mut self) -> &SavedBlock {
  175|      0|        self.add_legacy_send_to(Account::from(42), Amount::raw(1))
  176|      0|    }
  177|       |
  178|      0|    pub fn add_legacy_send_to(&mut self, destination: Account, amount: Amount) -> &SavedBlock {
  179|      0|        let block = self
  180|      0|            .new_legacy_send_block()
  181|      0|            .amount(amount)
  182|      0|            .destination(destination)
  183|      0|            .build();
  184|      0|        self.add_block(block, Epoch::Epoch0)
  185|      0|    }
  186|       |
  187|      1|    pub fn add_state(&mut self) -> &SavedBlock {
  188|      1|        let state = self.new_state_block().build();
  189|      1|        self.add_block(state, Epoch::Epoch0)
  190|      1|    }
  191|       |
  192|      0|    pub fn add_epoch_v1(&mut self) -> &SavedBlock {
  193|      0|        let epoch_block = self.new_epoch1_block().build();
  194|      0|        self.add_block(epoch_block, Epoch::Epoch0)
  195|      0|    }
  196|       |
  197|      0|    pub fn add_epoch_v2(&mut self) -> &SavedBlock {
  198|      0|        let epoch_block = self.new_epoch2_block().build();
  199|      0|        self.add_block(epoch_block, Epoch::Epoch0)
  200|      0|    }
  201|       |
  202|      0|    pub fn new_epoch1_block(&self) -> TestStateBlockBuilder {
  203|      0|        self.new_state_block()
  204|      0|            .link(epoch_v1_link())
  205|      0|            .key(&DEV_GENESIS_KEY)
  206|      0|    }
  207|       |
  208|      0|    pub fn new_epoch2_block(&self) -> TestStateBlockBuilder {
  209|      0|        self.new_state_block()
  210|      0|            .link(epoch_v2_link())
  211|      0|            .key(&DEV_GENESIS_KEY)
  212|      0|    }
  213|       |
  214|      0|    pub fn new_legacy_open_block(&self) -> TestLegacyOpenBlockBuilder {
  215|      0|        TestBlockBuilder::legacy_open()
  216|      0|            .source(BlockHash::from(123))
  217|      0|            .representative(PublicKey::from(456))
  218|      0|            .sign(&self.priv_key)
  219|      0|    }
  220|       |
  221|      1|    pub fn new_state_block(&self) -> TestStateBlockBuilder {
  222|      1|        TestBlockBuilder::state()
  223|      1|            .account(self.account)
  224|      1|            .balance(self.balance)
  225|      1|            .representative(self.representative)
  226|      1|            .link(0)
  227|      1|            .previous(self.frontier())
  228|      1|            .key(&self.priv_key)
  229|      1|    }
  230|       |
  231|      0|    pub fn new_open_block(&self) -> TestStateBlockBuilder {
  232|      0|        TestBlockBuilder::state()
  233|      0|            .account(self.account)
  234|      0|            .balance(42)
  235|      0|            .representative(1234)
  236|      0|            .link(555)
  237|      0|            .previous(0)
  238|      0|            .key(&self.priv_key)
  239|      0|    }
  240|       |
  241|      0|    pub fn new_legacy_send_block(&self) -> TestLegacySendBlockBuilder {
  242|      0|        TestBlockBuilder::legacy_send()
  243|      0|            .previous(self.frontier())
  244|      0|            .destination(Account::from(42))
  245|      0|            .previous_balance(self.balance)
  246|      0|            .amount(1)
  247|      0|            .sign(self.priv_key.clone())
  248|      0|    }
  249|       |
  250|      0|    pub fn new_send_block(&self) -> TestStateBlockBuilder {
  251|      0|        self.new_state_block()
  252|      0|            .previous_balance(self.balance)
  253|      0|            .amount_sent(Amount::raw(1))
  254|      0|            .link(123)
  255|      0|    }
  256|       |
  257|      0|    pub fn new_receive_block(&self) -> TestStateBlockBuilder {
  258|      0|        self.new_state_block()
  259|      0|            .previous_balance(self.balance)
  260|      0|            .balance(self.balance + Amount::raw(1))
  261|      0|            .link(123)
  262|      0|    }
  263|       |
  264|      0|    pub fn new_epoch1_open_block(&self) -> TestStateBlockBuilder {
  265|      0|        TestBlockBuilder::state()
  266|      0|            .account(self.account)
  267|      0|            .balance(0)
  268|      0|            .representative(0)
  269|      0|            .link(epoch_v1_link())
  270|      0|            .previous(0)
  271|      0|            .key(&DEV_GENESIS_KEY)
  272|      0|    }
  273|       |
  274|      0|    pub fn new_legacy_receive_block(&self) -> TestLegacyReceiveBlockBuilder {
  275|      0|        TestBlockBuilder::legacy_receive()
  276|      0|            .previous(self.frontier())
  277|      0|            .source(BlockHash::from(123))
  278|      0|            .sign(&self.priv_key)
  279|      0|    }
  280|       |
  281|      0|    pub fn new_legacy_change_block(&self) -> TestLegacyChangeBlockBuilder {
  282|      0|        TestBlockBuilder::legacy_change()
  283|      0|            .previous(self.frontier())
  284|      0|            .representative(PublicKey::from(42))
  285|      0|            .sign(&self.priv_key)
  286|      0|    }
  287|       |
  288|      0|    pub fn take_blocks(self) -> Vec<SavedBlock> {
  289|      0|        self.blocks
  290|      0|    }
  291|       |
  292|      0|    pub fn account_info(&self) -> AccountInfo {
  293|      0|        AccountInfo {
  294|      0|            head: self.frontier(),
  295|      0|            representative: self.representative,
  296|      0|            open_block: self.open(),
  297|      0|            balance: self.latest_block().balance(),
  298|      0|            modified: 123.into(),
  299|      0|            block_count: self.height(),
  300|      0|            epoch: self.epoch,
  301|      0|        }
  302|      0|    }
  303|       |
  304|      0|    fn amount_of_block(&self, height: u64) -> Amount {
  305|      0|        let balance = self.balance_on_height(height);
  306|      0|        let previous_balance = self.balance_on_height(height - 1);
  307|      0|        if balance > previous_balance {
  308|      0|            balance - previous_balance
  309|       |        } else {
  310|      0|            previous_balance - balance
  311|       |        }
  312|      0|    }
  313|       |
  314|      0|    fn balance_on_height(&self, height: u64) -> Amount {
  315|      0|        if height == 0 {
  316|      0|            Amount::zero()
  317|       |        } else {
  318|      0|            self.blocks[height as usize - 1].balance()
  319|       |        }
  320|      0|    }
  321|       |
  322|      2|    pub fn add_block(&mut self, block: Block, source_epoch: Epoch) -> &SavedBlock {
  323|      2|        if let Some(new_balance) = block.balance_field() {
                                  ^1
  324|      1|            self.balance = new_balance;
  325|      1|        }
  326|       |
  327|      2|        if block.link_field().unwrap_or_default() == epoch_v1_link() {
  328|      0|            self.epoch = Epoch::Epoch1;
  329|      2|        } else if block.link_field().unwrap_or_default() == epoch_v2_link() {
  330|      0|            self.epoch = Epoch::Epoch2;
  331|      2|        }
  332|       |
  333|      2|        let sideband = BlockSideband {
  334|      2|            height: self.height() + 1,
  335|      2|            timestamp: UnixTimestamp::new(1),
  336|      2|            successor: BlockHash::zero(),
  337|      2|            account: self.account,
  338|      2|            balance: self.balance,
  339|      2|            details: BlockDetails::new(self.epoch, false, false, false),
  340|      2|            source_epoch,
  341|      2|        };
  342|      2|
  343|      2|        if !self.blocks.is_empty() {
  344|      1|            let previous = self.blocks.last_mut().unwrap();
  345|      1|            let mut sideband = previous.sideband.clone();
  346|      1|            sideband.successor = block.hash();
  347|      1|            previous.set_sideband(sideband);
  348|      1|        }
  349|       |
  350|      2|        if let Some(rep) = block.representative_field() {
  351|      2|            self.representative = rep;
  352|      2|        }
                       ^0
  353|       |
  354|      2|        self.blocks.push(SavedBlock::new(block, sideband));
  355|      2|        self.blocks.last().unwrap()
  356|      2|    }
  357|       |
  358|      0|    pub fn representative_at_height(&self, height: u64) -> Option<PublicKey> {
  359|      0|        self.blocks[..height as usize]
  360|      0|            .iter()
  361|      0|            .rev()
  362|      0|            .filter_map(|b| b.representative_field())
  363|      0|            .next()
  364|      0|    }
  365|       |}
  366|       |
  367|       |impl Default for SavedAccountChain {
  368|      0|    fn default() -> Self {
  369|      0|        Self::new()
  370|      0|    }
  371|       |}
  372|       |
  373|       |#[cfg(test)]
  374|       |mod tests {
  375|       |    use super::*;
  376|       |    use crate::BlockType;
  377|       |
  378|       |    #[test]
  379|       |    fn default_account() {
  380|       |        let chain1 = SavedAccountChain::new();
  381|       |        let chain2 = SavedAccountChain::new();
  382|       |        assert_ne!(chain1.account, chain2.account);
  383|       |    }
  384|       |
  385|       |    #[test]
  386|       |    fn add_legacy_open() {
  387|       |        let mut genesis = SavedAccountChain::genesis();
  388|       |        let mut chain = SavedAccountChain::new();
  389|       |        genesis.add_legacy_send_to(chain.account, Amount::raw(10));
  390|       |        chain.add_legacy_open_from_account(&genesis);
  391|       |        let block = chain.latest_block();
  392|       |        assert_eq!(block.account_field(), Some(chain.account()));
  393|       |        assert_eq!(block.block_type(), BlockType::LegacyOpen);
  394|       |        assert_eq!(block.height(), 1);
  395|       |        assert_eq!(chain.frontier(), block.hash());
  396|       |        assert_eq!(chain.height(), 1);
  397|       |        assert_eq!(
  398|       |            chain.account_info().representative,
  399|       |            block.representative_field().unwrap()
  400|       |        );
  401|       |    }
  402|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/saved_block_lattice_builder.rs:
    1|       |use crate::{
    2|       |    blocks::{
    3|       |        open_block::OpenBlockArgs, receive_block::ReceiveBlockArgs, send_block::SendBlockArgs,
    4|       |        state_block::EpochBlockArgs,
    5|       |    },
    6|       |    dev_epoch1_signer, epoch_v1_link,
    7|       |    utils::UnixTimestamp,
    8|       |    work::{WorkPool, WorkPoolImpl},
    9|       |    Account, Amount, Block, BlockDetails, BlockHash, BlockSideband, ChangeBlockArgs, Epoch, Link,
   10|       |    PendingInfo, PendingKey, PrivateKey, PublicKey, Root, SavedBlock, StateBlockArgs,
   11|       |    DEV_GENESIS_BLOCK, DEV_GENESIS_KEY,
   12|       |};
   13|       |use std::collections::HashMap;
   14|       |
   15|       |pub struct SavedBlockLatticeBuilder {
   16|       |    accounts: HashMap<Account, Frontier>,
   17|       |    work_pool: WorkPoolImpl,
   18|       |    pending_receives: HashMap<PendingKey, PendingInfo>,
   19|       |    now: UnixTimestamp,
   20|       |}
   21|       |
   22|       |#[derive(Clone, Default)]
   23|       |struct Frontier {
   24|       |    hash: BlockHash,
   25|       |    representative: PublicKey,
   26|       |    balance: Amount,
   27|       |    height: u64,
   28|       |}
   29|       |
   30|       |impl SavedBlockLatticeBuilder {
   31|      2|    pub fn new() -> Self {
   32|      2|        let mut accounts = HashMap::new();
   33|      2|        accounts.insert(
   34|      2|            DEV_GENESIS_KEY.account(),
   35|      2|            Frontier {
   36|      2|                hash: DEV_GENESIS_BLOCK.hash(),
   37|      2|                representative: DEV_GENESIS_KEY.public_key(),
   38|      2|                balance: Amount::MAX,
   39|      2|                height: 1,
   40|      2|            },
   41|      2|        );
   42|      2|        let work_pool = WorkPoolImpl::new_dev();
   43|      2|        Self {
   44|      2|            accounts,
   45|      2|            work_pool,
   46|      2|            pending_receives: Default::default(),
   47|      2|            now: UnixTimestamp::new(42),
   48|      2|        }
   49|      2|    }
   50|       |
   51|      0|    pub fn set_now(&mut self, now: UnixTimestamp) {
   52|      0|        self.now = now;
   53|      0|    }
   54|       |
   55|      0|    pub fn advance_time(&mut self) {
   56|      0|        self.now = self.now.add(1);
   57|      0|    }
   58|       |
   59|      0|    pub fn genesis(&mut self) -> SavedAccountChainBuilder {
   60|      0|        self.account(&DEV_GENESIS_KEY)
   61|      0|    }
   62|       |
   63|     32|    pub fn account<'a>(&'a mut self, key: &'a PrivateKey) -> SavedAccountChainBuilder<'a> {
   64|     32|        SavedAccountChainBuilder { lattice: self, key }
   65|     32|    }
   66|       |
   67|      0|    pub fn epoch_open(&mut self, account: impl Into<Account>) -> SavedBlock {
   68|      0|        let account = account.into();
   69|      0|        assert!(!self.accounts.contains_key(&account));
   70|      0|        assert!(self
   71|      0|            .pending_receives
   72|      0|            .keys()
   73|      0|            .any(|k| k.receiving_account == account));
   74|       |
   75|      0|        let receive: Block = EpochBlockArgs {
   76|      0|            epoch_signer: dev_epoch1_signer(),
   77|      0|            account,
   78|      0|            previous: BlockHash::zero(),
   79|      0|            representative: PublicKey::zero(),
   80|      0|            balance: Amount::zero(),
   81|      0|            link: epoch_v1_link(),
   82|      0|            work: self.work_pool.generate_dev2(account.into()).unwrap(),
   83|      0|        }
   84|      0|        .into();
   85|      0|
   86|      0|        let new_frontier = Frontier {
   87|      0|            hash: receive.hash(),
   88|      0|            representative: PublicKey::zero(),
   89|      0|            balance: Amount::zero(),
   90|      0|            height: 1,
   91|      0|        };
   92|      0|
   93|      0|        let sideband = self.sideband_for(account, &Frontier::default(), &new_frontier);
   94|      0|
   95|      0|        self.accounts.insert(account, new_frontier);
   96|      0|
   97|      0|        SavedBlock::new(receive, sideband)
   98|      0|    }
   99|       |
  100|     32|    fn sideband_for(
  101|     32|        &self,
  102|     32|        account: Account,
  103|     32|        old_frontier: &Frontier,
  104|     32|        new_frontier: &Frontier,
  105|     32|    ) -> BlockSideband {
  106|     32|        let is_send = new_frontier.balance < old_frontier.balance;
  107|     32|        let is_receive = new_frontier.balance > old_frontier.balance;
  108|     32|
  109|     32|        BlockSideband {
  110|     32|            height: new_frontier.height,
  111|     32|            timestamp: self.now,
  112|     32|            successor: BlockHash::zero(),
  113|     32|            account,
  114|     32|            balance: new_frontier.balance,
  115|     32|            details: BlockDetails::new(Epoch::Epoch0, is_send, is_receive, false), //TODO epoch
  116|     32|            source_epoch: Epoch::Epoch0,                                           //TODO
  117|     32|        }
  118|     32|    }
  119|       |
  120|      4|    fn pop_pending_receive(
  121|      4|        &mut self,
  122|      4|        receiving_account: impl Into<Account>,
  123|      4|        send_hash: BlockHash,
  124|      4|    ) -> PendingInfo {
  125|      4|        self.pending_receives
  126|      4|            .remove(&PendingKey::new(receiving_account.into(), send_hash))
  127|      4|            .expect("no pending receive found")
  128|      4|    }
  129|       |}
  130|       |
  131|       |impl Clone for SavedBlockLatticeBuilder {
  132|      0|    fn clone(&self) -> Self {
  133|      0|        Self {
  134|      0|            accounts: self.accounts.clone(),
  135|      0|            work_pool: WorkPoolImpl::new_dev(),
  136|      0|            pending_receives: self.pending_receives.clone(),
  137|      0|            now: self.now,
  138|      0|        }
  139|      0|    }
  140|       |}
  141|       |
  142|       |pub struct SavedAccountChainBuilder<'a> {
  143|       |    lattice: &'a mut SavedBlockLatticeBuilder,
  144|       |    key: &'a PrivateKey,
  145|       |}
  146|       |
  147|       |impl<'a> SavedAccountChainBuilder<'a> {
  148|      0|    pub fn send_max(&mut self, destination: impl Into<Account>) -> SavedBlock {
  149|      0|        self.send_all_except(destination, 0)
  150|      0|    }
  151|       |
  152|      0|    pub fn send_all_except(
  153|      0|        &mut self,
  154|      0|        destination: impl Into<Account>,
  155|      0|        keep: impl Into<Amount>,
  156|      0|    ) -> SavedBlock {
  157|      0|        let frontier = self.get_frontier();
  158|      0|        self.send(destination, frontier.balance - keep.into())
  159|      0|    }
  160|       |
  161|     28|    pub fn send(
  162|     28|        &mut self,
  163|     28|        destination: impl Into<Account>,
  164|     28|        amount: impl Into<Amount>,
  165|     28|    ) -> SavedBlock {
  166|     28|        let destination = destination.into();
  167|     28|        let old_frontier = self.get_frontier();
  168|     28|        let amount = amount.into();
  169|     28|        let new_balance = old_frontier.balance - amount;
  170|     28|
  171|     28|        let send: Block = StateBlockArgs {
  172|     28|            key: self.key,
  173|     28|            previous: old_frontier.hash,
  174|     28|            representative: old_frontier.representative,
  175|     28|            balance: new_balance,
  176|     28|            link: destination.into(),
  177|     28|            work: self
  178|     28|                .lattice
  179|     28|                .work_pool
  180|     28|                .generate_dev2(old_frontier.hash.into())
  181|     28|                .unwrap(),
  182|     28|        }
  183|     28|        .into();
  184|     28|
  185|     28|        let new_frontier = Frontier {
  186|     28|            hash: send.hash(),
  187|     28|            representative: old_frontier.representative,
  188|     28|            balance: new_balance,
  189|     28|            height: old_frontier.height + 1,
  190|     28|        };
  191|     28|
  192|     28|        let sideband = self
  193|     28|            .lattice
  194|     28|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  195|     28|
  196|     28|        self.set_new_frontier(new_frontier);
  197|     28|        self.lattice.pending_receives.insert(
  198|     28|            PendingKey::new(destination, send.hash()),
  199|     28|            PendingInfo {
  200|     28|                source: self.key.account(),
  201|     28|                amount,
  202|     28|                epoch: Epoch::Epoch0,
  203|     28|            },
  204|     28|        );
  205|     28|
  206|     28|        SavedBlock::new(send, sideband)
  207|     28|    }
  208|       |
  209|      0|    pub fn legacy_send(
  210|      0|        &mut self,
  211|      0|        destination: impl Into<Account>,
  212|      0|        amount: impl Into<Amount>,
  213|      0|    ) -> SavedBlock {
  214|      0|        let destination = destination.into();
  215|      0|        let old_frontier = self.get_frontier();
  216|      0|        let amount = amount.into();
  217|      0|        let new_balance = old_frontier.balance - amount;
  218|      0|
  219|      0|        let work = self
  220|      0|            .lattice
  221|      0|            .work_pool
  222|      0|            .generate_dev2(old_frontier.hash.into())
  223|      0|            .unwrap();
  224|      0|
  225|      0|        let send: Block = SendBlockArgs {
  226|      0|            key: self.key,
  227|      0|            previous: old_frontier.hash,
  228|      0|            destination,
  229|      0|            balance: new_balance,
  230|      0|            work,
  231|      0|        }
  232|      0|        .into();
  233|      0|
  234|      0|        let new_frontier = Frontier {
  235|      0|            hash: send.hash(),
  236|      0|            balance: new_balance,
  237|      0|            height: old_frontier.height,
  238|      0|            ..old_frontier
  239|      0|        };
  240|      0|
  241|      0|        let sideband = self
  242|      0|            .lattice
  243|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  244|      0|
  245|      0|        self.set_new_frontier(new_frontier);
  246|      0|
  247|      0|        self.lattice.pending_receives.insert(
  248|      0|            PendingKey::new(destination, send.hash()),
  249|      0|            PendingInfo {
  250|      0|                source: self.key.account(),
  251|      0|                amount,
  252|      0|                epoch: Epoch::Epoch0,
  253|      0|            },
  254|      0|        );
  255|      0|
  256|      0|        SavedBlock::new(send, sideband)
  257|      0|    }
  258|       |
  259|      0|    pub fn legacy_open(&mut self, corresponding_send: &Block) -> SavedBlock {
  260|      0|        self.legacy_open_with_rep(corresponding_send, self.key.public_key())
  261|      0|    }
  262|       |
  263|      0|    pub fn legacy_open_with_rep(
  264|      0|        &mut self,
  265|      0|        corresponding_send: &Block,
  266|      0|        new_representative: impl Into<PublicKey>,
  267|      0|    ) -> SavedBlock {
  268|      0|        assert!(!self.lattice.accounts.contains_key(&self.key.account()));
  269|      0|        assert_eq!(corresponding_send.destination_or_link(), self.key.account());
  270|       |
  271|      0|        let amount = self
  272|      0|            .lattice
  273|      0|            .pop_pending_receive(self.key, corresponding_send.hash())
  274|      0|            .amount;
  275|      0|
  276|      0|        let root: Root = self.key.account().into();
  277|      0|
  278|      0|        let work = self.lattice.work_pool.generate_dev2(root).unwrap();
  279|      0|        let receive: Block = OpenBlockArgs {
  280|      0|            key: &self.key,
  281|      0|            source: corresponding_send.hash(),
  282|      0|            representative: new_representative.into(),
  283|      0|            work,
  284|      0|        }
  285|      0|        .into();
  286|      0|
  287|      0|        let old_frontier = Frontier::default();
  288|      0|
  289|      0|        let new_frontier = Frontier {
  290|      0|            hash: receive.hash(),
  291|      0|            representative: self.key.public_key(),
  292|      0|            balance: amount,
  293|      0|            height: 1,
  294|      0|        };
  295|      0|
  296|      0|        let sideband = self
  297|      0|            .lattice
  298|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  299|      0|
  300|      0|        self.set_new_frontier(new_frontier);
  301|      0|
  302|      0|        SavedBlock::new(receive, sideband)
  303|      0|    }
  304|       |
  305|      0|    pub fn legacy_receive(&mut self, corresponding_send: &Block) -> SavedBlock {
  306|      0|        let frontier = self.get_frontier();
  307|      0|        self.legacy_receive_with_rep(corresponding_send, frontier.representative)
  308|      0|    }
  309|       |
  310|      0|    pub fn legacy_receive_with_rep(
  311|      0|        &mut self,
  312|      0|        corresponding_send: &Block,
  313|      0|        new_representative: impl Into<PublicKey>,
  314|      0|    ) -> SavedBlock {
  315|      0|        assert_eq!(corresponding_send.destination_or_link(), self.key.account());
  316|      0|        let amount = self
  317|      0|            .lattice
  318|      0|            .pop_pending_receive(self.key, corresponding_send.hash())
  319|      0|            .amount;
  320|      0|
  321|      0|        let old_frontier = self.get_frontier();
  322|      0|        let root: Root = old_frontier.hash.into();
  323|      0|        let new_balance = old_frontier.balance + amount;
  324|      0|        let work = self.lattice.work_pool.generate_dev2(root).unwrap();
  325|      0|
  326|      0|        let receive: Block = ReceiveBlockArgs {
  327|      0|            key: self.key,
  328|      0|            previous: old_frontier.hash,
  329|      0|            source: corresponding_send.hash(),
  330|      0|            work,
  331|      0|        }
  332|      0|        .into();
  333|      0|
  334|      0|        let new_frontier = Frontier {
  335|      0|            hash: receive.hash(),
  336|      0|            representative: new_representative.into(),
  337|      0|            balance: new_balance,
  338|      0|            height: old_frontier.height + 1,
  339|      0|        };
  340|      0|
  341|      0|        let sideband = self
  342|      0|            .lattice
  343|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  344|      0|
  345|      0|        self.set_new_frontier(new_frontier);
  346|      0|
  347|      0|        SavedBlock::new(receive, sideband)
  348|      0|    }
  349|       |
  350|      4|    pub fn receive(&mut self, corresponding_send: &Block) -> SavedBlock {
  351|      4|        let frontier = self.get_frontier_or_empty();
  352|      4|        self.receive_and_change(corresponding_send, frontier.representative)
  353|      4|    }
  354|       |
  355|      4|    pub fn receive_and_change(
  356|      4|        &mut self,
  357|      4|        corresponding_send: &Block,
  358|      4|        new_representative: impl Into<PublicKey>,
  359|      4|    ) -> SavedBlock {
  360|      4|        assert_eq!(corresponding_send.destination_or_link(), self.key.account());
  361|      4|        let amount = self
  362|      4|            .lattice
  363|      4|            .pop_pending_receive(self.key, corresponding_send.hash())
  364|      4|            .amount;
  365|      4|
  366|      4|        let old_frontier = self.get_frontier_or_empty();
  367|       |
  368|      4|        let root: Root = if old_frontier.hash.is_zero() {
  369|      4|            self.key.account().into()
  370|       |        } else {
  371|      0|            old_frontier.hash.into()
  372|       |        };
  373|       |
  374|      4|        let new_balance = old_frontier.balance + amount;
  375|      4|
  376|      4|        let receive: Block = StateBlockArgs {
  377|      4|            key: self.key,
  378|      4|            previous: old_frontier.hash,
  379|      4|            representative: new_representative.into(),
  380|      4|            balance: new_balance,
  381|      4|            link: corresponding_send.hash().into(),
  382|      4|            work: self.lattice.work_pool.generate_dev2(root).unwrap(),
  383|      4|        }
  384|      4|        .into();
  385|      4|
  386|      4|        let new_frontier = Frontier {
  387|      4|            hash: receive.hash(),
  388|      4|            representative: old_frontier.representative,
  389|      4|            balance: new_balance,
  390|      4|            height: old_frontier.height + 1,
  391|      4|        };
  392|      4|
  393|      4|        let sideband = self
  394|      4|            .lattice
  395|      4|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  396|      4|
  397|      4|        self.set_new_frontier(new_frontier);
  398|      4|
  399|      4|        SavedBlock::new(receive, sideband)
  400|      4|    }
  401|       |
  402|      0|    pub fn legacy_change(&mut self, new_representative: impl Into<PublicKey>) -> SavedBlock {
  403|      0|        let old_frontier = self.get_frontier();
  404|      0|        let new_representative = new_representative.into();
  405|      0|        let work = self
  406|      0|            .lattice
  407|      0|            .work_pool
  408|      0|            .generate_dev2(old_frontier.hash.into())
  409|      0|            .unwrap();
  410|      0|
  411|      0|        let change: Block = ChangeBlockArgs {
  412|      0|            key: self.key,
  413|      0|            previous: old_frontier.hash,
  414|      0|            representative: new_representative,
  415|      0|            work,
  416|      0|        }
  417|      0|        .into();
  418|      0|
  419|      0|        let new_frontier = Frontier {
  420|      0|            hash: change.hash(),
  421|      0|            representative: new_representative,
  422|      0|            height: old_frontier.height + 1,
  423|      0|            ..old_frontier
  424|      0|        };
  425|      0|
  426|      0|        let sideband = self
  427|      0|            .lattice
  428|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  429|      0|
  430|      0|        self.set_new_frontier(new_frontier);
  431|      0|
  432|      0|        SavedBlock::new(change, sideband)
  433|      0|    }
  434|       |
  435|      0|    pub fn change(&mut self, new_representative: impl Into<PublicKey>) -> SavedBlock {
  436|      0|        let old_frontier = self.get_frontier();
  437|      0|        let new_representative = new_representative.into();
  438|      0|        let change: Block = StateBlockArgs {
  439|      0|            key: self.key,
  440|      0|            previous: old_frontier.hash,
  441|      0|            representative: new_representative,
  442|      0|            balance: old_frontier.balance,
  443|      0|            link: Link::zero(),
  444|      0|            work: self
  445|      0|                .lattice
  446|      0|                .work_pool
  447|      0|                .generate_dev2(old_frontier.hash.into())
  448|      0|                .unwrap(),
  449|      0|        }
  450|      0|        .into();
  451|      0|
  452|      0|        let new_frontier = Frontier {
  453|      0|            hash: change.hash(),
  454|      0|            representative: new_representative,
  455|      0|            balance: old_frontier.balance,
  456|      0|            height: old_frontier.height + 1,
  457|      0|        };
  458|      0|        let sideband = self
  459|      0|            .lattice
  460|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  461|      0|        self.set_new_frontier(new_frontier);
  462|      0|
  463|      0|        SavedBlock::new(change, sideband)
  464|      0|    }
  465|       |
  466|      0|    pub fn epoch1(&mut self) -> SavedBlock {
  467|      0|        let old_frontier = self.get_frontier();
  468|      0|        let epoch: Block = EpochBlockArgs {
  469|      0|            epoch_signer: dev_epoch1_signer(),
  470|      0|            account: self.key.account(),
  471|      0|            previous: old_frontier.hash,
  472|      0|            representative: old_frontier.representative,
  473|      0|            balance: old_frontier.balance,
  474|      0|            link: epoch_v1_link(),
  475|      0|            work: self
  476|      0|                .lattice
  477|      0|                .work_pool
  478|      0|                .generate_dev2(old_frontier.hash.into())
  479|      0|                .unwrap(),
  480|      0|        }
  481|      0|        .into();
  482|      0|
  483|      0|        let new_frontier = Frontier {
  484|      0|            hash: epoch.hash(),
  485|      0|            height: old_frontier.height + 1,
  486|      0|            ..old_frontier
  487|      0|        };
  488|      0|
  489|      0|        let sideband = self
  490|      0|            .lattice
  491|      0|            .sideband_for(self.key.account(), &old_frontier, &new_frontier);
  492|      0|        self.set_new_frontier(new_frontier);
  493|      0|
  494|      0|        SavedBlock::new(epoch, sideband)
  495|      0|    }
  496|       |
  497|     32|    fn set_new_frontier(&mut self, new_frontier: Frontier) {
  498|     32|        self.lattice
  499|     32|            .accounts
  500|     32|            .insert(self.key.account(), new_frontier);
  501|     32|    }
  502|       |
  503|     28|    fn get_frontier(&self) -> Frontier {
  504|     28|        self.lattice
  505|     28|            .accounts
  506|     28|            .get(&self.key.account())
  507|     28|            .expect("Cannot send/change from unopenend account!")
  508|     28|            .clone()
  509|     28|    }
  510|       |
  511|      8|    fn get_frontier_or_empty(&self) -> Frontier {
  512|      8|        self.lattice
  513|      8|            .accounts
  514|      8|            .get(&self.key.account())
  515|      8|            .cloned()
  516|      8|            .unwrap_or_else(|| Frontier {
  517|      8|                hash: BlockHash::zero(),
  518|      8|                representative: self.key.public_key(),
  519|      8|                balance: Amount::zero(),
  520|      8|                height: 0,
  521|      8|            })
  522|      8|    }
  523|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/send.rs:
    1|       |use crate::{
    2|       |    blocks::send_block::SendBlockArgs,
    3|       |    work::{WorkPool, STUB_WORK_POOL},
    4|       |    Account, Amount, Block, BlockDetails, BlockHash, BlockSideband, Epoch, PrivateKey, SavedBlock,
    5|       |};
    6|       |
    7|       |pub struct TestLegacySendBlockBuilder {
    8|       |    previous: Option<BlockHash>,
    9|       |    destination: Option<Account>,
   10|       |    balance: Option<Amount>,
   11|       |    previous_balance: Option<Amount>,
   12|       |    work: Option<u64>,
   13|       |    priv_key: Option<PrivateKey>,
   14|       |}
   15|       |
   16|       |impl TestLegacySendBlockBuilder {
   17|      0|    pub(super) fn new() -> Self {
   18|      0|        Self {
   19|      0|            previous: None,
   20|      0|            destination: None,
   21|      0|            balance: None,
   22|      0|            previous_balance: None,
   23|      0|            work: None,
   24|      0|            priv_key: None,
   25|      0|        }
   26|      0|    }
   27|       |
   28|      0|    pub fn previous(mut self, hash: BlockHash) -> Self {
   29|      0|        self.previous = Some(hash);
   30|      0|        self
   31|      0|    }
   32|       |
   33|      0|    pub fn destination(mut self, destination: Account) -> Self {
   34|      0|        self.destination = Some(destination);
   35|      0|        self
   36|      0|    }
   37|       |
   38|      0|    pub fn balance(mut self, balance: impl Into<Amount>) -> Self {
   39|      0|        self.balance = Some(balance.into());
   40|      0|        self
   41|      0|    }
   42|       |
   43|      0|    pub fn previous_balance(mut self, balance: Amount) -> Self {
   44|      0|        self.previous_balance = Some(balance);
   45|      0|        self
   46|      0|    }
   47|       |
   48|      0|    pub fn amount(mut self, amount: impl Into<Amount>) -> Self {
   49|      0|        let previous_balance = self
   50|      0|            .previous_balance
   51|      0|            .expect("no previous balance specified");
   52|      0|        self.balance = Some(previous_balance - amount.into());
   53|      0|        self
   54|      0|    }
   55|       |
   56|      0|    pub fn sign(mut self, priv_key: PrivateKey) -> Self {
   57|      0|        self.priv_key = Some(priv_key);
   58|      0|        self
   59|      0|    }
   60|       |
   61|      0|    pub fn work(mut self, work: u64) -> Self {
   62|      0|        self.work = Some(work);
   63|      0|        self
   64|      0|    }
   65|       |
   66|      0|    pub fn build(self) -> Block {
   67|      0|        let priv_key = self.priv_key.unwrap_or_default();
   68|      0|        let previous = self.previous.unwrap_or(BlockHash::from(1));
   69|      0|        let destination = self.destination.unwrap_or(Account::from(2));
   70|      0|        let balance = self.balance.unwrap_or(Amount::raw(3));
   71|      0|        let work = self
   72|      0|            .work
   73|      0|            .unwrap_or_else(|| STUB_WORK_POOL.generate_dev2(previous.into()).unwrap());
   74|      0|
   75|      0|        SendBlockArgs {
   76|      0|            key: &priv_key,
   77|      0|            previous,
   78|      0|            destination,
   79|      0|            balance,
   80|      0|            work,
   81|      0|        }
   82|      0|        .into()
   83|      0|    }
   84|       |
   85|      0|    pub fn build_saved(self) -> SavedBlock {
   86|      0|        let block = self.build();
   87|      0|
   88|      0|        let details = BlockDetails::new(Epoch::Epoch0, true, false, false);
   89|      0|        let sideband = BlockSideband {
   90|      0|            account: Account::from(4),
   91|      0|            successor: BlockHash::zero(),
   92|      0|            balance: block.balance_field().unwrap(),
   93|      0|            height: 5,
   94|      0|            timestamp: 8.into(),
   95|      0|            details,
   96|      0|            source_epoch: Epoch::Epoch0,
   97|      0|        };
   98|      0|        SavedBlock::new(block, sideband)
   99|      0|    }
  100|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/state.rs:
    1|       |use crate::blocks::state_block::EpochBlockArgs;
    2|       |use crate::work::WorkPool;
    3|       |use crate::{work::STUB_WORK_POOL, StateBlock};
    4|       |use crate::{
    5|       |    Account, Amount, Block, BlockBase, BlockDetails, BlockHash, BlockSideband, Epoch, Link,
    6|       |    PrivateKey, PublicKey, SavedBlock, Signature, StateBlockArgs,
    7|       |};
    8|       |use anyhow::Result;
    9|       |
   10|       |pub struct TestStateBlockBuilder {
   11|       |    account: Option<Account>,
   12|       |    previous: BlockHash,
   13|       |    representative: PublicKey,
   14|       |    balance: Amount,
   15|       |    link: Link,
   16|       |    priv_key: PrivateKey,
   17|       |    work: Option<u64>,
   18|       |    signature: Option<Signature>,
   19|       |    previous_balance: Option<Amount>,
   20|       |}
   21|       |
   22|       |impl TestStateBlockBuilder {
   23|      1|    pub(super) fn new() -> Self {
   24|      1|        let key = PrivateKey::new();
   25|      1|        Self {
   26|      1|            account: None,
   27|      1|            previous: BlockHash::from(2),
   28|      1|            representative: PublicKey::from(3),
   29|      1|            balance: Amount::from(4),
   30|      1|            link: Link::from(5),
   31|      1|            priv_key: key,
   32|      1|            previous_balance: None,
   33|      1|            work: None,
   34|      1|            signature: None,
   35|      1|        }
   36|      1|    }
   37|       |
   38|      0|    pub fn from(mut self, other: &StateBlock) -> Self {
   39|      0|        self.account = Some(other.account());
   40|      0|        self.previous = other.previous();
   41|      0|        self.representative = other.representative();
   42|      0|        self.balance = other.balance();
   43|      0|        self.link = other.link();
   44|      0|        self.signature = Some(other.signature().clone());
   45|      0|        self.work = Some(other.work());
   46|      0|        self
   47|      0|    }
   48|       |
   49|      0|    pub fn previous_balance(mut self, balance: Amount) -> Self {
   50|      0|        self.previous_balance = Some(balance);
   51|      0|        self
   52|      0|    }
   53|       |
   54|      1|    pub fn account(mut self, account: impl Into<Account>) -> Self {
   55|      1|        self.account = Some(account.into());
   56|      1|        self
   57|      1|    }
   58|       |
   59|      0|    pub fn account_address(self, address: impl AsRef<str>) -> Result<Self> {
   60|      0|        Ok(self.account(Account::decode_account(address)?))
   61|      0|    }
   62|       |
   63|      1|    pub fn previous(mut self, previous: impl Into<BlockHash>) -> Self {
   64|      1|        self.previous = previous.into();
   65|      1|        self
   66|      1|    }
   67|       |
   68|      0|    pub fn previous_hex(self, previous: impl AsRef<str>) -> Result<Self> {
   69|      0|        Ok(self.previous(BlockHash::decode_hex(previous)?))
   70|      0|    }
   71|       |
   72|      1|    pub fn representative(mut self, rep: impl Into<PublicKey>) -> Self {
   73|      1|        self.representative = rep.into();
   74|      1|        self
   75|      1|    }
   76|       |
   77|      0|    pub fn representative_address(self, address: impl AsRef<str>) -> Result<Self> {
   78|      0|        Ok(self.representative(Account::decode_account(address)?))
   79|      0|    }
   80|       |
   81|      1|    pub fn balance(mut self, balance: impl Into<Amount>) -> Self {
   82|      1|        self.balance = balance.into();
   83|      1|        self
   84|      1|    }
   85|       |
   86|      0|    pub fn balance_dec(self, balance: impl AsRef<str>) -> Result<Self> {
   87|      0|        Ok(self.balance(balance.as_ref().parse::<u128>()?))
   88|      0|    }
   89|       |
   90|      0|    pub fn amount_sent(self, amount: impl Into<Amount>) -> Self {
   91|      0|        let previous_balance = self
   92|      0|            .previous_balance
   93|      0|            .expect("previous balance not specified");
   94|      0|        self.balance(previous_balance - amount.into())
   95|      0|    }
   96|       |
   97|      0|    pub fn amount_received(self, amount: impl Into<Amount>) -> Self {
   98|      0|        let previous_balance = self
   99|      0|            .previous_balance
  100|      0|            .expect("previous balance not specified");
  101|      0|        self.balance(previous_balance + amount.into())
  102|      0|    }
  103|       |
  104|      1|    pub fn link(mut self, link: impl Into<Link>) -> Self {
  105|      1|        self.link = link.into();
  106|      1|        self
  107|      1|    }
  108|       |
  109|      0|    pub fn link_hex(self, link: impl AsRef<str>) -> Result<Self> {
  110|      0|        Ok(self.link(Link::decode_hex(link)?))
  111|      0|    }
  112|       |
  113|      1|    pub fn key(mut self, key: &PrivateKey) -> Self {
  114|      1|        self.signature = None;
  115|      1|        self.priv_key = key.clone();
  116|      1|        self
  117|      1|    }
  118|       |
  119|      0|    pub fn signature(mut self, signature: Signature) -> Self {
  120|      0|        self.signature = Some(signature);
  121|      0|        self
  122|      0|    }
  123|       |
  124|      0|    pub fn sign_zero(self) -> Self {
  125|      0|        self.signature(Signature::new())
  126|      0|    }
  127|       |
  128|      0|    pub fn work(mut self, work: u64) -> Self {
  129|      0|        self.work = Some(work);
  130|      0|        self
  131|      0|    }
  132|       |
  133|      0|    pub fn zero(mut self) -> Self {
  134|      0|        self.account = Some(Account::zero());
  135|      0|        self.previous = BlockHash::zero();
  136|      0|        self.representative = PublicKey::zero();
  137|      0|        self.balance = Amount::zero();
  138|      0|        self.link = Link::zero();
  139|      0|        self.signature = None;
  140|      0|        self.work = Some(0);
  141|      0|        self
  142|      0|    }
  143|       |
  144|      1|    pub fn build(self) -> Block {
  145|      1|        let account = self.account.unwrap_or_else(|| self.priv_key.account());
                                                                   ^0
  146|      1|        let work = self.work.unwrap_or_else(|| {
  147|      1|            let root = if self.previous.is_zero() {
  148|      0|                account.into()
  149|       |            } else {
  150|      1|                self.previous.into()
  151|       |            };
  152|      1|            STUB_WORK_POOL.generate_dev2(root).unwrap()
  153|      1|        });
  154|       |
  155|      1|        let mut block: Block = match self.account {
  156|      1|            Some(account) => {
  157|      1|                // Misuse the epoch block constructor, so that we can create the block
  158|      1|                // for the given account
  159|      1|                EpochBlockArgs {
  160|      1|                    account,
  161|      1|                    previous: self.previous,
  162|      1|                    representative: self.representative,
  163|      1|                    balance: self.balance,
  164|      1|                    link: self.link,
  165|      1|                    epoch_signer: &self.priv_key,
  166|      1|                    work,
  167|      1|                }
  168|      1|                .into()
  169|       |            }
  170|      0|            None => StateBlockArgs {
  171|      0|                key: &self.priv_key,
  172|      0|                previous: self.previous,
  173|      0|                representative: self.representative,
  174|      0|                balance: self.balance,
  175|      0|                link: self.link,
  176|      0|                work,
  177|      0|            }
  178|      0|            .into(),
  179|       |        };
  180|       |
  181|      1|        if let Some(signature) = self.signature {
                                  ^0
  182|      0|            block.set_signature(signature);
  183|      1|        }
  184|       |
  185|      1|        block
  186|      1|    }
  187|       |
  188|      0|    pub fn build_saved(self) -> SavedBlock {
  189|      0|        let block = self.build();
  190|      0|
  191|      0|        let details = BlockDetails::new(Epoch::Epoch0, true, false, false);
  192|      0|        let sideband = BlockSideband {
  193|      0|            height: 5,
  194|      0|            timestamp: 6.into(),
  195|      0|            successor: BlockHash::zero(),
  196|      0|            account: block.account_field().unwrap(),
  197|      0|            balance: block.balance_field().unwrap(),
  198|      0|            details,
  199|      0|            source_epoch: Epoch::Epoch0,
  200|      0|        };
  201|      0|        SavedBlock::new(block, sideband)
  202|      0|    }
  203|       |}
  204|       |
  205|       |#[cfg(test)]
  206|       |mod tests {
  207|       |    use super::*;
  208|       |    use crate::{BlockBase, TestBlockBuilder};
  209|       |
  210|       |    #[test]
  211|       |    fn state_block() {
  212|       |        let Block::State(block1) = TestBlockBuilder::state()
  213|       |            .account(3)
  214|       |            .previous(1)
  215|       |            .representative(6)
  216|       |            .balance(2)
  217|       |            .link(4)
  218|       |            .work(5)
  219|       |            .build()
  220|       |        else {
  221|       |            panic!("not a state block")
  222|       |        };
  223|       |
  224|       |        assert_eq!(block1.account(), Account::from(3));
  225|       |        assert_eq!(block1.previous(), BlockHash::from(1));
  226|       |        assert_eq!(block1.representative(), Account::from(6).into());
  227|       |        assert_eq!(block1.balance(), Amount::raw(2));
  228|       |        assert_eq!(block1.link(), Link::from(4));
  229|       |    }
  230|       |
  231|       |    #[test]
  232|       |    fn copy_state_block() -> anyhow::Result<()> {
  233|       |        let block = TestBlockBuilder::state()
  234|       |            .account_address("xrb_15nhh1kzw3x8ohez6s75wy3jr6dqgq65oaede1fzk5hqxk4j8ehz7iqtb3to")?
  235|       |            .previous_hex("FEFBCE274E75148AB31FF63EFB3082EF1126BF72BF3FA9C76A97FD5A9F0EBEC5")?
  236|       |            .balance_dec("2251569974100400000000000000000000")?
  237|       |            .representative_address(
  238|       |                "xrb_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou",
  239|       |            )?
  240|       |            .link_hex("E16DD58C1EFA8B521545B0A74375AA994D9FC43828A4266D75ECF57F07A7EE86")?
  241|       |            .build();
  242|       |
  243|       |        assert_eq!(
  244|       |            block.hash().to_string(),
  245|       |            "2D243F8F92CDD0AD94A1D456A6B15F3BE7A6FCBD98D4C5831D06D15C818CD81F"
  246|       |        );
  247|       |
  248|       |        let Block::State(b) = &block else {
  249|       |            panic!("not a state block")
  250|       |        };
  251|       |        let block2 = TestBlockBuilder::state().from(&b).build();
  252|       |        assert_eq!(
  253|       |            block2.hash().to_string(),
  254|       |            "2D243F8F92CDD0AD94A1D456A6B15F3BE7A6FCBD98D4C5831D06D15C818CD81F"
  255|       |        );
  256|       |
  257|       |        let block3 = TestBlockBuilder::state()
  258|       |            .from(&b)
  259|       |            .sign_zero()
  260|       |            .work(0)
  261|       |            .build();
  262|       |        assert_eq!(
  263|       |            block3.hash().to_string(),
  264|       |            "2D243F8F92CDD0AD94A1D456A6B15F3BE7A6FCBD98D4C5831D06D15C818CD81F"
  265|       |        );
  266|       |        Ok(())
  267|       |    }
  268|       |
  269|       |    #[test]
  270|       |    /// Make sure manually- and builder constructed all-zero blocks have equal hashes, and check signature.
  271|       |    fn zeroed_state_block() {
  272|       |        let key = PrivateKey::from(42);
  273|       |        let zero_block_manual = TestBlockBuilder::state()
  274|       |            .account(0)
  275|       |            .previous(0)
  276|       |            .representative(0)
  277|       |            .balance(0)
  278|       |            .link(0)
  279|       |            .key(&key)
  280|       |            .work(0)
  281|       |            .build();
  282|       |
  283|       |        let zero_block_build = TestBlockBuilder::state().zero().key(&key).build();
  284|       |        assert_eq!(zero_block_manual.hash(), zero_block_build.hash());
  285|       |        key.public_key()
  286|       |            .verify(
  287|       |                zero_block_build.hash().as_bytes(),
  288|       |                zero_block_build.signature(),
  289|       |            )
  290|       |            .unwrap();
  291|       |    }
  292|       |
  293|       |    #[test]
  294|       |    fn state_block_from_live_network() -> Result<()> {
  295|       |        // Test against a random hash from the live network
  296|       |        let block = TestBlockBuilder::state()
  297|       |            .account_address("xrb_15nhh1kzw3x8ohez6s75wy3jr6dqgq65oaede1fzk5hqxk4j8ehz7iqtb3to")?
  298|       |            .previous_hex("FEFBCE274E75148AB31FF63EFB3082EF1126BF72BF3FA9C76A97FD5A9F0EBEC5")?
  299|       |            .balance_dec("2251569974100400000000000000000000")?
  300|       |            .representative_address(
  301|       |                "xrb_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou",
  302|       |            )?
  303|       |            .link_hex("E16DD58C1EFA8B521545B0A74375AA994D9FC43828A4266D75ECF57F07A7EE86")?
  304|       |            .build();
  305|       |        assert_eq!(
  306|       |            block.hash().to_string(),
  307|       |            "2D243F8F92CDD0AD94A1D456A6B15F3BE7A6FCBD98D4C5831D06D15C818CD81F"
  308|       |        );
  309|       |        assert!(block.source_field().is_none());
  310|       |        assert!(block.destination_field().is_none());
  311|       |        assert_eq!(
  312|       |            block.link_field().unwrap().encode_hex(),
  313|       |            "E16DD58C1EFA8B521545B0A74375AA994D9FC43828A4266D75ECF57F07A7EE86"
  314|       |        );
  315|       |        Ok(())
  316|       |    }
  317|       |
  318|       |    #[test]
  319|       |    fn state_equality() {
  320|       |        let key1 = PrivateKey::new();
  321|       |        let block1: Block = StateBlockArgs {
  322|       |            key: &key1,
  323|       |            previous: 1.into(),
  324|       |            representative: 3.into(),
  325|       |            balance: 2.into(),
  326|       |            link: 4.into(),
  327|       |            work: 5,
  328|       |        }
  329|       |        .into();
  330|       |
  331|       |        let block2 = TestBlockBuilder::state()
  332|       |            .account(key1.public_key())
  333|       |            .previous(1)
  334|       |            .representative(3)
  335|       |            .balance(2)
  336|       |            .link(4)
  337|       |            .key(&key1)
  338|       |            .work(5)
  339|       |            .build();
  340|       |
  341|       |        assert_eq!(block1.hash(), block2.hash());
  342|       |        assert_eq!(block1.work(), block2.work());
  343|       |    }
  344|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/builders/unsaved_block_lattice_builder.rs:
    1|       |use super::saved_block_lattice_builder::{SavedAccountChainBuilder, SavedBlockLatticeBuilder};
    2|       |use crate::{Account, Amount, Block, PrivateKey, PublicKey, DEV_GENESIS_KEY};
    3|       |
    4|       |#[derive(Clone)]
    5|       |pub struct UnsavedBlockLatticeBuilder {
    6|       |    inner: SavedBlockLatticeBuilder,
    7|       |}
    8|       |
    9|       |impl UnsavedBlockLatticeBuilder {
   10|      2|    pub fn new() -> Self {
   11|      2|        Self {
   12|      2|            inner: SavedBlockLatticeBuilder::new(),
   13|      2|        }
   14|      2|    }
   15|       |
   16|     28|    pub fn genesis(&mut self) -> UnsavedAccountChainBuilder {
   17|     28|        self.account(&DEV_GENESIS_KEY)
   18|     28|    }
   19|       |
   20|     32|    pub fn account<'a>(&'a mut self, key: &'a PrivateKey) -> UnsavedAccountChainBuilder<'a> {
   21|     32|        UnsavedAccountChainBuilder {
   22|     32|            inner: self.inner.account(key),
   23|     32|        }
   24|     32|    }
   25|       |
   26|      0|    pub fn epoch_open(&mut self, account: impl Into<Account>) -> Block {
   27|      0|        self.inner.epoch_open(account).block
   28|      0|    }
   29|       |}
   30|       |
   31|       |pub struct UnsavedAccountChainBuilder<'a> {
   32|       |    inner: SavedAccountChainBuilder<'a>,
   33|       |}
   34|       |
   35|       |impl<'a> UnsavedAccountChainBuilder<'a> {
   36|      0|    pub fn send_max(&mut self, destination: impl Into<Account>) -> Block {
   37|      0|        self.inner.send_max(destination).block
   38|      0|    }
   39|       |
   40|      0|    pub fn send_all_except(
   41|      0|        &mut self,
   42|      0|        destination: impl Into<Account>,
   43|      0|        keep: impl Into<Amount>,
   44|      0|    ) -> Block {
   45|      0|        self.inner.send_all_except(destination, keep).block
   46|      0|    }
   47|       |
   48|     28|    pub fn send(&mut self, destination: impl Into<Account>, amount: impl Into<Amount>) -> Block {
   49|     28|        self.inner.send(destination, amount).block
   50|     28|    }
   51|       |
   52|      0|    pub fn legacy_send(
   53|      0|        &mut self,
   54|      0|        destination: impl Into<Account>,
   55|      0|        amount: impl Into<Amount>,
   56|      0|    ) -> Block {
   57|      0|        self.inner.legacy_send(destination, amount).block
   58|      0|    }
   59|       |
   60|      0|    pub fn legacy_open(&mut self, corresponding_send: &Block) -> Block {
   61|      0|        self.inner.legacy_open(corresponding_send).block
   62|      0|    }
   63|       |
   64|      0|    pub fn legacy_open_with_rep(
   65|      0|        &mut self,
   66|      0|        corresponding_send: &Block,
   67|      0|        new_representative: impl Into<PublicKey>,
   68|      0|    ) -> Block {
   69|      0|        self.inner
   70|      0|            .legacy_open_with_rep(corresponding_send, new_representative)
   71|      0|            .block
   72|      0|    }
   73|       |
   74|      0|    pub fn legacy_receive(&mut self, corresponding_send: &Block) -> Block {
   75|      0|        self.inner.legacy_receive(corresponding_send).block
   76|      0|    }
   77|       |
   78|      0|    pub fn legacy_receive_with_rep(
   79|      0|        &mut self,
   80|      0|        corresponding_send: &Block,
   81|      0|        new_representative: impl Into<PublicKey>,
   82|      0|    ) -> Block {
   83|      0|        self.inner
   84|      0|            .legacy_open_with_rep(corresponding_send, new_representative)
   85|      0|            .block
   86|      0|    }
   87|       |
   88|      4|    pub fn receive(&mut self, corresponding_send: &Block) -> Block {
   89|      4|        self.inner.receive(corresponding_send).block
   90|      4|    }
   91|       |
   92|      0|    pub fn receive_and_change(
   93|      0|        &mut self,
   94|      0|        corresponding_send: &Block,
   95|      0|        new_representative: impl Into<PublicKey>,
   96|      0|    ) -> Block {
   97|      0|        self.inner
   98|      0|            .receive_and_change(corresponding_send, new_representative)
   99|      0|            .block
  100|      0|    }
  101|       |
  102|      0|    pub fn legacy_change(&mut self, new_representative: impl Into<PublicKey>) -> Block {
  103|      0|        self.inner.legacy_change(new_representative).block
  104|      0|    }
  105|       |
  106|      0|    pub fn change(&mut self, new_representative: impl Into<PublicKey>) -> Block {
  107|      0|        self.inner.change(new_representative).block
  108|      0|    }
  109|       |
  110|      0|    pub fn epoch1(&mut self) -> Block {
  111|      0|        self.inner.epoch1().block
  112|      0|    }
  113|       |}
  114|       |
  115|       |#[cfg(test)]
  116|       |mod tests {
  117|       |    use super::*;
  118|       |    use crate::{work::WorkThresholds, BlockDetails, BlockHash, StateBlockArgs, DEV_GENESIS_BLOCK};
  119|       |
  120|       |    #[test]
  121|       |    fn state_send() {
  122|       |        let mut lattice = UnsavedBlockLatticeBuilder::new();
  123|       |        let key1 = PrivateKey::from(42);
  124|       |
  125|       |        let send = lattice.genesis().send(&key1, 1);
  126|       |
  127|       |        let expected: Block = StateBlockArgs {
  128|       |            key: &DEV_GENESIS_KEY,
  129|       |            previous: DEV_GENESIS_BLOCK.hash(),
  130|       |            representative: DEV_GENESIS_KEY.public_key(),
  131|       |            balance: Amount::MAX - Amount::raw(1),
  132|       |            link: key1.account().into(),
  133|       |            work: send.work(),
  134|       |        }
  135|       |        .into();
  136|       |        assert_eq!(send, expected);
  137|       |        assert!(WorkThresholds::publish_dev().is_valid_pow(
  138|       |            &send,
  139|       |            &BlockDetails::new(crate::Epoch::Epoch2, true, false, false)
  140|       |        ))
  141|       |    }
  142|       |
  143|       |    #[test]
  144|       |    fn send_twice() {
  145|       |        let mut lattice = UnsavedBlockLatticeBuilder::new();
  146|       |        let key1 = PrivateKey::from(42);
  147|       |
  148|       |        let send1 = lattice.genesis().send(&key1, 1);
  149|       |        let send2 = lattice.genesis().send(&key1, 2);
  150|       |
  151|       |        let expected: Block = StateBlockArgs {
  152|       |            key: &DEV_GENESIS_KEY,
  153|       |            previous: send1.hash(),
  154|       |            representative: DEV_GENESIS_KEY.public_key(),
  155|       |            balance: Amount::MAX - Amount::raw(3),
  156|       |            link: key1.account().into(),
  157|       |            work: send2.work(),
  158|       |        }
  159|       |        .into();
  160|       |        assert_eq!(send2, expected);
  161|       |    }
  162|       |
  163|       |    #[test]
  164|       |    fn state_open() {
  165|       |        let mut lattice = UnsavedBlockLatticeBuilder::new();
  166|       |        let key1 = PrivateKey::from(42);
  167|       |        let send = lattice.genesis().send(&key1, 1);
  168|       |
  169|       |        let open = lattice.account(&key1).receive(&send);
  170|       |
  171|       |        let expected: Block = StateBlockArgs {
  172|       |            key: &key1,
  173|       |            previous: BlockHash::zero(),
  174|       |            representative: key1.public_key(),
  175|       |            balance: Amount::raw(1),
  176|       |            link: send.hash().into(),
  177|       |            work: open.work(),
  178|       |        }
  179|       |        .into();
  180|       |        assert_eq!(open, expected);
  181|       |        assert!(WorkThresholds::publish_dev().is_valid_pow(
  182|       |            &send,
  183|       |            &BlockDetails::new(crate::Epoch::Epoch2, false, true, false)
  184|       |        ))
  185|       |    }
  186|       |
  187|       |    #[test]
  188|       |    fn state_receive() {
  189|       |        let mut lattice = UnsavedBlockLatticeBuilder::new();
  190|       |        let key1 = PrivateKey::from(42);
  191|       |        let send1 = lattice.genesis().send(&key1, 1);
  192|       |        let send2 = lattice.genesis().send(&key1, 2);
  193|       |        let open = lattice.account(&key1).receive(&send1);
  194|       |
  195|       |        let receive = lattice.account(&key1).receive(&send2);
  196|       |
  197|       |        let expected: Block = StateBlockArgs {
  198|       |            key: &key1,
  199|       |            previous: open.hash(),
  200|       |            representative: key1.public_key(),
  201|       |            balance: Amount::raw(3),
  202|       |            link: send2.hash().into(),
  203|       |            work: receive.work(),
  204|       |        }
  205|       |        .into();
  206|       |        assert_eq!(receive, expected);
  207|       |    }
  208|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/change_block.rs:
    1|       |use super::{Block, BlockBase};
    2|       |use crate::{
    3|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount, BlockHash, BlockHashBuilder, BlockType, DependentBlocks, JsonBlock, Link,
    5|       |    PrivateKey, PublicKey, Root, Signature, WorkNonce,
    6|       |};
    7|       |use anyhow::Result;
    8|       |
    9|       |#[derive(Clone, Debug)]
   10|       |pub struct ChangeBlock {
   11|       |    work: u64,
   12|       |    signature: Signature,
   13|       |    hashables: ChangeHashables,
   14|       |    hash: BlockHash,
   15|       |}
   16|       |
   17|       |impl ChangeBlock {
   18|      0|    pub fn new_test_instance() -> Self {
   19|      0|        let key = PrivateKey::from(42);
   20|      0|        ChangeBlockArgs {
   21|      0|            key: &key,
   22|      0|            previous: 123.into(),
   23|      0|            representative: 456.into(),
   24|      0|            work: 69420,
   25|      0|        }
   26|      0|        .into()
   27|      0|    }
   28|       |
   29|      0|    pub fn mandatory_representative(&self) -> PublicKey {
   30|      0|        self.hashables.representative
   31|      0|    }
   32|       |
   33|      0|    pub fn serialized_size() -> usize {
   34|      0|        ChangeHashables::serialized_size()
   35|      0|            + Signature::serialized_size()
   36|      0|            + std::mem::size_of::<u64>()
   37|      0|    }
   38|       |
   39|      0|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
   40|      0|        let hashables = ChangeHashables {
   41|      0|            previous: BlockHash::deserialize(stream)?,
   42|      0|            representative: PublicKey::deserialize(stream)?,
   43|       |        };
   44|       |
   45|      0|        let signature = Signature::deserialize(stream)?;
   46|      0|        let mut work_bytes = [0u8; 8];
   47|      0|        stream.read_bytes(&mut work_bytes, 8)?;
   48|      0|        let work = u64::from_le_bytes(work_bytes);
   49|      0|        let hash = hashables.hash();
   50|      0|        Ok(Self {
   51|      0|            work,
   52|      0|            signature,
   53|      0|            hashables,
   54|      0|            hash,
   55|      0|        })
   56|      0|    }
   57|       |
   58|      0|    pub fn dependent_blocks(&self) -> DependentBlocks {
   59|      0|        DependentBlocks::new(self.previous(), BlockHash::zero())
   60|      0|    }
   61|       |}
   62|       |
   63|      0|pub fn valid_change_block_predecessor(predecessor: BlockType) -> bool {
   64|      0|    matches!(
   65|      0|        predecessor,
   66|       |        BlockType::LegacySend
   67|       |            | BlockType::LegacyReceive
   68|       |            | BlockType::LegacyOpen
   69|       |            | BlockType::LegacyChange
   70|       |    )
   71|      0|}
   72|       |
   73|       |impl PartialEq for ChangeBlock {
   74|      0|    fn eq(&self, other: &Self) -> bool {
   75|      0|        self.work == other.work
   76|      0|            && self.signature == other.signature
   77|      0|            && self.hashables == other.hashables
   78|      0|    }
   79|       |}
   80|       |
   81|       |impl Eq for ChangeBlock {}
   82|       |
   83|       |impl BlockBase for ChangeBlock {
   84|      0|    fn block_type(&self) -> BlockType {
   85|      0|        BlockType::LegacyChange
   86|      0|    }
   87|       |
   88|      0|    fn account_field(&self) -> Option<Account> {
   89|      0|        None
   90|      0|    }
   91|       |
   92|      0|    fn hash(&self) -> BlockHash {
   93|      0|        self.hash
   94|      0|    }
   95|       |
   96|      0|    fn link_field(&self) -> Option<Link> {
   97|      0|        None
   98|      0|    }
   99|       |
  100|      0|    fn signature(&self) -> &Signature {
  101|      0|        &self.signature
  102|      0|    }
  103|       |
  104|      0|    fn set_work(&mut self, work: u64) {
  105|      0|        self.work = work;
  106|      0|    }
  107|       |
  108|      0|    fn work(&self) -> u64 {
  109|      0|        self.work
  110|      0|    }
  111|       |
  112|      0|    fn set_signature(&mut self, signature: Signature) {
  113|      0|        self.signature = signature.clone();
  114|      0|    }
  115|       |
  116|      0|    fn previous(&self) -> BlockHash {
  117|      0|        self.hashables.previous
  118|      0|    }
  119|       |
  120|      0|    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter) {
  121|      0|        self.hashables.previous.serialize(writer);
  122|      0|        self.hashables.representative.serialize(writer);
  123|      0|        self.signature.serialize(writer);
  124|      0|        writer.write_bytes_safe(&self.work.to_le_bytes());
  125|      0|    }
  126|       |
  127|      0|    fn root(&self) -> Root {
  128|      0|        self.previous().into()
  129|      0|    }
  130|       |
  131|      0|    fn balance_field(&self) -> Option<Amount> {
  132|      0|        None
  133|      0|    }
  134|       |
  135|      0|    fn source_field(&self) -> Option<BlockHash> {
  136|      0|        None
  137|      0|    }
  138|       |
  139|      0|    fn representative_field(&self) -> Option<PublicKey> {
  140|      0|        Some(self.hashables.representative)
  141|      0|    }
  142|       |
  143|      0|    fn valid_predecessor(&self, block_type: BlockType) -> bool {
  144|      0|        valid_change_block_predecessor(block_type)
  145|      0|    }
  146|       |
  147|      0|    fn destination_field(&self) -> Option<Account> {
  148|      0|        None
  149|      0|    }
  150|       |
  151|      0|    fn json_representation(&self) -> JsonBlock {
  152|      0|        JsonBlock::Change(JsonChangeBlock {
  153|      0|            previous: self.hashables.previous,
  154|      0|            representative: self.hashables.representative.into(),
  155|      0|            work: self.work.into(),
  156|      0|            signature: self.signature.clone(),
  157|      0|        })
  158|      0|    }
  159|       |}
  160|       |
  161|       |#[derive(Clone, PartialEq, Eq, Debug)]
  162|       |struct ChangeHashables {
  163|       |    previous: BlockHash,
  164|       |    representative: PublicKey,
  165|       |}
  166|       |
  167|       |impl ChangeHashables {
  168|      0|    fn serialized_size() -> usize {
  169|      0|        BlockHash::serialized_size() + Account::serialized_size()
  170|      0|    }
  171|       |
  172|      0|    fn hash(&self) -> BlockHash {
  173|      0|        BlockHashBuilder::new()
  174|      0|            .update(self.previous.as_bytes())
  175|      0|            .update(self.representative.as_bytes())
  176|      0|            .build()
  177|      0|    }
  178|       |}
  179|       |
  180|       |pub struct ChangeBlockArgs<'a> {
  181|       |    pub key: &'a PrivateKey,
  182|       |    pub previous: BlockHash,
  183|       |    pub representative: PublicKey,
  184|       |    pub work: u64,
  185|       |}
  186|       |
  187|       |impl<'a> From<ChangeBlockArgs<'a>> for ChangeBlock {
  188|      0|    fn from(value: ChangeBlockArgs<'a>) -> Self {
  189|      0|        let hashables = ChangeHashables {
  190|      0|            previous: value.previous,
  191|      0|            representative: value.representative,
  192|      0|        };
  193|      0|
  194|      0|        let hash = hashables.hash();
  195|      0|        let signature = value.key.sign(hash.as_bytes());
  196|      0|
  197|      0|        Self {
  198|      0|            work: value.work,
  199|      0|            signature,
  200|      0|            hashables,
  201|      0|            hash,
  202|      0|        }
  203|      0|    }
  204|       |}
  205|       |
  206|       |impl<'a> From<ChangeBlockArgs<'a>> for Block {
  207|      0|    fn from(value: ChangeBlockArgs<'a>) -> Self {
  208|      0|        Block::LegacyChange(value.into())
  209|      0|    }
  210|       |}
  211|       |
  212|      0|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  213|       |pub struct JsonChangeBlock {
  214|       |    pub previous: BlockHash,
  215|       |    pub representative: Account,
  216|       |    pub signature: Signature,
  217|       |    pub work: WorkNonce,
  218|       |}
  219|       |
  220|       |impl From<JsonChangeBlock> for ChangeBlock {
  221|      0|    fn from(value: JsonChangeBlock) -> Self {
  222|      0|        let hashables = ChangeHashables {
  223|      0|            previous: value.previous,
  224|      0|            representative: value.representative.into(),
  225|      0|        };
  226|      0|
  227|      0|        let hash = hashables.hash();
  228|      0|
  229|      0|        Self {
  230|      0|            work: value.work.into(),
  231|      0|            signature: value.signature,
  232|      0|            hashables,
  233|      0|            hash,
  234|      0|        }
  235|      0|    }
  236|       |}
  237|       |
  238|       |#[cfg(test)]
  239|       |mod tests {
  240|       |    use super::*;
  241|       |    use crate::{utils::MemoryStream, Block, PrivateKey};
  242|       |
  243|       |    #[test]
  244|       |    fn create_block() {
  245|       |        let key1 = PrivateKey::new();
  246|       |        let previous = BlockHash::from(1);
  247|       |        let block: ChangeBlock = ChangeBlockArgs {
  248|       |            key: &key1,
  249|       |            previous,
  250|       |            representative: 2.into(),
  251|       |            work: 5,
  252|       |        }
  253|       |        .into();
  254|       |        assert_eq!(block.previous(), previous);
  255|       |        assert_eq!(block.root(), block.previous().into());
  256|       |    }
  257|       |
  258|       |    // original test: change_block.deserialize
  259|       |    #[test]
  260|       |    fn serialize() {
  261|       |        let key1 = PrivateKey::new();
  262|       |        let block1: ChangeBlock = ChangeBlockArgs {
  263|       |            key: &key1,
  264|       |            previous: 1.into(),
  265|       |            representative: 2.into(),
  266|       |            work: 5,
  267|       |        }
  268|       |        .into();
  269|       |        let mut stream = MemoryStream::new();
  270|       |        block1.serialize_without_block_type(&mut stream);
  271|       |        assert_eq!(ChangeBlock::serialized_size(), stream.bytes_written());
  272|       |
  273|       |        let block2 = ChangeBlock::deserialize(&mut stream).unwrap();
  274|       |        assert_eq!(block1, block2);
  275|       |    }
  276|       |
  277|       |    #[test]
  278|       |    fn serialize_serde() {
  279|       |        let block = Block::LegacyChange(ChangeBlock::new_test_instance());
  280|       |        let serialized = serde_json::to_string_pretty(&block).unwrap();
  281|       |        assert_eq!(
  282|       |            serialized,
  283|       |            r#"{
  284|       |  "type": "change",
  285|       |  "previous": "000000000000000000000000000000000000000000000000000000000000007B",
  286|       |  "representative": "nano_11111111111111111111111111111111111111111111111111gahteczqci",
  287|       |  "signature": "6F6E98FB9C3D0B91CBAF78C8613C7A7AE990AA627B9C1381D1D97AB7118C91D169381E3897A477286A4AFB68F7CD347F3FF16F8AB4C33241D8BF793CE29E730B",
  288|       |  "work": "0000000000010F2C"
  289|       |}"#
  290|       |        );
  291|       |    }
  292|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/mod.rs:
    1|       |mod block_details;
    2|       |mod block_priority;
    3|       |
    4|       |pub use block_details::BlockDetails;
    5|       |pub use block_priority::block_priority;
    6|       |
    7|       |mod block_sideband;
    8|       |pub use block_sideband::BlockSideband;
    9|       |
   10|       |mod change_block;
   11|       |use change_block::JsonChangeBlock;
   12|       |pub use change_block::{valid_change_block_predecessor, ChangeBlock, ChangeBlockArgs};
   13|       |
   14|       |mod open_block;
   15|       |pub use open_block::{JsonOpenBlock, OpenBlock, OpenBlockArgs};
   16|       |
   17|       |mod receive_block;
   18|       |pub use receive_block::{
   19|       |    valid_receive_block_predecessor, JsonReceiveBlock, ReceiveBlock, ReceiveBlockArgs,
   20|       |};
   21|       |
   22|       |mod send_block;
   23|       |use send_block::JsonSendBlock;
   24|       |pub use send_block::{valid_send_block_predecessor, SendBlock, SendBlockArgs};
   25|       |
   26|       |mod state_block;
   27|       |pub use state_block::{EpochBlockArgs, JsonStateBlock, StateBlock, StateBlockArgs};
   28|       |
   29|       |mod builders;
   30|       |pub use builders::*;
   31|       |
   32|       |use crate::{
   33|       |    utils::{BufferWriter, Deserialize, MemoryStream, Stream, UnixTimestamp},
   34|       |    Account, Amount, BlockHash, BlockHashBuilder, Epoch, Epochs, FullHash, Link, PrivateKey,
   35|       |    PublicKey, QualifiedRoot, Root, Signature,
   36|       |};
   37|       |use num::FromPrimitive;
   38|       |use std::{
   39|       |    ops::{Deref, DerefMut},
   40|       |    sync::LazyLock,
   41|       |};
   42|       |
   43|       |#[repr(u8)]
   44|  65.6k|#[derive(PartialEq, Eq, Debug, Clone, Copy, FromPrimitive)]
   45|       |pub enum BlockType {
   46|       |    Invalid = 0,
   47|       |    NotABlock = 1,
   48|       |    LegacySend = 2,
   49|       |    LegacyReceive = 3,
   50|       |    LegacyOpen = 4,
   51|       |    LegacyChange = 5,
   52|       |    State = 6,
   53|       |}
   54|       |
   55|       |impl TryFrom<BlockType> for BlockSubType {
   56|       |    type Error = anyhow::Error;
   57|       |
   58|      0|    fn try_from(value: BlockType) -> Result<Self, Self::Error> {
   59|      0|        match value {
   60|      0|            BlockType::LegacySend => Ok(BlockSubType::Send),
   61|      0|            BlockType::LegacyReceive => Ok(BlockSubType::Receive),
   62|      0|            BlockType::LegacyOpen => Ok(BlockSubType::Open),
   63|      0|            BlockType::LegacyChange => Ok(BlockSubType::Change),
   64|      0|            BlockType::State => Ok(BlockSubType::Send),
   65|       |            BlockType::Invalid | BlockType::NotABlock => {
   66|      0|                Err(anyhow!("Invalid block type for conversion to subtype"))
   67|       |            }
   68|       |        }
   69|      0|    }
   70|       |}
   71|       |
   72|       |impl TryFrom<u8> for BlockType {
   73|       |    type Error = anyhow::Error;
   74|       |
   75|      0|    fn try_from(value: u8) -> Result<Self, Self::Error> {
   76|      0|        FromPrimitive::from_u8(value).ok_or_else(|| anyhow!("invalid block type value"))
   77|      0|    }
   78|       |}
   79|       |
   80|       |#[derive(PartialEq, Eq, Debug, Clone, Copy)]
   81|       |pub enum BlockSubType {
   82|       |    Send,
   83|       |    Receive,
   84|       |    Open,
   85|       |    Change,
   86|       |    Epoch,
   87|       |}
   88|       |
   89|       |impl BlockSubType {
   90|      0|    pub fn as_str(&self) -> &'static str {
   91|      0|        match self {
   92|      0|            BlockSubType::Send => "send",
   93|      0|            BlockSubType::Receive => "receive",
   94|      0|            BlockSubType::Open => "open",
   95|      0|            BlockSubType::Change => "change",
   96|      0|            BlockSubType::Epoch => "epoch",
   97|       |        }
   98|      0|    }
   99|       |}
  100|       |
  101|       |pub trait BlockBase: FullHash {
  102|       |    fn block_type(&self) -> BlockType;
  103|       |    fn account_field(&self) -> Option<Account>;
  104|       |    fn hash(&self) -> BlockHash;
  105|       |    fn link_field(&self) -> Option<Link>;
  106|       |    fn signature(&self) -> &Signature;
  107|       |    fn set_signature(&mut self, signature: Signature);
  108|       |    fn work(&self) -> u64;
  109|       |    fn set_work(&mut self, work: u64);
  110|       |    fn previous(&self) -> BlockHash;
  111|       |    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter);
  112|      0|    fn to_json(&self) -> anyhow::Result<String> {
  113|      0|        Ok(serde_json::to_string(&self.json_representation())?)
  114|      0|    }
  115|       |    fn json_representation(&self) -> JsonBlock;
  116|       |    fn root(&self) -> Root;
  117|       |    fn balance_field(&self) -> Option<Amount>;
  118|       |    /// Source block for open/receive blocks, zero otherwise.
  119|       |    fn source_field(&self) -> Option<BlockHash>;
  120|       |    fn representative_field(&self) -> Option<PublicKey>;
  121|       |    fn destination_field(&self) -> Option<Account>;
  122|      0|    fn qualified_root(&self) -> QualifiedRoot {
  123|      0|        QualifiedRoot::new(self.root(), self.previous())
  124|      0|    }
  125|       |    fn valid_predecessor(&self, block_type: BlockType) -> bool;
  126|       |}
  127|       |
  128|       |impl<T: BlockBase> FullHash for T {
  129|      0|    fn full_hash(&self) -> BlockHash {
  130|      0|        BlockHashBuilder::new()
  131|      0|            .update(self.hash().as_bytes())
  132|      0|            .update(self.signature().as_bytes())
  133|      0|            .update(self.work().to_ne_bytes())
  134|      0|            .build()
  135|      0|    }
  136|       |}
  137|       |
  138|      0|pub fn serialized_block_size(block_type: BlockType) -> usize {
  139|      0|    match block_type {
  140|      0|        BlockType::Invalid | BlockType::NotABlock => 0,
  141|      0|        BlockType::LegacySend => SendBlock::serialized_size(),
  142|      0|        BlockType::LegacyReceive => ReceiveBlock::serialized_size(),
  143|      0|        BlockType::LegacyOpen => OpenBlock::serialized_size(),
  144|      0|        BlockType::LegacyChange => ChangeBlock::serialized_size(),
  145|      0|        BlockType::State => StateBlock::serialized_size(),
  146|       |    }
  147|      0|}
  148|       |
  149|       |#[derive(Clone, PartialEq, Eq, Debug)]
  150|       |pub enum Block {
  151|       |    LegacySend(SendBlock),
  152|       |    LegacyReceive(ReceiveBlock),
  153|       |    LegacyOpen(OpenBlock),
  154|       |    LegacyChange(ChangeBlock),
  155|       |    State(StateBlock),
  156|       |}
  157|       |
  158|       |impl Block {
  159|     11|    pub fn new_test_instance() -> Self {
  160|     11|        let key = PrivateKey::from(42);
  161|     11|        Self::new_test_instance_with_key(key)
  162|     11|    }
  163|       |
  164|      0|    pub fn new_test_open() -> Self {
  165|      0|        let key = PrivateKey::from(42);
  166|      0|        StateBlockArgs {
  167|      0|            key: &key,
  168|      0|            previous: BlockHash::zero(),
  169|      0|            representative: 789.into(),
  170|      0|            balance: 420.into(),
  171|      0|            link: 111.into(),
  172|      0|            work: 69420,
  173|      0|        }
  174|      0|        .into()
  175|      0|    }
  176|       |
  177|     11|    pub fn new_test_instance_with_key(key: impl Into<PrivateKey>) -> Self {
  178|     11|        let key = key.into();
  179|     11|        StateBlockArgs {
  180|     11|            key: &key,
  181|     11|            previous: 456.into(),
  182|     11|            representative: 789.into(),
  183|     11|            balance: 420.into(),
  184|     11|            link: 111.into(),
  185|     11|            work: 69420,
  186|     11|        }
  187|     11|        .into()
  188|     11|    }
  189|       |
  190|  65.7k|    pub fn block_type(&self) -> BlockType {
  191|  65.7k|        self.as_block().block_type()
  192|  65.7k|    }
  193|       |
  194|      0|    pub fn as_block_mut(&mut self) -> &mut dyn BlockBase {
  195|      0|        match self {
  196|      0|            Block::LegacySend(b) => b,
  197|      0|            Block::LegacyReceive(b) => b,
  198|      0|            Block::LegacyOpen(b) => b,
  199|      0|            Block::LegacyChange(b) => b,
  200|      0|            Block::State(b) => b,
  201|       |        }
  202|      0|    }
  203|       |
  204|  65.7k|    pub fn as_block(&self) -> &dyn BlockBase {
  205|  65.7k|        match self {
  206|      0|            Block::LegacySend(b) => b,
  207|      0|            Block::LegacyReceive(b) => b,
  208|  16.4k|            Block::LegacyOpen(b) => b,
  209|      0|            Block::LegacyChange(b) => b,
  210|  49.2k|            Block::State(b) => b,
  211|       |        }
  212|  65.7k|    }
  213|       |
  214|    156|    pub fn is_open(&self) -> bool {
  215|    156|        match &self {
  216|      0|            Block::LegacyOpen(_) => true,
  217|    156|            Block::State(state) => state.previous().is_zero(),
  218|      0|            _ => false,
  219|       |        }
  220|    156|    }
  221|       |
  222|      0|    pub fn is_legacy(&self) -> bool {
  223|      0|        !matches!(self, Block::State(_))
  224|      0|    }
  225|       |
  226|      0|    pub fn is_change(&self) -> bool {
  227|      0|        match self {
  228|      0|            Block::LegacyChange(_) => true,
  229|      0|            Block::State(state) => state.link().is_zero(),
  230|      0|            _ => false,
  231|       |        }
  232|      0|    }
  233|       |
  234|     36|    pub fn source_or_link(&self) -> BlockHash {
  235|     36|        self.source_field()
  236|     36|            .unwrap_or_else(|| self.link_field().unwrap_or_default().into())
  237|     36|    }
  238|       |
  239|      4|    pub fn destination_or_link(&self) -> Account {
  240|      4|        self.destination_field()
  241|      4|            .unwrap_or_else(|| self.link_field().unwrap_or_default().into())
  242|      4|    }
  243|       |
  244|     61|    pub fn serialize(&self, stream: &mut dyn BufferWriter) {
  245|     61|        let block_type = self.block_type() as u8;
  246|     61|        stream.write_u8_safe(block_type);
  247|     61|        self.serialize_without_block_type(stream);
  248|     61|    }
  249|       |
  250|  65.5k|    pub fn deserialize_block_type(
  251|  65.5k|        block_type: BlockType,
  252|  65.5k|        stream: &mut dyn Stream,
  253|  65.5k|    ) -> anyhow::Result<Self> {
  254|  65.5k|        let block = match block_type {
  255|      0|            BlockType::LegacyReceive => Self::LegacyReceive(ReceiveBlock::deserialize(stream)?),
  256|  16.4k|            BlockType::LegacyOpen => Self::LegacyOpen(OpenBlock::deserialize(stream)?),
                                                                                                  ^0
  257|      0|            BlockType::LegacyChange => Self::LegacyChange(ChangeBlock::deserialize(stream)?),
  258|  49.1k|            BlockType::State => Self::State(StateBlock::deserialize(stream)?),
                                                                                         ^0
  259|      0|            BlockType::LegacySend => Self::LegacySend(SendBlock::deserialize(stream)?),
  260|      0|            BlockType::Invalid | BlockType::NotABlock => bail!("invalid block type"),
  261|       |        };
  262|  65.5k|        Ok(block)
  263|  65.5k|    }
  264|       |
  265|  65.5k|    pub fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Block> {
  266|  65.5k|        let block_type =
  267|  65.5k|            BlockType::from_u8(stream.read_u8()?).ok_or_else(|| anyhow!("invalid block type"))?;
                                                             ^0               ^0                            ^0
  268|  65.5k|        Self::deserialize_block_type(block_type, stream)
  269|  65.5k|    }
  270|       |}
  271|       |
  272|       |impl From<Block> for serde_json::Value {
  273|      0|    fn from(value: Block) -> Self {
  274|      0|        serde_json::to_value(value.json_representation()).unwrap()
  275|      0|    }
  276|       |}
  277|       |
  278|       |impl From<SavedBlock> for serde_json::Value {
  279|      0|    fn from(value: SavedBlock) -> Self {
  280|      0|        let mut result = serde_json::to_value(value.block.json_representation()).unwrap();
  281|      0|        if let serde_json::Value::Object(obj) = &mut result {
  282|      0|            obj.insert(
  283|      0|                "subtype".to_string(),
  284|      0|                serde_json::Value::String(value.subtype().as_str().to_owned()),
  285|      0|            );
  286|      0|        }
  287|      0|        result
  288|      0|    }
  289|       |}
  290|       |
  291|       |impl FullHash for Block {
  292|      0|    fn full_hash(&self) -> BlockHash {
  293|      0|        self.as_block().full_hash()
  294|      0|    }
  295|       |}
  296|       |
  297|       |impl Deref for Block {
  298|       |    type Target = dyn BlockBase;
  299|       |
  300|  99.2k|    fn deref(&self) -> &Self::Target {
  301|  99.2k|        match self {
  302|      0|            Block::LegacySend(b) => b,
  303|      0|            Block::LegacyReceive(b) => b,
  304|  16.5k|            Block::LegacyOpen(b) => b,
  305|      0|            Block::LegacyChange(b) => b,
  306|  82.7k|            Block::State(b) => b,
  307|       |        }
  308|  99.2k|    }
  309|       |}
  310|       |
  311|       |impl DerefMut for Block {
  312|      1|    fn deref_mut(&mut self) -> &mut Self::Target {
  313|      1|        match self {
  314|      0|            Block::LegacySend(b) => b,
  315|      0|            Block::LegacyReceive(b) => b,
  316|      0|            Block::LegacyOpen(b) => b,
  317|      0|            Block::LegacyChange(b) => b,
  318|      1|            Block::State(b) => b,
  319|       |        }
  320|      1|    }
  321|       |}
  322|       |
  323|       |impl serde::Serialize for Block {
  324|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
  325|      0|    where
  326|      0|        S: serde::Serializer,
  327|      0|    {
  328|      0|        let json = self.as_block().json_representation();
  329|      0|        json.serialize(serializer)
  330|      0|    }
  331|       |}
  332|       |
  333|    129|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  334|       |#[serde(tag = "type", rename_all = "snake_case")]
  335|       |pub enum JsonBlock {
  336|       |    Open(JsonOpenBlock),
  337|       |    Change(JsonChangeBlock),
  338|       |    Receive(JsonReceiveBlock),
  339|       |    Send(JsonSendBlock),
  340|       |    State(JsonStateBlock),
  341|       |}
  342|       |
  343|       |impl<'de> serde::Deserialize<'de> for Block {
  344|    129|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
  345|    129|    where
  346|    129|        D: serde::Deserializer<'de>,
  347|    129|    {
  348|    129|        let json_block = JsonBlock::deserialize(deserializer)?;
                                                                           ^0
  349|    129|        Ok(json_block.into())
  350|    129|    }
  351|       |}
  352|       |
  353|       |impl From<JsonBlock> for Block {
  354|    129|    fn from(value: JsonBlock) -> Self {
  355|    129|        match value {
  356|    129|            JsonBlock::Open(open) => Block::LegacyOpen(open.into()),
  357|      0|            JsonBlock::Change(change) => Block::LegacyChange(change.into()),
  358|      0|            JsonBlock::Receive(receive) => Block::LegacyReceive(receive.into()),
  359|      0|            JsonBlock::Send(send) => Block::LegacySend(send.into()),
  360|      0|            JsonBlock::State(state) => Block::State(state.into()),
  361|       |        }
  362|    129|    }
  363|       |}
  364|       |
  365|       |impl From<Block> for JsonBlock {
  366|      0|    fn from(value: Block) -> Self {
  367|      0|        value.as_block().json_representation()
  368|      0|    }
  369|       |}
  370|       |
  371|       |impl From<&Block> for JsonBlock {
  372|      0|    fn from(value: &Block) -> Self {
  373|      0|        value.as_block().json_representation()
  374|      0|    }
  375|       |}
  376|       |
  377|       |/// A block with additional data about that block (the "sideband")
  378|       |/// which is only known when the block is saved.
  379|       |/// The sideband contains additional data like block height, block time, etc.
  380|       |#[derive(Clone, Debug, PartialEq, Eq)]
  381|       |pub struct SavedBlock {
  382|       |    block: Block,
  383|       |    sideband: BlockSideband,
  384|       |}
  385|       |
  386|       |impl SavedBlock {
  387|     98|    pub fn new(block: Block, sideband: BlockSideband) -> Self {
  388|     98|        Self { block, sideband }
  389|     98|    }
  390|       |
  391|      0|    pub fn new_test_open_block() -> Self {
  392|      0|        let block = Block::new_test_open();
  393|      0|        let sideband = BlockSideband {
  394|      0|            height: 1,
  395|      0|            timestamp: 222222.into(),
  396|      0|            successor: BlockHash::zero(),
  397|      0|            account: block.account_field().unwrap(),
  398|      0|            balance: block.balance_field().unwrap(),
  399|      0|            details: BlockDetails::new(Epoch::Epoch2, false, true, false),
  400|      0|            source_epoch: Epoch::Epoch0,
  401|      0|        };
  402|      0|        Self::new(block, sideband)
  403|      0|    }
  404|       |
  405|      0|    pub fn new_test_instance() -> Self {
  406|      0|        let block = Block::new_test_instance();
  407|      0|        let sideband = Self::test_sideband(&block);
  408|      0|        Self::new(block, sideband)
  409|      0|    }
  410|       |
  411|      0|    pub fn new_test_instance_with_key(key: impl Into<PrivateKey>) -> Self {
  412|      0|        let block = Block::new_test_instance_with_key(key);
  413|      0|        let sideband = Self::test_sideband(&block);
  414|      0|        Self::new(block, sideband)
  415|      0|    }
  416|       |
  417|      0|    fn test_sideband(block: &Block) -> BlockSideband {
  418|      0|        BlockSideband {
  419|      0|            height: 2,
  420|      0|            timestamp: 222222.into(),
  421|      0|            successor: BlockHash::zero(),
  422|      0|            account: block.account_field().unwrap(),
  423|      0|            balance: block.balance_field().unwrap(),
  424|      0|            details: BlockDetails::new(Epoch::Epoch2, true, false, false),
  425|      0|            source_epoch: Epoch::Epoch0,
  426|      0|        }
  427|      0|    }
  428|       |
  429|      1|    pub fn set_sideband(&mut self, sideband: BlockSideband) {
  430|      1|        self.sideband = sideband;
  431|      1|    }
  432|       |
  433|  65.5k|    pub fn account(&self) -> Account {
  434|  65.5k|        match self.account_field() {
  435|  65.5k|            Some(account) => account,
  436|      0|            None => self.sideband.account,
  437|       |        }
  438|  65.5k|    }
  439|       |
  440|  65.5k|    pub fn height(&self) -> u64 {
  441|  65.5k|        self.sideband.height
  442|  65.5k|    }
  443|       |
  444|      0|    pub fn timestamp(&self) -> UnixTimestamp {
  445|      0|        self.sideband.timestamp
  446|      0|    }
  447|       |
  448|      0|    pub fn subtype(&self) -> BlockSubType {
  449|      0|        self.sideband.details.subtype()
  450|      0|    }
  451|       |
  452|     59|    pub fn successor(&self) -> Option<BlockHash> {
  453|     59|        if self.sideband.successor.is_zero() {
  454|     59|            None
  455|       |        } else {
  456|      0|            Some(self.sideband.successor)
  457|       |        }
  458|     59|    }
  459|       |
  460|      0|    pub fn epoch(&self) -> Epoch {
  461|      0|        self.sideband.details.epoch
  462|      0|    }
  463|       |
  464|      0|    pub fn is_epoch(&self) -> bool {
  465|      0|        self.sideband.details.is_epoch
  466|      0|    }
  467|       |
  468|      0|    pub fn is_receive(&self) -> bool {
  469|      0|        self.sideband.details.is_receive
  470|      0|    }
  471|       |
  472|  16.3k|    pub fn is_send(&self) -> bool {
  473|  16.3k|        match &self.block {
  474|      0|            Block::LegacySend(_) => true,
  475|  16.3k|            Block::State(_) => self.sideband.details.is_send,
  476|      0|            _ => false,
  477|       |        }
  478|  16.3k|    }
  479|       |
  480|      0|    pub fn source(&self) -> Option<BlockHash> {
  481|      0|        match &self.block {
  482|      0|            Block::LegacyOpen(i) => Some(i.source()),
  483|      0|            Block::LegacyReceive(i) => Some(i.source()),
  484|      0|            Block::State(i) => {
  485|      0|                if self.sideband.details.is_receive {
  486|      0|                    Some(i.link().into())
  487|       |                } else {
  488|      0|                    None
  489|       |                }
  490|       |            }
  491|      0|            _ => None,
  492|       |        }
  493|      0|    }
  494|       |
  495|      0|    pub fn source_epoch(&self) -> Epoch {
  496|      0|        self.sideband.source_epoch
  497|      0|    }
  498|       |
  499|      0|    pub fn destination(&self) -> Option<Account> {
  500|      0|        match &self.block {
  501|      0|            Block::LegacySend(i) => Some(i.destination()),
  502|      0|            Block::State(i) => {
  503|      0|                if self.sideband.details.is_send {
  504|      0|                    Some(i.link().into())
  505|       |                } else {
  506|      0|                    None
  507|       |                }
  508|       |            }
  509|      0|            _ => None,
  510|       |        }
  511|      0|    }
  512|       |
  513|     61|    pub fn serialize_with_sideband(&self) -> Vec<u8> {
  514|     61|        let mut stream = MemoryStream::new();
  515|     61|        self.block.serialize(&mut stream);
  516|     61|        self.sideband
  517|     61|            .serialize(&mut stream, self.block.block_type());
  518|     61|        stream.to_vec()
  519|     61|    }
  520|       |
  521|     84|    pub fn balance(&self) -> Amount {
  522|     84|        match &self.block {
  523|      0|            Block::LegacySend(b) => b.balance(),
  524|     78|            Block::State(b) => b.balance(),
  525|      6|            _ => self.sideband.balance,
  526|       |        }
  527|     84|    }
  528|       |
  529|      0|    pub fn details(&self) -> &BlockDetails {
  530|      0|        &self.sideband.details
  531|      0|    }
  532|       |
  533|      0|    pub fn sideband(&self) -> &BlockSideband {
  534|      0|        &self.sideband
  535|      0|    }
  536|       |
  537|       |    /// There can be at most two dependencies per block, namely "previous" and "link/source".
  538|  16.3k|    pub fn dependent_blocks(&self, epochs: &Epochs, genesis_account: &Account) -> DependentBlocks {
  539|  16.3k|        match &self.block {
  540|      0|            Block::LegacySend(b) => b.dependent_blocks(),
  541|      0|            Block::LegacyChange(b) => b.dependent_blocks(),
  542|      0|            Block::LegacyReceive(b) => b.dependent_blocks(),
  543|      0|            Block::LegacyOpen(b) => b.dependent_blocks(genesis_account),
  544|  16.3k|            Block::State(state) => {
  545|  16.3k|                let link_refers_to_block = !self.is_send() && !epochs.is_epoch_link(&state.link());
  546|  16.3k|                let linked_block = if link_refers_to_block {
  547|  16.3k|                    state.link().into()
  548|       |                } else {
  549|      0|                    BlockHash::zero()
  550|       |                };
  551|  16.3k|                DependentBlocks::new(self.previous(), linked_block)
  552|       |            }
  553|       |        }
  554|  16.3k|    }
  555|       |}
  556|       |
  557|       |impl Deref for SavedBlock {
  558|       |    type Target = Block;
  559|       |
  560|  98.5k|    fn deref(&self) -> &Self::Target {
  561|  98.5k|        &self.block
  562|  98.5k|    }
  563|       |}
  564|       |
  565|       |impl DerefMut for SavedBlock {
  566|      0|    fn deref_mut(&mut self) -> &mut Self::Target {
  567|      0|        &mut self.block
  568|      0|    }
  569|       |}
  570|       |
  571|       |impl From<SavedBlock> for Block {
  572|      0|    fn from(value: SavedBlock) -> Self {
  573|      0|        value.block
  574|      0|    }
  575|       |}
  576|       |
  577|       |impl Deserialize for SavedBlock {
  578|       |    type Target = Self;
  579|  65.5k|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self> {
  580|  65.5k|        let block = Block::deserialize(stream)?;
                                                            ^0
  581|  65.5k|        let mut sideband = BlockSideband::from_stream(stream, block.block_type())?;
                                                                                               ^0
  582|       |        // BlockSideband does not serialize all data depending on the block type.
  583|       |        // That's why we fill in the missing data here:
  584|  65.5k|        match &block {
  585|      0|            Block::LegacySend(i) => {
  586|      0|                sideband.balance = i.balance();
  587|      0|                sideband.details = BlockDetails::new(Epoch::Epoch0, true, false, false)
  588|       |            }
  589|  16.4k|            Block::LegacyOpen(open) => {
  590|  16.4k|                sideband.account = open.account();
  591|  16.4k|                sideband.details = BlockDetails::new(Epoch::Epoch0, false, true, false)
  592|       |            }
  593|       |            Block::LegacyReceive(_) => {
  594|      0|                sideband.details = BlockDetails::new(Epoch::Epoch0, false, true, false)
  595|       |            }
  596|       |            Block::LegacyChange(_) => {
  597|      0|                sideband.details = BlockDetails::new(Epoch::Epoch0, false, false, false)
  598|       |            }
  599|  49.1k|            Block::State(state) => {
  600|  49.1k|                sideband.account = state.account();
  601|  49.1k|                sideband.balance = state.balance();
  602|  49.1k|            }
  603|       |        }
  604|  65.5k|        Ok(SavedBlock { block, sideband })
  605|  65.5k|    }
  606|       |}
  607|       |
  608|       |#[derive(Clone)]
  609|       |pub enum MaybeSavedBlock {
  610|       |    Saved(SavedBlock),
  611|       |    Unsaved(Block),
  612|       |}
  613|       |
  614|       |impl From<MaybeSavedBlock> for Block {
  615|      0|    fn from(value: MaybeSavedBlock) -> Self {
  616|      0|        match value {
  617|      0|            MaybeSavedBlock::Saved(b) => b.into(),
  618|      0|            MaybeSavedBlock::Unsaved(b) => b,
  619|       |        }
  620|      0|    }
  621|       |}
  622|       |
  623|       |impl Deref for MaybeSavedBlock {
  624|       |    type Target = Block;
  625|       |
  626|      0|    fn deref(&self) -> &Self::Target {
  627|      0|        match self {
  628|      0|            MaybeSavedBlock::Saved(b) => b,
  629|      0|            MaybeSavedBlock::Unsaved(b) => b,
  630|       |        }
  631|      0|    }
  632|       |}
  633|       |
  634|       |static DEV_PRIVATE_KEY_DATA: &str =
  635|       |    "34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4";
  636|       |pub static DEV_PUBLIC_KEY_DATA: &str =
  637|       |    "B0311EA55708D6A53C75CDBF88300259C6D018522FE3D4D0A242E431F9E8B6D0"; // xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtdo
  638|       |pub static DEV_GENESIS_KEY: LazyLock<PrivateKey> =
  639|      1|    LazyLock::new(|| PrivateKey::from_hex_str(DEV_PRIVATE_KEY_DATA).unwrap());
  640|       |
  641|       |static DEV_GENESIS_DATA: &str = r###"{
  642|       |	"type": "open",
  643|       |	"source": "B0311EA55708D6A53C75CDBF88300259C6D018522FE3D4D0A242E431F9E8B6D0",
  644|       |	"representative": "xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtdo",
  645|       |	"account": "xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtdo",
  646|       |	"work": "7b42a00ee91d5810",
  647|       |	"signature": "ECDA914373A2F0CA1296475BAEE40500A7F0A7AD72A5A80C81D7FAB7F6C802B2CC7DB50F5DD0FB25B2EF11761FA7344A158DD5A700B21BD47DE5BD0F63153A02"
  648|       |    }"###;
  649|       |
  650|       |pub static DEV_GENESIS_BLOCK: LazyLock<Block> =
  651|      1|    LazyLock::new(|| serde_json::from_str(DEV_GENESIS_DATA).unwrap());
  652|       |
  653|       |#[derive(Default)]
  654|       |pub struct DependentBlocks {
  655|       |    dependents: [BlockHash; 2],
  656|       |}
  657|       |
  658|       |impl DependentBlocks {
  659|  16.3k|    pub fn new(previous: BlockHash, link: BlockHash) -> Self {
  660|  16.3k|        Self {
  661|  16.3k|            dependents: [previous, link],
  662|  16.3k|        }
  663|  16.3k|    }
  664|       |
  665|      0|    pub fn none() -> Self {
  666|      0|        Self::new(BlockHash::zero(), BlockHash::zero())
  667|      0|    }
  668|       |
  669|      0|    pub fn previous(&self) -> Option<BlockHash> {
  670|      0|        self.get_index(0)
  671|      0|    }
  672|       |
  673|      0|    pub fn link(&self) -> Option<BlockHash> {
  674|      0|        self.get_index(1)
  675|      0|    }
  676|       |
  677|      0|    fn get_index(&self, index: usize) -> Option<BlockHash> {
  678|      0|        if self.dependents[index].is_zero() {
  679|      0|            None
  680|       |        } else {
  681|      0|            Some(self.dependents[index])
  682|       |        }
  683|      0|    }
  684|       |
  685|  16.3k|    pub fn iter(&self) -> impl Iterator<Item = &BlockHash> {
  686|  16.3k|        self.dependents
  687|  16.3k|            .iter()
  688|  32.7k|            .flat_map(|i| if i.is_zero() { None } else { Some(i) })
                                                         ^16.3k        ^16.3k
  689|  16.3k|    }
  690|       |}
  691|       |
  692|       |#[cfg(test)]
  693|       |mod tests {
  694|       |    use super::*;
  695|       |
  696|       |    #[test]
  697|       |    fn serialize_legacy_open() {
  698|       |        let block = TestBlockBuilder::legacy_open().build_saved();
  699|       |        assert_serializable(block.into());
  700|       |    }
  701|       |
  702|       |    #[test]
  703|       |    fn serialize_legacy_receive() {
  704|       |        let block = TestBlockBuilder::legacy_receive().build();
  705|       |        assert_serializable(block);
  706|       |    }
  707|       |
  708|       |    #[test]
  709|       |    fn serialize_legacy_send() {
  710|       |        let block = TestBlockBuilder::legacy_send().build();
  711|       |        assert_serializable(block);
  712|       |    }
  713|       |
  714|       |    #[test]
  715|       |    fn serialize_legacy_change() {
  716|       |        let block = TestBlockBuilder::legacy_change().build();
  717|       |        assert_serializable(block);
  718|       |    }
  719|       |
  720|       |    #[test]
  721|       |    fn serialize_state() {
  722|       |        let block = TestBlockBuilder::state().build();
  723|       |        assert_serializable(block);
  724|       |    }
  725|       |
  726|       |    fn assert_serializable(block: Block) {
  727|       |        let mut buffer = MemoryStream::new();
  728|       |        block.serialize(&mut buffer);
  729|       |        let deserialized = Block::deserialize(&mut buffer).unwrap();
  730|       |        assert_eq!(deserialized, block);
  731|       |    }
  732|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/open_block.rs:
    1|       |use super::{Block, BlockBase, BlockType};
    2|       |use crate::{
    3|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount, BlockHash, BlockHashBuilder, DependentBlocks, JsonBlock, Link, PrivateKey,
    5|       |    PublicKey, Root, Signature, WorkNonce,
    6|       |};
    7|       |use anyhow::Result;
    8|       |
    9|       |#[derive(Clone, Debug)]
   10|       |pub struct OpenBlock {
   11|       |    work: u64,
   12|       |    signature: Signature,
   13|       |    hashables: OpenHashables,
   14|       |    hash: BlockHash,
   15|       |}
   16|       |
   17|       |impl OpenBlock {
   18|  16.4k|    pub fn account(&self) -> Account {
   19|  16.4k|        self.hashables.account
   20|  16.4k|    }
   21|       |
   22|      0|    pub fn new_test_instance() -> Self {
   23|      0|        let key = PrivateKey::from(42);
   24|      0|        OpenBlockArgs {
   25|      0|            key: &key,
   26|      0|            source: BlockHash::from(123),
   27|      0|            representative: PublicKey::from(456),
   28|      0|            work: 69420,
   29|      0|        }
   30|      0|        .into()
   31|      0|    }
   32|       |
   33|      0|    pub fn source(&self) -> BlockHash {
   34|      0|        self.hashables.source
   35|      0|    }
   36|       |
   37|      0|    pub fn representative(&self) -> PublicKey {
   38|      0|        self.hashables.representative
   39|      0|    }
   40|       |
   41|      0|    pub fn serialized_size() -> usize {
   42|      0|        OpenHashables::serialized_size() + Signature::serialized_size() + std::mem::size_of::<u64>()
   43|      0|    }
   44|       |
   45|  16.4k|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
   46|  16.4k|        let hashables = OpenHashables {
   47|  16.4k|            source: BlockHash::deserialize(stream)?,
                                                                ^0
   48|  16.4k|            representative: PublicKey::deserialize(stream)?,
                                                                        ^0
   49|  16.4k|            account: Account::deserialize(stream)?,
                                                               ^0
   50|       |        };
   51|  16.4k|        let signature = Signature::deserialize(stream)?;
                                                                    ^0
   52|  16.4k|        let mut work_bytes = [0u8; 8];
   53|  16.4k|        stream.read_bytes(&mut work_bytes, 8)?;
                                                           ^0
   54|  16.4k|        let work = u64::from_le_bytes(work_bytes);
   55|  16.4k|        let hash = hashables.hash();
   56|  16.4k|        Ok(OpenBlock {
   57|  16.4k|            work,
   58|  16.4k|            signature,
   59|  16.4k|            hashables,
   60|  16.4k|            hash,
   61|  16.4k|        })
   62|  16.4k|    }
   63|       |
   64|      0|    pub fn dependent_blocks(&self, genesis_account: &Account) -> DependentBlocks {
   65|      0|        if self.account() == *genesis_account {
   66|      0|            DependentBlocks::none()
   67|       |        } else {
   68|      0|            DependentBlocks::new(self.source(), BlockHash::zero())
   69|       |        }
   70|      0|    }
   71|       |}
   72|       |
   73|       |impl PartialEq for OpenBlock {
   74|      0|    fn eq(&self, other: &Self) -> bool {
   75|      0|        self.work == other.work
   76|      0|            && self.signature == other.signature
   77|      0|            && self.hashables == other.hashables
   78|      0|    }
   79|       |}
   80|       |
   81|       |impl Eq for OpenBlock {}
   82|       |
   83|       |impl BlockBase for OpenBlock {
   84|  16.4k|    fn block_type(&self) -> BlockType {
   85|  16.4k|        BlockType::LegacyOpen
   86|  16.4k|    }
   87|       |
   88|  16.4k|    fn account_field(&self) -> Option<Account> {
   89|  16.4k|        Some(self.hashables.account)
   90|  16.4k|    }
   91|       |
   92|     71|    fn hash(&self) -> BlockHash {
   93|     71|        self.hash
   94|     71|    }
   95|       |
   96|      2|    fn link_field(&self) -> Option<Link> {
   97|      2|        None
   98|      2|    }
   99|       |
  100|      0|    fn signature(&self) -> &Signature {
  101|      0|        &self.signature
  102|      0|    }
  103|       |
  104|      0|    fn set_signature(&mut self, signature: Signature) {
  105|      0|        self.signature = signature;
  106|      0|    }
  107|       |
  108|      0|    fn set_work(&mut self, work: u64) {
  109|      0|        self.work = work;
  110|      0|    }
  111|       |
  112|      0|    fn work(&self) -> u64 {
  113|      0|        self.work
  114|      0|    }
  115|       |
  116|     27|    fn previous(&self) -> BlockHash {
  117|     27|        BlockHash::zero()
  118|     27|    }
  119|       |
  120|     28|    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter) {
  121|     28|        self.hashables.source.serialize(writer);
  122|     28|        self.hashables.representative.serialize(writer);
  123|     28|        self.hashables.account.serialize(writer);
  124|     28|        self.signature.serialize(writer);
  125|     28|        writer.write_bytes_safe(&self.work.to_le_bytes());
  126|     28|    }
  127|       |
  128|      3|    fn root(&self) -> Root {
  129|      3|        self.hashables.account.into()
  130|      3|    }
  131|       |
  132|      1|    fn balance_field(&self) -> Option<Amount> {
  133|      1|        None
  134|      1|    }
  135|       |
  136|      0|    fn source_field(&self) -> Option<BlockHash> {
  137|      0|        Some(self.hashables.source)
  138|      0|    }
  139|       |
  140|      1|    fn representative_field(&self) -> Option<PublicKey> {
  141|      1|        Some(self.hashables.representative)
  142|      1|    }
  143|       |
  144|      0|    fn valid_predecessor(&self, _block_type: BlockType) -> bool {
  145|      0|        false
  146|      0|    }
  147|       |
  148|      0|    fn qualified_root(&self) -> crate::QualifiedRoot {
  149|      0|        crate::QualifiedRoot::new(self.root(), self.previous())
  150|      0|    }
  151|       |
  152|      0|    fn destination_field(&self) -> Option<Account> {
  153|      0|        None
  154|      0|    }
  155|       |
  156|      0|    fn json_representation(&self) -> JsonBlock {
  157|      0|        JsonBlock::Open(JsonOpenBlock {
  158|      0|            source: self.hashables.source,
  159|      0|            representative: self.hashables.representative.into(),
  160|      0|            account: self.hashables.account,
  161|      0|            work: self.work.into(),
  162|      0|            signature: self.signature.clone(),
  163|      0|        })
  164|      0|    }
  165|       |}
  166|       |
  167|       |#[derive(Clone, PartialEq, Eq, Debug)]
  168|       |struct OpenHashables {
  169|       |    /// Block with first send transaction to this account
  170|       |    source: BlockHash,
  171|       |    representative: PublicKey,
  172|       |    account: Account,
  173|       |}
  174|       |
  175|       |impl OpenHashables {
  176|      0|    fn serialized_size() -> usize {
  177|      0|        BlockHash::serialized_size() + Account::serialized_size() + Account::serialized_size()
  178|      0|    }
  179|       |
  180|  16.5k|    fn hash(&self) -> BlockHash {
  181|  16.5k|        BlockHashBuilder::new()
  182|  16.5k|            .update(self.source.as_bytes())
  183|  16.5k|            .update(self.representative.as_bytes())
  184|  16.5k|            .update(self.account.as_bytes())
  185|  16.5k|            .build()
  186|  16.5k|    }
  187|       |}
  188|       |
  189|       |pub struct OpenBlockArgs<'a> {
  190|       |    pub key: &'a PrivateKey,
  191|       |    pub source: BlockHash,
  192|       |    pub representative: PublicKey,
  193|       |    pub work: u64,
  194|       |}
  195|       |
  196|       |impl<'a> From<OpenBlockArgs<'a>> for OpenBlock {
  197|      1|    fn from(value: OpenBlockArgs<'a>) -> Self {
  198|      1|        let hashables = OpenHashables {
  199|      1|            source: value.source,
  200|      1|            representative: value.representative,
  201|      1|            account: value.key.account(),
  202|      1|        };
  203|      1|
  204|      1|        let hash = hashables.hash();
  205|      1|        let signature = value.key.sign(hash.as_bytes());
  206|      1|
  207|      1|        Self {
  208|      1|            signature,
  209|      1|            hashables,
  210|      1|            hash,
  211|      1|            work: value.work,
  212|      1|        }
  213|      1|    }
  214|       |}
  215|       |
  216|       |impl<'a> From<OpenBlockArgs<'a>> for Block {
  217|      1|    fn from(value: OpenBlockArgs<'a>) -> Self {
  218|      1|        Self::LegacyOpen(value.into())
  219|      1|    }
  220|       |}
  221|       |
  222|    774|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  223|       |pub struct JsonOpenBlock {
  224|       |    pub account: Account,
  225|       |    pub source: BlockHash,
  226|       |    pub representative: Account,
  227|       |    pub signature: Signature,
  228|       |    pub work: WorkNonce,
  229|       |}
  230|       |
  231|       |impl From<JsonOpenBlock> for OpenBlock {
  232|    129|    fn from(value: JsonOpenBlock) -> Self {
  233|    129|        let hashables = OpenHashables {
  234|    129|            source: value.source,
  235|    129|            representative: value.representative.into(),
  236|    129|            account: value.account,
  237|    129|        };
  238|    129|
  239|    129|        let hash = hashables.hash();
  240|    129|
  241|    129|        Self {
  242|    129|            work: value.work.into(),
  243|    129|            signature: value.signature,
  244|    129|            hashables,
  245|    129|            hash,
  246|    129|        }
  247|    129|    }
  248|       |}
  249|       |
  250|       |#[cfg(test)]
  251|       |mod tests {
  252|       |    use super::*;
  253|       |    use crate::{utils::MemoryStream, Block, PrivateKey};
  254|       |
  255|       |    #[test]
  256|       |    fn create_block() {
  257|       |        let key = PrivateKey::new();
  258|       |        let source = BlockHash::from(1);
  259|       |        let representative = PublicKey::from(2);
  260|       |        let block: OpenBlock = OpenBlockArgs {
  261|       |            key: &key,
  262|       |            source,
  263|       |            representative,
  264|       |            work: 0,
  265|       |        }
  266|       |        .into();
  267|       |
  268|       |        assert_eq!(block.account_field(), Some(key.account()));
  269|       |        assert_eq!(block.root(), key.account().into());
  270|       |    }
  271|       |
  272|       |    // original test: open_block.deserialize
  273|       |    #[test]
  274|       |    fn serialize() {
  275|       |        let block1 = OpenBlock::new_test_instance();
  276|       |        let mut stream = MemoryStream::new();
  277|       |        block1.serialize_without_block_type(&mut stream);
  278|       |        assert_eq!(OpenBlock::serialized_size(), stream.bytes_written());
  279|       |
  280|       |        let block2 = OpenBlock::deserialize(&mut stream).unwrap();
  281|       |        assert_eq!(block1, block2);
  282|       |    }
  283|       |
  284|       |    #[test]
  285|       |    fn serialize_serde() {
  286|       |        let block = Block::LegacyOpen(OpenBlock::new_test_instance());
  287|       |        let serialized = serde_json::to_string_pretty(&block).unwrap();
  288|       |        assert_eq!(
  289|       |            serialized,
  290|       |            r#"{
  291|       |  "type": "open",
  292|       |  "account": "nano_39y535msmkzb31bx73tdnf8iken5ucw9jt98re7nriduus6cgs6uonjdm8r5",
  293|       |  "source": "000000000000000000000000000000000000000000000000000000000000007B",
  294|       |  "representative": "nano_11111111111111111111111111111111111111111111111111gahteczqci",
  295|       |  "signature": "A8980EB0E15F4722B4644AF254DC88DF4044ABDFB483DDAC36EDA276122D099105C3EF3B3CD677E6438DEE876B84A9433CFC83CF54F864DE034F7D97A3370C07",
  296|       |  "work": "0000000000010F2C"
  297|       |}"#
  298|       |        );
  299|       |    }
  300|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/receive_block.rs:
    1|       |use super::{Block, BlockBase, BlockType};
    2|       |use crate::{
    3|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount, BlockHash, BlockHashBuilder, DependentBlocks, JsonBlock, Link, PrivateKey,
    5|       |    PublicKey, Root, Signature, WorkNonce,
    6|       |};
    7|       |use anyhow::Result;
    8|       |
    9|       |#[derive(Clone, Debug)]
   10|       |pub struct ReceiveBlock {
   11|       |    work: u64,
   12|       |    signature: Signature,
   13|       |    hashables: ReceiveHashables,
   14|       |    hash: BlockHash,
   15|       |}
   16|       |
   17|       |impl ReceiveBlock {
   18|      0|    pub fn new_test_instance() -> Self {
   19|      0|        let key = PrivateKey::from(42);
   20|      0|        ReceiveBlockArgs {
   21|      0|            key: &key,
   22|      0|            previous: 123.into(),
   23|      0|            source: 456.into(),
   24|      0|            work: 69420,
   25|      0|        }
   26|      0|        .into()
   27|      0|    }
   28|       |
   29|       |    // Receive blocks always have a source
   30|      0|    pub fn source(&self) -> BlockHash {
   31|      0|        self.hashables.source
   32|      0|    }
   33|       |
   34|      0|    pub fn serialized_size() -> usize {
   35|      0|        ReceiveHashables::serialized_size()
   36|      0|            + Signature::serialized_size()
   37|      0|            + std::mem::size_of::<u64>()
   38|      0|    }
   39|       |
   40|      0|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
   41|      0|        let previous = BlockHash::deserialize(stream)?;
   42|      0|        let source = BlockHash::deserialize(stream)?;
   43|      0|        let signature = Signature::deserialize(stream)?;
   44|      0|        let mut work_bytes = [0u8; 8];
   45|      0|        stream.read_bytes(&mut work_bytes, 8)?;
   46|      0|        let work = u64::from_le_bytes(work_bytes);
   47|      0|        let hashables = ReceiveHashables { previous, source };
   48|      0|        let hash = hashables.hash();
   49|      0|        Ok(Self {
   50|      0|            work,
   51|      0|            signature,
   52|      0|            hashables,
   53|      0|            hash,
   54|      0|        })
   55|      0|    }
   56|       |
   57|      0|    pub fn dependent_blocks(&self) -> DependentBlocks {
   58|      0|        DependentBlocks::new(self.previous(), self.source())
   59|      0|    }
   60|       |}
   61|       |
   62|      0|pub fn valid_receive_block_predecessor(predecessor: BlockType) -> bool {
   63|      0|    matches!(
   64|      0|        predecessor,
   65|       |        BlockType::LegacySend
   66|       |            | BlockType::LegacyReceive
   67|       |            | BlockType::LegacyOpen
   68|       |            | BlockType::LegacyChange
   69|       |    )
   70|      0|}
   71|       |
   72|       |impl PartialEq for ReceiveBlock {
   73|      0|    fn eq(&self, other: &Self) -> bool {
   74|      0|        self.work == other.work
   75|      0|            && self.signature == other.signature
   76|      0|            && self.hashables == other.hashables
   77|      0|    }
   78|       |}
   79|       |
   80|       |impl Eq for ReceiveBlock {}
   81|       |
   82|       |impl BlockBase for ReceiveBlock {
   83|      0|    fn block_type(&self) -> BlockType {
   84|      0|        BlockType::LegacyReceive
   85|      0|    }
   86|       |
   87|      0|    fn account_field(&self) -> Option<Account> {
   88|      0|        None
   89|      0|    }
   90|       |
   91|      0|    fn hash(&self) -> BlockHash {
   92|      0|        self.hash
   93|      0|    }
   94|       |
   95|      0|    fn link_field(&self) -> Option<Link> {
   96|      0|        None
   97|      0|    }
   98|       |
   99|      0|    fn signature(&self) -> &Signature {
  100|      0|        &self.signature
  101|      0|    }
  102|       |
  103|      0|    fn set_signature(&mut self, signature: Signature) {
  104|      0|        self.signature = signature;
  105|      0|    }
  106|       |
  107|      0|    fn set_work(&mut self, work: u64) {
  108|      0|        self.work = work;
  109|      0|    }
  110|       |
  111|      0|    fn work(&self) -> u64 {
  112|      0|        self.work
  113|      0|    }
  114|       |
  115|      0|    fn previous(&self) -> BlockHash {
  116|      0|        self.hashables.previous
  117|      0|    }
  118|       |
  119|      0|    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter) {
  120|      0|        self.hashables.previous.serialize(writer);
  121|      0|        self.hashables.source.serialize(writer);
  122|      0|        self.signature.serialize(writer);
  123|      0|        writer.write_bytes_safe(&self.work.to_le_bytes());
  124|      0|    }
  125|       |
  126|      0|    fn root(&self) -> Root {
  127|      0|        self.previous().into()
  128|      0|    }
  129|       |
  130|      0|    fn balance_field(&self) -> Option<Amount> {
  131|      0|        None
  132|      0|    }
  133|       |
  134|      0|    fn source_field(&self) -> Option<BlockHash> {
  135|      0|        Some(self.hashables.source)
  136|      0|    }
  137|       |
  138|      0|    fn representative_field(&self) -> Option<PublicKey> {
  139|      0|        None
  140|      0|    }
  141|       |
  142|      0|    fn valid_predecessor(&self, block_type: BlockType) -> bool {
  143|      0|        valid_receive_block_predecessor(block_type)
  144|      0|    }
  145|       |
  146|      0|    fn destination_field(&self) -> Option<Account> {
  147|      0|        None
  148|      0|    }
  149|       |
  150|      0|    fn json_representation(&self) -> JsonBlock {
  151|      0|        JsonBlock::Receive(JsonReceiveBlock {
  152|      0|            previous: self.hashables.previous,
  153|      0|            source: self.hashables.source,
  154|      0|            work: self.work.into(),
  155|      0|            signature: self.signature.clone(),
  156|      0|        })
  157|      0|    }
  158|       |}
  159|       |
  160|       |#[derive(Clone, PartialEq, Eq, Debug)]
  161|       |struct ReceiveHashables {
  162|       |    previous: BlockHash,
  163|       |    source: BlockHash,
  164|       |}
  165|       |
  166|       |impl ReceiveHashables {
  167|      0|    fn serialized_size() -> usize {
  168|      0|        BlockHash::serialized_size() + BlockHash::serialized_size()
  169|      0|    }
  170|       |
  171|      0|    fn hash(&self) -> BlockHash {
  172|      0|        BlockHashBuilder::new()
  173|      0|            .update(self.previous.as_bytes())
  174|      0|            .update(self.source.as_bytes())
  175|      0|            .build()
  176|      0|    }
  177|       |}
  178|       |
  179|       |pub struct ReceiveBlockArgs<'a> {
  180|       |    pub key: &'a PrivateKey,
  181|       |    pub previous: BlockHash,
  182|       |    pub source: BlockHash,
  183|       |    pub work: u64,
  184|       |}
  185|       |
  186|       |impl<'a> From<ReceiveBlockArgs<'a>> for ReceiveBlock {
  187|      0|    fn from(value: ReceiveBlockArgs<'a>) -> Self {
  188|      0|        let hashables = ReceiveHashables {
  189|      0|            previous: value.previous,
  190|      0|            source: value.source,
  191|      0|        };
  192|      0|        let hash = hashables.hash();
  193|      0|        let signature = value.key.sign(hash.as_bytes());
  194|      0|
  195|      0|        Self {
  196|      0|            work: value.work,
  197|      0|            signature,
  198|      0|            hashables,
  199|      0|            hash,
  200|      0|        }
  201|      0|    }
  202|       |}
  203|       |
  204|       |impl<'a> From<ReceiveBlockArgs<'a>> for Block {
  205|      0|    fn from(value: ReceiveBlockArgs<'a>) -> Self {
  206|      0|        Block::LegacyReceive(value.into())
  207|      0|    }
  208|       |}
  209|       |
  210|      0|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  211|       |pub struct JsonReceiveBlock {
  212|       |    pub previous: BlockHash,
  213|       |    pub source: BlockHash,
  214|       |    pub signature: Signature,
  215|       |    pub work: WorkNonce,
  216|       |}
  217|       |
  218|       |impl From<JsonReceiveBlock> for ReceiveBlock {
  219|      0|    fn from(value: JsonReceiveBlock) -> Self {
  220|      0|        let hashables = ReceiveHashables {
  221|      0|            previous: value.previous,
  222|      0|            source: value.source,
  223|      0|        };
  224|      0|        let hash = hashables.hash();
  225|      0|
  226|      0|        Self {
  227|      0|            work: value.work.into(),
  228|      0|            signature: value.signature,
  229|      0|            hashables,
  230|      0|            hash,
  231|      0|        }
  232|      0|    }
  233|       |}
  234|       |
  235|       |#[cfg(test)]
  236|       |mod tests {
  237|       |    use super::*;
  238|       |    use crate::{utils::MemoryStream, Block, PrivateKey};
  239|       |
  240|       |    #[test]
  241|       |    fn create_block() {
  242|       |        let key = PrivateKey::new();
  243|       |        let previous = BlockHash::from(1);
  244|       |        let block: ReceiveBlock = ReceiveBlockArgs {
  245|       |            key: &key,
  246|       |            previous,
  247|       |            source: 2.into(),
  248|       |            work: 4,
  249|       |        }
  250|       |        .into();
  251|       |        assert_eq!(block.previous(), previous);
  252|       |        assert_eq!(block.root(), previous.into());
  253|       |    }
  254|       |
  255|       |    // original test: block.receive_serialize
  256|       |    // original test: receive_block.deserialize
  257|       |    #[test]
  258|       |    fn serialize() {
  259|       |        let key1 = PrivateKey::new();
  260|       |        let block1: ReceiveBlock = ReceiveBlockArgs {
  261|       |            key: &key1,
  262|       |            previous: 0.into(),
  263|       |            source: 1.into(),
  264|       |            work: 4,
  265|       |        }
  266|       |        .into();
  267|       |        let mut stream = MemoryStream::new();
  268|       |        block1.serialize_without_block_type(&mut stream);
  269|       |        assert_eq!(ReceiveBlock::serialized_size(), stream.bytes_written());
  270|       |
  271|       |        let block2 = ReceiveBlock::deserialize(&mut stream).unwrap();
  272|       |        assert_eq!(block1, block2);
  273|       |    }
  274|       |
  275|       |    #[test]
  276|       |    fn serialize_serde() {
  277|       |        let block = Block::LegacyReceive(ReceiveBlock::new_test_instance());
  278|       |        let serialized = serde_json::to_string_pretty(&block).unwrap();
  279|       |        assert_eq!(
  280|       |            serialized,
  281|       |            r#"{
  282|       |  "type": "receive",
  283|       |  "previous": "000000000000000000000000000000000000000000000000000000000000007B",
  284|       |  "source": "00000000000000000000000000000000000000000000000000000000000001C8",
  285|       |  "signature": "6F6E98FB9C3D0B91CBAF78C8613C7A7AE990AA627B9C1381D1D97AB7118C91D169381E3897A477286A4AFB68F7CD347F3FF16F8AB4C33241D8BF793CE29E730B",
  286|       |  "work": "0000000000010F2C"
  287|       |}"#
  288|       |        );
  289|       |    }
  290|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/send_block.rs:
    1|       |use super::{Block, BlockBase, BlockType};
    2|       |use crate::{
    3|       |    utils::{BufferWriter, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount, BlockHash, BlockHashBuilder, DependentBlocks, JsonBlock, Link, PendingKey,
    5|       |    PrivateKey, PublicKey, Root, Signature, WorkNonce,
    6|       |};
    7|       |use anyhow::Result;
    8|       |use serde::de::{Unexpected, Visitor};
    9|       |
   10|       |#[derive(Clone, Default, Debug)]
   11|       |pub struct SendBlock {
   12|       |    hashables: SendHashables,
   13|       |    signature: Signature,
   14|       |    work: u64,
   15|       |    hash: BlockHash,
   16|       |}
   17|       |
   18|       |impl SendBlock {
   19|      0|    pub fn new_test_instance() -> Self {
   20|      0|        let key = PrivateKey::from(42);
   21|      0|        SendBlockArgs {
   22|      0|            key: &key,
   23|      0|            previous: 1.into(),
   24|      0|            destination: 2.into(),
   25|      0|            balance: 3.into(),
   26|      0|            work: 424269420,
   27|      0|        }
   28|      0|        .into()
   29|      0|    }
   30|       |
   31|      0|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
   32|      0|        let hashables = SendHashables::deserialize(stream)?;
   33|      0|        let signature = Signature::deserialize(stream)?;
   34|       |
   35|      0|        let mut buffer = [0u8; 8];
   36|      0|        stream.read_bytes(&mut buffer, 8)?;
   37|      0|        let work = u64::from_le_bytes(buffer);
   38|      0|        let hash = hashables.hash();
   39|      0|        Ok(SendBlock {
   40|      0|            hashables,
   41|      0|            signature,
   42|      0|            work,
   43|      0|            hash,
   44|      0|        })
   45|      0|    }
   46|       |
   47|      0|    pub fn serialized_size() -> usize {
   48|      0|        SendHashables::serialized_size() + Signature::serialized_size() + std::mem::size_of::<u64>()
   49|      0|    }
   50|       |
   51|      0|    pub fn zero(&mut self) {
   52|      0|        self.work = 0;
   53|      0|        self.signature = Signature::new();
   54|      0|        self.hashables.clear();
   55|      0|    }
   56|       |
   57|      0|    pub fn balance(&self) -> Amount {
   58|      0|        self.hashables.balance
   59|      0|    }
   60|       |
   61|      0|    pub fn set_destination(&mut self, destination: Account) {
   62|      0|        self.hashables.destination = destination;
   63|      0|    }
   64|       |
   65|      0|    pub fn set_previous(&mut self, previous: BlockHash) {
   66|      0|        self.hashables.previous = previous;
   67|      0|    }
   68|       |
   69|      0|    pub fn set_balance(&mut self, balance: Amount) {
   70|      0|        self.hashables.balance = balance;
   71|      0|    }
   72|       |
   73|      0|    pub fn pending_key(&self) -> PendingKey {
   74|      0|        PendingKey::new(self.hashables.destination, self.hash())
   75|      0|    }
   76|       |
   77|      0|    pub fn destination(&self) -> Account {
   78|      0|        self.hashables.destination
   79|      0|    }
   80|       |
   81|      0|    pub fn dependent_blocks(&self) -> DependentBlocks {
   82|      0|        DependentBlocks::new(self.previous(), BlockHash::zero())
   83|      0|    }
   84|       |}
   85|       |
   86|      0|pub fn valid_send_block_predecessor(block_type: BlockType) -> bool {
   87|      0|    match block_type {
   88|       |        BlockType::LegacySend
   89|       |        | BlockType::LegacyReceive
   90|       |        | BlockType::LegacyOpen
   91|      0|        | BlockType::LegacyChange => true,
   92|      0|        BlockType::NotABlock | BlockType::State | BlockType::Invalid => false,
   93|       |    }
   94|      0|}
   95|       |
   96|       |impl PartialEq for SendBlock {
   97|      0|    fn eq(&self, other: &Self) -> bool {
   98|      0|        self.hashables == other.hashables
   99|      0|            && self.signature == other.signature
  100|      0|            && self.work == other.work
  101|      0|    }
  102|       |}
  103|       |
  104|       |impl Eq for SendBlock {}
  105|       |
  106|       |impl BlockBase for SendBlock {
  107|      0|    fn block_type(&self) -> BlockType {
  108|      0|        BlockType::LegacySend
  109|      0|    }
  110|       |
  111|      0|    fn account_field(&self) -> Option<Account> {
  112|      0|        None
  113|      0|    }
  114|       |
  115|      0|    fn hash(&self) -> BlockHash {
  116|      0|        self.hash
  117|      0|    }
  118|       |
  119|      0|    fn link_field(&self) -> Option<Link> {
  120|      0|        None
  121|      0|    }
  122|       |
  123|      0|    fn signature(&self) -> &Signature {
  124|      0|        &self.signature
  125|      0|    }
  126|       |
  127|      0|    fn set_signature(&mut self, signature: Signature) {
  128|      0|        self.signature = signature;
  129|      0|    }
  130|       |
  131|      0|    fn set_work(&mut self, work: u64) {
  132|      0|        self.work = work;
  133|      0|    }
  134|       |
  135|      0|    fn work(&self) -> u64 {
  136|      0|        self.work
  137|      0|    }
  138|       |
  139|      0|    fn previous(&self) -> BlockHash {
  140|      0|        self.hashables.previous
  141|      0|    }
  142|       |
  143|      0|    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter) {
  144|      0|        self.hashables.serialize(writer);
  145|      0|        self.signature.serialize(writer);
  146|      0|        writer.write_bytes_safe(&self.work.to_le_bytes());
  147|      0|    }
  148|       |
  149|      0|    fn root(&self) -> Root {
  150|      0|        self.previous().into()
  151|      0|    }
  152|       |
  153|      0|    fn balance_field(&self) -> Option<Amount> {
  154|      0|        Some(self.hashables.balance)
  155|      0|    }
  156|       |
  157|      0|    fn source_field(&self) -> Option<BlockHash> {
  158|      0|        None
  159|      0|    }
  160|       |
  161|      0|    fn representative_field(&self) -> Option<PublicKey> {
  162|      0|        None
  163|      0|    }
  164|       |
  165|      0|    fn valid_predecessor(&self, block_type: BlockType) -> bool {
  166|      0|        valid_send_block_predecessor(block_type)
  167|      0|    }
  168|       |
  169|      0|    fn destination_field(&self) -> Option<Account> {
  170|      0|        Some(self.hashables.destination)
  171|      0|    }
  172|       |
  173|      0|    fn json_representation(&self) -> JsonBlock {
  174|      0|        JsonBlock::Send(JsonSendBlock {
  175|      0|            previous: self.hashables.previous,
  176|      0|            destination: self.hashables.destination,
  177|      0|            balance: self.hashables.balance.into(),
  178|      0|            work: self.work.into(),
  179|      0|            signature: self.signature.clone(),
  180|      0|        })
  181|      0|    }
  182|       |}
  183|       |
  184|       |impl From<JsonSendBlock> for SendBlock {
  185|      0|    fn from(value: JsonSendBlock) -> Self {
  186|      0|        let hashables = SendHashables {
  187|      0|            previous: value.previous,
  188|      0|            destination: value.destination,
  189|      0|            balance: value.balance.into(),
  190|      0|        };
  191|      0|
  192|      0|        let hash = hashables.hash();
  193|      0|
  194|      0|        Self {
  195|      0|            hashables,
  196|      0|            work: value.work.into(),
  197|      0|            signature: value.signature,
  198|      0|            hash,
  199|      0|        }
  200|      0|    }
  201|       |}
  202|       |
  203|       |#[derive(Clone, PartialEq, Eq, Default, Debug)]
  204|       |struct SendHashables {
  205|       |    pub previous: BlockHash,
  206|       |    pub destination: Account,
  207|       |    pub balance: Amount,
  208|       |}
  209|       |
  210|       |impl SendHashables {
  211|      0|    pub fn serialized_size() -> usize {
  212|      0|        BlockHash::serialized_size() + Account::serialized_size() + Amount::serialized_size()
  213|      0|    }
  214|       |
  215|      0|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
  216|      0|        let mut buffer_32 = [0u8; 32];
  217|      0|        let mut buffer_16 = [0u8; 16];
  218|      0|
  219|      0|        stream.read_bytes(&mut buffer_32, 32)?;
  220|      0|        let previous = BlockHash::from_bytes(buffer_32);
  221|      0|
  222|      0|        stream.read_bytes(&mut buffer_32, 32)?;
  223|      0|        let destination = Account::from_bytes(buffer_32);
  224|      0|
  225|      0|        stream.read_bytes(&mut buffer_16, 16)?;
  226|      0|        let balance = Amount::raw(u128::from_be_bytes(buffer_16));
  227|      0|
  228|      0|        Ok(Self {
  229|      0|            previous,
  230|      0|            destination,
  231|      0|            balance,
  232|      0|        })
  233|      0|    }
  234|       |
  235|      0|    fn clear(&mut self) {
  236|      0|        self.previous = BlockHash::zero();
  237|      0|        self.destination = Account::zero();
  238|      0|        self.balance = Amount::raw(0);
  239|      0|    }
  240|       |
  241|      0|    fn hash(&self) -> BlockHash {
  242|      0|        BlockHashBuilder::new()
  243|      0|            .update(self.previous.as_bytes())
  244|      0|            .update(self.destination.as_bytes())
  245|      0|            .update(self.balance.to_be_bytes())
  246|      0|            .build()
  247|      0|    }
  248|       |}
  249|       |
  250|       |impl crate::utils::Serialize for SendHashables {
  251|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  252|      0|        self.previous.serialize(stream);
  253|      0|        self.destination.serialize(stream);
  254|      0|        self.balance.serialize(stream);
  255|      0|    }
  256|       |}
  257|       |
  258|       |pub struct SendBlockArgs<'a> {
  259|       |    pub key: &'a PrivateKey,
  260|       |    pub previous: BlockHash,
  261|       |    pub destination: Account,
  262|       |    pub balance: Amount,
  263|       |    pub work: u64,
  264|       |}
  265|       |
  266|       |impl<'a> From<SendBlockArgs<'a>> for SendBlock {
  267|      0|    fn from(value: SendBlockArgs<'a>) -> Self {
  268|      0|        let hashables = SendHashables {
  269|      0|            previous: value.previous,
  270|      0|            destination: value.destination,
  271|      0|            balance: value.balance,
  272|      0|        };
  273|      0|
  274|      0|        let hash = hashables.hash();
  275|      0|        let signature = value.key.sign(hash.as_bytes());
  276|      0|
  277|      0|        Self {
  278|      0|            hashables,
  279|      0|            work: value.work,
  280|      0|            signature,
  281|      0|            hash,
  282|      0|        }
  283|      0|    }
  284|       |}
  285|       |
  286|       |impl<'a> From<SendBlockArgs<'a>> for Block {
  287|      0|    fn from(value: SendBlockArgs<'a>) -> Self {
  288|      0|        Block::LegacySend(value.into())
  289|      0|    }
  290|       |}
  291|       |
  292|      0|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  293|       |pub struct JsonSendBlock {
  294|       |    pub previous: BlockHash,
  295|       |    pub destination: Account,
  296|       |    pub balance: AmountHex,
  297|       |    pub work: WorkNonce,
  298|       |    pub signature: Signature,
  299|       |}
  300|       |
  301|       |#[derive(Debug, PartialEq, Eq, Clone, Copy)]
  302|       |pub struct AmountHex(u128);
  303|       |
  304|       |impl AmountHex {
  305|      0|    pub fn new(amount: u128) -> Self {
  306|      0|        Self(amount)
  307|      0|    }
  308|       |}
  309|       |
  310|       |impl From<Amount> for AmountHex {
  311|      0|    fn from(value: Amount) -> Self {
  312|      0|        Self(value.number())
  313|      0|    }
  314|       |}
  315|       |
  316|       |impl From<AmountHex> for Amount {
  317|      0|    fn from(value: AmountHex) -> Self {
  318|      0|        Amount::raw(value.0)
  319|      0|    }
  320|       |}
  321|       |
  322|       |impl serde::Serialize for AmountHex {
  323|      0|    fn serialize<S>(&self, serializer: S) -> std::prelude::v1::Result<S::Ok, S::Error>
  324|      0|    where
  325|      0|        S: serde::Serializer,
  326|      0|    {
  327|      0|        let amount = Amount::raw(self.0);
  328|      0|        let hex = amount.encode_hex();
  329|      0|        serializer.serialize_str(&hex)
  330|      0|    }
  331|       |}
  332|       |
  333|       |impl<'de> serde::Deserialize<'de> for AmountHex {
  334|      0|    fn deserialize<D>(deserializer: D) -> std::prelude::v1::Result<Self, D::Error>
  335|      0|    where
  336|      0|        D: serde::Deserializer<'de>,
  337|      0|    {
  338|      0|        let value = deserializer.deserialize_str(AmountHexVisitor {})?;
  339|      0|        Ok(value)
  340|      0|    }
  341|       |}
  342|       |
  343|       |struct AmountHexVisitor {}
  344|       |
  345|       |impl<'de> Visitor<'de> for AmountHexVisitor {
  346|       |    type Value = AmountHex;
  347|       |
  348|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
  349|      0|        formatter.write_str("a u128 bit amount in encoded as hex string")
  350|      0|    }
  351|       |
  352|      0|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  353|      0|    where
  354|      0|        E: serde::de::Error,
  355|      0|    {
  356|      0|        let amount = Amount::decode_hex(v).map_err(|_| {
  357|      0|            serde::de::Error::invalid_value(
  358|      0|                Unexpected::Str(v),
  359|      0|                &"a u128 bit amount in encoded as hex string",
  360|      0|            )
  361|      0|        })?;
  362|      0|        Ok(amount.into())
  363|      0|    }
  364|       |}
  365|       |
  366|       |#[cfg(test)]
  367|       |mod tests {
  368|       |    use super::*;
  369|       |    use crate::{utils::MemoryStream, Block, PrivateKey};
  370|       |
  371|       |    #[test]
  372|       |    fn create_send_block() {
  373|       |        let key = PrivateKey::new();
  374|       |        let mut block: SendBlock = SendBlockArgs {
  375|       |            key: &key,
  376|       |            previous: 0.into(),
  377|       |            destination: 1.into(),
  378|       |            balance: 13.into(),
  379|       |            work: 2,
  380|       |        }
  381|       |        .into();
  382|       |
  383|       |        assert_eq!(block.root(), block.previous().into());
  384|       |        let hash = block.hash().to_owned();
  385|       |        assert!(key
  386|       |            .public_key()
  387|       |            .verify(hash.as_bytes(), &block.signature)
  388|       |            .is_ok());
  389|       |
  390|       |        block.set_signature(Signature::from_bytes([1; 64]));
  391|       |        assert!(key
  392|       |            .public_key()
  393|       |            .verify(hash.as_bytes(), &block.signature)
  394|       |            .is_err());
  395|       |    }
  396|       |
  397|       |    // original test: block.send_serialize
  398|       |    // original test: send_block.deserialize
  399|       |    #[test]
  400|       |    fn serialize() {
  401|       |        let key = PrivateKey::new();
  402|       |        let block1: SendBlock = SendBlockArgs {
  403|       |            key: &key,
  404|       |            previous: 0.into(),
  405|       |            destination: 1.into(),
  406|       |            balance: 2.into(),
  407|       |            work: 5,
  408|       |        }
  409|       |        .into();
  410|       |        let mut stream = MemoryStream::new();
  411|       |        block1.serialize_without_block_type(&mut stream);
  412|       |        assert_eq!(SendBlock::serialized_size(), stream.bytes_written());
  413|       |
  414|       |        let block2 = SendBlock::deserialize(&mut stream).unwrap();
  415|       |        assert_eq!(block1, block2);
  416|       |    }
  417|       |
  418|       |    #[test]
  419|       |    fn serialize_serde() {
  420|       |        let block = Block::LegacySend(SendBlock::new_test_instance());
  421|       |        let serialized = serde_json::to_string_pretty(&block).unwrap();
  422|       |        assert_eq!(
  423|       |            serialized,
  424|       |            r#"{
  425|       |  "type": "send",
  426|       |  "previous": "0000000000000000000000000000000000000000000000000000000000000001",
  427|       |  "destination": "nano_11111111111111111111111111111111111111111111111111147dcwzp3c",
  428|       |  "balance": "00000000000000000000000000000003",
  429|       |  "work": "000000001949D66C",
  430|       |  "signature": "076FF9D1587141EC1DDB05493092B0BFE160B6EEE96D37462B11A81F2622A5211756316A9B48BB403EE4AC57BCCA2023C2075F7214B6B33211B9E5350B76A606"
  431|       |}"#
  432|       |        );
  433|       |    }
  434|       |
  435|       |    #[test]
  436|       |    fn serde_serialize_amount_hex() {
  437|       |        let serialized =
  438|       |            serde_json::to_string_pretty(&AmountHex::new(337010421085160209006996005437231978653))
  439|       |                .unwrap();
  440|       |        assert_eq!(serialized, "\"FD89D89D89D89D89D89D89D89D89D89D\"");
  441|       |    }
  442|       |
  443|       |    #[test]
  444|       |    fn serde_deserialize_amount_hex() {
  445|       |        let deserialized: AmountHex =
  446|       |            serde_json::from_str("\"FD89D89D89D89D89D89D89D89D89D89D\"").unwrap();
  447|       |        assert_eq!(
  448|       |            deserialized,
  449|       |            AmountHex::new(337010421085160209006996005437231978653)
  450|       |        );
  451|       |    }
  452|       |}

/home/gustav/code/nano/rsnano-node/core/src/blocks/state_block.rs:
    1|       |use super::{Block, BlockBase, BlockType};
    2|       |use crate::{
    3|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount, BlockHash, BlockHashBuilder, JsonBlock, Link, PrivateKey, PublicKey, Root,
    5|       |    Signature, WorkNonce,
    6|       |};
    7|       |use anyhow::Result;
    8|       |
    9|       |#[derive(Clone, Default, Debug)]
   10|       |pub struct StateBlock {
   11|       |    hashables: StateHashables,
   12|       |    signature: Signature,
   13|       |    hash: BlockHash,
   14|       |    work: u64,
   15|       |}
   16|       |
   17|       |impl StateBlock {
   18|      0|    pub fn verify_signature(&self) -> anyhow::Result<()> {
   19|      0|        self.account()
   20|      0|            .as_key()
   21|      0|            .verify(self.hash().as_bytes(), self.signature())
   22|      0|    }
   23|       |
   24|  49.1k|    pub fn account(&self) -> Account {
   25|  49.1k|        self.hashables.account
   26|  49.1k|    }
   27|       |
   28|  33.4k|    pub fn link(&self) -> Link {
   29|  33.4k|        self.hashables.link
   30|  33.4k|    }
   31|       |
   32|  49.6k|    pub fn balance(&self) -> Amount {
   33|  49.6k|        self.hashables.balance
   34|  49.6k|    }
   35|       |
   36|      0|    pub fn source(&self) -> BlockHash {
   37|      0|        BlockHash::zero()
   38|      0|    }
   39|       |
   40|      0|    pub fn representative(&self) -> PublicKey {
   41|      0|        self.hashables.representative
   42|      0|    }
   43|       |
   44|      0|    pub fn destination(&self) -> Account {
   45|      0|        Account::zero()
   46|      0|    }
   47|       |
   48|      0|    pub fn serialized_size() -> usize {
   49|      0|        Account::serialized_size() // Account
   50|      0|            + BlockHash::serialized_size() // Previous
   51|      0|            + Account::serialized_size() // Representative
   52|      0|            + Amount::serialized_size() // Balance
   53|      0|            + Link::serialized_size() // Link
   54|      0|            + Signature::serialized_size()
   55|      0|            + std::mem::size_of::<u64>() // Work
   56|      0|    }
   57|       |
   58|  49.1k|    pub fn deserialize(stream: &mut dyn Stream) -> Result<Self> {
   59|  49.1k|        let account = Account::deserialize(stream)?;
                                                                ^0
   60|  49.1k|        let previous = BlockHash::deserialize(stream)?;
                                                                   ^0
   61|  49.1k|        let representative = PublicKey::deserialize(stream)?;
                                                                         ^0
   62|  49.1k|        let balance = Amount::deserialize(stream)?;
                                                               ^0
   63|  49.1k|        let link = Link::deserialize(stream)?;
                                                          ^0
   64|  49.1k|        let signature = Signature::deserialize(stream)?;
                                                                    ^0
   65|  49.1k|        let mut work_bytes = [0u8; 8];
   66|  49.1k|        stream.read_bytes(&mut work_bytes, 8)?;
                                                           ^0
   67|  49.1k|        let work = u64::from_be_bytes(work_bytes);
   68|  49.1k|        let hashables = StateHashables {
   69|  49.1k|            account,
   70|  49.1k|            previous,
   71|  49.1k|            representative,
   72|  49.1k|            balance,
   73|  49.1k|            link,
   74|  49.1k|        };
   75|  49.1k|        let hash = hashables.hash();
   76|  49.1k|        Ok(Self {
   77|  49.1k|            work,
   78|  49.1k|            signature,
   79|  49.1k|            hashables,
   80|  49.1k|            hash,
   81|  49.1k|        })
   82|  49.1k|    }
   83|       |}
   84|       |
   85|       |impl PartialEq for StateBlock {
   86|      0|    fn eq(&self, other: &Self) -> bool {
   87|      0|        self.work == other.work
   88|      0|            && self.signature == other.signature
   89|      0|            && self.hashables == other.hashables
   90|      0|    }
   91|       |}
   92|       |
   93|       |impl Eq for StateBlock {}
   94|       |
   95|       |impl BlockBase for StateBlock {
   96|  49.2k|    fn block_type(&self) -> BlockType {
   97|  49.2k|        BlockType::State
   98|  49.2k|    }
   99|       |
  100|  49.1k|    fn account_field(&self) -> Option<Account> {
  101|  49.1k|        Some(self.hashables.account)
  102|  49.1k|    }
  103|       |
  104|  16.6k|    fn hash(&self) -> BlockHash {
  105|  16.6k|        self.hash
  106|  16.6k|    }
  107|       |
  108|     70|    fn link_field(&self) -> Option<Link> {
  109|     70|        Some(self.hashables.link)
  110|     70|    }
  111|       |
  112|     32|    fn signature(&self) -> &Signature {
  113|     32|        &self.signature
  114|     32|    }
  115|       |
  116|      0|    fn set_signature(&mut self, signature: Signature) {
  117|      0|        self.signature = signature;
  118|      0|    }
  119|       |
  120|      1|    fn set_work(&mut self, work: u64) {
  121|      1|        self.work = work;
  122|      1|    }
  123|       |
  124|     33|    fn work(&self) -> u64 {
  125|     33|        self.work
  126|     33|    }
  127|       |
  128|  16.8k|    fn previous(&self) -> BlockHash {
  129|  16.8k|        self.hashables.previous
  130|  16.8k|    }
  131|       |
  132|     33|    fn serialize_without_block_type(&self, writer: &mut dyn BufferWriter) {
  133|     33|        self.hashables.account.serialize(writer);
  134|     33|        self.hashables.previous.serialize(writer);
  135|     33|        self.hashables.representative.serialize(writer);
  136|     33|        self.hashables.balance.serialize(writer);
  137|     33|        self.hashables.link.serialize(writer);
  138|     33|        self.signature.serialize(writer);
  139|     33|        writer.write_bytes_safe(&self.work.to_be_bytes());
  140|     33|    }
  141|       |
  142|     33|    fn root(&self) -> Root {
  143|     33|        if !self.previous().is_zero() {
  144|     29|            self.previous().into()
  145|       |        } else {
  146|      4|            self.hashables.account.into()
  147|       |        }
  148|     33|    }
  149|       |
  150|      1|    fn balance_field(&self) -> Option<Amount> {
  151|      1|        Some(self.hashables.balance)
  152|      1|    }
  153|       |
  154|     36|    fn source_field(&self) -> Option<BlockHash> {
  155|     36|        None
  156|     36|    }
  157|       |
  158|     33|    fn representative_field(&self) -> Option<PublicKey> {
  159|     33|        Some(self.hashables.representative)
  160|     33|    }
  161|       |
  162|     28|    fn valid_predecessor(&self, _block_type: BlockType) -> bool {
  163|     28|        true
  164|     28|    }
  165|       |
  166|      4|    fn destination_field(&self) -> Option<Account> {
  167|      4|        None
  168|      4|    }
  169|       |
  170|      0|    fn json_representation(&self) -> JsonBlock {
  171|      0|        JsonBlock::State(JsonStateBlock {
  172|      0|            account: self.hashables.account,
  173|      0|            previous: self.hashables.previous,
  174|      0|            representative: self.hashables.representative.into(),
  175|      0|            balance: self.hashables.balance,
  176|      0|            link: self.hashables.link,
  177|      0|            link_as_account: Some(self.hashables.link.into()),
  178|      0|            signature: self.signature.clone(),
  179|      0|            work: self.work.into(),
  180|      0|        })
  181|      0|    }
  182|       |}
  183|       |
  184|       |#[derive(Clone, PartialEq, Eq, Default, Debug)]
  185|       |struct StateHashables {
  186|       |    // Account# / public key that operates this account
  187|       |    // Uses:
  188|       |    // Bulk signature validation in advance of further ledger processing
  189|       |    // Arranging uncomitted transactions by account
  190|       |    account: Account,
  191|       |
  192|       |    // Previous transaction in this chain
  193|       |    previous: BlockHash,
  194|       |
  195|       |    // Representative of this account
  196|       |    representative: PublicKey,
  197|       |
  198|       |    // Current balance of this account
  199|       |    // Allows lookup of account balance simply by looking at the head block
  200|       |    balance: Amount,
  201|       |
  202|       |    // Link field contains source block_hash if receiving, destination account if sending
  203|       |    link: Link,
  204|       |}
  205|       |
  206|       |impl StateHashables {
  207|  49.2k|    fn hash(&self) -> BlockHash {
  208|  49.2k|        let mut preamble = [0u8; 32];
  209|  49.2k|        preamble[31] = BlockType::State as u8;
  210|  49.2k|        BlockHashBuilder::new()
  211|  49.2k|            .update(preamble)
  212|  49.2k|            .update(self.account.as_bytes())
  213|  49.2k|            .update(self.previous.as_bytes())
  214|  49.2k|            .update(self.representative.as_bytes())
  215|  49.2k|            .update(self.balance.to_be_bytes())
  216|  49.2k|            .update(self.link.as_bytes())
  217|  49.2k|            .build()
  218|  49.2k|    }
  219|       |}
  220|       |
  221|       |#[derive(Clone)]
  222|       |pub struct StateBlockArgs<'a> {
  223|       |    pub key: &'a PrivateKey,
  224|       |    pub previous: BlockHash,
  225|       |    pub representative: PublicKey,
  226|       |    pub balance: Amount,
  227|       |    pub link: Link,
  228|       |    pub work: u64,
  229|       |}
  230|       |
  231|       |impl<'a> From<StateBlockArgs<'a>> for Block {
  232|     43|    fn from(value: StateBlockArgs<'a>) -> Self {
  233|     43|        let hashables = StateHashables {
  234|     43|            account: value.key.account(),
  235|     43|            previous: value.previous,
  236|     43|            representative: value.representative,
  237|     43|            balance: value.balance,
  238|     43|            link: value.link,
  239|     43|        };
  240|     43|
  241|     43|        let hash = hashables.hash();
  242|     43|        let signature = value.key.sign(hash.as_bytes());
  243|     43|
  244|     43|        Block::State(StateBlock {
  245|     43|            hashables,
  246|     43|            signature,
  247|     43|            hash,
  248|     43|            work: value.work,
  249|     43|        })
  250|     43|    }
  251|       |}
  252|       |
  253|       |pub struct EpochBlockArgs<'a> {
  254|       |    pub epoch_signer: &'a PrivateKey,
  255|       |    pub account: Account,
  256|       |    pub previous: BlockHash,
  257|       |    pub representative: PublicKey,
  258|       |    pub balance: Amount,
  259|       |    pub link: Link,
  260|       |    pub work: u64,
  261|       |}
  262|       |
  263|       |impl<'a> From<EpochBlockArgs<'a>> for Block {
  264|      1|    fn from(value: EpochBlockArgs<'a>) -> Self {
  265|      1|        let hashables = StateHashables {
  266|      1|            account: value.account,
  267|      1|            previous: value.previous,
  268|      1|            representative: value.representative,
  269|      1|            balance: value.balance,
  270|      1|            link: value.link,
  271|      1|        };
  272|      1|
  273|      1|        let hash = hashables.hash();
  274|      1|        let signature = value.epoch_signer.sign(hash.as_bytes());
  275|      1|
  276|      1|        Block::State(StateBlock {
  277|      1|            hashables,
  278|      1|            signature,
  279|      1|            hash,
  280|      1|            work: value.work,
  281|      1|        })
  282|      1|    }
  283|       |}
  284|       |
  285|       |impl From<JsonStateBlock> for StateBlock {
  286|      0|    fn from(value: JsonStateBlock) -> Self {
  287|      0|        let hashables = StateHashables {
  288|      0|            account: value.account,
  289|      0|            previous: value.previous,
  290|      0|            representative: value.representative.into(),
  291|      0|            balance: value.balance,
  292|      0|            link: value.link,
  293|      0|        };
  294|      0|
  295|      0|        let hash = hashables.hash();
  296|      0|
  297|      0|        Self {
  298|      0|            work: value.work.into(),
  299|      0|            signature: value.signature,
  300|      0|            hashables,
  301|      0|            hash,
  302|      0|        }
  303|      0|    }
  304|       |}
  305|       |
  306|      0|#[derive(PartialEq, Eq, Debug, serde::Serialize, serde::Deserialize, Clone)]
  307|       |pub struct JsonStateBlock {
  308|       |    pub account: Account,
  309|       |    pub previous: BlockHash,
  310|       |    pub representative: Account,
  311|       |    pub balance: Amount,
  312|       |    pub link: Link,
  313|       |    pub link_as_account: Option<Account>,
  314|       |    pub signature: Signature,
  315|       |    pub work: WorkNonce,
  316|       |}
  317|       |
  318|       |#[cfg(test)]
  319|       |mod tests {
  320|       |    use super::*;
  321|       |    use crate::{utils::MemoryStream, Block, TestBlockBuilder, TestStateBlockBuilder};
  322|       |
  323|       |    #[test]
  324|       |    fn serialization() {
  325|       |        let block1 = TestBlockBuilder::state().work(5).build();
  326|       |        let mut stream = MemoryStream::new();
  327|       |        block1.serialize_without_block_type(&mut stream);
  328|       |        assert_eq!(StateBlock::serialized_size(), stream.bytes_written());
  329|       |        assert_eq!(stream.byte_at(215), 0x5); // Ensure work is serialized big-endian
  330|       |
  331|       |        let block2 = StateBlock::deserialize(&mut stream).unwrap();
  332|       |        assert_eq!(block1, Block::State(block2));
  333|       |    }
  334|       |
  335|       |    #[test]
  336|       |    fn hashing() {
  337|       |        let key = PrivateKey::from(42);
  338|       |        let block = TestBlockBuilder::state().key(&key).build();
  339|       |        let hash = block.hash();
  340|       |        assert_eq!(hash, TestBlockBuilder::state().key(&key).build().hash());
  341|       |
  342|       |        let assert_different_hash = |b: TestStateBlockBuilder| {
  343|       |            assert_ne!(hash, b.build().hash());
  344|       |        };
  345|       |
  346|       |        assert_different_hash(
  347|       |            TestBlockBuilder::state()
  348|       |                .key(&key)
  349|       |                .account(Account::from(1000)),
  350|       |        );
  351|       |        assert_different_hash(
  352|       |            TestBlockBuilder::state()
  353|       |                .key(&key)
  354|       |                .previous(BlockHash::from(1000)),
  355|       |        );
  356|       |        assert_different_hash(
  357|       |            TestBlockBuilder::state()
  358|       |                .key(&key)
  359|       |                .representative(Account::from(1000)),
  360|       |        );
  361|       |        assert_different_hash(
  362|       |            TestBlockBuilder::state()
  363|       |                .key(&key)
  364|       |                .balance(Amount::from(1000)),
  365|       |        );
  366|       |        assert_different_hash(TestBlockBuilder::state().key(&key).link(Link::from(1000)));
  367|       |    }
  368|       |
  369|       |    #[test]
  370|       |    fn serialize_serde() {
  371|       |        let block = Block::new_test_instance();
  372|       |        let serialized = serde_json::to_string_pretty(&block).unwrap();
  373|       |        assert_eq!(
  374|       |            serialized,
  375|       |            r#"{
  376|       |  "type": "state",
  377|       |  "account": "nano_39y535msmkzb31bx73tdnf8iken5ucw9jt98re7nriduus6cgs6uonjdm8r5",
  378|       |  "previous": "00000000000000000000000000000000000000000000000000000000000001C8",
  379|       |  "representative": "nano_11111111111111111111111111111111111111111111111111ros3kc7wyy",
  380|       |  "balance": "420",
  381|       |  "link": "000000000000000000000000000000000000000000000000000000000000006F",
  382|       |  "link_as_account": "nano_111111111111111111111111111111111111111111111111115hkrzwewgm",
  383|       |  "signature": "F26EC6180795C63CFEC46F929DCF6269445208B6C1C837FA64925F1D61C218D4D263F9A73A4B76E3174888C6B842FC1380AC15183FA67E92B2091FEBCCBDB308",
  384|       |  "work": "0000000000010F2C"
  385|       |}"#
  386|       |        );
  387|       |    }
  388|       |}

/home/gustav/code/nano/rsnano-node/core/src/confirmation_height_info.rs:
    1|       |use crate::{
    2|       |    utils::{
    3|       |        BufferWriter, Deserialize, FixedSizeSerialize, MutStreamAdapter, Serialize, Stream,
    4|       |        StreamExt,
    5|       |    },
    6|       |    BlockHash,
    7|       |};
    8|       |
    9|       |#[derive(Default, PartialEq, Eq, Debug, Clone)]
   10|       |pub struct ConfirmationHeightInfo {
   11|       |    pub height: u64,
   12|       |    pub frontier: BlockHash,
   13|       |}
   14|       |
   15|       |impl ConfirmationHeightInfo {
   16|  16.4k|    pub fn new(height: u64, frontier: BlockHash) -> Self {
   17|  16.4k|        Self { height, frontier }
   18|  16.4k|    }
   19|       |
   20|  16.4k|    pub fn to_bytes(&self) -> [u8; 40] {
   21|  16.4k|        let mut buffer = [0; 40];
   22|  16.4k|        let mut stream = MutStreamAdapter::new(&mut buffer);
   23|  16.4k|        self.serialize(&mut stream);
   24|  16.4k|        buffer
   25|  16.4k|    }
   26|       |
   27|      0|    pub fn test_instance() -> Self {
   28|      0|        Self {
   29|      0|            height: 42,
   30|      0|            frontier: BlockHash::from(7),
   31|      0|        }
   32|      0|    }
   33|       |}
   34|       |
   35|       |impl Serialize for ConfirmationHeightInfo {
   36|  16.4k|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   37|  16.4k|        writer.write_u64_ne_safe(self.height);
   38|  16.4k|        self.frontier.serialize(writer);
   39|  16.4k|    }
   40|       |}
   41|       |
   42|       |impl FixedSizeSerialize for ConfirmationHeightInfo {
   43|      0|    fn serialized_size() -> usize {
   44|      0|        std::mem::size_of::<u64>() + BlockHash::serialized_size()
   45|      0|    }
   46|       |}
   47|       |
   48|       |impl Deserialize for ConfirmationHeightInfo {
   49|       |    type Target = Self;
   50|  49.3k|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self> {
   51|  49.3k|        let height = stream.read_u64_ne()?;
                                                       ^0
   52|  49.3k|        let frontier = BlockHash::deserialize(stream)?;
                                                                   ^0
   53|  49.3k|        Ok(Self { height, frontier })
   54|  49.3k|    }
   55|       |}

/home/gustav/code/nano/rsnano-node/core/src/difficulty.rs:
    1|       |use crate::Root;
    2|       |use blake2::{
    3|       |    digest::{Update, VariableOutput},
    4|       |    Blake2bVar,
    5|       |};
    6|       |use std::collections::HashMap;
    7|       |use std::mem::size_of;
    8|       |
    9|      0|#[derive(Clone, Copy, FromPrimitive, PartialEq, Eq)]
   10|       |pub enum WorkVersion {
   11|       |    Unspecified,
   12|       |    Work1,
   13|       |}
   14|       |
   15|       |impl WorkVersion {
   16|      0|    pub fn as_str(&self) -> &'static str {
   17|      0|        match self {
   18|      0|            WorkVersion::Work1 => "work_1",
   19|      0|            WorkVersion::Unspecified => "unspecified",
   20|       |        }
   21|      0|    }
   22|       |}
   23|       |
   24|       |impl TryFrom<u8> for WorkVersion {
   25|       |    type Error = anyhow::Error;
   26|       |
   27|      0|    fn try_from(value: u8) -> Result<Self, Self::Error> {
   28|      0|        match value {
   29|      0|            0 => Ok(WorkVersion::Unspecified),
   30|      0|            1 => Ok(WorkVersion::Work1),
   31|      0|            _ => Err(anyhow!("unknown work version")),
   32|       |        }
   33|      0|    }
   34|       |}
   35|       |
   36|       |pub trait Difficulty: Send + Sync {
   37|       |    fn get_difficulty(&self, root: &Root, work: u64) -> u64;
   38|       |    fn clone(&self) -> Box<dyn Difficulty>;
   39|       |}
   40|       |
   41|       |#[derive(Clone, Default)]
   42|       |pub struct DifficultyV1 {}
   43|       |impl DifficultyV1 {
   44|      0|    pub fn to_multiplier(difficulty: u64, base_difficulty: u64) -> f64 {
   45|      0|        debug_assert!(difficulty > 0);
   46|      0|        base_difficulty.wrapping_neg() as f64 / difficulty.wrapping_neg() as f64
   47|      0|    }
   48|       |
   49|      0|    pub fn from_multiplier(multiplier: f64, base_difficulty: u64) -> u64 {
   50|      0|        debug_assert!(multiplier > 0f64);
   51|      0|        let reverse_difficulty: u128 =
   52|      0|            ((base_difficulty.wrapping_neg() as f64) / multiplier) as u128;
   53|      0|        if reverse_difficulty > u64::MAX as u128 {
   54|      0|            0
   55|      0|        } else if reverse_difficulty != 0 || base_difficulty == 0 || multiplier < 1f64 {
   56|      0|            (reverse_difficulty as u64).wrapping_neg()
   57|       |        } else {
   58|      0|            u64::MAX
   59|       |        }
   60|      0|    }
   61|       |}
   62|       |
   63|       |impl Difficulty for DifficultyV1 {
   64|  28.9k|    fn get_difficulty(&self, root: &Root, work: u64) -> u64 {
   65|  28.9k|        let mut buffer = [0; size_of::<u64>()];
   66|  28.9k|        let mut hasher = Blake2bVar::new(buffer.len()).unwrap();
   67|  28.9k|        hasher.update(&work.to_le_bytes());
   68|  28.9k|        hasher.update(root.as_bytes());
   69|  28.9k|        hasher.finalize_variable(&mut buffer).unwrap();
   70|  28.9k|        u64::from_le_bytes(buffer)
   71|  28.9k|    }
   72|       |
   73|    185|    fn clone(&self) -> Box<dyn Difficulty> {
   74|    185|        Box::<DifficultyV1>::default()
   75|    185|    }
   76|       |}
   77|       |
   78|       |#[derive(Clone, Default)]
   79|       |pub struct StubDifficulty {
   80|       |    preset_difficulties: HashMap<(Root, u64), u64>,
   81|       |}
   82|       |
   83|       |impl StubDifficulty {
   84|      2|    pub fn new() -> Self {
   85|      2|        Self {
   86|      2|            preset_difficulties: HashMap::new(),
   87|      2|        }
   88|      2|    }
   89|       |
   90|      0|    pub fn set_difficulty(&mut self, root: Root, work: u64, difficulty: u64) {
   91|      0|        self.preset_difficulties.insert((root, work), difficulty);
   92|      0|    }
   93|       |}
   94|       |
   95|       |impl Difficulty for StubDifficulty {
   96|      1|    fn get_difficulty(&self, root: &Root, work: u64) -> u64 {
   97|      1|        self.preset_difficulties
   98|      1|            .get(&(*root, work))
   99|      1|            .cloned()
  100|      1|            .unwrap_or(work)
  101|      1|    }
  102|       |
  103|     25|    fn clone(&self) -> Box<dyn Difficulty> {
  104|     25|        Box::new(StubDifficulty {
  105|     25|            preset_difficulties: self.preset_difficulties.clone(),
  106|     25|        })
  107|     25|    }
  108|       |}
  109|       |
  110|       |#[cfg(test)]
  111|       |mod tests {
  112|       |    use super::*;
  113|       |    use crate::work::WorkThresholds;
  114|       |
  115|       |    #[test]
  116|       |    fn stub_difficulty() {
  117|       |        let mut difficulty = StubDifficulty::new();
  118|       |        assert_eq!(difficulty.get_difficulty(&Root::from(1), 2), 2);
  119|       |
  120|       |        difficulty.set_difficulty(Root::from(1), 2, 3);
  121|       |        assert_eq!(difficulty.get_difficulty(&Root::from(1), 2), 3);
  122|       |    }
  123|       |
  124|       |    #[test]
  125|       |    fn difficulty_for_root() {
  126|       |        let difficulty = DifficultyV1::default();
  127|       |        let result = difficulty.get_difficulty(&Root::from(123), 456);
  128|       |        assert_eq!(result, 10978371542656683347);
  129|       |    }
  130|       |
  131|       |    #[test]
  132|       |    fn multipliers_1() {
  133|       |        let base = 0xff000000_00000000_u64;
  134|       |        let difficulty = 0xfff27e7a_57c285cd_u64;
  135|       |        let expected_multiplier = 18.95461493377003_f64;
  136|       |
  137|       |        assert!(
  138|       |            (expected_multiplier - DifficultyV1::to_multiplier(difficulty, base)).abs() < 1e-10
  139|       |        );
  140|       |        assert_eq!(
  141|       |            difficulty,
  142|       |            DifficultyV1::from_multiplier(expected_multiplier, base)
  143|       |        );
  144|       |    }
  145|       |
  146|       |    #[test]
  147|       |    fn multipliers_2() {
  148|       |        let base = 0xffffffc0_00000000_u64;
  149|       |        let difficulty = 0xfffffe00_00000000_u64;
  150|       |        let expected_multiplier = 0.125_f64;
  151|       |
  152|       |        assert!(
  153|       |            (expected_multiplier - DifficultyV1::to_multiplier(difficulty, base)).abs() < 1e-10
  154|       |        );
  155|       |        assert_eq!(
  156|       |            difficulty,
  157|       |            DifficultyV1::from_multiplier(expected_multiplier, base)
  158|       |        );
  159|       |    }
  160|       |
  161|       |    #[test]
  162|       |    fn multipliers_3() {
  163|       |        let base = u64::MAX;
  164|       |        let difficulty = 0xffffffff_ffffff00_u64;
  165|       |        let expected_multiplier = 0.00390625_f64;
  166|       |
  167|       |        assert!((expected_multiplier - DifficultyV1::to_multiplier(difficulty, base)) < 1e-10);
  168|       |        assert_eq!(
  169|       |            difficulty,
  170|       |            DifficultyV1::from_multiplier(expected_multiplier, base)
  171|       |        );
  172|       |    }
  173|       |
  174|       |    #[test]
  175|       |    fn multipliers_4() {
  176|       |        let base = 0x80000000_00000000_u64;
  177|       |        let difficulty = 0xf0000000_00000000_u64;
  178|       |        let expected_multiplier = 8.0_f64;
  179|       |
  180|       |        assert!((expected_multiplier - DifficultyV1::to_multiplier(difficulty, base)) < 1e-10);
  181|       |        assert_eq!(
  182|       |            difficulty,
  183|       |            DifficultyV1::from_multiplier(expected_multiplier, base)
  184|       |        );
  185|       |    }
  186|       |
  187|       |    // The death checks don't fail on a release config, so guard against them
  188|       |    #[cfg(debug_assertions)]
  189|       |    #[test]
  190|       |    fn multipliers_nil() {
  191|       |        let base = 0xffffffc0_00000000_u64;
  192|       |        let difficulty_nil = 0_u64;
  193|       |        let multiplier_nil = 0_f64;
  194|       |
  195|       |        assert!(
  196|       |            std::panic::catch_unwind(|| { DifficultyV1::to_multiplier(difficulty_nil, base) })
  197|       |                .is_err()
  198|       |        );
  199|       |        assert!(std::panic::catch_unwind(|| {
  200|       |            DifficultyV1::from_multiplier(multiplier_nil, base)
  201|       |        })
  202|       |        .is_err());
  203|       |    }
  204|       |
  205|       |    #[test]
  206|       |    fn difficulty_overflow_max() {
  207|       |        // Overflow max (attempt to overflow & receive lower difficulty)
  208|       |
  209|       |        let base = u64::MAX; // Max possible difficulty
  210|       |        let difficulty = u64::MAX;
  211|       |        let multiplier = 1.001_f64; // Try to increase difficulty above max
  212|       |
  213|       |        assert_eq!(difficulty, DifficultyV1::from_multiplier(multiplier, base));
  214|       |    }
  215|       |
  216|       |    #[test]
  217|       |    fn difficulty_overflow_min() {
  218|       |        // Overflow min (attempt to overflow & receive higher difficulty)
  219|       |
  220|       |        let base = 1_u64; // Min possible difficulty before 0
  221|       |        let difficulty = 0_u64;
  222|       |        let multiplier = 0.999_f64; // Increase difficulty
  223|       |
  224|       |        assert_eq!(difficulty, DifficultyV1::from_multiplier(multiplier, base));
  225|       |    }
  226|       |
  227|       |    #[test]
  228|       |    fn difficulty_0_decrease() {
  229|       |        // Tests with base difficulty 0 should return 0 with any multiplier
  230|       |        let base = 0_u64; // Min possible difficulty
  231|       |        let difficulty = 0_u64;
  232|       |        let multiplier = 0.000000001_f64; // Decrease difficulty
  233|       |
  234|       |        assert_eq!(difficulty, DifficultyV1::from_multiplier(multiplier, base));
  235|       |    }
  236|       |
  237|       |    #[test]
  238|       |    fn difficulty_0_increase() {
  239|       |        let base = 0_u64; // Min possible difficulty
  240|       |        let difficulty = 0_u64;
  241|       |        let multiplier = 1000000000.0_f64; // Increase difficulty
  242|       |
  243|       |        assert_eq!(difficulty, DifficultyV1::from_multiplier(multiplier, base));
  244|       |    }
  245|       |
  246|       |    #[test]
  247|       |    fn network_multiplier() {
  248|       |        let full = WorkThresholds::publish_full();
  249|       |        let beta = WorkThresholds::publish_beta();
  250|       |        let dev = WorkThresholds::publish_dev();
  251|       |
  252|       |        let assert_multiplier = |difficulty: u64, base_difficulty: u64, expected: f64| {
  253|       |            let multi = DifficultyV1::to_multiplier(difficulty, base_difficulty);
  254|       |            assert!((multi - expected).abs() < 1e-10);
  255|       |        };
  256|       |
  257|       |        // live
  258|       |        assert_multiplier(full.epoch_2, full.epoch_1, 8.0);
  259|       |        assert_multiplier(full.epoch_2_receive, full.epoch_1, 1.0 / 8.0);
  260|       |        assert_multiplier(full.epoch_2_receive, full.entry, 1.0);
  261|       |        assert_multiplier(full.epoch_2, full.base, 1.0);
  262|       |
  263|       |        // beta
  264|       |        assert_multiplier(beta.epoch_1, full.epoch_1, 1.0 / 64.0);
  265|       |        assert_multiplier(beta.epoch_2, beta.epoch_1, 1.0);
  266|       |        assert_multiplier(beta.epoch_2_receive, beta.epoch_1, 1.0 / 2.0);
  267|       |        assert_multiplier(beta.epoch_2_receive, beta.entry, 1.0);
  268|       |        assert_multiplier(beta.epoch_2, beta.base, 1.0);
  269|       |
  270|       |        // dev
  271|       |        assert_multiplier(dev.epoch_2, dev.epoch_1, 8.0);
  272|       |        assert_multiplier(dev.epoch_2_receive, dev.epoch_1, 1.0 / 8.0);
  273|       |        assert_multiplier(dev.epoch_2_receive, dev.entry, 1.0);
  274|       |        assert_multiplier(dev.epoch_2, dev.base, 1.0);
  275|       |    }
  276|       |}

/home/gustav/code/nano/rsnano-node/core/src/epoch.rs:
    1|       |use crate::{Account, Block, Link, PrivateKey, PublicKey, DEV_GENESIS_KEY};
    2|       |use num_traits::FromPrimitive;
    3|       |use std::collections::HashMap;
    4|       |
    5|       |/**
    6|       | * Tag for which epoch an entry belongs to
    7|       | */
    8|       |
    9|       |#[repr(u8)]
   10|  98.6k|#[derive(PartialEq, Eq, Debug, Clone, Copy, FromPrimitive, Hash, Default, PartialOrd, Ord)]
   11|       |pub enum Epoch {
   12|       |    Invalid = 0,
   13|       |    #[default]
   14|       |    Unspecified = 1,
   15|       |    Epoch0 = 2,
   16|       |    Epoch1 = 3,
   17|       |    Epoch2 = 4,
   18|       |}
   19|       |
   20|       |impl Epoch {
   21|       |    pub const EPOCH_BEGIN: Epoch = Epoch::Epoch0;
   22|       |    pub const MAX: Epoch = Epoch::Epoch2;
   23|      0|    pub fn epoch_number(&self) -> u8 {
   24|      0|        match self {
   25|      0|            Epoch::Epoch1 => 1,
   26|      0|            Epoch::Epoch2 => 2,
   27|      0|            _ => 0,
   28|       |        }
   29|      0|    }
   30|       |}
   31|       |
   32|       |#[derive(Clone, Debug, PartialEq)]
   33|       |struct EpochInfo {
   34|       |    pub signer: PublicKey,
   35|       |    pub link: Link,
   36|       |}
   37|       |
   38|       |#[derive(Clone, Default, Debug, PartialEq)]
   39|       |pub struct Epochs {
   40|       |    epochs: HashMap<Epoch, EpochInfo>,
   41|       |}
   42|       |
   43|       |impl Epochs {
   44|     32|    pub fn new() -> Self {
   45|     32|        Default::default()
   46|     32|    }
   47|       |
   48|     64|    pub fn add(&mut self, epoch: Epoch, signer: PublicKey, link: Link) {
   49|     64|        self.epochs.insert(epoch, EpochInfo { signer, link });
   50|     64|    }
   51|       |
   52|       |    /// Returns true if link matches one of the released epoch links.
   53|       |    /// WARNING: just because a legal block contains an epoch link, it does not mean it is an epoch block.
   54|       |    /// A legal block containing an epoch link can easily be constructed by sending to an address identical
   55|       |    /// to one of the epoch links.
   56|       |    /// Epoch blocks follow the following rules and a block must satisfy them all to be a true epoch block:
   57|       |    ///     epoch blocks are always state blocks
   58|       |    ///     epoch blocks never change the balance of an account
   59|       |    ///     epoch blocks always have a link field that starts with the ascii bytes "epoch v1 block" or "epoch v2 block" (and possibly others in the future)
   60|       |    ///     epoch blocks never change the representative
   61|       |    ///     epoch blocks are not signed by the account key, they are signed either by genesis or by special epoch keys
   62|  16.9k|    pub fn is_epoch_link(&self, link: &Link) -> bool {
   63|  33.9k|        self.epochs.values().any(|x| &x.link == link)
   64|  16.9k|    }
   65|       |
   66|      0|    pub fn link(&self, epoch: Epoch) -> Option<&Link> {
   67|      0|        self.epochs.get(&epoch).map(|x| &x.link)
   68|      0|    }
   69|       |
   70|      0|    pub fn signer(&self, epoch: Epoch) -> Option<&PublicKey> {
   71|      0|        self.epochs.get(&epoch).map(|x| &x.signer)
   72|      0|    }
   73|       |
   74|      0|    pub fn epoch(&self, link: &Link) -> Option<Epoch> {
   75|      0|        for (k, v) in &self.epochs {
   76|      0|            if &v.link == link {
   77|      0|                return Some(*k);
   78|      0|            }
   79|       |        }
   80|       |
   81|      0|        None
   82|      0|    }
   83|       |
   84|       |    /// Checks that new_epoch is 1 version higher than epoch
   85|      0|    pub fn is_sequential(epoch: Epoch, new_epoch: Epoch) -> bool {
   86|      0|        // Currently assumes that the epoch versions in the enum are sequential.
   87|      0|        let epoch_id = epoch as u8;
   88|      0|        let new_epoch_id = new_epoch as u8;
   89|      0|        epoch_id >= Epoch::Epoch0 as u8 && new_epoch_id == epoch_id + 1
   90|      0|    }
   91|       |
   92|      0|    pub fn validate_epoch_signature(&self, block: &Block) -> anyhow::Result<()> {
   93|      0|        let epoch_signer: PublicKey = self
   94|      0|            .epoch_signer(&block.link_field().unwrap_or_default())
   95|      0|            .ok_or_else(|| anyhow!("not an epoch link!"))?
   96|      0|            .into();
   97|      0|
   98|      0|        epoch_signer.verify(block.hash().as_bytes(), block.signature())
   99|      0|    }
  100|       |
  101|      0|    pub fn epoch_signer(&self, link: &Link) -> Option<Account> {
  102|      0|        self.signer(self.epoch(link)?).map(|i| i.into())
  103|      0|    }
  104|       |}
  105|       |
  106|       |// Epoch is bit packed in BlockDetails. That's why it's max is limited to 4 bits
  107|       |const_assert!((Epoch::MAX as u8) < (1 << 5));
  108|       |
  109|       |impl TryFrom<u8> for Epoch {
  110|       |    type Error = anyhow::Error;
  111|       |
  112|      0|    fn try_from(value: u8) -> Result<Self, Self::Error> {
  113|      0|        FromPrimitive::from_u8(value).ok_or_else(|| anyhow!("invalid epoch value"))
  114|      0|    }
  115|       |}
  116|       |
  117|     34|pub fn epoch_v1_link() -> Link {
  118|     34|    let mut link_bytes = [0u8; 32];
  119|     34|    link_bytes[..14].copy_from_slice(b"epoch v1 block");
  120|     34|    Link::from_bytes(link_bytes)
  121|     34|}
  122|       |
  123|     34|pub fn epoch_v2_link() -> Link {
  124|     34|    let mut link_bytes = [0u8; 32];
  125|     34|    link_bytes[..14].copy_from_slice(b"epoch v2 block");
  126|     34|    Link::from_bytes(link_bytes)
  127|     34|}
  128|       |
  129|      0|pub fn dev_epoch1_signer() -> &'static PrivateKey {
  130|      0|    &DEV_GENESIS_KEY
  131|      0|}
  132|       |
  133|       |#[cfg(test)]
  134|       |mod tests {
  135|       |    use super::*;
  136|       |
  137|       |    #[test]
  138|       |    fn is_sequential() {
  139|       |        assert!(Epochs::is_sequential(Epoch::Epoch0, Epoch::Epoch1));
  140|       |        assert!(Epochs::is_sequential(Epoch::Epoch1, Epoch::Epoch2));
  141|       |
  142|       |        assert_eq!(Epochs::is_sequential(Epoch::Epoch0, Epoch::Epoch2), false);
  143|       |        assert_eq!(Epochs::is_sequential(Epoch::Epoch0, Epoch::Invalid), false);
  144|       |        assert_eq!(
  145|       |            Epochs::is_sequential(Epoch::Unspecified, Epoch::Epoch1),
  146|       |            false
  147|       |        );
  148|       |        assert_eq!(Epochs::is_sequential(Epoch::Epoch1, Epoch::Epoch0), false);
  149|       |        assert_eq!(Epochs::is_sequential(Epoch::Epoch2, Epoch::Epoch0), false);
  150|       |        assert_eq!(Epochs::is_sequential(Epoch::Epoch2, Epoch::Epoch2), false);
  151|       |    }
  152|       |
  153|       |    #[test]
  154|       |    fn epoch_link_empty() {
  155|       |        let epochs = Epochs::new();
  156|       |        let link = Link::from(42);
  157|       |        assert_eq!(epochs.is_epoch_link(&link), false);
  158|       |        assert_eq!(epochs.signer(Epoch::Epoch1), None);
  159|       |        assert_eq!(epochs.epoch(&link), None);
  160|       |        assert_eq!(epochs.link(Epoch::Epoch1), None);
  161|       |    }
  162|       |
  163|       |    #[test]
  164|       |    fn epoch_link_for_epoch1() {
  165|       |        let mut epochs = Epochs::new();
  166|       |        let link1 = Link::from(42);
  167|       |        let link2 = Link::from(43);
  168|       |        let epoch_key = PublicKey::from(100);
  169|       |
  170|       |        epochs.add(Epoch::Epoch1, epoch_key, link1);
  171|       |
  172|       |        assert_eq!(epochs.is_epoch_link(&link1), true);
  173|       |        assert_eq!(epochs.is_epoch_link(&link2), false);
  174|       |        assert_eq!(epochs.signer(Epoch::Epoch1), Some(&epoch_key));
  175|       |        assert_eq!(epochs.link(Epoch::Epoch1), Some(&link1));
  176|       |        assert_eq!(epochs.epoch(&link1), Some(Epoch::Epoch1));
  177|       |    }
  178|       |
  179|       |    #[test]
  180|       |    fn epoch_link_for_epoch2() {
  181|       |        let mut epochs = Epochs::new();
  182|       |        let link1 = Link::from(42);
  183|       |        let link2 = Link::from(43);
  184|       |        let epoch_key1 = PublicKey::from(100);
  185|       |        let epoch_key2 = PublicKey::from(200);
  186|       |
  187|       |        epochs.add(Epoch::Epoch1, epoch_key1, link1);
  188|       |        epochs.add(Epoch::Epoch2, epoch_key2, link2);
  189|       |
  190|       |        assert_eq!(epochs.is_epoch_link(&link2), true);
  191|       |        assert_eq!(epochs.signer(Epoch::Epoch2), Some(&epoch_key2));
  192|       |        assert_eq!(epochs.link(Epoch::Epoch2), Some(&link2));
  193|       |        assert_eq!(epochs.epoch(&link2), Some(Epoch::Epoch2));
  194|       |    }
  195|       |}

/home/gustav/code/nano/rsnano-node/core/src/kdf.rs:
    1|       |use crate::RawKey;
    2|       |use argon2::{Variant, Version};
    3|       |
    4|       |/// Key derivation function
    5|       |#[derive(Clone)]
    6|       |pub struct KeyDerivationFunction {
    7|       |    kdf_work: u32,
    8|       |}
    9|       |
   10|       |impl KeyDerivationFunction {
   11|      3|    pub fn new(kdf_work: u32) -> Self {
   12|      3|        Self { kdf_work }
   13|      3|    }
   14|       |
   15|      0|    pub fn hash_password(&self, password: &str, salt: &[u8; 32]) -> RawKey {
   16|      0|        let config = argon2::Config {
   17|      0|            hash_length: 32,
   18|      0|            lanes: 1,
   19|      0|            mem_cost: self.kdf_work,
   20|      0|            time_cost: 1,
   21|      0|            variant: Variant::Argon2d,
   22|      0|            version: Version::Version10,
   23|      0|            ..Default::default()
   24|      0|        };
   25|      0|
   26|      0|        let hash = argon2::hash_raw(password.as_bytes(), salt, &config).unwrap();
   27|      0|        RawKey::from_bytes(hash.as_slice().try_into().unwrap())
   28|      0|    }
   29|       |}

/home/gustav/code/nano/rsnano-node/core/src/lib.rs:
    1|       |#![allow(clippy::missing_safety_doc)]
    2|       |
    3|       |#[macro_use]
    4|       |extern crate anyhow;
    5|       |
    6|       |#[macro_use]
    7|       |extern crate num_derive;
    8|       |
    9|       |#[macro_use]
   10|       |extern crate static_assertions;
   11|       |
   12|       |mod account;
   13|       |mod amount;
   14|       |mod block_hash;
   15|       |mod node_id;
   16|       |mod public_key;
   17|       |mod vote;
   18|       |
   19|       |pub use account::Account;
   20|       |pub use amount::Amount;
   21|       |use blake2::{
   22|       |    digest::{Update, VariableOutput},
   23|       |    Blake2bVar,
   24|       |};
   25|       |pub use block_hash::{BlockHash, BlockHashBuilder};
   26|       |pub use node_id::NodeId;
   27|       |pub use public_key::PublicKey;
   28|       |use serde::de::{Unexpected, Visitor};
   29|       |pub use vote::*;
   30|       |
   31|       |mod private_key;
   32|       |pub use private_key::{PrivateKey, PrivateKeyFactory};
   33|       |
   34|       |mod raw_key;
   35|       |pub use raw_key::RawKey;
   36|       |
   37|       |mod signature;
   38|       |pub use signature::Signature;
   39|       |
   40|       |mod u256_struct;
   41|       |
   42|       |pub mod utils;
   43|       |
   44|       |mod qualified_root;
   45|       |pub use qualified_root::QualifiedRoot;
   46|       |
   47|       |mod account_info;
   48|       |pub use account_info::AccountInfo;
   49|       |
   50|       |mod epoch;
   51|       |pub use epoch::*;
   52|       |
   53|       |mod confirmation_height_info;
   54|       |pub use confirmation_height_info::ConfirmationHeightInfo;
   55|       |
   56|       |mod pending_key;
   57|       |pub use pending_key::PendingKey;
   58|       |
   59|       |mod pending_info;
   60|       |pub use pending_info::PendingInfo;
   61|       |
   62|       |mod difficulty;
   63|       |pub use difficulty::{Difficulty, DifficultyV1, StubDifficulty, WorkVersion};
   64|       |
   65|       |mod blocks;
   66|       |pub use blocks::*;
   67|       |
   68|       |pub mod work;
   69|       |
   70|       |mod unchecked_info;
   71|       |pub use unchecked_info::{UncheckedInfo, UncheckedKey};
   72|       |
   73|       |mod kdf;
   74|       |pub use kdf::KeyDerivationFunction;
   75|       |use utils::{BufferWriter, Deserialize, Serialize, Stream};
   76|       |
   77|       |use std::{
   78|       |    fmt::{Debug, Display, Write},
   79|       |    str::FromStr,
   80|       |    sync::Mutex,
   81|       |};
   82|       |use std::{num::ParseIntError, sync::LazyLock};
   83|       |
   84|      0|pub fn encode_hex(i: u128) -> String {
   85|      0|    let mut result = String::with_capacity(32);
   86|      0|    for byte in i.to_be_bytes() {
   87|      0|        write!(&mut result, "{:02X}", byte).unwrap();
   88|      0|    }
   89|      0|    result
   90|      0|}
   91|       |
   92|      4|pub fn write_hex_bytes(bytes: &[u8], f: &mut std::fmt::Formatter) -> Result<(), std::fmt::Error> {
   93|    132|    for &byte in bytes {
                       ^128
   94|    128|        write!(f, "{:02X}", byte)?;
                                               ^0
   95|       |    }
   96|      4|    Ok(())
   97|      4|}
   98|       |
   99|      0|pub fn to_hex_string(i: u64) -> String {
  100|      0|    format!("{:016X}", i)
  101|      0|}
  102|       |
  103|      0|pub fn u64_from_hex_str(s: impl AsRef<str>) -> Result<u64, ParseIntError> {
  104|      0|    u64::from_str_radix(s.as_ref(), 16)
  105|      0|}
  106|       |
  107|       |u256_struct!(HashOrAccount);
  108|       |serialize_32_byte_string!(HashOrAccount);
  109|       |u256_struct!(Link);
  110|       |serialize_32_byte_string!(Link);
  111|       |u256_struct!(Root);
  112|       |serialize_32_byte_string!(Root);
  113|       |u256_struct!(WalletId);
  114|       |serialize_32_byte_string!(WalletId);
  115|       |
  116|       |impl WalletId {
  117|      0|    pub fn random() -> Self {
  118|      0|        let key = PrivateKey::new();
  119|      0|        Self::from_bytes(*key.public_key().as_bytes())
  120|      0|    }
  121|       |}
  122|       |
  123|       |impl From<HashOrAccount> for Account {
  124|      0|    fn from(source: HashOrAccount) -> Self {
  125|      0|        Account::from_bytes(*source.as_bytes())
  126|      0|    }
  127|       |}
  128|       |
  129|       |impl From<&HashOrAccount> for Account {
  130|      0|    fn from(source: &HashOrAccount) -> Self {
  131|      0|        Account::from_bytes(*source.as_bytes())
  132|      0|    }
  133|       |}
  134|       |
  135|       |impl From<Link> for Account {
  136|     32|    fn from(link: Link) -> Self {
  137|     32|        Account::from_bytes(*link.as_bytes())
  138|     32|    }
  139|       |}
  140|       |
  141|       |impl From<&Link> for Account {
  142|      0|    fn from(link: &Link) -> Self {
  143|      0|        Account::from_bytes(*link.as_bytes())
  144|      0|    }
  145|       |}
  146|       |
  147|       |impl From<Root> for Account {
  148|      0|    fn from(root: Root) -> Self {
  149|      0|        Account::from_bytes(*root.as_bytes())
  150|      0|    }
  151|       |}
  152|       |
  153|       |impl From<Account> for Link {
  154|     28|    fn from(account: Account) -> Self {
  155|     28|        Link::from_bytes(*account.as_bytes())
  156|     28|    }
  157|       |}
  158|       |
  159|       |impl From<&Account> for Link {
  160|      0|    fn from(account: &Account) -> Self {
  161|      0|        Link::from_bytes(*account.as_bytes())
  162|      0|    }
  163|       |}
  164|       |
  165|       |impl From<BlockHash> for Link {
  166|      4|    fn from(hash: BlockHash) -> Self {
  167|      4|        Link::from_bytes(*hash.as_bytes())
  168|      4|    }
  169|       |}
  170|       |
  171|       |impl From<HashOrAccount> for BlockHash {
  172|      0|    fn from(source: HashOrAccount) -> Self {
  173|      0|        BlockHash::from_bytes(*source.as_bytes())
  174|      0|    }
  175|       |}
  176|       |
  177|       |impl From<&HashOrAccount> for BlockHash {
  178|      0|    fn from(source: &HashOrAccount) -> Self {
  179|      0|        BlockHash::from_bytes(*source.as_bytes())
  180|      0|    }
  181|       |}
  182|       |impl From<Link> for BlockHash {
  183|  16.4k|    fn from(link: Link) -> Self {
  184|  16.4k|        BlockHash::from_bytes(*link.as_bytes())
  185|  16.4k|    }
  186|       |}
  187|       |
  188|       |impl From<Root> for BlockHash {
  189|      0|    fn from(root: Root) -> Self {
  190|      0|        BlockHash::from_bytes(*root.as_bytes())
  191|      0|    }
  192|       |}
  193|       |
  194|       |impl From<Account> for HashOrAccount {
  195|      0|    fn from(account: Account) -> Self {
  196|      0|        HashOrAccount::from_bytes(*account.as_bytes())
  197|      0|    }
  198|       |}
  199|       |
  200|       |impl From<&BlockHash> for HashOrAccount {
  201|      0|    fn from(hash: &BlockHash) -> Self {
  202|      0|        HashOrAccount::from_bytes(*hash.as_bytes())
  203|      0|    }
  204|       |}
  205|       |
  206|       |impl From<BlockHash> for HashOrAccount {
  207|      0|    fn from(hash: BlockHash) -> Self {
  208|      0|        HashOrAccount::from_bytes(*hash.as_bytes())
  209|      0|    }
  210|       |}
  211|       |
  212|       |impl From<Link> for HashOrAccount {
  213|      0|    fn from(link: Link) -> Self {
  214|      0|        HashOrAccount::from_bytes(*link.as_bytes())
  215|      0|    }
  216|       |}
  217|       |
  218|       |impl From<&Link> for HashOrAccount {
  219|      0|    fn from(link: &Link) -> Self {
  220|      0|        HashOrAccount::from_bytes(*link.as_bytes())
  221|      0|    }
  222|       |}
  223|       |
  224|       |impl From<Account> for Root {
  225|     12|    fn from(key: Account) -> Self {
  226|     12|        Root::from_bytes(*key.as_bytes())
  227|     12|    }
  228|       |}
  229|       |
  230|       |impl From<&PublicKey> for Root {
  231|      0|    fn from(key: &PublicKey) -> Self {
  232|      0|        Root::from_bytes(*key.as_bytes())
  233|      0|    }
  234|       |}
  235|       |
  236|       |impl From<PublicKey> for Root {
  237|      0|    fn from(key: PublicKey) -> Self {
  238|      0|        Root::from_bytes(*key.as_bytes())
  239|      0|    }
  240|       |}
  241|       |
  242|       |impl From<&Account> for Root {
  243|      0|    fn from(hash: &Account) -> Self {
  244|      0|        Root::from_bytes(*hash.as_bytes())
  245|      0|    }
  246|       |}
  247|       |
  248|       |impl From<BlockHash> for Root {
  249|     58|    fn from(hash: BlockHash) -> Self {
  250|     58|        Root::from_bytes(*hash.as_bytes())
  251|     58|    }
  252|       |}
  253|       |
  254|       |impl From<&BlockHash> for Root {
  255|      0|    fn from(hash: &BlockHash) -> Self {
  256|      0|        Root::from_bytes(*hash.as_bytes())
  257|      0|    }
  258|       |}
  259|       |
  260|       |pub trait FullHash {
  261|       |    /// Generates a hash that includes the signature an PoW field
  262|       |    fn full_hash(&self) -> BlockHash;
  263|       |}
  264|       |
  265|       |#[derive(PartialEq, Eq, Debug, Copy, Clone, PartialOrd, Ord)]
  266|       |pub struct NoValue {}
  267|       |
  268|       |impl utils::FixedSizeSerialize for NoValue {
  269|      0|    fn serialized_size() -> usize {
  270|      0|        0
  271|      0|    }
  272|       |}
  273|       |
  274|       |impl utils::Serialize for NoValue {
  275|      0|    fn serialize(&self, _writer: &mut dyn BufferWriter) {}
  276|       |}
  277|       |
  278|       |impl utils::Deserialize for NoValue {
  279|       |    type Target = Self;
  280|      0|    fn deserialize(_stream: &mut dyn utils::Stream) -> anyhow::Result<NoValue> {
  281|      0|        Ok(NoValue {})
  282|      0|    }
  283|       |}
  284|       |
  285|      0|pub fn deterministic_key(seed: &RawKey, index: u32) -> RawKey {
  286|      0|    let mut buffer = [0; 32];
  287|      0|    let mut hasher = Blake2bVar::new(buffer.len()).unwrap();
  288|      0|    hasher.update(seed.as_bytes());
  289|      0|    hasher.update(&index.to_be_bytes());
  290|      0|    hasher.finalize_variable(&mut buffer).unwrap();
  291|      0|    RawKey::from_bytes(buffer)
  292|      0|}
  293|       |
  294|       |/**
  295|       | * Network variants with different genesis blocks and network parameters
  296|       | */
  297|       |#[repr(u16)]
  298|      0|#[derive(Clone, Copy, FromPrimitive, PartialEq, Eq, Debug)]
  299|       |pub enum Networks {
  300|       |    Invalid = 0x0,
  301|       |    // Low work parameters, publicly known genesis key, dev IP ports
  302|       |    NanoDevNetwork = 0x5241, // 'R', 'A'
  303|       |    // Normal work parameters, secret beta genesis key, beta IP ports
  304|       |    NanoBetaNetwork = 0x5242, // 'R', 'B'
  305|       |    // Normal work parameters, secret live key, live IP ports
  306|       |    NanoLiveNetwork = 0x5243, // 'R', 'C'
  307|       |    // Normal work parameters, secret test genesis key, test IP ports
  308|       |    NanoTestNetwork = 0x5258, // 'R', 'X'
  309|       |}
  310|       |
  311|       |impl Networks {
  312|      0|    pub fn as_str(&self) -> &str {
  313|      0|        match self {
  314|      0|            Networks::Invalid => "invalid",
  315|      0|            Networks::NanoDevNetwork => "dev",
  316|      0|            Networks::NanoBetaNetwork => "beta",
  317|      0|            Networks::NanoLiveNetwork => "live",
  318|      0|            Networks::NanoTestNetwork => "test",
  319|       |        }
  320|      0|    }
  321|       |}
  322|       |
  323|       |impl FromStr for Networks {
  324|       |    type Err = &'static str;
  325|       |
  326|      0|    fn from_str(s: &str) -> Result<Networks, Self::Err> {
  327|      0|        match s {
  328|      0|            "dev" => Ok(Networks::NanoDevNetwork),
  329|      0|            "beta" => Ok(Networks::NanoBetaNetwork),
  330|      0|            "live" => Ok(Networks::NanoLiveNetwork),
  331|      0|            "test" => Ok(Networks::NanoTestNetwork),
  332|      0|            _ => Err("Invalid network"),
  333|       |        }
  334|      0|    }
  335|       |}
  336|       |//
  337|       |//todo: make configurable in builld script again!
  338|       |pub static ACTIVE_NETWORK: LazyLock<Mutex<Networks>> =
  339|      0|    LazyLock::new(|| Mutex::new(Networks::NanoBetaNetwork));
  340|       |
  341|       |#[derive(PartialEq, Eq, Debug, Default, Clone)]
  342|       |pub struct Frontier {
  343|       |    pub account: Account,
  344|       |    pub hash: BlockHash,
  345|       |}
  346|       |
  347|       |impl Frontier {
  348|     15|    pub fn new(account: Account, hash: BlockHash) -> Self {
  349|     15|        Self { account, hash }
  350|     15|    }
  351|       |}
  352|       |
  353|       |impl Frontier {
  354|      0|    pub fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self> {
  355|      0|        let account = Account::deserialize(stream)?;
  356|      0|        let hash = BlockHash::deserialize(stream)?;
  357|      0|        Ok(Self::new(account, hash))
  358|      0|    }
  359|       |}
  360|       |
  361|       |impl Serialize for Frontier {
  362|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  363|      0|        self.account.serialize(stream);
  364|      0|        self.hash.serialize(stream);
  365|      0|    }
  366|       |}
  367|       |
  368|       |#[derive(PartialEq, Eq, Copy, Clone, PartialOrd, Ord, Default)]
  369|       |pub struct WorkNonce(u64);
  370|       |
  371|       |impl Display for WorkNonce {
  372|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  373|      0|        write!(f, "{:016X}", self.0)
  374|      0|    }
  375|       |}
  376|       |
  377|       |impl Debug for WorkNonce {
  378|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  379|      0|        std::fmt::Display::fmt(&self, f)
  380|      0|    }
  381|       |}
  382|       |
  383|       |impl From<u64> for WorkNonce {
  384|      0|    fn from(value: u64) -> Self {
  385|      0|        Self(value)
  386|      0|    }
  387|       |}
  388|       |
  389|       |impl From<WorkNonce> for u64 {
  390|    129|    fn from(value: WorkNonce) -> Self {
  391|    129|        value.0
  392|    129|    }
  393|       |}
  394|       |
  395|       |impl serde::Serialize for WorkNonce {
  396|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
  397|      0|    where
  398|      0|        S: serde::Serializer,
  399|      0|    {
  400|      0|        serializer.serialize_str(&to_hex_string(self.0))
  401|      0|    }
  402|       |}
  403|       |
  404|       |impl<'de> serde::Deserialize<'de> for WorkNonce {
  405|    129|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
  406|    129|    where
  407|    129|        D: serde::Deserializer<'de>,
  408|    129|    {
  409|    129|        let value = deserializer.deserialize_str(WorkNonceVisitor {})?;
                                                                                   ^0
  410|    129|        Ok(value)
  411|    129|    }
  412|       |}
  413|       |
  414|       |struct WorkNonceVisitor {}
  415|       |
  416|       |impl<'de> Visitor<'de> for WorkNonceVisitor {
  417|       |    type Value = WorkNonce;
  418|       |
  419|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
  420|      0|        formatter.write_str("a hex string containing 8 bytes")
  421|      0|    }
  422|       |
  423|    129|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  424|    129|    where
  425|    129|        E: serde::de::Error,
  426|    129|    {
  427|    129|        let mut bytes = [0; 8];
  428|    129|        hex::decode_to_slice(v, &mut bytes).map_err(|_| {
  429|      0|            serde::de::Error::invalid_value(Unexpected::Str(v), &"a hex string containing 8 bytes")
  430|    129|        })?;
                        ^0
  431|    129|        Ok(WorkNonce(u64::from_be_bytes(bytes)))
  432|    129|    }
  433|       |}
  434|       |
  435|       |#[cfg(test)]
  436|       |mod tests {
  437|       |    use super::*;
  438|       |
  439|       |    #[test]
  440|       |    fn test_deterministic_key() {
  441|       |        let seed = RawKey::from(1);
  442|       |        let key = deterministic_key(&seed, 3);
  443|       |        assert_eq!(
  444|       |            key,
  445|       |            RawKey::decode_hex("89A518E3B70A0843DE8470F87FF851F9C980B1B2802267A05A089677B8FA1926")
  446|       |                .unwrap()
  447|       |        );
  448|       |    }
  449|       |
  450|       |    #[test]
  451|       |    fn serialize_work_nonce() {
  452|       |        let serialized = serde_json::to_string(&WorkNonce::from(123)).unwrap();
  453|       |        assert_eq!(serialized, "\"000000000000007B\"");
  454|       |    }
  455|       |}

/home/gustav/code/nano/rsnano-node/core/src/node_id.rs:
    1|       |use crate::{Account, PrivateKey, PublicKey};
    2|       |use serde::de::{Unexpected, Visitor};
    3|       |use std::{fmt::Display, str::FromStr};
    4|       |
    5|       |#[derive(PartialEq, Eq, Clone, Copy, Hash, Default, PartialOrd, Ord)]
    6|       |pub struct NodeId([u8; 32]);
    7|       |
    8|       |impl NodeId {
    9|       |    pub const ZERO: Self = NodeId::from_bytes([0; 32]);
   10|       |
   11|      3|    pub const fn from_bytes(bytes: [u8; 32]) -> Self {
   12|      3|        Self(bytes)
   13|      3|    }
   14|       |
   15|      3|    pub const fn as_key(&self) -> PublicKey {
   16|      3|        PublicKey::from_bytes(self.0)
   17|      3|    }
   18|       |}
   19|       |
   20|       |impl From<i32> for NodeId {
   21|      0|    fn from(value: i32) -> Self {
   22|      0|        let mut bytes = [0; 32];
   23|      0|        bytes[28..].copy_from_slice(&value.to_be_bytes());
   24|      0|        Self::from_bytes(bytes)
   25|      0|    }
   26|       |}
   27|       |
   28|       |impl From<u64> for NodeId {
   29|      0|    fn from(value: u64) -> Self {
   30|      0|        let mut bytes = [0; 32];
   31|      0|        bytes[24..].copy_from_slice(&value.to_be_bytes());
   32|      0|        Self::from_bytes(bytes)
   33|      0|    }
   34|       |}
   35|       |
   36|       |impl From<u128> for NodeId {
   37|      0|    fn from(value: u128) -> Self {
   38|      0|        let mut bytes = [0; 32];
   39|      0|        bytes[16..].copy_from_slice(&value.to_be_bytes());
   40|      0|        Self::from_bytes(bytes)
   41|      0|    }
   42|       |}
   43|       |
   44|       |impl Display for NodeId {
   45|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   46|      0|        let mut result = Account::from_bytes(self.0).encode_account();
   47|      0|        result.replace_range(0..4, "node");
   48|      0|        write!(f, "{}", result)
   49|      0|    }
   50|       |}
   51|       |
   52|       |impl std::fmt::Debug for NodeId {
   53|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   54|      0|        std::fmt::Display::fmt(&self, f)
   55|      0|    }
   56|       |}
   57|       |
   58|       |impl FromStr for NodeId {
   59|       |    type Err = anyhow::Error;
   60|       |
   61|      0|    fn from_str(s: &str) -> Result<Self, Self::Err> {
   62|      0|        let mut node_id = s.to_string();
   63|      0|        if node_id.starts_with("node_") {
   64|      0|            node_id.replace_range(0..5, "nano_");
   65|      0|            let account = Account::decode_account(node_id)?;
   66|      0|            Ok(Self::from_bytes(*account.as_bytes()))
   67|       |        } else {
   68|      0|            bail!("Invalid node ID format")
   69|       |        }
   70|      0|    }
   71|       |}
   72|       |
   73|       |impl crate::utils::Serialize for NodeId {
   74|      3|    fn serialize(&self, writer: &mut dyn crate::utils::BufferWriter) {
   75|      3|        writer.write_bytes_safe(&self.0)
   76|      3|    }
   77|       |}
   78|       |
   79|       |impl crate::utils::Deserialize for NodeId {
   80|       |    type Target = Self;
   81|      0|    fn deserialize(stream: &mut dyn crate::utils::Stream) -> anyhow::Result<Self> {
   82|      0|        let mut result = Self::ZERO;
   83|      0|        stream.read_bytes(&mut result.0, 32)?;
   84|      0|        Ok(result)
   85|      0|    }
   86|       |}
   87|       |
   88|       |impl serde::Serialize for NodeId {
   89|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
   90|      0|    where
   91|      0|        S: serde::Serializer,
   92|      0|    {
   93|      0|        serializer.serialize_str(&self.to_string())
   94|      0|    }
   95|       |}
   96|       |
   97|       |impl<'de> serde::Deserialize<'de> for NodeId {
   98|      0|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
   99|      0|    where
  100|      0|        D: serde::Deserializer<'de>,
  101|      0|    {
  102|      0|        let value = deserializer.deserialize_str(NodeIdVisitor {})?;
  103|      0|        Ok(value)
  104|      0|    }
  105|       |}
  106|       |
  107|       |struct NodeIdVisitor {}
  108|       |
  109|       |impl<'de> Visitor<'de> for NodeIdVisitor {
  110|       |    type Value = NodeId;
  111|       |
  112|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
  113|      0|        formatter.write_str("a node ID in the form \"node_...\"")
  114|      0|    }
  115|       |
  116|      0|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  117|      0|    where
  118|      0|        E: serde::de::Error,
  119|      0|    {
  120|      0|        v.parse::<NodeId>().map_err(|_| {
  121|      0|            serde::de::Error::invalid_value(
  122|      0|                Unexpected::Str(v),
  123|      0|                &"a node ID in the form \"node_...\"",
  124|      0|            )
  125|      0|        })
  126|      0|    }
  127|       |}
  128|       |
  129|       |impl From<NodeId> for PublicKey {
  130|      3|    fn from(value: NodeId) -> Self {
  131|      3|        value.as_key()
  132|      3|    }
  133|       |}
  134|       |
  135|       |impl From<PublicKey> for NodeId {
  136|      3|    fn from(value: PublicKey) -> Self {
  137|      3|        Self::from_bytes(*value.as_bytes())
  138|      3|    }
  139|       |}
  140|       |
  141|       |impl From<&PrivateKey> for NodeId {
  142|      0|    fn from(value: &PrivateKey) -> Self {
  143|      0|        value.public_key().into()
  144|      0|    }
  145|       |}
  146|       |
  147|       |#[cfg(test)]
  148|       |mod tests {
  149|       |    use super::*;
  150|       |
  151|       |    #[test]
  152|       |    fn to_string() {
  153|       |        assert_eq!(
  154|       |            NodeId::from(123).to_string(),
  155|       |            "node_111111111111111111111111111111111111111111111111115uwdgas549"
  156|       |        );
  157|       |    }
  158|       |
  159|       |    #[test]
  160|       |    fn parse() {
  161|       |        assert_eq!(
  162|       |            "node_111111111111111111111111111111111111111111111111115uwdgas549"
  163|       |                .parse::<NodeId>()
  164|       |                .unwrap(),
  165|       |            NodeId::from(123),
  166|       |        );
  167|       |    }
  168|       |
  169|       |    #[test]
  170|       |    fn parse_fails() {
  171|       |        let err = "invalid".parse::<NodeId>().unwrap_err();
  172|       |        assert_eq!(err.to_string(), "Invalid node ID format");
  173|       |    }
  174|       |
  175|       |    #[test]
  176|       |    fn json_serialize() {
  177|       |        let json = serde_json::to_string(&NodeId::from(123)).unwrap();
  178|       |        assert_eq!(
  179|       |            json,
  180|       |            "\"node_111111111111111111111111111111111111111111111111115uwdgas549\""
  181|       |        )
  182|       |    }
  183|       |
  184|       |    #[test]
  185|       |    fn json_deserialize() {
  186|       |        let json = "\"node_111111111111111111111111111111111111111111111111115uwdgas549\"";
  187|       |        assert_eq!(
  188|       |            serde_json::from_str::<NodeId>(&json).unwrap(),
  189|       |            NodeId::from(123)
  190|       |        );
  191|       |    }
  192|       |
  193|       |    #[test]
  194|       |    fn json_deserialize_error() {
  195|       |        let json = "\"invalid\"";
  196|       |        let error = serde_json::from_str::<NodeId>(&json).unwrap_err();
  197|       |        assert!(error
  198|       |            .to_string()
  199|       |            .contains("a node ID in the form \"node_...\""));
  200|       |    }
  201|       |}

/home/gustav/code/nano/rsnano-node/core/src/pending_info.rs:
    1|       |use crate::{
    2|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    3|       |    Account, Amount, Epoch,
    4|       |};
    5|       |use num::FromPrimitive;
    6|       |use std::mem::size_of;
    7|       |
    8|       |/// Information on an uncollected send
    9|       |/// This struct captures the data stored in a pending table entry
   10|       |#[derive(PartialEq, Eq, Debug, Clone)]
   11|       |pub struct PendingInfo {
   12|       |    /// The account sending the funds
   13|       |    pub source: Account,
   14|       |    /// Amount receivable in this transaction
   15|       |    pub amount: Amount,
   16|       |    /// Epoch of sending block, this info is stored here to make it possible to prune the send block
   17|       |    pub epoch: Epoch,
   18|       |}
   19|       |
   20|       |impl Default for PendingInfo {
   21|      0|    fn default() -> Self {
   22|      0|        Self {
   23|      0|            source: Default::default(),
   24|      0|            amount: Default::default(),
   25|      0|            epoch: Epoch::Epoch0,
   26|      0|        }
   27|      0|    }
   28|       |}
   29|       |
   30|       |impl PendingInfo {
   31|     28|    pub fn new(source: Account, amount: Amount, epoch: Epoch) -> Self {
   32|     28|        Self {
   33|     28|            source,
   34|     28|            amount,
   35|     28|            epoch,
   36|     28|        }
   37|     28|    }
   38|       |
   39|     28|    pub fn to_bytes(&self) -> [u8; 49] {
   40|     28|        let mut bytes = [0; 49];
   41|     28|        bytes[..32].copy_from_slice(self.source.as_bytes());
   42|     28|        bytes[32..48].copy_from_slice(&self.amount.to_be_bytes());
   43|     28|        bytes[48] = self.epoch as u8;
   44|     28|        bytes
   45|     28|    }
   46|       |
   47|      0|    pub fn new_test_instance() -> Self {
   48|      0|        Self::new(Account::from(3), Amount::raw(4), Epoch::Epoch2)
   49|      0|    }
   50|       |}
   51|       |
   52|       |impl Serialize for PendingInfo {
   53|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   54|      0|        self.source.serialize(stream);
   55|      0|        self.amount.serialize(stream);
   56|      0|        stream.write_u8_safe(self.epoch as u8);
   57|      0|    }
   58|       |}
   59|       |
   60|       |impl FixedSizeSerialize for PendingInfo {
   61|      0|    fn serialized_size() -> usize {
   62|      0|        Account::serialized_size() + Amount::serialized_size() + size_of::<u8>()
   63|      0|    }
   64|       |}
   65|       |
   66|       |impl Deserialize for PendingInfo {
   67|       |    type Target = Self;
   68|       |
   69|     38|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   70|     38|        let source = Account::deserialize(stream)?;
                                                               ^0
   71|     38|        let amount = Amount::deserialize(stream)?;
                                                              ^0
   72|     38|        let epoch =
   73|     38|            FromPrimitive::from_u8(stream.read_u8()?).ok_or_else(|| anyhow!("invalid epoch"))?;
                                                                 ^0               ^0                       ^0
   74|     38|        Ok(Self {
   75|     38|            source,
   76|     38|            amount,
   77|     38|            epoch,
   78|     38|        })
   79|     38|    }
   80|       |}

/home/gustav/code/nano/rsnano-node/core/src/pending_key.rs:
    1|       |use crate::{
    2|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    3|       |    Account, Block, BlockHash,
    4|       |};
    5|       |use primitive_types::U512;
    6|       |
    7|       |/// This struct represents the data written into the pending (receivable) database table key
    8|       |/// the receiving account and hash of the send block identify a pending db table entry
    9|       |#[derive(Default, PartialEq, Eq, Debug, Clone, Hash, Ord, Copy)]
   10|       |pub struct PendingKey {
   11|       |    pub receiving_account: Account,
   12|       |    pub send_block_hash: BlockHash,
   13|       |}
   14|       |
   15|       |impl PendingKey {
   16|    134|    pub fn new(receiving_account: Account, send_block_hash: BlockHash) -> Self {
   17|    134|        Self {
   18|    134|            receiving_account,
   19|    134|            send_block_hash,
   20|    134|        }
   21|    134|    }
   22|       |
   23|     64|    pub fn to_bytes(&self) -> [u8; 64] {
   24|     64|        let mut result = [0; 64];
   25|     64|        result[..32].copy_from_slice(self.receiving_account.as_bytes());
   26|     64|        result[32..].copy_from_slice(self.send_block_hash.as_bytes());
   27|     64|        result
   28|     64|    }
   29|       |
   30|     28|    pub fn for_send_block(block: &Block) -> Self {
   31|     28|        Self::new(block.link_field().unwrap_or_default().into(), block.hash())
   32|     28|    }
   33|       |
   34|      0|    pub fn for_receive_block(block: &Block) -> Self {
   35|      0|        Self::new(
   36|      0|            block.account_field().unwrap(),
   37|      0|            block.link_field().unwrap_or_default().into(),
   38|      0|        )
   39|      0|    }
   40|       |
   41|      0|    pub fn new_test_instance() -> Self {
   42|      0|        Self::new(Account::from(1), BlockHash::from(2))
   43|      0|    }
   44|       |}
   45|       |
   46|       |impl Serialize for PendingKey {
   47|     38|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   48|     38|        self.receiving_account.serialize(writer);
   49|     38|        self.send_block_hash.serialize(writer);
   50|     38|    }
   51|       |}
   52|       |
   53|       |impl FixedSizeSerialize for PendingKey {
   54|      0|    fn serialized_size() -> usize {
   55|      0|        Account::serialized_size() + BlockHash::serialized_size()
   56|      0|    }
   57|       |}
   58|       |
   59|       |impl Deserialize for PendingKey {
   60|       |    type Target = Self;
   61|       |
   62|     34|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   63|     34|        let account = Account::deserialize(stream)?;
                                                                ^0
   64|     34|        let hash = BlockHash::deserialize(stream)?;
                                                               ^0
   65|     34|        Ok(Self {
   66|     34|            receiving_account: account,
   67|     34|            send_block_hash: hash,
   68|     34|        })
   69|     34|    }
   70|       |}
   71|       |
   72|       |impl From<U512> for PendingKey {
   73|      0|    fn from(value: U512) -> Self {
   74|      0|        let buffer = value.to_big_endian();
   75|      0|        PendingKey::new(
   76|      0|            Account::from_slice(&buffer[..32]).unwrap(),
   77|      0|            BlockHash::from_slice(&buffer[32..]).unwrap(),
   78|      0|        )
   79|      0|    }
   80|       |}
   81|       |
   82|       |impl PartialOrd for PendingKey {
   83|      0|    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
   84|      0|        if self.receiving_account == other.receiving_account {
   85|      0|            self.send_block_hash.partial_cmp(&other.send_block_hash)
   86|       |        } else {
   87|      0|            self.receiving_account.partial_cmp(&other.receiving_account)
   88|       |        }
   89|      0|    }
   90|       |}
   91|       |
   92|       |#[cfg(test)]
   93|       |mod tests {
   94|       |    use crate::PendingKey;
   95|       |
   96|       |    #[test]
   97|       |    fn pending_key_sorting() {
   98|       |        let one = PendingKey::new(1.into(), 2.into());
   99|       |        let one_same = PendingKey::new(1.into(), 2.into());
  100|       |        let two = PendingKey::new(1.into(), 3.into());
  101|       |        let three = PendingKey::new(2.into(), 1.into());
  102|       |        assert!(one < two);
  103|       |        assert!(one < three);
  104|       |        assert!(two < three);
  105|       |        assert!(one == one_same);
  106|       |        assert!(one != two);
  107|       |    }
  108|       |}

/home/gustav/code/nano/rsnano-node/core/src/private_key.rs:
    1|       |use super::{PublicKey, RawKey, Signature};
    2|       |use crate::{Account, Link, Root};
    3|       |use anyhow::Context;
    4|       |use ed25519_dalek::ed25519::signature::SignerMut;
    5|       |use rsnano_nullable_random::NullableRng;
    6|       |
    7|       |pub struct PrivateKeyFactory {
    8|       |    rng: NullableRng,
    9|       |}
   10|       |
   11|       |impl PrivateKeyFactory {
   12|       |    #[allow(dead_code)]
   13|      0|    fn new(rng: NullableRng) -> Self {
   14|      0|        Self { rng }
   15|      0|    }
   16|       |
   17|      7|    pub fn new_null() -> Self {
   18|      7|        Self {
   19|      7|            rng: NullableRng::new_null(),
   20|      7|        }
   21|      7|    }
   22|       |
   23|      3|    pub fn new_null_with(prv: RawKey) -> Self {
   24|      3|        Self {
   25|      3|            rng: NullableRng::new_null_bytes(prv.as_bytes()),
   26|      3|        }
   27|      3|    }
   28|       |
   29|     49|    pub fn create_key(&mut self) -> PrivateKey {
   30|     49|        let private_key = ed25519_dalek::SigningKey::generate(&mut self.rng);
   31|     49|        PrivateKey { private_key }
   32|     49|    }
   33|       |}
   34|       |
   35|       |impl Default for PrivateKeyFactory {
   36|     45|    fn default() -> Self {
   37|     45|        Self {
   38|     45|            rng: NullableRng::thread_rng(),
   39|     45|        }
   40|     45|    }
   41|       |}
   42|       |
   43|       |#[derive(Clone)]
   44|       |pub struct PrivateKey {
   45|       |    private_key: ed25519_dalek::SigningKey,
   46|       |}
   47|       |
   48|       |impl Default for PrivateKey {
   49|     42|    fn default() -> Self {
   50|     42|        PrivateKeyFactory::default().create_key()
   51|     42|    }
   52|       |}
   53|       |
   54|       |impl PrivateKey {
   55|     42|    pub fn new() -> Self {
   56|     42|        Default::default()
   57|     42|    }
   58|       |
   59|      0|    pub fn zero() -> Self {
   60|      0|        Self::from_bytes(&[0u8; 32])
   61|      0|    }
   62|       |
   63|      0|    pub fn is_zero(&self) -> bool {
   64|      0|        self.private_key.to_bytes() == [0; 32]
   65|      0|    }
   66|       |
   67|     19|    pub fn from_bytes(bytes: &[u8; 32]) -> Self {
   68|     19|        let signing_key = ed25519_dalek::SigningKey::from_bytes(bytes);
   69|     19|        Self {
   70|     19|            private_key: signing_key,
   71|     19|        }
   72|     19|    }
   73|       |
   74|      5|    pub fn from_hex_str(s: impl AsRef<str>) -> anyhow::Result<Self> {
   75|      5|        let input = s.as_ref();
   76|      5|        let mut bytes = [0u8; 32];
   77|      5|        hex::decode_to_slice(input, &mut bytes)
   78|      5|            .with_context(|| format!("input string: '{}'", input))?;
                                           ^1                                   ^1
   79|      4|        Ok(Self::from_bytes(&bytes))
   80|      5|    }
   81|       |
   82|     89|    pub fn sign(&self, data: &[u8]) -> Signature {
   83|     89|        let mut signing_key = self.private_key.clone();
   84|     89|        let signature = signing_key.sign(data);
   85|     89|        Signature::from_bytes(signature.to_bytes())
   86|     89|    }
   87|       |
   88|    200|    pub fn account(&self) -> Account {
   89|    200|        Account::from_bytes(self.private_key.verifying_key().to_bytes())
   90|    200|    }
   91|       |
   92|    117|    pub fn public_key(&self) -> PublicKey {
   93|    117|        PublicKey::from_bytes(self.private_key.verifying_key().to_bytes())
   94|    117|    }
   95|       |
   96|      9|    pub fn raw_key(&self) -> RawKey {
   97|      9|        RawKey::from_bytes(self.private_key.to_bytes())
   98|      9|    }
   99|       |}
  100|       |
  101|       |impl From<u64> for PrivateKey {
  102|     15|    fn from(value: u64) -> Self {
  103|     15|        let mut bytes = [0; 32];
  104|     15|        bytes[..8].copy_from_slice(&value.to_be_bytes());
  105|     15|        Self::from_bytes(&bytes)
  106|     15|    }
  107|       |}
  108|       |
  109|       |impl From<RawKey> for PrivateKey {
  110|      0|    fn from(value: RawKey) -> Self {
  111|      0|        Self::from_bytes(value.as_bytes())
  112|      0|    }
  113|       |}
  114|       |
  115|       |impl From<&PrivateKey> for Root {
  116|      0|    fn from(value: &PrivateKey) -> Self {
  117|      0|        value.public_key().as_account().into()
  118|      0|    }
  119|       |}
  120|       |
  121|       |impl From<&PrivateKey> for Link {
  122|      0|    fn from(value: &PrivateKey) -> Self {
  123|      0|        value.public_key().as_account().into()
  124|      0|    }
  125|       |}
  126|       |
  127|       |impl From<&PrivateKey> for Account {
  128|     32|    fn from(value: &PrivateKey) -> Self {
  129|     32|        value.public_key().as_account()
  130|     32|    }
  131|       |}
  132|       |
  133|       |impl From<&PrivateKey> for PublicKey {
  134|      0|    fn from(value: &PrivateKey) -> Self {
  135|      0|        value.public_key()
  136|      0|    }
  137|       |}
  138|       |
  139|       |#[cfg(test)]
  140|       |mod tests {
  141|       |    use super::*;
  142|       |    use crate::BlockHash;
  143|       |    use ed25519_dalek::ed25519::signature::SignerMut;
  144|       |
  145|       |    #[test]
  146|       |    fn ed25519_signing() -> anyhow::Result<()> {
  147|       |        let secret_key = ed25519_dalek::SecretKey::from([0u8; 32]);
  148|       |        let message = [0u8; 32];
  149|       |        let mut signing_key = ed25519_dalek::SigningKey::from(&secret_key);
  150|       |        let public_key = ed25519_dalek::VerifyingKey::from(&signing_key);
  151|       |        let signature = signing_key.sign(&message);
  152|       |        public_key.verify_strict(&message, &signature).unwrap();
  153|       |
  154|       |        let mut sig_bytes = signature.to_bytes();
  155|       |        sig_bytes[32] ^= 0x1;
  156|       |        let signature = ed25519_dalek::Signature::from_bytes(&sig_bytes);
  157|       |        assert!(public_key.verify_strict(&message, &signature).is_err());
  158|       |
  159|       |        Ok(())
  160|       |    }
  161|       |
  162|       |    #[test]
  163|       |    fn sign_message_test() -> anyhow::Result<()> {
  164|       |        let prv_key = PrivateKey::new();
  165|       |        let data = [0u8; 32];
  166|       |        let signature = prv_key.sign(&data);
  167|       |        prv_key.public_key().verify(&data, &signature)?;
  168|       |        Ok(())
  169|       |    }
  170|       |
  171|       |    #[test]
  172|       |    fn signing_same_message_twice_produces_equal_signatures() {
  173|       |        // the C++ implementation adds random bytes and a padding when signing for extra security and for making side channel attacks more difficult.
  174|       |        // Currently the Rust impl does not do that.
  175|       |        // In C++ signing the same message twice will produce different signatures. In Rust we get the same signature.
  176|       |        let prv_key = PrivateKey::new();
  177|       |        let data = [1, 2, 3];
  178|       |        let signature_a = prv_key.sign(&data);
  179|       |        let signature_b = prv_key.sign(&data);
  180|       |        assert_eq!(signature_a, signature_b);
  181|       |    }
  182|       |
  183|       |    // This block signature caused issues during live bootstrap. This was fixed by enabling the
  184|       |    // feature "legacy-compatibility" for the crate ed25519-dalek-blake2b
  185|       |    #[test]
  186|       |    fn regression_validate_weird_signature() {
  187|       |        let public_key = PublicKey::decode_hex(
  188|       |            "49FEC0594D6E7F7040312E400F5F5285CB51FAF5DD8EB10CADBB02915058CCF7",
  189|       |        )
  190|       |        .unwrap();
  191|       |
  192|       |        let hash = BlockHash::decode_hex(
  193|       |            "E03D646E37DAE61E4D21281054418EF733CCFB9943B424B36B203ED063340A88",
  194|       |        )
  195|       |        .unwrap();
  196|       |
  197|       |        let signature = Signature::decode_hex("3C14AF3E82BFC7DFD04EDF1639CDBF3580C02450CED478F269A4169A941617097D73A77721B62847558659371DBC3F6830724A7A55117750E5743562D1CF671E").unwrap();
  198|       |
  199|       |        public_key.verify(hash.as_bytes(), &signature).unwrap();
  200|       |    }
  201|       |
  202|       |    // This block signature caused issues during live bootstrap. This was fixed by using verify() instead of verify_strict()
  203|       |    #[test]
  204|       |    fn regression_validate_weird_signature2() {
  205|       |        let public_key = PublicKey::from(
  206|       |            Account::decode_account(
  207|       |                "nano_11a11111111111111111111111111111111111111111111111116iq5p4i8",
  208|       |            )
  209|       |            .unwrap(),
  210|       |        );
  211|       |
  212|       |        let hash = BlockHash::decode_hex(
  213|       |            "150AFD70BD1E9845715F91D7CD7D5EE2683668199F19B4DF533FC7802CE07CA2",
  214|       |        )
  215|       |        .unwrap();
  216|       |
  217|       |        let signature = Signature::decode_hex("1A8CFB63796525E47EBAF0B8696D95E2B893CBCC13454CB34530A59A3725C1A9FEA02A1F072BADE964BE5378CFA5AD50E743F167987444B1C9E3D7B3E6009F07").unwrap();
  218|       |
  219|       |        public_key.verify(hash.as_bytes(), &signature).unwrap();
  220|       |    }
  221|       |
  222|       |    mod key_pair_factory {
  223|       |        use super::*;
  224|       |
  225|       |        #[test]
  226|       |        fn create_key_pair() {
  227|       |            let random_data = [
  228|       |                0x11, 0x22, 0x33, 0x44, 0x11, 0x22, 0x33, 0x44, 0x11, 0x22, 0x33, 0x44, 0x11, 0x22,
  229|       |                0x33, 0x44, 0x11, 0x22, 0x33, 0x44, 0x11, 0x22, 0x33, 0x44, 0x11, 0x22, 0x33, 0x44,
  230|       |                0x11, 0x22, 0x33, 0x44,
  231|       |            ];
  232|       |            let rng = NullableRng::new_null_bytes(&random_data);
  233|       |            let mut key_pair_factory = PrivateKeyFactory::new(rng);
  234|       |
  235|       |            let key_pair = key_pair_factory.create_key();
  236|       |
  237|       |            assert_eq!(key_pair.raw_key().as_bytes(), &random_data);
  238|       |        }
  239|       |
  240|       |        #[test]
  241|       |        fn nullable() {
  242|       |            let mut key_pair_factory = PrivateKeyFactory::new_null();
  243|       |            let key_pair = key_pair_factory.create_key();
  244|       |            assert_ne!(key_pair.raw_key(), RawKey::zero());
  245|       |        }
  246|       |
  247|       |        #[test]
  248|       |        fn configured_response() {
  249|       |            let expected = RawKey::from_bytes([3; 32]);
  250|       |            let mut key_pair_factory = PrivateKeyFactory::new_null_with(expected);
  251|       |            assert_eq!(key_pair_factory.create_key().raw_key(), expected);
  252|       |        }
  253|       |    }
  254|       |}

/home/gustav/code/nano/rsnano-node/core/src/public_key.rs:
    1|       |use crate::{serialize_32_byte_string, u256_struct, Account, RawKey, Signature};
    2|       |use ed25519_dalek::Verifier;
    3|       |
    4|       |u256_struct!(PublicKey);
    5|       |serialize_32_byte_string!(PublicKey);
    6|       |
    7|       |impl PublicKey {
    8|       |    /// IV for Key encryption
    9|      0|    pub fn initialization_vector(&self) -> [u8; 16] {
   10|      0|        self.0[..16].try_into().unwrap()
   11|      0|    }
   12|       |
   13|     32|    pub fn as_account(&self) -> Account {
   14|     32|        self.into()
   15|     32|    }
   16|       |
   17|     32|    pub fn verify(&self, message: &[u8], signature: &Signature) -> anyhow::Result<()> {
   18|     32|        let public = ed25519_dalek::VerifyingKey::from_bytes(&self.0)
   19|     32|            .map_err(|_| anyhow!("could not extract public key"))?;
                                       ^0                                      ^0
   20|     32|        let sig = ed25519_dalek::Signature::from_bytes(signature.as_bytes());
   21|     32|        public
   22|     32|            .verify(message, &sig)
   23|     32|            .map_err(|_| anyhow!("could not verify message"))?;
                                       ^0                                  ^0
   24|     32|        Ok(())
   25|     32|    }
   26|       |}
   27|       |
   28|       |impl TryFrom<&RawKey> for PublicKey {
   29|       |    type Error = anyhow::Error;
   30|      0|    fn try_from(prv: &RawKey) -> Result<Self, Self::Error> {
   31|      0|        let secret = ed25519_dalek::SecretKey::from(*prv.as_bytes());
   32|      0|        let signing_key = ed25519_dalek::SigningKey::from(&secret);
   33|      0|        let public = ed25519_dalek::VerifyingKey::from(&signing_key);
   34|      0|        Ok(PublicKey::from_bytes(public.to_bytes()))
   35|      0|    }
   36|       |}

/home/gustav/code/nano/rsnano-node/core/src/qualified_root.rs:
    1|       |use crate::{
    2|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, MutStreamAdapter, Serialize, Stream},
    3|       |    BlockHash, Root,
    4|       |};
    5|       |use primitive_types::U512;
    6|       |use std::hash::Hash;
    7|       |
    8|       |#[derive(
    9|       |    Default,
   10|       |    Clone,
   11|       |    PartialEq,
   12|       |    Eq,
   13|       |    Hash,
   14|       |    Debug,
   15|       |    PartialOrd,
   16|       |    Ord,
   17|       |    serde::Serialize,
   18|      0|    serde::Deserialize,
   19|       |)]
   20|       |pub struct QualifiedRoot {
   21|       |    pub root: Root,
   22|       |    pub previous: BlockHash,
   23|       |}
   24|       |
   25|       |impl QualifiedRoot {
   26|      1|    pub fn new(root: Root, previous: BlockHash) -> Self {
   27|      1|        Self { root, previous }
   28|      1|    }
   29|       |
   30|      0|    pub fn to_bytes(&self) -> [u8; 64] {
   31|      0|        let mut buffer = [0; 64];
   32|      0|        let mut stream = MutStreamAdapter::new(&mut buffer);
   33|      0|        self.serialize(&mut stream);
   34|      0|        buffer
   35|      0|    }
   36|       |
   37|      1|    pub fn new_test_instance() -> Self {
   38|      1|        Self::new(Root::from(111), BlockHash::from(222))
   39|      1|    }
   40|       |
   41|      0|    pub fn decode_hex(s: impl AsRef<str>) -> anyhow::Result<Self> {
   42|      0|        let mut bytes = [0u8; 64];
   43|      0|        hex::decode_to_slice(s.as_ref(), &mut bytes)?;
   44|      0|        let root = Root::from_bytes(bytes[0..32].try_into().unwrap());
   45|      0|        let previous = BlockHash::from_bytes(bytes[32..].try_into().unwrap());
   46|      0|        Ok(Self { root, previous })
   47|      0|    }
   48|       |}
   49|       |
   50|       |impl Serialize for QualifiedRoot {
   51|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   52|      0|        self.root.serialize(writer);
   53|      0|        self.previous.serialize(writer);
   54|      0|    }
   55|       |}
   56|       |
   57|       |impl FixedSizeSerialize for QualifiedRoot {
   58|      0|    fn serialized_size() -> usize {
   59|      0|        Root::serialized_size() + BlockHash::serialized_size()
   60|      0|    }
   61|       |}
   62|       |
   63|       |impl Deserialize for QualifiedRoot {
   64|       |    type Target = Self;
   65|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<QualifiedRoot> {
   66|      0|        let root = Root::deserialize(stream)?;
   67|      0|        let previous = BlockHash::deserialize(stream)?;
   68|      0|        Ok(QualifiedRoot { root, previous })
   69|      0|    }
   70|       |}
   71|       |
   72|       |impl From<U512> for QualifiedRoot {
   73|      0|    fn from(value: U512) -> Self {
   74|      0|        let bytes = value.to_big_endian();
   75|      0|        let root = Root::from_slice(&bytes[..32]).unwrap();
   76|      0|        let previous = BlockHash::from_slice(&bytes[32..]).unwrap();
   77|      0|        QualifiedRoot { root, previous }
   78|      0|    }
   79|       |}
   80|       |
   81|       |#[cfg(test)]
   82|       |mod tests {
   83|       |    use super::*;
   84|       |
   85|       |    #[test]
   86|       |    fn decode_hex() {
   87|       |        let hex = "000000000000000000000000000000000000000000000000000000000000007B000000000000000000000000000000000000000000000000000000000000007C";
   88|       |        let decoded = QualifiedRoot::decode_hex(hex).unwrap();
   89|       |        assert_eq!(decoded.root, Root::from(123));
   90|       |        assert_eq!(decoded.previous, BlockHash::from(124));
   91|       |    }
   92|       |}

/home/gustav/code/nano/rsnano-node/core/src/raw_key.rs:
    1|       |use crate::{serialize_32_byte_string, u256_struct};
    2|       |use ctr::cipher::{KeyIvInit, StreamCipher};
    3|       |use rand::{thread_rng, Rng};
    4|       |use std::ops::BitXorAssign;
    5|       |
    6|       |type Aes256Ctr = ctr::Ctr64BE<aes::Aes256>;
    7|       |
    8|       |u256_struct!(RawKey);
    9|       |serialize_32_byte_string!(RawKey);
   10|       |
   11|       |impl RawKey {
   12|      0|    pub fn random() -> Self {
   13|      0|        Self::from_bytes(thread_rng().gen())
   14|      0|    }
   15|       |
   16|      0|    pub fn encrypt(&self, key: &RawKey, iv: &[u8; 16]) -> Self {
   17|      0|        let mut cipher = Aes256Ctr::new(&(*key.as_bytes()).into(), &(*iv).into());
   18|      0|        let mut buf = self.0;
   19|      0|        cipher.apply_keystream(&mut buf);
   20|      0|        RawKey(buf)
   21|      0|    }
   22|       |
   23|      0|    pub fn decrypt(&self, key: &RawKey, iv: &[u8; 16]) -> Self {
   24|      0|        self.encrypt(key, iv)
   25|      0|    }
   26|       |
   27|       |    /// IV for Key encryption
   28|      0|    pub fn initialization_vector_low(&self) -> [u8; 16] {
   29|      0|        self.0[..16].try_into().unwrap()
   30|      0|    }
   31|       |
   32|       |    /// IV for Key encryption
   33|      0|    pub fn initialization_vector_high(&self) -> [u8; 16] {
   34|      0|        self.0[16..].try_into().unwrap()
   35|      0|    }
   36|       |}
   37|       |
   38|       |impl BitXorAssign for RawKey {
   39|      0|    fn bitxor_assign(&mut self, rhs: Self) {
   40|      0|        for (a, b) in self.0.iter_mut().zip(rhs.0) {
   41|      0|            *a ^= b;
   42|      0|        }
   43|      0|    }
   44|       |}
   45|       |
   46|       |#[cfg(test)]
   47|       |mod tests {
   48|       |    use crate::{PrivateKey, PublicKey};
   49|       |
   50|       |    use super::*;
   51|       |
   52|       |    #[test]
   53|       |    fn encrypt() {
   54|       |        let clear_text = RawKey::from(1);
   55|       |        let key = RawKey::from(2);
   56|       |        let iv: u128 = 123;
   57|       |        let encrypted = RawKey::encrypt(&clear_text, &key, &iv.to_be_bytes());
   58|       |        let expected =
   59|       |            RawKey::decode_hex("3ED412A6F9840EA148EAEE236AFD10983D8E11326B07DFB33C5E1C47000AF3FD")
   60|       |                .unwrap();
   61|       |        assert_eq!(encrypted, expected)
   62|       |    }
   63|       |
   64|       |    #[test]
   65|       |    fn encrypt_and_decrypt() {
   66|       |        let clear_text = RawKey::from(1);
   67|       |        let key = RawKey::from(2);
   68|       |        let iv: u128 = 123;
   69|       |        let encrypted = clear_text.encrypt(&key, &iv.to_be_bytes());
   70|       |        let decrypted = encrypted.decrypt(&key, &iv.to_be_bytes());
   71|       |        assert_eq!(decrypted, clear_text)
   72|       |    }
   73|       |
   74|       |    #[test]
   75|       |    fn key_encryption() {
   76|       |        let keypair = PrivateKey::new();
   77|       |        let secret_key = RawKey::zero();
   78|       |        let iv = keypair.public_key().initialization_vector();
   79|       |        let encrypted = keypair.raw_key().encrypt(&secret_key, &iv);
   80|       |        let decrypted = encrypted.decrypt(&secret_key, &iv);
   81|       |        assert_eq!(keypair.raw_key(), decrypted);
   82|       |        let decrypted_pub = PublicKey::try_from(&decrypted).unwrap();
   83|       |        assert_eq!(keypair.public_key(), decrypted_pub);
   84|       |    }
   85|       |
   86|       |    #[test]
   87|       |    fn encrypt_produces_same_result_every_time() {
   88|       |        let secret = RawKey::zero();
   89|       |        let number = RawKey::from(1);
   90|       |        let iv = [1; 16];
   91|       |        let encrypted1 = number.encrypt(&secret, &iv);
   92|       |        let encrypted2 = number.encrypt(&secret, &iv);
   93|       |        assert_eq!(encrypted1, encrypted2);
   94|       |    }
   95|       |}

/home/gustav/code/nano/rsnano-node/core/src/signature.rs:
    1|       |use crate::utils::{BufferWriter, Serialize, Stream};
    2|       |use serde::de::{Unexpected, Visitor};
    3|       |use std::fmt::{Debug, Write};
    4|       |
    5|       |#[derive(Clone, PartialEq, Eq, PartialOrd, Ord)]
    6|       |pub struct Signature {
    7|       |    bytes: [u8; 64],
    8|       |}
    9|       |
   10|       |impl Signature {
   11|     48|    pub fn new() -> Self {
   12|     48|        Self { bytes: [0u8; 64] }
   13|     48|    }
   14|       |
   15|    218|    pub fn from_bytes(bytes: [u8; 64]) -> Self {
   16|    218|        Self { bytes }
   17|    218|    }
   18|       |
   19|      0|    pub fn try_from_bytes(bytes: &[u8]) -> anyhow::Result<Self> {
   20|      0|        Ok(Self::from_bytes(bytes.try_into()?))
   21|      0|    }
   22|       |
   23|      0|    pub const fn serialized_size() -> usize {
   24|      0|        64
   25|      0|    }
   26|       |
   27|  65.5k|    pub fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Signature> {
   28|  65.5k|        let mut result = Signature { bytes: [0; 64] };
   29|  65.5k|
   30|  65.5k|        stream.read_bytes(&mut result.bytes, 64)?;
                                                              ^0
   31|  65.5k|        Ok(result)
   32|  65.5k|    }
   33|       |
   34|     32|    pub fn as_bytes(&'_ self) -> &'_ [u8; 64] {
   35|     32|        &self.bytes
   36|     32|    }
   37|       |
   38|      0|    pub fn encode_hex(&self) -> String {
   39|      0|        let mut result = String::with_capacity(128);
   40|      0|        for byte in self.bytes {
   41|      0|            write!(&mut result, "{:02X}", byte).unwrap();
   42|      0|        }
   43|      0|        result
   44|      0|    }
   45|       |
   46|    129|    pub fn decode_hex(s: impl AsRef<str>) -> anyhow::Result<Self> {
   47|    129|        let mut bytes = [0u8; 64];
   48|    129|        hex::decode_to_slice(s.as_ref(), &mut bytes)?;
                                                                  ^0
   49|    129|        Ok(Signature::from_bytes(bytes))
   50|    129|    }
   51|       |}
   52|       |
   53|       |impl Default for Signature {
   54|      3|    fn default() -> Self {
   55|      3|        Self { bytes: [0; 64] }
   56|      3|    }
   57|       |}
   58|       |
   59|       |impl Debug for Signature {
   60|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   61|      0|        for byte in self.bytes {
   62|      0|            write!(f, "{:02X}", byte)?;
   63|       |        }
   64|      0|        Ok(())
   65|      0|    }
   66|       |}
   67|       |
   68|       |impl Serialize for Signature {
   69|     61|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   70|     61|        writer.write_bytes_safe(&self.bytes)
   71|     61|    }
   72|       |}
   73|       |
   74|       |impl serde::Serialize for Signature {
   75|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
   76|      0|    where
   77|      0|        S: serde::Serializer,
   78|      0|    {
   79|      0|        serializer.serialize_str(&self.encode_hex())
   80|      0|    }
   81|       |}
   82|       |
   83|       |impl<'de> serde::Deserialize<'de> for Signature {
   84|    129|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
   85|    129|    where
   86|    129|        D: serde::Deserializer<'de>,
   87|    129|    {
   88|    129|        let value = deserializer.deserialize_str(SignatureVisitor {})?;
                                                                                   ^0
   89|    129|        Ok(value)
   90|    129|    }
   91|       |}
   92|       |
   93|       |pub(crate) struct SignatureVisitor {}
   94|       |
   95|       |impl<'de> Visitor<'de> for SignatureVisitor {
   96|       |    type Value = Signature;
   97|       |
   98|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
   99|      0|        formatter.write_str("a hex string containing 64 bytes")
  100|      0|    }
  101|       |
  102|    129|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  103|    129|    where
  104|    129|        E: serde::de::Error,
  105|    129|    {
  106|    129|        let signature = Signature::decode_hex(v).map_err(|_| {
  107|      0|            serde::de::Error::invalid_value(Unexpected::Str(v), &"a hex string containing 64 bytes")
  108|    129|        })?;
                        ^0
  109|    129|        Ok(signature)
  110|    129|    }
  111|       |}
  112|       |
  113|       |#[cfg(test)]
  114|       |mod tests {
  115|       |    use super::*;
  116|       |
  117|       |    #[test]
  118|       |    fn debug_format() {
  119|       |        let signature = Signature::from_bytes([42; 64]);
  120|       |        let result = format!("{:?}", signature);
  121|       |        assert_eq!(result, "2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A2A");
  122|       |    }
  123|       |}

/home/gustav/code/nano/rsnano-node/core/src/u256_struct.rs:
    1|       |use serde::de::{Unexpected, Visitor};
    2|       |
    3|       |#[macro_export]
    4|       |macro_rules! u256_struct {
    5|       |    ($name:ident) => {
    6|       |        #[derive(PartialEq, Eq, Clone, Copy, Hash, Default, PartialOrd, Ord)]
    7|       |        pub struct $name([u8; 32]);
    8|       |
    9|       |        #[allow(dead_code)]
   10|       |        impl $name {
   11|       |            pub const MAX: Self = Self([0xFF; 32]);
   12|       |
   13|   493k|            pub const fn zero() -> Self {
   14|   493k|                Self([0; 32])
   15|   493k|            }
   16|       |
   17|   164k|            pub fn is_zero(&self) -> bool {
   18|   164k|                self.0 == [0; 32]
   19|   164k|            }
   20|       |
   21|  84.2k|            pub const fn from_bytes(bytes: [u8; 32]) -> Self {
   22|  84.2k|                Self(bytes)
   23|  84.2k|            }
   24|       |
   25|      0|            pub fn from_slice(bytes: &[u8]) -> Option<Self> {
   26|      0|                match bytes.try_into() {
   27|      0|                    Ok(value) => Some(Self(value)),
   28|      0|                    Err(_) => None,
   29|       |                }
   30|      0|            }
   31|       |
   32|   473k|            pub fn as_bytes(&'_ self) -> &'_ [u8; 32] {
   33|   473k|                &self.0
   34|   473k|            }
   35|       |
   36|    295|            pub fn number(&self) -> primitive_types::U256 {
   37|    295|                primitive_types::U256::from_big_endian(&self.0)
   38|    295|            }
   39|       |
   40|     92|            pub fn inc(&self) -> Option<Self> {
   41|     92|                self.number()
   42|     92|                    .checked_add(primitive_types::U256::from(1))
   43|     92|                    .map(|i| Self::from(i))
                                           ^91
   44|     92|            }
   45|       |
   46|     50|            pub fn inc_or_max(&self) -> Self {
   47|     50|                self.inc().unwrap_or(Self::MAX)
   48|     50|            }
   49|       |
   50|     11|            pub fn encode_hex(&self) -> String {
   51|       |                use std::fmt::Write;
   52|     11|                let mut result = String::with_capacity(64);
   53|    352|                for &byte in self.as_bytes() {
                                           ^11
   54|    352|                    write!(&mut result, "{:02X}", byte).unwrap();
   55|    352|                }
   56|     11|                result
   57|     11|            }
   58|       |
   59|     65|            pub fn decode_hex(s: impl AsRef<str>) -> anyhow::Result<Self> {
   60|     65|                Ok(Self::from_bytes($crate::u256_struct::decode_32_bytes_hex(
   61|     65|                    s,
   62|     65|                )?))
                               ^0
   63|     65|            }
   64|       |        }
   65|       |
   66|       |        impl $crate::utils::Serialize for $name {
   67|  19.2k|            fn serialize(&self, writer: &mut dyn $crate::utils::BufferWriter) {
   68|  19.2k|                writer.write_bytes_safe(&self.0)
   69|  19.2k|            }
   70|       |        }
   71|       |
   72|       |        impl $crate::utils::FixedSizeSerialize for $name {
   73|     28|            fn serialized_size() -> usize {
   74|     28|                32
   75|     28|            }
   76|       |        }
   77|       |
   78|       |        impl $crate::utils::Deserialize for $name {
   79|       |            type Target = Self;
   80|   362k|            fn deserialize(stream: &mut dyn $crate::utils::Stream) -> anyhow::Result<Self> {
   81|   362k|                let mut result = Self::zero();
   82|   362k|                stream.read_bytes(&mut result.0, 32)?;
                                                                  ^0
   83|   362k|                Ok(result)
   84|   362k|            }
   85|       |        }
   86|       |
   87|       |        impl From<i32> for $name {
   88|    473|            fn from(value: i32) -> Self {
   89|    473|                let mut bytes = [0; 32];
   90|    473|                bytes[28..].copy_from_slice(&value.to_be_bytes());
   91|    473|                Self::from_bytes(bytes)
   92|    473|            }
   93|       |        }
   94|       |
   95|       |        impl From<u64> for $name {
   96|      0|            fn from(value: u64) -> Self {
   97|      0|                let mut bytes = [0; 32];
   98|      0|                bytes[24..].copy_from_slice(&value.to_be_bytes());
   99|      0|                Self::from_bytes(bytes)
  100|      0|            }
  101|       |        }
  102|       |
  103|       |        impl From<u128> for $name {
  104|      0|            fn from(value: u128) -> Self {
  105|      0|                let mut bytes = [0; 32];
  106|      0|                bytes[16..].copy_from_slice(&value.to_be_bytes());
  107|      0|                Self::from_bytes(bytes)
  108|      0|            }
  109|       |        }
  110|       |
  111|       |        impl From<primitive_types::U256> for $name {
  112|  5.20k|            fn from(value: primitive_types::U256) -> Self {
  113|  5.20k|                Self(value.to_big_endian())
  114|  5.20k|            }
  115|       |        }
  116|       |
  117|       |        impl std::fmt::Debug for $name {
  118|      4|            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  119|      4|                $crate::write_hex_bytes(&self.0, f)
  120|      4|            }
  121|       |        }
  122|       |
  123|       |        impl std::fmt::Display for $name {
  124|      0|            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  125|      0|                $crate::write_hex_bytes(&self.0, f)
  126|      0|            }
  127|       |        }
  128|       |    };
  129|       |}
  130|       |
  131|    194|pub fn decode_32_bytes_hex(s: impl AsRef<str>) -> anyhow::Result<[u8; 32]> {
  132|    194|    let s = s.as_ref();
  133|    194|    if s.is_empty() || s.len() > 64 {
  134|      0|        bail!(
  135|      0|            "Invalid U256 string length. Expected <= 64 but was {}",
  136|      0|            s.len()
  137|      0|        );
  138|    194|    }
  139|    194|
  140|    194|    let mut padded_string = String::new();
  141|    194|    let sanitized = if s.len() < 64 {
  142|      0|        for _ in 0..(64 - s.len()) {
  143|      0|            padded_string.push('0');
  144|      0|        }
  145|      0|        padded_string.push_str(s);
  146|      0|        &padded_string
  147|       |    } else {
  148|    194|        s
  149|       |    };
  150|       |
  151|    194|    let mut bytes = [0u8; 32];
  152|    194|    hex::decode_to_slice(sanitized, &mut bytes)?;
                                                             ^0
  153|    194|    Ok(bytes)
  154|    194|}
  155|       |
  156|       |#[macro_export]
  157|       |macro_rules! serialize_32_byte_string {
  158|       |    ($name:ident) => {
  159|       |        impl serde::Serialize for $name {
  160|      0|            fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
  161|      0|            where
  162|      0|                S: serde::Serializer,
  163|      0|            {
  164|      0|                serializer.serialize_str(&self.encode_hex())
  165|      0|            }
  166|       |        }
  167|       |
  168|       |        impl<'de> serde::Deserialize<'de> for $name {
  169|    129|            fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
  170|    129|            where
  171|    129|                D: serde::Deserializer<'de>,
  172|    129|            {
  173|    129|                let value = deserializer.deserialize_str($crate::u256_struct::U256Visitor {})?;
                                                                                                           ^0
  174|    129|                Ok(Self::from_bytes(value))
  175|    129|            }
  176|       |        }
  177|       |    };
  178|       |}
  179|       |
  180|       |pub(crate) struct U256Visitor {}
  181|       |
  182|       |impl<'de> Visitor<'de> for U256Visitor {
  183|       |    type Value = [u8; 32];
  184|       |
  185|      0|    fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
  186|      0|        formatter.write_str("a hex string containing 32 bytes")
  187|      0|    }
  188|       |
  189|    129|    fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
  190|    129|    where
  191|    129|        E: serde::de::Error,
  192|    129|    {
  193|    129|        let bytes = decode_32_bytes_hex(v).map_err(|_| {
  194|      0|            serde::de::Error::invalid_value(Unexpected::Str(v), &"a hex string containing 32 bytes")
  195|    129|        })?;
                        ^0
  196|    129|        Ok(bytes)
  197|    129|    }
  198|       |}
  199|       |
  200|       |#[cfg(test)]
  201|       |mod tests {
  202|       |    use primitive_types::U256;
  203|       |
  204|       |    u256_struct!(U256Test);
  205|       |
  206|       |    #[test]
  207|       |    fn constructor() {
  208|       |        let x = U256Test::zero();
  209|       |        assert_eq!(x.0, [0; 32]);
  210|       |        assert!(x.is_zero());
  211|       |    }
  212|       |
  213|       |    #[test]
  214|       |    fn decode_hex() {
  215|       |        // Happy path
  216|       |        assert_eq!(U256Test::decode_hex("0").unwrap(), U256Test::zero());
  217|       |        assert_eq!(U256Test::decode_hex("1").unwrap(), U256Test::from(1));
  218|       |        assert_eq!(U256Test::decode_hex("01").unwrap(), U256Test::from(1));
  219|       |        assert_eq!(U256Test::decode_hex("A").unwrap(), U256Test::from(0xa));
  220|       |        assert_eq!(
  221|       |            U256Test::decode_hex(
  222|       |                "ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff"
  223|       |            )
  224|       |            .unwrap(),
  225|       |            U256Test::from(U256::MAX)
  226|       |        );
  227|       |
  228|       |        // Errors
  229|       |        assert!(U256Test::decode_hex("!").is_err());
  230|       |        assert!(U256Test::decode_hex("-1").is_err());
  231|       |        assert!(U256Test::decode_hex(
  232|       |            "affffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff"
  233|       |        )
  234|       |        .is_err());
  235|       |    }
  236|       |
  237|       |    #[test]
  238|       |    fn encode_hex() {
  239|       |        assert_eq!(
  240|       |            U256Test::zero().encode_hex(),
  241|       |            "0000000000000000000000000000000000000000000000000000000000000000"
  242|       |        );
  243|       |        assert_eq!(
  244|       |            U256Test::from(0x12ab).encode_hex(),
  245|       |            "00000000000000000000000000000000000000000000000000000000000012AB"
  246|       |        );
  247|       |        assert_eq!(
  248|       |            U256Test::from_bytes([0xff; 32]).encode_hex(),
  249|       |            "FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"
  250|       |        );
  251|       |    }
  252|       |
  253|       |    #[test]
  254|       |    fn big_endian() {
  255|       |        let value = U256Test::from(1);
  256|       |        assert_eq!(value.as_bytes()[31], 1);
  257|       |    }
  258|       |}

/home/gustav/code/nano/rsnano-node/core/src/unchecked_info.rs:
    1|       |use super::BlockHash;
    2|       |use crate::{
    3|       |    utils::{
    4|       |        BufferWriter, Deserialize, FixedSizeSerialize, MemoryStream, Serialize, Stream, StreamExt,
    5|       |    },
    6|       |    Block,
    7|       |};
    8|       |use std::time::{SystemTime, UNIX_EPOCH};
    9|       |
   10|       |/// Information on an unchecked block
   11|       |#[derive(Clone, Debug)]
   12|       |pub struct UncheckedInfo {
   13|       |    pub block: Block,
   14|       |
   15|       |    /// Seconds since posix epoch
   16|       |    pub modified: u64,
   17|       |}
   18|       |
   19|       |impl UncheckedInfo {
   20|     10|    pub fn new(block: Block) -> Self {
   21|     10|        Self {
   22|     10|            block,
   23|     10|            modified: SystemTime::now()
   24|     10|                .duration_since(UNIX_EPOCH)
   25|     10|                .unwrap()
   26|     10|                .as_secs(),
   27|     10|        }
   28|     10|    }
   29|       |
   30|      0|    pub fn to_bytes(&self) -> Vec<u8> {
   31|      0|        let mut stream = MemoryStream::new();
   32|      0|        self.serialize(&mut stream);
   33|      0|        stream.to_vec()
   34|      0|    }
   35|       |}
   36|       |
   37|       |impl Serialize for UncheckedInfo {
   38|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   39|      0|        self.block.serialize(stream);
   40|      0|        stream.write_u64_ne_safe(self.modified);
   41|      0|    }
   42|       |}
   43|       |
   44|       |impl Deserialize for UncheckedInfo {
   45|       |    type Target = Self;
   46|       |
   47|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   48|      0|        let block = Block::deserialize(stream)?;
   49|      0|        let modified = stream.read_u64_ne()?;
   50|      0|        Ok(Self { block, modified })
   51|      0|    }
   52|       |}
   53|       |
   54|       |#[derive(Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash)]
   55|       |pub struct UncheckedKey {
   56|       |    pub previous: BlockHash,
   57|       |    pub hash: BlockHash,
   58|       |}
   59|       |
   60|       |impl UncheckedKey {
   61|     10|    pub fn new(previous: BlockHash, hash: BlockHash) -> Self {
   62|     10|        Self { previous, hash }
   63|     10|    }
   64|       |
   65|      0|    pub fn to_bytes(&self) -> [u8; 64] {
   66|      0|        let mut result = [0; 64];
   67|      0|        result[..32].copy_from_slice(self.previous.as_bytes());
   68|      0|        result[32..].copy_from_slice(self.hash.as_bytes());
   69|      0|        result
   70|      0|    }
   71|       |}
   72|       |
   73|       |impl Deserialize for UncheckedKey {
   74|       |    type Target = Self;
   75|       |
   76|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   77|      0|        let previous = BlockHash::deserialize(stream)?;
   78|      0|        let hash = BlockHash::deserialize(stream)?;
   79|      0|        Ok(Self { previous, hash })
   80|      0|    }
   81|       |}
   82|       |
   83|       |impl Serialize for UncheckedKey {
   84|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   85|      0|        self.previous.serialize(writer);
   86|      0|        self.hash.serialize(writer);
   87|      0|    }
   88|       |}
   89|       |
   90|       |impl FixedSizeSerialize for UncheckedKey {
   91|      0|    fn serialized_size() -> usize {
   92|      0|        BlockHash::serialized_size() * 2
   93|      0|    }
   94|       |}

/home/gustav/code/nano/rsnano-node/core/src/utils/container_info.rs:
    1|       |use serde_json::json;
    2|       |
    3|       |#[derive(PartialEq, Eq, Debug)]
    4|       |pub struct ContainerSize {
    5|       |    pub count: usize,
    6|       |    pub element_size: usize,
    7|       |}
    8|       |
    9|       |#[derive(PartialEq, Eq, Debug)]
   10|       |pub struct Leaf {
   11|       |    pub name: String,
   12|       |    pub info: ContainerSize,
   13|       |}
   14|       |
   15|       |impl Leaf {
   16|      0|    fn into_json(self) -> (String, serde_json::Value) {
   17|      0|        let fields = json!(
   18|      0|        {
   19|      0|            "count": self.info.count.to_string(),
   20|      0|            "size": self.info.element_size.to_string()
   21|      0|        });
   22|      0|        (self.name, fields)
   23|      0|    }
   24|       |}
   25|       |
   26|       |#[derive(PartialEq, Eq, Debug)]
   27|       |pub struct Node {
   28|       |    pub name: String,
   29|       |    pub children: ContainerInfo,
   30|       |}
   31|       |
   32|       |impl Node {
   33|      0|    fn into_json(self) -> (String, serde_json::Value) {
   34|      0|        let mut children = serde_json::Map::new();
   35|      0|        for child in self.children.0 {
   36|      0|            let (name, value) = child.into_json();
   37|      0|            children.insert(name, value);
   38|      0|        }
   39|      0|        (self.name, serde_json::Value::Object(children))
   40|      0|    }
   41|       |}
   42|       |
   43|       |#[derive(PartialEq, Eq, Debug)]
   44|       |pub enum ContainerInfoEntry {
   45|       |    Leaf(Leaf),
   46|       |    Node(Node),
   47|       |}
   48|       |
   49|       |impl ContainerInfoEntry {
   50|      0|    fn into_json(self) -> (String, serde_json::Value) {
   51|      0|        match self {
   52|      0|            ContainerInfoEntry::Leaf(leaf) => leaf.into_json(),
   53|      0|            ContainerInfoEntry::Node(node) => node.into_json(),
   54|       |        }
   55|      0|    }
   56|       |}
   57|       |
   58|       |#[derive(PartialEq, Eq, Debug)]
   59|       |pub struct ContainerInfo(Vec<ContainerInfoEntry>);
   60|       |
   61|       |impl ContainerInfo {
   62|      4|    pub fn builder() -> ContainerInfosBuilder {
   63|      4|        ContainerInfosBuilder(Vec::new())
   64|      4|    }
   65|       |
   66|      0|    pub fn into_json(self) -> serde_json::Value {
   67|      0|        let mut data = serde_json::Map::new();
   68|      0|        for entry in self.0 {
   69|      0|            let (name, value) = entry.into_json();
   70|      0|            data.insert(name, value);
   71|      0|        }
   72|      0|        serde_json::Value::Object(data)
   73|      0|    }
   74|       |}
   75|       |
   76|       |pub struct ContainerInfosBuilder(Vec<ContainerInfoEntry>);
   77|       |
   78|       |impl ContainerInfosBuilder {
   79|     12|    pub fn leaf(mut self, name: impl Into<String>, count: usize, element_size: usize) -> Self {
   80|     12|        self.0.push(ContainerInfoEntry::Leaf(Leaf {
   81|     12|            name: name.into(),
   82|     12|            info: ContainerSize {
   83|     12|                count,
   84|     12|                element_size,
   85|     12|            },
   86|     12|        }));
   87|     12|        self
   88|     12|    }
   89|       |
   90|      2|    pub fn node(mut self, name: impl Into<String>, infos: ContainerInfo) -> Self {
   91|      2|        self.0.push(ContainerInfoEntry::Node(Node {
   92|      2|            name: name.into(),
   93|      2|            children: infos,
   94|      2|        }));
   95|      2|        self
   96|      2|    }
   97|      4|    pub fn finish(self) -> ContainerInfo {
   98|      4|        ContainerInfo(self.0)
   99|      4|    }
  100|       |}
  101|       |
  102|       |impl<const N: usize> From<[(&'static str, usize, usize); N]> for ContainerInfo {
  103|      1|    fn from(value: [(&'static str, usize, usize); N]) -> Self {
  104|      1|        let mut builder = ContainerInfo::builder();
  105|      6|        for (name, count, element_size) in value {
                           ^5
  106|      5|            builder = builder.leaf(name, count, element_size);
  107|      5|        }
  108|      1|        builder.finish()
  109|      1|    }
  110|       |}

/home/gustav/code/nano/rsnano-node/core/src/utils/fair_queue.rs:
    1|       |use std::{
    2|       |    cmp::min,
    3|       |    collections::{BTreeMap, HashMap, VecDeque},
    4|       |    hash::Hash,
    5|       |    ops::RangeBounds,
    6|       |};
    7|       |
    8|       |use super::ContainerInfo;
    9|       |
   10|       |/// Queue items of type T from source S
   11|       |pub struct FairQueue<S, T>
   12|       |where
   13|       |    S: Ord + Copy,
   14|       |{
   15|       |    queues: BTreeMap<S, Entry<T>>,
   16|       |    current_queue_key: Option<S>,
   17|       |    max_size_query: Box<dyn Fn(&S) -> usize + Send + Sync>,
   18|       |    priority_query: Box<dyn Fn(&S) -> usize + Send + Sync>,
   19|       |    counter: usize,
   20|       |    total_len: usize,
   21|       |}
   22|       |
   23|       |impl<S, T> FairQueue<S, T>
   24|       |where
   25|       |    S: Ord + Copy,
   26|       |{
   27|     27|    pub fn new(
   28|     27|        max_size_query: impl Fn(&S) -> usize + Send + Sync + 'static,
   29|     27|        priority_query: impl Fn(&S) -> usize + Send + Sync + 'static,
   30|     27|    ) -> Self {
   31|     27|        Self {
   32|     27|            queues: BTreeMap::new(),
   33|     27|            current_queue_key: None,
   34|     27|            counter: 0,
   35|     27|            total_len: 0,
   36|     27|            max_size_query: Box::new(max_size_query),
   37|     27|            priority_query: Box::new(priority_query),
   38|     27|        }
   39|     27|    }
   40|       |
   41|      3|    pub fn sum_queue_len<R>(&self, range: R) -> usize
   42|      3|    where
   43|      3|        R: RangeBounds<S>,
   44|      3|    {
   45|      3|        self.queues.range(range).map(|(_, q)| q.len()).sum()
                                                            ^0
   46|      3|    }
   47|       |
   48|      0|    pub fn queue_len(&self, source: &S) -> usize {
   49|      0|        self.queues.get(source).map(|q| q.len()).unwrap_or_default()
   50|      0|    }
   51|       |
   52|      0|    pub fn max_len(&self, source: &S) -> usize {
   53|      0|        self.queues
   54|      0|            .get(source)
   55|      0|            .map(|q| q.max_size)
   56|      0|            .unwrap_or_default()
   57|      0|    }
   58|       |
   59|      0|    pub fn priority(&self, source: &S) -> usize {
   60|      0|        self.queues
   61|      0|            .get(source)
   62|      0|            .map(|q| q.priority)
   63|      0|            .unwrap_or_default()
   64|      0|    }
   65|       |
   66|      0|    pub fn free_capacity(&self, source: &S) -> usize {
   67|      0|        self.queues
   68|      0|            .get(source)
   69|      0|            .map(|q| q.max_size - q.len())
   70|      0|            .unwrap_or_else(|| (self.max_size_query)(source))
   71|      0|    }
   72|       |
   73|     68|    pub fn len(&self) -> usize {
   74|     68|        self.total_len
   75|     68|    }
   76|       |
   77|     51|    pub fn is_empty(&self) -> bool {
   78|     51|        self.len() == 0
   79|     51|    }
   80|       |
   81|      0|    pub fn queues_len(&self) -> usize {
   82|      0|        self.queues.len()
   83|      0|    }
   84|       |
   85|      0|    pub fn clear(&mut self) {
   86|      0|        self.queues.clear();
   87|      0|    }
   88|       |
   89|       |    /// Push an item to the appropriate queue based on the source
   90|       |    /// item will be dropped if the queue is full
   91|       |    /// @return true if added, false if dropped
   92|      1|    pub fn push(&mut self, source: S, item: T) -> bool {
   93|      1|        let entry = self.queues.entry(source.clone()).or_insert_with(|| {
   94|      1|            let max_size = (self.max_size_query)(&source);
   95|      1|            let priority = (self.priority_query)(&source);
   96|      1|            Entry::new(max_size, priority)
   97|      1|        });
   98|      1|        let added = entry.push(item);
   99|      1|        if added {
  100|      1|            self.total_len += 1;
  101|      1|        }
                       ^0
  102|      1|        added
  103|      1|    }
  104|       |
  105|      1|    pub fn next(&mut self) -> Option<(S, T)> {
  106|      1|        if self.total_len == 0 {
  107|      0|            return None;
  108|      1|        }
  109|      1|
  110|      1|        if self.should_seek() {
  111|      1|            self.seek_next();
  112|      1|        }
                       ^0
  113|       |
  114|      1|        let it = self.current_queue_key.as_ref()?;
                                                              ^0
  115|      1|        let queue = self.queues.get_mut(it).unwrap();
  116|      1|        self.counter += 1;
  117|      1|        self.total_len -= 1;
  118|      1|        Some((it.clone(), queue.pop().unwrap()))
  119|      1|    }
  120|       |
  121|      1|    fn should_seek(&self) -> bool {
  122|      1|        match &self.current_queue_key {
  123|      0|            Some(key) => match self.queues.get(key) {
  124|      0|                Some(queue) => {
  125|      0|                    if queue.is_empty() {
  126|      0|                        true
  127|       |                    } else {
  128|       |                        // Allow up to `queue.priority` requests to be processed before moving to the next queue
  129|      0|                        self.counter >= queue.priority
  130|       |                    }
  131|       |                }
  132|      0|                None => true,
  133|       |            },
  134|      1|            None => true,
  135|       |        }
  136|      1|    }
  137|       |
  138|     13|    pub fn next_batch(&mut self, max_count: usize) -> VecDeque<(S, T)> {
  139|     13|        let count = min(self.len(), max_count);
  140|     13|
  141|     13|        let mut result = VecDeque::new();
  142|     14|        while result.len() < count {
  143|      1|            result.push_back(self.next().unwrap());
  144|      1|        }
  145|     13|        result
  146|     13|    }
  147|       |
  148|      0|    pub fn remove(&mut self, key: &S) {
  149|      0|        if let Some(removed) = self.queues.remove(key) {
  150|      0|            self.total_len -= removed.len();
  151|      0|            self.current_queue_key = None;
  152|      0|        }
  153|      0|    }
  154|       |
  155|      0|    pub fn compacted_info<R>(&self, compact: impl Fn(&S) -> R) -> FairQueueInfo<R>
  156|      0|    where
  157|      0|        R: Hash + Eq + Copy,
  158|      0|    {
  159|      0|        let mut total_size = 0;
  160|      0|        let mut total_max_size = 0;
  161|      0|        let mut queues_info: HashMap<R, QueueInfo<R>> = HashMap::new();
  162|       |
  163|       |        // Iterate over all queues
  164|      0|        for (key, entry) in self.queues.iter() {
  165|      0|            let compacted_source = compact(key);
  166|      0|            let size = entry.len();
  167|      0|            total_size += size;
  168|      0|            total_max_size += entry.max_size;
  169|      0|
  170|      0|            queues_info
  171|      0|                .entry(compacted_source)
  172|      0|                .and_modify(|i| {
  173|      0|                    i.size += size;
  174|      0|                    i.max_size += entry.max_size;
  175|      0|                })
  176|      0|                .or_insert_with(|| QueueInfo {
  177|      0|                    source: compacted_source,
  178|      0|                    size,
  179|      0|                    max_size: entry.max_size,
  180|      0|                });
  181|      0|        }
  182|       |
  183|      0|        FairQueueInfo {
  184|      0|            queues: queues_info,
  185|      0|            total_size,
  186|      0|            total_max_size,
  187|      0|        }
  188|      0|    }
  189|       |
  190|      0|    pub fn container_info(&self) -> ContainerInfo {
  191|      0|        [
  192|      0|            (
  193|      0|                "queues",
  194|      0|                self.queues.len(),
  195|      0|                std::mem::size_of::<S>() + std::mem::size_of::<Entry<T>>(),
  196|      0|            ),
  197|      0|            (
  198|      0|                "total_size",
  199|      0|                self.len(),
  200|      0|                std::mem::size_of::<S>() + std::mem::size_of::<Entry<T>>(),
  201|      0|            ),
  202|      0|        ]
  203|      0|        .into()
  204|      0|    }
  205|       |
  206|      1|    fn seek_next(&mut self) {
  207|      1|        self.counter = 0;
  208|       |        //TODO unwraps and inefficient access!
  209|       |        //TODO Endless loop if everything is empty!
  210|       |        loop {
  211|      1|            if let Some(current) = self.current_queue_key.take() {
                                      ^0
  212|      0|                let mut it = self.queues.range(current..);
  213|      0|                if let Some(_) = it.next() {
  214|      0|                    self.current_queue_key = it.next().map(|(k, _)| k.clone());
  215|      0|                }
  216|      1|            }
  217|       |
  218|      1|            if self.current_queue_key.is_none() {
  219|      1|                self.current_queue_key = Some(self.queues.first_key_value().unwrap().0.clone());
  220|      1|            }
                           ^0
  221|       |
  222|      1|            if !self
  223|      1|                .queues
  224|      1|                .get(self.current_queue_key.as_ref().unwrap())
  225|      1|                .unwrap()
  226|      1|                .is_empty()
  227|       |            {
  228|      1|                break;
  229|      0|            }
  230|       |        }
  231|      1|    }
  232|       |}
  233|       |
  234|       |struct Entry<T> {
  235|       |    requests: VecDeque<T>,
  236|       |    priority: usize,
  237|       |    max_size: usize,
  238|       |}
  239|       |
  240|       |impl<T> Entry<T> {
  241|      1|    pub fn new(max_size: usize, priority: usize) -> Self {
  242|      1|        Self {
  243|      1|            max_size,
  244|      1|            priority,
  245|      1|            requests: Default::default(),
  246|      1|        }
  247|      1|    }
  248|       |
  249|      1|    pub fn pop(&mut self) -> Option<T> {
  250|      1|        self.requests.pop_front()
  251|      1|    }
  252|       |
  253|      1|    pub fn push(&mut self, request: T) -> bool {
  254|      1|        if self.requests.len() < self.max_size {
  255|      1|            self.requests.push_back(request);
  256|      1|            true // Added
  257|       |        } else {
  258|      0|            false // Dropped
  259|       |        }
  260|      1|    }
  261|       |
  262|      1|    pub fn is_empty(&self) -> bool {
  263|      1|        self.requests.is_empty()
  264|      1|    }
  265|       |
  266|      0|    pub fn len(&self) -> usize {
  267|      0|        self.requests.len()
  268|      0|    }
  269|       |}
  270|       |
  271|       |pub struct FairQueueInfo<S>
  272|       |where
  273|       |    S: Clone + Hash + Eq,
  274|       |{
  275|       |    pub queues: HashMap<S, QueueInfo<S>>,
  276|       |    pub total_size: usize,
  277|       |    pub total_max_size: usize,
  278|       |}
  279|       |
  280|       |impl<S> Default for FairQueueInfo<S>
  281|       |where
  282|       |    S: Clone + Hash + Eq,
  283|       |{
  284|      0|    fn default() -> Self {
  285|      0|        Self {
  286|      0|            total_size: 0,
  287|      0|            total_max_size: 0,
  288|      0|            queues: Default::default(),
  289|      0|        }
  290|      0|    }
  291|       |}
  292|       |
  293|       |#[derive(Clone)]
  294|       |pub struct QueueInfo<S>
  295|       |where
  296|       |    S: Clone,
  297|       |{
  298|       |    pub source: S,
  299|       |    pub size: usize,
  300|       |    pub max_size: usize,
  301|       |}
  302|       |
  303|       |#[cfg(test)]
  304|       |mod tests {
  305|       |    use super::*;
  306|       |
  307|       |    #[test]
  308|       |    fn empty() {
  309|       |        let queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 999, |_| 999);
  310|       |        assert_eq!(queue.len(), 0);
  311|       |        assert!(queue.is_empty());
  312|       |        assert_eq!(queue.free_capacity(&1), 999);
  313|       |        assert_eq!(queue.free_capacity(&2), 999);
  314|       |    }
  315|       |
  316|       |    #[test]
  317|       |    fn process_one() {
  318|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 1, |_| 1);
  319|       |        queue.push(7, "foo");
  320|       |
  321|       |        assert_eq!(queue.len(), 1);
  322|       |        assert_eq!(queue.queues_len(), 1);
  323|       |        assert_eq!(queue.queue_len(&7), 1);
  324|       |        assert_eq!(queue.queue_len(&8), 0);
  325|       |        assert_eq!(queue.free_capacity(&7), 0);
  326|       |        assert_eq!(queue.free_capacity(&8), 1);
  327|       |
  328|       |        let (source, item) = queue.next().unwrap();
  329|       |        assert_eq!(source, 7);
  330|       |        assert_eq!(item, "foo");
  331|       |        assert!(queue.is_empty());
  332|       |    }
  333|       |
  334|       |    #[test]
  335|       |    fn fifo() {
  336|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 999, |_| 1);
  337|       |
  338|       |        queue.push(7, "a");
  339|       |        queue.push(7, "b");
  340|       |        queue.push(7, "c");
  341|       |
  342|       |        assert_eq!(queue.len(), 3);
  343|       |        assert_eq!(queue.queues_len(), 1);
  344|       |        assert_eq!(queue.queue_len(&7), 3);
  345|       |
  346|       |        assert_eq!(queue.next(), Some((7, "a")));
  347|       |        assert_eq!(queue.next(), Some((7, "b")));
  348|       |        assert_eq!(queue.next(), Some((7, "c")));
  349|       |        assert!(queue.is_empty());
  350|       |        assert_eq!(queue.free_capacity(&7), 999);
  351|       |    }
  352|       |
  353|       |    #[test]
  354|       |    fn process_many() {
  355|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 1, |_| 1);
  356|       |
  357|       |        queue.push(7, "a");
  358|       |        queue.push(8, "b");
  359|       |        queue.push(9, "c");
  360|       |
  361|       |        assert_eq!(queue.len(), 3);
  362|       |        assert_eq!(queue.queues_len(), 3);
  363|       |
  364|       |        assert_eq!(queue.next(), Some((7, "a")));
  365|       |        assert_eq!(queue.next(), Some((8, "b")));
  366|       |        assert_eq!(queue.next(), Some((9, "c")));
  367|       |        assert!(queue.is_empty());
  368|       |    }
  369|       |
  370|       |    #[test]
  371|       |    fn max_queue_size() {
  372|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 2, |_| 1);
  373|       |
  374|       |        queue.push(7, "a");
  375|       |        queue.push(7, "b");
  376|       |        queue.push(7, "c");
  377|       |
  378|       |        assert_eq!(queue.len(), 2);
  379|       |
  380|       |        assert_eq!(queue.next(), Some((7, "a")));
  381|       |        assert_eq!(queue.next(), Some((7, "b")));
  382|       |        assert!(queue.is_empty());
  383|       |    }
  384|       |
  385|       |    #[test]
  386|       |    fn round_robin_with_priority() {
  387|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(
  388|       |            |_| 999,
  389|       |            |origin| match origin {
  390|       |                7 => 1,
  391|       |                8 => 2,
  392|       |                9 => 3,
  393|       |                _ => unreachable!(),
  394|       |            },
  395|       |        );
  396|       |
  397|       |        queue.push(7, "7a");
  398|       |        queue.push(7, "7b");
  399|       |        queue.push(7, "7c");
  400|       |        queue.push(8, "8a");
  401|       |        queue.push(8, "8b");
  402|       |        queue.push(8, "8c");
  403|       |        queue.push(9, "9a");
  404|       |        queue.push(9, "9b");
  405|       |        queue.push(9, "9c");
  406|       |        assert_eq!(queue.len(), 9);
  407|       |
  408|       |        // Processing 1x live, 2x bootstrap, 3x unchecked before moving to the next source
  409|       |        assert_eq!(queue.next().unwrap().1, "7a");
  410|       |        assert_eq!(queue.next().unwrap().1, "8a");
  411|       |        assert_eq!(queue.next().unwrap().1, "8b");
  412|       |        assert_eq!(queue.next().unwrap().1, "9a");
  413|       |        assert_eq!(queue.next().unwrap().1, "9b");
  414|       |        assert_eq!(queue.next().unwrap().1, "9c");
  415|       |        assert_eq!(queue.next().unwrap().1, "7b");
  416|       |        assert_eq!(queue.next().unwrap().1, "8c");
  417|       |        assert_eq!(queue.next().unwrap().1, "7c");
  418|       |        assert!(queue.is_empty());
  419|       |    }
  420|       |
  421|       |    #[test]
  422|       |    fn sum_queue_len() {
  423|       |        let mut queue: FairQueue<usize, &'static str> = FairQueue::new(|_| 999, |_| 999);
  424|       |
  425|       |        queue.push(3, "x");
  426|       |        queue.push(4, "x");
  427|       |        queue.push(4, "x");
  428|       |        queue.push(5, "x");
  429|       |        queue.push(5, "x");
  430|       |        queue.push(6, "x");
  431|       |        queue.push(7, "x");
  432|       |
  433|       |        assert_eq!(queue.sum_queue_len(4..=6), 5);
  434|       |    }
  435|       |}

/home/gustav/code/nano/rsnano-node/core/src/utils/mod.rs:
    1|       |mod container_info;
    2|       |mod fair_queue;
    3|       |mod peer;
    4|       |mod stream;
    5|       |
    6|       |pub use container_info::*;
    7|       |pub use fair_queue::*;
    8|       |pub use peer::*;
    9|       |use std::{
   10|       |    net::{Ipv6Addr, SocketAddrV6},
   11|       |    thread::available_parallelism,
   12|       |    time::{Duration, SystemTime, SystemTimeError, UNIX_EPOCH},
   13|       |};
   14|       |pub use stream::*;
   15|       |
   16|       |pub trait Serialize {
   17|       |    fn serialize(&self, stream: &mut dyn BufferWriter);
   18|       |}
   19|       |
   20|       |pub trait FixedSizeSerialize: Serialize {
   21|       |    fn serialized_size() -> usize;
   22|       |}
   23|       |
   24|       |pub trait Deserialize {
   25|       |    type Target;
   26|       |    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target>;
   27|       |}
   28|       |
   29|       |impl Serialize for u64 {
   30|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   31|      0|        stream.write_u64_be_safe(*self)
   32|      0|    }
   33|       |}
   34|       |
   35|       |impl FixedSizeSerialize for u64 {
   36|      0|    fn serialized_size() -> usize {
   37|      0|        std::mem::size_of::<u64>()
   38|      0|    }
   39|       |}
   40|       |
   41|       |impl Deserialize for u64 {
   42|       |    type Target = Self;
   43|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<u64> {
   44|      0|        stream.read_u64_be()
   45|      0|    }
   46|       |}
   47|       |
   48|       |impl Serialize for [u8; 64] {
   49|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   50|      0|        stream.write_bytes_safe(self)
   51|      0|    }
   52|       |}
   53|       |
   54|       |impl FixedSizeSerialize for [u8; 64] {
   55|      0|    fn serialized_size() -> usize {
   56|      0|        64
   57|      0|    }
   58|       |}
   59|       |
   60|       |impl Deserialize for [u8; 64] {
   61|       |    type Target = Self;
   62|       |
   63|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   64|      0|        let mut buffer = [0; 64];
   65|      0|        stream.read_bytes(&mut buffer, 64)?;
   66|      0|        Ok(buffer)
   67|      0|    }
   68|       |}
   69|       |
   70|     54|pub fn get_cpu_count() -> usize {
   71|     54|    // Try to read overridden value from environment variable
   72|     54|    let value = std::env::var("NANO_HARDWARE_CONCURRENCY")
   73|     54|        .unwrap_or_else(|_| "0".into())
   74|     54|        .parse::<usize>()
   75|     54|        .unwrap_or_default();
   76|     54|
   77|     54|    if value > 0 {
   78|      0|        return value;
   79|     54|    }
   80|     54|
   81|     54|    available_parallelism().unwrap().get()
   82|     54|}
   83|       |
   84|       |pub type MemoryIntensiveInstrumentationCallback = extern "C" fn() -> bool;
   85|       |
   86|       |pub static mut MEMORY_INTENSIVE_INSTRUMENTATION: Option<MemoryIntensiveInstrumentationCallback> =
   87|       |    None;
   88|       |
   89|      0|extern "C" fn default_is_sanitizer_build_callback() -> bool {
   90|      0|    false
   91|      0|}
   92|       |pub static mut IS_SANITIZER_BUILD: MemoryIntensiveInstrumentationCallback =
   93|       |    default_is_sanitizer_build_callback;
   94|       |
   95|     36|pub fn memory_intensive_instrumentation() -> bool {
   96|     36|    match std::env::var("NANO_MEMORY_INTENSIVE") {
   97|      0|        Ok(val) => matches!(val.to_lowercase().as_str(), "1" | "true" | "on"),
   98|       |        Err(_) => unsafe {
   99|     36|            match MEMORY_INTENSIVE_INSTRUMENTATION {
  100|      0|                Some(f) => f(),
  101|     36|                None => false,
  102|       |            }
  103|       |        },
  104|       |    }
  105|     36|}
  106|       |
  107|      0|pub fn is_sanitizer_build() -> bool {
  108|      0|    unsafe { IS_SANITIZER_BUILD() }
  109|      0|}
  110|       |
  111|      0|pub fn milliseconds_since_epoch() -> u64 {
  112|      0|    SystemTime::now()
  113|      0|        .duration_since(SystemTime::UNIX_EPOCH)
  114|      0|        .unwrap()
  115|      0|        .as_millis() as u64
  116|      0|}
  117|       |
  118|      6|pub fn system_time_as_seconds(time: SystemTime) -> u64 {
  119|      6|    time.duration_since(SystemTime::UNIX_EPOCH)
  120|      6|        .expect("Time went backwards")
  121|      6|        .as_secs()
  122|      6|}
  123|       |
  124|       |/// Elapsed seconds since UNIX_EPOCH
  125|       |#[derive(PartialEq, Eq, Clone, Copy, PartialOrd, Ord, Default)]
  126|       |pub struct UnixTimestamp(u64);
  127|       |
  128|       |impl UnixTimestamp {
  129|       |    pub const ZERO: Self = Self(0);
  130|       |    pub const MAX: Self = Self(u64::MAX);
  131|       |
  132|    251|    pub const fn new(seconds_since_epoch: u64) -> Self {
  133|    251|        Self(seconds_since_epoch)
  134|    251|    }
  135|       |
  136|     32|    pub fn now() -> Self {
  137|     32|        Self(Self::seconds_since_unix_epoch())
  138|     32|    }
  139|       |
  140|     59|    pub fn as_u64(&self) -> u64 {
  141|     59|        self.0
  142|     59|    }
  143|       |
  144|     32|    fn seconds_since_unix_epoch() -> u64 {
  145|     32|        SystemTime::now()
  146|     32|            .duration_since(SystemTime::UNIX_EPOCH)
  147|     32|            .unwrap()
  148|     32|            .as_secs()
  149|     32|    }
  150|       |
  151|     61|    pub fn to_be_bytes(&self) -> [u8; 8] {
  152|     61|        self.0.to_be_bytes()
  153|     61|    }
  154|       |
  155|  65.5k|    pub fn from_be_bytes(bytes: [u8; 8]) -> Self {
  156|  65.5k|        Self(u64::from_be_bytes(bytes))
  157|  65.5k|    }
  158|       |
  159|      0|    pub fn add(&self, seconds: u64) -> Self {
  160|      0|        Self(self.0 + seconds)
  161|      0|    }
  162|       |}
  163|       |
  164|       |impl From<u64> for UnixTimestamp {
  165|    210|    fn from(value: u64) -> Self {
  166|    210|        Self::new(value)
  167|    210|    }
  168|       |}
  169|       |
  170|       |impl TryFrom<SystemTime> for UnixTimestamp {
  171|       |    type Error = SystemTimeError;
  172|       |
  173|      0|    fn try_from(value: SystemTime) -> Result<Self, Self::Error> {
  174|      0|        Ok(Self(value.duration_since(UNIX_EPOCH)?.as_secs()))
  175|      0|    }
  176|       |}
  177|       |
  178|       |impl std::fmt::Display for UnixTimestamp {
  179|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  180|      0|        std::fmt::Display::fmt(&self.0, f)
  181|      0|    }
  182|       |}
  183|       |
  184|       |impl std::fmt::Debug for UnixTimestamp {
  185|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  186|      0|        std::fmt::Debug::fmt(&self.0, f)
  187|      0|    }
  188|       |}
  189|       |
  190|      0|pub fn get_env_or_default<T>(variable_name: &str, default: T) -> T
  191|      0|where
  192|      0|    T: core::str::FromStr + Copy,
  193|      0|{
  194|      0|    std::env::var(variable_name)
  195|      0|        .map(|v| v.parse::<T>().unwrap_or(default))
  196|      0|        .unwrap_or(default)
  197|      0|}
  198|       |
  199|      3|pub fn get_env_or_default_string(variable_name: &str, default: impl Into<String>) -> String {
  200|      3|    std::env::var(variable_name).unwrap_or_else(|_| default.into())
  201|      3|}
  202|       |
  203|     59|pub fn get_env_bool(variable_name: impl AsRef<str>) -> Option<bool> {
  204|     59|    let variable_name = variable_name.as_ref();
  205|     59|    std::env::var(variable_name)
  206|     59|        .ok()
  207|     59|        .map(|val| match val.to_lowercase().as_ref() {
  208|      0|            "1" | "true" | "on" => true,
  209|      0|            "0" | "false" | "off" => false,
  210|      0|            _ => panic!("Invalid environment boolean value: {variable_name} = {val}"),
  211|     59|        })
                      ^0
  212|     59|}
  213|       |
  214|      4|pub fn parse_endpoint(s: &str) -> SocketAddrV6 {
  215|      4|    s.parse().unwrap()
  216|      4|}
  217|       |
  218|       |pub const NULL_ENDPOINT: SocketAddrV6 = SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0);
  219|       |
  220|       |pub const TEST_ENDPOINT_1: SocketAddrV6 =
  221|       |    SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 0x10, 0, 0, 1), 1111, 0, 0);
  222|       |
  223|       |pub const TEST_ENDPOINT_2: SocketAddrV6 =
  224|       |    SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 0x10, 0, 0, 2), 2222, 0, 0);
  225|       |
  226|       |pub const TEST_ENDPOINT_3: SocketAddrV6 =
  227|       |    SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 0x10, 0, 0, 3), 3333, 0, 0);
  228|       |
  229|     14|pub fn new_test_timestamp() -> SystemTime {
  230|     14|    UNIX_EPOCH + Duration::from_secs(1_000_000)
  231|     14|}

/home/gustav/code/nano/rsnano-node/core/src/utils/peer.rs:
    1|       |use serde::{de::Error, Deserialize, Deserializer, Serialize, Serializer};
    2|       |use std::{net::SocketAddrV6, str::FromStr};
    3|       |
    4|       |#[derive(Clone, Debug, PartialEq, Eq)]
    5|       |pub struct Peer {
    6|       |    pub address: String,
    7|       |    pub port: u16,
    8|       |}
    9|       |
   10|       |impl std::fmt::Display for Peer {
   11|      1|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   12|      1|        write!(f, "{}:{}", self.address, self.port)
   13|      1|    }
   14|       |}
   15|       |
   16|       |impl Peer {
   17|     17|    pub fn new(address: impl Into<String>, port: u16) -> Self {
   18|     17|        Self {
   19|     17|            address: address.into(),
   20|     17|            port,
   21|     17|        }
   22|     17|    }
   23|       |
   24|      1|    pub fn parse_list(input: &[String], default_port: u16) -> Vec<Peer> {
   25|      1|        input
   26|      1|            .iter()
   27|      1|            .filter_map(|s| parse_peer(s, default_port).ok())
   28|      1|            .collect()
   29|      1|    }
   30|       |}
   31|       |
   32|      1|fn parse_peer(input: &str, default_port: u16) -> anyhow::Result<Peer> {
   33|      1|    if input.contains(']') {
   34|       |        // IPV6 with port
   35|      0|        let addr = SocketAddrV6::from_str(input)?;
   36|      0|        Ok(Peer::new(addr.ip().to_string(), addr.port()))
   37|      1|    } else if input.contains("::") {
   38|       |        // IPV6 without port
   39|      0|        Ok(Peer::new(input.to_owned(), default_port))
   40|      1|    } else if input.contains(':') {
   41|       |        // hostname/ipv4 with port
   42|      0|        let mut values = input.split(':');
   43|      0|        let host = values.next().unwrap().to_owned();
   44|      0|        let port = values
   45|      0|            .next()
   46|      0|            .ok_or_else(|| anyhow!("no port"))?
   47|      0|            .parse::<u16>()?;
   48|      0|        Ok(Peer::new(host, port))
   49|       |    } else {
   50|       |        // just hostname/ipv4
   51|      1|        Ok(Peer::new(input.to_owned(), default_port))
   52|       |    }
   53|      1|}
   54|       |
   55|       |impl FromStr for Peer {
   56|       |    type Err = String;
   57|       |
   58|      1|    fn from_str(s: &str) -> Result<Self, Self::Err> {
   59|      1|        let parts: Vec<&str> = s.split(':').collect();
   60|      1|        if parts.len() != 2 {
   61|      0|            return Err("Invalid format".into());
   62|      1|        }
   63|      1|
   64|      1|        let address = parts[0].to_string();
   65|      1|        let port = parts[1]
   66|      1|            .parse::<u16>()
   67|      1|            .map_err(|_| "Invalid port".to_string())?;
                                       ^0                         ^0
   68|       |
   69|      1|        Ok(Peer { address, port })
   70|      1|    }
   71|       |}
   72|       |
   73|       |impl Serialize for Peer {
   74|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
   75|      0|    where
   76|      0|        S: Serializer,
   77|      0|    {
   78|      0|        serializer.serialize_str(&self.to_string())
   79|      0|    }
   80|       |}
   81|       |
   82|       |impl<'de> Deserialize<'de> for Peer {
   83|      0|    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
   84|      0|    where
   85|      0|        D: Deserializer<'de>,
   86|      0|    {
   87|      0|        let s = String::deserialize(deserializer)?;
   88|      0|        s.parse().map_err(D::Error::custom)
   89|      0|    }
   90|       |}
   91|       |
   92|       |#[cfg(test)]
   93|       |mod tests {
   94|       |    use super::*;
   95|       |    use serde_json;
   96|       |
   97|       |    #[test]
   98|       |    fn test_peer_serialize() {
   99|       |        let peer = Peer::new("192.168.1.1", 7075);
  100|       |        let serialized = serde_json::to_string(&peer).unwrap();
  101|       |        assert_eq!(serialized, "\"192.168.1.1:7075\"");
  102|       |    }
  103|       |
  104|       |    #[test]
  105|       |    fn test_peer_deserialize() {
  106|       |        let serialized = "\"192.168.1.1:7075\"";
  107|       |        let peer: Peer = serde_json::from_str(serialized).unwrap();
  108|       |        assert_eq!(peer, Peer::new("192.168.1.1", 7075));
  109|       |    }
  110|       |
  111|       |    #[test]
  112|       |    fn test_peer_invalid_deserialize() {
  113|       |        let invalid_inputs = vec![
  114|       |            "\"invalid\"",
  115|       |            "\"192.168.1.1\"",
  116|       |            "\"192.168.1.1:\"",
  117|       |            "\"192.168.1.1:abc\"",
  118|       |            "\"192.168.1.1:65536\"",
  119|       |        ];
  120|       |
  121|       |        for input in invalid_inputs {
  122|       |            let result: Result<Peer, _> = serde_json::from_str(input);
  123|       |            assert!(result.is_err(), "Expected error for input: {}", input);
  124|       |        }
  125|       |    }
  126|       |
  127|       |    #[test]
  128|       |    fn parse_empty_list() {
  129|       |        assert!(Peer::parse_list(&[], 42).is_empty());
  130|       |    }
  131|       |
  132|       |    #[test]
  133|       |    fn parse_host_names_only() {
  134|       |        assert_eq!(
  135|       |            Peer::parse_list(
  136|       |                &[
  137|       |                    "localhost".to_owned(),
  138|       |                    "127.0.0.1".to_owned(),
  139|       |                    "my.other.host".to_owned()
  140|       |                ],
  141|       |                42
  142|       |            ),
  143|       |            [
  144|       |                Peer::new("localhost", 42),
  145|       |                Peer::new("127.0.0.1", 42),
  146|       |                Peer::new("my.other.host", 42)
  147|       |            ]
  148|       |        );
  149|       |    }
  150|       |
  151|       |    #[test]
  152|       |    fn parse_ipv6() {
  153|       |        assert_eq!(parse_peer("::1", 42).unwrap(), Peer::new("::1", 42));
  154|       |    }
  155|       |
  156|       |    #[test]
  157|       |    fn parse_ipv6_with_port() {
  158|       |        assert_eq!(parse_peer("[::1]:100", 42).unwrap(), Peer::new("::1", 100));
  159|       |    }
  160|       |
  161|       |    #[test]
  162|       |    fn parse_hostname_with_port() {
  163|       |        assert_eq!(
  164|       |            parse_peer("my.host.de:100", 42).unwrap(),
  165|       |            Peer::new("my.host.de", 100)
  166|       |        );
  167|       |    }
  168|       |
  169|       |    #[test]
  170|       |    fn should_remove_invalid_peers() {
  171|       |        assert!(
  172|       |            Peer::parse_list(&["[asdfasfd]:1".to_owned(), "localhost:".to_owned()], 42).is_empty()
  173|       |        )
  174|       |    }
  175|       |}

/home/gustav/code/nano/rsnano-node/core/src/utils/stream.rs:
    1|       |pub trait Stream {
    2|       |    fn write_u8(&mut self, value: u8) -> anyhow::Result<()>;
    3|       |    fn write_bytes(&mut self, bytes: &[u8]) -> anyhow::Result<()>;
    4|       |    fn read_u8(&mut self) -> anyhow::Result<u8>;
    5|       |    fn read_bytes(&mut self, buffer: &mut [u8], len: usize) -> anyhow::Result<()>;
    6|       |
    7|       |    ///  Looking ahead into the stream.
    8|       |    ///  returns:  The number of characters available.
    9|       |    ///  If a read position is available, returns the number of characters
   10|       |    ///  available for reading before the buffer must be refilled.
   11|       |    ///  Otherwise returns the derived showmanyc().
   12|       |    fn in_avail(&mut self) -> anyhow::Result<usize>;
   13|       |}
   14|       |
   15|       |pub trait StreamExt: Stream {
   16|      0|    fn read_u32_be(&mut self) -> anyhow::Result<u32> {
   17|      0|        let mut buffer = [0u8; 4];
   18|      0|        self.read_bytes(&mut buffer, 4)?;
   19|      0|        Ok(u32::from_be_bytes(buffer))
   20|      0|    }
   21|       |
   22|      0|    fn read_u64_be(&mut self) -> anyhow::Result<u64> {
   23|      0|        let mut buffer = [0u8; 8];
   24|      0|        self.read_bytes(&mut buffer, 8)?;
   25|      0|        Ok(u64::from_be_bytes(buffer))
   26|      0|    }
   27|       |
   28|      0|    fn read_u64_le(&mut self) -> anyhow::Result<u64> {
   29|      0|        let mut buffer = [0u8; 8];
   30|      0|        self.read_bytes(&mut buffer, 8)?;
   31|      0|        Ok(u64::from_le_bytes(buffer))
   32|      0|    }
   33|       |
   34|      0|    fn read_u128_le(&mut self) -> anyhow::Result<u128> {
   35|      0|        let mut buffer = [0u8; 16];
   36|      0|        self.read_bytes(&mut buffer, 16)?;
   37|      0|        Ok(u128::from_le_bytes(buffer))
   38|      0|    }
   39|       |
   40|      0|    fn read_u128_be(&mut self) -> anyhow::Result<u128> {
   41|      0|        let mut buffer = [0u8; 16];
   42|      0|        self.read_bytes(&mut buffer, 16)?;
   43|      0|        Ok(u128::from_be_bytes(buffer))
   44|      0|    }
   45|       |
   46|  49.7k|    fn read_u64_ne(&mut self) -> anyhow::Result<u64> {
   47|  49.7k|        let mut buffer = [0u8; 8];
   48|  49.7k|        self.read_bytes(&mut buffer, 8)?;
                                                     ^0
   49|  49.7k|        Ok(u64::from_ne_bytes(buffer))
   50|  49.7k|    }
   51|       |
   52|      0|    fn write_u32_be(&mut self, value: u32) -> anyhow::Result<()> {
   53|      0|        self.write_bytes(&value.to_be_bytes())
   54|      0|    }
   55|       |
   56|      0|    fn write_u64_be(&mut self, value: u64) -> anyhow::Result<()> {
   57|      0|        self.write_bytes(&value.to_be_bytes())
   58|      0|    }
   59|       |
   60|      0|    fn write_u64_ne(&mut self, value: u64) -> anyhow::Result<()> {
   61|      0|        self.write_bytes(&value.to_ne_bytes())
   62|      0|    }
   63|       |}
   64|       |
   65|       |impl<T: Stream + ?Sized> StreamExt for T {}
   66|       |
   67|       |#[derive(Default)]
   68|       |pub struct MemoryStream {
   69|       |    bytes: Vec<u8>,
   70|       |    read_index: usize,
   71|       |}
   72|       |
   73|       |impl MemoryStream {
   74|     64|    pub fn new() -> Self {
   75|     64|        Default::default()
   76|     64|    }
   77|       |
   78|      0|    pub fn bytes_written(&self) -> usize {
   79|      0|        self.bytes.len()
   80|      0|    }
   81|       |
   82|      0|    pub fn byte_at(&self, i: usize) -> u8 {
   83|      0|        self.bytes[i]
   84|      0|    }
   85|       |
   86|      3|    pub fn as_bytes(&self) -> &[u8] {
   87|      3|        &self.bytes
   88|      3|    }
   89|       |
   90|     61|    pub fn to_vec(self) -> Vec<u8> {
   91|     61|        self.bytes
   92|     61|    }
   93|       |
   94|      0|    pub fn at_end(&self) -> bool {
   95|      0|        self.bytes.len() - self.read_index == 0
   96|      0|    }
   97|       |}
   98|       |
   99|       |impl BufferWriter for MemoryStream {
  100|    590|    fn write_bytes_safe(&mut self, bytes: &[u8]) {
  101|    590|        self.bytes.extend_from_slice(bytes);
  102|    590|    }
  103|       |
  104|    145|    fn write_u8_safe(&mut self, value: u8) {
  105|    145|        self.bytes.push(value);
  106|    145|    }
  107|       |
  108|      3|    fn write_u32_be_safe(&mut self, value: u32) {
  109|      3|        self.write_bytes_safe(&value.to_be_bytes());
  110|      3|    }
  111|       |
  112|     24|    fn write_u64_be_safe(&mut self, value: u64) {
  113|     24|        self.write_bytes_safe(&value.to_be_bytes());
  114|     24|    }
  115|       |
  116|      0|    fn write_u64_ne_safe(&mut self, value: u64) {
  117|      0|        self.write_bytes_safe(&value.to_ne_bytes());
  118|      0|    }
  119|       |}
  120|       |
  121|       |impl Stream for MemoryStream {
  122|      0|    fn write_u8(&mut self, value: u8) -> anyhow::Result<()> {
  123|      0|        self.bytes.push(value);
  124|      0|        Ok(())
  125|      0|    }
  126|       |
  127|      0|    fn write_bytes(&mut self, bytes: &[u8]) -> anyhow::Result<()> {
  128|      0|        self.bytes.extend_from_slice(bytes);
  129|      0|        Ok(())
  130|      0|    }
  131|       |
  132|      0|    fn read_u8(&mut self) -> anyhow::Result<u8> {
  133|      0|        if self.read_index >= self.bytes.len() {
  134|      0|            bail!("no more bytes to read")
  135|      0|        }
  136|      0|
  137|      0|        let result = self.bytes[self.read_index];
  138|      0|        self.read_index += 1;
  139|      0|        Ok(result)
  140|      0|    }
  141|       |
  142|      0|    fn read_bytes(&mut self, buffer: &mut [u8], len: usize) -> anyhow::Result<()> {
  143|      0|        if self.read_index + len > self.bytes.len() {
  144|      0|            bail!("not enough bytes to read")
  145|      0|        }
  146|      0|
  147|      0|        buffer.copy_from_slice(&self.bytes[self.read_index..self.read_index + len]);
  148|      0|        self.read_index += len;
  149|      0|        Ok(())
  150|      0|    }
  151|       |
  152|      0|    fn in_avail(&mut self) -> anyhow::Result<usize> {
  153|      0|        Ok(self.bytes.len() - self.read_index)
  154|      0|    }
  155|       |}
  156|       |
  157|       |pub struct MutStreamAdapter<'a> {
  158|       |    bytes: &'a mut [u8],
  159|       |    read_index: usize,
  160|       |    write_index: usize,
  161|       |}
  162|       |
  163|       |pub trait BufferWriter {
  164|       |    fn write_bytes_safe(&mut self, bytes: &[u8]);
  165|       |    fn write_u8_safe(&mut self, value: u8);
  166|       |    fn write_u32_be_safe(&mut self, value: u32);
  167|       |    fn write_u64_be_safe(&mut self, value: u64);
  168|       |    fn write_u64_ne_safe(&mut self, value: u64);
  169|       |}
  170|       |
  171|       |impl<'a> MutStreamAdapter<'a> {
  172|  18.7k|    pub fn new(bytes: &'a mut [u8]) -> Self {
  173|  18.7k|        Self {
  174|  18.7k|            bytes,
  175|  18.7k|            read_index: 0,
  176|  18.7k|            write_index: 0,
  177|  18.7k|        }
  178|  18.7k|    }
  179|       |
  180|      0|    pub fn bytes_written(&self) -> usize {
  181|      0|        self.write_index
  182|      0|    }
  183|       |
  184|  2.29k|    pub fn written(&self) -> &[u8] {
  185|  2.29k|        &self.bytes[..self.write_index]
  186|  2.29k|    }
  187|       |}
  188|       |
  189|       |impl<'a> BufferWriter for MutStreamAdapter<'a> {
  190|  35.5k|    fn write_bytes_safe(&mut self, bytes: &[u8]) {
  191|  35.5k|        if self.write_index + bytes.len() > self.bytes.len() {
  192|      0|            panic!("buffer full");
  193|  35.5k|        }
  194|  35.5k|        self.bytes[self.write_index..self.write_index + bytes.len()].copy_from_slice(bytes);
  195|  35.5k|        self.write_index += bytes.len();
  196|  35.5k|    }
  197|       |
  198|     59|    fn write_u8_safe(&mut self, value: u8) {
  199|     59|        if self.write_index >= self.bytes.len() {
  200|      0|            panic!("buffer full");
  201|     59|        }
  202|     59|        self.bytes[self.write_index] = value;
  203|     59|        self.write_index += 1;
  204|     59|    }
  205|       |
  206|      0|    fn write_u32_be_safe(&mut self, value: u32) {
  207|      0|        self.write_bytes_safe(&value.to_be_bytes())
  208|      0|    }
  209|       |
  210|      0|    fn write_u64_be_safe(&mut self, value: u64) {
  211|      0|        self.write_bytes_safe(&value.to_be_bytes())
  212|      0|    }
  213|       |
  214|  16.5k|    fn write_u64_ne_safe(&mut self, value: u64) {
  215|  16.5k|        self.write_bytes_safe(&value.to_ne_bytes())
  216|  16.5k|    }
  217|       |}
  218|       |
  219|       |impl<'a> Stream for MutStreamAdapter<'a> {
  220|      0|    fn write_u8(&mut self, value: u8) -> anyhow::Result<()> {
  221|      0|        if self.write_index >= self.bytes.len() {
  222|      0|            bail!("buffer full");
  223|      0|        }
  224|      0|        self.bytes[self.write_index] = value;
  225|      0|        self.write_index += 1;
  226|      0|        Ok(())
  227|      0|    }
  228|       |
  229|      0|    fn write_bytes(&mut self, bytes: &[u8]) -> anyhow::Result<()> {
  230|      0|        if self.write_index + bytes.len() > self.bytes.len() {
  231|      0|            bail!("buffer full");
  232|      0|        }
  233|      0|        self.bytes[self.write_index..self.write_index + bytes.len()].copy_from_slice(bytes);
  234|      0|        self.write_index += bytes.len();
  235|      0|        Ok(())
  236|      0|    }
  237|       |
  238|      0|    fn read_u8(&mut self) -> anyhow::Result<u8> {
  239|      0|        if self.read_index >= self.bytes.len() {
  240|      0|            bail!("no more bytes to read")
  241|      0|        }
  242|      0|
  243|      0|        let result = self.bytes[self.read_index];
  244|      0|        self.read_index += 1;
  245|      0|        Ok(result)
  246|      0|    }
  247|       |
  248|      0|    fn read_bytes(&mut self, buffer: &mut [u8], len: usize) -> anyhow::Result<()> {
  249|      0|        if self.read_index + len > self.bytes.len() {
  250|      0|            bail!("not enough bytes to read")
  251|      0|        }
  252|      0|
  253|      0|        buffer.copy_from_slice(&self.bytes[self.read_index..self.read_index + len]);
  254|      0|        self.read_index += len;
  255|      0|        Ok(())
  256|      0|    }
  257|       |
  258|      0|    fn in_avail(&mut self) -> anyhow::Result<usize> {
  259|      0|        Ok(self.bytes.len() - self.read_index)
  260|      0|    }
  261|       |}
  262|       |
  263|       |pub struct BufferReader<'a> {
  264|       |    bytes: &'a [u8],
  265|       |    read_index: usize,
  266|       |}
  267|       |
  268|       |impl<'a> BufferReader<'a> {
  269|   115k|    pub fn new(bytes: &'a [u8]) -> Self {
  270|   115k|        Self {
  271|   115k|            bytes,
  272|   115k|            read_index: 0,
  273|   115k|        }
  274|   115k|    }
  275|       |
  276|      0|    pub fn remaining(&self) -> &[u8] {
  277|      0|        &self.bytes[self.read_index..]
  278|      0|    }
  279|       |}
  280|       |
  281|       |impl<'a> Stream for BufferReader<'a> {
  282|      0|    fn write_u8(&mut self, _value: u8) -> anyhow::Result<()> {
  283|      0|        bail!("not supported");
  284|      0|    }
  285|       |
  286|      0|    fn write_bytes(&mut self, _bytes: &[u8]) -> anyhow::Result<()> {
  287|      0|        bail!("not supported");
  288|      0|    }
  289|       |
  290|   164k|    fn read_u8(&mut self) -> anyhow::Result<u8> {
  291|   164k|        if self.read_index >= self.bytes.len() {
  292|      0|            bail!("no more bytes to read")
  293|   164k|        }
  294|   164k|
  295|   164k|        let result = self.bytes[self.read_index];
  296|   164k|        self.read_index += 1;
  297|   164k|        Ok(result)
  298|   164k|    }
  299|       |
  300|   723k|    fn read_bytes(&mut self, buffer: &mut [u8], len: usize) -> anyhow::Result<()> {
  301|   723k|        if self.read_index + len > self.bytes.len() {
  302|      0|            bail!("not enough bytes to read")
  303|   723k|        }
  304|   723k|
  305|   723k|        buffer.copy_from_slice(&self.bytes[self.read_index..self.read_index + len]);
  306|   723k|        self.read_index += len;
  307|   723k|        Ok(())
  308|   723k|    }
  309|       |
  310|      0|    fn in_avail(&mut self) -> anyhow::Result<usize> {
  311|      0|        Ok(self.bytes.len() - self.read_index)
  312|      0|    }
  313|       |}
  314|       |
  315|       |#[cfg(test)]
  316|       |mod tests {
  317|       |    use super::*;
  318|       |    use anyhow::Result;
  319|       |
  320|       |    #[test]
  321|       |    fn test_stream() -> Result<()> {
  322|       |        let mut stream = MemoryStream::new();
  323|       |        stream.write_bytes(&[1, 2, 3])?;
  324|       |        assert_eq!(stream.bytes_written(), 3);
  325|       |
  326|       |        let mut read_buffer = [0u8; 3];
  327|       |        stream.read_bytes(&mut read_buffer, 3)?;
  328|       |        assert_eq!([1, 2, 3], read_buffer);
  329|       |
  330|       |        assert!(stream.read_bytes(&mut read_buffer, 1).is_err());
  331|       |        Ok(())
  332|       |    }
  333|       |}

/home/gustav/code/nano/rsnano-node/core/src/vote.rs:
    1|       |use super::{
    2|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Stream},
    3|       |    Account, BlockHash, BlockHashBuilder, FullHash, PrivateKey, Signature,
    4|       |};
    5|       |use crate::{utils::Serialize, Amount, PublicKey};
    6|       |use anyhow::Result;
    7|       |use std::time::{Duration, SystemTime};
    8|       |
    9|      0|#[derive(FromPrimitive, Copy, Clone, PartialEq, Eq, Debug)]
   10|       |pub enum VoteSource {
   11|       |    Live,
   12|       |    Rebroadcast,
   13|       |    Cache,
   14|       |}
   15|       |
   16|      0|#[derive(FromPrimitive, Clone, Copy, PartialEq, Eq, Debug)]
   17|       |pub enum VoteCode {
   18|       |    Invalid,       // Vote is not signed correctly
   19|       |    Replay,        // Vote does not have the highest timestamp, it's a replay
   20|       |    Vote,          // Vote has the highest timestamp
   21|       |    Indeterminate, // Unknown if replay or vote
   22|       |    Ignored,       // Vote is valid, but got ingored (e.g. due to cooldown)
   23|       |}
   24|       |
   25|       |impl VoteCode {
   26|      0|    pub fn as_str(&self) -> &'static str {
   27|      0|        match self {
   28|      0|            VoteCode::Vote => "vote",
   29|      0|            VoteCode::Replay => "replay",
   30|      0|            VoteCode::Indeterminate => "indeterminate",
   31|      0|            VoteCode::Ignored => "ignored",
   32|      0|            VoteCode::Invalid => "invalid",
   33|       |        }
   34|      0|    }
   35|       |}
   36|       |
   37|       |#[derive(Clone, Debug, serde::Serialize)]
   38|       |#[serde(rename_all = "snake_case")]
   39|       |pub struct Vote {
   40|       |    pub timestamp: u64,
   41|       |
   42|       |    // Account that's voting
   43|       |    pub voting_account: PublicKey,
   44|       |
   45|       |    // Signature of timestamp + block hashes
   46|       |    pub signature: Signature,
   47|       |
   48|       |    // The hashes for which this vote directly covers
   49|       |    pub hashes: Vec<BlockHash>,
   50|       |}
   51|       |
   52|       |static HASH_PREFIX: &str = "vote ";
   53|       |
   54|       |impl Vote {
   55|       |    pub const MAX_HASHES: usize = 255;
   56|      7|    pub fn null() -> Self {
   57|      7|        Self {
   58|      7|            timestamp: 0,
   59|      7|            voting_account: PublicKey::zero(),
   60|      7|            signature: Signature::new(),
   61|      7|            hashes: Vec::new(),
   62|      7|        }
   63|      7|    }
   64|       |
   65|      4|    pub fn new_final(key: &PrivateKey, hashes: Vec<BlockHash>) -> Self {
   66|      4|        assert!(hashes.len() <= Self::MAX_HASHES);
   67|      4|        Self::new(key, Self::TIMESTAMP_MAX, Self::DURATION_MAX, hashes)
   68|      4|    }
   69|       |
   70|     41|    pub fn new(
   71|     41|        priv_key: &PrivateKey,
   72|     41|        timestamp: u64,
   73|     41|        duration: u8,
   74|     41|        hashes: Vec<BlockHash>,
   75|     41|    ) -> Self {
   76|     41|        assert!(hashes.len() <= Self::MAX_HASHES);
   77|     41|        let mut result = Self {
   78|     41|            voting_account: priv_key.public_key(),
   79|     41|            timestamp: packed_timestamp(timestamp, duration),
   80|     41|            signature: Signature::new(),
   81|     41|            hashes,
   82|     41|        };
   83|     41|        result.signature = priv_key.sign(result.hash().as_bytes());
   84|     41|        result
   85|     41|    }
   86|       |
   87|      0|    pub fn new_test_instance() -> Self {
   88|      0|        let key = PrivateKey::from(42);
   89|      0|        Self::new(&key, 1, 2, vec![BlockHash::from(5)])
   90|      0|    }
   91|       |
   92|       |    /// Timestamp for final vote
   93|       |    pub const FINAL_TIMESTAMP: u64 = u64::MAX;
   94|       |    pub const DURATION_MAX: u8 = 0x0F;
   95|       |    pub const TIMESTAMP_MAX: u64 = 0xFFFF_FFFF_FFFF_FFF0;
   96|       |    pub const TIMESTAMP_MIN: u64 = 0x0000_0000_0000_0010;
   97|       |    const TIMESTAMP_MASK: u64 = 0xFFFF_FFFF_FFFF_FFF0;
   98|       |
   99|       |    /// Returns the timestamp of the vote (with the duration bits masked, set to zero)
  100|       |    /// If it is a final vote, all the bits including duration bits are returned as they are, all FF
  101|     17|    pub fn timestamp(&self) -> u64 {
  102|     17|        if self.is_final() {
  103|      3|            self.timestamp //final vote
  104|       |        } else {
  105|     14|            self.timestamp & Self::TIMESTAMP_MASK
  106|       |        }
  107|     17|    }
  108|       |
  109|     68|    pub fn is_final(&self) -> bool {
  110|     68|        self.timestamp == Vote::FINAL_TIMESTAMP
  111|     68|    }
  112|       |
  113|      0|    pub fn duration_bits(&self) -> u8 {
  114|      0|        // Duration field is specified in the 4 low-order bits of the timestamp.
  115|      0|        // This makes the timestamp have a minimum granularity of 16ms
  116|      0|        // The duration is specified as 2^(duration + 4) giving it a range of 16-524,288ms in power of two increments
  117|      0|        let result = self.timestamp & !Self::TIMESTAMP_MASK;
  118|      0|        result as u8
  119|      0|    }
  120|       |
  121|      0|    pub fn duration(&self) -> Duration {
  122|      0|        Duration::from_millis(1 << (self.duration_bits() + 4))
  123|      0|    }
  124|       |
  125|      0|    fn serialize_json(&self) -> serde_json::Value {
  126|      0|        let mut values = serde_json::Map::new();
  127|      0|        values.insert(
  128|      0|            "account".to_string(),
  129|      0|            serde_json::Value::String(Account::from(self.voting_account).encode_account()),
  130|      0|        );
  131|      0|        values.insert(
  132|      0|            "signature".to_string(),
  133|      0|            serde_json::Value::String(self.signature.encode_hex()),
  134|      0|        );
  135|      0|        values.insert(
  136|      0|            "sequence".to_string(),
  137|      0|            serde_json::Value::String(self.timestamp().to_string()),
  138|      0|        );
  139|      0|        values.insert(
  140|      0|            "timestamp".to_string(),
  141|      0|            serde_json::Value::String(self.timestamp().to_string()),
  142|      0|        );
  143|      0|        values.insert(
  144|      0|            "duration".to_string(),
  145|      0|            serde_json::Value::String(self.duration_bits().to_string()),
  146|      0|        );
  147|      0|        let mut blocks = Vec::new();
  148|      0|        for hash in &self.hashes {
  149|      0|            blocks.push(serde_json::Value::String(hash.to_string()));
  150|      0|        }
  151|      0|        values.insert("blocks".to_string(), serde_json::Value::Array(blocks));
  152|      0|        serde_json::Value::Object(values)
  153|      0|    }
  154|       |
  155|      0|    pub fn to_json(&self) -> String {
  156|      0|        self.serialize_json().to_string()
  157|      0|    }
  158|       |
  159|     41|    pub fn hash(&self) -> BlockHash {
  160|     41|        let mut builder = BlockHashBuilder::new().update(HASH_PREFIX);
  161|       |
  162|     79|        for hash in &self.hashes {
                          ^38
  163|     38|            builder = builder.update(hash.as_bytes())
  164|       |        }
  165|       |
  166|     41|        builder.update(self.timestamp.to_ne_bytes()).build()
  167|     41|    }
  168|       |
  169|      0|    pub fn deserialize(&mut self, stream: &mut impl Stream) -> Result<()> {
  170|      0|        self.voting_account = PublicKey::deserialize(stream)?;
  171|      0|        self.signature = Signature::deserialize(stream)?;
  172|      0|        let mut buffer = [0; 8];
  173|      0|        stream.read_bytes(&mut buffer, 8)?;
  174|      0|        self.timestamp = u64::from_le_bytes(buffer);
  175|      0|        self.hashes = Vec::new();
  176|      0|        while stream.in_avail()? > 0 && self.hashes.len() < Self::MAX_HASHES {
  177|      0|            self.hashes.push(BlockHash::deserialize(stream)?);
  178|       |        }
  179|      0|        Ok(())
  180|      0|    }
  181|       |
  182|      0|    pub fn validate(&self) -> Result<()> {
  183|      0|        self.voting_account
  184|      0|            .verify(self.hash().as_bytes(), &self.signature)
  185|      0|    }
  186|       |
  187|      0|    pub fn serialized_size(count: usize) -> usize {
  188|      0|        Account::serialized_size()
  189|      0|        + Signature::serialized_size()
  190|      0|        + std::mem::size_of::<u64>() // timestamp
  191|      0|        + (BlockHash::serialized_size() * count)
  192|      0|    }
  193|       |}
  194|       |
  195|       |impl Serialize for Vote {
  196|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  197|      0|        self.voting_account.serialize(writer);
  198|      0|        self.signature.serialize(writer);
  199|      0|        writer.write_bytes_safe(&self.timestamp.to_le_bytes());
  200|      0|        for hash in &self.hashes {
  201|      0|            hash.serialize(writer);
  202|      0|        }
  203|      0|    }
  204|       |}
  205|       |
  206|       |impl PartialEq for Vote {
  207|      0|    fn eq(&self, other: &Self) -> bool {
  208|      0|        self.timestamp == other.timestamp
  209|      0|            && self.voting_account == other.voting_account
  210|      0|            && self.signature == other.signature
  211|      0|            && self.hashes == other.hashes
  212|      0|    }
  213|       |}
  214|       |
  215|       |impl Eq for Vote {}
  216|       |
  217|       |impl FullHash for Vote {
  218|      0|    fn full_hash(&self) -> BlockHash {
  219|      0|        BlockHashBuilder::new()
  220|      0|            .update(self.hash().as_bytes())
  221|      0|            .update(self.voting_account.as_bytes())
  222|      0|            .update(self.signature.as_bytes())
  223|      0|            .build()
  224|      0|    }
  225|       |}
  226|       |
  227|     41|fn packed_timestamp(timestamp: u64, duration: u8) -> u64 {
  228|     41|    debug_assert!(duration <= Vote::DURATION_MAX);
  229|     41|    debug_assert!(timestamp != Vote::TIMESTAMP_MAX || duration == Vote::DURATION_MAX);
                                                                    ^5
  230|     41|    (timestamp & Vote::TIMESTAMP_MASK) | (duration as u64)
  231|     41|}
  232|       |
  233|       |#[derive(Clone, Debug)]
  234|       |pub struct VoteWithWeightInfo {
  235|       |    pub representative: PublicKey,
  236|       |    pub time: SystemTime,
  237|       |    pub timestamp: u64,
  238|       |    pub hash: BlockHash,
  239|       |    pub weight: Amount,
  240|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/cpu_work_generator.rs:
    1|       |use crate::{
    2|       |    difficulty::{Difficulty, DifficultyV1},
    3|       |    Root,
    4|       |};
    5|       |
    6|       |use super::{WorkGenerator, WorkRng, WorkTicket, XorShift1024Star};
    7|       |#[cfg(test)]
    8|       |use std::sync::{Arc, Mutex};
    9|       |use std::{thread, time::Duration};
   10|       |
   11|       |pub(crate) trait Sleeper {
   12|       |    fn sleep(&mut self, duration: Duration);
   13|       |}
   14|       |
   15|       |pub(crate) struct ThreadSleeper {}
   16|       |
   17|       |impl ThreadSleeper {
   18|      5|    pub(crate) fn new() -> Self {
   19|      5|        Self {}
   20|      5|    }
   21|       |}
   22|       |
   23|       |impl Sleeper for ThreadSleeper {
   24|      0|    fn sleep(&mut self, duration: Duration) {
   25|      0|        thread::sleep(duration);
   26|      0|    }
   27|       |}
   28|       |
   29|       |#[cfg(test)]
   30|       |pub(crate) struct StubSleeper {
   31|       |    calls: Arc<Mutex<Vec<Duration>>>,
   32|       |}
   33|       |
   34|       |#[cfg(test)]
   35|       |impl StubSleeper {
   36|       |    pub(crate) fn new() -> Self {
   37|       |        Self {
   38|       |            calls: Arc::new(Mutex::new(Vec::new())),
   39|       |        }
   40|       |    }
   41|       |
   42|       |    pub(crate) fn calls(&self) -> Vec<Duration> {
   43|       |        self.calls.lock().unwrap().clone()
   44|       |    }
   45|       |}
   46|       |
   47|       |#[cfg(test)]
   48|       |impl Sleeper for StubSleeper {
   49|       |    fn sleep(&mut self, duration: Duration) {
   50|       |        let mut lock = self.calls.lock().unwrap();
   51|       |        lock.push(duration);
   52|       |    }
   53|       |}
   54|       |
   55|       |#[cfg(test)]
   56|       |impl Clone for StubSleeper {
   57|       |    fn clone(&self) -> Self {
   58|       |        Self {
   59|       |            calls: Arc::clone(&self.calls),
   60|       |        }
   61|       |    }
   62|       |}
   63|       |
   64|       |pub(crate) struct CpuWorkGenerator<
   65|       |    Rng = XorShift1024Star,
   66|       |    Diff = DifficultyV1,
   67|       |    Sleep = ThreadSleeper,
   68|       |> where
   69|       |    Rng: WorkRng,
   70|       |    Diff: Difficulty,
   71|       |    Sleep: Sleeper,
   72|       |{
   73|       |    // Quick RNG for work attempts.
   74|       |    rng: Rng,
   75|       |    difficulty: Diff,
   76|       |    sleeper: Sleep,
   77|       |    rate_limiter: Duration,
   78|       |    pub iteration_size: usize,
   79|       |}
   80|       |
   81|       |const DEFAULT_ITERATION_SIZE: usize = 256;
   82|       |
   83|      5|pub(crate) fn create_cpu_work_generator<R, D, S>(
   84|      5|    rng: R,
   85|      5|    difficulty: D,
   86|      5|    sleeper: S,
   87|      5|    rate_limiter: Duration,
   88|      5|) -> CpuWorkGenerator<R, D, S>
   89|      5|where
   90|      5|    R: WorkRng,
   91|      5|    D: Difficulty,
   92|      5|    S: Sleeper,
   93|      5|{
   94|      5|    CpuWorkGenerator {
   95|      5|        rng,
   96|      5|        difficulty,
   97|      5|        sleeper,
   98|      5|        rate_limiter,
   99|      5|        iteration_size: DEFAULT_ITERATION_SIZE,
  100|      5|    }
  101|      5|}
  102|       |
  103|       |impl CpuWorkGenerator {
  104|      5|    pub fn new(rate_limiter: Duration) -> Self {
  105|      5|        create_cpu_work_generator(
  106|      5|            XorShift1024Star::new(),
  107|      5|            DifficultyV1::default(),
  108|      5|            ThreadSleeper::new(),
  109|      5|            rate_limiter,
  110|      5|        )
  111|      5|    }
  112|       |}
  113|       |
  114|       |// Single threaded PoW generation on the CPU
  115|       |impl<Rng, Diff, Sleep> CpuWorkGenerator<Rng, Diff, Sleep>
  116|       |where
  117|       |    Rng: WorkRng,
  118|       |    Diff: Difficulty,
  119|       |    Sleep: Sleeper,
  120|       |{
  121|  28.8k|    fn next(&mut self, item: &Root) -> (u64, u64) {
  122|  28.8k|        let work = self.rng.next_work();
  123|  28.8k|        let difficulty = self.difficulty.get_difficulty(item, work);
  124|  28.8k|        (work, difficulty)
  125|  28.8k|    }
  126|       |
  127|       |    /// Tries to create PoW in a batch of 256 iterations
  128|    129|    fn try_create_batch(&mut self, item: &Root, min_difficulty: u64) -> Option<u64> {
  129|    129|        // Don't query main memory every iteration in order to reduce memory bus traffic
  130|    129|        // All operations here operate on stack memory
  131|    129|        // Count iterations down to zero since comparing to zero is easier than comparing to another number
  132|    129|        let mut iteration = self.iteration_size;
  133|    129|        let mut work = 0;
  134|    129|        let mut difficulty = 0;
  135|  29.0k|        while iteration > 0 && difficulty < min_difficulty {
                                             ^28.9k
  136|  28.8k|            (work, difficulty) = self.next(item);
  137|  28.8k|            iteration -= 1;
  138|  28.8k|        }
  139|       |
  140|    129|        if difficulty >= min_difficulty {
  141|     32|            Some(work)
  142|       |        } else {
  143|     97|            None
  144|       |        }
  145|    129|    }
  146|       |}
  147|       |
  148|       |impl<Rng, Diff, Sleep> WorkGenerator for CpuWorkGenerator<Rng, Diff, Sleep>
  149|       |where
  150|       |    Rng: WorkRng,
  151|       |    Diff: Difficulty,
  152|       |    Sleep: Sleeper,
  153|       |{
  154|     32|    fn create(
  155|     32|        &mut self,
  156|     32|        item: &Root,
  157|     32|        min_difficulty: u64,
  158|     32|        work_ticket: &WorkTicket,
  159|     32|    ) -> Option<u64> {
  160|    129|        while !work_ticket.expired() {
  161|    129|            let result = self.try_create_batch(item, min_difficulty);
  162|    129|            if result.is_some() {
  163|     32|                return result;
  164|     97|            }
  165|     97|
  166|     97|            // Add a rate limiter (if specified) to the pow calculation to save some CPUs which don't want to operate at full throttle
  167|     97|            if !self.rate_limiter.is_zero() {
  168|      0|                self.sleeper.sleep(self.rate_limiter);
  169|     97|            }
  170|       |        }
  171|      0|        None
  172|     32|    }
  173|       |}
  174|       |
  175|       |#[cfg(test)]
  176|       |pub(crate) struct StubWorkRng {
  177|       |    preset_random_numbers: Vec<u64>,
  178|       |    index: usize,
  179|       |}
  180|       |
  181|       |#[cfg(test)]
  182|       |impl StubWorkRng {
  183|       |    pub(crate) fn new(preset_random_numbers: Vec<u64>) -> Self {
  184|       |        Self {
  185|       |            preset_random_numbers,
  186|       |            index: 0,
  187|       |        }
  188|       |    }
  189|       |}
  190|       |
  191|       |#[cfg(test)]
  192|       |impl WorkRng for StubWorkRng {
  193|       |    fn next_work(&mut self) -> u64 {
  194|       |        let result = self.preset_random_numbers[self.index];
  195|       |        self.index += 1;
  196|       |        result
  197|       |    }
  198|       |}
  199|       |
  200|       |#[cfg(test)]
  201|       |mod tests {
  202|       |    use crate::StubDifficulty;
  203|       |
  204|       |    use super::*;
  205|       |
  206|       |    #[test]
  207|       |    fn stub_work_rng() {
  208|       |        let mut rng = StubWorkRng::new(vec![1, 2, 3]);
  209|       |        assert_eq!(rng.next_work(), 1);
  210|       |        assert_eq!(rng.next_work(), 2);
  211|       |        assert_eq!(rng.next_work(), 3);
  212|       |    }
  213|       |
  214|       |    #[test]
  215|       |    #[should_panic]
  216|       |    fn stub_work_rng_out_of_bounds() {
  217|       |        let mut rng = StubWorkRng::new(vec![1]);
  218|       |        assert_eq!(rng.next_work(), 1);
  219|       |        let _ = rng.next_work();
  220|       |    }
  221|       |
  222|       |    #[test]
  223|       |    fn initialization() {
  224|       |        let rate_limiter = Duration::from_millis(100);
  225|       |        let generator = CpuWorkGenerator::new(rate_limiter);
  226|       |        assert_eq!(generator.iteration_size, 256);
  227|       |        assert_eq!(generator.rate_limiter, rate_limiter);
  228|       |    }
  229|       |
  230|       |    #[test]
  231|       |    fn create_work() {
  232|       |        let root = Root::from(1);
  233|       |        let work = 2;
  234|       |        let difficulty = 100;
  235|       |
  236|       |        let stub_rng = StubWorkRng::new(vec![work]);
  237|       |        let mut difficulty_calc = StubDifficulty::new();
  238|       |        difficulty_calc.set_difficulty(root, work, difficulty);
  239|       |        let mut generator =
  240|       |            create_cpu_work_generator(stub_rng, difficulty_calc, StubSleeper::new(), RATE_LIMIT);
  241|       |
  242|       |        let result = generator.create(&root, difficulty, &WorkTicket::never_expires());
  243|       |
  244|       |        assert_eq!(result, Some(work))
  245|       |    }
  246|       |
  247|       |    #[test]
  248|       |    fn create_work_multiple_tries() {
  249|       |        let root = Root::from(1);
  250|       |        let work = 5;
  251|       |        let difficulty = 100;
  252|       |
  253|       |        let stub_rng = StubWorkRng::new(vec![1, 2, 3, 4, work]);
  254|       |        let mut difficulty_calc = StubDifficulty::new();
  255|       |        difficulty_calc.set_difficulty(root, work, difficulty);
  256|       |
  257|       |        let sleeper = StubSleeper::new();
  258|       |        let mut generator =
  259|       |            create_cpu_work_generator(stub_rng, difficulty_calc, sleeper.clone(), RATE_LIMIT);
  260|       |
  261|       |        let result = generator.create(&root, difficulty, &WorkTicket::never_expires());
  262|       |
  263|       |        assert_eq!(result, Some(work));
  264|       |        assert!(sleeper.calls().is_empty());
  265|       |    }
  266|       |
  267|       |    #[test]
  268|       |    fn rate_limit() {
  269|       |        let root = Root::from(1);
  270|       |        let work = 5;
  271|       |        let difficulty = 100;
  272|       |
  273|       |        let stub_rng = StubWorkRng::new(vec![1, 2, 3, 4, work]);
  274|       |        let mut difficulty_calc = StubDifficulty::new();
  275|       |        difficulty_calc.set_difficulty(root, work, difficulty);
  276|       |
  277|       |        let sleeper = StubSleeper::new();
  278|       |        let mut generator =
  279|       |            create_cpu_work_generator(stub_rng, difficulty_calc, sleeper.clone(), RATE_LIMIT);
  280|       |        generator.iteration_size = 2;
  281|       |
  282|       |        let result = generator.create(&root, difficulty, &WorkTicket::never_expires());
  283|       |
  284|       |        assert_eq!(result, Some(work));
  285|       |        assert_eq!(sleeper.calls(), vec![RATE_LIMIT, RATE_LIMIT]);
  286|       |    }
  287|       |
  288|       |    #[test]
  289|       |    fn expired_work_ticket() {
  290|       |        let root = Root::from(1);
  291|       |
  292|       |        let stub_rng = StubWorkRng::new(vec![]);
  293|       |        let sleeper = StubSleeper::new();
  294|       |        let mut generator =
  295|       |            create_cpu_work_generator(stub_rng, StubDifficulty::new(), sleeper.clone(), RATE_LIMIT);
  296|       |
  297|       |        let result = generator.create(&root, 100, &WorkTicket::already_expired());
  298|       |
  299|       |        assert_eq!(result, None);
  300|       |        assert_eq!(sleeper.calls(), vec![]);
  301|       |    }
  302|       |
  303|       |    const RATE_LIMIT: Duration = Duration::from_millis(1000);
  304|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/stub_work_pool.rs:
    1|       |use super::WorkPool;
    2|       |use crate::Root;
    3|       |
    4|       |/// The StubWorkPool assumes work == difficulty
    5|       |pub struct StubWorkPool {
    6|       |    base_difficulty: u64,
    7|       |}
    8|       |
    9|       |impl StubWorkPool {
   10|      1|    pub fn new(base_difficulty: u64) -> Self {
   11|      1|        Self { base_difficulty }
   12|      1|    }
   13|       |}
   14|       |
   15|       |impl Default for StubWorkPool {
   16|      0|    fn default() -> Self {
   17|      0|        Self::new(123)
   18|      0|    }
   19|       |}
   20|       |
   21|       |impl WorkPool for StubWorkPool {
   22|      0|    fn generate_async(
   23|      0|        &self,
   24|      0|        _root: Root,
   25|      0|        difficulty: u64,
   26|      0|        done: Option<Box<dyn FnOnce(Option<u64>) + Send>>,
   27|      0|    ) {
   28|      0|        if let Some(done) = done {
   29|      0|            done(Some(difficulty))
   30|      0|        }
   31|      0|    }
   32|       |
   33|      0|    fn generate_dev(&self, _root: Root, difficulty: u64) -> Option<u64> {
   34|      0|        Some(difficulty)
   35|      0|    }
   36|       |
   37|      2|    fn generate_dev2(&self, _root: Root) -> Option<u64> {
   38|      2|        Some(self.base_difficulty)
   39|      2|    }
   40|       |
   41|      0|    fn generate(&self, _root: Root, difficulty: u64) -> Option<u64> {
   42|      0|        Some(difficulty)
   43|      0|    }
   44|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/work_pool.rs:
    1|       |use super::{
    2|       |    CpuWorkGenerator, StubWorkPool, WorkItem, WorkQueueCoordinator, WorkThread, WorkThresholds,
    3|       |    WorkTicket, WORK_THRESHOLDS_STUB,
    4|       |};
    5|       |use crate::{utils::ContainerInfo, Root};
    6|       |use std::{
    7|       |    mem::size_of,
    8|       |    sync::{Arc, Condvar, LazyLock, Mutex},
    9|       |    thread::{self, JoinHandle},
   10|       |    time::Duration,
   11|       |};
   12|       |
   13|       |pub trait WorkPool: Send + Sync {
   14|       |    fn generate_async(
   15|       |        &self,
   16|       |        root: Root,
   17|       |        difficulty: u64,
   18|       |        done: Option<Box<dyn FnOnce(Option<u64>) + Send>>,
   19|       |    );
   20|       |
   21|       |    fn generate_dev(&self, root: Root, difficulty: u64) -> Option<u64>;
   22|       |
   23|       |    fn generate_dev2(&self, root: Root) -> Option<u64>;
   24|       |
   25|       |    fn generate(&self, root: Root, difficulty: u64) -> Option<u64>;
   26|       |}
   27|       |
   28|       |pub struct WorkPoolImpl {
   29|       |    threads: Vec<JoinHandle<()>>,
   30|       |    work_queue: Arc<WorkQueueCoordinator>,
   31|       |    work_thresholds: WorkThresholds,
   32|       |    pow_rate_limiter: Duration,
   33|       |}
   34|       |
   35|       |impl WorkPoolImpl {
   36|      5|    pub fn new(
   37|      5|        work_thresholds: WorkThresholds,
   38|      5|        thread_count: usize,
   39|      5|        pow_rate_limiter: Duration,
   40|      5|    ) -> Self {
   41|      5|        let mut pool = Self {
   42|      5|            threads: Vec::new(),
   43|      5|            work_queue: Arc::new(WorkQueueCoordinator::new()),
   44|      5|            work_thresholds,
   45|      5|            pow_rate_limiter,
   46|      5|        };
   47|      5|
   48|      5|        pool.spawn_threads(thread_count);
   49|      5|        pool
   50|      5|    }
   51|       |
   52|      2|    pub fn new_dev() -> Self {
   53|      2|        Self::new(WorkThresholds::publish_dev().clone(), 1, Duration::ZERO)
   54|      2|    }
   55|       |
   56|      1|    pub fn new_null(configured_work: u64) -> Self {
   57|      1|        let mut pool = Self {
   58|      1|            threads: Vec::new(),
   59|      1|            work_queue: Arc::new(WorkQueueCoordinator::new()),
   60|      1|            work_thresholds: WORK_THRESHOLDS_STUB.clone(),
   61|      1|            pow_rate_limiter: Duration::ZERO,
   62|      1|        };
   63|      1|
   64|      1|        pool.threads
   65|      1|            .push(pool.spawn_stub_worker_thread(configured_work));
   66|      1|        pool
   67|      1|    }
   68|       |
   69|      0|    pub fn disabled() -> Self {
   70|      0|        Self {
   71|      0|            threads: Vec::new(),
   72|      0|            work_queue: Arc::new(WorkQueueCoordinator::new()),
   73|      0|            work_thresholds: WORK_THRESHOLDS_STUB.clone(),
   74|      0|            pow_rate_limiter: Duration::ZERO,
   75|      0|        }
   76|      0|    }
   77|       |
   78|      5|    fn spawn_threads(&mut self, thread_count: usize) {
   79|      5|        for _ in 0..thread_count {
   80|      5|            self.threads.push(self.spawn_cpu_worker_thread())
   81|       |        }
   82|      5|    }
   83|       |
   84|      5|    fn spawn_cpu_worker_thread(&self) -> JoinHandle<()> {
   85|      5|        self.spawn_worker_thread(CpuWorkGenerator::new(self.pow_rate_limiter))
   86|      5|    }
   87|       |
   88|      1|    fn spawn_stub_worker_thread(&self, configured_work: u64) -> JoinHandle<()> {
   89|      1|        self.spawn_worker_thread(StubWorkGenerator(configured_work))
   90|      1|    }
   91|       |
   92|      6|    fn spawn_worker_thread<T>(&self, work_generator: T) -> JoinHandle<()>
   93|      6|    where
   94|      6|        T: WorkGenerator + Send + Sync + 'static,
   95|      6|    {
   96|      6|        let work_queue = Arc::clone(&self.work_queue);
   97|      6|        thread::Builder::new()
   98|      6|            .name("Work pool".to_string())
   99|      6|            .spawn(move || {
  100|      6|                WorkThread::new(work_generator, work_queue).work_loop();
  101|      6|            })
  102|      6|            .unwrap()
  103|      6|    }
  104|       |
  105|      0|    pub fn has_opencl(&self) -> bool {
  106|      0|        false
  107|      0|    }
  108|       |
  109|      3|    pub fn work_generation_enabled(&self) -> bool {
  110|      3|        !self.threads.is_empty()
  111|      3|    }
  112|       |
  113|      0|    pub fn cancel(&self, root: &Root) {
  114|      0|        self.work_queue.cancel(root);
  115|      0|    }
  116|       |
  117|      6|    pub fn stop(&self) {
  118|      6|        self.work_queue.stop();
  119|      6|    }
  120|       |
  121|      0|    pub fn size(&self) -> usize {
  122|      0|        self.work_queue.lock_work_queue().len()
  123|      0|    }
  124|       |
  125|      0|    pub fn pending_value_size() -> usize {
  126|      0|        size_of::<WorkItem>()
  127|      0|    }
  128|       |
  129|      0|    pub fn thread_count(&self) -> usize {
  130|      0|        self.threads.len()
  131|      0|    }
  132|       |
  133|      0|    pub fn threshold_base(&self) -> u64 {
  134|      0|        self.work_thresholds.threshold_base()
  135|      0|    }
  136|       |
  137|      0|    pub fn difficulty(&self, root: &Root, work: u64) -> u64 {
  138|      0|        self.work_thresholds.difficulty(root, work)
  139|      0|    }
  140|       |
  141|      0|    pub fn container_info(&self) -> ContainerInfo {
  142|      0|        [("pending", self.size(), Self::pending_value_size())].into()
  143|      0|    }
  144|       |}
  145|       |
  146|       |impl WorkPool for WorkPoolImpl {
  147|     33|    fn generate_async(
  148|     33|        &self,
  149|     33|        root: Root,
  150|     33|        difficulty: u64,
  151|     33|        done: Option<Box<dyn FnOnce(Option<u64>) + Send>>,
  152|     33|    ) {
  153|     33|        debug_assert!(!root.is_zero());
  154|     33|        if !self.threads.is_empty() {
  155|     33|            self.work_queue.enqueue(WorkItem {
  156|     33|                item: root,
  157|     33|                min_difficulty: difficulty,
  158|     33|                callback: done,
  159|     33|            });
  160|     33|        } else if let Some(callback) = done {
                                         ^0          ^0
  161|      0|            callback(None);
  162|      0|        }
  163|     33|    }
  164|       |
  165|      0|    fn generate_dev(&self, root: Root, difficulty: u64) -> Option<u64> {
  166|      0|        self.generate(root, difficulty)
  167|      0|    }
  168|       |
  169|     32|    fn generate_dev2(&self, root: Root) -> Option<u64> {
  170|     32|        self.generate(root, self.work_thresholds.base)
  171|     32|    }
  172|       |
  173|     32|    fn generate(&self, root: Root, difficulty: u64) -> Option<u64> {
  174|     32|        if self.threads.is_empty() {
  175|      0|            return None;
  176|     32|        }
  177|     32|
  178|     32|        let done_notifier = WorkDoneNotifier::new();
  179|     32|        let done_notifier_clone = done_notifier.clone();
  180|     32|
  181|     32|        self.generate_async(
  182|     32|            root,
  183|     32|            difficulty,
  184|     32|            Some(Box::new(move |work| {
  185|     32|                done_notifier_clone.signal_done(work);
  186|     32|            })),
  187|     32|        );
  188|     32|
  189|     32|        done_notifier.wait()
  190|     32|    }
  191|       |}
  192|       |
  193|       |#[derive(Default)]
  194|       |struct WorkDoneState {
  195|       |    work: Option<u64>,
  196|       |    done: bool,
  197|       |}
  198|       |
  199|       |#[derive(Clone)]
  200|       |struct WorkDoneNotifier {
  201|       |    state: Arc<(Mutex<WorkDoneState>, Condvar)>,
  202|       |}
  203|       |
  204|       |impl WorkDoneNotifier {
  205|     32|    fn new() -> Self {
  206|     32|        Self {
  207|     32|            state: Arc::new((Mutex::new(WorkDoneState::default()), Condvar::new())),
  208|     32|        }
  209|     32|    }
  210|       |
  211|     32|    fn signal_done(&self, work: Option<u64>) {
  212|     32|        {
  213|     32|            let mut lock = self.state.0.lock().unwrap();
  214|     32|            lock.work = work;
  215|     32|            lock.done = true;
  216|     32|        }
  217|     32|        self.state.1.notify_one();
  218|     32|    }
  219|       |
  220|     32|    fn wait(&self) -> Option<u64> {
  221|     32|        let mut lock = self.state.0.lock().unwrap();
  222|       |        loop {
  223|     64|            if lock.done {
  224|     32|                return lock.work;
  225|     32|            }
  226|     32|            lock = self.state.1.wait(lock).unwrap();
  227|       |        }
  228|     32|    }
  229|       |}
  230|       |
  231|       |impl Drop for WorkPoolImpl {
  232|      6|    fn drop(&mut self) {
  233|      6|        self.stop();
  234|      6|        for handle in self.threads.drain(..) {
  235|      6|            handle.join().unwrap();
  236|      6|        }
  237|      6|    }
  238|       |}
  239|       |
  240|       |pub(crate) trait WorkGenerator {
  241|       |    fn create(&mut self, item: &Root, min_difficulty: u64, work_ticket: &WorkTicket)
  242|       |        -> Option<u64>;
  243|       |}
  244|       |
  245|       |struct StubWorkGenerator(u64);
  246|       |
  247|       |impl WorkGenerator for StubWorkGenerator {
  248|      1|    fn create(
  249|      1|        &mut self,
  250|      1|        _item: &Root,
  251|      1|        _min_difficulty: u64,
  252|      1|        _work_ticket: &WorkTicket,
  253|      1|    ) -> Option<u64> {
  254|      1|        Some(self.0)
  255|      1|    }
  256|       |}
  257|       |
  258|       |pub static STUB_WORK_POOL: LazyLock<StubWorkPool> =
  259|      1|    LazyLock::new(|| StubWorkPool::new(WorkThresholds::publish_dev().base));
  260|       |
  261|       |#[cfg(test)]
  262|       |mod tests {
  263|       |    use super::*;
  264|       |    use crate::{Block, TestBlockBuilder};
  265|       |    use std::sync::mpsc;
  266|       |
  267|       |    pub static WORK_POOL: LazyLock<WorkPoolImpl> = LazyLock::new(|| {
  268|       |        WorkPoolImpl::new(
  269|       |            WorkThresholds::publish_dev().clone(),
  270|       |            crate::utils::get_cpu_count(),
  271|       |            Duration::ZERO,
  272|       |        )
  273|       |    });
  274|       |
  275|       |    #[test]
  276|       |    fn work_disabled() {
  277|       |        let pool = WorkPoolImpl::new(WorkThresholds::publish_dev().clone(), 0, Duration::ZERO);
  278|       |        let result = pool.generate_dev2(Root::from(1));
  279|       |        assert_eq!(result, None);
  280|       |    }
  281|       |
  282|       |    #[test]
  283|       |    fn work_one() {
  284|       |        let pool = &WORK_POOL;
  285|       |        let mut block = TestBlockBuilder::state().build();
  286|       |        let root = block.root();
  287|       |        block.set_work(pool.generate_dev2(root).unwrap());
  288|       |        assert!(pool.threshold_base() < difficulty(&block));
  289|       |    }
  290|       |
  291|       |    #[test]
  292|       |    fn work_validate() {
  293|       |        let pool = &WORK_POOL;
  294|       |        let mut block = TestBlockBuilder::legacy_send().work(6).build();
  295|       |        assert!(difficulty(&block) < pool.threshold_base());
  296|       |        let root = block.root();
  297|       |        block
  298|       |            .as_block_mut()
  299|       |            .set_work(pool.generate_dev2(root).unwrap());
  300|       |        assert!(difficulty(&block) > pool.threshold_base());
  301|       |    }
  302|       |
  303|       |    #[test]
  304|       |    fn work_cancel() {
  305|       |        let (tx, rx) = mpsc::channel();
  306|       |        let key = Root::from(12345);
  307|       |        WORK_POOL.generate_async(
  308|       |            key,
  309|       |            WorkThresholds::publish_dev().base,
  310|       |            Some(Box::new(move |_done| {
  311|       |                tx.send(()).unwrap();
  312|       |            })),
  313|       |        );
  314|       |        WORK_POOL.cancel(&key);
  315|       |        assert_eq!(rx.recv_timeout(Duration::from_secs(2)), Ok(()))
  316|       |    }
  317|       |
  318|       |    #[test]
  319|       |    fn work_difficulty() {
  320|       |        let root = Root::from(1);
  321|       |        let difficulty1 = 0xff00000000000000;
  322|       |        let difficulty2 = 0xfff0000000000000;
  323|       |        let difficulty3 = 0xffff000000000000;
  324|       |        let mut result_difficulty = u64::MAX;
  325|       |
  326|       |        while result_difficulty > difficulty2 {
  327|       |            let work = WORK_POOL.generate(root, difficulty1).unwrap();
  328|       |            result_difficulty = WorkThresholds::publish_dev().difficulty(&root, work);
  329|       |        }
  330|       |        assert!(result_difficulty > difficulty1);
  331|       |
  332|       |        result_difficulty = u64::MAX;
  333|       |        while result_difficulty > difficulty3 {
  334|       |            let work = WORK_POOL.generate(root, difficulty2).unwrap();
  335|       |            result_difficulty = WorkThresholds::publish_dev().difficulty(&root, work);
  336|       |        }
  337|       |        assert!(result_difficulty > difficulty2);
  338|       |    }
  339|       |
  340|       |    fn difficulty(block: &Block) -> u64 {
  341|       |        WorkThresholds::publish_dev().difficulty_block(block)
  342|       |    }
  343|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/work_queue.rs:
    1|       |use crate::Root;
    2|       |use std::sync::{
    3|       |    atomic::{AtomicBool, AtomicI32, Ordering},
    4|       |    Condvar, Mutex, MutexGuard,
    5|       |};
    6|       |
    7|       |static NEVER_EXPIRES: AtomicI32 = AtomicI32::new(0);
    8|       |
    9|       |#[derive(Clone)]
   10|       |pub struct WorkTicket<'a> {
   11|       |    ticket: &'a AtomicI32,
   12|       |    ticket_copy: i32,
   13|       |}
   14|       |
   15|       |impl<'a> WorkTicket<'a> {
   16|      0|    pub fn never_expires() -> Self {
   17|      0|        Self::new(&NEVER_EXPIRES)
   18|      0|    }
   19|       |
   20|      0|    pub fn already_expired() -> Self {
   21|      0|        Self {
   22|      0|            ticket: &NEVER_EXPIRES,
   23|      0|            ticket_copy: 1,
   24|      0|        }
   25|      0|    }
   26|       |
   27|     33|    pub fn new(ticket: &'a AtomicI32) -> Self {
   28|     33|        Self {
   29|     33|            ticket,
   30|     33|            ticket_copy: ticket.load(Ordering::SeqCst),
   31|     33|        }
   32|     33|    }
   33|       |
   34|    162|    pub fn expired(&self) -> bool {
   35|    162|        self.ticket_copy != self.ticket.load(Ordering::SeqCst)
   36|    162|    }
   37|       |}
   38|       |
   39|       |pub(crate) struct WorkItem {
   40|       |    pub item: Root,
   41|       |    pub min_difficulty: u64,
   42|       |    pub callback: Option<Box<dyn FnOnce(Option<u64>) + Send>>,
   43|       |}
   44|       |
   45|       |impl WorkItem {
   46|     33|    pub fn work_found(&mut self, work: u64) {
   47|       |        // we're the ones that found the solution
   48|     33|        if let Some(callback) = self.callback.take() {
   49|     33|            (callback)(Some(work));
   50|     33|        }
                       ^0
   51|     33|    }
   52|       |}
   53|       |
   54|       |pub(crate) struct WorkQueue(Vec<WorkItem>);
   55|       |
   56|       |impl WorkQueue {
   57|      6|    pub fn new() -> Self {
   58|      6|        WorkQueue(Vec::new())
   59|      6|    }
   60|       |
   61|     71|    pub fn first(&self) -> Option<&WorkItem> {
   62|     71|        self.0.first()
   63|     71|    }
   64|       |
   65|      0|    pub fn is_first(&self, root: &Root) -> bool {
   66|      0|        if let Some(front) = self.first() {
   67|      0|            front.item == *root
   68|       |        } else {
   69|      0|            false
   70|       |        }
   71|      0|    }
   72|       |
   73|      0|    pub fn cancel(&mut self, root: &Root) -> Vec<Box<dyn FnOnce(Option<u64>) + Send>> {
   74|      0|        let mut cancelled = Vec::new();
   75|      0|        self.0.retain_mut(|item| {
   76|      0|            let retain = item.item != *root;
   77|      0|            if !retain {
   78|      0|                if let Some(callback) = item.callback.take() {
   79|      0|                    cancelled.push(callback);
   80|      0|                }
   81|      0|            }
   82|      0|            retain
   83|      0|        });
   84|      0|        cancelled
   85|      0|    }
   86|       |
   87|     33|    pub fn enqueue(&mut self, item: WorkItem) {
   88|     33|        self.0.push(item);
   89|     33|    }
   90|       |
   91|     33|    pub fn dequeue(&mut self) -> WorkItem {
   92|     33|        self.0.remove(0)
   93|     33|    }
   94|       |
   95|      0|    pub fn len(&self) -> usize {
   96|      0|        self.0.len()
   97|      0|    }
   98|       |}
   99|       |
  100|       |/// Coordinates access to the work queue between multiple threads
  101|       |pub(crate) struct WorkQueueCoordinator {
  102|       |    work_queue: Mutex<WorkQueue>,
  103|       |    should_stop: AtomicBool,
  104|       |    producer_condition: Condvar,
  105|       |    ticket: AtomicI32,
  106|       |}
  107|       |
  108|       |impl WorkQueueCoordinator {
  109|      6|    pub fn new() -> Self {
  110|      6|        Self {
  111|      6|            work_queue: Mutex::new(WorkQueue::new()),
  112|      6|            should_stop: AtomicBool::new(false),
  113|      6|            producer_condition: Condvar::new(),
  114|      6|            ticket: AtomicI32::new(0),
  115|      6|        }
  116|      6|    }
  117|       |
  118|     77|    pub fn should_stop(&self) -> bool {
  119|     77|        self.should_stop.load(Ordering::Relaxed)
  120|     77|    }
  121|       |
  122|     72|    pub fn lock_work_queue(&self) -> MutexGuard<WorkQueue> {
  123|     72|        self.work_queue.lock().unwrap()
  124|     72|    }
  125|       |
  126|     38|    pub fn wait_for_new_work_item<'a>(
  127|     38|        &'a self,
  128|     38|        guard: MutexGuard<'a, WorkQueue>,
  129|     38|    ) -> MutexGuard<'a, WorkQueue> {
  130|     38|        self.producer_condition.wait(guard).unwrap()
  131|     38|    }
  132|       |
  133|     33|    pub fn enqueue(&self, work_item: WorkItem) {
  134|     33|        {
  135|     33|            let mut pending = self.work_queue.lock().unwrap();
  136|     33|            pending.enqueue(work_item)
  137|     33|        }
  138|     33|        self.producer_condition.notify_all();
  139|     33|    }
  140|       |
  141|      6|    pub fn notify_new_work_ticket(&self) {
  142|      6|        self.producer_condition.notify_all()
  143|      6|    }
  144|       |
  145|      6|    pub fn stop(&self) {
  146|      6|        self.should_stop.store(true, Ordering::Relaxed);
  147|      6|        self.expire_work_tickets();
  148|      6|        self.notify_new_work_ticket();
  149|      6|    }
  150|       |
  151|     33|    pub fn create_work_ticket(&'_ self) -> WorkTicket<'_> {
  152|     33|        WorkTicket::new(&self.ticket)
  153|     33|    }
  154|       |
  155|     39|    pub fn expire_work_tickets(&self) {
  156|     39|        self.ticket.fetch_add(1, Ordering::SeqCst);
  157|     39|    }
  158|       |
  159|      0|    pub fn cancel(&self, root: &Root) {
  160|      0|        let mut cancelled = Vec::new();
  161|      0|        {
  162|      0|            let mut lock = self.lock_work_queue();
  163|      0|            if !self.should_stop() {
  164|      0|                if lock.is_first(root) {
  165|      0|                    self.expire_work_tickets();
  166|      0|                }
  167|       |
  168|      0|                cancelled = lock.cancel(root);
  169|      0|            }
  170|       |        }
  171|       |
  172|      0|        for callback in cancelled {
  173|      0|            callback(None);
  174|      0|        }
  175|      0|    }
  176|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/work_thread.rs:
    1|       |use super::{work_queue::WorkQueue, WorkGenerator, WorkQueueCoordinator, WorkTicket};
    2|       |use std::sync::{Arc, MutexGuard};
    3|       |
    4|       |pub(crate) struct WorkThread<T>
    5|       |where
    6|       |    T: WorkGenerator + Send + Sync,
    7|       |{
    8|       |    work_queue: Arc<WorkQueueCoordinator>,
    9|       |    work_generator: T,
   10|       |}
   11|       |
   12|       |/// A single thread to generate PoW
   13|       |impl<T> WorkThread<T>
   14|       |where
   15|       |    T: WorkGenerator + Send + Sync,
   16|       |{
   17|      6|    pub fn new(work_generator: T, work_queue: Arc<WorkQueueCoordinator>) -> Self {
   18|      6|        Self {
   19|      6|            work_generator,
   20|      6|            work_queue,
   21|      6|        }
   22|      6|    }
   23|       |
   24|      6|    pub fn work_loop(mut self) {
   25|      6|        let mut queue_lock = self.work_queue.lock_work_queue();
   26|     77|        while !self.work_queue.should_stop() {
   27|     71|            if let Some(current) = queue_lock.first() {
                                      ^33
   28|     33|                let item = current.item;
   29|     33|                let min_difficulty = current.min_difficulty;
   30|     33|                let work_ticket = self.work_queue.create_work_ticket();
   31|     33|
   32|     33|                // drop work_queue lock, because work generation will take some time
   33|     33|                drop(queue_lock);
   34|     33|
   35|     33|                let result = self
   36|     33|                    .work_generator
   37|     33|                    .create(&item, min_difficulty, &work_ticket);
   38|     33|
   39|     33|                queue_lock = Self::handle_work_result(result, &self.work_queue, &work_ticket);
   40|     38|            } else {
   41|     38|                queue_lock = self.work_queue.wait_for_new_work_item(queue_lock);
   42|     38|            }
   43|       |        }
   44|      6|    }
   45|       |
   46|     33|    fn handle_work_result<'a>(
   47|     33|        result: Option<u64>,
   48|     33|        work_queue: &'a WorkQueueCoordinator,
   49|     33|        work_ticket: &WorkTicket,
   50|     33|    ) -> MutexGuard<'a, WorkQueue> {
   51|     33|        let mut queue_lock = work_queue.lock_work_queue();
   52|     33|        if let Some(work) = result {
   53|     33|            if !work_ticket.expired() {
   54|     33|                queue_lock = Self::notify_work_found(work_queue, queue_lock, work);
   55|     33|            }
                           ^0
   56|      0|        } else {
   57|      0|            // A different thread found a solution
   58|      0|        }
   59|       |
   60|     33|        queue_lock
   61|     33|    }
   62|       |
   63|     33|    fn notify_work_found<'a>(
   64|     33|        work_queue: &'a WorkQueueCoordinator,
   65|     33|        mut queue_lock: MutexGuard<'a, WorkQueue>,
   66|     33|        work: u64,
   67|     33|    ) -> MutexGuard<'a, WorkQueue> {
   68|     33|        // Signal other threads to stop their work next time they check their ticket
   69|     33|        work_queue.expire_work_tickets();
   70|     33|        let mut current = queue_lock.dequeue();
   71|     33|
   72|     33|        // work_found callback can take some time, to let's drop the lock
   73|     33|        drop(queue_lock);
   74|     33|        current.work_found(work);
   75|     33|        work_queue.lock_work_queue()
   76|     33|    }
   77|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/work_thresholds.rs:
    1|       |use crate::{
    2|       |    Block, BlockDetails, BlockType, Difficulty, DifficultyV1, Epoch, Networks, Root, StubDifficulty,
    3|       |};
    4|       |use std::{
    5|       |    cmp::{max, min},
    6|       |    sync::LazyLock,
    7|       |};
    8|       |
    9|       |pub static WORK_THRESHOLDS_STUB: LazyLock<WorkThresholds> = LazyLock::new(WorkThresholds::new_stub);
   10|       |
   11|       |pub struct WorkThresholds {
   12|       |    pub epoch_1: u64,
   13|       |    pub epoch_2: u64,
   14|       |    pub epoch_2_receive: u64,
   15|       |
   16|       |    // Automatically calculated. The base threshold is the maximum of all thresholds and is used for all work multiplier calculations
   17|       |    pub base: u64,
   18|       |
   19|       |    // Automatically calculated. The entry threshold is the minimum of all thresholds and defines the required work to enter the node, but does not guarantee a block is processed
   20|       |    pub entry: u64,
   21|       |    pub difficulty: Box<dyn Difficulty>,
   22|       |}
   23|       |
   24|       |impl Clone for WorkThresholds {
   25|    210|    fn clone(&self) -> Self {
   26|    210|        Self {
   27|    210|            epoch_1: self.epoch_1,
   28|    210|            epoch_2: self.epoch_2,
   29|    210|            epoch_2_receive: self.epoch_2_receive,
   30|    210|            base: self.base,
   31|    210|            entry: self.entry,
   32|    210|            difficulty: self.difficulty.clone(),
   33|    210|        }
   34|    210|    }
   35|       |}
   36|       |
   37|       |impl PartialEq for WorkThresholds {
   38|      1|    fn eq(&self, other: &Self) -> bool {
   39|      1|        self.epoch_1 == other.epoch_1
   40|      1|            && self.epoch_2 == other.epoch_2
   41|      1|            && self.epoch_2_receive == other.epoch_2_receive
   42|      1|            && self.base == other.base
   43|      1|            && self.entry == other.entry
   44|      1|            && self.difficulty.get_difficulty(&Root::default(), 0)
   45|      1|                == other.difficulty.get_difficulty(&Root::default(), 0)
   46|      1|    }
   47|       |}
   48|       |
   49|       |impl std::fmt::Debug for WorkThresholds {
   50|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   51|      0|        f.debug_struct("WorkThresholds")
   52|      0|            .field("epoch_1", &self.epoch_1)
   53|      0|            .field("epoch_2", &self.epoch_2)
   54|      0|            .field("epoch_2_receive", &self.epoch_2_receive)
   55|      0|            .field("base", &self.base)
   56|      0|            .field("entry", &self.entry)
   57|      0|            .finish()
   58|      0|    }
   59|       |}
   60|       |
   61|      1|static PUBLISH_FULL: LazyLock<WorkThresholds> = LazyLock::new(|| {
   62|      1|    WorkThresholds::new(
   63|      1|        0xffffffc000000000,
   64|      1|        0xfffffff800000000, // 8x higher than epoch_1
   65|      1|        0xfffffe0000000000, // 8x lower than epoch_1
   66|      1|    )
   67|      1|});
   68|       |
   69|      1|static PUBLISH_BETA: LazyLock<WorkThresholds> = LazyLock::new(|| {
   70|      1|    WorkThresholds::new(
   71|      1|        0xfffff00000000000, // 64x lower than publish_full.epoch_1
   72|      1|        0xfffff00000000000, // same as epoch_1
   73|      1|        0xffffe00000000000, // 2x lower than epoch_1
   74|      1|    )
   75|      1|});
   76|       |
   77|      1|static PUBLISH_DEV: LazyLock<WorkThresholds> = LazyLock::new(|| {
   78|      1|    WorkThresholds::new(
   79|      1|        0xfe00000000000000, // Very low for tests
   80|      1|        0xffc0000000000000, // 8x higher than epoch_1
   81|      1|        0xf000000000000000, // 8x lower than epoch_1
   82|      1|    )
   83|      1|});
   84|       |
   85|      0|static PUBLISH_TEST: LazyLock<WorkThresholds> = LazyLock::new(|| {
   86|      0|    WorkThresholds::new(
   87|      0|        get_env_threshold_or_default("NANO_TEST_EPOCH_1", 0xffffffc000000000),
   88|      0|        get_env_threshold_or_default("NANO_TEST_EPOCH_2", 0xfffffff800000000), // 8x higher than epoch_1
   89|      0|        get_env_threshold_or_default("NANO_TEST_EPOCH_2_RECV", 0xfffffe0000000000), // 8x lower than epoch_1
   90|      0|    )
   91|      0|});
   92|       |
   93|      0|fn get_env_threshold_or_default(variable_name: &str, default_value: u64) -> u64 {
   94|      0|    match std::env::var(variable_name) {
   95|      0|        Ok(value) => parse_hex_u64(value).expect("could not parse difficulty env var"),
   96|      0|        Err(_) => default_value,
   97|       |    }
   98|      0|}
   99|       |
  100|      0|fn parse_hex_u64(value: impl AsRef<str>) -> Result<u64, std::num::ParseIntError> {
  101|      0|    let s = value.as_ref();
  102|      0|    let s = s.strip_prefix("0x").unwrap_or(s);
  103|      0|    u64::from_str_radix(s, 16)
  104|      0|}
  105|       |
  106|       |impl WorkThresholds {
  107|      1|    pub fn publish_full() -> &'static WorkThresholds {
  108|      1|        &PUBLISH_FULL
  109|      1|    }
  110|       |
  111|      4|    pub fn publish_beta() -> &'static WorkThresholds {
  112|      4|        &PUBLISH_BETA
  113|      4|    }
  114|       |
  115|      9|    pub fn publish_dev() -> &'static WorkThresholds {
  116|      9|        &PUBLISH_DEV
  117|      9|    }
  118|       |
  119|      0|    pub fn publish_test() -> &'static WorkThresholds {
  120|      0|        &PUBLISH_TEST
  121|      0|    }
  122|       |}
  123|       |
  124|       |impl WorkThresholds {
  125|      3|    pub fn new(epoch_1: u64, epoch_2: u64, epoch_2_receive: u64) -> Self {
  126|      3|        Self::with_difficulty(
  127|      3|            Box::<DifficultyV1>::default(),
  128|      3|            epoch_1,
  129|      3|            epoch_2,
  130|      3|            epoch_2_receive,
  131|      3|        )
  132|      3|    }
  133|       |
  134|      0|    pub fn default_for(network: Networks) -> Self {
  135|      0|        match network {
  136|      0|            Networks::NanoDevNetwork => Self::publish_dev().clone(),
  137|      0|            Networks::NanoBetaNetwork => Self::publish_beta().clone(),
  138|      0|            Networks::NanoLiveNetwork => Self::publish_full().clone(),
  139|      0|            Networks::NanoTestNetwork => Self::publish_test().clone(),
  140|       |            Networks::Invalid => {
  141|      0|                panic!("no default network set")
  142|       |            }
  143|       |        }
  144|      0|    }
  145|       |
  146|      2|    pub fn new_stub() -> Self {
  147|      2|        WorkThresholds::with_difficulty(
  148|      2|            Box::new(StubDifficulty::new()),
  149|      2|            0xfe00000000000000, // Very low for tests
  150|      2|            0xffc0000000000000, // 8x higher than epoch_1
  151|      2|            0xf000000000000000, // 8x lower than epoch_1
  152|      2|        )
  153|      2|    }
  154|       |
  155|      5|    pub fn with_difficulty(
  156|      5|        difficulty: Box<dyn Difficulty>,
  157|      5|        epoch_1: u64,
  158|      5|        epoch_2: u64,
  159|      5|        epoch_2_receive: u64,
  160|      5|    ) -> Self {
  161|      5|        Self {
  162|      5|            epoch_1,
  163|      5|            epoch_2,
  164|      5|            epoch_2_receive,
  165|      5|            base: max(max(epoch_1, epoch_2), epoch_2_receive),
  166|      5|            entry: min(min(epoch_1, epoch_2), epoch_2_receive),
  167|      5|            difficulty,
  168|      5|        }
  169|      5|    }
  170|       |
  171|      1|    pub fn threshold_entry(&self, block_type: BlockType) -> u64 {
  172|      1|        match block_type {
  173|      1|            BlockType::State => self.entry,
  174|      0|            _ => self.epoch_1,
  175|       |        }
  176|      1|    }
  177|       |
  178|     32|    pub fn threshold(&self, details: &BlockDetails) -> u64 {
  179|     32|        match details.epoch {
  180|       |            Epoch::Epoch2 => {
  181|      0|                if details.is_receive || details.is_epoch {
  182|      0|                    self.epoch_2_receive
  183|       |                } else {
  184|      0|                    self.epoch_2
  185|       |                }
  186|       |            }
  187|     32|            Epoch::Epoch1 | Epoch::Epoch0 => self.epoch_1,
  188|       |            _ => {
  189|      0|                debug_assert!(
  190|      0|                    false,
  191|      0|                    "Invalid epoch specified to work_v1 ledger work_threshold"
  192|       |                );
  193|      0|                u64::MAX
  194|       |            }
  195|       |        }
  196|     32|    }
  197|       |
  198|      3|    pub fn threshold_base(&self) -> u64 {
  199|      3|        self.base
  200|      3|    }
  201|       |
  202|      0|    pub fn normalized_multiplier(&self, multiplier: f64, threshold: u64) -> f64 {
  203|      0|        debug_assert!(multiplier >= 1f64);
  204|       |        /* Normalization rules
  205|       |        ratio = multiplier of max work threshold (send epoch 2) from given threshold
  206|       |        i.e. max = 0xfe00000000000000, given = 0xf000000000000000, ratio = 8.0
  207|       |        normalized = (multiplier + (ratio - 1)) / ratio;
  208|       |        Epoch 1
  209|       |        multiplier	 | normalized
  210|       |        1.0 		 | 1.0
  211|       |        9.0 		 | 2.0
  212|       |        25.0 		 | 4.0
  213|       |        Epoch 2 (receive / epoch subtypes)
  214|       |        multiplier	 | normalized
  215|       |        1.0 		 | 1.0
  216|       |        65.0 		 | 2.0
  217|       |        241.0 		 | 4.0
  218|       |        */
  219|      0|        if threshold == self.epoch_1 || threshold == self.epoch_2_receive {
  220|      0|            let ratio = DifficultyV1::to_multiplier(self.epoch_2, threshold);
  221|      0|            debug_assert!(ratio >= 1f64);
  222|      0|            let result = (multiplier + (ratio - 1f64)) / ratio;
  223|      0|            debug_assert!(result >= 1f64);
  224|      0|            result
  225|       |        } else {
  226|      0|            multiplier
  227|       |        }
  228|      0|    }
  229|       |
  230|      0|    pub fn denormalized_multiplier(&self, multiplier: f64, threshold: u64) -> f64 {
  231|      0|        debug_assert!(multiplier >= 1f64);
  232|      0|        if threshold == self.epoch_1 || threshold == self.epoch_2_receive {
  233|      0|            let ratio = DifficultyV1::to_multiplier(self.epoch_2, threshold);
  234|      0|            debug_assert!(ratio >= 1f64);
  235|      0|            let result = multiplier * ratio + 1f64 - ratio;
  236|      0|            debug_assert!(result >= 1f64);
  237|      0|            result
  238|       |        } else {
  239|      0|            multiplier
  240|       |        }
  241|      0|    }
  242|       |
  243|     33|    pub fn difficulty(&self, root: &Root, work: u64) -> u64 {
  244|     33|        self.difficulty.get_difficulty(root, work)
  245|     33|    }
  246|       |
  247|     33|    pub fn difficulty_block(&self, block: &Block) -> u64 {
  248|     33|        self.difficulty(&block.root(), block.work())
  249|     33|    }
  250|       |
  251|      0|    pub fn validate_entry(&self, root: &Root, work: u64) -> bool {
  252|      0|        self.difficulty(root, work) >= self.threshold_entry(BlockType::State)
  253|      0|    }
  254|       |
  255|      1|    pub fn validate_entry_block(&self, block: &Block) -> bool {
  256|      1|        let difficulty = self.difficulty_block(block);
  257|      1|        let threshold = self.threshold_entry(block.block_type());
  258|      1|        difficulty >= threshold
  259|      1|    }
  260|       |
  261|     32|    pub fn is_valid_pow(&self, block: &Block, details: &BlockDetails) -> bool {
  262|     32|        self.difficulty_block(block) >= self.threshold(details)
  263|     32|    }
  264|       |}
  265|       |
  266|       |#[cfg(test)]
  267|       |mod tests {
  268|       |    use super::*;
  269|       |    use crate::{Amount, BlockHash, JsonBlock};
  270|       |
  271|       |    #[test]
  272|       |    fn test_parse_threshold() {
  273|       |        assert_eq!(parse_hex_u64("0xffffffc000000000"), Ok(0xffffffc000000000));
  274|       |        assert_eq!(parse_hex_u64("0xFFFFFFC000000000"), Ok(0xffffffc000000000));
  275|       |        assert_eq!(parse_hex_u64("FFFFFFC000000000"), Ok(0xffffffc000000000));
  276|       |    }
  277|       |
  278|       |    #[test]
  279|       |    fn difficulty_block() {
  280|       |        let block = Block::new_test_instance();
  281|       |        assert_eq!(
  282|       |            WorkThresholds::publish_full().difficulty_block(&block),
  283|       |            9665579333895977632
  284|       |        );
  285|       |    }
  286|       |
  287|       |    #[test]
  288|       |    fn threshold_epoch0_send() {
  289|       |        assert_eq!(
  290|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  291|       |                epoch: Epoch::Epoch0,
  292|       |                is_send: true,
  293|       |                is_receive: false,
  294|       |                is_epoch: false
  295|       |            }),
  296|       |            0xffffffc000000000
  297|       |        );
  298|       |    }
  299|       |
  300|       |    #[test]
  301|       |    fn threshold_epoch0_receive() {
  302|       |        assert_eq!(
  303|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  304|       |                epoch: Epoch::Epoch0,
  305|       |                is_send: false,
  306|       |                is_receive: true,
  307|       |                is_epoch: false
  308|       |            }),
  309|       |            0xffffffc000000000
  310|       |        );
  311|       |    }
  312|       |
  313|       |    #[test]
  314|       |    fn threshold_epoch1_send() {
  315|       |        assert_eq!(
  316|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  317|       |                epoch: Epoch::Epoch1,
  318|       |                is_send: true,
  319|       |                is_receive: false,
  320|       |                is_epoch: false
  321|       |            }),
  322|       |            0xffffffc000000000
  323|       |        );
  324|       |    }
  325|       |
  326|       |    #[test]
  327|       |    fn threshold_epoch1_receive() {
  328|       |        assert_eq!(
  329|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  330|       |                epoch: Epoch::Epoch1,
  331|       |                is_send: false,
  332|       |                is_receive: true,
  333|       |                is_epoch: false
  334|       |            }),
  335|       |            0xffffffc000000000
  336|       |        );
  337|       |    }
  338|       |
  339|       |    #[test]
  340|       |    fn threshold_epoch2_send() {
  341|       |        assert_eq!(
  342|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  343|       |                epoch: Epoch::Epoch2,
  344|       |                is_send: true,
  345|       |                is_receive: false,
  346|       |                is_epoch: false
  347|       |            }),
  348|       |            0xfffffff800000000
  349|       |        );
  350|       |    }
  351|       |
  352|       |    #[test]
  353|       |    fn threshold_epoch2_receive() {
  354|       |        assert_eq!(
  355|       |            WorkThresholds::publish_full().threshold(&BlockDetails {
  356|       |                epoch: Epoch::Epoch2,
  357|       |                is_send: false,
  358|       |                is_receive: true,
  359|       |                is_epoch: false
  360|       |            }),
  361|       |            0xfffffe0000000000
  362|       |        );
  363|       |    }
  364|       |
  365|       |    #[test]
  366|       |    fn validate_real_block() {
  367|       |        let json_block = r###"{
  368|       |  "type": "send",
  369|       |  "previous": "991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948",
  370|       |  "destination": "nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo",
  371|       |  "balance": "FD89D89D89D89D89D89D89D89D89D89D",
  372|       |  "signature": "5B11B17DB9C8FE0CC58CAC6A6EECEF9CB122DA8A81C6D3DB1B5EE3AB065AA8F8CB1D6765C8EB91B58530C5FF5987AD95E6D34BB57F44257E20795EE412E61600",
  373|       |  "work": "3c82cc724905ee95"
  374|       |}"###;
  375|       |        let block: Block = serde_json::from_str::<JsonBlock>(json_block)
  376|       |            .unwrap()
  377|       |            .into();
  378|       |        let thresholds = WorkThresholds::publish_full();
  379|       |        assert_eq!(
  380|       |            block.hash(),
  381|       |            BlockHash::decode_hex(
  382|       |                "A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293"
  383|       |            )
  384|       |            .unwrap()
  385|       |        );
  386|       |        assert_eq!(
  387|       |            block.balance_field().unwrap(),
  388|       |            Amount::raw(337010421085160209006996005437231978653)
  389|       |        );
  390|       |        assert_eq!(thresholds.validate_entry_block(&block), true);
  391|       |        assert_eq!(thresholds.difficulty_block(&block), 18446743921403126366);
  392|       |    }
  393|       |}

/home/gustav/code/nano/rsnano-node/core/src/work/xorshift.rs:
    1|       |use super::WorkRng;
    2|       |use rand::{thread_rng, Rng};
    3|       |
    4|       |pub(crate) struct XorShift1024Star {
    5|       |    s: [u64; 16],
    6|       |    p: u32,
    7|       |}
    8|       |
    9|       |impl XorShift1024Star {
   10|      5|    pub fn new() -> Self {
   11|      5|        Self {
   12|      5|            s: thread_rng().gen(),
   13|      5|            p: 0,
   14|      5|        }
   15|      5|    }
   16|  28.8k|    pub fn next(&mut self) -> u64 {
   17|  28.8k|        let p_l = self.p;
   18|  28.8k|        let pn = p_l.wrapping_add(1) & 15;
   19|  28.8k|        self.p = pn;
   20|  28.8k|        let mut s0 = self.s[p_l as usize];
   21|  28.8k|        let mut s1 = self.s[pn as usize];
   22|  28.8k|        s1 ^= s1 << 31; //a
   23|  28.8k|        s1 ^= s1 >> 11; //b
   24|  28.8k|        s0 ^= s0 >> 30; //c
   25|  28.8k|        let x = s0 ^ s1;
   26|  28.8k|        self.s[pn as usize] = x;
   27|  28.8k|        x.wrapping_mul(1181783497276652981u64)
   28|  28.8k|    }
   29|       |}
   30|       |
   31|       |impl WorkRng for XorShift1024Star {
   32|  28.8k|    fn next_work(&mut self) -> u64 {
   33|  28.8k|        self.next()
   34|  28.8k|    }
   35|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_cementer.rs:
    1|       |use crate::{LedgerConstants, LedgerObserver, LedgerSetAny, LedgerSetConfirmed};
    2|       |use rsnano_core::{BlockHash, ConfirmationHeightInfo, SavedBlock};
    3|       |use rsnano_store_lmdb::{LmdbStore, LmdbWriteTransaction, Transaction};
    4|       |use std::{collections::VecDeque, sync::atomic::Ordering};
    5|       |
    6|       |/// Cements Blocks in the ledger
    7|       |pub(crate) struct BlockCementer<'a> {
    8|       |    constants: &'a LedgerConstants,
    9|       |    store: &'a LmdbStore,
   10|       |    observer: &'a dyn LedgerObserver,
   11|       |    any: LedgerSetAny<'a>,
   12|       |    confirmed: LedgerSetConfirmed<'a>,
   13|       |}
   14|       |
   15|       |impl<'a> BlockCementer<'a> {
   16|  16.3k|    pub(crate) fn new(
   17|  16.3k|        store: &'a LmdbStore,
   18|  16.3k|        observer: &'a dyn LedgerObserver,
   19|  16.3k|        constants: &'a LedgerConstants,
   20|  16.3k|    ) -> Self {
   21|  16.3k|        Self {
   22|  16.3k|            store,
   23|  16.3k|            observer,
   24|  16.3k|            constants,
   25|  16.3k|            any: LedgerSetAny::new(store),
   26|  16.3k|            confirmed: LedgerSetConfirmed::new(store),
   27|  16.3k|        }
   28|  16.3k|    }
   29|       |
   30|  16.3k|    pub(crate) fn confirm(
   31|  16.3k|        &self,
   32|  16.3k|        txn: &mut LmdbWriteTransaction,
   33|  16.3k|        target_hash: BlockHash,
   34|  16.3k|        max_blocks: usize,
   35|  16.3k|    ) -> Vec<SavedBlock> {
   36|  16.3k|        let mut result = Vec::new();
   37|  16.3k|
   38|  16.3k|        let mut stack = VecDeque::new();
   39|  16.3k|        stack.push_back(target_hash);
   40|  32.7k|        while let Some(&hash) = stack.back() {
                                      ^16.3k
   41|  16.3k|            let block = self.any.get_block(txn, &hash).unwrap();
   42|  16.3k|
   43|  16.3k|            let dependents =
   44|  16.3k|                block.dependent_blocks(&self.constants.epochs, &self.constants.genesis_account);
   45|  16.3k|            for dependent in dependents.iter() {
   46|  16.3k|                if !dependent.is_zero() && !self.confirmed.block_exists_or_pruned(txn, dependent) {
   47|      0|                    self.observer.dependent_unconfirmed();
   48|      0|
   49|      0|                    stack.push_back(*dependent);
   50|      0|
   51|      0|                    // Limit the stack size to avoid excessive memory usage
   52|      0|                    // This will forget the bottom of the dependency tree
   53|      0|                    if stack.len() > max_blocks {
   54|      0|                        stack.pop_front();
   55|      0|                    }
   56|  16.3k|                }
   57|       |            }
   58|       |
   59|  16.3k|            if stack.back() == Some(&hash) {
   60|  16.3k|                stack.pop_back();
   61|  16.3k|                if !self.confirmed.block_exists_or_pruned(txn, &hash) {
   62|  16.3k|                    // We must only confirm blocks that have their dependencies confirmed
   63|  16.3k|
   64|  16.3k|                    let conf_height = ConfirmationHeightInfo::new(block.height(), block.hash());
   65|  16.3k|
   66|  16.3k|                    // Update store
   67|  16.3k|                    self.store
   68|  16.3k|                        .confirmation_height
   69|  16.3k|                        .put(txn, &block.account(), &conf_height);
   70|  16.3k|                    self.store
   71|  16.3k|                        .cache
   72|  16.3k|                        .cemented_count
   73|  16.3k|                        .fetch_add(1, Ordering::SeqCst);
   74|  16.3k|
   75|  16.3k|                    self.observer.blocks_cemented(1);
   76|  16.3k|
   77|  16.3k|                    result.push(block);
   78|  16.3k|                }
                               ^0
   79|      0|            } else {
   80|      0|                // Unconfirmed dependencies were added
   81|      0|            }
   82|       |
   83|       |            // Refresh the transaction to avoid long-running transactions
   84|       |            // Ensure that the block wasn't rolled back during the refresh
   85|  16.3k|            let refreshed = txn.refresh_if_needed();
   86|  16.3k|            if refreshed {
   87|      2|                if !self.any.block_exists(txn, &target_hash) {
   88|      0|                    break; // Block was rolled back during cementing
   89|      2|                }
   90|  16.3k|            }
   91|       |
   92|       |            // Early return might leave parts of the dependency tree unconfirmed
   93|  16.3k|            if result.len() >= max_blocks {
   94|      0|                break;
   95|  16.3k|            }
   96|       |        }
   97|  16.3k|        result
   98|  16.3k|    }
   99|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/block_inserter.rs:
    1|       |use crate::Ledger;
    2|       |use rsnano_core::{
    3|       |    Account, AccountInfo, Amount, Block, BlockSideband, PendingInfo, PendingKey, SavedBlock,
    4|       |};
    5|       |use rsnano_store_lmdb::LmdbWriteTransaction;
    6|       |use std::sync::atomic::Ordering;
    7|       |
    8|       |#[derive(Debug, PartialEq)]
    9|       |pub(crate) struct BlockInsertInstructions {
   10|       |    pub account: Account,
   11|       |    pub old_account_info: AccountInfo,
   12|       |    pub set_account_info: AccountInfo,
   13|       |    pub delete_pending: Option<PendingKey>,
   14|       |    pub insert_pending: Option<(PendingKey, PendingInfo)>,
   15|       |    pub set_sideband: BlockSideband,
   16|       |    pub is_epoch_block: bool,
   17|       |}
   18|       |
   19|       |/// Inserts a new block into the ledger
   20|       |pub(crate) struct BlockInserter<'a> {
   21|       |    ledger: &'a Ledger,
   22|       |    txn: &'a mut LmdbWriteTransaction,
   23|       |    block: &'a Block,
   24|       |    instructions: &'a BlockInsertInstructions,
   25|       |}
   26|       |
   27|       |impl<'a> BlockInserter<'a> {
   28|     32|    pub(crate) fn new(
   29|     32|        ledger: &'a Ledger,
   30|     32|        txn: &'a mut LmdbWriteTransaction,
   31|     32|        block: &'a Block,
   32|     32|        instructions: &'a BlockInsertInstructions,
   33|     32|    ) -> Self {
   34|     32|        Self {
   35|     32|            ledger,
   36|     32|            txn,
   37|     32|            block,
   38|     32|            instructions,
   39|     32|        }
   40|     32|    }
   41|       |
   42|     32|    pub(crate) fn insert(&mut self) -> SavedBlock {
   43|     32|        let sideband = self.instructions.set_sideband.clone();
   44|     32|        let saved_block = SavedBlock::new(self.block.clone(), sideband);
   45|     32|        self.ledger.store.block.put(self.txn, &saved_block);
   46|     32|        self.update_account();
   47|     32|        self.delete_old_pending_info();
   48|     32|        self.insert_new_pending_info();
   49|     32|        self.update_representative_cache();
   50|     32|        self.ledger
   51|     32|            .observer
   52|     32|            .block_added(self.block, self.instructions.is_epoch_block);
   53|     32|        self.ledger
   54|     32|            .store
   55|     32|            .cache
   56|     32|            .block_count
   57|     32|            .fetch_add(1, Ordering::SeqCst);
   58|     32|
   59|     32|        saved_block
   60|     32|    }
   61|       |
   62|     32|    fn update_account(&mut self) {
   63|     32|        self.ledger.update_account(
   64|     32|            self.txn,
   65|     32|            &self.instructions.account,
   66|     32|            &self.instructions.old_account_info,
   67|     32|            &self.instructions.set_account_info,
   68|     32|        );
   69|     32|    }
   70|       |
   71|     32|    fn delete_old_pending_info(&mut self) {
   72|     32|        if let Some(key) = &self.instructions.delete_pending {
                                  ^4
   73|      4|            self.ledger.store.pending.del(self.txn, key);
   74|     28|        }
   75|     32|    }
   76|       |
   77|     32|    fn insert_new_pending_info(&mut self) {
   78|     32|        if let Some((key, info)) = &self.instructions.insert_pending {
                                   ^28
   79|     28|            self.ledger.store.pending.put(self.txn, key, info);
   80|     28|        }
                       ^4
   81|     32|    }
   82|       |
   83|     32|    fn update_representative_cache(&mut self) {
   84|     32|        if !self.instructions.old_account_info.head.is_zero() {
   85|     28|            // Move existing representation & add in amount delta
   86|     28|            self.ledger.rep_weights_updater.representation_add_dual(
   87|     28|                self.txn,
   88|     28|                self.instructions.old_account_info.representative,
   89|     28|                Amount::zero().wrapping_sub(self.instructions.old_account_info.balance),
   90|     28|                self.instructions.set_account_info.representative,
   91|     28|                self.instructions.set_account_info.balance,
   92|     28|            );
   93|     28|        } else {
   94|      4|            // Add in amount delta only
   95|      4|            self.ledger.rep_weights_updater.representation_add(
   96|      4|                self.txn,
   97|      4|                self.instructions.set_account_info.representative,
   98|      4|                self.instructions.set_account_info.balance,
   99|      4|            );
  100|      4|        }
  101|     32|    }
  102|       |}
  103|       |
  104|       |#[cfg(test)]
  105|       |mod tests {
  106|       |    use super::*;
  107|       |    use rsnano_core::{BlockHash, PublicKey, TestBlockBuilder};
  108|       |
  109|       |    #[test]
  110|       |    fn insert_open_state_block() {
  111|       |        let (mut block, instructions) = open_state_block_instructions();
  112|       |        let ledger = Ledger::new_null();
  113|       |
  114|       |        let result = insert(&ledger, &mut block, &instructions);
  115|       |
  116|       |        let expected_block = SavedBlock::new(block.clone(), instructions.set_sideband.clone());
  117|       |        assert_eq!(result.saved_blocks, vec![expected_block]);
  118|       |        assert_eq!(
  119|       |            result.saved_accounts,
  120|       |            vec![(instructions.account, instructions.set_account_info.clone())]
  121|       |        );
  122|       |        assert_eq!(
  123|       |            ledger
  124|       |                .rep_weights
  125|       |                .weight(&instructions.set_account_info.representative),
  126|       |            instructions.set_account_info.balance
  127|       |        );
  128|       |        assert_eq!(ledger.store.cache.block_count.load(Ordering::Relaxed), 1);
  129|       |        assert_eq!(result.deleted_pending, Vec::new());
  130|       |    }
  131|       |
  132|       |    #[test]
  133|       |    fn delete_old_pending() {
  134|       |        let (mut block, mut instructions) = legacy_open_block_instructions();
  135|       |        let pending_key = PendingKey::new_test_instance();
  136|       |        instructions.delete_pending = Some(pending_key.clone());
  137|       |        let ledger = Ledger::new_null();
  138|       |
  139|       |        let result = insert(&ledger, &mut block, &instructions);
  140|       |
  141|       |        assert_eq!(result.deleted_pending, vec![pending_key]);
  142|       |    }
  143|       |
  144|       |    #[test]
  145|       |    fn insert_pending() {
  146|       |        let (mut block, mut instructions) = legacy_open_block_instructions();
  147|       |        let pending_key = PendingKey::new_test_instance();
  148|       |        let pending_info = PendingInfo::new_test_instance();
  149|       |        instructions.insert_pending = Some((pending_key.clone(), pending_info.clone()));
  150|       |        let ledger = Ledger::new_null();
  151|       |
  152|       |        let result = insert(&ledger, &mut block, &instructions);
  153|       |
  154|       |        assert_eq!(result.saved_pending, vec![(pending_key, pending_info)]);
  155|       |    }
  156|       |
  157|       |    #[test]
  158|       |    fn update_representative() {
  159|       |        let old_representative = PublicKey::from(1111);
  160|       |        let new_representative = PublicKey::from(2222);
  161|       |        let open = TestBlockBuilder::legacy_open()
  162|       |            .representative(old_representative)
  163|       |            .build();
  164|       |        let sideband = BlockSideband {
  165|       |            successor: BlockHash::zero(),
  166|       |            ..BlockSideband::new_test_instance()
  167|       |        };
  168|       |        let open = SavedBlock::new(open, sideband.clone());
  169|       |
  170|       |        let state = TestBlockBuilder::state()
  171|       |            .previous(open.hash())
  172|       |            .representative(new_representative)
  173|       |            .balance(sideband.balance)
  174|       |            .build();
  175|       |        let (mut state, instructions) = state_block_instructions_for(&open, state);
  176|       |
  177|       |        let ledger = Ledger::new_null_builder().block(&open).finish();
  178|       |        insert(&ledger, &mut state, &instructions);
  179|       |        assert_eq!(
  180|       |            ledger.rep_weights.weight(&new_representative),
  181|       |            instructions.set_account_info.balance
  182|       |        );
  183|       |    }
  184|       |
  185|       |    fn insert(
  186|       |        ledger: &Ledger,
  187|       |        block: &mut Block,
  188|       |        instructions: &BlockInsertInstructions,
  189|       |    ) -> InsertResult {
  190|       |        let mut txn = ledger.rw_txn();
  191|       |        let saved_blocks = ledger.store.block.track_puts();
  192|       |        let saved_accounts = ledger.store.account.track_puts();
  193|       |        let saved_pending = ledger.store.pending.track_puts();
  194|       |        let deleted_pending = ledger.store.pending.track_deletions();
  195|       |
  196|       |        let mut block_inserter = BlockInserter::new(&ledger, &mut txn, block, &instructions);
  197|       |        block_inserter.insert();
  198|       |
  199|       |        InsertResult {
  200|       |            saved_blocks: saved_blocks.output(),
  201|       |            saved_accounts: saved_accounts.output(),
  202|       |            saved_pending: saved_pending.output(),
  203|       |            deleted_pending: deleted_pending.output(),
  204|       |        }
  205|       |    }
  206|       |
  207|       |    struct InsertResult {
  208|       |        saved_blocks: Vec<SavedBlock>,
  209|       |        saved_accounts: Vec<(Account, AccountInfo)>,
  210|       |        saved_pending: Vec<(PendingKey, PendingInfo)>,
  211|       |        deleted_pending: Vec<PendingKey>,
  212|       |    }
  213|       |
  214|       |    fn legacy_open_block_instructions() -> (Block, BlockInsertInstructions) {
  215|       |        let block = TestBlockBuilder::legacy_open().build();
  216|       |        let sideband = BlockSideband {
  217|       |            successor: BlockHash::zero(),
  218|       |            ..BlockSideband::new_test_instance()
  219|       |        };
  220|       |        let account_info = AccountInfo {
  221|       |            head: block.hash(),
  222|       |            open_block: block.hash(),
  223|       |            ..AccountInfo::new_test_instance()
  224|       |        };
  225|       |        let instructions = BlockInsertInstructions {
  226|       |            account: block.account_field().unwrap(),
  227|       |            old_account_info: AccountInfo::default(),
  228|       |            set_account_info: account_info,
  229|       |            delete_pending: None,
  230|       |            insert_pending: None,
  231|       |            set_sideband: sideband,
  232|       |            is_epoch_block: false,
  233|       |        };
  234|       |
  235|       |        (block, instructions)
  236|       |    }
  237|       |
  238|       |    fn open_state_block_instructions() -> (Block, BlockInsertInstructions) {
  239|       |        let block = TestBlockBuilder::state()
  240|       |            .previous(BlockHash::zero())
  241|       |            .build();
  242|       |        let sideband = BlockSideband {
  243|       |            successor: BlockHash::zero(),
  244|       |            ..BlockSideband::new_test_instance()
  245|       |        };
  246|       |        let account_info = AccountInfo {
  247|       |            head: block.hash(),
  248|       |            open_block: block.hash(),
  249|       |            ..AccountInfo::new_test_instance()
  250|       |        };
  251|       |        let instructions = BlockInsertInstructions {
  252|       |            account: Account::from(1),
  253|       |            old_account_info: AccountInfo::default(),
  254|       |            set_account_info: account_info,
  255|       |            delete_pending: None,
  256|       |            insert_pending: None,
  257|       |            set_sideband: sideband,
  258|       |            is_epoch_block: false,
  259|       |        };
  260|       |
  261|       |        (block, instructions)
  262|       |    }
  263|       |
  264|       |    fn state_block_instructions_for(
  265|       |        previous: &SavedBlock,
  266|       |        block: Block,
  267|       |    ) -> (Block, BlockInsertInstructions) {
  268|       |        let sideband = BlockSideband {
  269|       |            successor: BlockHash::zero(),
  270|       |            balance: block.balance_field().unwrap(),
  271|       |            account: block.account_field().unwrap(),
  272|       |            ..BlockSideband::new_test_instance()
  273|       |        };
  274|       |        let old_account_info = AccountInfo {
  275|       |            head: previous.hash(),
  276|       |            balance: previous.balance(),
  277|       |            ..AccountInfo::new_test_instance()
  278|       |        };
  279|       |        let new_account_info = AccountInfo {
  280|       |            head: block.hash(),
  281|       |            open_block: block.hash(),
  282|       |            balance: block.balance_field().unwrap(),
  283|       |            representative: block.representative_field().unwrap(),
  284|       |            ..AccountInfo::new_test_instance()
  285|       |        };
  286|       |        let instructions = BlockInsertInstructions {
  287|       |            account: Account::from(1),
  288|       |            old_account_info,
  289|       |            set_account_info: new_account_info,
  290|       |            delete_pending: None,
  291|       |            insert_pending: None,
  292|       |            set_sideband: sideband,
  293|       |            is_epoch_block: false,
  294|       |        };
  295|       |
  296|       |        (block, instructions)
  297|       |    }
  298|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/common_rules.rs:
    1|       |use super::BlockValidator;
    2|       |use crate::BlockStatus;
    3|       |use rsnano_core::PublicKey;
    4|       |
    5|       |impl<'a> BlockValidator<'a> {
    6|     32|    pub(crate) fn ensure_block_does_not_exist_yet(&self) -> Result<(), BlockStatus> {
    7|     32|        if self.block_exists {
    8|      0|            Err(BlockStatus::Old)
    9|       |        } else {
   10|     32|            Ok(())
   11|       |        }
   12|     32|    }
   13|       |
   14|     32|    pub(crate) fn ensure_valid_signature(&self) -> Result<(), BlockStatus> {
   15|     32|        let result = if self.is_epoch_block() {
   16|      0|            self.epochs.validate_epoch_signature(self.block)
   17|       |        } else {
   18|     32|            let pub_key: PublicKey = self.account.into();
   19|     32|            pub_key.verify(self.block.hash().as_bytes(), self.block.signature())
   20|       |        };
   21|     32|        result.map_err(|_| BlockStatus::BadSignature)
                                         ^0
   22|     32|    }
   23|       |
   24|     32|    pub(crate) fn ensure_account_exists_for_none_open_block(&self) -> Result<(), BlockStatus> {
   25|     32|        if !self.block.is_open() && self.is_new_account() {
                                                  ^28
   26|      0|            Err(BlockStatus::GapPrevious)
   27|       |        } else {
   28|     32|            Ok(())
   29|       |        }
   30|     32|    }
   31|       |
   32|     32|    pub(crate) fn ensure_previous_block_is_correct(&self) -> Result<(), BlockStatus> {
   33|     32|        self.ensure_previous_block_exists()?;
                                                         ^0
   34|     32|        self.ensure_previous_block_is_account_head()
   35|     32|    }
   36|       |
   37|     32|    fn ensure_previous_block_exists(&self) -> Result<(), BlockStatus> {
   38|     32|        if self.account_exists() && self.previous_block.is_none() {
                                                  ^28
   39|      0|            return Err(BlockStatus::GapPrevious);
   40|     32|        }
   41|     32|
   42|     32|        if self.is_new_account() && !self.block.previous().is_zero() {
                                                  ^4
   43|      0|            return Err(BlockStatus::GapPrevious);
   44|     32|        }
   45|     32|
   46|     32|        Ok(())
   47|     32|    }
   48|       |
   49|     32|    fn ensure_previous_block_is_account_head(&self) -> Result<(), BlockStatus> {
   50|     32|        if let Some(info) = &self.old_account_info {
                                  ^28
   51|     28|            if self.block.previous() != info.head {
   52|      0|                return Err(BlockStatus::Fork);
   53|     28|            }
   54|      4|        }
   55|       |
   56|     32|        Ok(())
   57|     32|    }
   58|       |
   59|     32|    pub(crate) fn ensure_sufficient_work(&self) -> Result<(), BlockStatus> {
   60|     32|        if !self.work.is_valid_pow(self.block, &self.block_details()) {
   61|      0|            Err(BlockStatus::InsufficientWork)
   62|       |        } else {
   63|     32|            Ok(())
   64|       |        }
   65|     32|    }
   66|       |
   67|     32|    pub(crate) fn ensure_valid_predecessor(&self) -> Result<(), BlockStatus> {
   68|     32|        if self.block.previous().is_zero() {
   69|      4|            return Ok(());
   70|     28|        }
   71|       |
   72|     28|        let previous = self
   73|     28|            .previous_block
   74|     28|            .as_ref()
   75|     28|            .ok_or(BlockStatus::GapPrevious)?;
                                                          ^0
   76|       |
   77|     28|        if !self.block.valid_predecessor(previous.block_type()) {
   78|      0|            Err(BlockStatus::BlockPosition)
   79|       |        } else {
   80|     28|            Ok(())
   81|       |        }
   82|     32|    }
   83|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/epoch_block_rules.rs:
    1|       |use super::BlockValidator;
    2|       |use crate::BlockStatus;
    3|       |use rsnano_core::{Block, Epoch, Epochs};
    4|       |
    5|       |impl<'a> BlockValidator<'a> {
    6|     32|    pub(crate) fn ensure_valid_epoch_block(&self) -> Result<(), BlockStatus> {
    7|     32|        self.ensure_epoch_block_does_not_change_representative()?;
                                                                              ^0
    8|     32|        self.ensure_epoch_open_has_burn_account_as_rep()?;
                                                                      ^0
    9|     32|        self.ensure_epoch_open_has_pending_entry()?;
                                                                ^0
   10|     32|        self.ensure_valid_epoch_for_unopened_account()?;
                                                                    ^0
   11|     32|        self.ensure_epoch_upgrade_is_sequential_for_existing_account()?;
                                                                                    ^0
   12|     32|        self.ensure_epoch_block_does_not_change_balance()
   13|     32|    }
   14|       |
   15|     32|    fn ensure_epoch_block_does_not_change_representative(&self) -> Result<(), BlockStatus> {
   16|     32|        if let Block::State(state) = self.block {
   17|     32|            if self.is_epoch_block() {
   18|      0|                if let Some(info) = &self.old_account_info {
   19|      0|                    if state.representative() != info.representative {
   20|      0|                        return Err(BlockStatus::RepresentativeMismatch);
   21|      0|                    };
   22|      0|                }
   23|     32|            }
   24|      0|        }
   25|     32|        Ok(())
   26|     32|    }
   27|       |
   28|     32|    fn ensure_epoch_open_has_burn_account_as_rep(&self) -> Result<(), BlockStatus> {
   29|     32|        if let Block::State(state) = self.block {
   30|     32|            if self.is_epoch_block() && self.block.is_open() && !state.representative().is_zero() {
                                                      ^0                      ^0
   31|      0|                return Err(BlockStatus::RepresentativeMismatch);
   32|     32|            }
   33|      0|        }
   34|     32|        Ok(())
   35|     32|    }
   36|       |
   37|     32|    fn ensure_epoch_open_has_pending_entry(&self) -> Result<(), BlockStatus> {
   38|     32|        if self.block.is_open() && self.is_epoch_block() && !self.any_pending_exists {
                                                 ^4                       ^0
   39|      0|            return Err(BlockStatus::GapEpochOpenPending);
   40|     32|        }
   41|     32|        Ok(())
   42|     32|    }
   43|       |
   44|     32|    fn ensure_valid_epoch_for_unopened_account(&self) -> Result<(), BlockStatus> {
   45|     32|        if self.block.is_open()
   46|      4|            && self.is_epoch_block()
   47|      0|            && self.block_epoch_version() == Epoch::Invalid
   48|       |        {
   49|      0|            Err(BlockStatus::BlockPosition)
   50|       |        } else {
   51|     32|            Ok(())
   52|       |        }
   53|     32|    }
   54|       |
   55|     32|    fn ensure_epoch_upgrade_is_sequential_for_existing_account(&self) -> Result<(), BlockStatus> {
   56|     32|        if self.is_epoch_block() {
   57|      0|            if let Some(info) = &self.old_account_info {
   58|      0|                if !Epochs::is_sequential(info.epoch, self.block_epoch_version()) {
   59|      0|                    return Err(BlockStatus::BlockPosition);
   60|      0|                }
   61|      0|            }
   62|     32|        }
   63|     32|        Ok(())
   64|     32|    }
   65|       |
   66|     32|    fn ensure_epoch_block_does_not_change_balance(&self) -> Result<(), BlockStatus> {
   67|     32|        if self.is_epoch_block() && self.balance_changed() {
                                                  ^0
   68|      0|            return Err(BlockStatus::BalanceMismatch);
   69|     32|        }
   70|     32|        Ok(())
   71|     32|    }
   72|       |
   73|       |    /// If the previous block is missing, we cannot determine whether it is an epoch block
   74|       |    /// or not. That means we don't know how to check the signature. This precheck just checks
   75|       |    /// the signature with both the account owner and the epoch signer, because one of them
   76|       |    /// must be correct.
   77|       |    /// It's important to abort early with BadSignature, so that the block does not get added
   78|       |    /// to the unchecked map!
   79|     32|    pub(crate) fn epoch_block_pre_checks(&self) -> Result<(), BlockStatus> {
   80|     32|        self.ensure_epoch_block_candidate_is_signed_by_owner_or_epoch_account()?;
                                                                                             ^0
   81|     32|        self.ensure_previous_block_exists_for_epoch_block_candidate()
   82|     32|    }
   83|       |
   84|       |    /// This is a precheck that allows for an early return if a block with an epoch link
   85|       |    /// is not signed by the account owner or the epoch signer.
   86|       |    /// It is not sure yet, if the block is an epoch block, because it could just be
   87|       |    /// a normal send to the epoch account.
   88|     32|    pub fn ensure_epoch_block_candidate_is_signed_by_owner_or_epoch_account(
   89|     32|        &self,
   90|     32|    ) -> Result<(), BlockStatus> {
   91|     32|        if let Block::State(state_block) = self.block {
   92|       |            // Check for possible regular state blocks with epoch link (send subtype)
   93|     32|            if self.has_epoch_link(state_block)
   94|      0|                && (state_block.verify_signature().is_err()
   95|      0|                    && self.epochs.validate_epoch_signature(self.block).is_err())
   96|       |            {
   97|      0|                return Err(BlockStatus::BadSignature);
   98|     32|            }
   99|      0|        }
  100|     32|        Ok(())
  101|     32|    }
  102|       |
  103|     32|    pub fn ensure_previous_block_exists_for_epoch_block_candidate(
  104|     32|        &self,
  105|     32|    ) -> Result<(), BlockStatus> {
  106|     32|        if let Block::State(state_block) = self.block {
  107|     32|            if self.has_epoch_link(state_block)
  108|      0|                && !self.block.previous().is_zero()
  109|      0|                && self.previous_block.is_none()
  110|       |            {
  111|      0|                return Err(BlockStatus::GapPrevious);
  112|     32|            }
  113|      0|        }
  114|     32|        Ok(())
  115|     32|    }
  116|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/helpers.rs:
    1|       |use rsnano_core::{
    2|       |    AccountInfo, Amount, Block, BlockBase, BlockDetails, BlockHash, BlockSideband, Epoch,
    3|       |    PendingInfo, PendingKey, PublicKey, StateBlock,
    4|       |};
    5|       |
    6|       |use super::BlockValidator;
    7|       |
    8|       |impl<'a> BlockValidator<'a> {
    9|     64|    pub(crate) fn account_exists(&self) -> bool {
   10|     64|        self.old_account_info.is_some()
   11|     64|    }
   12|       |
   13|     60|    pub(crate) fn is_new_account(&self) -> bool {
   14|     60|        self.old_account_info.is_none()
   15|     60|    }
   16|       |
   17|     96|    pub(crate) fn previous_balance(&self) -> Amount {
   18|     96|        self.previous_block
   19|     96|            .as_ref()
   20|     96|            .map(|b| b.balance())
                                   ^84
   21|     96|            .unwrap_or_default()
   22|     96|    }
   23|       |
   24|     96|    pub(crate) fn is_send(&self) -> bool {
   25|     96|        match self.block {
   26|      0|            Block::LegacySend(_) => true,
   27|     96|            Block::State(state) => match &self.old_account_info {
   28|     84|                Some(info) => state.balance() < info.balance,
   29|     12|                None => false,
   30|       |            },
   31|      0|            _ => false,
   32|       |        }
   33|     96|    }
   34|       |
   35|    160|    pub(crate) fn is_receive(&self) -> bool {
   36|    160|        match self.block {
   37|      0|            Block::LegacyReceive(_) | Block::LegacyOpen(_) => true,
   38|    160|            Block::State(state_block) => {
   39|    160|                // receives from the epoch account are forbidden
   40|    160|                if self.has_epoch_link(state_block) {
   41|      0|                    return false;
   42|    160|                }
   43|    160|
   44|    160|                match &self.old_account_info {
   45|    140|                    Some(info) => {
   46|    140|                        state_block.balance() >= info.balance && !state_block.link().is_zero()
                                                                               ^0
   47|       |                    }
   48|     20|                    None => true,
   49|       |                }
   50|       |            }
   51|      0|            _ => false,
   52|       |        }
   53|    160|    }
   54|       |
   55|    156|    pub(crate) fn source_epoch(&self) -> Epoch {
   56|    156|        self.pending_receive_info
   57|    156|            .as_ref()
   58|    156|            .map(|p| p.epoch)
                                   ^16
   59|    156|            .unwrap_or(Epoch::Epoch0)
   60|    156|    }
   61|       |
   62|     96|    pub(crate) fn amount_received(&self) -> Amount {
   63|     96|        match &self.block {
   64|      0|            Block::LegacyReceive(_) | Block::LegacyOpen(_) => self.pending_amount(),
   65|     96|            Block::State(state) => {
   66|     96|                let previous = self.previous_balance();
   67|     96|                if previous < state.balance() {
   68|     12|                    state.balance() - previous
   69|       |                } else {
   70|     84|                    Amount::zero()
   71|       |                }
   72|       |            }
   73|      0|            _ => Amount::zero(),
   74|       |        }
   75|     96|    }
   76|       |
   77|      0|    pub fn pending_amount(&self) -> Amount {
   78|      0|        self.pending_receive_info
   79|      0|            .as_ref()
   80|      0|            .map(|i| i.amount)
   81|      0|            .unwrap_or_default()
   82|      0|    }
   83|       |
   84|     92|    pub(crate) fn amount_sent(&self) -> Amount {
   85|     92|        if let Some(info) = &self.old_account_info {
                                  ^84
   86|     84|            let balance = match self.block {
   87|      0|                Block::LegacySend(i) => Some(i.balance()),
   88|     84|                Block::State(i) => Some(i.balance()),
   89|      0|                _ => None,
   90|       |            };
   91|     84|            if let Some(balance) = balance {
   92|     84|                if balance < info.balance {
   93|     84|                    return info.balance - balance;
   94|      0|                }
   95|      0|            }
   96|      8|        }
   97|      8|        Amount::zero()
   98|     92|    }
   99|       |
  100|     92|    pub(crate) fn new_balance(&self) -> Amount {
  101|     92|        self.old_balance() + self.amount_received() - self.amount_sent()
  102|     92|    }
  103|       |
  104|    120|    fn old_balance(&self) -> Amount {
  105|    120|        self.old_account_info
  106|    120|            .as_ref()
  107|    120|            .map(|i| i.balance)
                                   ^112
  108|    120|            .unwrap_or_default()
  109|    120|    }
  110|       |
  111|    612|    pub(crate) fn has_epoch_link(&self, state_block: &StateBlock) -> bool {
  112|    612|        self.epochs.is_epoch_link(&state_block.link())
  113|    612|    }
  114|       |
  115|       |    /// This check only makes sense after ensure_previous_block_exists_for_epoch_block_candidate,
  116|       |    /// because we need the previous block for the balance change check!
  117|    388|    pub(crate) fn is_epoch_block(&self) -> bool {
  118|    388|        match self.block {
  119|    388|            Block::State(state_block) => {
  120|    388|                self.has_epoch_link(state_block) && self.previous_balance() == state_block.balance()
                                                                  ^0
  121|       |            }
  122|      0|            _ => false,
  123|       |        }
  124|    388|    }
  125|       |
  126|      0|    pub(crate) fn block_epoch_version(&self) -> Epoch {
  127|      0|        match self.block {
  128|      0|            Block::State(state) => self.epochs.epoch(&state.link()).unwrap_or(Epoch::Invalid),
  129|      0|            _ => Epoch::Epoch0,
  130|       |        }
  131|      0|    }
  132|       |
  133|    124|    pub(crate) fn epoch(&self) -> Epoch {
  134|    124|        if self.is_epoch_block() {
  135|      0|            self.block_epoch_version()
  136|       |        } else {
  137|    124|            std::cmp::max(self.old_epoch_version(), self.source_epoch())
  138|       |        }
  139|    124|    }
  140|       |
  141|    124|    fn old_epoch_version(&self) -> Epoch {
  142|    124|        self.old_account_info
  143|    124|            .as_ref()
  144|    124|            .map(|i| i.epoch)
                                   ^112
  145|    124|            .unwrap_or(Epoch::Epoch0)
  146|    124|    }
  147|       |
  148|     32|    pub(crate) fn open_block(&self) -> BlockHash {
  149|     32|        match &self.old_account_info {
  150|     28|            Some(info) => info.open_block,
  151|      4|            None => self.block.hash(),
  152|       |        }
  153|     32|    }
  154|       |
  155|     32|    pub(crate) fn new_representative(&self) -> PublicKey {
  156|     32|        self.block
  157|     32|            .representative_field()
  158|     32|            .unwrap_or(self.old_representative())
  159|     32|    }
  160|       |
  161|     32|    fn old_representative(&self) -> PublicKey {
  162|     32|        self.old_account_info
  163|     32|            .as_ref()
  164|     32|            .map(|x| x.representative)
                                   ^28
  165|     32|            .unwrap_or_default()
  166|     32|    }
  167|       |
  168|     28|    pub(crate) fn amount(&self) -> Amount {
  169|     28|        let old_balance = self.old_balance();
  170|     28|        let new_balance = self.new_balance();
  171|     28|
  172|     28|        if old_balance > new_balance {
  173|     28|            old_balance - new_balance
  174|       |        } else {
  175|      0|            new_balance - old_balance
  176|       |        }
  177|     28|    }
  178|       |
  179|     32|    pub(crate) fn delete_received_pending_info(&self) -> Option<PendingKey> {
  180|     32|        if self.is_receive() {
  181|      4|            Some(PendingKey::new(self.account, self.block.source_or_link()))
  182|       |        } else {
  183|     28|            None
  184|       |        }
  185|     32|    }
  186|       |
  187|     32|    pub(crate) fn new_pending_info(&self) -> Option<(PendingKey, PendingInfo)> {
  188|     32|        match self.block {
  189|       |            Block::State(_) => {
  190|     32|                if self.is_send() {
  191|     28|                    let key = PendingKey::for_send_block(self.block);
  192|     28|                    let info = PendingInfo::new(self.account, self.amount(), self.epoch());
  193|     28|                    Some((key, info))
  194|       |                } else {
  195|      4|                    None
  196|       |                }
  197|       |            }
  198|      0|            Block::LegacySend(send) => {
  199|      0|                let amount_sent = self.amount_sent();
  200|      0|                Some((
  201|      0|                    PendingKey::new(send.destination(), send.hash()),
  202|      0|                    PendingInfo::new(self.account, amount_sent, Epoch::Epoch0),
  203|      0|                ))
  204|       |            }
  205|      0|            _ => None,
  206|       |        }
  207|     32|    }
  208|       |
  209|     32|    pub(crate) fn new_sideband(&self) -> BlockSideband {
  210|     32|        BlockSideband {
  211|     32|            height: self.new_block_count(),
  212|     32|            timestamp: self.now,
  213|     32|            successor: BlockHash::zero(),
  214|     32|            account: self.account,
  215|     32|            balance: self.new_balance(),
  216|     32|            details: self.block_details(),
  217|     32|            source_epoch: self.source_epoch(),
  218|     32|        }
  219|     32|    }
  220|       |
  221|     32|    pub(crate) fn new_account_info(&self) -> AccountInfo {
  222|     32|        AccountInfo {
  223|     32|            head: self.block.hash(),
  224|     32|            representative: self.new_representative(),
  225|     32|            open_block: self.open_block(),
  226|     32|            balance: self.new_balance(),
  227|     32|            modified: self.now,
  228|     32|            block_count: self.new_block_count(),
  229|     32|            epoch: self.epoch(),
  230|     32|        }
  231|     32|    }
  232|       |
  233|     64|    pub(crate) fn new_block_count(&self) -> u64 {
  234|     64|        self.old_account_info
  235|     64|            .as_ref()
  236|     64|            .map(|info| info.block_count)
                                      ^56
  237|     64|            .unwrap_or_default()
  238|     64|            + 1
  239|     64|    }
  240|       |
  241|     64|    pub(crate) fn block_details(&self) -> BlockDetails {
  242|     64|        BlockDetails::new(
  243|     64|            self.epoch(),
  244|     64|            self.is_send(),
  245|     64|            self.is_receive(),
  246|     64|            self.is_epoch_block(),
  247|     64|        )
  248|     64|    }
  249|       |
  250|      0|    pub(crate) fn balance_changed(&self) -> bool {
  251|      0|        if let Some(info) = &self.old_account_info {
  252|      0|            self.new_balance() != info.balance
  253|       |        } else {
  254|      0|            false
  255|       |        }
  256|      0|    }
  257|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/mod.rs:
    1|       |mod common_rules;
    2|       |mod epoch_block_rules;
    3|       |mod helpers;
    4|       |mod open_block_rules;
    5|       |mod receive_block_rules;
    6|       |mod send_block_rules;
    7|       |#[cfg(test)]
    8|       |mod tests;
    9|       |
   10|       |use super::BlockInsertInstructions;
   11|       |use crate::BlockStatus;
   12|       |use rsnano_core::{
   13|       |    utils::UnixTimestamp, work::WorkThresholds, Account, AccountInfo, Block, Epochs, PendingInfo,
   14|       |    SavedBlock,
   15|       |};
   16|       |
   17|       |/// Validates a single block before it gets inserted into the ledger
   18|       |pub(crate) struct BlockValidator<'a> {
   19|       |    pub block: &'a Block,
   20|       |    pub epochs: &'a Epochs,
   21|       |    pub work: &'a WorkThresholds,
   22|       |    pub block_exists: bool,
   23|       |    pub account: Account,
   24|       |    pub previous_block: Option<SavedBlock>,
   25|       |    pub old_account_info: Option<AccountInfo>,
   26|       |    pub pending_receive_info: Option<PendingInfo>,
   27|       |    pub any_pending_exists: bool,
   28|       |    pub source_block_exists: bool,
   29|       |    pub now: UnixTimestamp,
   30|       |}
   31|       |
   32|       |impl<'a> BlockValidator<'a> {
   33|     32|    pub(crate) fn validate(&self) -> Result<BlockInsertInstructions, BlockStatus> {
   34|     32|        self.epoch_block_pre_checks()?;
                                                   ^0
   35|     32|        self.ensure_block_does_not_exist_yet()?;
                                                            ^0
   36|     32|        self.ensure_valid_predecessor()?;
                                                     ^0
   37|     32|        self.ensure_valid_signature()?;
                                                   ^0
   38|     32|        self.ensure_block_is_not_for_burn_account()?;
                                                                 ^0
   39|     32|        self.ensure_account_exists_for_none_open_block()?;
                                                                      ^0
   40|     32|        self.ensure_no_double_account_open()?;
                                                          ^0
   41|     32|        self.ensure_previous_block_is_correct()?;
                                                             ^0
   42|     32|        self.ensure_open_block_has_link()?;
                                                       ^0
   43|     32|        self.ensure_no_reveive_balance_change_without_link()?;
                                                                          ^0
   44|     32|        self.ensure_pending_receive_is_correct()?;
                                                              ^0
   45|     32|        self.ensure_sufficient_work()?;
                                                   ^0
   46|     32|        self.ensure_no_negative_amount_send()?;
                                                           ^0
   47|     32|        self.ensure_valid_epoch_block()?;
                                                     ^0
   48|       |
   49|     32|        Ok(self.create_instructions())
   50|     32|    }
   51|       |
   52|     32|    fn create_instructions(&self) -> BlockInsertInstructions {
   53|     32|        BlockInsertInstructions {
   54|     32|            account: self.account,
   55|     32|            old_account_info: self.old_account_info.clone().unwrap_or_default(),
   56|     32|            set_account_info: self.new_account_info(),
   57|     32|            delete_pending: self.delete_received_pending_info(),
   58|     32|            insert_pending: self.new_pending_info(),
   59|     32|            set_sideband: self.new_sideband(),
   60|     32|            is_epoch_block: self.is_epoch_block(),
   61|     32|        }
   62|     32|    }
   63|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/open_block_rules.rs:
    1|       |use super::BlockValidator;
    2|       |use crate::BlockStatus;
    3|       |use rsnano_core::Block;
    4|       |
    5|       |impl<'a> BlockValidator<'a> {
    6|     32|    pub(crate) fn ensure_block_is_not_for_burn_account(&self) -> Result<(), BlockStatus> {
    7|     32|        if self.account.is_zero() {
    8|      0|            Err(BlockStatus::OpenedBurnAccount)
    9|       |        } else {
   10|     32|            Ok(())
   11|       |        }
   12|     32|    }
   13|       |
   14|     32|    pub(crate) fn ensure_no_double_account_open(&self) -> Result<(), BlockStatus> {
   15|     32|        if self.account_exists() && self.block.is_open() {
                                                  ^28
   16|      0|            Err(BlockStatus::Fork)
   17|       |        } else {
   18|     32|            Ok(())
   19|       |        }
   20|     32|    }
   21|       |
   22|     32|    pub(crate) fn ensure_open_block_has_link(&self) -> Result<(), BlockStatus> {
   23|     32|        if let Block::State(state) = self.block {
   24|     32|            if self.block.is_open() && state.link().is_zero() {
                                                     ^4
   25|      0|                return Err(BlockStatus::GapSource);
   26|     32|            }
   27|      0|        }
   28|     32|        Ok(())
   29|     32|    }
   30|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/receive_block_rules.rs:
    1|       |use super::BlockValidator;
    2|       |use crate::BlockStatus;
    3|       |use rsnano_core::{Block, Epoch};
    4|       |
    5|       |impl<'a> BlockValidator<'a> {
    6|     32|    pub fn ensure_pending_receive_is_correct(&self) -> Result<(), BlockStatus> {
    7|     32|        self.ensure_source_block_exists()?;
                                                       ^0
    8|     32|        self.ensure_receive_block_receives_pending_amount()?;
                                                                         ^0
    9|     32|        self.ensure_legacy_source_is_epoch_0()
   10|     32|    }
   11|       |
   12|     32|    fn ensure_source_block_exists(&self) -> Result<(), BlockStatus> {
   13|     32|        if self.is_receive() && !self.source_block_exists {
                                              ^4
   14|      0|            Err(BlockStatus::GapSource)
   15|       |        } else {
   16|     32|            Ok(())
   17|       |        }
   18|     32|    }
   19|       |
   20|     32|    fn ensure_receive_block_receives_pending_amount(&self) -> Result<(), BlockStatus> {
   21|     32|        if self.is_receive() {
   22|      4|            match &self.pending_receive_info {
   23|      4|                Some(pending) => {
   24|      4|                    if self.amount_received() != pending.amount {
   25|      0|                        return Err(BlockStatus::BalanceMismatch);
   26|      4|                    }
   27|       |                }
   28|       |                None => {
   29|      0|                    return Err(BlockStatus::Unreceivable);
   30|       |                }
   31|       |            };
   32|     28|        }
   33|       |
   34|     32|        Ok(())
   35|     32|    }
   36|       |
   37|     32|    fn ensure_legacy_source_is_epoch_0(&self) -> Result<(), BlockStatus> {
   38|     32|        let is_legacy_receive =
   39|     32|            matches!(self.block, Block::LegacyReceive(_) | Block::LegacyOpen(_));
   40|       |
   41|     32|        if is_legacy_receive
   42|      0|            && self
   43|      0|                .pending_receive_info
   44|      0|                .as_ref()
   45|      0|                .map(|x| x.epoch)
   46|      0|                .unwrap_or_default()
   47|      0|                != Epoch::Epoch0
   48|       |        {
   49|      0|            Err(BlockStatus::Unreceivable)
   50|       |        } else {
   51|     32|            Ok(())
   52|       |        }
   53|     32|    }
   54|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validation/send_block_rules.rs:
    1|       |use super::BlockValidator;
    2|       |use crate::BlockStatus;
    3|       |use rsnano_core::Block;
    4|       |
    5|       |impl<'a> BlockValidator<'a> {
    6|       |    /// If there's no link, the balance must remain the same, only the representative can change
    7|     32|    pub(crate) fn ensure_no_reveive_balance_change_without_link(&self) -> Result<(), BlockStatus> {
    8|     32|        if let Block::State(state) = self.block {
    9|     32|            if state.link().is_zero() && !self.amount_received().is_zero() {
                                                       ^0
   10|      0|                return Err(BlockStatus::BalanceMismatch);
   11|     32|            }
   12|      0|        }
   13|       |
   14|     32|        Ok(())
   15|     32|    }
   16|       |
   17|     32|    pub(crate) fn ensure_no_negative_amount_send(&self) -> Result<(), BlockStatus> {
   18|       |        // Is this trying to spend a negative amount (Malicious)
   19|     32|        if let Block::LegacySend(send) = self.block {
                                               ^0
   20|      0|            if self.previous_balance() < send.balance() {
   21|      0|                return Err(BlockStatus::NegativeSpend);
   22|      0|            };
   23|     32|        }
   24|       |
   25|     32|        Ok(())
   26|     32|    }
   27|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_insertion/validator_factory.rs:
    1|       |use rsnano_core::{utils::UnixTimestamp, Account, Block, PendingKey, SavedBlock};
    2|       |use rsnano_store_lmdb::Transaction;
    3|       |
    4|       |use crate::Ledger;
    5|       |
    6|       |use super::BlockValidator;
    7|       |
    8|       |pub(crate) struct BlockValidatorFactory<'a> {
    9|       |    ledger: &'a Ledger,
   10|       |    txn: &'a dyn Transaction,
   11|       |    block: &'a Block,
   12|       |}
   13|       |
   14|       |impl<'a> BlockValidatorFactory<'a> {
   15|     32|    pub(crate) fn new(ledger: &'a Ledger, txn: &'a dyn Transaction, block: &'a Block) -> Self {
   16|     32|        Self { ledger, txn, block }
   17|     32|    }
   18|       |
   19|     32|    pub(crate) fn create_validator(&self) -> BlockValidator<'a> {
   20|     32|        let previous_block = self.load_previous_block();
   21|     32|        let account = self.get_account(&previous_block);
   22|     32|        let account = account.unwrap_or_default();
   23|     32|        let source_block = self.block.source_or_link();
   24|     32|        let source_block_exists = !source_block.is_zero()
   25|     32|            && self
   26|     32|                .ledger
   27|     32|                .any()
   28|     32|                .block_exists_or_pruned(self.txn, &source_block);
   29|       |
   30|     32|        let pending_receive_info = if source_block.is_zero() {
   31|      0|            None
   32|       |        } else {
   33|     32|            self.ledger
   34|     32|                .any()
   35|     32|                .get_pending(self.txn, &PendingKey::new(account, source_block))
   36|       |        };
   37|       |
   38|     32|        BlockValidator {
   39|     32|            block: self.block,
   40|     32|            epochs: &self.ledger.constants.epochs,
   41|     32|            work: &self.ledger.constants.work,
   42|     32|            account,
   43|     32|            block_exists: self
   44|     32|                .ledger
   45|     32|                .any()
   46|     32|                .block_exists_or_pruned(self.txn, &self.block.hash()),
   47|     32|            old_account_info: self.ledger.account_info(self.txn, &account),
   48|     32|            pending_receive_info,
   49|     32|            any_pending_exists: self.ledger.any().receivable_exists(self.txn, account),
   50|     32|            source_block_exists,
   51|     32|            previous_block,
   52|     32|            now: UnixTimestamp::now(),
   53|     32|        }
   54|     32|    }
   55|       |
   56|     32|    fn get_account(&self, previous: &Option<SavedBlock>) -> Option<Account> {
   57|     32|        match self.block.account_field() {
   58|     32|            Some(account) => Some(account),
   59|      0|            None => match previous {
   60|      0|                Some(p) => Some(p.account()),
   61|      0|                None => None,
   62|       |            },
   63|       |        }
   64|     32|    }
   65|       |
   66|     32|    fn load_previous_block(&self) -> Option<SavedBlock> {
   67|     32|        if !self.block.previous().is_zero() {
   68|     28|            self.ledger
   69|     28|                .any()
   70|     28|                .get_block(self.txn, &self.block.previous())
   71|       |        } else {
   72|      4|            None
   73|       |        }
   74|     32|    }
   75|       |}
   76|       |
   77|       |#[cfg(test)]
   78|       |mod tests {
   79|       |    use super::*;
   80|       |    use rsnano_core::{AccountInfo, BlockHash, Link, PendingInfo, TestBlockBuilder};
   81|       |
   82|       |    #[test]
   83|       |    fn block_for_unknown_account() {
   84|       |        let block = TestBlockBuilder::state().build();
   85|       |        let ledger = Ledger::new_null_builder().finish();
   86|       |        let txn = ledger.read_txn();
   87|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
   88|       |
   89|       |        assert_eq!(validator.block.hash(), block.hash());
   90|       |        assert_eq!(validator.epochs, &ledger.constants.epochs);
   91|       |        assert_eq!(validator.account, block.account_field().unwrap());
   92|       |        assert_eq!(validator.block_exists, false);
   93|       |        assert_eq!(validator.old_account_info, None);
   94|       |        assert_eq!(validator.pending_receive_info, None);
   95|       |        assert_eq!(validator.any_pending_exists, false);
   96|       |        assert_eq!(validator.source_block_exists, false);
   97|       |        assert_eq!(validator.previous_block, None);
   98|       |        assert!(validator.now >= UnixTimestamp::now());
   99|       |    }
  100|       |
  101|       |    #[test]
  102|       |    fn get_account_from_previous_block() {
  103|       |        let previous = TestBlockBuilder::legacy_send().build_saved();
  104|       |        let block = TestBlockBuilder::legacy_send()
  105|       |            .previous(previous.hash())
  106|       |            .build();
  107|       |        let ledger = Ledger::new_null_builder().block(&previous).finish();
  108|       |        let txn = ledger.read_txn();
  109|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  110|       |
  111|       |        assert_eq!(validator.account, previous.account());
  112|       |    }
  113|       |
  114|       |    #[test]
  115|       |    fn block_exists() {
  116|       |        let block = TestBlockBuilder::state().build_saved();
  117|       |        let ledger = Ledger::new_null_builder().block(&block).finish();
  118|       |        let txn = ledger.read_txn();
  119|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  120|       |        assert_eq!(validator.block_exists, true);
  121|       |    }
  122|       |
  123|       |    #[test]
  124|       |    fn pruned_block_exists() {
  125|       |        let block = TestBlockBuilder::state().build();
  126|       |        let ledger = Ledger::new_null_builder().pruned(&block.hash()).finish();
  127|       |        let txn = ledger.read_txn();
  128|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  129|       |        assert_eq!(validator.block_exists, true);
  130|       |    }
  131|       |
  132|       |    #[test]
  133|       |    fn account_info() {
  134|       |        let block = TestBlockBuilder::state().build();
  135|       |        let account_info = AccountInfo::new_test_instance();
  136|       |        let ledger = Ledger::new_null_builder()
  137|       |            .account_info(&block.account_field().unwrap(), &account_info)
  138|       |            .finish();
  139|       |        let txn = ledger.read_txn();
  140|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  141|       |        assert_eq!(validator.old_account_info, Some(account_info));
  142|       |    }
  143|       |
  144|       |    #[test]
  145|       |    fn pending_receive_info_for_state_block() {
  146|       |        let block = TestBlockBuilder::state().link(Link::from(42)).build();
  147|       |        let pending_info = PendingInfo::new_test_instance();
  148|       |        let ledger = Ledger::new_null_builder()
  149|       |            .pending(
  150|       |                &PendingKey::new(block.account_field().unwrap(), BlockHash::from(42)),
  151|       |                &pending_info,
  152|       |            )
  153|       |            .finish();
  154|       |        let txn = ledger.read_txn();
  155|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  156|       |        assert_eq!(validator.pending_receive_info, Some(pending_info));
  157|       |    }
  158|       |
  159|       |    #[test]
  160|       |    fn pending_receive_info_for_legacy_receive() {
  161|       |        let previous = TestBlockBuilder::legacy_open().build_saved();
  162|       |        let account = previous.account();
  163|       |        let block = TestBlockBuilder::legacy_receive()
  164|       |            .previous(previous.hash())
  165|       |            .source(BlockHash::from(42))
  166|       |            .build();
  167|       |        let pending_info = PendingInfo::new_test_instance();
  168|       |        let ledger = Ledger::new_null_builder()
  169|       |            .block(&previous)
  170|       |            .pending(
  171|       |                &PendingKey::new(account, BlockHash::from(42)),
  172|       |                &pending_info,
  173|       |            )
  174|       |            .finish();
  175|       |        let txn = ledger.read_txn();
  176|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  177|       |        assert_eq!(validator.pending_receive_info, Some(pending_info));
  178|       |    }
  179|       |
  180|       |    #[test]
  181|       |    fn any_pending_exists() {
  182|       |        let block = TestBlockBuilder::state().build();
  183|       |        let pending_info = PendingInfo::new_test_instance();
  184|       |        let ledger = Ledger::new_null_builder()
  185|       |            .pending(
  186|       |                &PendingKey::new(block.account_field().unwrap(), BlockHash::from(42)),
  187|       |                &pending_info,
  188|       |            )
  189|       |            .finish();
  190|       |        let txn = ledger.read_txn();
  191|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  192|       |        assert_eq!(validator.any_pending_exists, true);
  193|       |    }
  194|       |
  195|       |    #[test]
  196|       |    fn source_block_exists() {
  197|       |        let source = TestBlockBuilder::state().build_saved();
  198|       |        let block = TestBlockBuilder::state().link(source.hash()).build();
  199|       |        let ledger = Ledger::new_null_builder().block(&source).finish();
  200|       |        let txn = ledger.read_txn();
  201|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  202|       |        assert_eq!(validator.source_block_exists, true);
  203|       |    }
  204|       |
  205|       |    #[test]
  206|       |    fn pruned_source_block_exists() {
  207|       |        let block = TestBlockBuilder::state().link(BlockHash::from(42)).build();
  208|       |        let ledger = Ledger::new_null_builder()
  209|       |            .pruned(&BlockHash::from(42))
  210|       |            .finish();
  211|       |        let txn = ledger.read_txn();
  212|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  213|       |        assert_eq!(validator.source_block_exists, true);
  214|       |    }
  215|       |
  216|       |    #[test]
  217|       |    fn previous_block() {
  218|       |        let previous = SavedBlock::new_test_instance();
  219|       |        let block = TestBlockBuilder::state()
  220|       |            .previous(previous.hash())
  221|       |            .build_saved();
  222|       |        let ledger = Ledger::new_null_builder().block(&previous).finish();
  223|       |        let txn = ledger.read_txn();
  224|       |        let validator = BlockValidatorFactory::new(&ledger, &txn, &block).create_validator();
  225|       |        assert_eq!(validator.previous_block, Some(previous));
  226|       |    }
  227|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_rollback/instructions_executor.rs:
    1|       |use super::rollback_planner::RollbackInstructions;
    2|       |use crate::Ledger;
    3|       |use rsnano_core::{Amount, PublicKey};
    4|       |use rsnano_store_lmdb::LmdbWriteTransaction;
    5|       |use std::sync::atomic::Ordering;
    6|       |
    7|       |/// Updates the ledger according to the RollbackInstructions
    8|       |pub(crate) struct RollbackInstructionsExecutor<'a> {
    9|       |    ledger: &'a Ledger,
   10|       |    txn: &'a mut LmdbWriteTransaction,
   11|       |    instructions: &'a RollbackInstructions,
   12|       |}
   13|       |
   14|       |impl<'a> RollbackInstructionsExecutor<'a> {
   15|      0|    pub(crate) fn new(
   16|      0|        ledger: &'a Ledger,
   17|      0|        txn: &'a mut LmdbWriteTransaction,
   18|      0|        instructions: &'a RollbackInstructions,
   19|      0|    ) -> Self {
   20|      0|        Self {
   21|      0|            ledger,
   22|      0|            txn,
   23|      0|            instructions,
   24|      0|        }
   25|      0|    }
   26|       |
   27|      0|    pub(crate) fn execute(&mut self) {
   28|      0|        self.update_pending_table();
   29|      0|        self.update_account_table();
   30|      0|        self.update_block_table();
   31|      0|        self.roll_back_representative_cache();
   32|      0|        self.ledger
   33|      0|            .store
   34|      0|            .cache
   35|      0|            .block_count
   36|      0|            .fetch_sub(1, Ordering::SeqCst);
   37|      0|
   38|      0|        self.ledger
   39|      0|            .observer
   40|      0|            .block_rolled_back(self.instructions.block_sub_type);
   41|      0|    }
   42|       |
   43|      0|    fn update_block_table(&mut self) {
   44|      0|        self.ledger
   45|      0|            .store
   46|      0|            .block
   47|      0|            .del(self.txn, &self.instructions.block_hash);
   48|       |
   49|      0|        if let Some(hash) = self.instructions.clear_successor {
   50|      0|            self.ledger.store.block.successor_clear(self.txn, &hash);
   51|      0|        }
   52|      0|    }
   53|       |
   54|      0|    fn update_account_table(&mut self) {
   55|      0|        self.ledger.update_account(
   56|      0|            self.txn,
   57|      0|            &self.instructions.account,
   58|      0|            &self.instructions.old_account_info,
   59|      0|            &self.instructions.set_account_info,
   60|      0|        );
   61|      0|    }
   62|       |
   63|      0|    fn update_pending_table(&mut self) {
   64|      0|        if let Some(pending_key) = &self.instructions.remove_pending {
   65|      0|            self.ledger.store.pending.del(self.txn, pending_key);
   66|      0|        }
   67|      0|        if let Some((key, info)) = &self.instructions.add_pending {
   68|      0|            self.ledger.store.pending.put(self.txn, key, info);
   69|      0|        }
   70|      0|    }
   71|       |
   72|      0|    fn roll_back_representative_cache(&mut self) {
   73|      0|        if let Some(previous_rep) = &self.instructions.new_representative {
   74|      0|            self.roll_back_change_in_representative_cache(previous_rep);
   75|      0|        } else {
   76|      0|            self.roll_back_receive_in_representative_cache()
   77|       |        }
   78|      0|    }
   79|       |
   80|      0|    fn roll_back_change_in_representative_cache(&mut self, previous_representative: &PublicKey) {
   81|      0|        self.ledger.rep_weights_updater.representation_add_dual(
   82|      0|            self.txn,
   83|      0|            self.instructions.old_account_info.representative,
   84|      0|            Amount::zero().wrapping_sub(self.instructions.old_account_info.balance),
   85|      0|            *previous_representative,
   86|      0|            self.instructions.new_balance,
   87|      0|        );
   88|      0|    }
   89|       |
   90|      0|    fn roll_back_receive_in_representative_cache(&mut self) {
   91|      0|        self.ledger.rep_weights_updater.representation_add(
   92|      0|            self.txn,
   93|      0|            self.instructions.old_account_info.representative,
   94|      0|            Amount::zero().wrapping_sub(self.instructions.old_account_info.balance),
   95|      0|        );
   96|      0|    }
   97|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_rollback/planner_factory.rs:
    1|       |use super::rollback_planner::RollbackPlanner;
    2|       |use crate::Ledger;
    3|       |use rsnano_core::{
    4|       |    utils::UnixTimestamp, Account, AccountInfo, Block, BlockHash, ConfirmationHeightInfo,
    5|       |    PendingInfo, PendingKey, PublicKey, SavedBlock,
    6|       |};
    7|       |use rsnano_store_lmdb::Transaction;
    8|       |
    9|       |pub(crate) struct RollbackPlannerFactory<'a> {
   10|       |    ledger: &'a Ledger,
   11|       |    txn: &'a dyn Transaction,
   12|       |    head_block: &'a SavedBlock,
   13|       |}
   14|       |
   15|       |impl<'a> RollbackPlannerFactory<'a> {
   16|      0|    pub(crate) fn new(
   17|      0|        ledger: &'a Ledger,
   18|      0|        txn: &'a dyn Transaction,
   19|      0|        head_block: &'a SavedBlock,
   20|      0|    ) -> Self {
   21|      0|        Self {
   22|      0|            ledger,
   23|      0|            txn,
   24|      0|            head_block,
   25|      0|        }
   26|      0|    }
   27|       |
   28|      0|    pub(crate) fn create_planner(&self) -> anyhow::Result<RollbackPlanner<'a>> {
   29|      0|        let account = self.get_account(self.head_block)?;
   30|      0|        let planner = RollbackPlanner {
   31|      0|            epochs: &self.ledger.constants.epochs,
   32|      0|            head_block: self.head_block.clone(),
   33|      0|            account,
   34|      0|            current_account_info: self.load_account(&account),
   35|      0|            previous_representative: self.get_previous_representative()?,
   36|      0|            previous: self.load_previous_block()?,
   37|      0|            linked_account: self.load_linked_account(),
   38|      0|            pending_receive: self.load_pending_receive(),
   39|      0|            latest_block_for_destination: self.latest_block_for_destination(),
   40|      0|            confirmation_height: self.account_confirmation_height(),
   41|      0|            now: UnixTimestamp::now(),
   42|      0|        };
   43|      0|        Ok(planner)
   44|      0|    }
   45|       |
   46|      0|    fn latest_block_for_destination(&self) -> Option<BlockHash> {
   47|      0|        self.ledger
   48|      0|            .any()
   49|      0|            .account_head(self.txn, &self.head_block.destination_or_link())
   50|      0|    }
   51|       |
   52|      0|    fn load_pending_receive(&self) -> Option<PendingInfo> {
   53|      0|        self.ledger.any().get_pending(
   54|      0|            self.txn,
   55|      0|            &PendingKey::new(
   56|      0|                self.head_block.destination_or_link(),
   57|      0|                self.head_block.hash(),
   58|      0|            ),
   59|      0|        )
   60|      0|    }
   61|       |
   62|      0|    fn load_linked_account(&self) -> Account {
   63|      0|        self.ledger
   64|      0|            .any()
   65|      0|            .block_account(self.txn, &self.head_block.source_or_link())
   66|      0|            .unwrap_or_default()
   67|      0|    }
   68|       |
   69|      0|    fn load_previous_block(&self) -> anyhow::Result<Option<SavedBlock>> {
   70|      0|        let previous = self.head_block.previous();
   71|      0|        Ok(if previous.is_zero() {
   72|      0|            None
   73|       |        } else {
   74|      0|            Some(self.load_block(&previous)?)
   75|       |        })
   76|      0|    }
   77|       |
   78|      0|    fn account_confirmation_height(&self) -> ConfirmationHeightInfo {
   79|      0|        self.ledger
   80|      0|            .store
   81|      0|            .confirmation_height
   82|      0|            .get(self.txn, &self.head_block.account())
   83|      0|            .unwrap_or_default()
   84|      0|    }
   85|       |
   86|      0|    fn get_account(&self, block: &Block) -> anyhow::Result<Account> {
   87|      0|        self.ledger
   88|      0|            .any()
   89|      0|            .block_account(self.txn, &block.hash())
   90|      0|            .ok_or_else(|| anyhow!("account not found"))
   91|      0|    }
   92|       |
   93|      0|    fn load_account(&self, account: &Account) -> AccountInfo {
   94|      0|        self.ledger
   95|      0|            .account_info(self.txn, account)
   96|      0|            .unwrap_or_default()
   97|      0|    }
   98|       |
   99|      0|    fn load_block(&self, block_hash: &BlockHash) -> anyhow::Result<SavedBlock> {
  100|      0|        self.ledger
  101|      0|            .any()
  102|      0|            .get_block(self.txn, block_hash)
  103|      0|            .ok_or_else(|| anyhow!("block not found"))
  104|      0|    }
  105|       |
  106|      0|    fn get_previous_representative(&self) -> anyhow::Result<Option<PublicKey>> {
  107|      0|        let previous = self.head_block.previous();
  108|      0|        let rep_block_hash = if !previous.is_zero() {
  109|      0|            self.ledger.representative_block_hash(self.txn, &previous)
  110|       |        } else {
  111|      0|            BlockHash::zero()
  112|       |        };
  113|       |
  114|      0|        let previous_rep = if !rep_block_hash.is_zero() {
  115|      0|            let rep_block = self.load_block(&rep_block_hash)?;
  116|      0|            Some(rep_block.representative_field().unwrap_or_default())
  117|       |        } else {
  118|      0|            None
  119|       |        };
  120|      0|        Ok(previous_rep)
  121|      0|    }
  122|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_rollback/rollback_performer.rs:
    1|       |use rsnano_core::{AccountInfo, BlockHash, SavedBlock};
    2|       |use rsnano_store_lmdb::LmdbWriteTransaction;
    3|       |
    4|       |use crate::Ledger;
    5|       |
    6|       |use super::{
    7|       |    instructions_executor::RollbackInstructionsExecutor, planner_factory::RollbackPlannerFactory,
    8|       |    rollback_planner::RollbackStep,
    9|       |};
   10|       |
   11|       |pub(crate) struct BlockRollbackPerformer<'a> {
   12|       |    ledger: &'a Ledger,
   13|       |    pub txn: &'a mut LmdbWriteTransaction,
   14|       |    pub rolled_back: Vec<SavedBlock>,
   15|       |}
   16|       |
   17|       |impl<'a> BlockRollbackPerformer<'a> {
   18|      0|    pub(crate) fn new(ledger: &'a Ledger, txn: &'a mut LmdbWriteTransaction) -> Self {
   19|      0|        Self {
   20|      0|            ledger,
   21|      0|            txn,
   22|      0|            rolled_back: Vec::new(),
   23|      0|        }
   24|      0|    }
   25|       |
   26|      0|    pub(crate) fn roll_back(&mut self, block_hash: &BlockHash) -> anyhow::Result<()> {
   27|      0|        self.roll_back_block_and_successors(block_hash)?;
   28|      0|        Ok(())
   29|      0|    }
   30|       |
   31|      0|    fn roll_back_block_and_successors(&mut self, block_hash: &BlockHash) -> anyhow::Result<()> {
   32|      0|        let block = self.load_block(block_hash)?;
   33|      0|        while self.block_exists(block_hash) {
   34|      0|            let head_block = self.load_account_head(&block)?;
   35|      0|            self.roll_back_head_block(head_block)?;
   36|       |        }
   37|      0|        Ok(())
   38|      0|    }
   39|       |
   40|      0|    fn roll_back_head_block(&mut self, head_block: SavedBlock) -> Result<(), anyhow::Error> {
   41|      0|        let planner =
   42|      0|            RollbackPlannerFactory::new(self.ledger, self.txn, &head_block).create_planner()?;
   43|      0|        let step = planner.roll_back_head_block()?;
   44|      0|        self.execute(step, head_block)?;
   45|      0|        Ok(())
   46|      0|    }
   47|       |
   48|      0|    fn execute(&mut self, step: RollbackStep, head_block: SavedBlock) -> Result<(), anyhow::Error> {
   49|      0|        match step {
   50|      0|            RollbackStep::RollBackBlock(instructions) => {
   51|      0|                RollbackInstructionsExecutor::new(self.ledger, self.txn, &instructions).execute();
   52|      0|                self.rolled_back.push(head_block);
   53|      0|                Ok(())
   54|       |            }
   55|      0|            RollbackStep::RequestDependencyRollback(dependency_hash) => {
   56|      0|                self.roll_back_block_and_successors(&dependency_hash)
   57|       |            }
   58|       |        }
   59|      0|    }
   60|       |
   61|      0|    fn block_exists(&self, block_hash: &BlockHash) -> bool {
   62|      0|        self.ledger.any().block_exists(self.txn, block_hash)
   63|      0|    }
   64|       |
   65|      0|    fn load_account_head(&self, block: &SavedBlock) -> anyhow::Result<SavedBlock> {
   66|      0|        let account_info = self.get_account_info(block);
   67|      0|        self.load_block(&account_info.head)
   68|      0|    }
   69|       |
   70|      0|    fn get_account_info(&self, block: &SavedBlock) -> AccountInfo {
   71|      0|        self.ledger
   72|      0|            .account_info(self.txn, &block.account())
   73|      0|            .unwrap()
   74|      0|    }
   75|       |
   76|      0|    fn load_block(&self, block_hash: &BlockHash) -> anyhow::Result<SavedBlock> {
   77|      0|        self.ledger
   78|      0|            .any()
   79|      0|            .get_block(self.txn, block_hash)
   80|      0|            .ok_or_else(|| anyhow!("block not found"))
   81|      0|    }
   82|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/block_rollback/rollback_planner.rs:
    1|       |use rsnano_core::{
    2|       |    utils::UnixTimestamp, Account, AccountInfo, Amount, BlockHash, BlockSubType,
    3|       |    ConfirmationHeightInfo, Epoch, Epochs, PendingInfo, PendingKey, PublicKey, SavedBlock,
    4|       |};
    5|       |
    6|       |pub(crate) enum RollbackStep {
    7|       |    RollBackBlock(RollbackInstructions),
    8|       |    /// the given dependent block has to be rolled back first
    9|       |    RequestDependencyRollback(BlockHash),
   10|       |}
   11|       |
   12|       |/// Describes how to roll back a block
   13|       |pub(crate) struct RollbackInstructions {
   14|       |    pub block_hash: BlockHash,
   15|       |    pub block_sub_type: BlockSubType,
   16|       |    pub account: Account,
   17|       |    pub remove_pending: Option<PendingKey>,
   18|       |    pub add_pending: Option<(PendingKey, PendingInfo)>,
   19|       |    pub set_account_info: AccountInfo,
   20|       |    pub old_account_info: AccountInfo,
   21|       |    pub clear_successor: Option<BlockHash>,
   22|       |    pub new_balance: Amount,
   23|       |    pub new_representative: Option<PublicKey>,
   24|       |}
   25|       |
   26|       |/// Create RollbackInstructions for a given block
   27|       |pub(crate) struct RollbackPlanner<'a> {
   28|       |    pub epochs: &'a Epochs,
   29|       |    pub head_block: SavedBlock,
   30|       |    pub account: Account,
   31|       |    pub current_account_info: AccountInfo,
   32|       |    pub previous_representative: Option<PublicKey>,
   33|       |    pub previous: Option<SavedBlock>,
   34|       |    pub linked_account: Account,
   35|       |    pub pending_receive: Option<PendingInfo>,
   36|       |    pub latest_block_for_destination: Option<BlockHash>,
   37|       |    pub confirmation_height: ConfirmationHeightInfo,
   38|       |    pub now: UnixTimestamp,
   39|       |}
   40|       |
   41|       |impl<'a> RollbackPlanner<'a> {
   42|      0|    pub(crate) fn roll_back_head_block(&self) -> anyhow::Result<RollbackStep> {
   43|      0|        self.ensure_block_is_not_confirmed()?;
   44|      0|        let block_sub_type = self.block_sub_type();
   45|      0|
   46|      0|        if block_sub_type == BlockSubType::Send {
   47|      0|            if let Some(step) = self.roll_back_destination_account_if_send_block_is_received()? {
   48|      0|                return Ok(step);
   49|      0|            }
   50|      0|        }
   51|       |
   52|      0|        let instructions = RollbackInstructions {
   53|      0|            block_hash: self.head_block.hash(),
   54|      0|            account: self.account,
   55|      0|            old_account_info: self.current_account_info.clone(),
   56|      0|            new_representative: self.previous_representative,
   57|      0|            block_sub_type,
   58|      0|            remove_pending: self.remove_pending(),
   59|      0|            add_pending: self.add_pending(),
   60|      0|            set_account_info: self.previous_account_info(),
   61|      0|            clear_successor: self.previous.as_ref().map(|b| b.hash()),
   62|      0|            new_balance: self.previous_balance(),
   63|      0|        };
   64|      0|
   65|      0|        Ok(RollbackStep::RollBackBlock(instructions))
   66|      0|    }
   67|       |
   68|      0|    fn ensure_block_is_not_confirmed(&self) -> anyhow::Result<()> {
   69|      0|        if self.head_block.height() <= self.confirmation_height.height {
   70|      0|            bail!("Only unconfirmed blocks can be rolled back")
   71|      0|        }
   72|      0|
   73|      0|        Ok(())
   74|      0|    }
   75|       |
   76|      0|    fn roll_back_destination_account_if_send_block_is_received(
   77|      0|        &self,
   78|      0|    ) -> anyhow::Result<Option<RollbackStep>> {
   79|      0|        if self.pending_receive.is_some() {
   80|      0|            return Ok(None);
   81|      0|        }
   82|       |
   83|      0|        let latest_destination_block = self
   84|      0|            .latest_block_for_destination
   85|      0|            .ok_or_else(|| anyhow!("no latest block for destination"))?;
   86|       |
   87|      0|        Ok(Some(RollbackStep::RequestDependencyRollback(
   88|      0|            latest_destination_block,
   89|      0|        )))
   90|      0|    }
   91|       |
   92|      0|    fn add_pending(&self) -> Option<(PendingKey, PendingInfo)> {
   93|      0|        match self.block_sub_type() {
   94|       |            BlockSubType::Open | BlockSubType::Receive => {
   95|      0|                let source_hash = self.head_block.source_or_link();
   96|      0|                // Pending account entry can be incorrect if source block was pruned. But it's not affecting correct ledger processing
   97|      0|                Some((
   98|      0|                    PendingKey::new(self.account, source_hash),
   99|      0|                    PendingInfo::new(
  100|      0|                        self.linked_account,
  101|      0|                        self.current_account_info.balance - self.previous_balance(),
  102|      0|                        self.head_block.source_epoch(),
  103|      0|                    ),
  104|      0|                ))
  105|       |            }
  106|      0|            _ => None,
  107|       |        }
  108|      0|    }
  109|       |
  110|      0|    fn remove_pending(&self) -> Option<PendingKey> {
  111|      0|        if self.block_sub_type() == BlockSubType::Send {
  112|      0|            Some(PendingKey::new(
  113|      0|                self.head_block.destination_or_link(),
  114|      0|                self.head_block.hash(),
  115|      0|            ))
  116|       |        } else {
  117|      0|            None
  118|       |        }
  119|      0|    }
  120|       |
  121|      0|    fn block_sub_type(&self) -> BlockSubType {
  122|      0|        if self.current_account_info.balance < self.previous_balance() {
  123|      0|            BlockSubType::Send
  124|      0|        } else if self.current_account_info.balance > self.previous_balance() {
  125|      0|            if self.head_block.is_open() {
  126|      0|                BlockSubType::Open
  127|       |            } else {
  128|      0|                BlockSubType::Receive
  129|       |            }
  130|      0|        } else if self
  131|      0|            .epochs
  132|      0|            .is_epoch_link(&self.head_block.link_field().unwrap_or_default())
  133|       |        {
  134|      0|            BlockSubType::Epoch
  135|       |        } else {
  136|      0|            BlockSubType::Change
  137|       |        }
  138|      0|    }
  139|       |
  140|      0|    fn previous_account_info(&self) -> AccountInfo {
  141|      0|        if self.head_block.previous().is_zero() {
  142|      0|            Default::default()
  143|       |        } else {
  144|      0|            AccountInfo {
  145|      0|                head: self.head_block.previous(),
  146|      0|                representative: self.previous_representative(),
  147|      0|                open_block: self.current_account_info.open_block,
  148|      0|                balance: self.previous_balance(),
  149|      0|                modified: self.now,
  150|      0|                block_count: self.current_account_info.block_count - 1,
  151|      0|                epoch: self.previous_epoch(),
  152|      0|            }
  153|       |        }
  154|      0|    }
  155|       |
  156|      0|    fn previous_representative(&self) -> PublicKey {
  157|      0|        self.previous_representative
  158|      0|            .unwrap_or(self.current_account_info.representative)
  159|      0|    }
  160|       |
  161|      0|    fn previous_epoch(&self) -> Epoch {
  162|      0|        match &self.previous {
  163|      0|            Some(previous) => previous.epoch(),
  164|      0|            None => Epoch::Epoch0,
  165|       |        }
  166|      0|    }
  167|       |
  168|      0|    fn previous_balance(&self) -> Amount {
  169|      0|        match &self.previous {
  170|      0|            Some(previous) => previous.balance(),
  171|      0|            None => Amount::zero(),
  172|       |        }
  173|      0|    }
  174|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/dependent_blocks_finder.rs:
    1|       |use crate::ledger::Ledger;
    2|       |use rsnano_core::{Block, BlockBase, BlockHash, DependentBlocks, SavedBlock, StateBlock};
    3|       |use rsnano_store_lmdb::Transaction;
    4|       |
    5|       |/// Finds all dependent blocks for a given block.
    6|       |/// There can be at most two dependencies per block, namely "previous" and "link/source".
    7|       |pub struct DependentBlocksFinder<'a> {
    8|       |    ledger: &'a Ledger,
    9|       |    txn: &'a dyn Transaction,
   10|       |}
   11|       |
   12|       |impl<'a> DependentBlocksFinder<'a> {
   13|      0|    pub fn new(ledger: &'a Ledger, txn: &'a dyn Transaction) -> Self {
   14|      0|        Self { ledger, txn }
   15|      0|    }
   16|       |
   17|      0|    pub fn find_dependent_blocks(&self, block: &SavedBlock) -> DependentBlocks {
   18|      0|        block.dependent_blocks(
   19|      0|            &self.ledger.constants.epochs,
   20|      0|            &self.ledger.constants.genesis_account,
   21|      0|        )
   22|      0|    }
   23|       |
   24|      0|    pub fn find_dependent_blocks_for_unsaved_block(&self, block: &Block) -> DependentBlocks {
   25|      0|        match block {
   26|      0|            Block::LegacySend(b) => b.dependent_blocks(),
   27|      0|            Block::LegacyChange(b) => b.dependent_blocks(),
   28|      0|            Block::LegacyReceive(b) => b.dependent_blocks(),
   29|      0|            Block::LegacyOpen(b) => b.dependent_blocks(&self.ledger.constants.genesis_account),
   30|       |            // a ledger lookup is needed if it is a state block!
   31|      0|            Block::State(state) => {
   32|      0|                let linked_block = if self.is_receive_or_change(state) {
   33|      0|                    state.link().into()
   34|       |                } else {
   35|      0|                    BlockHash::zero()
   36|       |                };
   37|      0|                DependentBlocks::new(block.previous(), linked_block)
   38|       |            }
   39|       |        }
   40|      0|    }
   41|       |
   42|      0|    fn is_receive_or_change(&self, state: &StateBlock) -> bool {
   43|      0|        !self.ledger.is_epoch_link(&state.link()) && !self.is_send(state)
   44|      0|    }
   45|       |
   46|       |    // This function is used in place of block.is_send() as it is tolerant to the block not having the sideband information loaded
   47|       |    // This is needed for instance in vote generation on forks which have not yet had sideband information attached
   48|      0|    fn is_send(&self, block: &StateBlock) -> bool {
   49|      0|        if block.previous().is_zero() {
   50|      0|            return false;
   51|      0|        }
   52|      0|
   53|      0|        let previous_balance = self
   54|      0|            .ledger
   55|      0|            .any()
   56|      0|            .block_balance(self.txn, &block.previous())
   57|      0|            .unwrap_or_default();
   58|      0|
   59|      0|        block.balance() < previous_balance
   60|      0|    }
   61|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/generate_cache_flags.rs:
    1|       |#[derive(Clone)]
    2|       |pub struct GenerateCacheFlags {
    3|       |    pub reps: bool,
    4|       |    pub cemented_count: bool,
    5|       |    pub unchecked_count: bool,
    6|       |    pub account_count: bool,
    7|       |    pub block_count: bool,
    8|       |}
    9|       |
   10|       |impl GenerateCacheFlags {
   11|     30|    pub fn new() -> Self {
   12|     30|        Self {
   13|     30|            reps: true,
   14|     30|            cemented_count: true,
   15|     30|            unchecked_count: true,
   16|     30|            account_count: true,
   17|     30|            block_count: true,
   18|     30|        }
   19|     30|    }
   20|       |
   21|      0|    pub fn enable_all(&mut self) {
   22|      0|        self.reps = true;
   23|      0|        self.cemented_count = true;
   24|      0|        self.unchecked_count = true;
   25|      0|        self.account_count = true;
   26|      0|    }
   27|       |}
   28|       |
   29|       |impl Default for GenerateCacheFlags {
   30|      0|    fn default() -> Self {
   31|      0|        Self::new()
   32|      0|    }
   33|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/ledger.rs:
    1|       |use super::DependentBlocksFinder;
    2|       |use crate::{
    3|       |    block_cementer::BlockCementer,
    4|       |    block_insertion::{BlockInserter, BlockValidatorFactory},
    5|       |    ledger_set_confirmed::LedgerSetConfirmed,
    6|       |    BlockRollbackPerformer, GenerateCacheFlags, LedgerConstants, LedgerSetAny, RepWeightCache,
    7|       |    RepWeightsUpdater, RepresentativeBlockFinder, WriteGuard, WriteQueue,
    8|       |};
    9|       |use rsnano_core::{
   10|       |    block_priority,
   11|       |    utils::{ContainerInfo, UnixTimestamp},
   12|       |    Account, AccountInfo, Amount, Block, BlockHash, BlockSubType, ConfirmationHeightInfo,
   13|       |    DependentBlocks, Epoch, Link, PendingInfo, PendingKey, PublicKey, Root, SavedBlock,
   14|       |};
   15|       |use rsnano_store_lmdb::{
   16|       |    ConfiguredAccountDatabaseBuilder, ConfiguredBlockDatabaseBuilder,
   17|       |    ConfiguredConfirmationHeightDatabaseBuilder, ConfiguredPeersDatabaseBuilder,
   18|       |    ConfiguredPendingDatabaseBuilder, ConfiguredPrunedDatabaseBuilder, LedgerCache,
   19|       |    LmdbAccountStore, LmdbBlockStore, LmdbConfirmationHeightStore, LmdbEnv, LmdbFinalVoteStore,
   20|       |    LmdbOnlineWeightStore, LmdbPeerStore, LmdbPendingStore, LmdbPrunedStore, LmdbReadTransaction,
   21|       |    LmdbRepWeightStore, LmdbStore, LmdbVersionStore, LmdbWriteTransaction, Transaction,
   22|       |};
   23|       |use std::{
   24|       |    collections::HashMap,
   25|       |    net::SocketAddrV6,
   26|       |    sync::{
   27|       |        atomic::{AtomicBool, Ordering},
   28|       |        Arc,
   29|       |    },
   30|       |    time::{Duration, SystemTime},
   31|       |};
   32|       |
   33|      0|#[derive(PartialEq, Eq, Debug, Clone, Copy, FromPrimitive)]
   34|       |#[repr(u8)]
   35|       |pub enum BlockStatus {
   36|       |    Progress,      // Hasn't been seen before, signed correctly
   37|       |    BadSignature,  // Signature was bad, forged or transmission error
   38|       |    Old,           // Already seen and was valid
   39|       |    NegativeSpend, // Malicious attempt to spend a negative amount
   40|       |    Fork,          // Malicious fork based on previous
   41|       |    /// Source block doesn't exist, has already been received, or requires an account upgrade (epoch blocks)
   42|       |    Unreceivable,
   43|       |    /// Block marked as previous is unknown
   44|       |    GapPrevious,
   45|       |    /// Block marked as source is unknown
   46|       |    GapSource,
   47|       |    /// Block marked as pending blocks required for epoch open block are unknown
   48|       |    GapEpochOpenPending,
   49|       |    /// Block attempts to open the burn account
   50|       |    OpenedBurnAccount,
   51|       |    /// Balance and amount delta don't match
   52|       |    BalanceMismatch,
   53|       |    /// Representative is changed when it is not allowed
   54|       |    RepresentativeMismatch,
   55|       |    /// This block cannot follow the previous block
   56|       |    BlockPosition,
   57|       |    /// Insufficient work for this block, even though it passed the minimal validation
   58|       |    InsufficientWork,
   59|       |}
   60|       |
   61|       |impl BlockStatus {
   62|      0|    pub fn as_str(&self) -> &'static str {
   63|      0|        match self {
   64|      0|            BlockStatus::Progress => "Progress",
   65|      0|            BlockStatus::BadSignature => "Bad signature",
   66|      0|            BlockStatus::Old => "Old",
   67|      0|            BlockStatus::NegativeSpend => "Negative spend",
   68|      0|            BlockStatus::Fork => "Fork",
   69|      0|            BlockStatus::Unreceivable => "Unreceivable",
   70|      0|            BlockStatus::GapPrevious => "Gap previous",
   71|      0|            BlockStatus::GapSource => "Gap source",
   72|      0|            BlockStatus::GapEpochOpenPending => "Gap epoch open pendign",
   73|      0|            BlockStatus::OpenedBurnAccount => "Opened burn account",
   74|      0|            BlockStatus::BalanceMismatch => "Balance mismatch",
   75|      0|            BlockStatus::RepresentativeMismatch => "Representative mismatch",
   76|      0|            BlockStatus::BlockPosition => "Block position",
   77|      0|            BlockStatus::InsufficientWork => "Insufficient work",
   78|       |        }
   79|      0|    }
   80|       |}
   81|       |
   82|       |pub trait LedgerObserver: Send + Sync {
   83|  16.3k|    fn blocks_cemented(&self, _cemented_count: u64) {}
   84|      0|    fn block_rolled_back(&self, _block_type: BlockSubType) {}
   85|      0|    fn block_rolled_back2(&self, _block: &Block, _is_epoch: bool) {}
   86|     32|    fn block_added(&self, _block: &Block, _is_epoch: bool) {}
   87|      0|    fn dependent_unconfirmed(&self) {}
   88|       |}
   89|       |
   90|       |pub struct NullLedgerObserver {}
   91|       |
   92|       |impl NullLedgerObserver {
   93|     27|    pub fn new() -> Self {
   94|     27|        Self {}
   95|     27|    }
   96|       |}
   97|       |
   98|       |impl LedgerObserver for NullLedgerObserver {}
   99|       |
  100|       |pub struct Ledger {
  101|       |    pub store: Arc<LmdbStore>,
  102|       |    pub rep_weights_updater: RepWeightsUpdater,
  103|       |    pub rep_weights: Arc<RepWeightCache>,
  104|       |    pub constants: LedgerConstants,
  105|       |    pub observer: Arc<dyn LedgerObserver>,
  106|       |    pruning: AtomicBool,
  107|       |    pub write_queue: Arc<WriteQueue>,
  108|       |}
  109|       |
  110|       |pub struct NullLedgerBuilder {
  111|       |    blocks: ConfiguredBlockDatabaseBuilder,
  112|       |    accounts: ConfiguredAccountDatabaseBuilder,
  113|       |    pending: ConfiguredPendingDatabaseBuilder,
  114|       |    pruned: ConfiguredPrunedDatabaseBuilder,
  115|       |    peers: ConfiguredPeersDatabaseBuilder,
  116|       |    confirmation_height: ConfiguredConfirmationHeightDatabaseBuilder,
  117|       |    min_rep_weight: Amount,
  118|       |}
  119|       |
  120|       |impl NullLedgerBuilder {
  121|     20|    fn new() -> Self {
  122|     20|        Self {
  123|     20|            blocks: ConfiguredBlockDatabaseBuilder::new(),
  124|     20|            accounts: ConfiguredAccountDatabaseBuilder::new(),
  125|     20|            pending: ConfiguredPendingDatabaseBuilder::new(),
  126|     20|            pruned: ConfiguredPrunedDatabaseBuilder::new(),
  127|     20|            peers: ConfiguredPeersDatabaseBuilder::new(),
  128|     20|            confirmation_height: ConfiguredConfirmationHeightDatabaseBuilder::new(),
  129|     20|            min_rep_weight: Amount::zero(),
  130|     20|        }
  131|     20|    }
  132|       |
  133|      0|    pub fn block(mut self, block: &SavedBlock) -> Self {
  134|      0|        self.blocks = self.blocks.block(block);
  135|      0|        self
  136|      0|    }
  137|       |
  138|      1|    pub fn blocks<'a>(mut self, blocks: impl IntoIterator<Item = &'a SavedBlock>) -> Self {
  139|      2|        for b in blocks.into_iter() {
                               ^1
  140|      2|            self.blocks = self.blocks.block(b);
  141|      2|        }
  142|      1|        self
  143|      1|    }
  144|       |
  145|     19|    pub fn peers(mut self, peers: impl IntoIterator<Item = (SocketAddrV6, SystemTime)>) -> Self {
  146|     19|        for (peer, time) in peers.into_iter() {
                           ^17
  147|     17|            self.peers = self.peers.peer(peer, time)
  148|       |        }
  149|     19|        self
  150|     19|    }
  151|       |
  152|      1|    pub fn confirmation_height(mut self, account: &Account, info: &ConfirmationHeightInfo) -> Self {
  153|      1|        self.confirmation_height = self.confirmation_height.height(account, info);
  154|      1|        self
  155|      1|    }
  156|       |
  157|      0|    pub fn account_info(mut self, account: &Account, info: &AccountInfo) -> Self {
  158|      0|        self.accounts = self.accounts.account(account, info);
  159|      0|        self
  160|      0|    }
  161|       |
  162|      0|    pub fn pending(mut self, key: &PendingKey, info: &PendingInfo) -> Self {
  163|      0|        self.pending = self.pending.pending(key, info);
  164|      0|        self
  165|      0|    }
  166|       |
  167|      0|    pub fn pruned(mut self, hash: &BlockHash) -> Self {
  168|      0|        self.pruned = self.pruned.pruned(hash);
  169|      0|        self
  170|      0|    }
  171|       |
  172|     20|    pub fn finish(self) -> Ledger {
  173|     20|        let env = Arc::new(
  174|     20|            LmdbEnv::new_null_with()
  175|     20|                .configured_database(self.blocks.build())
  176|     20|                .configured_database(self.accounts.build())
  177|     20|                .configured_database(self.pending.build())
  178|     20|                .configured_database(self.pruned.build())
  179|     20|                .configured_database(self.confirmation_height.build())
  180|     20|                .configured_database(self.peers.build())
  181|     20|                .build(),
  182|     20|        );
  183|     20|
  184|     20|        let store = LmdbStore {
  185|     20|            cache: Arc::new(LedgerCache::new()),
  186|     20|            env: env.clone(),
  187|     20|            account: Arc::new(LmdbAccountStore::new(env.clone()).unwrap()),
  188|     20|            block: Arc::new(LmdbBlockStore::new(env.clone()).unwrap()),
  189|     20|            confirmation_height: Arc::new(LmdbConfirmationHeightStore::new(env.clone()).unwrap()),
  190|     20|            final_vote: Arc::new(LmdbFinalVoteStore::new(env.clone()).unwrap()),
  191|     20|            online_weight: Arc::new(LmdbOnlineWeightStore::new(env.clone()).unwrap()),
  192|     20|            peer: Arc::new(LmdbPeerStore::new(env.clone()).unwrap()),
  193|     20|            pending: Arc::new(LmdbPendingStore::new(env.clone()).unwrap()),
  194|     20|            pruned: Arc::new(LmdbPrunedStore::new(env.clone()).unwrap()),
  195|     20|            rep_weight: Arc::new(LmdbRepWeightStore::new(env.clone()).unwrap()),
  196|     20|            version: Arc::new(LmdbVersionStore::new(env.clone()).unwrap()),
  197|     20|        };
  198|     20|        Ledger::new(
  199|     20|            Arc::new(store),
  200|     20|            LedgerConstants::unit_test(),
  201|     20|            self.min_rep_weight,
  202|     20|            Arc::new(RepWeightCache::new()),
  203|     20|        )
  204|     20|        .unwrap()
  205|     20|    }
  206|       |}
  207|       |
  208|       |impl Ledger {
  209|      2|    pub fn new_null() -> Self {
  210|      2|        Self::new(
  211|      2|            Arc::new(LmdbStore::new_null()),
  212|      2|            LedgerConstants::unit_test(),
  213|      2|            Amount::zero(),
  214|      2|            Arc::new(RepWeightCache::new()),
  215|      2|        )
  216|      2|        .unwrap()
  217|      2|    }
  218|       |
  219|     20|    pub fn new_null_builder() -> NullLedgerBuilder {
  220|     20|        NullLedgerBuilder::new()
  221|     20|    }
  222|       |
  223|     27|    pub fn new(
  224|     27|        store: Arc<LmdbStore>,
  225|     27|        constants: LedgerConstants,
  226|     27|        min_rep_weight: Amount,
  227|     27|        rep_weights: Arc<RepWeightCache>,
  228|     27|    ) -> anyhow::Result<Self> {
  229|     27|        let rep_weights_updater =
  230|     27|            RepWeightsUpdater::new(store.rep_weight.clone(), min_rep_weight, &rep_weights);
  231|     27|
  232|     27|        let mut ledger = Self {
  233|     27|            rep_weights,
  234|     27|            rep_weights_updater,
  235|     27|            store,
  236|     27|            constants,
  237|     27|            observer: Arc::new(NullLedgerObserver::new()),
  238|     27|            pruning: AtomicBool::new(false),
  239|     27|            write_queue: Arc::new(WriteQueue::new()),
  240|     27|        };
  241|     27|
  242|     27|        ledger.initialize(&GenerateCacheFlags::new())?;
                                                                   ^0
  243|       |
  244|     27|        Ok(ledger)
  245|     27|    }
  246|       |
  247|      3|    pub fn set_observer(&mut self, observer: Arc<dyn LedgerObserver>) {
  248|      3|        self.observer = observer;
  249|      3|    }
  250|       |
  251|    115|    pub fn read_txn(&self) -> LmdbReadTransaction {
  252|    115|        self.store.tx_begin_read()
  253|    115|    }
  254|       |
  255|     74|    pub fn rw_txn(&self) -> LmdbWriteTransaction {
  256|     74|        self.store.tx_begin_write()
  257|     74|    }
  258|       |
  259|     27|    fn initialize(&mut self, generate_cache: &GenerateCacheFlags) -> anyhow::Result<()> {
  260|     27|        if self.store.account.iter(&self.read_txn()).next().is_none() {
  261|     27|            self.add_genesis_block(&mut self.rw_txn());
  262|     27|        }
                       ^0
  263|       |
  264|     27|        if generate_cache.reps || generate_cache.account_count || generate_cache.block_count {
                                                ^0                              ^0
  265|  1.08k|            self.store.account.for_each_par(|iter| {
  266|  1.08k|                let mut block_count = 0;
  267|  1.08k|                let mut account_count = 0;
  268|  1.08k|                let mut rep_weights: HashMap<PublicKey, Amount> = HashMap::new();
  269|  1.08k|                for (_, info) in iter {
                                      ^5
  270|      5|                    block_count += info.block_count;
  271|      5|                    account_count += 1;
  272|      5|                    if !info.balance.is_zero() {
  273|      5|                        let total = rep_weights.entry(info.representative).or_default();
  274|      5|                        *total += info.balance;
  275|      5|                    }
                                   ^0
  276|       |                }
  277|  1.08k|                self.store
  278|  1.08k|                    .cache
  279|  1.08k|                    .block_count
  280|  1.08k|                    .fetch_add(block_count, Ordering::SeqCst);
  281|  1.08k|                self.store
  282|  1.08k|                    .cache
  283|  1.08k|                    .account_count
  284|  1.08k|                    .fetch_add(account_count, Ordering::SeqCst);
  285|  1.08k|                self.rep_weights_updater.copy_from(&rep_weights);
  286|  1.08k|            });
  287|     27|        }
                       ^0
  288|       |
  289|     27|        if generate_cache.cemented_count {
  290|  1.08k|            self.store.confirmation_height.for_each_par(|iter| {
  291|  1.08k|                let mut cemented_count = 0;
  292|  1.08k|                for (_, info) in iter {
                                      ^6
  293|      6|                    cemented_count += info.height;
  294|      6|                }
  295|  1.08k|                self.store
  296|  1.08k|                    .cache
  297|  1.08k|                    .cemented_count
  298|  1.08k|                    .fetch_add(cemented_count, Ordering::SeqCst);
  299|  1.08k|            });
  300|     27|        }
                       ^0
  301|       |
  302|     27|        let transaction = self.store.tx_begin_read();
  303|     27|        self.store
  304|     27|            .cache
  305|     27|            .pruned_count
  306|     27|            .fetch_add(self.store.pruned.count(&transaction), Ordering::SeqCst);
  307|     27|
  308|     27|        Ok(())
  309|     27|    }
  310|       |
  311|     27|    fn add_genesis_block(&self, txn: &mut LmdbWriteTransaction) {
  312|     27|        let genesis_hash = self.constants.genesis_block.hash();
  313|     27|        let genesis_account = self.constants.genesis_account;
  314|     27|        self.store.block.put(txn, &self.constants.genesis_block);
  315|     27|
  316|     27|        self.store.confirmation_height.put(
  317|     27|            txn,
  318|     27|            &genesis_account,
  319|     27|            &ConfirmationHeightInfo::new(1, genesis_hash),
  320|     27|        );
  321|     27|
  322|     27|        self.store.account.put(
  323|     27|            txn,
  324|     27|            &genesis_account,
  325|     27|            &AccountInfo {
  326|     27|                head: genesis_hash,
  327|     27|                representative: genesis_account.into(),
  328|     27|                open_block: genesis_hash,
  329|     27|                balance: u128::MAX.into(),
  330|     27|                modified: UnixTimestamp::ZERO,
  331|     27|                block_count: 1,
  332|     27|                epoch: Epoch::Epoch0,
  333|     27|            },
  334|     27|        );
  335|     27|        self.store
  336|     27|            .rep_weight
  337|     27|            .put(txn, genesis_account.into(), Amount::MAX);
  338|     27|    }
  339|       |
  340|  16.3k|    pub fn refresh_if_needed(
  341|  16.3k|        &self,
  342|  16.3k|        write_guard: WriteGuard,
  343|  16.3k|        mut tx: LmdbWriteTransaction,
  344|  16.3k|    ) -> (WriteGuard, LmdbWriteTransaction) {
  345|  16.3k|        if tx.elapsed() > Duration::from_millis(500) {
  346|      3|            let writer = write_guard.writer;
  347|      3|            tx.commit();
  348|      3|            drop(write_guard);
  349|      3|
  350|      3|            let write_guard = self.write_queue.wait(writer);
  351|      3|            tx.renew();
  352|      3|            (write_guard, tx)
  353|       |        } else {
  354|  16.3k|            (write_guard, tx)
  355|       |        }
  356|  16.3k|    }
  357|       |
  358|  16.6k|    pub fn any(&self) -> LedgerSetAny {
  359|  16.6k|        LedgerSetAny::new(&self.store)
  360|  16.6k|    }
  361|       |
  362|  16.3k|    pub fn confirmed(&self) -> LedgerSetConfirmed {
  363|  16.3k|        LedgerSetConfirmed::new(&self.store)
  364|  16.3k|    }
  365|       |
  366|      3|    pub fn pruning_enabled(&self) -> bool {
  367|      3|        self.pruning.load(Ordering::SeqCst)
  368|      3|    }
  369|       |
  370|      0|    pub fn enable_pruning(&self) {
  371|      0|        self.pruning.store(true, Ordering::SeqCst);
  372|      0|    }
  373|       |
  374|      0|    pub fn bootstrap_weight_max_blocks(&self) -> u64 {
  375|      0|        self.rep_weights.bootstrap_weight_max_blocks()
  376|      0|    }
  377|       |
  378|      0|    pub fn unconfirmed_exists(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
  379|      0|        self.any().block_exists(tx, hash) && !self.confirmed().block_exists(tx, hash)
  380|      0|    }
  381|       |
  382|      0|    pub fn account_receivable(
  383|      0|        &self,
  384|      0|        txn: &dyn Transaction,
  385|      0|        account: &Account,
  386|      0|        only_confirmed: bool,
  387|      0|    ) -> Amount {
  388|      0|        let mut result = Amount::zero();
  389|       |
  390|      0|        for (key, info) in
  391|      0|            self.any()
  392|      0|                .account_receivable_upper_bound(txn, *account, BlockHash::zero())
  393|       |        {
  394|      0|            if !only_confirmed
  395|      0|                || self
  396|      0|                    .confirmed()
  397|      0|                    .block_exists_or_pruned(txn, &key.send_block_hash)
  398|      0|            {
  399|      0|                result += info.amount;
  400|      0|            }
  401|       |        }
  402|       |
  403|      0|        result
  404|      0|    }
  405|       |
  406|      0|    pub fn block_text(&self, hash: &BlockHash) -> anyhow::Result<String> {
  407|      0|        let txn = self.store.tx_begin_read();
  408|      0|        match self.any().get_block(&txn, hash) {
  409|      0|            Some(block) => block.to_json(),
  410|      0|            None => Ok(String::new()),
  411|       |        }
  412|      0|    }
  413|       |
  414|      3|    pub fn random_blocks(&self, tx: &dyn Transaction, count: usize) -> Vec<SavedBlock> {
  415|      3|        let mut result = Vec::with_capacity(count);
  416|      3|        let starting_hash = BlockHash::random();
  417|      3|
  418|      3|        // It is more efficient to choose a random starting point and pick a few sequential blocks from there
  419|      3|        let mut it = self.store.block.iter_range(tx, starting_hash..);
  420|     63|        while result.len() < count {
  421|     60|            match it.next() {
  422|     30|                Some(block) => result.push(block),
  423|     30|                None => {
  424|     30|                    // Wrap around when reaching the end
  425|     30|                    it = self.store.block.iter_range(tx, BlockHash::zero()..);
  426|     30|                }
  427|       |            }
  428|       |        }
  429|       |
  430|      3|        result
  431|      3|    }
  432|       |
  433|       |    /// Returns the cached vote weight for the given representative.
  434|       |    /// If the weight is below the cache limit it returns 0.
  435|       |    /// During bootstrap it returns the preconfigured bootstrap weights.
  436|      0|    pub fn weight(&self, rep: &PublicKey) -> Amount {
  437|      0|        self.rep_weights.weight(rep)
  438|      0|    }
  439|       |
  440|       |    /// Returns the exact vote weight for the given representative by doing a database lookup
  441|      0|    pub fn weight_exact(&self, txn: &dyn Transaction, representative: PublicKey) -> Amount {
  442|      0|        self.store
  443|      0|            .rep_weight
  444|      0|            .get(txn, &representative)
  445|      0|            .unwrap_or_default()
  446|      0|    }
  447|       |
  448|       |    /// Return latest root for account, account number if there are no blocks for this account
  449|      0|    pub fn latest_root(&self, txn: &dyn Transaction, account: &Account) -> Root {
  450|      0|        match self.account_info(txn, account) {
  451|      0|            Some(info) => info.head.into(),
  452|      0|            None => account.into(),
  453|       |        }
  454|      0|    }
  455|       |
  456|      0|    pub fn version(&self, txn: &dyn Transaction, hash: &BlockHash) -> Epoch {
  457|      0|        self.any()
  458|      0|            .get_block(txn, hash)
  459|      0|            .map(|block| block.epoch())
  460|      0|            .unwrap_or(Epoch::Epoch0)
  461|      0|    }
  462|       |
  463|      0|    pub fn is_epoch_link(&self, link: &Link) -> bool {
  464|      0|        self.constants.epochs.is_epoch_link(link)
  465|      0|    }
  466|       |
  467|      0|    pub fn epoch_signer(&self, link: &Link) -> Option<Account> {
  468|      0|        self.constants.epochs.epoch_signer(link)
  469|      0|    }
  470|       |
  471|       |    /// Given the block hash of a send block, find the associated receive block that receives that send.
  472|       |    /// The send block hash is not checked in any way, it is assumed to be correct.
  473|       |    /// Return the receive block on success and None on failure
  474|      0|    pub fn find_receive_block_by_send_hash(
  475|      0|        &self,
  476|      0|        txn: &dyn Transaction,
  477|      0|        destination: &Account,
  478|      0|        send_block_hash: &BlockHash,
  479|      0|    ) -> Option<SavedBlock> {
  480|       |        // get the cemented frontier
  481|      0|        let info = self.store.confirmation_height.get(txn, destination)?;
  482|      0|        let mut possible_receive_block = self.any().get_block(txn, &info.frontier);
  483|       |
  484|       |        // walk down the chain until the source field of a receive block matches the send block hash
  485|      0|        while let Some(current) = possible_receive_block {
  486|      0|            if current.is_receive() && Some(*send_block_hash) == current.source() {
  487|       |                // we have a match
  488|      0|                return Some(current);
  489|      0|            }
  490|      0|
  491|      0|            possible_receive_block = self.any().get_block(txn, &current.previous());
  492|       |        }
  493|       |
  494|      0|        None
  495|      0|    }
  496|       |
  497|      0|    pub fn epoch_link(&self, epoch: Epoch) -> Option<Link> {
  498|      0|        self.constants.epochs.link(epoch).cloned()
  499|      0|    }
  500|       |
  501|     32|    pub fn update_account(
  502|     32|        &self,
  503|     32|        txn: &mut LmdbWriteTransaction,
  504|     32|        account: &Account,
  505|     32|        old_info: &AccountInfo,
  506|     32|        new_info: &AccountInfo,
  507|     32|    ) {
  508|     32|        if !new_info.head.is_zero() {
  509|     32|            if old_info.head.is_zero() && new_info.open_block == new_info.head {
                                                        ^4
  510|      4|                self.store
  511|      4|                    .cache
  512|      4|                    .account_count
  513|      4|                    .fetch_add(1, Ordering::SeqCst);
  514|     28|            }
  515|     32|            if !old_info.head.is_zero() && old_info.epoch != new_info.epoch {
                                                         ^28
  516|      0|                // store.account ().put won't erase existing entries if they're in different tables
  517|      0|                self.store.account.del(txn, account);
  518|     32|            }
  519|     32|            self.store.account.put(txn, account, new_info);
  520|       |        } else {
  521|      0|            debug_assert!(!self.store.confirmation_height.exists(txn, account));
  522|      0|            self.store.account.del(txn, account);
  523|      0|            debug_assert!(self.store.cache.account_count.load(Ordering::SeqCst) > 0);
  524|      0|            self.store
  525|      0|                .cache
  526|      0|                .account_count
  527|      0|                .fetch_sub(1, Ordering::SeqCst);
  528|       |        }
  529|     32|    }
  530|       |
  531|      0|    pub fn pruning_action(
  532|      0|        &self,
  533|      0|        txn: &mut LmdbWriteTransaction,
  534|      0|        hash: &BlockHash,
  535|      0|        batch_size: u64,
  536|      0|    ) -> u64 {
  537|      0|        let mut pruned_count = 0;
  538|      0|        let mut hash = *hash;
  539|      0|        let genesis_hash = self.constants.genesis_block.hash();
  540|       |
  541|      0|        while !hash.is_zero() && hash != genesis_hash {
  542|      0|            if let Some(block) = self.any().get_block(txn, &hash) {
  543|      0|                assert!(self.confirmed().block_exists_or_pruned(txn, &hash));
  544|      0|                self.store.block.del(txn, &hash);
  545|      0|                self.store.pruned.put(txn, &hash);
  546|      0|                hash = block.previous();
  547|      0|                pruned_count += 1;
  548|      0|                self.store.cache.pruned_count.fetch_add(1, Ordering::SeqCst);
  549|      0|                if pruned_count % batch_size == 0 {
  550|      0|                    txn.commit();
  551|      0|                    txn.renew();
  552|      0|                }
  553|      0|            } else if self.store.pruned.exists(txn, &hash) {
  554|      0|                hash = BlockHash::zero();
  555|      0|            } else {
  556|      0|                panic!("Error finding block for pruning");
  557|       |            }
  558|       |        }
  559|       |
  560|      0|        pruned_count
  561|      0|    }
  562|       |
  563|      0|    pub fn dependents_confirmed(&self, txn: &dyn Transaction, block: &SavedBlock) -> bool {
  564|      0|        self.dependent_blocks(txn, block)
  565|      0|            .iter()
  566|      0|            .all(|hash| self.confirmed().block_exists_or_pruned(txn, hash))
  567|      0|    }
  568|       |
  569|      0|    pub fn dependent_blocks(&self, txn: &dyn Transaction, block: &SavedBlock) -> DependentBlocks {
  570|      0|        DependentBlocksFinder::new(self, txn).find_dependent_blocks(block)
  571|      0|    }
  572|       |
  573|      0|    pub fn dependents_confirmed_for_unsaved_block(
  574|      0|        &self,
  575|      0|        txn: &dyn Transaction,
  576|      0|        block: &Block,
  577|      0|    ) -> bool {
  578|      0|        self.dependent_blocks_for_unsaved_block(txn, block)
  579|      0|            .iter()
  580|      0|            .all(|hash| self.confirmed().block_exists_or_pruned(txn, hash))
  581|      0|    }
  582|       |
  583|      0|    fn dependent_blocks_for_unsaved_block(
  584|      0|        &self,
  585|      0|        txn: &dyn Transaction,
  586|      0|        block: &Block,
  587|      0|    ) -> DependentBlocks {
  588|      0|        DependentBlocksFinder::new(self, txn).find_dependent_blocks_for_unsaved_block(block)
  589|      0|    }
  590|       |
  591|       |    ///
  592|       |    /// Rollback blocks until `block' doesn't exist or it tries to penetrate the confirmation height
  593|      0|    pub fn rollback(
  594|      0|        &self,
  595|      0|        txn: &mut LmdbWriteTransaction,
  596|      0|        block: &BlockHash,
  597|      0|    ) -> Result<Vec<SavedBlock>, (anyhow::Error, Vec<SavedBlock>)> {
  598|      0|        let mut performer = BlockRollbackPerformer::new(self, txn);
  599|      0|        match performer.roll_back(block) {
  600|      0|            Ok(()) => Ok(performer.rolled_back),
  601|      0|            Err(e) => Err((e, performer.rolled_back)),
  602|       |        }
  603|      0|    }
  604|       |
  605|       |    /// Returns the latest block with representative information
  606|      0|    pub fn representative_block_hash(&self, txn: &dyn Transaction, hash: &BlockHash) -> BlockHash {
  607|      0|        let hash = RepresentativeBlockFinder::new(txn, self.store.as_ref()).find_rep_block(*hash);
  608|      0|        debug_assert!(hash.is_zero() || self.store.block.exists(txn, &hash));
  609|      0|        hash
  610|      0|    }
  611|       |
  612|     32|    pub fn process(
  613|     32|        &self,
  614|     32|        txn: &mut LmdbWriteTransaction,
  615|     32|        block: &Block,
  616|     32|    ) -> Result<SavedBlock, BlockStatus> {
  617|     32|        let validator = BlockValidatorFactory::new(self, txn, block).create_validator();
  618|     32|        let instructions = validator.validate()?;
                                                             ^0
  619|     32|        let inserted = BlockInserter::new(self, txn, block, &instructions).insert();
  620|     32|        Ok(inserted)
  621|     32|    }
  622|       |
  623|      0|    pub fn get_block(&self, txn: &dyn Transaction, hash: &BlockHash) -> Option<SavedBlock> {
  624|      0|        self.store.block.get(txn, hash)
  625|      0|    }
  626|       |
  627|     32|    pub fn account_info(
  628|     32|        &self,
  629|     32|        transaction: &dyn Transaction,
  630|     32|        account: &Account,
  631|     32|    ) -> Option<AccountInfo> {
  632|     32|        self.store.account.get(transaction, account)
  633|     32|    }
  634|       |
  635|      0|    pub fn get_confirmation_height(
  636|      0|        &self,
  637|      0|        txn: &dyn Transaction,
  638|      0|        account: &Account,
  639|      0|    ) -> Option<ConfirmationHeightInfo> {
  640|      0|        self.store.confirmation_height.get(txn, account)
  641|      0|    }
  642|       |
  643|      0|    pub fn confirm(&self, txn: &mut LmdbWriteTransaction, hash: BlockHash) -> Vec<SavedBlock> {
  644|      0|        self.confirm_max(txn, hash, 1024 * 128)
  645|      0|    }
  646|       |
  647|       |    /// Both stack and result set are bounded to limit maximum memory usage
  648|       |    /// Callers must ensure that the target block was confirmed, and if not, call this function multiple times
  649|  16.3k|    pub fn confirm_max(
  650|  16.3k|        &self,
  651|  16.3k|        txn: &mut LmdbWriteTransaction,
  652|  16.3k|        target_hash: BlockHash,
  653|  16.3k|        max_blocks: usize,
  654|  16.3k|    ) -> Vec<SavedBlock> {
  655|  16.3k|        BlockCementer::new(&self.store, self.observer.as_ref(), &self.constants).confirm(
  656|  16.3k|            txn,
  657|  16.3k|            target_hash,
  658|  16.3k|            max_blocks,
  659|  16.3k|        )
  660|  16.3k|    }
  661|       |
  662|       |    /// Returned priority balance is maximum of block balance and previous block balance
  663|       |    /// to handle full account balance send cases.
  664|       |    /// Returned timestamp is the previous block timestamp or the current timestamp
  665|       |    /// if there's no previous block.
  666|      0|    pub fn block_priority(
  667|      0|        &self,
  668|      0|        tx: &dyn Transaction,
  669|      0|        block: &SavedBlock,
  670|      0|    ) -> (Amount, UnixTimestamp) {
  671|      0|        let previous_block = self.previous_block(tx, block);
  672|      0|        block_priority(block, previous_block.as_ref())
  673|      0|    }
  674|       |
  675|      0|    pub fn previous_block(&self, tx: &dyn Transaction, block: &SavedBlock) -> Option<SavedBlock> {
  676|      0|        if block.previous().is_zero() {
  677|      0|            None
  678|       |        } else {
  679|      0|            self.any().get_block(tx, &block.previous())
  680|       |        }
  681|      0|    }
  682|       |
  683|      6|    pub fn cemented_count(&self) -> u64 {
  684|      6|        self.store.cache.cemented_count.load(Ordering::SeqCst)
  685|      6|    }
  686|       |
  687|      6|    pub fn block_count(&self) -> u64 {
  688|      6|        self.store.cache.block_count.load(Ordering::SeqCst)
  689|      6|    }
  690|       |
  691|      9|    pub fn account_count(&self) -> u64 {
  692|      9|        self.store.cache.account_count.load(Ordering::SeqCst)
  693|      9|    }
  694|       |
  695|      0|    pub fn pruned_count(&self) -> u64 {
  696|      0|        self.store.cache.pruned_count.load(Ordering::SeqCst)
  697|      0|    }
  698|       |
  699|      3|    pub fn backlog_count(&self) -> u64 {
  700|      3|        let blocks = self.block_count();
  701|      3|        let cemented = self.cemented_count();
  702|      3|        if blocks > cemented {
  703|      0|            blocks - cemented
  704|       |        } else {
  705|      3|            0
  706|       |        }
  707|      3|    }
  708|       |
  709|      0|    pub fn container_info(&self) -> ContainerInfo {
  710|      0|        ContainerInfo::builder()
  711|      0|            .node("rep_weights", self.rep_weights.container_info())
  712|      0|            .finish()
  713|      0|    }
  714|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/ledger_constants.rs:
    1|       |use rsnano_core::{
    2|       |    epoch_v1_link, epoch_v2_link,
    3|       |    utils::{get_env_or_default_string, UnixTimestamp},
    4|       |    work::{WorkThresholds, WORK_THRESHOLDS_STUB},
    5|       |    Account, Amount, Block, BlockDetails, BlockHash, BlockSideband, Epoch, Epochs, Networks,
    6|       |    PublicKey, SavedBlock, DEV_GENESIS_KEY,
    7|       |};
    8|       |use std::sync::LazyLock;
    9|       |
   10|       |static BETA_PUBLIC_KEY_DATA: &str =
   11|       |    "259A438A8F9F9226130C84D902C237AF3E57C0981C7D709C288046B110D8C8AC";
   12|       |
   13|      1|static TEST_PUBLIC_KEY_DATA: LazyLock<String> = LazyLock::new(|| {
   14|      1|    get_env_or_default_string(
   15|      1|        "NANO_TEST_GENESIS_PUB",
   16|      1|        "45C6FF9D1706D61F0821327752671BDA9F9ED2DA40326B01935AB566FB9E08ED",
   17|      1|    ) // nano_1jg8zygjg3pp5w644emqcbmjqpnzmubfni3kfe1s8pooeuxsw49fdq1mco9j
   18|      1|});
   19|       |
   20|       |static DEV_GENESIS_DATA: &str = r###"{
   21|       |	"type": "open",
   22|       |	"source": "B0311EA55708D6A53C75CDBF88300259C6D018522FE3D4D0A242E431F9E8B6D0",
   23|       |	"representative": "xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtdo",
   24|       |	"account": "xrb_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpiij4txtdo",
   25|       |	"work": "7b42a00ee91d5810",
   26|       |	"signature": "ECDA914373A2F0CA1296475BAEE40500A7F0A7AD72A5A80C81D7FAB7F6C802B2CC7DB50F5DD0FB25B2EF11761FA7344A158DD5A700B21BD47DE5BD0F63153A02"
   27|       |    }"###;
   28|       |
   29|       |static BETA_GENESIS_DATA: &str = r###"{
   30|       |	"type": "open",
   31|       |	"source": "259A438A8F9F9226130C84D902C237AF3E57C0981C7D709C288046B110D8C8AC",
   32|       |	"representative": "nano_1betag7az9wk6rbis38s1d35hdsycz1bi95xg4g4j148p6afjk7embcurda4",
   33|       |	"account": "nano_1betag7az9wk6rbis38s1d35hdsycz1bi95xg4g4j148p6afjk7embcurda4",
   34|       |	"work": "e87a3ce39b43b84c",
   35|       |	"signature": "BC588273AC689726D129D3137653FB319B6EE6DB178F97421D11D075B46FD52B6748223C8FF4179399D35CB1A8DF36F759325BD2D3D4504904321FAFB71D7602"
   36|       |    }"###;
   37|       |
   38|       |static LIVE_GENESIS_DATA: &str = r###"{
   39|       |	"type": "open",
   40|       |	"source": "E89208DD038FBB269987689621D52292AE9C35941A7484756ECCED92A65093BA",
   41|       |	"representative": "xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3",
   42|       |	"account": "xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3",
   43|       |	"work": "62f05417dd3fb691",
   44|       |	"signature": "9F0C933C8ADE004D808EA1985FA746A7E95BA2A38F867640F53EC8F180BDFE9E2C1268DEAD7C2664F356E37ABA362BC58E46DBA03E523A7B5A19E4B6EB12BB02"
   45|       |    }"###;
   46|       |
   47|      1|static TEST_GENESIS_DATA: LazyLock<String> = LazyLock::new(|| {
   48|      1|    get_env_or_default_string(
   49|      1|        "NANO_TEST_GENESIS_BLOCK",
   50|      1|        r###"{
   51|      1|        "type": "open",
   52|      1|        "source": "45C6FF9D1706D61F0821327752671BDA9F9ED2DA40326B01935AB566FB9E08ED",
   53|      1|        "representative": "nano_1jg8zygjg3pp5w644emqcbmjqpnzmubfni3kfe1s8pooeuxsw49fdq1mco9j",
   54|      1|        "account": "nano_1jg8zygjg3pp5w644emqcbmjqpnzmubfni3kfe1s8pooeuxsw49fdq1mco9j",
   55|      1|        "work": "bc1ef279c1a34eb1",
   56|      1|        "signature": "15049467CAEE3EC768639E8E35792399B6078DA763DA4EBA8ECAD33B0EDC4AF2E7403893A5A602EB89B978DABEF1D6606BB00F3C0EE11449232B143B6E07170E"
   57|      1|        }"###,
   58|      1|    )
   59|      1|});
   60|       |
   61|       |pub static LEDGER_CONSTANTS_STUB: LazyLock<LedgerConstants> =
   62|      0|    LazyLock::new(|| LedgerConstants::new(WORK_THRESHOLDS_STUB.clone(), Networks::NanoDevNetwork));
   63|       |
   64|       |pub static DEV_GENESIS_BLOCK: LazyLock<SavedBlock> =
   65|      0|    LazyLock::new(|| LEDGER_CONSTANTS_STUB.genesis_block.clone());
   66|       |
   67|       |pub static DEV_GENESIS_ACCOUNT: LazyLock<Account> =
   68|      0|    LazyLock::new(|| DEV_GENESIS_BLOCK.account_field().unwrap());
   69|       |#[allow(dead_code)]
   70|       |pub static DEV_GENESIS_PUB_KEY: LazyLock<PublicKey> =
   71|      0|    LazyLock::new(|| DEV_GENESIS_BLOCK.account_field().unwrap().into());
   72|      0|pub static DEV_GENESIS_HASH: LazyLock<BlockHash> = LazyLock::new(|| DEV_GENESIS_BLOCK.hash());
   73|       |
   74|    128|fn parse_block_from_genesis_data(genesis_data: &str) -> anyhow::Result<Block> {
   75|    128|    let block = serde_json::from_str(genesis_data)?;
                                                                ^0
   76|    128|    Ok(block)
   77|    128|}
   78|       |
   79|       |#[cfg(test)]
   80|       |mod tests {
   81|       |    use rsnano_core::BlockType;
   82|       |
   83|       |    use super::*;
   84|       |
   85|       |    #[test]
   86|       |    fn test_parse_block() {
   87|       |        let block_str = r###"{"type": "open", "source": "37FCEA4DA94F1635484EFCBA57483C4C654F573B435C09D8AACE1CB45E63FFB1", "representative": "nano_1fzwxb8tkmrp8o66xz7tcx65rm57bxdmpitw39ecomiwpjh89zxj33juzt6p", "account": "nano_1fzwxb8tkmrp8o66xz7tcx65rm57bxdmpitw39ecomiwpjh89zxj33juzt6p", "work": "ef0547d86748c71b", "signature": "13E33D1ADA50A79B64741C5159C0C0AFE0515581B47ABD73676FE02A1D600CDB637050D37BF92C9629649AE92949814BB57C6B5B0A44BF76E2F33043A3DF2D01"}"###;
   88|       |        let block = parse_block_from_genesis_data(block_str).unwrap();
   89|       |        assert_eq!(block.block_type(), BlockType::LegacyOpen);
   90|       |    }
   91|       |}
   92|       |
   93|       |#[derive(Clone)]
   94|       |pub struct LedgerConstants {
   95|       |    pub work: WorkThresholds,
   96|       |    pub genesis_block: SavedBlock,
   97|       |    pub genesis_account: Account,
   98|       |    pub genesis_amount: Amount,
   99|       |    pub burn_account: Account,
  100|       |    pub epochs: Epochs,
  101|       |}
  102|       |
  103|     32|pub fn genesis_sideband(genesis_account: Account) -> BlockSideband {
  104|     32|    BlockSideband {
  105|     32|        height: 1,
  106|     32|        timestamp: UnixTimestamp::ZERO,
  107|     32|        successor: BlockHash::zero(),
  108|     32|        account: genesis_account,
  109|     32|        balance: Amount::MAX,
  110|     32|        details: BlockDetails::new(Epoch::Epoch0, false, false, false),
  111|     32|        source_epoch: Epoch::Epoch0,
  112|     32|    }
  113|     32|}
  114|       |
  115|       |impl LedgerConstants {
  116|     32|    pub fn new(work: WorkThresholds, network: Networks) -> Self {
  117|     32|        let dev_genesis_block = parse_block_from_genesis_data(DEV_GENESIS_DATA).unwrap();
  118|     32|        let beta_genesis_block = parse_block_from_genesis_data(BETA_GENESIS_DATA).unwrap();
  119|     32|        let live_genesis_block = parse_block_from_genesis_data(LIVE_GENESIS_DATA).unwrap();
  120|     32|        let test_genesis_block = parse_block_from_genesis_data(TEST_GENESIS_DATA.as_str()).unwrap();
  121|       |
  122|     32|        let genesis_block = match network {
  123|     28|            Networks::NanoDevNetwork => dev_genesis_block,
  124|      4|            Networks::NanoBetaNetwork => beta_genesis_block,
  125|      0|            Networks::NanoTestNetwork => test_genesis_block,
  126|      0|            Networks::NanoLiveNetwork => live_genesis_block,
  127|      0|            Networks::Invalid => panic!("invalid network"),
  128|       |        };
  129|     32|        let genesis_account = genesis_block.account_field().unwrap();
  130|     32|
  131|     32|        let nano_beta_account = Account::decode_hex(BETA_PUBLIC_KEY_DATA).unwrap();
  132|     32|        let nano_test_account = Account::decode_hex(TEST_PUBLIC_KEY_DATA.as_str()).unwrap();
  133|     32|
  134|     32|        let mut epochs = Epochs::new();
  135|     32|
  136|     32|        let epoch_1_signer = PublicKey::from(genesis_account);
  137|     32|        let epoch_link_v1 = epoch_v1_link();
  138|     32|
  139|     32|        let nano_live_epoch_v2_signer = Account::decode_account(
  140|     32|            "nano_3qb6o6i1tkzr6jwr5s7eehfxwg9x6eemitdinbpi7u8bjjwsgqfj4wzser3x",
  141|     32|        )
  142|     32|        .unwrap();
  143|     32|        let epoch_2_signer = match network {
  144|     28|            Networks::NanoDevNetwork => DEV_GENESIS_KEY.public_key(),
  145|      4|            Networks::NanoBetaNetwork => nano_beta_account.into(),
  146|      0|            Networks::NanoLiveNetwork => nano_live_epoch_v2_signer.into(),
  147|      0|            Networks::NanoTestNetwork => nano_test_account.into(),
  148|      0|            _ => panic!("invalid network"),
  149|       |        };
  150|     32|        let epoch_link_v2 = epoch_v2_link();
  151|     32|
  152|     32|        epochs.add(Epoch::Epoch1, epoch_1_signer, epoch_link_v1);
  153|     32|        epochs.add(Epoch::Epoch2, epoch_2_signer, epoch_link_v2);
  154|     32|
  155|     32|        let genesis_block = SavedBlock::new(genesis_block, genesis_sideband(genesis_account));
  156|     32|
  157|     32|        Self {
  158|     32|            work,
  159|     32|            genesis_block,
  160|     32|            genesis_account,
  161|     32|            genesis_amount: Amount::raw(u128::MAX),
  162|     32|            burn_account: Account::zero(),
  163|     32|            epochs,
  164|     32|        }
  165|     32|    }
  166|       |
  167|      0|    pub fn live() -> Self {
  168|      0|        Self::new(
  169|      0|            WorkThresholds::publish_full().clone(),
  170|      0|            Networks::NanoLiveNetwork,
  171|      0|        )
  172|      0|    }
  173|       |
  174|      0|    pub fn beta() -> Self {
  175|      0|        Self::new(
  176|      0|            WorkThresholds::publish_beta().clone(),
  177|      0|            Networks::NanoBetaNetwork,
  178|      0|        )
  179|      0|    }
  180|       |
  181|      0|    pub fn test() -> Self {
  182|      0|        Self::new(
  183|      0|            WorkThresholds::publish_test().clone(),
  184|      0|            Networks::NanoTestNetwork,
  185|      0|        )
  186|      0|    }
  187|       |
  188|      2|    pub fn dev() -> Self {
  189|      2|        Self::new(
  190|      2|            WorkThresholds::publish_dev().clone(),
  191|      2|            Networks::NanoDevNetwork,
  192|      2|        )
  193|      2|    }
  194|       |
  195|     22|    pub fn unit_test() -> Self {
  196|     22|        Self::new(WORK_THRESHOLDS_STUB.clone(), Networks::NanoDevNetwork)
  197|     22|    }
  198|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/ledger_context.rs:
    1|       |use crate::{ledger_constants::LEDGER_CONSTANTS_STUB, Ledger, LedgerConstants, RepWeightCache};
    2|       |use rsnano_core::{Account, Amount, ConfirmationHeightInfo};
    3|       |use rsnano_store_lmdb::{LmdbStore, LmdbWriteTransaction, TestDbFile};
    4|       |use std::sync::Arc;
    5|       |
    6|       |#[cfg(test)]
    7|       |use crate::ledger_tests::helpers::AccountBlockFactory;
    8|       |
    9|       |pub struct LedgerContext {
   10|       |    pub ledger: Arc<Ledger>,
   11|       |    _db_file: TestDbFile,
   12|       |}
   13|       |
   14|       |impl LedgerContext {
   15|      0|    pub fn empty() -> Self {
   16|      0|        Self::with_constants(LEDGER_CONSTANTS_STUB.clone())
   17|      0|    }
   18|       |
   19|      2|    pub fn empty_dev() -> Self {
   20|      2|        Self::with_constants(LedgerConstants::dev())
   21|      2|    }
   22|       |
   23|      2|    pub fn with_constants(constants: LedgerConstants) -> Self {
   24|      2|        let db_file = TestDbFile::random();
   25|      2|        let store = Arc::new(LmdbStore::open(&db_file.path).build().unwrap());
   26|      2|        let rep_weights = Arc::new(RepWeightCache::new());
   27|      2|        let ledger =
   28|      2|            Arc::new(Ledger::new(store.clone(), constants, Amount::zero(), rep_weights).unwrap());
   29|      2|
   30|      2|        LedgerContext {
   31|      2|            ledger,
   32|      2|            _db_file: db_file,
   33|      2|        }
   34|      2|    }
   35|       |
   36|       |    #[cfg(test)]
   37|       |    pub(crate) fn genesis_block_factory(&self) -> AccountBlockFactory {
   38|       |        AccountBlockFactory::genesis(&self.ledger)
   39|       |    }
   40|       |
   41|       |    #[cfg(test)]
   42|       |    pub(crate) fn block_factory(&self) -> AccountBlockFactory {
   43|       |        AccountBlockFactory::new(&self.ledger)
   44|       |    }
   45|       |
   46|      0|    pub fn inc_confirmation_height(&self, txn: &mut LmdbWriteTransaction, account: &Account) {
   47|      0|        let mut height = self
   48|      0|            .ledger
   49|      0|            .store
   50|      0|            .confirmation_height
   51|      0|            .get(txn, account)
   52|      0|            .unwrap_or_else(|| ConfirmationHeightInfo {
   53|      0|                height: 0,
   54|      0|                frontier: self.ledger.account_info(txn, account).unwrap().head,
   55|      0|            });
   56|      0|        height.height = height.height + 1;
   57|      0|        self.ledger
   58|      0|            .store
   59|      0|            .confirmation_height
   60|      0|            .put(txn, account, &height);
   61|      0|    }
   62|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/ledger_set_any.rs:
    1|       |use rsnano_core::{
    2|       |    Account, AccountInfo, Amount, BlockHash, PendingInfo, PendingKey, QualifiedRoot, SavedBlock,
    3|       |};
    4|       |use rsnano_store_lmdb::{LmdbPendingStore, LmdbRangeIterator, LmdbStore, Transaction};
    5|       |use std::ops::{Deref, RangeBounds, RangeFrom};
    6|       |
    7|       |pub struct LedgerSetAny<'a> {
    8|       |    store: &'a LmdbStore,
    9|       |}
   10|       |
   11|       |impl<'a> LedgerSetAny<'a> {
   12|  32.9k|    pub fn new(store: &'a LmdbStore) -> Self {
   13|  32.9k|        Self { store }
   14|  32.9k|    }
   15|       |
   16|  16.4k|    pub fn get_block(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<SavedBlock> {
   17|  16.4k|        if hash.is_zero() {
   18|      0|            return None;
   19|  16.4k|        }
   20|  16.4k|        self.store.block.get(tx, hash)
   21|  16.4k|    }
   22|       |
   23|      0|    pub fn get_account(&self, tx: &dyn Transaction, account: &Account) -> Option<AccountInfo> {
   24|      0|        self.store.account.get(tx, account)
   25|      0|    }
   26|       |
   27|      0|    pub fn account_head(&self, tx: &dyn Transaction, account: &Account) -> Option<BlockHash> {
   28|      0|        self.get_account(tx, account).map(|i| i.head)
   29|      0|    }
   30|       |
   31|      0|    pub fn account_balance(&self, tx: &dyn Transaction, account: &Account) -> Option<Amount> {
   32|      0|        let head = self.account_head(tx, account)?;
   33|      0|        self.get_block(tx, &head).map(|b| b.balance())
   34|      0|    }
   35|       |
   36|      0|    pub fn account_height(&self, tx: &dyn Transaction, account: &Account) -> u64 {
   37|      0|        let Some(head) = self.account_head(tx, account) else {
   38|      0|            return 0;
   39|       |        };
   40|      0|        self.get_block(tx, &head)
   41|      0|            .map(|b| b.height())
   42|      0|            .expect("Head block not in ledger!")
   43|      0|    }
   44|       |
   45|      0|    pub fn block_account(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<Account> {
   46|      0|        self.get_block(tx, hash).map(|b| b.account())
   47|      0|    }
   48|       |
   49|      0|    pub fn block_amount(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<Amount> {
   50|      0|        let block = self.get_block(tx, hash)?;
   51|      0|        self.block_amount_for(tx, &block)
   52|      0|    }
   53|       |
   54|      0|    pub fn block_amount_for(&self, tx: &dyn Transaction, block: &SavedBlock) -> Option<Amount> {
   55|      0|        let block_balance = block.balance();
   56|      0|        if block.previous().is_zero() {
   57|      0|            Some(block_balance)
   58|       |        } else {
   59|      0|            let previous_balance = self.block_balance(tx, &block.previous())?;
   60|      0|            if block_balance > previous_balance {
   61|      0|                Some(block_balance - previous_balance)
   62|       |            } else {
   63|      0|                Some(previous_balance - block_balance)
   64|       |            }
   65|       |        }
   66|      0|    }
   67|       |
   68|      0|    pub fn block_balance(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<Amount> {
   69|      0|        if hash.is_zero() {
   70|      0|            return None;
   71|      0|        }
   72|      0|
   73|      0|        self.get_block(tx, hash).map(|b| b.balance())
   74|      0|    }
   75|       |
   76|  16.3k|    pub fn block_exists(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
   77|  16.3k|        if hash.is_zero() {
   78|      0|            return false;
   79|  16.3k|        }
   80|  16.3k|        self.store.block.exists(tx, hash)
   81|  16.3k|    }
   82|       |
   83|     67|    pub fn block_exists_or_pruned(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
   84|     67|        if hash.is_zero() {
   85|      0|            return false;
   86|     67|        }
   87|     67|        if self.store.pruned.exists(tx, hash) {
   88|      0|            true
   89|       |        } else {
   90|     67|            self.store.block.exists(tx, hash)
   91|       |        }
   92|     67|    }
   93|       |
   94|      0|    pub fn block_height(&self, tx: &dyn Transaction, hash: &BlockHash) -> u64 {
   95|      0|        self.get_block(tx, hash)
   96|      0|            .map(|b| b.height())
   97|      0|            .unwrap_or_default()
   98|      0|    }
   99|       |
  100|      0|    pub fn block_successor(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<BlockHash> {
  101|      0|        self.block_successor_by_qualified_root(tx, &QualifiedRoot::new(hash.into(), *hash))
  102|      0|    }
  103|       |
  104|      0|    pub fn block_successor_by_qualified_root(
  105|      0|        &self,
  106|      0|        tx: &dyn Transaction,
  107|      0|        root: &QualifiedRoot,
  108|      0|    ) -> Option<BlockHash> {
  109|      0|        if !root.previous.is_zero() {
  110|      0|            self.store.block.successor(tx, &root.previous)
  111|       |        } else {
  112|      0|            self.get_account(tx, &root.root.into())
  113|      0|                .map(|i| i.open_block)
  114|       |        }
  115|      0|    }
  116|       |
  117|     32|    pub fn get_pending(&self, tx: &dyn Transaction, key: &PendingKey) -> Option<PendingInfo> {
  118|     32|        self.store.pending.get(tx, key)
  119|     32|    }
  120|       |
  121|       |    /// Returns the next receivable entry for the account 'account' with hash greater than 'hash'
  122|     32|    pub fn account_receivable_upper_bound<'txn>(
  123|     32|        &self,
  124|     32|        txn: &'txn dyn Transaction,
  125|     32|        account: Account,
  126|     32|        hash: BlockHash,
  127|     32|    ) -> AnyReceivableIterator<'txn>
  128|     32|    where
  129|     32|        'a: 'txn,
  130|     32|    {
  131|     32|        AnyReceivableIterator::<'txn>::new(
  132|     32|            txn,
  133|     32|            self.store.pending.deref(),
  134|     32|            account,
  135|     32|            Some(account),
  136|     32|            hash.inc(),
  137|     32|        )
  138|     32|    }
  139|       |
  140|       |    /// Returns the next receivable entry for an account greater than 'account'
  141|      0|    pub fn receivable_upper_bound<'txn>(
  142|      0|        &self,
  143|      0|        txn: &'txn dyn Transaction,
  144|      0|        account: Account,
  145|      0|    ) -> AnyReceivableIterator<'txn>
  146|      0|    where
  147|      0|        'a: 'txn,
  148|      0|    {
  149|      0|        match account.inc() {
  150|      0|            None => AnyReceivableIterator::<'txn>::new(
  151|      0|                txn,
  152|      0|                &self.store.pending,
  153|      0|                Default::default(),
  154|      0|                None,
  155|      0|                None,
  156|      0|            ),
  157|      0|            Some(account) => AnyReceivableIterator::<'txn>::new(
  158|      0|                txn,
  159|      0|                &self.store.pending,
  160|      0|                account,
  161|      0|                None,
  162|      0|                Some(BlockHash::zero()),
  163|      0|            ),
  164|       |        }
  165|      0|    }
  166|       |
  167|       |    /// Returns the next receivable entry for an account greater than or equal to 'account'
  168|      0|    pub fn receivable_lower_bound<'txn>(
  169|      0|        &'a self,
  170|      0|        txn: &'a dyn Transaction,
  171|      0|        account: Account,
  172|      0|    ) -> AnyReceivableIterator<'txn>
  173|      0|    where
  174|      0|        'a: 'txn,
  175|      0|    {
  176|      0|        AnyReceivableIterator::<'txn>::new(
  177|      0|            txn,
  178|      0|            &self.store.pending,
  179|      0|            account,
  180|      0|            None,
  181|      0|            Some(BlockHash::zero()),
  182|      0|        )
  183|      0|    }
  184|       |
  185|     32|    pub fn receivable_exists(&self, txn: &dyn Transaction, account: Account) -> bool {
  186|     32|        self.account_receivable_upper_bound(txn, account, BlockHash::zero())
  187|     32|            .next()
  188|     32|            .is_some()
  189|     32|    }
  190|       |
  191|      0|    pub fn accounts<'txn>(
  192|      0|        &self,
  193|      0|        tx: &'txn dyn Transaction,
  194|      0|    ) -> impl Iterator<Item = (Account, AccountInfo)> + 'txn {
  195|      0|        self.store.account.iter(tx)
  196|      0|    }
  197|       |
  198|     60|    pub fn accounts_range<'txn>(
  199|     60|        &self,
  200|     60|        tx: &'txn dyn Transaction,
  201|     60|        range: impl RangeBounds<Account> + 'static,
  202|     60|    ) -> impl Iterator<Item = (Account, AccountInfo)> + 'txn {
  203|     60|        self.store.account.iter_range(tx, range)
  204|     60|    }
  205|       |}
  206|       |
  207|       |pub struct AnyReceivableIterator<'a> {
  208|       |    returned_account: Option<Account>,
  209|       |    inner: LmdbRangeIterator<'a, PendingKey, PendingInfo, RangeFrom<PendingKey>>,
  210|       |    is_first: bool,
  211|       |}
  212|       |
  213|       |impl<'a> AnyReceivableIterator<'a> {
  214|     32|    pub fn new(
  215|     32|        txn: &'a dyn Transaction,
  216|     32|        pending: &'a LmdbPendingStore,
  217|     32|        requested_account: Account,
  218|     32|        returned_account: Option<Account>,
  219|     32|        next_hash: Option<BlockHash>,
  220|     32|    ) -> Self {
  221|     32|        let cursor = txn
  222|     32|            .open_ro_cursor(pending.database())
  223|     32|            .expect("could not read from account store");
  224|       |
  225|     32|        let inner = match next_hash {
  226|     32|            Some(hash) => {
  227|     32|                let start = PendingKey::new(requested_account, hash);
  228|     32|                LmdbRangeIterator::new(cursor, start..)
  229|       |            }
  230|      0|            None => LmdbRangeIterator::empty(PendingKey::default()..),
  231|       |        };
  232|       |
  233|     32|        Self {
  234|     32|            returned_account,
  235|     32|            inner,
  236|     32|            is_first: true,
  237|     32|        }
  238|     32|    }
  239|       |}
  240|       |
  241|       |impl<'a> Iterator for AnyReceivableIterator<'a> {
  242|       |    type Item = (PendingKey, PendingInfo);
  243|       |
  244|     32|    fn next(&mut self) -> Option<Self::Item> {
  245|     32|        if self.is_first {
  246|     32|            self.is_first = false;
  247|     32|            let (key, info) = self.inner.next()?;
                               ^4                            ^28
  248|      4|            match self.returned_account {
  249|      4|                Some(returned_acc) => {
  250|      4|                    if returned_acc != key.receiving_account {
  251|      0|                        return None;
  252|      4|                    }
  253|       |                }
  254|      0|                None => {
  255|      0|                    // The first result defines the returned account
  256|      0|                    self.returned_account = Some(key.receiving_account);
  257|      0|                }
  258|       |            }
  259|      4|            return Some((key, info));
  260|      0|        }
  261|       |
  262|      0|        let (key, info) = self.inner.next()?;
  263|      0|        match self.returned_account {
  264|      0|            Some(account) => {
  265|      0|                if key.receiving_account == account {
  266|      0|                    Some((key, info))
  267|       |                } else {
  268|      0|                    None
  269|       |                }
  270|       |            }
  271|      0|            None => None,
  272|       |        }
  273|     32|    }
  274|       |}
  275|       |
  276|       |#[cfg(test)]
  277|       |mod tests {
  278|       |    use super::*;
  279|       |    use crate::Ledger;
  280|       |
  281|       |    #[test]
  282|       |    fn iter_all_lower_bound() {
  283|       |        let key1 = PendingKey::new(Account::from(1), BlockHash::from(100));
  284|       |        let key2 = PendingKey::new(Account::from(1), BlockHash::from(101));
  285|       |        let key3 = PendingKey::new(Account::from(3), BlockHash::from(4));
  286|       |
  287|       |        test_lower_bound(
  288|       |            &[key1.clone(), key2.clone(), key3.clone()],
  289|       |            Account::from(0),
  290|       |            &[key1.clone(), key2.clone()],
  291|       |        );
  292|       |        test_lower_bound(
  293|       |            &[key1.clone(), key2.clone(), key3.clone()],
  294|       |            Account::from(1),
  295|       |            &[key1.clone(), key2.clone()],
  296|       |        );
  297|       |        test_lower_bound(
  298|       |            &[key1.clone(), key2.clone(), key3.clone()],
  299|       |            Account::from(3),
  300|       |            &[key3.clone()],
  301|       |        );
  302|       |        test_lower_bound(
  303|       |            &[key1.clone(), key2.clone(), key3.clone()],
  304|       |            Account::from(4),
  305|       |            &[],
  306|       |        );
  307|       |    }
  308|       |
  309|       |    #[test]
  310|       |    fn iter_all_upper_bound() {
  311|       |        let key1 = PendingKey::new(Account::from(1), BlockHash::from(100));
  312|       |        let key2 = PendingKey::new(Account::from(1), BlockHash::from(101));
  313|       |        let key3 = PendingKey::new(Account::from(3), BlockHash::from(4));
  314|       |        test_upper_bound(
  315|       |            &[key1.clone(), key2.clone(), key3.clone()],
  316|       |            Account::from(0),
  317|       |            &[key1.clone(), key2.clone()],
  318|       |        );
  319|       |        test_upper_bound(
  320|       |            &[key1.clone(), key2.clone(), key3.clone()],
  321|       |            Account::from(1),
  322|       |            &[key3.clone()],
  323|       |        );
  324|       |        test_upper_bound(
  325|       |            &[key1.clone(), key2.clone(), key3.clone()],
  326|       |            Account::from(4),
  327|       |            &[],
  328|       |        );
  329|       |    }
  330|       |
  331|       |    fn test_upper_bound(
  332|       |        existing_keys: &[PendingKey],
  333|       |        queried_account: Account,
  334|       |        expected_result: &[PendingKey],
  335|       |    ) {
  336|       |        let ledger = ledger_with_pending_entries(existing_keys);
  337|       |        let tx = ledger.read_txn();
  338|       |        let result: Vec<_> = ledger
  339|       |            .any()
  340|       |            .receivable_upper_bound(&tx, queried_account)
  341|       |            .map(|(k, _)| k)
  342|       |            .collect();
  343|       |
  344|       |        assert_eq!(result, expected_result);
  345|       |    }
  346|       |
  347|       |    fn test_lower_bound(
  348|       |        existing_keys: &[PendingKey],
  349|       |        queried_account: Account,
  350|       |        expected_result: &[PendingKey],
  351|       |    ) {
  352|       |        let ledger = ledger_with_pending_entries(existing_keys);
  353|       |        let tx = ledger.read_txn();
  354|       |        let result: Vec<_> = ledger
  355|       |            .any()
  356|       |            .receivable_lower_bound(&tx, queried_account)
  357|       |            .map(|(k, _)| k)
  358|       |            .collect();
  359|       |
  360|       |        assert_eq!(result, expected_result);
  361|       |    }
  362|       |
  363|       |    fn ledger_with_pending_entries(existing_keys: &[PendingKey]) -> Ledger {
  364|       |        let info = PendingInfo::new_test_instance();
  365|       |        let mut builder = Ledger::new_null_builder();
  366|       |        for key in existing_keys {
  367|       |            builder = builder.pending(key, &info);
  368|       |        }
  369|       |        builder.finish()
  370|       |    }
  371|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/ledger_set_confirmed.rs:
    1|       |use rsnano_core::{Account, Amount, BlockHash, PendingInfo, PendingKey, SavedBlock};
    2|       |use rsnano_store_lmdb::{LmdbStore, Transaction};
    3|       |
    4|       |pub struct LedgerSetConfirmed<'a> {
    5|       |    store: &'a LmdbStore,
    6|       |}
    7|       |
    8|       |impl<'a> LedgerSetConfirmed<'a> {
    9|  32.7k|    pub fn new(store: &'a LmdbStore) -> Self {
   10|  32.7k|        Self { store }
   11|  32.7k|    }
   12|       |
   13|  49.1k|    pub fn get_block(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<SavedBlock> {
   14|  49.1k|        if hash.is_zero() {
   15|      0|            return None;
   16|  49.1k|        }
   17|  49.1k|        let block = self.store.block.get(tx, hash)?;
                                                                ^0
   18|  49.1k|        let info = self.store.confirmation_height.get(tx, &block.account())?;
                                                                                         ^0
   19|  49.1k|        if block.height() <= info.height {
   20|  16.3k|            Some(block)
   21|       |        } else {
   22|  32.7k|            None
   23|       |        }
   24|  49.1k|    }
   25|       |
   26|      0|    pub fn account_head(&self, tx: &dyn Transaction, account: &Account) -> Option<BlockHash> {
   27|      0|        let info = self.store.confirmation_height.get(tx, account)?;
   28|      0|        Some(info.frontier)
   29|      0|    }
   30|       |
   31|      0|    pub fn account_height(&self, tx: &dyn Transaction, account: &Account) -> u64 {
   32|      0|        let Some(head) = self.account_head(tx, account) else {
   33|      0|            return 0;
   34|       |        };
   35|      0|        self.get_block(tx, &head)
   36|      0|            .map(|b| b.height())
   37|      0|            .expect("Head block not in ledger!")
   38|      0|    }
   39|       |
   40|      0|    pub fn block_balance(&self, tx: &dyn Transaction, hash: &BlockHash) -> Option<Amount> {
   41|      0|        if hash.is_zero() {
   42|      0|            return None;
   43|      0|        }
   44|      0|
   45|      0|        self.get_block(tx, hash).map(|b| b.balance())
   46|      0|    }
   47|       |
   48|  49.1k|    pub fn block_exists(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
   49|  49.1k|        self.get_block(tx, hash).is_some()
   50|  49.1k|    }
   51|       |
   52|  32.7k|    pub fn block_exists_or_pruned(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
   53|  32.7k|        if hash.is_zero() {
   54|      0|            return false;
   55|  32.7k|        }
   56|  32.7k|        if self.store.pruned.exists(tx, hash) {
   57|      0|            true
   58|       |        } else {
   59|  32.7k|            self.block_exists(tx, hash)
   60|       |        }
   61|  32.7k|    }
   62|       |
   63|      0|    pub fn account_balance(&self, tx: &dyn Transaction, account: &Account) -> Option<Amount> {
   64|      0|        let head = self.account_head(tx, account)?;
   65|      0|        self.get_block(tx, &head).map(|b| b.balance())
   66|      0|    }
   67|       |
   68|       |    /// Returns the next receivable entry for an account greater than or equal to 'account'
   69|      0|    pub fn receivable_lower_bound<'txn>(
   70|      0|        &'a self,
   71|      0|        txn: &'a dyn Transaction,
   72|      0|        account: Account,
   73|      0|    ) -> ConfirmedReceivableIterator<'txn>
   74|      0|    where
   75|      0|        'a: 'txn,
   76|      0|    {
   77|      0|        ConfirmedReceivableIterator::<'txn> {
   78|      0|            txn,
   79|      0|            set: self,
   80|      0|            requested_account: account,
   81|      0|            actual_account: None,
   82|      0|            next_hash: Some(BlockHash::zero()),
   83|      0|        }
   84|      0|    }
   85|       |
   86|      0|    fn first_receivable_lower_bound(
   87|      0|        &self,
   88|      0|        txn: &dyn Transaction,
   89|      0|        account: Account,
   90|      0|        send_hash: BlockHash,
   91|      0|    ) -> Option<(PendingKey, PendingInfo)> {
   92|      0|        let mut it = self
   93|      0|            .store
   94|      0|            .pending
   95|      0|            .iter_range(txn, PendingKey::new(account, send_hash)..);
   96|       |
   97|      0|        let (mut key, mut info) = it.next()?;
   98|       |
   99|      0|        while !self.block_exists(txn, &key.send_block_hash) {
  100|      0|            (key, info) = it.next()?;
  101|       |        }
  102|       |
  103|      0|        Some((key, info))
  104|      0|    }
  105|       |}
  106|       |
  107|       |pub struct ConfirmedReceivableIterator<'a> {
  108|       |    pub txn: &'a dyn Transaction,
  109|       |    pub set: &'a LedgerSetConfirmed<'a>,
  110|       |    pub requested_account: Account,
  111|       |    pub actual_account: Option<Account>,
  112|       |    pub next_hash: Option<BlockHash>,
  113|       |}
  114|       |
  115|       |impl<'a> Iterator for ConfirmedReceivableIterator<'a> {
  116|       |    type Item = (PendingKey, PendingInfo);
  117|       |
  118|      0|    fn next(&mut self) -> Option<Self::Item> {
  119|      0|        let hash = self.next_hash?;
  120|      0|        let account = self.actual_account.unwrap_or(self.requested_account);
  121|      0|        let (key, info) = self
  122|      0|            .set
  123|      0|            .first_receivable_lower_bound(self.txn, account, hash)?;
  124|      0|        match self.actual_account {
  125|      0|            Some(account) => {
  126|      0|                if key.receiving_account == account {
  127|      0|                    self.next_hash = key.send_block_hash.inc();
  128|      0|                    Some((key.clone(), info.clone()))
  129|       |                } else {
  130|      0|                    None
  131|       |                }
  132|       |            }
  133|       |            None => {
  134|      0|                self.actual_account = Some(key.receiving_account);
  135|      0|                self.next_hash = key.send_block_hash.inc();
  136|      0|                Some((key.clone(), info.clone()))
  137|       |            }
  138|       |        }
  139|      0|    }
  140|       |}
  141|       |
  142|       |#[cfg(test)]
  143|       |mod tests {
  144|       |    use crate::Ledger;
  145|       |    use rsnano_core::{
  146|       |        Account, BlockHash, ConfirmationHeightInfo, PendingInfo, PendingKey, SavedBlock,
  147|       |    };
  148|       |
  149|       |    #[test]
  150|       |    fn iter_receivables() {
  151|       |        let account = Account::from(1);
  152|       |
  153|       |        let block1 = SavedBlock::new_test_instance_with_key(42);
  154|       |        let block2 = SavedBlock::new_test_instance_with_key(43);
  155|       |        let block3 = SavedBlock::new_test_instance_with_key(44);
  156|       |
  157|       |        let ledger = Ledger::new_null_builder()
  158|       |            .blocks([&block1, &block2, &block3])
  159|       |            .confirmation_height(
  160|       |                &block1.account(),
  161|       |                &ConfirmationHeightInfo::new(9999, BlockHash::zero()),
  162|       |            )
  163|       |            .confirmation_height(
  164|       |                &block2.account(),
  165|       |                &ConfirmationHeightInfo::new(0, BlockHash::zero()),
  166|       |            )
  167|       |            .confirmation_height(
  168|       |                &block3.account(),
  169|       |                &ConfirmationHeightInfo::new(9999, BlockHash::zero()),
  170|       |            )
  171|       |            .pending(
  172|       |                &PendingKey::new(account, block1.hash()),
  173|       |                &PendingInfo::new_test_instance(),
  174|       |            )
  175|       |            .pending(
  176|       |                &PendingKey::new(account, block2.hash()),
  177|       |                &PendingInfo::new_test_instance(),
  178|       |            )
  179|       |            .pending(
  180|       |                &PendingKey::new(account, block3.hash()),
  181|       |                &PendingInfo::new_test_instance(),
  182|       |            )
  183|       |            .finish();
  184|       |
  185|       |        let tx = ledger.read_txn();
  186|       |        let receivable: Vec<_> = ledger
  187|       |            .confirmed()
  188|       |            .receivable_lower_bound(&tx, Account::zero())
  189|       |            .map(|i| i.0)
  190|       |            .collect();
  191|       |
  192|       |        let mut expected = vec![
  193|       |            PendingKey::new(account, block1.hash()),
  194|       |            PendingKey::new(account, block3.hash()),
  195|       |        ];
  196|       |        expected.sort_by_key(|i| i.send_block_hash);
  197|       |
  198|       |        assert_eq!(receivable, expected);
  199|       |    }
  200|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/rep_weight_cache.rs:
    1|       |use rsnano_core::{utils::ContainerInfo, Account, Amount, PublicKey};
    2|       |use rsnano_store_lmdb::LedgerCache;
    3|       |use std::{
    4|       |    collections::HashMap,
    5|       |    mem::size_of,
    6|       |    sync::{
    7|       |        atomic::{AtomicBool, Ordering},
    8|       |        Arc, RwLock, RwLockReadGuard,
    9|       |    },
   10|       |};
   11|       |
   12|       |/// Returns the cached vote weight for the given representative.
   13|       |/// If the weight is below the cache limit it returns 0.
   14|       |/// During bootstrap it returns the preconfigured bootstrap weights.
   15|       |pub struct RepWeightCache {
   16|       |    weights: Arc<RwLock<HashMap<PublicKey, Amount>>>,
   17|       |    bootstrap_weights: RwLock<HashMap<PublicKey, Amount>>,
   18|       |    max_blocks: u64,
   19|       |    ledger_cache: Arc<LedgerCache>,
   20|       |    check_bootstrap_weights: AtomicBool,
   21|       |}
   22|       |
   23|       |impl RepWeightCache {
   24|     32|    pub fn new() -> Self {
   25|     32|        Self {
   26|     32|            weights: Arc::new(RwLock::new(HashMap::new())),
   27|     32|            bootstrap_weights: RwLock::new(HashMap::new()),
   28|     32|            max_blocks: 0,
   29|     32|            ledger_cache: Arc::new(LedgerCache::new()),
   30|     32|            check_bootstrap_weights: AtomicBool::new(false),
   31|     32|        }
   32|     32|    }
   33|       |
   34|      3|    pub fn with_bootstrap_weights(
   35|      3|        bootstrap_weights: HashMap<PublicKey, Amount>,
   36|      3|        max_blocks: u64,
   37|      3|        ledger_cache: Arc<LedgerCache>,
   38|      3|    ) -> Self {
   39|      3|        Self {
   40|      3|            weights: Arc::new(RwLock::new(HashMap::new())),
   41|      3|            bootstrap_weights: RwLock::new(bootstrap_weights),
   42|      3|            max_blocks,
   43|      3|            ledger_cache,
   44|      3|            check_bootstrap_weights: AtomicBool::new(true),
   45|      3|        }
   46|      3|    }
   47|       |
   48|     12|    pub fn read(&self) -> RwLockReadGuard<HashMap<PublicKey, Amount>> {
   49|     12|        if self.use_bootstrap_weights() {
   50|      0|            self.bootstrap_weights.read().unwrap()
   51|       |        } else {
   52|     12|            self.weights.read().unwrap()
   53|       |        }
   54|     12|    }
   55|       |
   56|     30|    pub fn use_bootstrap_weights(&self) -> bool {
   57|     30|        if self.check_bootstrap_weights.load(Ordering::SeqCst) {
   58|      3|            if self.ledger_cache.block_count.load(Ordering::SeqCst) < self.max_blocks {
   59|      0|                return true;
   60|      3|            } else {
   61|      3|                self.check_bootstrap_weights.store(false, Ordering::SeqCst);
   62|      3|            }
   63|     27|        }
   64|     30|        false
   65|     30|    }
   66|       |
   67|     18|    pub fn weight(&self, rep: &PublicKey) -> Amount {
   68|     18|        let weights = if self.use_bootstrap_weights() {
   69|      0|            &self.bootstrap_weights
   70|       |        } else {
   71|     18|            &self.weights
   72|       |        };
   73|       |
   74|     18|        weights
   75|     18|            .read()
   76|     18|            .unwrap()
   77|     18|            .get(rep)
   78|     18|            .cloned()
   79|     18|            .unwrap_or_default()
   80|     18|    }
   81|       |
   82|      0|    pub fn bootstrap_weight_max_blocks(&self) -> u64 {
   83|      0|        self.max_blocks
   84|      0|    }
   85|       |
   86|      3|    pub fn bootstrap_weights(&self) -> HashMap<PublicKey, Amount> {
   87|      3|        self.bootstrap_weights.read().unwrap().clone()
   88|      3|    }
   89|       |
   90|      0|    pub fn block_count(&self) -> u64 {
   91|      0|        self.ledger_cache.block_count.load(Ordering::SeqCst)
   92|      0|    }
   93|       |
   94|      0|    pub fn len(&self) -> usize {
   95|      0|        self.weights.read().unwrap().len()
   96|      0|    }
   97|       |
   98|      8|    pub fn set(&self, account: PublicKey, weight: Amount) {
   99|      8|        self.weights.write().unwrap().insert(account, weight);
  100|      8|    }
  101|       |
  102|     27|    pub(super) fn inner(&self) -> Arc<RwLock<HashMap<PublicKey, Amount>>> {
  103|     27|        self.weights.clone()
  104|     27|    }
  105|       |
  106|      0|    pub fn container_info(&self) -> ContainerInfo {
  107|      0|        [("rep_weights", self.len(), size_of::<(Account, Amount)>())].into()
  108|      0|    }
  109|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/rep_weights_updater.rs:
    1|       |use crate::RepWeightCache;
    2|       |use rsnano_core::{Amount, PublicKey};
    3|       |use rsnano_store_lmdb::{LmdbRepWeightStore, LmdbWriteTransaction};
    4|       |use std::collections::HashMap;
    5|       |use std::sync::{Arc, RwLock};
    6|       |
    7|       |/// Updates the representative weights in the ledger and in the in-memory cache
    8|       |pub struct RepWeightsUpdater {
    9|       |    weight_cache: Arc<RwLock<HashMap<PublicKey, Amount>>>,
   10|       |    store: Arc<LmdbRepWeightStore>,
   11|       |    min_weight: Amount,
   12|       |}
   13|       |
   14|       |impl RepWeightsUpdater {
   15|     27|    pub fn new(store: Arc<LmdbRepWeightStore>, min_weight: Amount, cache: &RepWeightCache) -> Self {
   16|     27|        RepWeightsUpdater {
   17|     27|            weight_cache: cache.inner(),
   18|     27|            store,
   19|     27|            min_weight,
   20|     27|        }
   21|     27|    }
   22|       |
   23|       |    /// Only use this method when loading rep weights from the database table
   24|  1.08k|    pub fn copy_from(&self, other: &HashMap<PublicKey, Amount>) {
   25|  1.08k|        let mut guard_this = self.weight_cache.write().unwrap();
   26|  1.08k|        for (account, amount) in other {
                           ^5
   27|      5|            let prev_amount = self.get(&guard_this, account);
   28|      5|            self.put_cache(&mut guard_this, *account, prev_amount.wrapping_add(*amount));
   29|      5|        }
   30|  1.08k|    }
   31|       |
   32|      5|    fn get(&self, weights: &HashMap<PublicKey, Amount>, account: &PublicKey) -> Amount {
   33|      5|        weights.get(account).cloned().unwrap_or_default()
   34|      5|    }
   35|       |
   36|     32|    pub fn representation_add(
   37|     32|        &self,
   38|     32|        tx: &mut LmdbWriteTransaction,
   39|     32|        representative: PublicKey,
   40|     32|        amount: Amount,
   41|     32|    ) {
   42|     32|        let previous_weight = self.store.get(tx, &representative).unwrap_or_default();
   43|     32|        let new_weight = previous_weight.wrapping_add(amount);
   44|     32|        self.put_store(tx, representative, previous_weight, new_weight);
   45|     32|        let mut guard = self.weight_cache.write().unwrap();
   46|     32|        self.put_cache(&mut guard, representative, new_weight);
   47|     32|    }
   48|       |
   49|     37|    fn put_cache(
   50|     37|        &self,
   51|     37|        weights: &mut HashMap<PublicKey, Amount>,
   52|     37|        representative: PublicKey,
   53|     37|        new_weight: Amount,
   54|     37|    ) {
   55|     37|        if new_weight < self.min_weight || new_weight.is_zero() {
   56|      0|            weights.remove(&representative);
   57|     37|        } else {
   58|     37|            weights.insert(representative, new_weight);
   59|     37|        }
   60|     37|    }
   61|       |
   62|     32|    fn put_store(
   63|     32|        &self,
   64|     32|        tx: &mut LmdbWriteTransaction,
   65|     32|        representative: PublicKey,
   66|     32|        previous_weight: Amount,
   67|     32|        new_weight: Amount,
   68|     32|    ) {
   69|     32|        if new_weight.is_zero() {
   70|      0|            if !previous_weight.is_zero() {
   71|      0|                self.store.del(tx, &representative);
   72|      0|            }
   73|     32|        } else {
   74|     32|            self.store.put(tx, representative, new_weight);
   75|     32|        }
   76|     32|    }
   77|       |
   78|       |    /// Only use this method when loading rep weights from the database table!
   79|      0|    pub fn representation_put(&self, representative: PublicKey, weight: Amount) {
   80|      0|        let mut guard = self.weight_cache.write().unwrap();
   81|      0|        self.put_cache(&mut guard, representative, weight);
   82|      0|    }
   83|       |
   84|     28|    pub fn representation_add_dual(
   85|     28|        &self,
   86|     28|        tx: &mut LmdbWriteTransaction,
   87|     28|        rep_1: PublicKey,
   88|     28|        amount_1: Amount,
   89|     28|        rep_2: PublicKey,
   90|     28|        amount_2: Amount,
   91|     28|    ) {
   92|     28|        if rep_1 != rep_2 {
   93|      0|            let previous_weight_1 = self.store.get(tx, &rep_1).unwrap_or_default();
   94|      0|            let previous_weight_2 = self.store.get(tx, &rep_2).unwrap_or_default();
   95|      0|            let new_weight_1 = previous_weight_1.wrapping_add(amount_1);
   96|      0|            let new_weight_2 = previous_weight_2.wrapping_add(amount_2);
   97|      0|            self.put_store(tx, rep_1, previous_weight_1, new_weight_1);
   98|      0|            self.put_store(tx, rep_2, previous_weight_2, new_weight_2);
   99|      0|            let mut guard = self.weight_cache.write().unwrap();
  100|      0|            self.put_cache(&mut guard, rep_1, new_weight_1);
  101|      0|            self.put_cache(&mut guard, rep_2, new_weight_2);
  102|     28|        } else {
  103|     28|            self.representation_add(tx, rep_1, amount_1.wrapping_add(amount_2));
  104|     28|        }
  105|     28|    }
  106|       |}
  107|       |
  108|       |#[cfg(test)]
  109|       |mod tests {
  110|       |    use super::*;
  111|       |    use rsnano_store_lmdb::{ConfiguredRepWeightDatabaseBuilder, LmdbEnv};
  112|       |
  113|       |    #[test]
  114|       |    fn representation_changes() {
  115|       |        let env = Arc::new(LmdbEnv::new_null());
  116|       |        let store = Arc::new(LmdbRepWeightStore::new(env).unwrap());
  117|       |        let account = PublicKey::from(1);
  118|       |        let rep_weights = RepWeightCache::new();
  119|       |        let rep_weights_updater = RepWeightsUpdater::new(store, Amount::zero(), &rep_weights);
  120|       |        assert_eq!(rep_weights.weight(&account), Amount::zero());
  121|       |
  122|       |        rep_weights_updater.representation_put(account, Amount::from(1));
  123|       |        assert_eq!(rep_weights.weight(&account), Amount::from(1));
  124|       |
  125|       |        rep_weights_updater.representation_put(account, Amount::from(2));
  126|       |        assert_eq!(rep_weights.weight(&account), Amount::from(2));
  127|       |    }
  128|       |
  129|       |    #[test]
  130|       |    fn delete_rep_weight_of_zero() {
  131|       |        let representative = PublicKey::from(1);
  132|       |        let weight = Amount::from(100);
  133|       |
  134|       |        let env = Arc::new(
  135|       |            LmdbEnv::new_null_with()
  136|       |                .configured_database(ConfiguredRepWeightDatabaseBuilder::create(vec![(
  137|       |                    representative,
  138|       |                    weight,
  139|       |                )]))
  140|       |                .build(),
  141|       |        );
  142|       |        let store = Arc::new(LmdbRepWeightStore::new(Arc::clone(&env)).unwrap());
  143|       |        let delete_tracker = store.track_deletions();
  144|       |        let rep_weights = RepWeightCache::new();
  145|       |        let rep_weights_updater = RepWeightsUpdater::new(store, Amount::zero(), &rep_weights);
  146|       |        rep_weights_updater.representation_put(representative, weight);
  147|       |        let mut tx = env.tx_begin_write();
  148|       |
  149|       |        // set weight to 0
  150|       |        rep_weights_updater.representation_add(
  151|       |            &mut tx,
  152|       |            representative,
  153|       |            Amount::zero().wrapping_sub(weight),
  154|       |        );
  155|       |
  156|       |        assert_eq!(rep_weights.len(), 0);
  157|       |        assert_eq!(delete_tracker.output(), vec![representative]);
  158|       |    }
  159|       |
  160|       |    #[test]
  161|       |    fn delete_rep_weight_of_zero_dual() {
  162|       |        let rep1 = PublicKey::from(1);
  163|       |        let rep2 = PublicKey::from(2);
  164|       |        let weight = Amount::from(100);
  165|       |
  166|       |        let env = Arc::new(
  167|       |            LmdbEnv::new_null_with()
  168|       |                .configured_database(ConfiguredRepWeightDatabaseBuilder::create(vec![
  169|       |                    (rep1, weight),
  170|       |                    (rep2, weight),
  171|       |                ]))
  172|       |                .build(),
  173|       |        );
  174|       |        let store = Arc::new(LmdbRepWeightStore::new(Arc::clone(&env)).unwrap());
  175|       |        let delete_tracker = store.track_deletions();
  176|       |        let rep_weights = RepWeightCache::new();
  177|       |        let rep_weights_updater = RepWeightsUpdater::new(store, Amount::zero(), &rep_weights);
  178|       |        rep_weights_updater.representation_put(rep1, weight);
  179|       |        rep_weights_updater.representation_put(rep2, weight);
  180|       |        let mut tx = env.tx_begin_write();
  181|       |
  182|       |        // set weight to 0
  183|       |        rep_weights_updater.representation_add_dual(
  184|       |            &mut tx,
  185|       |            rep1,
  186|       |            Amount::zero().wrapping_sub(weight),
  187|       |            rep2,
  188|       |            Amount::zero().wrapping_sub(weight),
  189|       |        );
  190|       |
  191|       |        assert_eq!(rep_weights.len(), 0);
  192|       |        assert_eq!(delete_tracker.output(), vec![rep1, rep2]);
  193|       |    }
  194|       |
  195|       |    #[test]
  196|       |    fn add_below_min_weight() {
  197|       |        let env = Arc::new(LmdbEnv::new_null());
  198|       |        let store = Arc::new(LmdbRepWeightStore::new(Arc::clone(&env)).unwrap());
  199|       |        let put_tracker = store.track_puts();
  200|       |        let mut txn = env.tx_begin_write();
  201|       |        let representative = PublicKey::from(1);
  202|       |        let min_weight = Amount::from(10);
  203|       |        let rep_weight = Amount::from(9);
  204|       |        let rep_weights = RepWeightCache::new();
  205|       |        let rep_weights_updater = RepWeightsUpdater::new(store, min_weight, &rep_weights);
  206|       |
  207|       |        rep_weights_updater.representation_add(&mut txn, representative, rep_weight);
  208|       |
  209|       |        assert_eq!(rep_weights.len(), 0);
  210|       |        assert_eq!(put_tracker.output(), vec![(representative, rep_weight)]);
  211|       |    }
  212|       |
  213|       |    #[test]
  214|       |    fn fall_below_min_weight() {
  215|       |        let representative = PublicKey::from(1);
  216|       |        let weight = Amount::from(11);
  217|       |        let env = Arc::new(
  218|       |            LmdbEnv::new_null_with()
  219|       |                .configured_database(ConfiguredRepWeightDatabaseBuilder::create(vec![(
  220|       |                    representative,
  221|       |                    weight,
  222|       |                )]))
  223|       |                .build(),
  224|       |        );
  225|       |        let store = Arc::new(LmdbRepWeightStore::new(Arc::clone(&env)).unwrap());
  226|       |        let put_tracker = store.track_puts();
  227|       |        let mut txn = env.tx_begin_write();
  228|       |        let min_weight = Amount::from(10);
  229|       |        let rep_weights = RepWeightCache::new();
  230|       |        let rep_weights_updater = RepWeightsUpdater::new(store, min_weight, &rep_weights);
  231|       |
  232|       |        rep_weights_updater.representation_add(
  233|       |            &mut txn,
  234|       |            representative,
  235|       |            Amount::zero().wrapping_sub(Amount::from(2)),
  236|       |        );
  237|       |
  238|       |        assert_eq!(rep_weights.len(), 0);
  239|       |        assert_eq!(put_tracker.output(), vec![(representative, 9.into())]);
  240|       |    }
  241|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/representative_block_finder.rs:
    1|       |use rsnano_core::{Block, BlockHash};
    2|       |use rsnano_store_lmdb::{LmdbStore, Transaction};
    3|       |
    4|       |/// Goes back in the block history until it finds a block with representative information
    5|       |pub struct RepresentativeBlockFinder<'a> {
    6|       |    txn: &'a dyn Transaction,
    7|       |    store: &'a LmdbStore,
    8|       |}
    9|       |
   10|       |impl<'a> RepresentativeBlockFinder<'a> {
   11|      0|    pub fn new(txn: &'a dyn Transaction, store: &'a LmdbStore) -> Self {
   12|      0|        Self { txn, store }
   13|      0|    }
   14|       |
   15|      0|    pub fn find_rep_block(&self, hash: BlockHash) -> BlockHash {
   16|      0|        let mut current = hash;
   17|      0|        let mut result = BlockHash::zero();
   18|      0|        while result.is_zero() {
   19|      0|            let Some(block) = self.store.block.get(self.txn, &current) else {
   20|      0|                return BlockHash::zero();
   21|       |            };
   22|      0|            (current, result) = match &*block {
   23|      0|                Block::LegacySend(_) => (block.previous(), BlockHash::zero()),
   24|      0|                Block::LegacyReceive(_) => (block.previous(), BlockHash::zero()),
   25|      0|                Block::LegacyOpen(_) => (BlockHash::zero(), block.hash()),
   26|      0|                Block::LegacyChange(_) => (BlockHash::zero(), block.hash()),
   27|      0|                Block::State(_) => (BlockHash::zero(), block.hash()),
   28|       |            };
   29|       |        }
   30|       |
   31|      0|        result
   32|      0|    }
   33|       |}

/home/gustav/code/nano/rsnano-node/ledger/src/write_queue.rs:
    1|       |use std::{
    2|       |    collections::VecDeque,
    3|       |    sync::{Arc, Condvar, Mutex},
    4|       |};
    5|       |
    6|       |/** Distinct areas write locking is done, order is irrelevant */
    7|      0|#[derive(FromPrimitive, Clone, Copy, PartialEq, Eq)]
    8|       |pub enum Writer {
    9|       |    ConfirmationHeight,
   10|       |    BlockProcessor,
   11|       |    Pruning,
   12|       |    VotingFinal,
   13|       |    BoundedBacklog,
   14|       |    OnlineReps,
   15|       |    Testing, // Used in tests to emulate a write lock
   16|       |}
   17|       |
   18|       |pub struct WriteGuard {
   19|       |    pub writer: Writer,
   20|       |    guard_finish_callback: Option<Arc<dyn Fn() + Send + Sync>>,
   21|       |}
   22|       |
   23|       |impl WriteGuard {
   24|      8|    pub fn new(writer: Writer, guard_finish_callback: Arc<dyn Fn() + Send + Sync>) -> Self {
   25|      8|        Self {
   26|      8|            writer,
   27|      8|            guard_finish_callback: Some(guard_finish_callback),
   28|      8|        }
   29|      8|    }
   30|       |
   31|      8|    pub fn release(&mut self) {
   32|      8|        if let Some(callback) = self.guard_finish_callback.take() {
   33|      8|            callback();
   34|      8|        }
                       ^0
   35|      8|    }
   36|       |
   37|      0|    pub fn is_owned(&self) -> bool {
   38|      0|        self.guard_finish_callback.is_some()
   39|      0|    }
   40|       |
   41|      0|    pub fn null() -> Self {
   42|      0|        Self {
   43|      0|            writer: Writer::Testing,
   44|      0|            guard_finish_callback: None,
   45|      0|        }
   46|      0|    }
   47|       |}
   48|       |
   49|       |impl Drop for WriteGuard {
   50|      8|    fn drop(&mut self) {
   51|      8|        self.release();
   52|      8|    }
   53|       |}
   54|       |
   55|       |pub struct WriteQueue {
   56|       |    data: Arc<WriteQueueData>,
   57|       |    guard_finish_callback: Arc<dyn Fn() + Send + Sync>,
   58|       |}
   59|       |
   60|       |struct WriteQueueData {
   61|       |    queue: Mutex<VecDeque<Writer>>,
   62|       |    condition: Condvar,
   63|       |}
   64|       |
   65|       |impl WriteQueue {
   66|     27|    pub fn new() -> Self {
   67|     27|        let data = Arc::new(WriteQueueData {
   68|     27|            queue: Mutex::new(VecDeque::new()),
   69|     27|            condition: Condvar::new(),
   70|     27|        });
   71|     27|
   72|     27|        let data_clone = data.clone();
   73|     27|
   74|     27|        Self {
   75|     27|            data,
   76|     27|            guard_finish_callback: Arc::new(move || {
   77|      8|                let mut guard = data_clone.queue.lock().unwrap();
   78|      8|                guard.pop_front();
   79|      8|                data_clone.condition.notify_all();
   80|     27|            }),
   81|     27|        }
   82|     27|    }
   83|       |
   84|       |    /// Blocks until we are at the head of the queue and blocks other waiters until write_guard goes out of scope
   85|      8|    pub fn wait(&self, writer: Writer) -> WriteGuard {
   86|      8|        let mut lk = self.data.queue.lock().unwrap();
   87|      8|        assert!(lk.iter().all(|i| *i != writer));
                                                ^0
   88|      8|        lk.push_back(writer);
   89|      8|
   90|      8|        let _result = self
   91|      8|            .data
   92|      8|            .condition
   93|      8|            .wait_while(lk, |queue| queue.front() != Some(&writer));
   94|      8|
   95|      8|        self.create_write_guard(writer)
   96|      8|    }
   97|       |
   98|       |    /// Returns true if this writer is anywhere in the queue. Currently only used in tests
   99|      0|    pub fn contains(&self, writer: Writer) -> bool {
  100|      0|        self.data.queue.lock().unwrap().contains(&writer)
  101|      0|    }
  102|       |
  103|      8|    fn create_write_guard(&self, writer: Writer) -> WriteGuard {
  104|      8|        WriteGuard::new(writer, Arc::clone(&self.guard_finish_callback))
  105|      8|    }
  106|       |}

/home/gustav/code/nano/rsnano-node/messages/src/asc_pull_ack.rs:
    1|       |use bitvec::prelude::BitArray;
    2|       |use num_traits::FromPrimitive;
    3|       |use rsnano_core::{
    4|       |    utils::{BufferWriter, Deserialize, Serialize, Stream, StreamExt},
    5|       |    Account, Block, BlockHash, BlockType, Frontier,
    6|       |};
    7|       |use serde::ser::SerializeStruct;
    8|       |use serde_derive::Serialize;
    9|       |use std::{collections::VecDeque, fmt::Display, mem::size_of};
   10|       |
   11|       |use super::{AscPullPayloadId, MessageVariant};
   12|       |
   13|       |#[derive(Clone, PartialEq, Eq, Debug)]
   14|       |pub enum AscPullAckType {
   15|       |    Blocks(BlocksAckPayload),
   16|       |    AccountInfo(AccountInfoAckPayload),
   17|       |    Frontiers(Vec<Frontier>),
   18|       |}
   19|       |
   20|       |#[derive(Clone, PartialEq, Eq, Debug)]
   21|       |pub struct AscPullAck {
   22|       |    pub id: u64,
   23|       |    pub pull_type: AscPullAckType,
   24|       |}
   25|       |
   26|       |impl AscPullAck {
   27|       |    pub const MAX_FRONTIERS: usize = 1000;
   28|       |
   29|      0|    pub fn new_test_instance_blocks() -> Self {
   30|      0|        Self {
   31|      0|            id: 12345,
   32|      0|            pull_type: AscPullAckType::Blocks(BlocksAckPayload(VecDeque::from([
   33|      0|                Block::new_test_instance(),
   34|      0|            ]))),
   35|      0|        }
   36|      0|    }
   37|       |
   38|      0|    pub fn new_test_instance_account() -> Self {
   39|      0|        Self {
   40|      0|            id: 12345,
   41|      0|            pull_type: AscPullAckType::AccountInfo(AccountInfoAckPayload::new_test_instance()),
   42|      0|        }
   43|      0|    }
   44|       |
   45|      0|    pub fn deserialize(stream: &mut impl Stream) -> Option<Self> {
   46|      0|        let pull_type_code = AscPullPayloadId::from_u8(stream.read_u8().ok()?)?;
   47|      0|        let id = stream.read_u64_be().ok()?;
   48|      0|        let pull_type = match pull_type_code {
   49|       |            AscPullPayloadId::Blocks => {
   50|      0|                let mut payload = BlocksAckPayload::default();
   51|      0|                payload.deserialize(stream).ok()?;
   52|      0|                AscPullAckType::Blocks(payload)
   53|       |            }
   54|       |            AscPullPayloadId::AccountInfo => {
   55|      0|                let mut payload = AccountInfoAckPayload::default();
   56|      0|                payload.deserialize(stream).ok()?;
   57|      0|                AscPullAckType::AccountInfo(payload)
   58|       |            }
   59|       |            AscPullPayloadId::Frontiers => {
   60|      0|                let mut frontiers = Vec::new();
   61|      0|                let mut current = Frontier::deserialize(stream).ok()?;
   62|      0|                while current != Frontier::default() && frontiers.len() < Self::MAX_FRONTIERS {
   63|      0|                    frontiers.push(current);
   64|      0|                    current = Frontier::deserialize(stream).ok()?;
   65|       |                }
   66|      0|                AscPullAckType::Frontiers(frontiers)
   67|       |            }
   68|       |        };
   69|       |
   70|      0|        Some(AscPullAck { id, pull_type })
   71|      0|    }
   72|       |
   73|      0|    pub fn payload_type(&self) -> AscPullPayloadId {
   74|      0|        match self.pull_type {
   75|      0|            AscPullAckType::Blocks(_) => AscPullPayloadId::Blocks,
   76|      0|            AscPullAckType::AccountInfo(_) => AscPullPayloadId::AccountInfo,
   77|      0|            AscPullAckType::Frontiers(_) => AscPullPayloadId::Frontiers,
   78|       |        }
   79|      0|    }
   80|       |
   81|      0|    fn serialize_pull_type(&self, writer: &mut dyn BufferWriter) {
   82|      0|        match &self.pull_type {
   83|      0|            AscPullAckType::Blocks(blocks) => blocks.serialize(writer),
   84|      0|            AscPullAckType::AccountInfo(account_info) => account_info.serialize(writer),
   85|      0|            AscPullAckType::Frontiers(frontiers) => {
   86|      0|                debug_assert!(frontiers.len() <= Self::MAX_FRONTIERS);
   87|      0|                for frontier in frontiers {
   88|      0|                    frontier.serialize(writer);
   89|      0|                }
   90|      0|                Frontier::default().serialize(writer);
   91|       |            }
   92|       |        }
   93|      0|    }
   94|       |
   95|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
   96|      0|        let payload_length = extensions.data as usize;
   97|      0|
   98|      0|        size_of::<u8>() // type code 
   99|      0|        + size_of::<u64>() // id
  100|      0|        + payload_length
  101|      0|    }
  102|       |}
  103|       |
  104|       |impl Serialize for AscPullAck {
  105|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  106|      0|        writer.write_u8_safe(self.payload_type() as u8);
  107|      0|        writer.write_u64_be_safe(self.id);
  108|      0|        self.serialize_pull_type(writer);
  109|      0|    }
  110|       |}
  111|       |
  112|       |impl MessageVariant for AscPullAck {
  113|      0|    fn header_extensions(&self, payload_len: u16) -> BitArray<u16> {
  114|      0|        BitArray::new(
  115|      0|            payload_len
  116|      0|            -1 // pull_type
  117|      0|            - 8, // ID
  118|      0|        )
  119|      0|    }
  120|       |}
  121|       |
  122|       |impl Display for AscPullAck {
  123|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  124|      0|        match &self.pull_type {
  125|      0|            AscPullAckType::Blocks(blocks) => {
  126|      0|                for block in blocks.blocks() {
  127|      0|                    write!(f, "{}", block.to_json().map_err(|_| std::fmt::Error)?)?;
  128|       |                }
  129|       |            }
  130|      0|            AscPullAckType::AccountInfo(info) => {
  131|      0|                write!(
  132|      0|                    f,
  133|      0|                    "\naccount public key:{} account open:{} account head:{} block count:{} confirmation frontier:{} confirmation height:{}",
  134|      0|                    info.account.encode_account(),
  135|      0|                    info.account_open,
  136|      0|                    info.account_head,
  137|      0|                    info.account_block_count,
  138|      0|                    info.account_conf_frontier,
  139|      0|                    info.account_conf_height,
  140|      0|                )?;
  141|       |            }
  142|      0|            AscPullAckType::Frontiers(_) => {}
  143|       |        }
  144|      0|        Ok(())
  145|      0|    }
  146|       |}
  147|       |
  148|       |#[derive(Clone, Default, PartialEq, Eq, Debug)]
  149|       |pub struct BlocksAckPayload(VecDeque<Block>);
  150|       |
  151|       |impl BlocksAckPayload {
  152|      0|    pub fn new(blocks: VecDeque<Block>) -> Self {
  153|      0|        if blocks.len() > Self::MAX_BLOCKS {
  154|      0|            panic!(
  155|      0|                "too many blocks for BlocksAckPayload. Maximum is {}, but was {}",
  156|      0|                Self::MAX_BLOCKS,
  157|      0|                blocks.len()
  158|      0|            );
  159|      0|        }
  160|      0|        Self(blocks)
  161|      0|    }
  162|       |
  163|       |    /* Header allows for 16 bit extensions; 65535 bytes / 500 bytes (block size with some future margin) ~ 131 */
  164|       |    pub const MAX_BLOCKS: usize = 128;
  165|       |
  166|      0|    pub fn blocks(&self) -> &VecDeque<Block> {
  167|      0|        &self.0
  168|      0|    }
  169|       |
  170|      0|    pub fn deserialize(&mut self, stream: &mut dyn Stream) -> anyhow::Result<()> {
  171|      0|        while let Ok(current) = Block::deserialize(stream) {
  172|      0|            if self.0.len() >= Self::MAX_BLOCKS {
  173|      0|                bail!("too many blocks")
  174|      0|            }
  175|      0|            self.0.push_back(current);
  176|       |        }
  177|      0|        Ok(())
  178|      0|    }
  179|       |}
  180|       |
  181|       |impl Serialize for BlocksAckPayload {
  182|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  183|      0|        for block in self.blocks() {
  184|      0|            block.serialize(writer);
  185|      0|        }
  186|       |        // For convenience, end with null block terminator
  187|      0|        writer.write_u8_safe(BlockType::NotABlock as u8)
  188|      0|    }
  189|       |}
  190|       |
  191|       |impl serde::Serialize for BlocksAckPayload {
  192|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
  193|      0|    where
  194|      0|        S: serde::Serializer,
  195|      0|    {
  196|      0|        let mut state = serializer.serialize_struct("Block", 6)?;
  197|      0|        state.serialize_field("blocks", &self.0)?;
  198|      0|        state.end()
  199|      0|    }
  200|       |}
  201|       |
  202|       |#[derive(Clone, Default, PartialEq, Eq, Debug, Serialize)]
  203|       |pub struct AccountInfoAckPayload {
  204|       |    pub account: Account,
  205|       |    pub account_open: BlockHash,
  206|       |    pub account_head: BlockHash,
  207|       |    pub account_block_count: u64,
  208|       |    pub account_conf_frontier: BlockHash,
  209|       |    pub account_conf_height: u64,
  210|       |}
  211|       |
  212|       |impl AccountInfoAckPayload {
  213|      0|    pub fn deserialize(&mut self, stream: &mut dyn Stream) -> anyhow::Result<()> {
  214|      0|        self.account = Account::deserialize(stream)?;
  215|      0|        self.account_open = BlockHash::deserialize(stream)?;
  216|      0|        self.account_head = BlockHash::deserialize(stream)?;
  217|      0|        self.account_block_count = stream.read_u64_be()?;
  218|      0|        self.account_conf_frontier = BlockHash::deserialize(stream)?;
  219|      0|        self.account_conf_height = stream.read_u64_be()?;
  220|      0|        Ok(())
  221|      0|    }
  222|       |
  223|      0|    pub(crate) fn new_test_instance() -> AccountInfoAckPayload {
  224|      0|        Self {
  225|      0|            account: Account::from(1),
  226|      0|            account_open: BlockHash::from(2),
  227|      0|            account_head: BlockHash::from(3),
  228|      0|            account_block_count: 4,
  229|      0|            account_conf_frontier: BlockHash::from(5),
  230|      0|            account_conf_height: 3,
  231|      0|        }
  232|      0|    }
  233|       |}
  234|       |
  235|       |impl Serialize for AccountInfoAckPayload {
  236|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  237|      0|        self.account.serialize(writer);
  238|      0|        self.account_open.serialize(writer);
  239|      0|        self.account_head.serialize(writer);
  240|      0|        writer.write_u64_be_safe(self.account_block_count);
  241|      0|        self.account_conf_frontier.serialize(writer);
  242|      0|        writer.write_u64_be_safe(self.account_conf_height);
  243|      0|    }
  244|       |}
  245|       |
  246|       |#[cfg(test)]
  247|       |mod tests {
  248|       |    use super::*;
  249|       |    use crate::{assert_deserializable, Message};
  250|       |    use rsnano_core::TestBlockBuilder;
  251|       |
  252|       |    #[test]
  253|       |    fn serialize_blocks() {
  254|       |        let original = Message::AscPullAck(AscPullAck {
  255|       |            id: 7,
  256|       |            pull_type: AscPullAckType::Blocks(BlocksAckPayload::new(VecDeque::from([
  257|       |                TestBlockBuilder::state().build(),
  258|       |                TestBlockBuilder::state().build(),
  259|       |            ]))),
  260|       |        });
  261|       |
  262|       |        assert_deserializable(&original);
  263|       |    }
  264|       |
  265|       |    #[test]
  266|       |    fn serialize_account_info() {
  267|       |        let original = Message::AscPullAck(AscPullAck {
  268|       |            id: 7,
  269|       |            pull_type: AscPullAckType::AccountInfo(AccountInfoAckPayload {
  270|       |                account: Account::from(1),
  271|       |                account_open: BlockHash::from(2),
  272|       |                account_head: BlockHash::from(3),
  273|       |                account_block_count: 4,
  274|       |                account_conf_frontier: BlockHash::from(5),
  275|       |                account_conf_height: 6,
  276|       |            }),
  277|       |        });
  278|       |
  279|       |        assert_deserializable(&original);
  280|       |    }
  281|       |
  282|       |    #[test]
  283|       |    fn serialize_frontiers() {
  284|       |        let original = Message::AscPullAck(AscPullAck {
  285|       |            id: 7,
  286|       |            pull_type: AscPullAckType::Frontiers(vec![Frontier::new(
  287|       |                Account::from(1),
  288|       |                BlockHash::from(2),
  289|       |            )]),
  290|       |        });
  291|       |
  292|       |        assert_deserializable(&original);
  293|       |    }
  294|       |
  295|       |    #[test]
  296|       |    fn display() {
  297|       |        let ack = Message::AscPullAck(AscPullAck {
  298|       |            id: 7,
  299|       |            pull_type: AscPullAckType::AccountInfo(AccountInfoAckPayload {
  300|       |                account: Account::from(1),
  301|       |                account_open: BlockHash::from(2),
  302|       |                account_head: BlockHash::from(3),
  303|       |                account_block_count: 4,
  304|       |                account_conf_frontier: BlockHash::from(5),
  305|       |                account_conf_height: 6,
  306|       |            }),
  307|       |        });
  308|       |        assert_eq!(ack.to_string(), "\naccount public key:nano_1111111111111111111111111111111111111111111111111113b8661hfk account open:0000000000000000000000000000000000000000000000000000000000000002 account head:0000000000000000000000000000000000000000000000000000000000000003 block count:4 confirmation frontier:0000000000000000000000000000000000000000000000000000000000000005 confirmation height:6");
  309|       |    }
  310|       |}

/home/gustav/code/nano/rsnano-node/messages/src/asc_pull_req.rs:
    1|       |use super::MessageVariant;
    2|       |use bitvec::prelude::BitArray;
    3|       |use num_traits::FromPrimitive;
    4|       |use rsnano_core::{
    5|       |    utils::{BufferWriter, Deserialize, Serialize, Stream, StreamExt},
    6|       |    Account, HashOrAccount,
    7|       |};
    8|       |use serde_derive::Serialize;
    9|       |use std::{fmt::Display, mem::size_of};
   10|       |
   11|       |/**
   12|       | * Type of requested asc pull data
   13|       | * - blocks:
   14|       | * - account_info:
   15|       | */
   16|       |#[repr(u8)]
   17|      0|#[derive(Clone, FromPrimitive)]
   18|       |pub enum AscPullPayloadId {
   19|       |    Blocks = 0x1,
   20|       |    AccountInfo = 0x2,
   21|       |    Frontiers = 0x3,
   22|       |}
   23|       |
   24|       |#[derive(Clone, PartialEq, Eq, Debug, Serialize)]
   25|       |#[serde(rename_all = "snake_case", tag = "pull_type")]
   26|       |pub enum AscPullReqType {
   27|       |    Blocks(BlocksReqPayload),
   28|       |    AccountInfo(AccountInfoReqPayload),
   29|       |    Frontiers(FrontiersReqPayload),
   30|       |}
   31|       |
   32|       |impl Serialize for AscPullReqType {
   33|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   34|      0|        match &self {
   35|      0|            AscPullReqType::Blocks(blocks) => blocks.serialize(writer),
   36|      0|            AscPullReqType::AccountInfo(account_info) => account_info.serialize(writer),
   37|      0|            AscPullReqType::Frontiers(frontiers) => frontiers.serialize(writer),
   38|       |        }
   39|      0|    }
   40|       |}
   41|       |
   42|      0|#[derive(FromPrimitive, PartialEq, Eq, Clone, Copy, Debug, Default, Serialize)]
   43|       |#[serde(rename_all = "snake_case")]
   44|       |pub enum HashType {
   45|       |    #[default]
   46|       |    Account = 0,
   47|       |    Block = 1,
   48|       |}
   49|       |
   50|       |impl HashType {
   51|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self> {
   52|      0|        FromPrimitive::from_u8(stream.read_u8()?).ok_or_else(|| anyhow!("target_type missing"))
   53|      0|    }
   54|       |}
   55|       |
   56|       |#[derive(Default, Clone, PartialEq, Eq, Debug, Serialize)]
   57|       |pub struct BlocksReqPayload {
   58|       |    pub start_type: HashType,
   59|       |    pub start: HashOrAccount,
   60|       |    pub count: u8,
   61|       |}
   62|       |
   63|       |impl BlocksReqPayload {
   64|      0|    pub fn new_test_instance() -> Self {
   65|      0|        Self {
   66|      0|            start: HashOrAccount::from(123),
   67|      0|            count: 100,
   68|      0|            start_type: HashType::Account,
   69|      0|        }
   70|      0|    }
   71|       |
   72|      0|    fn deserialize(&mut self, stream: &mut dyn Stream) -> anyhow::Result<()> {
   73|      0|        self.start = HashOrAccount::deserialize(stream)?;
   74|      0|        self.count = stream.read_u8()?;
   75|      0|        self.start_type = HashType::deserialize(stream)?;
   76|      0|        Ok(())
   77|      0|    }
   78|       |}
   79|       |
   80|       |impl Serialize for BlocksReqPayload {
   81|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   82|      0|        writer.write_bytes_safe(self.start.as_bytes());
   83|      0|        writer.write_u8_safe(self.count);
   84|      0|        writer.write_u8_safe(self.start_type as u8);
   85|      0|    }
   86|       |}
   87|       |
   88|       |#[derive(Default, Clone, PartialEq, Eq, Debug, Serialize)]
   89|       |#[serde(rename_all = "snake_case")]
   90|       |pub struct AccountInfoReqPayload {
   91|       |    pub target: HashOrAccount,
   92|       |    pub target_type: HashType,
   93|       |}
   94|       |
   95|       |impl AccountInfoReqPayload {
   96|      0|    fn deserialize(&mut self, stream: &mut dyn Stream) -> anyhow::Result<()> {
   97|      0|        self.target = HashOrAccount::deserialize(stream)?;
   98|      0|        self.target_type = HashType::deserialize(stream)?;
   99|      0|        Ok(())
  100|      0|    }
  101|       |
  102|      0|    pub fn new_test_instance() -> Self {
  103|      0|        Self {
  104|      0|            target: HashOrAccount::from(42),
  105|      0|            target_type: HashType::Account,
  106|      0|        }
  107|      0|    }
  108|       |}
  109|       |
  110|       |impl Serialize for AccountInfoReqPayload {
  111|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  112|      0|        writer.write_bytes_safe(self.target.as_bytes());
  113|      0|        writer.write_u8_safe(self.target_type as u8);
  114|      0|    }
  115|       |}
  116|       |
  117|       |#[derive(Default, Clone, PartialEq, Eq, Debug, Serialize)]
  118|       |#[serde(rename_all = "snake_case")]
  119|       |pub struct FrontiersReqPayload {
  120|       |    pub start: Account,
  121|       |    pub count: u16,
  122|       |}
  123|       |
  124|       |impl FrontiersReqPayload {
  125|       |    /// Header allows for 16 bit extensions; 65536 bytes / 64 bytes (account + frontier) ~ 1024,
  126|       |    /// but we need some space for null frontier terminator
  127|       |    pub const MAX_FRONTIERS: u16 = 1000;
  128|       |
  129|      0|    fn deserialize(&mut self, stream: &mut dyn Stream) -> anyhow::Result<()> {
  130|      0|        self.start = Account::deserialize(stream)?;
  131|      0|        let mut count_bytes = [0u8; 2];
  132|      0|        stream.read_bytes(&mut count_bytes, 2)?;
  133|      0|        self.count = u16::from_be_bytes(count_bytes);
  134|      0|        Ok(())
  135|      0|    }
  136|       |}
  137|       |
  138|       |impl Serialize for FrontiersReqPayload {
  139|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  140|      0|        self.start.serialize(stream);
  141|      0|        let count_bytes = self.count.to_be_bytes();
  142|      0|        stream.write_bytes_safe(&count_bytes);
  143|      0|    }
  144|       |}
  145|       |
  146|       |/// Ascending bootstrap pull request
  147|       |#[derive(Clone, PartialEq, Eq, Debug, Serialize)]
  148|       |#[serde(rename_all = "snake_case")]
  149|       |pub struct AscPullReq {
  150|       |    pub id: u64,
  151|       |    #[serde(flatten)]
  152|       |    pub req_type: AscPullReqType,
  153|       |}
  154|       |
  155|       |impl Display for AscPullReq {
  156|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  157|      0|        match &self.req_type {
  158|      0|            AscPullReqType::Blocks(blocks) => {
  159|      0|                write!(
  160|      0|                    f,
  161|      0|                    "\nacc:{} max block count:{} hash type: {}",
  162|      0|                    blocks.start, blocks.count, blocks.start_type as u8
  163|      0|                )?;
  164|       |            }
  165|      0|            AscPullReqType::AccountInfo(info) => {
  166|      0|                write!(
  167|      0|                    f,
  168|      0|                    "\ntarget:{} hash type:{}",
  169|      0|                    info.target, info.target_type as u8
  170|      0|                )?;
  171|       |            }
  172|      0|            AscPullReqType::Frontiers(frontiers) => {
  173|      0|                write!(f, "\nstart:{} count:{}", frontiers.start, frontiers.count)?;
  174|       |            }
  175|       |        }
  176|      0|        Ok(())
  177|      0|    }
  178|       |}
  179|       |
  180|       |impl AscPullReq {
  181|      0|    pub fn new_test_instance_blocks() -> Self {
  182|      0|        Self {
  183|      0|            id: 12345,
  184|      0|            req_type: AscPullReqType::Blocks(BlocksReqPayload::new_test_instance()),
  185|      0|        }
  186|      0|    }
  187|       |
  188|      0|    pub fn new_test_instance_account() -> Self {
  189|      0|        Self {
  190|      0|            id: 12345,
  191|      0|            req_type: AscPullReqType::AccountInfo(AccountInfoReqPayload::new_test_instance()),
  192|      0|        }
  193|      0|    }
  194|       |
  195|      0|    pub fn deserialize(stream: &mut impl Stream) -> Option<Self> {
  196|      0|        let pull_type = AscPullPayloadId::from_u8(stream.read_u8().ok()?)?;
  197|      0|        let id = stream.read_u64_be().ok()?;
  198|       |
  199|      0|        let req_type = match pull_type {
  200|       |            AscPullPayloadId::Blocks => {
  201|      0|                let mut payload = BlocksReqPayload::default();
  202|      0|                payload.deserialize(stream).ok()?;
  203|      0|                AscPullReqType::Blocks(payload)
  204|       |            }
  205|       |            AscPullPayloadId::AccountInfo => {
  206|      0|                let mut payload = AccountInfoReqPayload::default();
  207|      0|                payload.deserialize(stream).ok()?;
  208|      0|                AscPullReqType::AccountInfo(payload)
  209|       |            }
  210|       |            AscPullPayloadId::Frontiers => {
  211|      0|                let mut payload = FrontiersReqPayload::default();
  212|      0|                payload.deserialize(stream).ok()?;
  213|      0|                AscPullReqType::Frontiers(payload)
  214|       |            }
  215|       |        };
  216|      0|        Some(Self { id, req_type })
  217|      0|    }
  218|       |
  219|      0|    pub fn payload_type(&self) -> AscPullPayloadId {
  220|      0|        match &self.req_type {
  221|      0|            AscPullReqType::Blocks(_) => AscPullPayloadId::Blocks,
  222|      0|            AscPullReqType::AccountInfo(_) => AscPullPayloadId::AccountInfo,
  223|      0|            AscPullReqType::Frontiers(_) => AscPullPayloadId::Frontiers,
  224|       |        }
  225|      0|    }
  226|       |
  227|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
  228|      0|        let payload_len = extensions.data as usize;
  229|      0|        size_of::<u8>() // pull type
  230|      0|        + size_of::<u64>() // id
  231|      0|        + payload_len
  232|      0|    }
  233|       |}
  234|       |
  235|       |impl Serialize for AscPullReq {
  236|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  237|      0|        writer.write_u8_safe(self.payload_type() as u8);
  238|      0|        writer.write_u64_be_safe(self.id);
  239|      0|        self.req_type.serialize(writer);
  240|      0|    }
  241|       |}
  242|       |
  243|       |impl MessageVariant for AscPullReq {
  244|      0|    fn header_extensions(&self, payload_len: u16) -> BitArray<u16> {
  245|      0|        BitArray::new(
  246|      0|            payload_len
  247|      0|            -1 // pull_type
  248|      0|            - 8, // ID
  249|      0|        )
  250|      0|    }
  251|       |}
  252|       |
  253|       |#[cfg(test)]
  254|       |mod tests {
  255|       |    use super::*;
  256|       |    use crate::{assert_deserializable, Message};
  257|       |
  258|       |    #[test]
  259|       |    fn serialize_blocks() {
  260|       |        let original = Message::AscPullReq(AscPullReq {
  261|       |            id: 7,
  262|       |            req_type: AscPullReqType::Blocks(BlocksReqPayload {
  263|       |                start: HashOrAccount::from(3),
  264|       |                count: 111,
  265|       |                start_type: HashType::Block,
  266|       |            }),
  267|       |        });
  268|       |
  269|       |        assert_deserializable(&original);
  270|       |    }
  271|       |
  272|       |    #[test]
  273|       |    fn serialize_account_info() {
  274|       |        let original = Message::AscPullReq(AscPullReq {
  275|       |            id: 7,
  276|       |            req_type: AscPullReqType::AccountInfo(AccountInfoReqPayload {
  277|       |                target: HashOrAccount::from(123),
  278|       |                target_type: HashType::Block,
  279|       |            }),
  280|       |        });
  281|       |
  282|       |        assert_deserializable(&original);
  283|       |    }
  284|       |
  285|       |    #[test]
  286|       |    fn serialize_frontiers() {
  287|       |        let original = Message::AscPullReq(AscPullReq {
  288|       |            id: 7,
  289|       |            req_type: AscPullReqType::Frontiers(FrontiersReqPayload {
  290|       |                start: Account::from(42),
  291|       |                count: 69,
  292|       |            }),
  293|       |        });
  294|       |        assert_deserializable(&original);
  295|       |    }
  296|       |
  297|       |    #[test]
  298|       |    fn display_blocks_payload() {
  299|       |        let req = Message::AscPullReq(AscPullReq {
  300|       |            req_type: AscPullReqType::Blocks(BlocksReqPayload {
  301|       |                start: 1.into(),
  302|       |                count: 2,
  303|       |                start_type: HashType::Block,
  304|       |            }),
  305|       |            id: 7,
  306|       |        });
  307|       |        assert_eq!(req.to_string(), "\nacc:0000000000000000000000000000000000000000000000000000000000000001 max block count:2 hash type: 1");
  308|       |    }
  309|       |
  310|       |    #[test]
  311|       |    fn display_account_info_payload() {
  312|       |        let req = Message::AscPullReq(AscPullReq {
  313|       |            req_type: AscPullReqType::AccountInfo(AccountInfoReqPayload {
  314|       |                target: HashOrAccount::from(123),
  315|       |                target_type: HashType::Block,
  316|       |            }),
  317|       |            id: 7,
  318|       |        });
  319|       |        assert_eq!(
  320|       |            req.to_string(),
  321|       |            "\ntarget:000000000000000000000000000000000000000000000000000000000000007B hash type:1"
  322|       |        );
  323|       |    }
  324|       |}

/home/gustav/code/nano/rsnano-node/messages/src/bulk_pull.rs:
    1|       |use super::MessageVariant;
    2|       |use bitvec::prelude::BitArray;
    3|       |use rsnano_core::{
    4|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    5|       |    BlockHash, HashOrAccount,
    6|       |};
    7|       |use serde_derive::Serialize;
    8|       |use std::{fmt::Display, mem::size_of};
    9|       |
   10|       |#[derive(Clone, PartialEq, Eq, Debug, Serialize, Default)]
   11|       |#[serde(rename_all = "snake_case")]
   12|       |pub struct BulkPull {
   13|       |    pub start: HashOrAccount,
   14|       |    pub end: BlockHash,
   15|       |    pub count: u32,
   16|       |    pub ascending: bool,
   17|       |}
   18|       |
   19|       |impl BulkPull {
   20|       |    pub const COUNT_PRESENT_FLAG: usize = 0;
   21|       |    pub const ASCENDING_FLAG: usize = 1;
   22|       |    pub const EXTENDED_PARAMETERS_SIZE: usize = 8;
   23|       |
   24|      0|    pub fn new_test_instance() -> BulkPull {
   25|      0|        Self {
   26|      0|            start: 1.into(),
   27|      0|            end: 2.into(),
   28|      0|            count: 3,
   29|      0|            ascending: true,
   30|      0|        }
   31|      0|    }
   32|       |
   33|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
   34|      0|        HashOrAccount::serialized_size()
   35|      0|            + BlockHash::serialized_size()
   36|      0|            + (if extensions[BulkPull::COUNT_PRESENT_FLAG] {
   37|      0|                BulkPull::EXTENDED_PARAMETERS_SIZE
   38|       |            } else {
   39|      0|                0
   40|       |            })
   41|      0|    }
   42|       |
   43|      0|    pub fn deserialize(stream: &mut impl Stream, extensions: BitArray<u16>) -> Option<Self> {
   44|      0|        let start = HashOrAccount::deserialize(stream).ok()?;
   45|      0|        let end = BlockHash::deserialize(stream).ok()?;
   46|       |
   47|      0|        let count = if extensions[BulkPull::COUNT_PRESENT_FLAG] {
   48|      0|            let mut extended_parameters_buffers = [0u8; BulkPull::EXTENDED_PARAMETERS_SIZE];
   49|      0|            const_assert!(size_of::<u32>() < (BulkPull::EXTENDED_PARAMETERS_SIZE - 1)); // "count must fit within buffer")
   50|      0|
   51|      0|            stream
   52|      0|                .read_bytes(
   53|      0|                    &mut extended_parameters_buffers,
   54|      0|                    BulkPull::EXTENDED_PARAMETERS_SIZE,
   55|      0|                )
   56|      0|                .ok()?;
   57|      0|            if extended_parameters_buffers[0] != 0 {
   58|      0|                return None;
   59|       |            } else {
   60|      0|                u32::from_le_bytes(extended_parameters_buffers[1..5].try_into().unwrap())
   61|       |            }
   62|       |        } else {
   63|      0|            0
   64|       |        };
   65|       |
   66|      0|        let ascending = extensions[BulkPull::ASCENDING_FLAG];
   67|      0|
   68|      0|        Some(BulkPull {
   69|      0|            start,
   70|      0|            end,
   71|      0|            count,
   72|      0|            ascending,
   73|      0|        })
   74|      0|    }
   75|       |}
   76|       |
   77|       |impl Serialize for BulkPull {
   78|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   79|      0|        self.start.serialize(writer);
   80|      0|        self.end.serialize(writer);
   81|      0|
   82|      0|        if self.count > 0 {
   83|      0|            let mut count_buffer = [0u8; BulkPull::EXTENDED_PARAMETERS_SIZE];
   84|      0|            const_assert!(size_of::<u32>() < (BulkPull::EXTENDED_PARAMETERS_SIZE - 1)); // count must fit within buffer
   85|      0|
   86|      0|            count_buffer[1..5].copy_from_slice(&self.count.to_le_bytes());
   87|      0|            writer.write_bytes_safe(&count_buffer);
   88|      0|        }
   89|      0|    }
   90|       |}
   91|       |
   92|       |impl MessageVariant for BulkPull {
   93|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
   94|      0|        let mut extensions = BitArray::default();
   95|      0|        extensions.set(BulkPull::COUNT_PRESENT_FLAG, self.count > 0);
   96|      0|        extensions.set(BulkPull::ASCENDING_FLAG, self.ascending);
   97|      0|        extensions
   98|      0|    }
   99|       |}
  100|       |
  101|       |impl Display for BulkPull {
  102|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  103|      0|        write!(
  104|      0|            f,
  105|      0|            "\nstart={} end={} cnt={}",
  106|      0|            self.start, self.end, self.count
  107|      0|        )
  108|      0|    }
  109|       |}
  110|       |
  111|       |#[cfg(test)]
  112|       |mod tests {
  113|       |    use super::*;
  114|       |    use crate::{assert_deserializable, Message};
  115|       |
  116|       |    #[test]
  117|       |    fn bulk_pull_serialization() {
  118|       |        let message = Message::BulkPull(BulkPull::new_test_instance());
  119|       |        assert_deserializable(&message);
  120|       |    }
  121|       |}

/home/gustav/code/nano/rsnano-node/messages/src/bulk_pull_account.rs:
    1|       |use num_traits::FromPrimitive;
    2|       |use rsnano_core::{
    3|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    4|       |    Account, Amount,
    5|       |};
    6|       |use serde::ser::SerializeStruct;
    7|       |use serde_derive::Serialize;
    8|       |use std::{fmt::Display, mem::size_of};
    9|       |
   10|       |use super::MessageVariant;
   11|       |
   12|      0|#[derive(Clone, Copy, PartialEq, Eq, FromPrimitive, Debug, Serialize)]
   13|       |#[serde(rename_all = "snake_case")]
   14|       |#[repr(u8)]
   15|       |pub enum BulkPullAccountFlags {
   16|       |    PendingHashAndAmount = 0x0,
   17|       |    PendingAddressOnly = 0x1,
   18|       |    PendingHashAmountAndAddress = 0x2,
   19|       |}
   20|       |
   21|       |#[derive(Clone, Debug, PartialEq, Eq)]
   22|       |pub struct BulkPullAccount {
   23|       |    pub account: Account,
   24|       |    pub minimum_amount: Amount,
   25|       |    pub flags: BulkPullAccountFlags,
   26|       |}
   27|       |
   28|       |impl BulkPullAccount {
   29|      0|    pub fn deserialize(stream: &mut impl Stream) -> Option<Self> {
   30|      0|        let payload = Self {
   31|      0|            account: Account::deserialize(stream).ok()?,
   32|      0|            minimum_amount: Amount::deserialize(stream).ok()?,
   33|      0|            flags: BulkPullAccountFlags::from_u8(stream.read_u8().ok()?)?,
   34|       |        };
   35|      0|        Some(payload)
   36|      0|    }
   37|       |
   38|      0|    pub fn serialized_size() -> usize {
   39|      0|        Account::serialized_size() + Amount::serialized_size() + size_of::<BulkPullAccountFlags>()
   40|      0|    }
   41|       |
   42|      0|    pub fn new_test_instance() -> BulkPullAccount {
   43|      0|        Self {
   44|      0|            account: 1.into(),
   45|      0|            minimum_amount: 42.into(),
   46|      0|            flags: BulkPullAccountFlags::PendingHashAndAmount,
   47|      0|        }
   48|      0|    }
   49|       |}
   50|       |
   51|       |impl MessageVariant for BulkPullAccount {}
   52|       |
   53|       |impl Serialize for BulkPullAccount {
   54|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   55|      0|        self.account.serialize(writer);
   56|      0|        self.minimum_amount.serialize(writer);
   57|      0|        writer.write_u8_safe(self.flags as u8);
   58|      0|    }
   59|       |}
   60|       |
   61|       |impl Display for BulkPullAccount {
   62|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   63|      0|        write!(
   64|      0|            f,
   65|      0|            "\nacc={} min={}",
   66|      0|            self.account.encode_hex(),
   67|      0|            self.minimum_amount.to_string_dec()
   68|      0|        )?;
   69|       |
   70|      0|        let flag_str = match self.flags {
   71|      0|            BulkPullAccountFlags::PendingHashAndAmount => "pending_hash_and_amount",
   72|      0|            BulkPullAccountFlags::PendingAddressOnly => "pending_address_only",
   73|      0|            BulkPullAccountFlags::PendingHashAmountAndAddress => "pending_hash_amount_and_address",
   74|       |        };
   75|       |
   76|      0|        write!(f, " {}", flag_str)
   77|      0|    }
   78|       |}
   79|       |
   80|       |impl serde::Serialize for BulkPullAccount {
   81|      0|    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
   82|      0|    where
   83|      0|        S: serde::Serializer,
   84|      0|    {
   85|      0|        let mut state = serializer.serialize_struct("Message", 1)?;
   86|      0|        state.serialize_field("message_type", "bulk_push")?;
   87|      0|        state.end()
   88|      0|    }
   89|       |}

/home/gustav/code/nano/rsnano-node/messages/src/confirm_ack.rs:
    1|       |use super::{ConfirmReq, MessageVariant};
    2|       |use bitvec::prelude::BitArray;
    3|       |use rsnano_core::{
    4|       |    utils::{BufferWriter, Serialize, Stream},
    5|       |    Vote,
    6|       |};
    7|       |use std::fmt::{Debug, Display};
    8|       |/*
    9|       | * Binary Format:
   10|       | * [message_header] Common message header
   11|       | * [variable] Vote
   12|       | * - Serialized/deserialized by the `nano::vote` class.
   13|       | *
   14|       | * Header extensions:
   15|       | * - [0xf000] Count (for V1 protocol)
   16|       | * - [0x0f00] Block type
   17|       | *   - Not used anymore (V25.1+), but still present and set to `not_a_block = 0x1` for backwards compatibility
   18|       | * - [0xf000 (high), 0x00f0 (low)] Count V2 masks (for V2 protocol)
   19|       | * - [0x0001] Confirm V2 flag
   20|       | * - [0x0002] Reserved for V3+ versioning
   21|       | * - [0x0004] Rebroadcasted flag
   22|       | */
   23|       |#[derive(Clone, Debug, serde::Serialize)]
   24|       |pub struct ConfirmAck {
   25|       |    vote: Vote,
   26|       |    is_rebroadcasted: bool,
   27|       |    /// Messages deserialized from network should have their digest set
   28|       |    pub digest: u128,
   29|       |}
   30|       |
   31|       |impl ConfirmAck {
   32|       |    pub const HASHES_MAX: usize = 255;
   33|       |    pub const REBROADCASTED_FLAG: usize = 2;
   34|       |
   35|      0|    pub fn new_with_own_vote(vote: Vote) -> Self {
   36|      0|        assert!(vote.hashes.len() <= Self::HASHES_MAX);
   37|      0|        Self {
   38|      0|            vote,
   39|      0|            is_rebroadcasted: false,
   40|      0|            digest: 0,
   41|      0|        }
   42|      0|    }
   43|       |
   44|      0|    pub fn new_with_rebroadcasted_vote(vote: Vote) -> Self {
   45|      0|        assert!(vote.hashes.len() <= Self::HASHES_MAX);
   46|      0|        Self {
   47|      0|            vote,
   48|      0|            is_rebroadcasted: true,
   49|      0|            digest: 0,
   50|      0|        }
   51|      0|    }
   52|       |
   53|      0|    pub fn vote(&self) -> &Vote {
   54|      0|        &self.vote
   55|      0|    }
   56|       |
   57|      0|    pub fn is_rebroadcasted(&self) -> bool {
   58|      0|        self.is_rebroadcasted
   59|      0|    }
   60|       |
   61|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
   62|      0|        let count = ConfirmReq::count(extensions);
   63|      0|        Vote::serialized_size(count as usize)
   64|      0|    }
   65|       |
   66|      0|    pub fn deserialize(
   67|      0|        stream: &mut impl Stream,
   68|      0|        extensions: BitArray<u16>,
   69|      0|        digest: u128,
   70|      0|    ) -> Option<Self> {
   71|      0|        let mut vote = Vote::null();
   72|      0|        vote.deserialize(stream).ok()?;
   73|       |
   74|      0|        let is_rebroadcasted = extensions[Self::REBROADCASTED_FLAG];
   75|      0|        let mut ack = if is_rebroadcasted {
   76|      0|            ConfirmAck::new_with_rebroadcasted_vote(vote)
   77|       |        } else {
   78|      0|            ConfirmAck::new_with_own_vote(vote)
   79|       |        };
   80|      0|        ack.digest = digest;
   81|      0|
   82|      0|        Some(ack)
   83|      0|    }
   84|       |
   85|      0|    pub fn new_test_instance() -> Self {
   86|      0|        Self::new_with_own_vote(Vote::new_test_instance())
   87|      0|    }
   88|       |}
   89|       |
   90|       |impl Serialize for ConfirmAck {
   91|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   92|      0|        self.vote.serialize(writer);
   93|      0|    }
   94|       |}
   95|       |
   96|       |impl MessageVariant for ConfirmAck {
   97|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
   98|      0|        let mut extensions = BitArray::default();
   99|      0|        extensions |= ConfirmReq::count_bits(self.vote.hashes.len() as u8);
  100|      0|        extensions.set(Self::REBROADCASTED_FLAG, self.is_rebroadcasted);
  101|      0|        extensions
  102|      0|    }
  103|       |}
  104|       |
  105|       |impl PartialEq for ConfirmAck {
  106|      0|    fn eq(&self, other: &Self) -> bool {
  107|      0|        self.vote == other.vote
  108|      0|    }
  109|       |}
  110|       |
  111|       |impl Eq for ConfirmAck {}
  112|       |
  113|       |impl Display for ConfirmAck {
  114|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  115|      0|        write!(f, "\n{}", self.vote.to_json())
  116|      0|    }
  117|       |}
  118|       |
  119|       |#[cfg(test)]
  120|       |mod tests {
  121|       |    use super::*;
  122|       |    use crate::{assert_deserializable, Message};
  123|       |    use rsnano_core::{utils::MemoryStream, BlockHash, PrivateKey};
  124|       |
  125|       |    #[test]
  126|       |    fn serialize_v1() {
  127|       |        let keys = PrivateKey::new();
  128|       |        let hashes = vec![BlockHash::from(1)];
  129|       |        let vote = Vote::new(&keys, 0, 0, hashes);
  130|       |        let confirm = Message::ConfirmAck(ConfirmAck::new_with_own_vote(vote));
  131|       |
  132|       |        assert_deserializable(&confirm);
  133|       |    }
  134|       |
  135|       |    #[test]
  136|       |    fn serialize_v2() {
  137|       |        let keys = PrivateKey::new();
  138|       |        let mut hashes = Vec::new();
  139|       |        for i in 0..ConfirmAck::HASHES_MAX {
  140|       |            hashes.push(BlockHash::from(i as u64))
  141|       |        }
  142|       |        let vote = Vote::new(&keys, 0, 0, hashes);
  143|       |        let confirm = Message::ConfirmAck(ConfirmAck::new_with_own_vote(vote));
  144|       |
  145|       |        assert_deserializable(&confirm);
  146|       |    }
  147|       |
  148|       |    #[test]
  149|       |    #[should_panic]
  150|       |    fn panics_when_vote_contains_too_many_hashes() {
  151|       |        let keys = PrivateKey::new();
  152|       |        let hashes = vec![BlockHash::from(1); 256];
  153|       |        let vote = Vote::new(&keys, 0, 0, hashes);
  154|       |        Message::ConfirmAck(ConfirmAck::new_with_own_vote(vote));
  155|       |    }
  156|       |
  157|       |    #[test]
  158|       |    fn rebroadcasted_vote() {
  159|       |        let ack = ConfirmAck::new_with_rebroadcasted_vote(Vote::new_test_instance());
  160|       |        assert_eq!(ack.is_rebroadcasted(), true);
  161|       |    }
  162|       |
  163|       |    #[test]
  164|       |    fn extensions_without_rebroadcasted_flag() {
  165|       |        let ack = ConfirmAck::new_with_own_vote(Vote::new_test_instance());
  166|       |        let extensions = ack.header_extensions(0);
  167|       |        assert_eq!(extensions[ConfirmAck::REBROADCASTED_FLAG], false);
  168|       |    }
  169|       |
  170|       |    #[test]
  171|       |    fn extensions_with_rebroadcasted_flag() {
  172|       |        let ack = ConfirmAck::new_with_rebroadcasted_vote(Vote::new_test_instance());
  173|       |        let extensions = ack.header_extensions(0);
  174|       |        assert_eq!(extensions[ConfirmAck::REBROADCASTED_FLAG], true);
  175|       |    }
  176|       |
  177|       |    #[test]
  178|       |    fn deserialize_set_rebroadcasted_flag() {
  179|       |        let mut stream = MemoryStream::new();
  180|       |        let vote = Vote::new_test_instance();
  181|       |        vote.serialize(&mut stream);
  182|       |
  183|       |        let mut extensions = BitArray::<u16>::new(0);
  184|       |        extensions.set(ConfirmAck::REBROADCASTED_FLAG, true);
  185|       |
  186|       |        let ack = ConfirmAck::deserialize(&mut stream, extensions, 0).unwrap();
  187|       |
  188|       |        assert_eq!(ack.is_rebroadcasted(), true);
  189|       |    }
  190|       |
  191|       |    #[test]
  192|       |    fn deserialize_unset_rebroadcasted_flag() {
  193|       |        let mut stream = MemoryStream::new();
  194|       |        let vote = Vote::new_test_instance();
  195|       |        vote.serialize(&mut stream);
  196|       |
  197|       |        let mut extensions = BitArray::<u16>::new(0);
  198|       |        extensions.set(ConfirmAck::REBROADCASTED_FLAG, false);
  199|       |
  200|       |        let ack = ConfirmAck::deserialize(&mut stream, extensions, 0).unwrap();
  201|       |
  202|       |        assert_eq!(ack.is_rebroadcasted(), false);
  203|       |    }
  204|       |}

/home/gustav/code/nano/rsnano-node/messages/src/confirm_req.rs:
    1|       |use super::MessageVariant;
    2|       |use anyhow::Result;
    3|       |use bitvec::prelude::BitArray;
    4|       |use num_traits::FromPrimitive;
    5|       |use rsnano_core::{
    6|       |    serialized_block_size,
    7|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    8|       |    BlockHash, BlockType, Root,
    9|       |};
   10|       |use serde::ser::{SerializeSeq, SerializeStruct};
   11|       |use std::fmt::{Debug, Display, Write};
   12|       |
   13|       |/*
   14|       | * Binary Format:
   15|       | * [message_header] Common message header
   16|       | * [N x (32 bytes (block hash) + 32 bytes (root))] Pairs of (block_hash, root)
   17|       | * - The count is determined by the header's count bits.
   18|       | *
   19|       | * Header extensions:
   20|       | * - [0xf000] Count (for V1 protocol)
   21|       | * - [0x0f00] Block type
   22|       | *   - Not used anymore (V25.1+), but still present and set to `not_a_block = 0x1` for backwards compatibility
   23|       | * - [0xf000 (high), 0x00f0 (low)] Count V2 (for V2 protocol)
   24|       | * - [0x0001] Confirm V2 flag
   25|       | * - [0x0002] Reserved for V3+ versioning
   26|       | */
   27|       |#[derive(Clone, PartialEq, Eq, Debug)]
   28|       |pub struct ConfirmReq {
   29|       |    pub roots_hashes: Vec<(BlockHash, Root)>,
   30|       |}
   31|       |
   32|       |impl ConfirmReq {
   33|       |    pub const HASHES_MAX: usize = 255;
   34|       |
   35|       |    // Header extension bits:
   36|       |    // ----------------------
   37|       |    const COUNT_HIGH_MASK: u16 = 0b1111_0000_0000_0000;
   38|       |    const COUNT_HIGH_SHIFT: u16 = 12;
   39|       |    const BLOCK_TYPE_MASK: u16 = 0b0000_1111_0000_0000;
   40|       |    const BLOCK_TYPE_SHIFT: u16 = 8;
   41|       |    const COUNT_LOW_MASK: u16 = 0b0000_0000_1111_0000;
   42|       |    const COUNT_LOW_SHIFT: u16 = 4;
   43|       |    const V2_FLAG: u16 = 0b0000_0000_0000_0001;
   44|       |    // ----------------------
   45|       |
   46|      0|    pub fn new(roots_hashes: Vec<(BlockHash, Root)>) -> Self {
   47|      0|        if roots_hashes.len() > u8::MAX as usize {
   48|      0|            panic!("roots_hashes too big");
   49|      0|        }
   50|      0|        Self { roots_hashes }
   51|      0|    }
   52|       |
   53|      0|    pub fn new_test_instance() -> Self {
   54|      0|        Self::new(vec![(BlockHash::from(123), Root::from(456))])
   55|      0|    }
   56|       |
   57|      0|    pub fn roots_hashes(&self) -> &Vec<(BlockHash, Root)> {
   58|      0|        &self.roots_hashes
   59|      0|    }
   60|       |
   61|      0|    fn block_type(extensions: BitArray<u16>) -> BlockType {
   62|      0|        let value = (extensions.data & Self::BLOCK_TYPE_MASK) >> Self::BLOCK_TYPE_SHIFT;
   63|      0|        FromPrimitive::from_u16(value).unwrap_or(BlockType::Invalid)
   64|      0|    }
   65|       |
   66|      0|    pub fn count(extensions: BitArray<u16>) -> u8 {
   67|      0|        if Self::has_v2_flag(extensions) {
   68|      0|            Self::v2_count(extensions)
   69|       |        } else {
   70|      0|            Self::v1_count(extensions)
   71|       |        }
   72|      0|    }
   73|       |
   74|      0|    pub fn deserialize(stream: &mut impl Stream, extensions: BitArray<u16>) -> Option<Self> {
   75|      0|        Some(Self::new(Self::deserialize_roots(stream, extensions).ok()?))
   76|      0|    }
   77|       |
   78|      0|    fn deserialize_roots(
   79|      0|        stream: &mut impl Stream,
   80|      0|        extensions: BitArray<u16>,
   81|      0|    ) -> Result<Vec<(BlockHash, Root)>> {
   82|      0|        let count = Self::count(extensions) as usize;
   83|      0|        let mut roots_hashes = Vec::with_capacity(count);
   84|      0|        for _ in 0..count {
   85|      0|            let block_hash = BlockHash::deserialize(stream)?;
   86|      0|            let root = Root::deserialize(stream)?;
   87|      0|            if !block_hash.is_zero() || !root.is_zero() {
   88|      0|                roots_hashes.push((block_hash, root));
   89|      0|            }
   90|       |        }
   91|       |
   92|      0|        if roots_hashes.is_empty() || roots_hashes.len() != count {
   93|      0|            bail!("roots hashes empty or incorrect count");
   94|      0|        }
   95|      0|
   96|      0|        Ok(roots_hashes)
   97|      0|    }
   98|       |
   99|      0|    pub fn roots_string(&self) -> String {
  100|      0|        let mut result = String::new();
  101|      0|        for (hash, root) in &self.roots_hashes {
  102|      0|            write!(&mut result, "{}:{}, ", hash, root).unwrap();
  103|      0|        }
  104|      0|        result
  105|      0|    }
  106|       |
  107|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
  108|      0|        let count = Self::count(extensions);
  109|      0|        let mut result = 0;
  110|      0|        let block_type = Self::block_type(extensions);
  111|      0|        if block_type != BlockType::Invalid && block_type != BlockType::NotABlock {
  112|      0|            result = serialized_block_size(block_type);
  113|      0|        } else if block_type == BlockType::NotABlock {
  114|      0|            result = count as usize * (BlockHash::serialized_size() + Root::serialized_size());
  115|      0|        }
  116|      0|        result
  117|      0|    }
  118|       |
  119|      0|    pub fn count_bits(count: u8) -> BitArray<u16> {
  120|      0|        // We need those shenanigans because we need to keep compatibility with previous protocol versions (<= V25.1)
  121|      0|        //
  122|      0|        // V1:
  123|      0|        // 0b{CCCC}_0000_0000_0000
  124|      0|        //  C: count bits
  125|      0|        //
  126|      0|        // V2:
  127|      0|        // 0b{HHHH}_0000_{LLLL}_000{F}
  128|      0|        //  H: count high bits
  129|      0|        //  L: count low bits
  130|      0|        //  F: v2 flag
  131|      0|        if count < 16 {
  132|       |            // v1. Allows 4 bits
  133|      0|            BitArray::new((count as u16) << Self::COUNT_HIGH_SHIFT)
  134|       |        } else {
  135|       |            // v2. Allows 8 bits
  136|      0|            let mut bits = 0u16;
  137|      0|            let (left, right) = Self::split_count(count);
  138|      0|            bits |= Self::V2_FLAG;
  139|      0|            bits |= (left as u16) << Self::COUNT_HIGH_SHIFT;
  140|      0|            bits |= (right as u16) << Self::COUNT_LOW_SHIFT;
  141|      0|            BitArray::new(bits)
  142|       |        }
  143|      0|    }
  144|       |
  145|       |    /// Splits the count into two 4-bit parts
  146|      0|    fn split_count(count: u8) -> (u8, u8) {
  147|      0|        let left = (count >> 4) & 0xf;
  148|      0|        let right = count & 0xf;
  149|      0|        (left, right)
  150|      0|    }
  151|       |
  152|      0|    fn has_v2_flag(bits: BitArray<u16>) -> bool {
  153|      0|        bits.data & Self::V2_FLAG == Self::V2_FLAG
  154|      0|    }
  155|       |
  156|      0|    fn v1_count(bits: BitArray<u16>) -> u8 {
  157|      0|        ((bits.data & Self::COUNT_HIGH_MASK) >> Self::COUNT_HIGH_SHIFT) as u8
  158|      0|    }
  159|       |
  160|      0|    fn v2_count(bits: BitArray<u16>) -> u8 {
  161|      0|        let left = (bits.data & Self::COUNT_HIGH_MASK) >> Self::COUNT_HIGH_SHIFT;
  162|      0|        let right = (bits.data & Self::COUNT_LOW_MASK) >> Self::COUNT_LOW_SHIFT;
  163|      0|        ((left << 4) | right) as u8
  164|      0|    }
  165|       |}
  166|       |
  167|       |impl Serialize for ConfirmReq {
  168|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  169|      0|        for (hash, root) in &self.roots_hashes {
  170|      0|            writer.write_bytes_safe(hash.as_bytes());
  171|      0|            writer.write_bytes_safe(root.as_bytes());
  172|      0|        }
  173|      0|    }
  174|       |}
  175|       |
  176|       |struct SerializableRootsHashes<'a>(&'a Vec<(BlockHash, Root)>);
  177|       |
  178|       |impl<'a> serde::Serialize for SerializableRootsHashes<'a> {
  179|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
  180|      0|    where
  181|      0|        S: serde::Serializer,
  182|      0|    {
  183|      0|        let mut seq = serializer.serialize_seq(Some(self.0.len()))?;
  184|      0|        for item in self.0.iter() {
  185|      0|            seq.serialize_element(&SerializableRootHash(item))?;
  186|       |        }
  187|      0|        seq.end()
  188|      0|    }
  189|       |}
  190|       |
  191|       |struct SerializableRootHash<'a>(&'a (BlockHash, Root));
  192|       |
  193|       |impl<'a> serde::Serialize for SerializableRootHash<'a> {
  194|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
  195|      0|    where
  196|      0|        S: serde::Serializer,
  197|      0|    {
  198|      0|        let mut seq = serializer.serialize_struct("RootHash", 2)?;
  199|      0|        seq.serialize_field("hash", &self.0 .0)?;
  200|      0|        seq.serialize_field("root", &self.0 .1.encode_hex())?;
  201|      0|        seq.end()
  202|      0|    }
  203|       |}
  204|       |
  205|       |impl serde::Serialize for ConfirmReq {
  206|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
  207|      0|    where
  208|      0|        S: serde::Serializer,
  209|      0|    {
  210|      0|        let mut state = serializer.serialize_struct("ConfirmReq", 6)?;
  211|      0|        state.serialize_field("confirm_type", "roots_hashes")?;
  212|      0|        state.serialize_field("roots_hashes", &SerializableRootsHashes(&self.roots_hashes))?;
  213|      0|        state.end()
  214|      0|    }
  215|       |}
  216|       |
  217|       |impl MessageVariant for ConfirmReq {
  218|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
  219|      0|        let mut extensions = BitArray::default();
  220|      0|        extensions |= Self::count_bits(self.roots_hashes.len() as u8);
  221|      0|        // Set NotABlock (1) block type for hashes + roots request
  222|      0|        // This is needed to keep compatibility with previous protocol versions (<= V25.1)
  223|      0|        extensions |= BitArray::new((BlockType::NotABlock as u16) << Self::BLOCK_TYPE_SHIFT);
  224|      0|        extensions
  225|      0|    }
  226|       |}
  227|       |
  228|       |impl Display for ConfirmReq {
  229|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  230|      0|        for (hash, root) in &self.roots_hashes {
  231|      0|            write!(f, "\n{}:{}", hash, root)?;
  232|       |        }
  233|      0|        Ok(())
  234|      0|    }
  235|       |}
  236|       |
  237|       |#[cfg(test)]
  238|       |mod tests {
  239|       |    use super::*;
  240|       |    use crate::{assert_deserializable, Message};
  241|       |
  242|       |    #[test]
  243|       |    fn serialize() {
  244|       |        let confirm_req = Message::ConfirmReq(ConfirmReq::new_test_instance());
  245|       |        assert_deserializable(&confirm_req);
  246|       |    }
  247|       |
  248|       |    #[test]
  249|       |    fn serialize_many_roots_hashes() {
  250|       |        let roots_hashes = (0..7)
  251|       |            .into_iter()
  252|       |            .map(|i| (BlockHash::from(i), Root::from(i + 1)))
  253|       |            .collect();
  254|       |        let confirm_req = Message::ConfirmReq(ConfirmReq::new(roots_hashes));
  255|       |        assert_deserializable(&confirm_req);
  256|       |    }
  257|       |
  258|       |    #[test]
  259|       |    fn get_block_type_from_header() {
  260|       |        let extensions = Default::default();
  261|       |        assert_eq!(ConfirmReq::block_type(extensions), BlockType::Invalid);
  262|       |
  263|       |        let confirm_req = ConfirmReq::new_test_instance();
  264|       |        let extensions = confirm_req.header_extensions(0);
  265|       |        assert_eq!(ConfirmReq::block_type(extensions), BlockType::NotABlock);
  266|       |    }
  267|       |
  268|       |    #[test]
  269|       |    fn v1_extensions() {
  270|       |        let confirm_req = ConfirmReq::new(vec![(BlockHash::from(1), Root::from(2)); 15]);
  271|       |        let extensions = confirm_req.header_extensions(0);
  272|       |        // count=15 plus NotABlock flag
  273|       |        let expected = 0b_1111_0001_0000_0000;
  274|       |        assert_eq!(extensions.data, expected);
  275|       |    }
  276|       |
  277|       |    #[test]
  278|       |    fn use_v2_with_16_roots() {
  279|       |        let confirm_req = ConfirmReq::new(vec![(BlockHash::from(1), Root::from(2)); 16]);
  280|       |        let extensions = confirm_req.header_extensions(0);
  281|       |        // count=16 plus NotABlock flag plus v2 flag
  282|       |        let expected = 0b_0001_0001_0000_0001;
  283|       |        assert_eq!(extensions.data, expected);
  284|       |    }
  285|       |
  286|       |    #[test]
  287|       |    fn split_count() {
  288|       |        assert_eq!(ConfirmReq::split_count(0b0), (0b0, 0b0));
  289|       |        assert_eq!(ConfirmReq::split_count(0b1), (0b0, 0b1));
  290|       |        assert_eq!(ConfirmReq::split_count(0b11), (0b0, 0b11));
  291|       |        assert_eq!(ConfirmReq::split_count(0b111), (0b0, 0b111));
  292|       |        assert_eq!(ConfirmReq::split_count(0b1111), (0b0, 0b1111));
  293|       |        assert_eq!(ConfirmReq::split_count(0b11111), (0b1, 0b1111));
  294|       |        assert_eq!(ConfirmReq::split_count(0b111111), (0b11, 0b1111));
  295|       |        assert_eq!(ConfirmReq::split_count(0b10101010), (0b1010, 0b1010));
  296|       |    }
  297|       |
  298|       |    #[test]
  299|       |    fn extract_v1_count() {
  300|       |        assert_eq!(ConfirmReq::count(BitArray::new(0)), 0);
  301|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b0001_0000_0000_0000)), 1);
  302|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b1010_0000_0000_0000)), 10);
  303|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b1111_0000_0000_0000)), 15);
  304|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b1111_0000_1111_0000)), 15);
  305|       |    }
  306|       |
  307|       |    #[test]
  308|       |    fn extract_v2_count() {
  309|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b0000_0000_0000_0001)), 0);
  310|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b0000_0000_1010_0001)), 10);
  311|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b0000_0000_1111_0001)), 15);
  312|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b0001_0000_0000_0001)), 16);
  313|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b1111_0000_0001_0001)), 241);
  314|       |        assert_eq!(ConfirmReq::count(BitArray::new(0b1111_0000_1111_0001)), 255);
  315|       |    }
  316|       |
  317|       |    #[test]
  318|       |    fn v2_extensions() {
  319|       |        let confirm_req = ConfirmReq::new(vec![(BlockHash::from(1), Root::from(2)); 0b10001010]);
  320|       |        let extensions = confirm_req.header_extensions(0);
  321|       |        let expected = 0b1000_0001_1010_0001;
  322|       |        assert_eq!(extensions.data, expected);
  323|       |    }
  324|       |
  325|       |    #[test]
  326|       |    fn serialize_v2() {
  327|       |        let confirm_req =
  328|       |            Message::ConfirmReq(ConfirmReq::new(vec![
  329|       |                (BlockHash::from(1), Root::from(2));
  330|       |                255
  331|       |            ]));
  332|       |        assert_deserializable(&confirm_req);
  333|       |    }
  334|       |
  335|       |    #[test]
  336|       |    #[should_panic]
  337|       |    fn panics_when_roots_hashes_are_too_big() {
  338|       |        ConfirmReq::new(vec![(BlockHash::from(1), Root::from(2)); 256]);
  339|       |    }
  340|       |}

/home/gustav/code/nano/rsnano-node/messages/src/frontier_req.rs:
    1|       |use super::MessageVariant;
    2|       |use bitvec::prelude::BitArray;
    3|       |use rsnano_core::{
    4|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, Serialize, Stream},
    5|       |    Account,
    6|       |};
    7|       |use serde_derive::Serialize;
    8|       |use std::{fmt::Display, mem::size_of};
    9|       |
   10|       |#[derive(Clone, Debug, PartialEq, Eq, Serialize)]
   11|       |pub struct FrontierReq {
   12|       |    pub start: Account,
   13|       |    pub age: u32,
   14|       |    pub count: u32,
   15|       |    pub only_confirmed: bool,
   16|       |}
   17|       |
   18|       |impl FrontierReq {
   19|      0|    pub fn new_test_instance() -> Self {
   20|      0|        Self {
   21|      0|            start: 1.into(),
   22|      0|            age: 2,
   23|      0|            count: 3,
   24|      0|            only_confirmed: false,
   25|      0|        }
   26|      0|    }
   27|       |
   28|      0|    pub fn serialized_size() -> usize {
   29|      0|        Account::serialized_size()
   30|      0|        + size_of::<u32>() // age
   31|      0|        + size_of::<u32>() //count
   32|      0|    }
   33|       |
   34|       |    pub const ONLY_CONFIRMED: usize = 1;
   35|       |
   36|      0|    pub fn deserialize(stream: &mut impl Stream, extensions: BitArray<u16>) -> Option<Self> {
   37|      0|        let start = Account::deserialize(stream).ok()?;
   38|      0|        let mut buffer = [0u8; 4];
   39|      0|        stream.read_bytes(&mut buffer, 4).ok()?;
   40|      0|        let age = u32::from_le_bytes(buffer);
   41|      0|        stream.read_bytes(&mut buffer, 4).ok()?;
   42|      0|        let count = u32::from_le_bytes(buffer);
   43|      0|        let only_confirmed = extensions[FrontierReq::ONLY_CONFIRMED];
   44|      0|
   45|      0|        Some(FrontierReq {
   46|      0|            start,
   47|      0|            age,
   48|      0|            count,
   49|      0|            only_confirmed,
   50|      0|        })
   51|      0|    }
   52|       |}
   53|       |
   54|       |impl Serialize for FrontierReq {
   55|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   56|      0|        self.start.serialize(writer);
   57|      0|        writer.write_bytes_safe(&self.age.to_le_bytes());
   58|      0|        writer.write_bytes_safe(&self.count.to_le_bytes());
   59|      0|    }
   60|       |}
   61|       |
   62|       |impl MessageVariant for FrontierReq {
   63|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
   64|      0|        let mut extensions = BitArray::default();
   65|      0|        extensions.set(Self::ONLY_CONFIRMED, self.only_confirmed);
   66|      0|        extensions
   67|      0|    }
   68|       |}
   69|       |
   70|       |impl Display for FrontierReq {
   71|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   72|      0|        write!(
   73|      0|            f,
   74|      0|            "\nstart={} maxage={} count={}",
   75|      0|            self.start, self.age, self.count
   76|      0|        )
   77|      0|    }
   78|       |}
   79|       |
   80|       |#[cfg(test)]
   81|       |mod tests {
   82|       |    use super::*;
   83|       |    use crate::{assert_deserializable, Message};
   84|       |
   85|       |    #[test]
   86|       |    fn serialize() {
   87|       |        let request = Message::FrontierReq(FrontierReq::new_test_instance());
   88|       |        assert_deserializable(&request);
   89|       |    }
   90|       |}

/home/gustav/code/nano/rsnano-node/messages/src/keepalive.rs:
    1|       |use rsnano_core::utils::{BufferWriter, Serialize, Stream};
    2|       |use serde_derive::Serialize;
    3|       |use std::{
    4|       |    fmt::Display,
    5|       |    net::{Ipv6Addr, SocketAddrV6},
    6|       |};
    7|       |
    8|       |use super::MessageVariant;
    9|       |
   10|       |#[derive(Clone, PartialEq, Eq, Debug, Serialize)]
   11|       |#[serde(rename_all = "snake_case")]
   12|       |pub struct Keepalive {
   13|       |    pub peers: [SocketAddrV6; 8],
   14|       |}
   15|       |
   16|       |impl Keepalive {
   17|      0|    pub const fn new_test_instance() -> Self {
   18|      0|        Self {
   19|      0|            peers: [
   20|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 4), 1111, 0, 0),
   21|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 5), 2222, 0, 0),
   22|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 6), 3333, 0, 0),
   23|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 7), 4444, 0, 0),
   24|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 8), 5555, 0, 0),
   25|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 9), 6666, 0, 0),
   26|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 0x10), 7777, 0, 0),
   27|      0|                SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 1, 2, 3, 0x11), 8888, 0, 0),
   28|      0|            ],
   29|      0|        }
   30|      0|    }
   31|      0|    pub fn deserialize(stream: &mut impl Stream) -> Option<Self> {
   32|      0|        let mut peers = empty_peers();
   33|       |
   34|      0|        for i in 0..8 {
   35|      0|            let mut addr_buffer = [0u8; 16];
   36|      0|            let mut port_buffer = [0u8; 2];
   37|      0|            stream.read_bytes(&mut addr_buffer, 16).ok()?;
   38|      0|            stream.read_bytes(&mut port_buffer, 2).ok()?;
   39|       |
   40|      0|            let port = u16::from_le_bytes(port_buffer);
   41|      0|            let ip_addr = Ipv6Addr::from(addr_buffer);
   42|      0|
   43|      0|            peers[i] = SocketAddrV6::new(ip_addr, port, 0, 0);
   44|       |        }
   45|       |
   46|      0|        Some(Self { peers })
   47|      0|    }
   48|       |
   49|      0|    pub fn serialized_size() -> usize {
   50|      0|        8 * (16 + 2)
   51|      0|    }
   52|       |}
   53|       |
   54|       |impl Default for Keepalive {
   55|      0|    fn default() -> Self {
   56|      0|        Self {
   57|      0|            peers: empty_peers(),
   58|      0|        }
   59|      0|    }
   60|       |}
   61|       |
   62|       |impl MessageVariant for Keepalive {}
   63|       |
   64|       |impl Serialize for Keepalive {
   65|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
   66|      0|        for peer in &self.peers {
   67|      0|            let ip_bytes = peer.ip().octets();
   68|      0|            stream.write_bytes_safe(&ip_bytes);
   69|      0|
   70|      0|            let port_bytes = peer.port().to_le_bytes();
   71|      0|            stream.write_bytes_safe(&port_bytes);
   72|      0|        }
   73|      0|    }
   74|       |}
   75|       |
   76|       |impl Display for Keepalive {
   77|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   78|      0|        for peer in &self.peers {
   79|      0|            write!(f, "\n{}", peer)?;
   80|       |        }
   81|      0|        Ok(())
   82|      0|    }
   83|       |}
   84|       |
   85|      0|fn empty_peers() -> [SocketAddrV6; 8] {
   86|      0|    [SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0); 8]
   87|      0|}
   88|       |
   89|       |#[cfg(test)]
   90|       |mod tests {
   91|       |    use std::str::FromStr;
   92|       |
   93|       |    use super::*;
   94|       |    use crate::{assert_deserializable, Message};
   95|       |
   96|       |    #[test]
   97|       |    fn serialize_no_peers() {
   98|       |        let request = Message::Keepalive(Keepalive::default());
   99|       |        assert_deserializable(&request);
  100|       |    }
  101|       |
  102|       |    #[test]
  103|       |    fn serialize_peers() {
  104|       |        let mut keepalive = Keepalive::default();
  105|       |        keepalive.peers[0] = SocketAddrV6::new(Ipv6Addr::LOCALHOST, 10000, 0, 0);
  106|       |        let request = Message::Keepalive(keepalive);
  107|       |        assert_deserializable(&request);
  108|       |    }
  109|       |
  110|       |    #[test]
  111|       |    fn keepalive_with_no_peers_to_string() {
  112|       |        let keepalive = Message::Keepalive(Default::default());
  113|       |        let expected = "\n[::]:0\n[::]:0\n[::]:0\n[::]:0\n[::]:0\n[::]:0\n[::]:0\n[::]:0";
  114|       |        assert_eq!(keepalive.to_string(), expected);
  115|       |    }
  116|       |
  117|       |    #[test]
  118|       |    fn keepalive_string() {
  119|       |        let mut keepalive = Keepalive::default();
  120|       |        keepalive.peers[1] = SocketAddrV6::new(Ipv6Addr::LOCALHOST, 45, 0, 0);
  121|       |        keepalive.peers[2] = SocketAddrV6::new(
  122|       |            Ipv6Addr::from_str("2001:db8:85a3:8d3:1319:8a2e:370:7348").unwrap(),
  123|       |            0,
  124|       |            0,
  125|       |            0,
  126|       |        );
  127|       |        keepalive.peers[3] = SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 65535, 0, 0);
  128|       |        keepalive.peers[4] =
  129|       |            SocketAddrV6::new(Ipv6Addr::from_str("::ffff:1.2.3.4").unwrap(), 1234, 0, 0);
  130|       |        keepalive.peers[5] =
  131|       |            SocketAddrV6::new(Ipv6Addr::from_str("::ffff:1.2.3.4").unwrap(), 1234, 0, 0);
  132|       |        keepalive.peers[6] =
  133|       |            SocketAddrV6::new(Ipv6Addr::from_str("::ffff:1.2.3.4").unwrap(), 1234, 0, 0);
  134|       |        keepalive.peers[7] =
  135|       |            SocketAddrV6::new(Ipv6Addr::from_str("::ffff:1.2.3.4").unwrap(), 1234, 0, 0);
  136|       |
  137|       |        let mut expected = String::new();
  138|       |        expected.push_str("\n[::]:0");
  139|       |        expected.push_str("\n[::1]:45");
  140|       |        expected.push_str("\n[2001:db8:85a3:8d3:1319:8a2e:370:7348]:0");
  141|       |        expected.push_str("\n[::]:65535");
  142|       |        expected.push_str("\n[::ffff:1.2.3.4]:1234");
  143|       |        expected.push_str("\n[::ffff:1.2.3.4]:1234");
  144|       |        expected.push_str("\n[::ffff:1.2.3.4]:1234");
  145|       |        expected.push_str("\n[::ffff:1.2.3.4]:1234");
  146|       |
  147|       |        assert_eq!(keepalive.to_string(), expected);
  148|       |    }
  149|       |}

/home/gustav/code/nano/rsnano-node/messages/src/lib.rs:
    1|       |#[macro_use]
    2|       |extern crate num_derive;
    3|       |
    4|       |#[macro_use]
    5|       |extern crate anyhow;
    6|       |
    7|       |#[macro_use]
    8|       |extern crate static_assertions;
    9|       |
   10|       |mod message;
   11|       |mod message_deserializer;
   12|       |mod network_filter;
   13|       |
   14|       |pub use message::*;
   15|       |pub use message_deserializer::*;
   16|       |pub use network_filter::*;
   17|       |
   18|       |mod message_serializer;
   19|       |pub use message_serializer::*;
   20|       |
   21|       |mod message_header;
   22|       |pub use message_header::*;
   23|       |
   24|       |mod node_id_handshake;
   25|       |pub use node_id_handshake::*;
   26|       |
   27|       |mod keepalive;
   28|       |pub use keepalive::*;
   29|       |
   30|       |mod publish;
   31|       |pub use publish::*;
   32|       |
   33|       |mod confirm_req;
   34|       |pub use confirm_req::*;
   35|       |
   36|       |mod confirm_ack;
   37|       |pub use confirm_ack::*;
   38|       |
   39|       |mod frontier_req;
   40|       |pub use frontier_req::*;
   41|       |
   42|       |mod bulk_pull;
   43|       |pub use bulk_pull::*;
   44|       |
   45|       |mod bulk_pull_account;
   46|       |pub use bulk_pull_account::*;
   47|       |
   48|       |mod telemetry_ack;
   49|       |use rsnano_core::utils::BufferReader;
   50|       |pub use telemetry_ack::*;
   51|       |
   52|       |mod asc_pull_req;
   53|       |pub use asc_pull_req::*;
   54|       |
   55|       |mod asc_pull_ack;
   56|       |pub use asc_pull_ack::*;
   57|       |
   58|       |pub trait MessageVisitor {
   59|       |    fn received(&mut self, message: &Message);
   60|       |}
   61|       |
   62|       |pub type Cookie = [u8; 32];
   63|       |
   64|       |pub fn deserialize_message(buffer: &[u8]) -> anyhow::Result<(MessageHeader, Message)> {
   65|       |    let (header_bytes, payload_bytes) = buffer.split_at(MessageHeader::SERIALIZED_SIZE);
   66|       |    let header = MessageHeader::deserialize_slice(header_bytes)?;
   67|       |    let message = Message::deserialize(payload_bytes, &header, 0)
   68|      0|        .ok_or_else(|| anyhow!("invalid message payload"))?;
   69|       |    Ok((header, message))
   70|       |}
   71|       |
   72|       |#[cfg(test)]
   73|       |pub(crate) fn assert_deserializable(original: &Message) {
   74|       |    let mut serializer = MessageSerializer::default();
   75|       |    let serialized = serializer.serialize(original);
   76|       |    let mut buffer = BufferReader::new(serialized);
   77|       |    let header = MessageHeader::deserialize(&mut buffer).unwrap();
   78|       |    assert_eq!(
   79|       |        header.payload_length(),
   80|       |        serialized.len() - MessageHeader::SERIALIZED_SIZE,
   81|       |        "serialized message has incorrect payload length"
   82|       |    );
   83|       |    let message_out = Message::deserialize(buffer.remaining(), &header, 0).unwrap();
   84|       |    assert_eq!(message_out, *original);
   85|       |}

/home/gustav/code/nano/rsnano-node/messages/src/message.rs:
    1|       |use super::*;
    2|       |use bitvec::prelude::BitArray;
    3|       |use rsnano_core::utils::{BufferReader, BufferWriter, Serialize};
    4|       |use std::fmt::Display;
    5|       |
    6|       |#[derive(Clone, Debug, PartialEq, Eq)]
    7|       |pub enum Message {
    8|       |    Keepalive(Keepalive),
    9|       |    Publish(Publish),
   10|       |    AscPullAck(AscPullAck),
   11|       |    AscPullReq(AscPullReq),
   12|       |    BulkPull(BulkPull),
   13|       |    BulkPullAccount(BulkPullAccount),
   14|       |    BulkPush,
   15|       |    ConfirmAck(ConfirmAck),
   16|       |    ConfirmReq(ConfirmReq),
   17|       |    FrontierReq(FrontierReq),
   18|       |    NodeIdHandshake(NodeIdHandshake),
   19|       |    TelemetryAck(TelemetryAck),
   20|       |    TelemetryReq,
   21|       |}
   22|       |
   23|       |pub trait MessageVariant: Display + Serialize {
   24|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
   25|      0|        Default::default()
   26|      0|    }
   27|       |}
   28|       |
   29|       |#[derive(Clone, PartialEq, Eq, Debug)]
   30|       |pub enum ParseMessageError {
   31|       |    Other(String),
   32|       |    InsufficientWork,
   33|       |    InvalidHeader,
   34|       |    InvalidMessageType,
   35|       |    InvalidMessage(MessageType),
   36|       |    InvalidNetwork,
   37|       |    OutdatedVersion,
   38|       |    DuplicatePublishMessage,
   39|       |    DuplicateConfirmAckMessage,
   40|       |    MessageSizeTooBig,
   41|       |    Stopped,
   42|       |}
   43|       |
   44|       |#[derive(Clone, PartialEq, Eq, Debug)]
   45|       |pub struct DeserializedMessage {
   46|       |    pub message: Message,
   47|       |    pub protocol: ProtocolInfo,
   48|       |}
   49|       |
   50|       |impl DeserializedMessage {
   51|      0|    pub fn new(message: Message, protocol: ProtocolInfo) -> Self {
   52|      0|        Self { message, protocol }
   53|      0|    }
   54|       |}
   55|       |
   56|       |impl Message {
   57|       |    pub const MAX_MESSAGE_SIZE: usize = 1024 * 65;
   58|       |
   59|      1|    pub fn message_type(&self) -> MessageType {
   60|      1|        match &self {
   61|      0|            Message::Keepalive(_) => MessageType::Keepalive,
   62|      0|            Message::Publish(_) => MessageType::Publish,
   63|      0|            Message::AscPullAck(_) => MessageType::AscPullAck,
   64|      0|            Message::AscPullReq(_) => MessageType::AscPullReq,
   65|      0|            Message::BulkPull(_) => MessageType::BulkPull,
   66|      0|            Message::BulkPullAccount(_) => MessageType::BulkPullAccount,
   67|      1|            Message::BulkPush => MessageType::BulkPush,
   68|      0|            Message::ConfirmAck(_) => MessageType::ConfirmAck,
   69|      0|            Message::ConfirmReq(_) => MessageType::ConfirmReq,
   70|      0|            Message::FrontierReq(_) => MessageType::FrontierReq,
   71|      0|            Message::NodeIdHandshake(_) => MessageType::NodeIdHandshake,
   72|      0|            Message::TelemetryAck(_) => MessageType::TelemetryAck,
   73|      0|            Message::TelemetryReq => MessageType::TelemetryReq,
   74|       |        }
   75|      1|    }
   76|       |
   77|      0|    pub fn as_message_variant(&self) -> Option<&dyn MessageVariant> {
   78|      0|        match &self {
   79|      0|            Message::Keepalive(x) => Some(x),
   80|      0|            Message::Publish(x) => Some(x),
   81|      0|            Message::AscPullAck(x) => Some(x),
   82|      0|            Message::AscPullReq(x) => Some(x),
   83|      0|            Message::BulkPull(x) => Some(x),
   84|      0|            Message::BulkPullAccount(x) => Some(x),
   85|      0|            Message::ConfirmAck(x) => Some(x),
   86|      0|            Message::ConfirmReq(x) => Some(x),
   87|      0|            Message::FrontierReq(x) => Some(x),
   88|      0|            Message::NodeIdHandshake(x) => Some(x),
   89|      0|            Message::TelemetryAck(x) => Some(x),
   90|      0|            _ => None,
   91|       |        }
   92|      0|    }
   93|       |
   94|      0|    pub fn serialize(&self, stream: &mut dyn BufferWriter) {
   95|      0|        if let Some(variant) = self.as_message_variant() {
   96|      0|            variant.serialize(stream);
   97|      0|        }
   98|      0|    }
   99|       |
  100|      0|    pub fn header_extensions(&self, payload_len: u16) -> BitArray<u16> {
  101|      0|        match self.as_message_variant() {
  102|      0|            Some(variant) => variant.header_extensions(payload_len),
  103|      0|            None => Default::default(),
  104|       |        }
  105|      0|    }
  106|       |
  107|      0|    pub fn deserialize(payload_bytes: &[u8], header: &MessageHeader, digest: u128) -> Option<Self> {
  108|      0|        let mut stream = BufferReader::new(payload_bytes);
  109|      0|        let msg = match header.message_type {
  110|      0|            MessageType::Keepalive => Message::Keepalive(Keepalive::deserialize(&mut stream)?),
  111|      0|            MessageType::Publish => Message::Publish(Publish::deserialize(
  112|      0|                &mut stream,
  113|      0|                header.extensions,
  114|      0|                digest,
  115|      0|            )?),
  116|      0|            MessageType::AscPullAck => Message::AscPullAck(AscPullAck::deserialize(&mut stream)?),
  117|      0|            MessageType::AscPullReq => Message::AscPullReq(AscPullReq::deserialize(&mut stream)?),
  118|       |            MessageType::BulkPull => {
  119|      0|                Message::BulkPull(BulkPull::deserialize(&mut stream, header.extensions)?)
  120|       |            }
  121|       |            MessageType::BulkPullAccount => {
  122|      0|                Message::BulkPullAccount(BulkPullAccount::deserialize(&mut stream)?)
  123|       |            }
  124|      0|            MessageType::BulkPush => Message::BulkPush,
  125|      0|            MessageType::ConfirmAck => Message::ConfirmAck(ConfirmAck::deserialize(
  126|      0|                &mut stream,
  127|      0|                header.extensions,
  128|      0|                digest,
  129|      0|            )?),
  130|       |            MessageType::ConfirmReq => {
  131|      0|                Message::ConfirmReq(ConfirmReq::deserialize(&mut stream, header.extensions)?)
  132|       |            }
  133|       |            MessageType::FrontierReq => {
  134|      0|                Message::FrontierReq(FrontierReq::deserialize(&mut stream, header.extensions)?)
  135|       |            }
  136|      0|            MessageType::NodeIdHandshake => Message::NodeIdHandshake(NodeIdHandshake::deserialize(
  137|      0|                &mut stream,
  138|      0|                header.extensions,
  139|      0|            )?),
  140|       |            MessageType::TelemetryAck => {
  141|      0|                Message::TelemetryAck(TelemetryAck::deserialize(&mut stream, header.extensions)?)
  142|       |            }
  143|      0|            MessageType::TelemetryReq => Message::TelemetryReq,
  144|      0|            MessageType::Invalid | MessageType::NotAType => return None,
  145|       |        };
  146|       |
  147|      0|        Some(msg)
  148|      0|    }
  149|       |}
  150|       |
  151|       |impl Display for Message {
  152|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  153|      0|        match self.as_message_variant() {
  154|      0|            Some(variant) => variant.fmt(f),
  155|      0|            None => Ok(()),
  156|       |        }
  157|      0|    }
  158|       |}
  159|       |
  160|      0|pub fn validate_header(
  161|      0|    header: &MessageHeader,
  162|      0|    expected_protocol: &ProtocolInfo,
  163|      0|) -> Result<(), ParseMessageError> {
  164|      0|    if header.protocol.network != expected_protocol.network {
  165|      0|        Err(ParseMessageError::InvalidNetwork)
  166|      0|    } else if header.protocol.version_using < expected_protocol.version_min {
  167|      0|        Err(ParseMessageError::OutdatedVersion)
  168|      0|    } else if !header.is_valid_message_type() {
  169|      0|        Err(ParseMessageError::InvalidHeader)
  170|      0|    } else if header.payload_length() > Message::MAX_MESSAGE_SIZE {
  171|      0|        Err(ParseMessageError::MessageSizeTooBig)
  172|       |    } else {
  173|      0|        Ok(())
  174|       |    }
  175|      0|}
  176|       |
  177|       |#[cfg(test)]
  178|       |mod tests {
  179|       |    use super::*;
  180|       |    use rsnano_core::{TestBlockBuilder, Vote};
  181|       |
  182|       |    #[test]
  183|       |    fn exact_confirm_ack() {
  184|       |        let message = Message::ConfirmAck(ConfirmAck::new_with_own_vote(Vote::new_test_instance()));
  185|       |        assert_deserializable(&message);
  186|       |    }
  187|       |
  188|       |    #[test]
  189|       |    fn exact_confirm_req() {
  190|       |        let message = Message::ConfirmReq(ConfirmReq::new_test_instance());
  191|       |        assert_deserializable(&message);
  192|       |    }
  193|       |
  194|       |    #[test]
  195|       |    fn exact_publish() {
  196|       |        let block = TestBlockBuilder::legacy_send().build();
  197|       |        let message = Message::Publish(Publish::new_from_originator(block));
  198|       |        assert_deserializable(&message);
  199|       |    }
  200|       |
  201|       |    #[test]
  202|       |    fn exact_keepalive() {
  203|       |        assert_deserializable(&Message::Keepalive(Keepalive::default()));
  204|       |    }
  205|       |
  206|       |    #[test]
  207|       |    fn exact_frontier_req() {
  208|       |        let message = Message::FrontierReq(FrontierReq::new_test_instance());
  209|       |        assert_deserializable(&message);
  210|       |    }
  211|       |
  212|       |    #[test]
  213|       |    fn exact_telemetry_req() {
  214|       |        assert_deserializable(&Message::TelemetryReq);
  215|       |    }
  216|       |
  217|       |    #[test]
  218|       |    fn exact_telemetry_ack() {
  219|       |        let mut data = TelemetryData::default();
  220|       |        data.unknown_data.push(0xFF);
  221|       |        assert_deserializable(&Message::TelemetryAck(TelemetryAck(Some(data))));
  222|       |    }
  223|       |
  224|       |    #[test]
  225|       |    fn exact_bulk_pull() {
  226|       |        let message = Message::BulkPull(BulkPull::new_test_instance());
  227|       |        assert_deserializable(&message);
  228|       |    }
  229|       |
  230|       |    #[test]
  231|       |    fn exact_bulk_pull_account() {
  232|       |        let message = Message::BulkPullAccount(BulkPullAccount::new_test_instance());
  233|       |        assert_deserializable(&message);
  234|       |    }
  235|       |
  236|       |    #[test]
  237|       |    fn exact_bulk_push() {
  238|       |        assert_deserializable(&Message::BulkPush);
  239|       |    }
  240|       |
  241|       |    #[test]
  242|       |    fn exact_node_id_handshake() {
  243|       |        let message = Message::NodeIdHandshake(NodeIdHandshake {
  244|       |            query: Some(NodeIdHandshakeQuery { cookie: [1; 32] }),
  245|       |            response: None,
  246|       |            is_v2: true,
  247|       |        });
  248|       |        assert_deserializable(&message);
  249|       |    }
  250|       |
  251|       |    #[test]
  252|       |    fn exact_asc_pull_req() {
  253|       |        let message = Message::AscPullReq(AscPullReq {
  254|       |            req_type: AscPullReqType::AccountInfo(AccountInfoReqPayload::new_test_instance()),
  255|       |            id: 7,
  256|       |        });
  257|       |        assert_deserializable(&message);
  258|       |    }
  259|       |
  260|       |    #[test]
  261|       |    fn exact_asc_pull_ack() {
  262|       |        let message = Message::AscPullAck(AscPullAck {
  263|       |            id: 7,
  264|       |            pull_type: AscPullAckType::AccountInfo(AccountInfoAckPayload::new_test_instance()),
  265|       |        });
  266|       |        assert_deserializable(&message);
  267|       |    }
  268|       |}

/home/gustav/code/nano/rsnano-node/messages/src/message_deserializer.rs:
    1|       |use crate::{
    2|       |    validate_header, DeserializedMessage, Message, MessageHeader, MessageType, NetworkFilter,
    3|       |    ParseMessageError, ProtocolInfo,
    4|       |};
    5|       |use rsnano_core::work::WorkThresholds;
    6|       |use std::{collections::VecDeque, io::Read, sync::Arc};
    7|       |
    8|       |pub struct MessageDeserializer {
    9|       |    buffer: VecDeque<u8>,
   10|       |    current_header: Option<MessageHeader>,
   11|       |    network_filter: Arc<NetworkFilter>,
   12|       |    work_thresholds: WorkThresholds,
   13|       |    protocol: ProtocolInfo,
   14|       |}
   15|       |
   16|       |impl MessageDeserializer {
   17|      0|    pub fn new(
   18|      0|        protocol: ProtocolInfo,
   19|      0|        network_filter: Arc<NetworkFilter>,
   20|      0|        work_thresholds: WorkThresholds,
   21|      0|    ) -> Self {
   22|      0|        Self {
   23|      0|            buffer: VecDeque::with_capacity(Message::MAX_MESSAGE_SIZE),
   24|      0|            current_header: None,
   25|      0|            network_filter,
   26|      0|            work_thresholds,
   27|      0|            protocol,
   28|      0|        }
   29|      0|    }
   30|       |
   31|      0|    pub fn push(&mut self, data: &[u8]) {
   32|      0|        self.buffer.extend(data);
   33|      0|    }
   34|       |
   35|      0|    pub fn try_deserialize(&mut self) -> Option<Result<DeserializedMessage, ParseMessageError>> {
   36|      0|        if let Some(header) = self.current_header.clone() {
   37|       |            // The header was already deserialized. Only the payload has to be read:
   38|      0|            self.try_deserialize_payload_for(header)
   39|       |        } else {
   40|      0|            self.deserialize_header_and_payload()
   41|       |        }
   42|      0|    }
   43|       |
   44|      0|    fn deserialize_header_and_payload(
   45|      0|        &mut self,
   46|      0|    ) -> Option<Result<DeserializedMessage, ParseMessageError>> {
   47|      0|        let header_bytes = self.read_header_bytes()?;
   48|       |
   49|      0|        let Ok(header) = MessageHeader::deserialize_slice(&header_bytes) else {
   50|      0|            return Some(Err(ParseMessageError::InvalidHeader));
   51|       |        };
   52|       |
   53|      0|        if let Err(e) = validate_header(&header, &self.protocol) {
   54|      0|            return Some(Err(e));
   55|      0|        }
   56|      0|
   57|      0|        self.current_header = Some(header.clone());
   58|      0|        self.try_deserialize_payload_for(header)
   59|      0|    }
   60|       |
   61|      0|    fn read_header_bytes(&mut self) -> Option<[u8; MessageHeader::SERIALIZED_SIZE]> {
   62|      0|        if self.buffer.len() < MessageHeader::SERIALIZED_SIZE {
   63|      0|            return None;
   64|      0|        }
   65|      0|        let mut header_bytes = [0; MessageHeader::SERIALIZED_SIZE];
   66|      0|
   67|      0|        match self.buffer.read_exact(&mut header_bytes) {
   68|      0|            Ok(_) => {}
   69|      0|            Err(_) => unreachable!("the buffer is big enough"),
   70|       |        }
   71|      0|        Some(header_bytes)
   72|      0|    }
   73|       |
   74|      0|    fn try_deserialize_payload_for(
   75|      0|        &mut self,
   76|      0|        header: MessageHeader,
   77|      0|    ) -> Option<Result<DeserializedMessage, ParseMessageError>> {
   78|      0|        if header.payload_length() > 0 && self.buffer.len() < header.payload_length() {
   79|       |            // We have to wait until more data is received
   80|      0|            return None;
   81|      0|        }
   82|      0|        self.current_header = None;
   83|      0|        Some(self.deserialize_payload_for(header))
   84|      0|    }
   85|       |
   86|      0|    fn deserialize_payload_for(
   87|      0|        &mut self,
   88|      0|        header: MessageHeader,
   89|      0|    ) -> Result<DeserializedMessage, ParseMessageError> {
   90|      0|        // TODO: don't copy buffer
   91|      0|        let payload_buffer: Vec<u8> = self.buffer.drain(..header.payload_length()).collect();
   92|       |
   93|      0|        let digest = self.filter_duplicate_messages(header.message_type, &payload_buffer)?;
   94|       |
   95|      0|        let Some(message) = Message::deserialize(&payload_buffer, &header, digest) else {
   96|      0|            return Err(ParseMessageError::InvalidMessage(header.message_type));
   97|       |        };
   98|       |
   99|      0|        self.validate_work(&message)?;
  100|      0|        Ok(DeserializedMessage::new(message, header.protocol))
  101|      0|    }
  102|       |
  103|      0|    fn validate_work(&self, message: &Message) -> Result<(), ParseMessageError> {
  104|      0|        let block = match message {
  105|      0|            Message::Publish(msg) => Some(&msg.block),
  106|      0|            _ => None,
  107|       |        };
  108|       |
  109|      0|        if let Some(block) = block {
  110|       |            // work is checked multiple times - here and in the block processor and maybe
  111|       |            // even more... TODO eliminate duplicate work checks
  112|      0|            if !self.work_thresholds.validate_entry_block(block) {
  113|      0|                return Err(ParseMessageError::InsufficientWork);
  114|      0|            }
  115|      0|        }
  116|       |
  117|      0|        Ok(())
  118|      0|    }
  119|       |
  120|       |    /// Early filtering to not waste time deserializing duplicate blocks
  121|      0|    fn filter_duplicate_messages(
  122|      0|        &self,
  123|      0|        message_type: MessageType,
  124|      0|        payload_bytes: &[u8],
  125|      0|    ) -> Result<u128, ParseMessageError> {
  126|      0|        if matches!(message_type, MessageType::Publish | MessageType::ConfirmAck) {
  127|      0|            let (digest, existed) = self.network_filter.apply(payload_bytes);
  128|      0|            if existed {
  129|      0|                if message_type == MessageType::ConfirmAck {
  130|      0|                    Err(ParseMessageError::DuplicateConfirmAckMessage)
  131|       |                } else {
  132|      0|                    Err(ParseMessageError::DuplicatePublishMessage)
  133|       |                }
  134|       |            } else {
  135|      0|                Ok(digest)
  136|       |            }
  137|       |        } else {
  138|      0|            Ok(0)
  139|       |        }
  140|      0|    }
  141|       |}
  142|       |
  143|       |#[cfg(test)]
  144|       |mod tests {
  145|       |    use super::*;
  146|       |    use crate::{AscPullAck, Keepalive, MessageSerializer};
  147|       |
  148|       |    mod happy_path {
  149|       |        use super::*;
  150|       |
  151|       |        #[test]
  152|       |        fn empty() {
  153|       |            let mut deserializer = create_deserializer();
  154|       |            assert!(deserializer.try_deserialize().is_none());
  155|       |        }
  156|       |
  157|       |        #[test]
  158|       |        fn deserialize_message_without_payload() {
  159|       |            let mut deserializer = create_deserializer();
  160|       |            deserializer.push(&message_bytes(&Message::TelemetryReq));
  161|       |
  162|       |            assert_eq!(
  163|       |                deserializer.try_deserialize(),
  164|       |                Some(Ok(DeserializedMessage::new(
  165|       |                    Message::TelemetryReq,
  166|       |                    Default::default()
  167|       |                )))
  168|       |            );
  169|       |        }
  170|       |
  171|       |        #[test]
  172|       |        fn deserialize_message_with_payload() {
  173|       |            let mut deserializer = create_deserializer();
  174|       |
  175|       |            let keepalive = Message::Keepalive(Keepalive::new_test_instance());
  176|       |            deserializer.push(&message_bytes(&keepalive));
  177|       |
  178|       |            assert_eq!(
  179|       |                deserializer.try_deserialize(),
  180|       |                Some(Ok(DeserializedMessage::new(keepalive, Default::default())))
  181|       |            );
  182|       |        }
  183|       |
  184|       |        #[test]
  185|       |        fn deserialize_multiple_messages() {
  186|       |            let mut deserializer = create_deserializer();
  187|       |
  188|       |            let keepalive = Message::Keepalive(Keepalive::new_test_instance());
  189|       |            deserializer.push(&message_bytes(&Message::TelemetryReq));
  190|       |            deserializer.push(&message_bytes(&keepalive));
  191|       |            deserializer.push(&message_bytes(&Message::TelemetryReq));
  192|       |
  193|       |            assert_eq!(
  194|       |                deserializer.try_deserialize(),
  195|       |                Some(Ok(DeserializedMessage::new(
  196|       |                    Message::TelemetryReq,
  197|       |                    Default::default()
  198|       |                )))
  199|       |            );
  200|       |            assert_eq!(
  201|       |                deserializer.try_deserialize(),
  202|       |                Some(Ok(DeserializedMessage::new(keepalive, Default::default())))
  203|       |            );
  204|       |            assert_eq!(
  205|       |                deserializer.try_deserialize(),
  206|       |                Some(Ok(DeserializedMessage::new(
  207|       |                    Message::TelemetryReq,
  208|       |                    Default::default()
  209|       |                )))
  210|       |            );
  211|       |            assert_eq!(deserializer.try_deserialize(), None);
  212|       |        }
  213|       |    }
  214|       |
  215|       |    mod unhappy_path {
  216|       |        use super::*;
  217|       |        use crate::{ConfirmAck, Publish};
  218|       |        use rsnano_core::Networks;
  219|       |
  220|       |        #[test]
  221|       |        fn push_incomplete_header() {
  222|       |            let mut deserializer = create_deserializer();
  223|       |            deserializer.push(&[1, 2]);
  224|       |            assert!(deserializer.try_deserialize().is_none());
  225|       |        }
  226|       |
  227|       |        #[test]
  228|       |        fn invalid_header() {
  229|       |            let mut deserializer = create_deserializer();
  230|       |            deserializer.push(&[1, 2, 3, 4, 5, 6, 7, 8]);
  231|       |
  232|       |            assert_eq!(
  233|       |                deserializer.try_deserialize(),
  234|       |                Some(Err(ParseMessageError::InvalidHeader))
  235|       |            );
  236|       |        }
  237|       |
  238|       |        #[test]
  239|       |        fn invalid_network() {
  240|       |            let mut deserializer = create_deserializer();
  241|       |
  242|       |            let mut serializer =
  243|       |                MessageSerializer::new(ProtocolInfo::default_for(Networks::NanoBetaNetwork));
  244|       |            let message = serializer.serialize(&Message::TelemetryReq);
  245|       |
  246|       |            deserializer.push(&message);
  247|       |
  248|       |            assert_eq!(
  249|       |                deserializer.try_deserialize(),
  250|       |                Some(Err(ParseMessageError::InvalidNetwork))
  251|       |            );
  252|       |        }
  253|       |
  254|       |        #[test]
  255|       |        fn invalid_payload() {
  256|       |            let mut deserializer = create_deserializer();
  257|       |            deserializer.push(&invalid_asc_pull_ack_bytes());
  258|       |
  259|       |            assert_eq!(
  260|       |                deserializer.try_deserialize(),
  261|       |                Some(Err(ParseMessageError::InvalidMessage(
  262|       |                    MessageType::AscPullAck
  263|       |                )))
  264|       |            );
  265|       |        }
  266|       |
  267|       |        #[test]
  268|       |        fn incomplete_playload() {
  269|       |            let mut deserializer = create_deserializer();
  270|       |            let keepalive = Message::Keepalive(Keepalive::new_test_instance());
  271|       |            let data = message_bytes(&keepalive);
  272|       |
  273|       |            // push incomplete message
  274|       |            deserializer.push(&data[..data.len() - 1]);
  275|       |            assert_eq!(deserializer.try_deserialize(), None);
  276|       |
  277|       |            // push missing byte
  278|       |            deserializer.push(&data[data.len() - 1..]);
  279|       |            assert_eq!(
  280|       |                deserializer.try_deserialize(),
  281|       |                Some(Ok(DeserializedMessage::new(keepalive, Default::default())))
  282|       |            );
  283|       |        }
  284|       |
  285|       |        #[test]
  286|       |        fn insufficient_work() {
  287|       |            let mut deserializer = create_deserializer();
  288|       |
  289|       |            let mut publish = Publish::new_test_instance();
  290|       |            publish.block.set_work(0);
  291|       |            let message = Message::Publish(publish);
  292|       |
  293|       |            deserializer.push(&message_bytes(&message));
  294|       |            let result = deserializer.try_deserialize().unwrap();
  295|       |
  296|       |            assert_eq!(result, Err(ParseMessageError::InsufficientWork));
  297|       |        }
  298|       |
  299|       |        // Send two publish messages and asserts that the duplication is detected.
  300|       |        #[test]
  301|       |        fn duplicate_publish_message() {
  302|       |            let mut deserializer = create_deserializer();
  303|       |
  304|       |            let message = Message::Publish(Publish::new_test_instance());
  305|       |            let message_bytes = message_bytes(&message);
  306|       |
  307|       |            deserializer.push(&message_bytes);
  308|       |            deserializer.try_deserialize();
  309|       |
  310|       |            deserializer.push(&message_bytes);
  311|       |            let result = deserializer.try_deserialize();
  312|       |
  313|       |            assert_eq!(
  314|       |                result,
  315|       |                Some(Err(ParseMessageError::DuplicatePublishMessage))
  316|       |            );
  317|       |        }
  318|       |        //
  319|       |        // Send two publish messages and asserts that the duplication is detected.
  320|       |        #[test]
  321|       |        fn duplicate_confirm_ack() {
  322|       |            let mut deserializer = create_deserializer();
  323|       |            let message = Message::ConfirmAck(ConfirmAck::new_test_instance());
  324|       |            let message_bytes = message_bytes(&message);
  325|       |
  326|       |            deserializer.push(&message_bytes);
  327|       |            deserializer.try_deserialize();
  328|       |
  329|       |            deserializer.push(&message_bytes);
  330|       |            let result = deserializer.try_deserialize();
  331|       |
  332|       |            assert_eq!(
  333|       |                result,
  334|       |                Some(Err(ParseMessageError::DuplicateConfirmAckMessage))
  335|       |            );
  336|       |        }
  337|       |    }
  338|       |
  339|       |    fn message_bytes(message: &Message) -> Vec<u8> {
  340|       |        let mut serializer = MessageSerializer::default();
  341|       |        serializer.serialize(message).to_vec()
  342|       |    }
  343|       |
  344|       |    fn invalid_asc_pull_ack_bytes() -> Vec<u8> {
  345|       |        let mut data = message_bytes(&Message::AscPullAck(AscPullAck::new_test_instance_blocks()));
  346|       |        // make message invalid:
  347|       |        data[MessageHeader::SERIALIZED_SIZE..].fill(0xFF);
  348|       |        data
  349|       |    }
  350|       |
  351|       |    fn create_deserializer() -> MessageDeserializer {
  352|       |        let filter = Arc::new(NetworkFilter::default());
  353|       |        MessageDeserializer::new(
  354|       |            ProtocolInfo::default(),
  355|       |            filter,
  356|       |            WorkThresholds::publish_dev().clone(),
  357|       |        )
  358|       |    }
  359|       |}

/home/gustav/code/nano/rsnano-node/messages/src/message_header.rs:
    1|       |use anyhow::Result;
    2|       |use bitvec::prelude::*;
    3|       |use num_traits::FromPrimitive;
    4|       |use rsnano_core::{
    5|       |    utils::{BufferWriter, MemoryStream, Serialize, Stream},
    6|       |    Networks,
    7|       |};
    8|       |use std::{
    9|       |    fmt::{Debug, Display},
   10|       |    mem::size_of,
   11|       |};
   12|       |
   13|       |use super::*;
   14|       |
   15|       |/// Message types are serialized to the network and existing values must thus never change as
   16|       |/// types are added, removed and reordered in the enum.
   17|       |#[repr(u8)]
   18|      0|#[derive(FromPrimitive, Clone, Copy, PartialEq, Eq, Hash)]
   19|       |pub enum MessageType {
   20|       |    Invalid = 0x0,
   21|       |    NotAType = 0x1,
   22|       |    Keepalive = 0x2,
   23|       |    Publish = 0x3,
   24|       |    ConfirmReq = 0x4,
   25|       |    ConfirmAck = 0x5,
   26|       |    BulkPull = 0x6,
   27|       |    BulkPush = 0x7,
   28|       |    FrontierReq = 0x8,
   29|       |    /* deleted 0x9 */
   30|       |    NodeIdHandshake = 0x0a,
   31|       |    BulkPullAccount = 0x0b,
   32|       |    TelemetryReq = 0x0c,
   33|       |    TelemetryAck = 0x0d,
   34|       |    AscPullReq = 0x0e,
   35|       |    AscPullAck = 0x0f,
   36|       |}
   37|       |
   38|       |impl MessageType {
   39|      0|    pub fn as_str(&self) -> &'static str {
   40|      0|        match self {
   41|      0|            MessageType::Invalid => "invalid",
   42|      0|            MessageType::NotAType => "not_a_type",
   43|      0|            MessageType::Keepalive => "keepalive",
   44|      0|            MessageType::Publish => "publish",
   45|      0|            MessageType::ConfirmReq => "confirm_req",
   46|      0|            MessageType::ConfirmAck => "confirm_ack",
   47|      0|            MessageType::BulkPull => "bulk_pull",
   48|      0|            MessageType::BulkPush => "bulk_push",
   49|      0|            MessageType::FrontierReq => "frontier_req",
   50|      0|            MessageType::NodeIdHandshake => "node_id_handshake",
   51|      0|            MessageType::BulkPullAccount => "bulk_pull_account",
   52|      0|            MessageType::TelemetryReq => "telemetry_req",
   53|      0|            MessageType::TelemetryAck => "telemetry_ack",
   54|      0|            MessageType::AscPullReq => "asc_pull_req",
   55|      0|            MessageType::AscPullAck => "asc_pull_ack",
   56|       |        }
   57|      0|    }
   58|       |}
   59|       |
   60|       |impl Debug for MessageType {
   61|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   62|      0|        f.write_str(self.as_str())
   63|      0|    }
   64|       |}
   65|       |
   66|       |#[derive(Clone, Debug, PartialEq, Eq, Copy)]
   67|       |pub struct ProtocolInfo {
   68|       |    pub version_using: u8,
   69|       |    pub version_max: u8,
   70|       |    pub version_min: u8,
   71|       |    pub network: Networks,
   72|       |}
   73|       |
   74|       |impl Default for ProtocolInfo {
   75|      9|    fn default() -> Self {
   76|      9|        Self {
   77|      9|            version_using: 0x15,
   78|      9|            version_max: 0x15,
   79|      9|            version_min: 0x14,
   80|      9|            network: Networks::NanoLiveNetwork,
   81|      9|        }
   82|      9|    }
   83|       |}
   84|       |
   85|       |impl ProtocolInfo {
   86|      0|    pub fn default_for(network: Networks) -> Self {
   87|      0|        Self {
   88|      0|            network,
   89|      0|            ..Default::default()
   90|      0|        }
   91|      0|    }
   92|       |}
   93|       |
   94|       |/*
   95|       | * Common Header Binary Format:
   96|       | * [2 bytes] Network (big endian)
   97|       | * [1 byte] Maximum protocol version
   98|       | * [1 byte] Protocol version currently in use
   99|       | * [1 byte] Minimum protocol version
  100|       | * [1 byte] Message type
  101|       | * [2 bytes] Extensions (message-specific flags and properties)
  102|       | *
  103|       | * Notes:
  104|       | * - The structure and bit usage of the `extensions` field vary by message type.
  105|       | */
  106|       |#[derive(Clone, PartialEq, Eq)]
  107|       |pub struct MessageHeader {
  108|       |    pub message_type: MessageType,
  109|       |    pub protocol: ProtocolInfo,
  110|       |    pub extensions: BitArray<u16>,
  111|       |}
  112|       |
  113|       |impl Default for MessageHeader {
  114|      0|    fn default() -> Self {
  115|      0|        Self {
  116|      0|            message_type: MessageType::Invalid,
  117|      0|            protocol: Default::default(),
  118|      0|            extensions: BitArray::ZERO,
  119|      0|        }
  120|      0|    }
  121|       |}
  122|       |
  123|       |impl MessageHeader {
  124|       |    pub const SERIALIZED_SIZE: usize = 8;
  125|       |
  126|      0|    pub fn new(message_type: MessageType, protocol: ProtocolInfo) -> Self {
  127|      0|        Self {
  128|      0|            message_type,
  129|      0|            protocol,
  130|      0|            ..Default::default()
  131|      0|        }
  132|      0|    }
  133|       |
  134|      0|    pub fn new_with_payload_len(
  135|      0|        message_type: MessageType,
  136|      0|        protocol: ProtocolInfo,
  137|      0|        payload: &impl Serialize,
  138|      0|    ) -> Self {
  139|      0|        let mut stream = MemoryStream::new();
  140|      0|        payload.serialize(&mut stream);
  141|      0|        let payload_len: u16 = stream.bytes_written() as u16;
  142|      0|
  143|      0|        Self {
  144|      0|            message_type,
  145|      0|            protocol,
  146|      0|            extensions: payload_len.into(),
  147|      0|        }
  148|      0|    }
  149|       |
  150|      0|    pub fn deserialize_slice(bytes: &[u8]) -> Result<MessageHeader> {
  151|      0|        let mut reader = BufferReader::new(bytes);
  152|      0|        Self::deserialize(&mut reader)
  153|      0|    }
  154|       |
  155|      0|    pub fn deserialize(stream: &mut impl Stream) -> Result<MessageHeader> {
  156|      0|        let mut header = Self::default();
  157|      0|        let mut buffer = [0; 2];
  158|      0|
  159|      0|        stream.read_bytes(&mut buffer, 2)?;
  160|      0|        header.protocol.network = Networks::from_u16(u16::from_be_bytes(buffer))
  161|      0|            .ok_or_else(|| anyhow!("invalid network"))?;
  162|       |
  163|      0|        header.protocol.version_max = stream.read_u8()?;
  164|      0|        header.protocol.version_using = stream.read_u8()?;
  165|      0|        header.protocol.version_min = stream.read_u8()?;
  166|      0|        header.message_type = MessageType::from_u8(stream.read_u8()?)
  167|      0|            .ok_or_else(|| anyhow!("invalid message type"))?;
  168|       |
  169|      0|        stream.read_bytes(&mut buffer, 2)?;
  170|      0|        header.extensions.data = u16::from_le_bytes(buffer);
  171|      0|        Ok(header)
  172|      0|    }
  173|       |
  174|      0|    pub fn set_extension(&mut self, position: usize, value: bool) {
  175|      0|        self.extensions.set(position, value);
  176|      0|    }
  177|       |
  178|      0|    pub fn set_flag(&mut self, flag: u8) {
  179|      0|        // Flags from 8 are block_type & count
  180|      0|        debug_assert!(flag < 8);
  181|      0|        self.extensions.set(flag as usize, true);
  182|      0|    }
  183|       |
  184|      0|    pub const fn serialized_size() -> usize {
  185|      0|        size_of::<u8>() // version_using
  186|      0|        + size_of::<u8>() // version_min
  187|      0|        + size_of::<u8>() // version_max
  188|      0|        + size_of::<Networks>()
  189|      0|        + size_of::<MessageType>()
  190|      0|        + size_of::<u16>() // extensions
  191|      0|    }
  192|       |
  193|      0|    pub fn serialize(&self, stream: &mut dyn BufferWriter) {
  194|      0|        stream.write_bytes_safe(&(self.protocol.network as u16).to_be_bytes());
  195|      0|        stream.write_u8_safe(self.protocol.version_max);
  196|      0|        stream.write_u8_safe(self.protocol.version_using);
  197|      0|        stream.write_u8_safe(self.protocol.version_min);
  198|      0|        stream.write_u8_safe(self.message_type as u8);
  199|      0|        stream.write_bytes_safe(&self.extensions.data.to_le_bytes());
  200|      0|    }
  201|       |
  202|       |    const BULK_PULL_COUNT_PRESENT_FLAG: usize = 0;
  203|       |
  204|      0|    pub fn bulk_pull_is_count_present(&self) -> bool {
  205|      0|        self.message_type == MessageType::BulkPull
  206|      0|            && self.extensions[Self::BULK_PULL_COUNT_PRESENT_FLAG]
  207|      0|    }
  208|       |
  209|      0|    pub fn payload_length(&self) -> usize {
  210|      0|        match self.message_type {
  211|      0|            MessageType::Keepalive => Keepalive::serialized_size(),
  212|      0|            MessageType::Publish => Publish::serialized_size(self.extensions),
  213|      0|            MessageType::ConfirmReq => ConfirmReq::serialized_size(self.extensions),
  214|      0|            MessageType::ConfirmAck => ConfirmAck::serialized_size(self.extensions),
  215|      0|            MessageType::BulkPull => BulkPull::serialized_size(self.extensions),
  216|      0|            MessageType::BulkPush | MessageType::TelemetryReq => 0,
  217|      0|            MessageType::FrontierReq => FrontierReq::serialized_size(),
  218|      0|            MessageType::NodeIdHandshake => NodeIdHandshake::serialized_size(self.extensions),
  219|      0|            MessageType::BulkPullAccount => BulkPullAccount::serialized_size(),
  220|      0|            MessageType::TelemetryAck => TelemetryAck::serialized_size(self.extensions),
  221|      0|            MessageType::AscPullReq => AscPullReq::serialized_size(self.extensions),
  222|      0|            MessageType::AscPullAck => AscPullAck::serialized_size(self.extensions),
  223|       |            MessageType::Invalid | MessageType::NotAType => {
  224|      0|                debug_assert!(false);
  225|      0|                0
  226|       |            }
  227|       |        }
  228|      0|    }
  229|       |
  230|      0|    pub fn is_valid_message_type(&self) -> bool {
  231|      0|        !matches!(
  232|      0|            self.message_type,
  233|       |            MessageType::Invalid | MessageType::NotAType
  234|       |        )
  235|      0|    }
  236|       |}
  237|       |
  238|       |impl Display for MessageHeader {
  239|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  240|      0|        f.write_fmt(format_args!(
  241|      0|            "NetID: {:04X}({}), ",
  242|      0|            self.protocol.network as u16,
  243|      0|            self.protocol.network.as_str()
  244|      0|        ))?;
  245|      0|        f.write_fmt(format_args!(
  246|      0|            "VerMaxUsingMin: {}/{}/{}, ",
  247|      0|            self.protocol.version_max, self.protocol.version_using, self.protocol.version_min
  248|      0|        ))?;
  249|      0|        f.write_fmt(format_args!(
  250|      0|            "MsgType: {}({}), ",
  251|      0|            self.message_type as u8,
  252|      0|            self.message_type.as_str()
  253|      0|        ))?;
  254|      0|        f.write_fmt(format_args!("Extensions: {:04X}", self.extensions.data))
  255|      0|    }
  256|       |}
  257|       |
  258|       |impl Debug for MessageHeader {
  259|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  260|      0|        Display::fmt(&self, f)
  261|      0|    }
  262|       |}
  263|       |
  264|       |#[cfg(test)]
  265|       |mod tests {
  266|       |    use super::*;
  267|       |    use rsnano_core::utils::MemoryStream;
  268|       |
  269|       |    #[test]
  270|       |    fn message_header_to_string() {
  271|       |        assert_eq!(
  272|       |            test_header().to_string(),
  273|       |            "NetID: 5241(dev), VerMaxUsingMin: 3/2/1, MsgType: 2(keepalive), Extensions: 000E"
  274|       |        );
  275|       |    }
  276|       |
  277|       |    #[test]
  278|       |    fn serialize_and_deserialize() {
  279|       |        let original = test_header();
  280|       |        let mut stream = MemoryStream::new();
  281|       |        original.serialize(&mut stream);
  282|       |        let deserialized = MessageHeader::deserialize(&mut stream).unwrap();
  283|       |        assert_eq!(original, deserialized);
  284|       |    }
  285|       |
  286|       |    fn test_header() -> MessageHeader {
  287|       |        let protocol = ProtocolInfo {
  288|       |            version_using: 2,
  289|       |            version_max: 3,
  290|       |            version_min: 1,
  291|       |            network: Networks::NanoDevNetwork,
  292|       |        };
  293|       |        MessageHeader {
  294|       |            message_type: MessageType::Keepalive,
  295|       |            protocol,
  296|       |            extensions: BitArray::from(14),
  297|       |        }
  298|       |    }
  299|       |
  300|       |    #[test]
  301|       |    fn serialize_header() {
  302|       |        let protocol_info = ProtocolInfo::default_for(Networks::NanoDevNetwork);
  303|       |        let mut header = MessageHeader::new(MessageType::Publish, protocol_info);
  304|       |        header.extensions = 0xABCD.into();
  305|       |
  306|       |        let mut stream = MemoryStream::new();
  307|       |        header.serialize(&mut stream);
  308|       |
  309|       |        let bytes = stream.as_bytes();
  310|       |        assert_eq!(bytes.len(), 8);
  311|       |        assert_eq!(bytes[0], 0x52);
  312|       |        assert_eq!(bytes[1], 0x41);
  313|       |        assert_eq!(bytes[2], protocol_info.version_using);
  314|       |        assert_eq!(bytes[3], protocol_info.version_max);
  315|       |        assert_eq!(bytes[4], protocol_info.version_min);
  316|       |        assert_eq!(bytes[5], 0x03); // publish
  317|       |        assert_eq!(bytes[6], 0xCD); // extensions
  318|       |        assert_eq!(bytes[7], 0xAB); // extensions
  319|       |    }
  320|       |}

/home/gustav/code/nano/rsnano-node/messages/src/message_serializer.rs:
    1|       |use super::{Message, MessageHeader, ProtocolInfo};
    2|       |use rsnano_core::utils::MutStreamAdapter;
    3|       |
    4|       |#[derive(Clone)]
    5|       |pub struct MessageSerializer {
    6|       |    protocol: ProtocolInfo,
    7|       |    buffer: Vec<u8>,
    8|       |}
    9|       |
   10|       |impl MessageSerializer {
   11|       |    const BUFFER_SIZE: usize = MessageHeader::SERIALIZED_SIZE + Message::MAX_MESSAGE_SIZE;
   12|      3|    pub fn new(protocol: ProtocolInfo) -> Self {
   13|      3|        Self {
   14|      3|            protocol,
   15|      3|            buffer: vec![0; Self::BUFFER_SIZE],
   16|      3|        }
   17|      3|    }
   18|       |
   19|      3|    pub fn new_with_buffer_size(protocol: ProtocolInfo, buffer_size: usize) -> Self {
   20|      3|        Self {
   21|      3|            protocol,
   22|      3|            buffer: vec![0; buffer_size],
   23|      3|        }
   24|      3|    }
   25|       |
   26|      0|    pub fn serialize(&'_ mut self, message: &Message) -> &'_ [u8] {
   27|      0|        let payload_len;
   28|      0|        {
   29|      0|            let mut payload_writer =
   30|      0|                MutStreamAdapter::new(&mut self.buffer[MessageHeader::SERIALIZED_SIZE..]);
   31|      0|            message.serialize(&mut payload_writer);
   32|      0|            payload_len = payload_writer.bytes_written();
   33|      0|
   34|      0|            let mut header_writer =
   35|      0|                MutStreamAdapter::new(&mut self.buffer[..MessageHeader::SERIALIZED_SIZE]);
   36|      0|            let mut header = MessageHeader::new(message.message_type(), self.protocol);
   37|      0|            header.extensions = message.header_extensions(payload_len as u16);
   38|      0|            header.serialize(&mut header_writer);
   39|      0|        }
   40|      0|        &self.buffer[..MessageHeader::SERIALIZED_SIZE + payload_len]
   41|      0|    }
   42|       |}
   43|       |
   44|       |impl Default for MessageSerializer {
   45|      0|    fn default() -> Self {
   46|      0|        Self::new(ProtocolInfo::default())
   47|      0|    }
   48|       |}

/home/gustav/code/nano/rsnano-node/messages/src/network_filter.rs:
    1|       |use rand::{thread_rng, Rng};
    2|       |use siphasher::{prelude::*, sip128::SipHasher};
    3|       |use std::sync::{
    4|       |    atomic::{AtomicU64, Ordering},
    5|       |    Mutex, MutexGuard,
    6|       |};
    7|       |
    8|       |#[derive(Clone, Default)]
    9|       |struct Entry {
   10|       |    digest: u128,
   11|       |    epoch: u64,
   12|       |}
   13|       |
   14|       |/// A probabilistic duplicate filter based on directed map caches, using SipHash 2/4/128
   15|       |/// The probability of false negatives (unique packet marked as duplicate) is the probability of a 128-bit SipHash collision.
   16|       |/// The probability of false positives (duplicate packet marked as unique) shrinks with a larger filter.
   17|       |pub struct NetworkFilter<T: NetworkFilterHasher = DefaultNetworkFilterHasher> {
   18|       |    items: Mutex<Vec<Entry>>,
   19|       |    hasher: T,
   20|       |    pub age_cutoff: u64,
   21|       |    current_epoch: AtomicU64,
   22|       |}
   23|       |
   24|       |impl<T: NetworkFilterHasher> NetworkFilter<T> {
   25|      3|    pub fn with_hasher(hasher: T, size: usize) -> Self {
   26|      3|        Self {
   27|      3|            items: Mutex::new(vec![Entry::default(); size]),
   28|      3|            hasher,
   29|      3|            age_cutoff: 0,
   30|      3|            current_epoch: AtomicU64::new(0),
   31|      3|        }
   32|      3|    }
   33|       |
   34|      0|    pub fn update(&self, epoch_inc: u64) {
   35|      0|        self.current_epoch.fetch_add(epoch_inc, Ordering::SeqCst);
   36|      0|    }
   37|       |
   38|      0|    fn compare(&self, existing: &Entry, digest: u128) -> bool {
   39|      0|        // Only consider digests to be the same if the epoch is within the age cutoff
   40|      0|        existing.digest == digest
   41|      0|            && existing.epoch + self.age_cutoff >= self.current_epoch.load(Ordering::SeqCst)
   42|      0|    }
   43|       |
   44|       |    /// Reads `count` bytes starting from `bytes` and inserts the siphash digest in the filter.
   45|       |    /// # Returns
   46|       |    /// * the resulting siphash digest
   47|       |    /// * a boolean representing the previous existence of the hash in the filter.
   48|      0|    pub fn apply(&self, bytes: &[u8]) -> (u128, bool) {
   49|      0|        let digest = self.hash(bytes);
   50|      0|        let existed = self.apply_digest(digest);
   51|      0|        (digest, existed)
   52|      0|    }
   53|       |
   54|      0|    pub fn apply_digest(&self, digest: u128) -> bool {
   55|      0|        let mut lock = self.items.lock().unwrap();
   56|      0|        let element = self.get_element(digest, &mut lock);
   57|      0|        let existed = self.compare(element, digest);
   58|      0|        if !existed {
   59|      0|            // Replace likely old element with a new one
   60|      0|            *element = Entry {
   61|      0|                digest,
   62|      0|                epoch: self.current_epoch.load(Ordering::SeqCst),
   63|      0|            };
   64|      0|        }
   65|      0|        existed
   66|      0|    }
   67|       |    /// Checks if the message is in the filter.
   68|      0|    pub fn check_message(&self, message: &[u8]) -> bool {
   69|      0|        let digest = self.hash(message);
   70|      0|        self.check(digest)
   71|      0|    }
   72|       |
   73|       |    /// Checks if the digest is in the filter.
   74|      0|    pub fn check(&self, digest: u128) -> bool {
   75|      0|        let mut guard = self.items.lock().unwrap();
   76|      0|        let element = self.get_element(digest, &mut guard);
   77|      0|        self.compare(element, digest)
   78|      0|    }
   79|       |
   80|       |    /// Sets the corresponding element in the filter to zero, if it matches `digest` exactly.
   81|      0|    pub fn clear(&self, digest: u128) {
   82|      0|        let mut lock = self.items.lock().unwrap();
   83|      0|        self.clear_locked(digest, &mut lock);
   84|      0|    }
   85|       |
   86|      0|    pub fn clear_many(&self, digests: impl IntoIterator<Item = u128>) {
   87|      0|        let mut lock = self.items.lock().unwrap();
   88|      0|        for digest in digests.into_iter() {
   89|      0|            self.clear_locked(digest, &mut lock);
   90|      0|        }
   91|      0|    }
   92|       |
   93|      0|    pub fn clear_bytes(&self, bytes: &[u8]) {
   94|      0|        self.clear(self.hash(bytes));
   95|      0|    }
   96|       |
   97|      0|    pub fn clear_all(&self) {
   98|      0|        let mut lock = self.items.lock().unwrap();
   99|      0|        lock.fill(Default::default());
  100|      0|    }
  101|       |
  102|      0|    fn clear_locked(&self, digest: u128, lock: &mut MutexGuard<Vec<Entry>>) {
  103|      0|        let element = self.get_element(digest, lock);
  104|      0|        if self.compare(&element, digest) {
  105|      0|            *element = Default::default();
  106|      0|        }
  107|      0|    }
  108|       |
  109|      0|    fn get_element<'a>(&self, hash: u128, items: &'a mut MutexGuard<Vec<Entry>>) -> &'a mut Entry {
  110|      0|        let index = (hash % items.len() as u128) as usize;
  111|      0|        items.get_mut(index).unwrap()
  112|      0|    }
  113|       |
  114|      0|    pub fn hash(&self, bytes: &[u8]) -> u128 {
  115|      0|        self.hasher.hash(bytes)
  116|      0|    }
  117|       |}
  118|       |
  119|       |impl NetworkFilter {
  120|      3|    pub fn new(size: usize) -> Self {
  121|      3|        NetworkFilter::with_hasher(DefaultNetworkFilterHasher::new(), size)
  122|      3|    }
  123|       |}
  124|       |
  125|       |impl Default for NetworkFilter {
  126|      0|    fn default() -> Self {
  127|      0|        Self::new(256 * 1024)
  128|      0|    }
  129|       |}
  130|       |
  131|       |pub trait NetworkFilterHasher {
  132|       |    fn hash(&self, bytes: &[u8]) -> u128;
  133|       |}
  134|       |
  135|       |pub struct DefaultNetworkFilterHasher {
  136|       |    key: [u8; 16],
  137|       |}
  138|       |
  139|       |impl DefaultNetworkFilterHasher {
  140|      3|    pub fn new() -> Self {
  141|      3|        Self {
  142|      3|            key: thread_rng().gen::<[u8; 16]>(),
  143|      3|        }
  144|      3|    }
  145|       |}
  146|       |
  147|       |impl Default for DefaultNetworkFilterHasher {
  148|      0|    fn default() -> Self {
  149|      0|        Self::new()
  150|      0|    }
  151|       |}
  152|       |
  153|       |impl NetworkFilterHasher for DefaultNetworkFilterHasher {
  154|      0|    fn hash(&self, bytes: &[u8]) -> u128 {
  155|      0|        let mut siphash = SipHasher::new_with_key(&self.key);
  156|      0|        siphash.write(bytes);
  157|      0|        siphash.finish128().as_u128()
  158|      0|    }
  159|       |}
  160|       |
  161|       |#[cfg(test)]
  162|       |mod tests {
  163|       |    use super::*;
  164|       |
  165|       |    #[derive(Default)]
  166|       |    struct StubHasher {}
  167|       |
  168|       |    impl NetworkFilterHasher for StubHasher {
  169|       |        fn hash(&self, bytes: &[u8]) -> u128 {
  170|       |            bytes[0] as u128
  171|       |        }
  172|       |    }
  173|       |
  174|       |    #[test]
  175|       |    fn apply_returns_if_key_existed() {
  176|       |        let filter = NetworkFilter::new(1);
  177|       |        let bytes = [1, 2, 3];
  178|       |
  179|       |        let (_, existed) = filter.apply(&bytes);
  180|       |        assert_eq!(existed, false);
  181|       |
  182|       |        let (_, existed) = filter.apply(&bytes);
  183|       |        assert_eq!(existed, true);
  184|       |    }
  185|       |
  186|       |    #[test]
  187|       |    fn check() {
  188|       |        let filter = NetworkFilter::with_hasher(StubHasher::default(), 10);
  189|       |        assert_eq!(filter.check(123), false);
  190|       |        assert_eq!(filter.check(123), false);
  191|       |
  192|       |        let (digest, _) = filter.apply(&[42]);
  193|       |        assert_eq!(filter.check(digest), true);
  194|       |        assert_eq!(filter.check(digest), true);
  195|       |
  196|       |        let (digest2, _) = filter.apply(&[100]);
  197|       |
  198|       |        assert_eq!(filter.check(digest), true);
  199|       |        assert_eq!(filter.check(digest2), true);
  200|       |        assert_eq!(filter.check(123), false);
  201|       |    }
  202|       |
  203|       |    #[test]
  204|       |    fn clear_bytes() {
  205|       |        let filter = NetworkFilter::new(1);
  206|       |        let bytes1 = [1, 2, 3];
  207|       |        let bytes2 = [1];
  208|       |
  209|       |        filter.apply(&bytes1);
  210|       |        filter.clear_bytes(&bytes1);
  211|       |
  212|       |        let (_, existed) = filter.apply(&bytes1);
  213|       |        assert_eq!(existed, false);
  214|       |
  215|       |        let (_, existed) = filter.apply(&bytes1);
  216|       |        assert_eq!(existed, true);
  217|       |
  218|       |        filter.clear_bytes(&bytes2);
  219|       |
  220|       |        let (_, existed) = filter.apply(&bytes1);
  221|       |        assert_eq!(existed, true);
  222|       |
  223|       |        let (_, existed) = filter.apply(&bytes2);
  224|       |        assert_eq!(existed, false);
  225|       |    }
  226|       |
  227|       |    #[test]
  228|       |    fn clear() {
  229|       |        let filter = NetworkFilter::new(1);
  230|       |        let bytes = [1, 2, 3];
  231|       |
  232|       |        let (digest, existed) = filter.apply(&bytes);
  233|       |        assert_eq!(existed, false);
  234|       |        assert_ne!(digest, 0);
  235|       |
  236|       |        let (digest2, existed) = filter.apply(&bytes);
  237|       |        assert_eq!(existed, true);
  238|       |        assert_eq!(digest2, digest);
  239|       |
  240|       |        filter.clear(digest);
  241|       |        let (_, existed) = filter.apply(&bytes);
  242|       |        assert_eq!(existed, false);
  243|       |    }
  244|       |
  245|       |    #[test]
  246|       |    fn stub_hasher() {
  247|       |        assert_eq!(0, StubHasher::default().hash(&[0]));
  248|       |        assert_eq!(1, StubHasher::default().hash(&[1]));
  249|       |    }
  250|       |
  251|       |    #[test]
  252|       |    fn clear_many() {
  253|       |        let filter = NetworkFilter::with_hasher(StubHasher::default(), 4);
  254|       |        let bytes1 = [1];
  255|       |        let bytes2 = [2];
  256|       |        let bytes3 = [3];
  257|       |        let (digest1, _) = filter.apply(&bytes1);
  258|       |        let (digest2, _) = filter.apply(&bytes2);
  259|       |        filter.apply(&bytes3);
  260|       |
  261|       |        filter.clear_many([digest1, digest2]);
  262|       |
  263|       |        let (_, existed) = filter.apply(&bytes1);
  264|       |        assert_eq!(existed, false);
  265|       |
  266|       |        let (_, existed) = filter.apply(&bytes2);
  267|       |        assert_eq!(existed, false);
  268|       |
  269|       |        let (_, existed) = filter.apply(&bytes3);
  270|       |        assert_eq!(existed, true);
  271|       |    }
  272|       |
  273|       |    #[test]
  274|       |    fn expire() {
  275|       |        let mut filter = NetworkFilter::with_hasher(StubHasher::default(), 4);
  276|       |        filter.age_cutoff = 2;
  277|       |        assert_eq!(filter.apply_digest(1), false); // Entry with epoch 0
  278|       |        filter.update(1); // Bump epoch to 1
  279|       |        assert_eq!(filter.apply_digest(2), false); // Entry with epoch 1
  280|       |
  281|       |        // Both values should be detected as present
  282|       |        assert!(filter.check(1));
  283|       |        assert!(filter.check(2));
  284|       |
  285|       |        filter.update(2); // Bump epoch to 3
  286|       |
  287|       |        assert_eq!(
  288|       |            filter.check(1),
  289|       |            false,
  290|       |            "Entry with epoch 0 should be expired"
  291|       |        );
  292|       |        assert_eq!(
  293|       |            filter.check(2),
  294|       |            true,
  295|       |            "Entry with epoch 1 should still be present"
  296|       |        );
  297|       |
  298|       |        filter.update(1); // Bump epoch to 4
  299|       |        assert_eq!(
  300|       |            filter.check(2),
  301|       |            false,
  302|       |            "Entry with epoch 1 should be expired"
  303|       |        );
  304|       |        assert_eq!(
  305|       |            filter.apply_digest(2),
  306|       |            false,
  307|       |            "Entry with epoch 1 should be replaced"
  308|       |        );
  309|       |    }
  310|       |}

/home/gustav/code/nano/rsnano-node/messages/src/node_id_handshake.rs:
    1|       |use super::MessageVariant;
    2|       |use crate::Cookie;
    3|       |use anyhow::Result;
    4|       |use bitvec::prelude::BitArray;
    5|       |use rand::{thread_rng, Rng};
    6|       |use rsnano_core::{
    7|       |    utils::{BufferWriter, Deserialize, FixedSizeSerialize, MemoryStream, Serialize, Stream},
    8|       |    write_hex_bytes, Account, BlockHash, NodeId, PrivateKey, PublicKey, Signature,
    9|       |};
   10|       |use serde::ser::SerializeStruct;
   11|       |use std::fmt::{Display, Write};
   12|       |
   13|       |#[derive(Clone, PartialEq, Eq, Debug)]
   14|       |pub struct NodeIdHandshakeQuery {
   15|       |    pub cookie: [u8; 32],
   16|       |}
   17|       |
   18|       |impl serde::Serialize for NodeIdHandshakeQuery {
   19|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
   20|      0|    where
   21|      0|        S: serde::Serializer,
   22|      0|    {
   23|      0|        let mut state = serializer.serialize_struct("NodeIdHandshakeQuery", 1)?;
   24|       |
   25|      0|        let mut short_cookie = String::with_capacity(32 * 2);
   26|      0|        for b in &self.cookie {
   27|      0|            write!(short_cookie, "{:02X}", b).unwrap();
   28|      0|        }
   29|      0|        state.serialize_field("cookie", &short_cookie)?;
   30|      0|        state.end()
   31|      0|    }
   32|       |}
   33|       |
   34|       |#[derive(Clone, PartialEq, Eq, Debug, serde::Serialize)]
   35|       |pub struct NodeIdHandshakeResponse {
   36|       |    pub node_id: NodeId,
   37|       |    pub signature: Signature,
   38|       |    pub v2: Option<V2Payload>,
   39|       |}
   40|       |
   41|       |impl NodeIdHandshakeResponse {
   42|      0|    pub fn new_v1(cookie: &Cookie, node_id: &PrivateKey) -> Self {
   43|      0|        let mut response = Self {
   44|      0|            node_id: node_id.public_key().into(),
   45|      0|            signature: Signature::default(),
   46|      0|            v2: None,
   47|      0|        };
   48|      0|        response.sign(cookie, node_id);
   49|      0|        response
   50|      0|    }
   51|       |
   52|      0|    pub fn new_v2(cookie: &Cookie, node_id: &PrivateKey, genesis: BlockHash) -> Self {
   53|      0|        let mut salt = [0; 32];
   54|      0|        thread_rng().fill(&mut salt);
   55|      0|
   56|      0|        let mut response = Self {
   57|      0|            node_id: node_id.public_key().into(),
   58|      0|            signature: Signature::default(),
   59|      0|            v2: Some(V2Payload { salt, genesis }),
   60|      0|        };
   61|      0|        response.sign(cookie, node_id);
   62|      0|        response
   63|      0|    }
   64|       |
   65|      0|    pub fn sign(&mut self, cookie: &Cookie, key: &PrivateKey) {
   66|      0|        debug_assert!(NodeId::from(key.public_key()) == self.node_id);
   67|      0|        let data = self.data_to_sign(cookie);
   68|      0|        self.signature = key.sign(&data);
   69|      0|        debug_assert!(self.validate(cookie).is_ok());
   70|      0|    }
   71|       |
   72|      0|    pub fn validate(&self, cookie: &Cookie) -> anyhow::Result<()> {
   73|      0|        let data = self.data_to_sign(cookie);
   74|      0|        let pub_key: PublicKey = self.node_id.into();
   75|      0|        pub_key.verify(&data, &self.signature)
   76|      0|    }
   77|       |
   78|      0|    fn data_to_sign(&self, cookie: &Cookie) -> Vec<u8> {
   79|      0|        let mut stream = MemoryStream::new();
   80|      0|        match &self.v2 {
   81|      0|            Some(v2) => {
   82|      0|                stream.write_bytes_safe(cookie);
   83|      0|                stream.write_bytes_safe(&v2.salt);
   84|      0|                v2.genesis.serialize(&mut stream);
   85|      0|            }
   86|      0|            None => stream.write_bytes_safe(cookie),
   87|       |        }
   88|      0|        stream.to_vec()
   89|      0|    }
   90|       |
   91|      0|    pub fn deserialize(stream: &mut dyn Stream, extensions: BitArray<u16>) -> Result<Self> {
   92|      0|        if NodeIdHandshake::has_v2_flag(extensions) {
   93|      0|            let node_id = NodeId::deserialize(stream)?;
   94|      0|            let mut salt = [0u8; 32];
   95|      0|            stream.read_bytes(&mut salt, 32)?;
   96|      0|            let genesis = BlockHash::deserialize(stream)?;
   97|      0|            let signature = Signature::deserialize(stream)?;
   98|      0|            Ok(Self {
   99|      0|                node_id,
  100|      0|                signature,
  101|      0|                v2: Some(V2Payload { salt, genesis }),
  102|      0|            })
  103|       |        } else {
  104|      0|            let node_id = NodeId::deserialize(stream)?;
  105|      0|            let signature = Signature::deserialize(stream)?;
  106|      0|            Ok(Self {
  107|      0|                node_id,
  108|      0|                signature,
  109|      0|                v2: None,
  110|      0|            })
  111|       |        }
  112|      0|    }
  113|       |
  114|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
  115|      0|        if NodeIdHandshake::has_v2_flag(extensions) {
  116|      0|            Account::serialized_size()
  117|      0|                + 32 // salt
  118|      0|                + BlockHash::serialized_size()
  119|      0|                + Signature::serialized_size()
  120|       |        } else {
  121|      0|            Account::serialized_size() + Signature::serialized_size()
  122|       |        }
  123|      0|    }
  124|       |}
  125|       |
  126|       |impl Serialize for NodeIdHandshakeResponse {
  127|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  128|      0|        match &self.v2 {
  129|      0|            Some(v2) => {
  130|      0|                self.node_id.serialize(stream);
  131|      0|                stream.write_bytes_safe(&v2.salt);
  132|      0|                v2.genesis.serialize(stream);
  133|      0|                self.signature.serialize(stream);
  134|      0|            }
  135|      0|            None => {
  136|      0|                self.node_id.serialize(stream);
  137|      0|                self.signature.serialize(stream);
  138|      0|            }
  139|       |        }
  140|      0|    }
  141|       |}
  142|       |
  143|       |#[derive(Clone, PartialEq, Eq, Debug)]
  144|       |pub struct V2Payload {
  145|       |    pub salt: [u8; 32],
  146|       |    pub genesis: BlockHash,
  147|       |}
  148|       |
  149|       |impl serde::Serialize for V2Payload {
  150|      0|    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
  151|      0|    where
  152|      0|        S: serde::Serializer,
  153|      0|    {
  154|      0|        let mut state = serializer.serialize_struct("V2Payload", 2)?;
  155|       |
  156|      0|        let mut short_salt = String::with_capacity(32 * 2);
  157|      0|        for b in &self.salt {
  158|      0|            write!(short_salt, "{:02X}", b).unwrap();
  159|      0|        }
  160|      0|        state.serialize_field("salt", &short_salt)?;
  161|      0|        state.serialize_field("genesis", &self.genesis)?;
  162|      0|        state.end()
  163|      0|    }
  164|       |}
  165|       |
  166|       |#[derive(Clone, PartialEq, Eq, Debug, serde::Serialize)]
  167|       |pub struct NodeIdHandshake {
  168|       |    pub query: Option<NodeIdHandshakeQuery>,
  169|       |    pub response: Option<NodeIdHandshakeResponse>,
  170|       |    pub is_v2: bool,
  171|       |}
  172|       |
  173|       |impl NodeIdHandshake {
  174|       |    pub const QUERY_FLAG: usize = 0;
  175|       |    pub const RESPONSE_FLAG: usize = 1;
  176|       |    pub const V2_FLAG: usize = 2;
  177|       |
  178|      0|    pub fn is_query(extensions: BitArray<u16>) -> bool {
  179|      0|        extensions[NodeIdHandshake::QUERY_FLAG]
  180|      0|    }
  181|       |
  182|      0|    pub fn is_response(extensions: BitArray<u16>) -> bool {
  183|      0|        extensions[NodeIdHandshake::RESPONSE_FLAG]
  184|      0|    }
  185|       |
  186|      0|    pub fn has_v2_flag(extensions: BitArray<u16>) -> bool {
  187|      0|        extensions[NodeIdHandshake::V2_FLAG]
  188|      0|    }
  189|       |
  190|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
  191|      0|        let mut size = 0;
  192|      0|        if Self::is_query(extensions) {
  193|      0|            size += 32
  194|      0|        }
  195|      0|        if Self::is_response(extensions) {
  196|      0|            size += NodeIdHandshakeResponse::serialized_size(extensions);
  197|      0|        }
  198|      0|        size
  199|      0|    }
  200|       |
  201|      0|    pub fn deserialize(stream: &mut dyn Stream, extensions: BitArray<u16>) -> Option<Self> {
  202|      0|        let query = if NodeIdHandshake::is_query(extensions) {
  203|      0|            let mut cookie = [0u8; 32];
  204|      0|            stream.read_bytes(&mut cookie, 32).ok()?;
  205|      0|            Some(NodeIdHandshakeQuery { cookie })
  206|       |        } else {
  207|      0|            None
  208|       |        };
  209|      0|        let response = if NodeIdHandshake::is_response(extensions) {
  210|      0|            Some(NodeIdHandshakeResponse::deserialize(stream, extensions).ok()?)
  211|       |        } else {
  212|      0|            None
  213|       |        };
  214|      0|        Some(Self {
  215|      0|            query,
  216|      0|            response,
  217|      0|            is_v2: Self::has_v2_flag(extensions),
  218|      0|        })
  219|      0|    }
  220|       |
  221|      0|    pub fn new_test_query() -> Self {
  222|      0|        let query = NodeIdHandshakeQuery { cookie: [42; 32] };
  223|      0|        Self {
  224|      0|            query: Some(query),
  225|      0|            response: None,
  226|      0|            is_v2: true,
  227|      0|        }
  228|      0|    }
  229|       |
  230|      0|    pub fn new_test_response_v1() -> Self {
  231|      0|        let response = NodeIdHandshakeResponse {
  232|      0|            node_id: NodeId::from(1),
  233|      0|            signature: Signature::from_bytes([42; 64]),
  234|      0|            v2: None,
  235|      0|        };
  236|      0|        Self {
  237|      0|            query: None,
  238|      0|            response: Some(response),
  239|      0|            is_v2: false,
  240|      0|        }
  241|      0|    }
  242|       |
  243|      0|    pub fn new_test_response_v2() -> Self {
  244|      0|        let response = NodeIdHandshakeResponse {
  245|      0|            node_id: NodeId::from(1),
  246|      0|            signature: Signature::from_bytes([42; 64]),
  247|      0|            v2: Some(V2Payload {
  248|      0|                salt: [7; 32],
  249|      0|                genesis: BlockHash::from(3),
  250|      0|            }),
  251|      0|        };
  252|      0|        Self {
  253|      0|            query: None,
  254|      0|            response: Some(response),
  255|      0|            is_v2: true,
  256|      0|        }
  257|      0|    }
  258|       |}
  259|       |
  260|       |impl Serialize for NodeIdHandshake {
  261|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  262|      0|        if let Some(query) = &self.query {
  263|      0|            writer.write_bytes_safe(&query.cookie);
  264|      0|        }
  265|      0|        if let Some(response) = &self.response {
  266|      0|            response.serialize(writer);
  267|      0|        }
  268|      0|    }
  269|       |}
  270|       |
  271|       |impl MessageVariant for NodeIdHandshake {
  272|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
  273|      0|        let mut extensions = BitArray::default();
  274|      0|        extensions.set(NodeIdHandshake::QUERY_FLAG, self.query.is_some());
  275|      0|        extensions.set(NodeIdHandshake::RESPONSE_FLAG, self.response.is_some());
  276|      0|        extensions.set(Self::V2_FLAG, self.is_v2);
  277|      0|        extensions
  278|      0|    }
  279|       |}
  280|       |
  281|       |impl Display for NodeIdHandshake {
  282|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  283|      0|        if let Some(query) = &self.query {
  284|      0|            write!(f, "\ncookie=")?;
  285|      0|            write_hex_bytes(&query.cookie, f)?;
  286|      0|        }
  287|       |
  288|      0|        if let Some(response) = &self.response {
  289|      0|            write!(
  290|      0|                f,
  291|      0|                "\nresp_node_id={}\nresp_sig={}",
  292|      0|                response.node_id,
  293|      0|                response.signature.encode_hex()
  294|      0|            )?;
  295|      0|        }
  296|       |
  297|      0|        Ok(())
  298|      0|    }
  299|       |}
  300|       |
  301|       |#[cfg(test)]
  302|       |mod tests {
  303|       |    use super::*;
  304|       |    use crate::{assert_deserializable, Message};
  305|       |
  306|       |    #[test]
  307|       |    fn serialize_query() {
  308|       |        let message = Message::NodeIdHandshake(NodeIdHandshake::new_test_query());
  309|       |        assert_deserializable(&message);
  310|       |    }
  311|       |
  312|       |    #[test]
  313|       |    fn serialize_response_v1() {
  314|       |        let message = Message::NodeIdHandshake(NodeIdHandshake::new_test_response_v1());
  315|       |        assert_deserializable(&message);
  316|       |    }
  317|       |
  318|       |    #[test]
  319|       |    fn serialize_response_v2() {
  320|       |        let message = Message::NodeIdHandshake(NodeIdHandshake::new_test_response_v2());
  321|       |        assert_deserializable(&message);
  322|       |    }
  323|       |
  324|       |    #[test]
  325|       |    fn valid_v1_signature() {
  326|       |        let key = PrivateKey::new();
  327|       |        let mut response = NodeIdHandshakeResponse {
  328|       |            node_id: key.public_key().into(),
  329|       |            signature: Signature::default(),
  330|       |            v2: None,
  331|       |        };
  332|       |        let cookie = [42; 32];
  333|       |
  334|       |        response.sign(&cookie, &key);
  335|       |
  336|       |        assert_ne!(response.signature, Signature::default());
  337|       |        assert!(response.validate(&cookie).is_ok());
  338|       |
  339|       |        // invalid cookie
  340|       |        assert!(response.validate(&[1; 32]).is_err());
  341|       |
  342|       |        // invalid node_id
  343|       |        response.node_id = NodeId::from(1);
  344|       |        assert!(response.validate(&cookie).is_err());
  345|       |    }
  346|       |
  347|       |    #[test]
  348|       |    fn valid_v2_signature() {
  349|       |        let key = PrivateKey::new();
  350|       |        let mut response = NodeIdHandshakeResponse {
  351|       |            node_id: key.public_key().into(),
  352|       |            signature: Signature::default(),
  353|       |            v2: Some(V2Payload {
  354|       |                salt: [1; 32],
  355|       |                genesis: BlockHash::from(3),
  356|       |            }),
  357|       |        };
  358|       |        let cookie = [42; 32];
  359|       |
  360|       |        response.sign(&cookie, &key);
  361|       |
  362|       |        assert_ne!(response.signature, Signature::default());
  363|       |        assert!(response.validate(&cookie).is_ok());
  364|       |
  365|       |        // invalid cookie
  366|       |        assert!(response.validate(&[1; 32]).is_err());
  367|       |
  368|       |        // invalid node_id
  369|       |        let mut copy = response.clone();
  370|       |        copy.node_id = NodeId::from(1);
  371|       |        assert!(copy.validate(&cookie).is_err());
  372|       |
  373|       |        // invalid salt
  374|       |        let mut copy = response.clone();
  375|       |        copy.v2.as_mut().unwrap().salt = [100; 32];
  376|       |        assert!(copy.validate(&cookie).is_err());
  377|       |
  378|       |        // invalid genesis
  379|       |        let mut copy = response.clone();
  380|       |        copy.v2.as_mut().unwrap().genesis = BlockHash::from(123);
  381|       |        assert!(copy.validate(&cookie).is_err());
  382|       |    }
  383|       |}

/home/gustav/code/nano/rsnano-node/messages/src/publish.rs:
    1|       |use super::MessageVariant;
    2|       |use bitvec::prelude::BitArray;
    3|       |use num_traits::FromPrimitive;
    4|       |use rsnano_core::{
    5|       |    serialized_block_size,
    6|       |    utils::{BufferWriter, Serialize, Stream},
    7|       |    Block, BlockType,
    8|       |};
    9|       |use serde_derive::Serialize;
   10|       |use std::fmt::{Debug, Display};
   11|       |
   12|       |#[derive(Clone, Eq, Serialize, Debug)]
   13|       |#[serde(rename_all = "snake_case")]
   14|       |pub struct Publish {
   15|       |    pub block: Block,
   16|       |
   17|       |    /// Messages deserialized from network should have their digest set
   18|       |    #[serde(skip_serializing)]
   19|       |    pub digest: u128,
   20|       |
   21|       |    pub is_originator: bool,
   22|       |}
   23|       |
   24|       |impl Publish {
   25|       |    const BLOCK_TYPE_MASK: u16 = 0x0f00;
   26|       |    const ORIGINATOR_FLAG: u16 = 1 << 2;
   27|       |
   28|      0|    pub fn new_from_originator(block: Block) -> Self {
   29|      0|        Self {
   30|      0|            block,
   31|      0|            digest: 0,
   32|      0|            is_originator: true,
   33|      0|        }
   34|      0|    }
   35|       |
   36|      0|    pub fn new_forward(block: Block) -> Self {
   37|      0|        Self {
   38|      0|            block,
   39|      0|            digest: 0,
   40|      0|            is_originator: false,
   41|      0|        }
   42|      0|    }
   43|       |
   44|      0|    pub fn new_test_instance() -> Self {
   45|      0|        Self {
   46|      0|            block: Block::new_test_instance(),
   47|      0|            digest: 0,
   48|      0|            is_originator: true,
   49|      0|        }
   50|      0|    }
   51|       |
   52|      0|    pub fn deserialize(
   53|      0|        stream: &mut impl Stream,
   54|      0|        extensions: BitArray<u16>,
   55|      0|        digest: u128,
   56|      0|    ) -> Option<Self> {
   57|      0|        let payload = Publish {
   58|      0|            block: Block::deserialize_block_type(Self::block_type(extensions), stream).ok()?,
   59|      0|            digest,
   60|      0|            is_originator: extensions.data & Self::ORIGINATOR_FLAG > 0,
   61|      0|        };
   62|      0|
   63|      0|        Some(payload)
   64|      0|    }
   65|       |
   66|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
   67|      0|        serialized_block_size(Self::block_type(extensions))
   68|      0|    }
   69|       |
   70|      0|    fn block_type(extensions: BitArray<u16>) -> BlockType {
   71|      0|        let mut value = extensions & BitArray::new(Self::BLOCK_TYPE_MASK);
   72|      0|        value.shift_left(8);
   73|      0|        FromPrimitive::from_u16(value.data).unwrap_or(BlockType::Invalid)
   74|      0|    }
   75|       |}
   76|       |
   77|       |impl PartialEq for Publish {
   78|      0|    fn eq(&self, other: &Self) -> bool {
   79|      0|        self.block == other.block
   80|      0|    }
   81|       |}
   82|       |
   83|       |impl Serialize for Publish {
   84|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   85|      0|        self.block.serialize_without_block_type(writer);
   86|      0|    }
   87|       |}
   88|       |
   89|       |impl MessageVariant for Publish {
   90|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
   91|      0|        let mut flags = (self.block.block_type() as u16) << 8;
   92|      0|        if self.is_originator {
   93|      0|            flags |= Self::ORIGINATOR_FLAG;
   94|      0|        }
   95|      0|        BitArray::new(flags)
   96|      0|    }
   97|       |}
   98|       |
   99|       |impl Display for Publish {
  100|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  101|      0|        write!(
  102|      0|            f,
  103|      0|            "\n{}",
  104|      0|            self.block.to_json().map_err(|_| std::fmt::Error)?
  105|       |        )
  106|      0|    }
  107|       |}
  108|       |
  109|       |#[cfg(test)]
  110|       |mod tests {
  111|       |    use super::*;
  112|       |    use rsnano_core::{utils::MemoryStream, TestBlockBuilder};
  113|       |
  114|       |    #[test]
  115|       |    fn create_from_originator() {
  116|       |        let publish = Publish::new_from_originator(Block::new_test_instance());
  117|       |        assert_eq!(publish.is_originator, true)
  118|       |    }
  119|       |
  120|       |    #[test]
  121|       |    fn create_forward() {
  122|       |        let publish = Publish::new_forward(Block::new_test_instance());
  123|       |        assert_eq!(publish.is_originator, false);
  124|       |    }
  125|       |
  126|       |    #[test]
  127|       |    fn originator_flag_in_header() {
  128|       |        let publish = Publish::new_from_originator(Block::new_test_instance());
  129|       |        let flags = publish.header_extensions(0);
  130|       |        assert!(flags.data & Publish::ORIGINATOR_FLAG > 0);
  131|       |    }
  132|       |
  133|       |    #[test]
  134|       |    fn originator_flag_not_in_header() {
  135|       |        let publish = Publish::new_forward(Block::new_test_instance());
  136|       |        let flags = publish.header_extensions(0);
  137|       |        assert_eq!(flags.data & Publish::ORIGINATOR_FLAG, 0);
  138|       |    }
  139|       |
  140|       |    #[test]
  141|       |    fn serialize() {
  142|       |        let block = TestBlockBuilder::state().build();
  143|       |        let mut publish1 = Publish::new_from_originator(block);
  144|       |        publish1.digest = 123;
  145|       |
  146|       |        let mut stream = MemoryStream::new();
  147|       |        publish1.serialize(&mut stream);
  148|       |
  149|       |        let extensions = publish1.header_extensions(0);
  150|       |        let publish2 = Publish::deserialize(&mut stream, extensions, 123).unwrap();
  151|       |        assert_eq!(publish1, publish2);
  152|       |    }
  153|       |}

/home/gustav/code/nano/rsnano-node/messages/src/telemetry_ack.rs:
    1|       |use super::MessageVariant;
    2|       |use anyhow::Result;
    3|       |use bitvec::prelude::BitArray;
    4|       |use rsnano_core::utils::{
    5|       |    BufferWriter, Deserialize, FixedSizeSerialize, MemoryStream, Serialize, Stream, StreamExt,
    6|       |};
    7|       |use rsnano_core::{to_hex_string, Account, BlockHash, NodeId, PrivateKey, Signature};
    8|       |use serde_derive::Serialize;
    9|       |use std::fmt::Display;
   10|       |use std::mem::size_of;
   11|       |use std::time::{Duration, SystemTime};
   12|       |
   13|       |#[repr(u8)]
   14|      0|#[derive(FromPrimitive, Copy, Clone, PartialEq, Eq)]
   15|       |pub enum TelemetryMaker {
   16|       |    NfNode = 0,
   17|       |    NfPrunedNode = 1,
   18|       |    NanoNodeLight = 2,
   19|       |    RsNano = 3,
   20|       |}
   21|       |
   22|       |#[derive(Clone, PartialEq, Eq, Debug)]
   23|       |pub struct TelemetryData {
   24|       |    pub signature: Signature,
   25|       |    pub node_id: NodeId,
   26|       |    pub block_count: u64,
   27|       |    pub cemented_count: u64,
   28|       |    pub unchecked_count: u64,
   29|       |    pub account_count: u64,
   30|       |    pub bandwidth_cap: u64,
   31|       |    pub uptime: u64,
   32|       |    pub peer_count: u32,
   33|       |    pub protocol_version: u8,
   34|       |    pub genesis_block: BlockHash,
   35|       |    pub major_version: u8,
   36|       |    pub minor_version: u8,
   37|       |    pub patch_version: u8,
   38|       |    pub pre_release_version: u8,
   39|       |    pub maker: u8, // Where this telemetry information originated
   40|       |    pub timestamp: SystemTime,
   41|       |    pub active_difficulty: u64,
   42|       |    pub unknown_data: Vec<u8>,
   43|       |}
   44|       |
   45|       |impl TelemetryData {
   46|       |    pub const SIZE_MASK: u16 = 0x3ff;
   47|       |
   48|      0|    pub fn new() -> Self {
   49|      0|        Self {
   50|      0|            signature: Signature::new(),
   51|      0|            node_id: NodeId::ZERO,
   52|      0|            block_count: 0,
   53|      0|            cemented_count: 0,
   54|      0|            unchecked_count: 0,
   55|      0|            account_count: 0,
   56|      0|            bandwidth_cap: 0,
   57|      0|            uptime: 0,
   58|      0|            peer_count: 0,
   59|      0|            protocol_version: 0,
   60|      0|            genesis_block: BlockHash::zero(),
   61|      0|            major_version: 0,
   62|      0|            minor_version: 0,
   63|      0|            patch_version: 0,
   64|      0|            pre_release_version: 0,
   65|      0|            maker: TelemetryMaker::RsNano as u8,
   66|      0|            timestamp: SystemTime::UNIX_EPOCH,
   67|      0|            active_difficulty: 0,
   68|      0|            unknown_data: Vec::new(),
   69|      0|        }
   70|      0|    }
   71|       |
   72|      0|    pub fn new_test_instance() -> Self {
   73|      0|        let mut data = TelemetryData::new();
   74|      0|        data.node_id = NodeId::from(42);
   75|      0|        data.major_version = 20;
   76|      0|        data.minor_version = 1;
   77|      0|        data.patch_version = 5;
   78|      0|        data.pre_release_version = 2;
   79|      0|        data.maker = TelemetryMaker::RsNano as u8;
   80|      0|        data.timestamp = SystemTime::UNIX_EPOCH + Duration::from_millis(100);
   81|      0|        data
   82|      0|    }
   83|       |
   84|       |    /// Size does not include unknown_data
   85|      0|    pub fn serialized_size_of_known_data() -> usize {
   86|      0|        Signature::serialized_size()
   87|      0|        + Account::serialized_size() // node id
   88|      0|        + size_of::<u64>() //block_count
   89|      0|          + size_of::<u64>()// cemented_count 
   90|      0|          + size_of::<u64>() // unchecked_count 
   91|      0|          + size_of::<u64>() // account_count 
   92|      0|          + size_of::<u64>() // bandwidth_cap 
   93|      0|          + size_of::<u32>() // peer_count
   94|      0|          + size_of::<u8>() // protocol_version
   95|      0|          + size_of::<u64>() // uptime 
   96|      0|          + BlockHash::serialized_size()
   97|      0|          + size_of::<u8>() // major_version 
   98|      0|          + size_of::<u8>() // minor_version 
   99|      0|          + size_of::<u8>() // patch_version 
  100|      0|          + size_of::<u8>() // pre_release_version 
  101|      0|          + size_of::<u8>() // maker 
  102|      0|          + size_of::<u64>() // timestamp 
  103|      0|          + size_of::<u64>() //active_difficulty)
  104|      0|    }
  105|       |
  106|      3|    pub fn serialize_without_signature(&self, writer: &mut dyn BufferWriter) {
  107|      3|        // All values should be serialized in big endian
  108|      3|        self.node_id.serialize(writer);
  109|      3|        writer.write_u64_be_safe(self.block_count);
  110|      3|        writer.write_u64_be_safe(self.cemented_count);
  111|      3|        writer.write_u64_be_safe(self.unchecked_count);
  112|      3|        writer.write_u64_be_safe(self.account_count);
  113|      3|        writer.write_u64_be_safe(self.bandwidth_cap);
  114|      3|        writer.write_u32_be_safe(self.peer_count);
  115|      3|        writer.write_u8_safe(self.protocol_version);
  116|      3|        writer.write_u64_be_safe(self.uptime);
  117|      3|        self.genesis_block.serialize(writer);
  118|      3|        writer.write_u8_safe(self.major_version);
  119|      3|        writer.write_u8_safe(self.minor_version);
  120|      3|        writer.write_u8_safe(self.patch_version);
  121|      3|        writer.write_u8_safe(self.pre_release_version);
  122|      3|        writer.write_u8_safe(self.maker);
  123|      3|        writer.write_u64_be_safe(
  124|      3|            self.timestamp
  125|      3|                .duration_since(SystemTime::UNIX_EPOCH)
  126|      3|                .unwrap()
  127|      3|                .as_millis() as u64,
  128|      3|        );
  129|      3|        writer.write_u64_be_safe(self.active_difficulty);
  130|      3|        writer.write_bytes_safe(&self.unknown_data);
  131|      3|    }
  132|       |
  133|      0|    pub fn deserialize(stream: &mut dyn Stream, payload_len: usize) -> anyhow::Result<Self> {
  134|      0|        let signature = Signature::deserialize(stream)?;
  135|      0|        let node_id = NodeId::deserialize(stream)?;
  136|      0|        let block_count = stream.read_u64_be()?;
  137|      0|        let cemented_count = stream.read_u64_be()?;
  138|      0|        let unchecked_count = stream.read_u64_be()?;
  139|      0|        let account_count = stream.read_u64_be()?;
  140|      0|        let bandwidth_cap = stream.read_u64_be()?;
  141|      0|        let peer_count = stream.read_u32_be()?;
  142|      0|        let protocol_version = stream.read_u8()?;
  143|      0|        let uptime = stream.read_u64_be()?;
  144|      0|        let genesis_block = BlockHash::deserialize(stream)?;
  145|      0|        let major_version = stream.read_u8()?;
  146|      0|        let minor_version = stream.read_u8()?;
  147|      0|        let patch_version = stream.read_u8()?;
  148|      0|        let pre_release_version = stream.read_u8()?;
  149|      0|        let maker = stream.read_u8()?;
  150|      0|        let timestamp_ms = stream.read_u64_be()?;
  151|      0|        let active_difficulty = stream.read_u64_be()?;
  152|      0|        let mut unknown_data = Vec::new();
  153|      0|        if payload_len as usize > TelemetryData::serialized_size_of_known_data() {
  154|      0|            let unknown_len =
  155|      0|                (payload_len as usize) - TelemetryData::serialized_size_of_known_data();
  156|      0|            unknown_data.resize(unknown_len, 0);
  157|      0|            stream.read_bytes(&mut unknown_data, unknown_len)?;
  158|      0|        }
  159|       |
  160|      0|        let data = TelemetryData {
  161|      0|            signature,
  162|      0|            node_id,
  163|      0|            block_count,
  164|      0|            cemented_count,
  165|      0|            unchecked_count,
  166|      0|            account_count,
  167|      0|            bandwidth_cap,
  168|      0|            peer_count,
  169|      0|            protocol_version,
  170|      0|            uptime,
  171|      0|            genesis_block,
  172|      0|            major_version,
  173|      0|            minor_version,
  174|      0|            patch_version,
  175|      0|            pre_release_version,
  176|      0|            maker,
  177|      0|            timestamp: SystemTime::UNIX_EPOCH + Duration::from_millis(timestamp_ms),
  178|      0|            active_difficulty,
  179|      0|            unknown_data,
  180|      0|        };
  181|      0|
  182|      0|        Ok(data)
  183|      0|    }
  184|       |
  185|      3|    pub fn sign(&mut self, key: &PrivateKey) -> Result<()> {
  186|      3|        debug_assert!(key.public_key() == self.node_id.into());
  187|      3|        let mut stream = MemoryStream::new();
  188|      3|        self.serialize_without_signature(&mut stream);
  189|      3|        self.signature = key.sign(stream.as_bytes());
  190|      3|        Ok(())
  191|      3|    }
  192|       |
  193|      0|    pub fn validate_signature(&self) -> bool {
  194|      0|        let mut stream = MemoryStream::new();
  195|      0|        self.serialize_without_signature(&mut stream);
  196|      0|        self.node_id
  197|      0|            .as_key()
  198|      0|            .verify(stream.as_bytes(), &self.signature)
  199|      0|            .is_ok()
  200|      0|    }
  201|       |
  202|      0|    pub fn to_json(&self) -> serde_json::Result<String> {
  203|      0|        let ignore_identification_metrics = true;
  204|      0|        let json_dto = TelemetryDataJsonDto {
  205|      0|            block_count: self.block_count.to_string(),
  206|      0|            cemented_count: self.cemented_count.to_string(),
  207|      0|            unchecked_count: self.unchecked_count.to_string(),
  208|      0|            account_count: self.account_count.to_string(),
  209|      0|            bandwidth_cap: self.bandwidth_cap.to_string(),
  210|      0|            peer_count: self.peer_count.to_string(),
  211|      0|            protocol_version: self.protocol_version.to_string(),
  212|      0|            uptime: self.uptime.to_string(),
  213|      0|            genesis_block: self.genesis_block.to_string(),
  214|      0|            major_version: self.major_version.to_string(),
  215|      0|            minor_version: self.minor_version.to_string(),
  216|      0|            patch_version: self.patch_version.to_string(),
  217|      0|            pre_release_version: self.pre_release_version.to_string(),
  218|      0|            maker: self.maker.to_string(),
  219|      0|            timestamp: self
  220|      0|                .timestamp
  221|      0|                .duration_since(SystemTime::UNIX_EPOCH)
  222|      0|                .unwrap_or_default()
  223|      0|                .as_millis()
  224|      0|                .to_string(),
  225|      0|            active_difficulty: to_hex_string(self.active_difficulty),
  226|      0|            node_id: if !ignore_identification_metrics {
  227|      0|                Some(self.node_id.to_string())
  228|       |            } else {
  229|      0|                None
  230|       |            },
  231|      0|            signature: if !ignore_identification_metrics {
  232|      0|                Some(self.signature.encode_hex())
  233|       |            } else {
  234|      0|                None
  235|       |            },
  236|       |        };
  237|       |
  238|      0|        serde_json::to_string_pretty(&json_dto)
  239|      0|    }
  240|       |}
  241|       |
  242|       |#[derive(Debug, Clone, PartialEq, Eq)]
  243|       |pub struct TelemetryAck(pub Option<TelemetryData>);
  244|       |
  245|       |impl TelemetryAck {
  246|      0|    pub fn new_test_instance() -> Self {
  247|      0|        Self(Some(TelemetryData::new_test_instance()))
  248|      0|    }
  249|       |
  250|      0|    pub fn serialized_size(extensions: BitArray<u16>) -> usize {
  251|      0|        (extensions.data & TelemetryData::SIZE_MASK) as usize
  252|      0|    }
  253|       |
  254|      0|    pub fn deserialize(stream: &mut dyn Stream, extensions: BitArray<u16>) -> Option<Self> {
  255|      0|        let payload_length = Self::serialized_size(extensions);
  256|      0|        if payload_length == 0 {
  257|      0|            return Some(Self(None));
  258|      0|        }
  259|       |
  260|      0|        let result = TelemetryData::deserialize(stream, payload_length).ok()?;
  261|       |
  262|      0|        Some(Self(Some(result)))
  263|      0|    }
  264|       |}
  265|       |
  266|       |impl Display for TelemetryAck {
  267|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  268|      0|        write!(f, "telemetry_ack")
  269|      0|    }
  270|       |}
  271|       |
  272|       |impl Serialize for TelemetryAck {
  273|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
  274|      0|        if let Some(data) = &self.0 {
  275|      0|            data.signature.serialize(writer);
  276|      0|            data.serialize_without_signature(writer);
  277|      0|        }
  278|      0|    }
  279|       |}
  280|       |
  281|       |impl MessageVariant for TelemetryAck {
  282|      0|    fn header_extensions(&self, _payload_len: u16) -> BitArray<u16> {
  283|      0|        match &self.0 {
  284|      0|            Some(data) => BitArray::new(
  285|      0|                TelemetryData::serialized_size_of_known_data() as u16
  286|      0|                    + data.unknown_data.len() as u16,
  287|      0|            ),
  288|      0|            None => Default::default(),
  289|       |        }
  290|      0|    }
  291|       |}
  292|       |
  293|       |#[derive(Serialize)]
  294|       |struct TelemetryDataJsonDto {
  295|       |    pub block_count: String,
  296|       |    pub cemented_count: String,
  297|       |    pub unchecked_count: String,
  298|       |    pub account_count: String,
  299|       |    pub bandwidth_cap: String,
  300|       |    pub peer_count: String,
  301|       |    pub protocol_version: String,
  302|       |    pub uptime: String,
  303|       |    pub genesis_block: String,
  304|       |    pub major_version: String,
  305|       |    pub minor_version: String,
  306|       |    pub patch_version: String,
  307|       |    pub pre_release_version: String,
  308|       |    pub maker: String,
  309|       |    pub timestamp: String,
  310|       |    pub active_difficulty: String,
  311|       |    // Keep these last for UI purposes:
  312|       |    #[serde(skip_serializing_if = "Option::is_none")]
  313|       |    pub node_id: Option<String>,
  314|       |    #[serde(skip_serializing_if = "Option::is_none")]
  315|       |    pub signature: Option<String>,
  316|       |}
  317|       |
  318|       |impl Default for TelemetryData {
  319|      0|    fn default() -> Self {
  320|      0|        Self::new()
  321|      0|    }
  322|       |}
  323|       |
  324|       |impl Display for TelemetryData {
  325|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  326|      0|        writeln!(f)?;
  327|      0|        write!(f, "{}", self.to_json().map_err(|_| std::fmt::Error)?)?;
  328|      0|        Ok(())
  329|      0|    }
  330|       |}
  331|       |
  332|       |#[cfg(test)]
  333|       |mod tests {
  334|       |    use super::*;
  335|       |    use crate::{assert_deserializable, Message};
  336|       |
  337|       |    #[test]
  338|       |    fn serialized_size() {
  339|       |        assert_eq!(TelemetryData::serialized_size_of_known_data(), 202);
  340|       |    }
  341|       |
  342|       |    // original test: telemetry.signatures
  343|       |    #[test]
  344|       |    fn sign_telemetry_data() -> Result<()> {
  345|       |        let keys = PrivateKey::new();
  346|       |        let mut data = test_data(&keys);
  347|       |        data.sign(&keys)?;
  348|       |        assert_eq!(data.validate_signature(), true);
  349|       |
  350|       |        let old_signature = data.signature.clone();
  351|       |        // Check that the signature is different if changing a piece of data
  352|       |        data.maker = 2;
  353|       |        data.sign(&keys)?;
  354|       |        assert_ne!(old_signature, data.signature);
  355|       |        Ok(())
  356|       |    }
  357|       |
  358|       |    //original test: telemetry.unknown_data
  359|       |    #[test]
  360|       |    fn sign_with_unknown_data() -> Result<()> {
  361|       |        let keys = PrivateKey::new();
  362|       |        let mut data = test_data(&keys);
  363|       |        data.unknown_data = vec![1];
  364|       |        data.sign(&keys)?;
  365|       |        assert_eq!(data.validate_signature(), true);
  366|       |        Ok(())
  367|       |    }
  368|       |
  369|       |    #[test]
  370|       |    fn max_possible_size() {
  371|       |        let keys = PrivateKey::new();
  372|       |        let mut data = test_data(&keys);
  373|       |        data.unknown_data = vec![
  374|       |            1;
  375|       |            TelemetryData::SIZE_MASK as usize
  376|       |                - TelemetryData::serialized_size_of_known_data()
  377|       |        ];
  378|       |
  379|       |        assert_deserializable(&Message::TelemetryAck(TelemetryAck(Some(data))));
  380|       |    }
  381|       |
  382|       |    fn test_data(keys: &PrivateKey) -> TelemetryData {
  383|       |        let mut data = TelemetryData::new();
  384|       |        data.node_id = keys.public_key().into();
  385|       |        data.major_version = 20;
  386|       |        data.minor_version = 1;
  387|       |        data.patch_version = 5;
  388|       |        data.pre_release_version = 2;
  389|       |        data.maker = 1;
  390|       |        data.timestamp = SystemTime::UNIX_EPOCH + Duration::from_millis(100);
  391|       |        data
  392|       |    }
  393|       |}

/home/gustav/code/nano/rsnano-node/network/src/attempt_container.rs:
    1|       |use crate::{
    2|       |    utils::{ipv4_address_or_ipv6_subnet, map_address_to_subnetwork},
    3|       |    ChannelDirection,
    4|       |};
    5|       |use rsnano_nullable_clock::Timestamp;
    6|       |use std::{
    7|       |    collections::HashMap,
    8|       |    net::{Ipv6Addr, SocketAddrV6},
    9|       |    time::Duration,
   10|       |};
   11|       |
   12|       |struct Entry {
   13|       |    endpoint: SocketAddrV6,
   14|       |    address: Ipv6Addr,
   15|       |    subnetwork: Ipv6Addr,
   16|       |    start: Timestamp,
   17|       |    direction: ChannelDirection,
   18|       |}
   19|       |
   20|       |impl Entry {
   21|     11|    fn new(endpoint: SocketAddrV6, direction: ChannelDirection, start: Timestamp) -> Self {
   22|     11|        Self {
   23|     11|            endpoint,
   24|     11|            address: ipv4_address_or_ipv6_subnet(endpoint.ip()),
   25|     11|            subnetwork: map_address_to_subnetwork(endpoint.ip()),
   26|     11|            start,
   27|     11|            direction,
   28|     11|        }
   29|     11|    }
   30|       |}
   31|       |
   32|       |/// Keeps track of running connection attempts
   33|       |#[derive(Default)]
   34|       |pub struct AttemptContainer {
   35|       |    by_endpoint: HashMap<SocketAddrV6, Entry>,
   36|       |    by_address: HashMap<Ipv6Addr, Vec<SocketAddrV6>>,
   37|       |    by_subnetwork: HashMap<Ipv6Addr, Vec<SocketAddrV6>>,
   38|       |}
   39|       |
   40|       |impl AttemptContainer {
   41|     11|    pub fn insert(
   42|     11|        &mut self,
   43|     11|        endpoint: SocketAddrV6,
   44|     11|        direction: ChannelDirection,
   45|     11|        start: Timestamp,
   46|     11|    ) -> bool {
   47|     11|        if self.by_endpoint.contains_key(&endpoint) {
   48|      0|            return false;
   49|     11|        }
   50|     11|
   51|     11|        let attempt = Entry::new(endpoint, direction, start);
   52|     11|        self.by_address
   53|     11|            .entry(attempt.address)
   54|     11|            .or_default()
   55|     11|            .push(attempt.endpoint);
   56|     11|        self.by_subnetwork
   57|     11|            .entry(attempt.subnetwork)
   58|     11|            .or_default()
   59|     11|            .push(attempt.endpoint);
   60|     11|        self.by_endpoint.insert(attempt.endpoint, attempt);
   61|     11|        true
   62|     11|    }
   63|       |
   64|      0|    pub fn remove(&mut self, endpoint: &SocketAddrV6) {
   65|      0|        if let Some(attempt) = self.by_endpoint.remove(endpoint) {
   66|      0|            let by_address = self.by_address.get_mut(&attempt.address).unwrap();
   67|      0|            if by_address.len() > 1 {
   68|      0|                by_address.retain(|x| x != endpoint);
   69|      0|            } else {
   70|      0|                self.by_address.remove(&attempt.address);
   71|      0|            }
   72|       |
   73|      0|            let by_subnet = self.by_subnetwork.get_mut(&attempt.subnetwork).unwrap();
   74|      0|            if by_subnet.len() > 1 {
   75|      0|                by_subnet.retain(|x| x != endpoint);
   76|      0|            } else {
   77|      0|                self.by_subnetwork.remove(&attempt.subnetwork);
   78|      0|            }
   79|      0|        }
   80|      0|    }
   81|       |
   82|     23|    pub fn count_by_subnetwork(&self, subnet: &Ipv6Addr) -> usize {
   83|     23|        // TODO use map_address_to_subnetwork
   84|     23|        match self.by_subnetwork.get(subnet) {
   85|     11|            Some(entries) => entries.len(),
   86|     12|            None => 0,
   87|       |        }
   88|     23|    }
   89|       |
   90|     31|    pub fn count_by_address(&self, address: &Ipv6Addr) -> usize {
   91|     31|        // TODO use ipv4_address_or_ipv6_subnet!
   92|     31|        match self.by_address.get(address) {
   93|      4|            Some(entries) => entries.len(),
   94|     27|            None => 0,
   95|       |        }
   96|     31|    }
   97|       |
   98|      0|    pub fn len(&self) -> usize {
   99|      0|        self.by_endpoint.len()
  100|      0|    }
  101|       |
  102|      0|    pub fn purge(&mut self, now: Timestamp, timeout: Duration) {
  103|      0|        while let Some((time, endpoint)) = self.get_oldest() {
  104|      0|            if now - time < timeout {
  105|      0|                return;
  106|      0|            }
  107|      0|
  108|      0|            self.remove(&endpoint);
  109|       |        }
  110|      0|    }
  111|       |
  112|      0|    fn get_oldest(&self) -> Option<(Timestamp, SocketAddrV6)> {
  113|      0|        self.by_endpoint
  114|      0|            .values()
  115|      0|            .filter(|i| i.direction == ChannelDirection::Outbound)
  116|      0|            .min_by_key(|i| i.start)
  117|      0|            .map(|i| (i.start, i.endpoint))
  118|      0|    }
  119|       |
  120|       |    pub const ELEMENT_SIZE: usize = std::mem::size_of::<Entry>();
  121|       |}

/home/gustav/code/nano/rsnano-node/network/src/bandwidth_limiter.rs:
    1|       |use rsnano_core::utils::ContainerInfo;
    2|       |
    3|       |use crate::{token_bucket::TokenBucket, TrafficType};
    4|       |use std::sync::Mutex;
    5|       |
    6|       |pub struct RateLimiter {
    7|       |    bucket: Mutex<TokenBucket>,
    8|       |}
    9|       |
   10|       |impl RateLimiter {
   11|     15|    pub fn new(limit: usize) -> Self {
   12|     15|        Self::with_burst_ratio(limit, 1.0)
   13|     15|    }
   14|       |
   15|     64|    pub fn with_burst_ratio(limit: usize, limit_burst_ratio: f64) -> Self {
   16|     64|        Self {
   17|     64|            bucket: Mutex::new(TokenBucket::new(
   18|     64|                (limit as f64 * limit_burst_ratio) as usize,
   19|     64|                limit,
   20|     64|            )),
   21|     64|        }
   22|     64|    }
   23|       |
   24|     54|    pub fn should_pass(&self, message_size: usize) -> bool {
   25|     54|        self.bucket.lock().unwrap().try_consume(message_size)
   26|     54|    }
   27|       |
   28|      0|    pub fn reset(&self, limit_burst_ratio: f64, limit: usize) {
   29|      0|        self.bucket
   30|      0|            .lock()
   31|      0|            .unwrap()
   32|      0|            .reset((limit as f64 * limit_burst_ratio) as usize, limit)
   33|      0|    }
   34|       |
   35|      0|    pub fn size(&self) -> usize {
   36|      0|        self.bucket.lock().unwrap().size()
   37|      0|    }
   38|       |}
   39|       |
   40|       |#[derive(Clone)]
   41|       |pub struct BandwidthLimiterConfig {
   42|       |    pub generic_limit: usize,
   43|       |    pub generic_burst_ratio: f64,
   44|       |
   45|       |    pub bootstrap_limit: usize,
   46|       |    pub bootstrap_burst_ratio: f64,
   47|       |}
   48|       |
   49|       |impl Default for BandwidthLimiterConfig {
   50|     20|    fn default() -> Self {
   51|     20|        Self {
   52|     20|            generic_limit: 10 * 1024 * 1024,
   53|     20|            generic_burst_ratio: 3_f64,
   54|     20|            bootstrap_limit: 5 * 1024 * 1024,
   55|     20|            bootstrap_burst_ratio: 1_f64,
   56|     20|        }
   57|     20|    }
   58|       |}
   59|       |
   60|       |pub struct BandwidthLimiter {
   61|       |    limiter_generic: RateLimiter,
   62|       |    limiter_bootstrap: RateLimiter,
   63|       |}
   64|       |
   65|       |impl BandwidthLimiter {
   66|     23|    pub fn new(config: BandwidthLimiterConfig) -> Self {
   67|     23|        Self {
   68|     23|            limiter_generic: RateLimiter::with_burst_ratio(
   69|     23|                config.generic_limit,
   70|     23|                config.generic_burst_ratio,
   71|     23|            ),
   72|     23|            limiter_bootstrap: RateLimiter::with_burst_ratio(
   73|     23|                config.bootstrap_limit,
   74|     23|                config.bootstrap_burst_ratio,
   75|     23|            ),
   76|     23|        }
   77|     23|    }
   78|       |
   79|       |    /**
   80|       |     * Check whether packet falls withing bandwidth limits and should be allowed
   81|       |     * @return true if OK, false if needs to be dropped
   82|       |     */
   83|      0|    pub fn should_pass(&self, buffer_size: usize, limit_type: TrafficType) -> bool {
   84|      0|        self.select_limiter(limit_type).should_pass(buffer_size)
   85|      0|    }
   86|       |
   87|      0|    pub fn reset(&self, limit: usize, burst_ratio: f64, limit_type: TrafficType) {
   88|      0|        self.select_limiter(limit_type).reset(burst_ratio, limit);
   89|      0|    }
   90|       |
   91|      0|    fn select_limiter(&self, limit_type: TrafficType) -> &RateLimiter {
   92|      0|        match limit_type {
   93|      0|            TrafficType::BootstrapServer => &self.limiter_bootstrap,
   94|      0|            _ => &self.limiter_generic,
   95|       |        }
   96|      0|    }
   97|       |
   98|      0|    pub fn container_info(&self) -> ContainerInfo {
   99|      0|        [
  100|      0|            ("generic", self.limiter_generic.size(), 0),
  101|      0|            ("bootstrap", self.limiter_bootstrap.size(), 0),
  102|      0|        ]
  103|      0|        .into()
  104|      0|    }
  105|       |}
  106|       |
  107|       |impl Default for BandwidthLimiter {
  108|      1|    fn default() -> Self {
  109|      1|        Self::new(Default::default())
  110|      1|    }
  111|       |}
  112|       |
  113|       |#[cfg(test)]
  114|       |mod tests {
  115|       |    use super::*;
  116|       |    use mock_instant::thread_local::MockClock;
  117|       |    use std::time::Duration;
  118|       |
  119|       |    #[test]
  120|       |    fn test_limit() {
  121|       |        let limiter = RateLimiter::with_burst_ratio(10, 1.5);
  122|       |        assert_eq!(limiter.should_pass(15), true);
  123|       |        assert_eq!(limiter.should_pass(1), false);
  124|       |        MockClock::advance(Duration::from_millis(100));
  125|       |        assert_eq!(limiter.should_pass(1), true);
  126|       |        assert_eq!(limiter.should_pass(1), false);
  127|       |    }
  128|       |}

/home/gustav/code/nano/rsnano-node/network/src/channel.rs:
    1|       |use num_traits::FromPrimitive;
    2|       |use rsnano_core::{
    3|       |    utils::{TEST_ENDPOINT_1, TEST_ENDPOINT_2},
    4|       |    NodeId,
    5|       |};
    6|       |use rsnano_nullable_clock::Timestamp;
    7|       |use std::{
    8|       |    net::{Ipv6Addr, SocketAddrV6},
    9|       |    sync::{
   10|       |        atomic::{AtomicBool, AtomicI64, AtomicU64, AtomicU8, Ordering},
   11|       |        Arc, Mutex,
   12|       |    },
   13|       |    time::Duration,
   14|       |};
   15|       |use tokio_util::sync::{CancellationToken, WaitForCancellationFuture};
   16|       |
   17|       |use crate::{
   18|       |    bandwidth_limiter::BandwidthLimiter,
   19|       |    utils::{ipv4_address_or_ipv6_subnet, map_address_to_subnetwork},
   20|       |    write_queue::{Entry, WriteQueue},
   21|       |    ChannelDirection, ChannelId, ChannelMode, NetworkObserver, NullNetworkObserver, TrafficType,
   22|       |};
   23|       |
   24|       |/// Default timeout in seconds
   25|       |const DEFAULT_TIMEOUT: u64 = 120;
   26|       |
   27|       |pub struct Channel {
   28|       |    channel_id: ChannelId,
   29|       |    local_addr: SocketAddrV6,
   30|       |    peer_addr: SocketAddrV6,
   31|       |    data: Mutex<PeerInfo>,
   32|       |    protocol_version: AtomicU8,
   33|       |    direction: ChannelDirection,
   34|       |
   35|       |    /// the timestamp (in seconds since epoch) of the last time there was successful activity on the socket
   36|       |    last_activity: AtomicI64,
   37|       |    last_bootstrap_attempt: AtomicI64,
   38|       |
   39|       |    /// Duration in seconds of inactivity that causes a socket timeout
   40|       |    /// activity is any successful connect, send or receive event
   41|       |    timeout_seconds: AtomicU64,
   42|       |
   43|       |    /// Flag that is set when cleanup decides to close the socket due to timeout.
   44|       |    /// NOTE: Currently used by tcp_server::timeout() but I suspect that this and tcp_server::timeout() are not needed.
   45|       |    timed_out: AtomicBool,
   46|       |
   47|       |    /// Set by close() - completion handlers must check this. This is more reliable than checking
   48|       |    /// error codes as the OS may have already completed the async operation.
   49|       |    closed: AtomicBool,
   50|       |
   51|       |    socket_type: AtomicU8,
   52|       |    write_queue: WriteQueue,
   53|       |    cancel_token: CancellationToken,
   54|       |    limiter: Arc<BandwidthLimiter>,
   55|       |    observer: Arc<dyn NetworkObserver>,
   56|       |}
   57|       |
   58|       |impl Channel {
   59|       |    const MAX_QUEUE_SIZE: usize = 64;
   60|       |
   61|     10|    pub fn new(
   62|     10|        channel_id: ChannelId,
   63|     10|        local_addr: SocketAddrV6,
   64|     10|        peer_addr: SocketAddrV6,
   65|     10|        direction: ChannelDirection,
   66|     10|        protocol_version: u8,
   67|     10|        now: Timestamp,
   68|     10|        limiter: Arc<BandwidthLimiter>,
   69|     10|        observer: Arc<dyn NetworkObserver>,
   70|     10|    ) -> Self {
   71|     10|        Self {
   72|     10|            channel_id,
   73|     10|            local_addr,
   74|     10|            peer_addr,
   75|     10|            // TODO set protocol version to 0
   76|     10|            protocol_version: AtomicU8::new(protocol_version),
   77|     10|            direction,
   78|     10|            last_activity: AtomicI64::new(now.into()),
   79|     10|            last_bootstrap_attempt: AtomicI64::new(0),
   80|     10|            timeout_seconds: AtomicU64::new(DEFAULT_TIMEOUT),
   81|     10|            timed_out: AtomicBool::new(false),
   82|     10|            socket_type: AtomicU8::new(ChannelMode::Undefined as u8),
   83|     10|            closed: AtomicBool::new(false),
   84|     10|            data: Mutex::new(PeerInfo {
   85|     10|                node_id: None,
   86|     10|                peering_addr: if direction == ChannelDirection::Outbound {
   87|     10|                    Some(peer_addr)
   88|       |                } else {
   89|      0|                    None
   90|       |                },
   91|       |            }),
   92|     10|            write_queue: WriteQueue::new(Self::MAX_QUEUE_SIZE, observer.clone()),
   93|     10|            cancel_token: CancellationToken::new(),
   94|     10|            limiter,
   95|     10|            observer,
   96|     10|        }
   97|     10|    }
   98|       |
   99|      1|    pub fn new_test_instance() -> Self {
  100|      1|        Self::new(
  101|      1|            ChannelId::from(42),
  102|      1|            TEST_ENDPOINT_1,
  103|      1|            TEST_ENDPOINT_2,
  104|      1|            ChannelDirection::Outbound,
  105|      1|            u8::MAX,
  106|      1|            Timestamp::new_test_instance(),
  107|      1|            Arc::new(BandwidthLimiter::default()),
  108|      1|            Arc::new(NullNetworkObserver::new()),
  109|      1|        )
  110|      1|    }
  111|       |
  112|      1|    pub fn channel_id(&self) -> ChannelId {
  113|      1|        self.channel_id
  114|      1|    }
  115|       |
  116|      0|    pub fn node_id(&self) -> Option<NodeId> {
  117|      0|        self.data.lock().unwrap().node_id
  118|      0|    }
  119|       |
  120|      3|    pub fn direction(&self) -> ChannelDirection {
  121|      3|        self.direction
  122|      3|    }
  123|       |
  124|      0|    pub fn local_addr(&self) -> SocketAddrV6 {
  125|      0|        self.local_addr
  126|      0|    }
  127|       |
  128|       |    /// The address that we are connected to. If this is an incoming channel, then
  129|       |    /// the peer_addr uses an ephemeral port
  130|     16|    pub fn peer_addr(&self) -> SocketAddrV6 {
  131|     16|        self.peer_addr
  132|     16|    }
  133|       |
  134|       |    /// The address where the peer accepts incoming connections. In case of an outbound
  135|       |    /// channel, the peer_addr and peering_addr are the same
  136|     12|    pub fn peering_addr(&self) -> Option<SocketAddrV6> {
  137|     12|        self.data.lock().unwrap().peering_addr.clone()
  138|     12|    }
  139|       |
  140|      0|    pub fn peering_addr_or_peer_addr(&self) -> SocketAddrV6 {
  141|      0|        self.data
  142|      0|            .lock()
  143|      0|            .unwrap()
  144|      0|            .peering_addr
  145|      0|            .clone()
  146|      0|            .unwrap_or(self.peer_addr)
  147|      0|    }
  148|       |
  149|      6|    pub fn ipv4_address_or_ipv6_subnet(&self) -> Ipv6Addr {
  150|      6|        ipv4_address_or_ipv6_subnet(&self.peer_addr().ip())
  151|      6|    }
  152|       |
  153|      3|    pub fn subnetwork(&self) -> Ipv6Addr {
  154|      3|        map_address_to_subnetwork(self.peer_addr().ip())
  155|      3|    }
  156|       |
  157|      9|    pub fn protocol_version(&self) -> u8 {
  158|      9|        self.protocol_version.load(Ordering::Relaxed)
  159|      9|    }
  160|       |
  161|      0|    pub fn set_protocol_version(&self, version: u8) {
  162|      0|        self.protocol_version.store(version, Ordering::Relaxed);
  163|      0|    }
  164|       |
  165|      0|    pub fn last_activity(&self) -> Timestamp {
  166|      0|        self.last_activity.load(Ordering::Relaxed).into()
  167|      0|    }
  168|       |
  169|      0|    pub fn set_last_activity(&self, now: Timestamp) {
  170|      0|        self.last_activity.store(now.into(), Ordering::Relaxed);
  171|      0|    }
  172|       |
  173|      0|    pub fn timeout(&self) -> Duration {
  174|      0|        Duration::from_secs(self.timeout_seconds.load(Ordering::Relaxed))
  175|      0|    }
  176|       |
  177|      9|    pub fn set_timeout(&self, value: Duration) {
  178|      9|        self.timeout_seconds
  179|      9|            .store(value.as_secs(), Ordering::Relaxed)
  180|      9|    }
  181|       |
  182|      0|    pub fn timed_out(&self) -> bool {
  183|      0|        self.timed_out.load(Ordering::Relaxed)
  184|      0|    }
  185|       |
  186|      0|    pub fn set_timed_out(&self, value: bool) {
  187|      0|        self.timed_out.store(value, Ordering::Relaxed)
  188|      0|    }
  189|       |
  190|     27|    pub fn is_alive(&self) -> bool {
  191|     27|        !self.is_closed()
  192|     27|    }
  193|       |
  194|     27|    pub fn is_closed(&self) -> bool {
  195|     27|        self.closed.load(Ordering::Relaxed)
  196|     27|    }
  197|       |
  198|      9|    pub fn close(&self) {
  199|      9|        let already_closed = self.closed.swap(true, Ordering::Relaxed);
  200|      9|        if already_closed {
  201|      0|            return;
  202|      9|        }
  203|      9|        self.set_timeout(Duration::ZERO);
  204|      9|        self.write_queue.close();
  205|      9|        self.cancel_token.cancel();
  206|      9|    }
  207|       |
  208|      0|    pub fn set_node_id(&self, node_id: NodeId) {
  209|      0|        self.data.lock().unwrap().node_id = Some(node_id);
  210|      0|    }
  211|       |
  212|      0|    pub fn set_peering_addr(&self, peering_addr: SocketAddrV6) {
  213|      0|        self.data.lock().unwrap().peering_addr = Some(peering_addr);
  214|      0|    }
  215|       |
  216|      9|    pub fn mode(&self) -> ChannelMode {
  217|      9|        FromPrimitive::from_u8(self.socket_type.load(Ordering::SeqCst)).unwrap()
  218|      9|    }
  219|       |
  220|      9|    pub fn set_mode(&self, mode: ChannelMode) {
  221|      9|        self.socket_type.store(mode as u8, Ordering::SeqCst);
  222|      9|    }
  223|       |
  224|      0|    pub fn last_bootstrap_attempt(&self) -> Timestamp {
  225|      0|        self.last_bootstrap_attempt.load(Ordering::Relaxed).into()
  226|      0|    }
  227|       |
  228|      0|    pub fn set_last_bootstrap_attempt(&self, now: Timestamp) {
  229|      0|        self.last_bootstrap_attempt
  230|      0|            .store(now.into(), Ordering::Relaxed);
  231|      0|    }
  232|       |
  233|      0|    pub fn should_drop(&self, traffic_type: TrafficType) -> bool {
  234|      0|        self.write_queue.free_capacity(traffic_type) == 0
  235|      0|    }
  236|       |
  237|      0|    pub fn send(&self, buffer: &[u8], traffic_type: TrafficType) -> bool {
  238|      0|        if self.is_closed() {
  239|      0|            return false;
  240|      0|        }
  241|      0|
  242|      0|        if self.should_drop(traffic_type) {
  243|      0|            return false;
  244|      0|        }
  245|      0|
  246|      0|        let should_pass = self.limiter.should_pass(buffer.len(), traffic_type);
  247|      0|        if !should_pass {
  248|      0|            return false;
  249|      0|        }
  250|      0|
  251|      0|        let inserted = self
  252|      0|            .write_queue
  253|      0|            .try_insert(Arc::new(buffer.to_vec()), traffic_type); // TODO don't copy into vec. Split into fixed size packets
  254|      0|        inserted
  255|      0|    }
  256|       |
  257|      0|    pub fn queue_len(&self) -> usize {
  258|      0|        self.write_queue.len()
  259|      0|    }
  260|       |
  261|      0|    pub async fn pop(&self) -> Option<Entry> {
  262|      0|        self.write_queue.pop().await
  263|      0|    }
  264|       |
  265|      0|    pub fn cancelled(&self) -> WaitForCancellationFuture<'_> {
  266|      0|        self.cancel_token.cancelled()
  267|      0|    }
  268|       |
  269|      0|    pub fn check_timeout(&self, now: Timestamp) -> bool {
  270|      0|        // If the socket is already dead, stop doing checkups
  271|      0|        if !self.is_alive() {
  272|      0|            return true;
  273|      0|        }
  274|      0|
  275|      0|        // if there is no activity for timeout seconds then disconnect
  276|      0|        let has_timed_out = (now - self.last_activity()) > self.timeout();
  277|      0|        if has_timed_out {
  278|      0|            self.observer.channel_timed_out(&self);
  279|      0|            self.set_timed_out(true);
  280|      0|            self.close();
  281|      0|        }
  282|      0|        has_timed_out
  283|      0|    }
  284|       |
  285|      0|    pub fn read_succeeded(&self, count: usize, now: Timestamp) {
  286|      0|        self.observer.read_succeeded(count);
  287|      0|        self.set_last_activity(now);
  288|      0|    }
  289|       |
  290|      0|    pub fn read_failed(&self) {
  291|      0|        self.observer.read_failed();
  292|      0|        self.close();
  293|      0|    }
  294|       |}
  295|       |
  296|       |struct PeerInfo {
  297|       |    node_id: Option<NodeId>,
  298|       |    peering_addr: Option<SocketAddrV6>,
  299|       |}

/home/gustav/code/nano/rsnano-node/network/src/dead_channel_cleanup.rs:
    1|       |use crate::{ChannelId, Network};
    2|       |use rsnano_nullable_clock::SteadyClock;
    3|       |use std::{
    4|       |    sync::{Arc, RwLock},
    5|       |    time::Duration,
    6|       |};
    7|       |
    8|       |pub trait DeadChannelCleanupStep: Send {
    9|       |    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]);
   10|       |}
   11|       |
   12|       |// Removes dead channels and all their related queue entries
   13|       |pub struct DeadChannelCleanup {
   14|       |    clock: Arc<SteadyClock>,
   15|       |    network: Arc<RwLock<Network>>,
   16|       |    cleanup_cutoff: Duration,
   17|       |    cleanup_steps: Vec<Box<dyn DeadChannelCleanupStep>>,
   18|       |}
   19|       |
   20|       |impl DeadChannelCleanup {
   21|      3|    pub fn new(
   22|      3|        clock: Arc<SteadyClock>,
   23|      3|        network: Arc<RwLock<Network>>,
   24|      3|        cleanup_cutoff: Duration,
   25|      3|    ) -> Self {
   26|      3|        Self {
   27|      3|            clock,
   28|      3|            network,
   29|      3|            cleanup_cutoff,
   30|      3|            cleanup_steps: Vec::new(),
   31|      3|        }
   32|      3|    }
   33|       |
   34|     24|    pub fn add_step(&mut self, step: impl DeadChannelCleanupStep + 'static) {
   35|     24|        self.cleanup_steps.push(Box::new(step));
   36|     24|    }
   37|       |
   38|      0|    pub fn clean_up(&self) {
   39|      0|        let removed_channels = self
   40|      0|            .network
   41|      0|            .write()
   42|      0|            .unwrap()
   43|      0|            .purge(self.clock.now(), self.cleanup_cutoff);
   44|      0|
   45|      0|        let channel_ids: Vec<_> = removed_channels.iter().map(|c| c.channel_id()).collect();
   46|       |
   47|      0|        for step in &self.cleanup_steps {
   48|      0|            step.clean_up_dead_channels(&channel_ids);
   49|      0|        }
   50|      0|    }
   51|       |}

/home/gustav/code/nano/rsnano-node/network/src/lib.rs:
    1|       |pub mod attempt_container;
    2|       |pub mod bandwidth_limiter;
    3|       |mod channel;
    4|       |mod dead_channel_cleanup;
    5|       |mod network;
    6|       |mod network_observer;
    7|       |mod peer_connector;
    8|       |pub mod peer_exclusion;
    9|       |mod tcp_channel_adapter;
   10|       |mod tcp_listener;
   11|       |mod tcp_network_adapter;
   12|       |pub mod token_bucket;
   13|       |pub mod utils;
   14|       |pub mod write_queue;
   15|       |
   16|       |use async_trait::async_trait;
   17|       |pub use channel::*;
   18|       |pub use dead_channel_cleanup::*;
   19|       |pub use network::*;
   20|       |pub use network_observer::*;
   21|       |use num_derive::FromPrimitive;
   22|       |pub use peer_connector::*;
   23|       |use std::{
   24|       |    fmt::{Debug, Display},
   25|       |    sync::Arc,
   26|       |};
   27|       |pub use tcp_channel_adapter::*;
   28|       |pub use tcp_listener::*;
   29|       |pub use tcp_network_adapter::*;
   30|       |
   31|       |#[macro_use]
   32|       |extern crate anyhow;
   33|       |
   34|       |#[derive(PartialEq, Eq, PartialOrd, Ord, Copy, Clone, Hash)]
   35|       |pub struct ChannelId(usize);
   36|       |
   37|       |impl ChannelId {
   38|       |    pub const LOOPBACK: Self = Self(0);
   39|       |    pub const MIN: Self = Self(usize::MIN);
   40|       |    pub const MAX: Self = Self(usize::MAX);
   41|       |
   42|      0|    pub fn as_usize(&self) -> usize {
   43|      0|        self.0
   44|      0|    }
   45|       |}
   46|       |
   47|       |impl Display for ChannelId {
   48|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   49|      0|        std::fmt::Display::fmt(&self.0, f)
   50|      0|    }
   51|       |}
   52|       |
   53|       |impl Debug for ChannelId {
   54|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   55|      0|        std::fmt::Debug::fmt(&self.0, f)
   56|      0|    }
   57|       |}
   58|       |
   59|       |impl From<usize> for ChannelId {
   60|     44|    fn from(value: usize) -> Self {
   61|     44|        Self(value)
   62|     44|    }
   63|       |}
   64|       |
   65|      0|#[derive(PartialEq, Eq, Clone, Copy, FromPrimitive, Debug)]
   66|       |pub enum ChannelDirection {
   67|       |    /// Socket was created by accepting an incoming connection
   68|       |    Inbound,
   69|       |    /// Socket was created by initiating an outgoing connection
   70|       |    Outbound,
   71|       |}
   72|       |
   73|      0|#[derive(FromPrimitive, Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]
   74|       |pub enum TrafficType {
   75|       |    Generic,
   76|       |    /// Ascending bootstrap (asc_pull_ack, asc_pull_req) traffic
   77|       |    BootstrapServer,
   78|       |    BootstrapRequests,
   79|       |    BlockBroadcast,
   80|       |    BlockBroadcastInitial,
   81|       |    BlockBroadcastRpc,
   82|       |    ConfirmationRequests,
   83|       |    Keepalive,
   84|       |    Vote,
   85|       |    VoteRebroadcast,
   86|       |    VoteReply,
   87|       |    RepCrawler,
   88|       |    Telemetry,
   89|       |}
   90|       |
   91|      9|#[derive(PartialEq, Eq, Clone, Copy, Debug, FromPrimitive)]
   92|       |pub enum ChannelMode {
   93|       |    /// No messages have been exchanged yet, so the mode is undefined
   94|       |    Undefined,
   95|       |    /// serve realtime traffic (votes, new blocks,...)
   96|       |    Realtime,
   97|       |}
   98|       |
   99|       |impl ChannelMode {
  100|      0|    pub fn as_str(&self) -> &'static str {
  101|      0|        match self {
  102|      0|            ChannelMode::Undefined => "undefined",
  103|      0|            ChannelMode::Realtime => "realtime",
  104|       |        }
  105|      0|    }
  106|       |}
  107|       |
  108|       |#[async_trait]
  109|       |pub trait AsyncBufferReader {
  110|       |    async fn read(&self, buffer: &mut [u8], count: usize) -> anyhow::Result<()>;
  111|       |}
  112|       |
  113|       |pub trait DataReceiverFactory {
  114|       |    fn create_receiver_for(&self, channel: Arc<Channel>) -> Box<dyn DataReceiver + Send>;
  115|       |}
  116|       |
  117|       |pub enum ReceiveResult {
  118|       |    Continue,
  119|       |    Abort,
  120|       |    Pause,
  121|       |}
  122|       |
  123|       |pub trait DataReceiver {
  124|       |    fn receive(&mut self, data: &[u8]) -> ReceiveResult;
  125|       |    /// after receive returns Pause this has to be called until it returns true
  126|       |    fn try_unpause(&self) -> ReceiveResult;
  127|       |}
  128|       |
  129|       |pub struct NullDataReceiverFactory;
  130|       |
  131|       |impl NullDataReceiverFactory {
  132|     22|    pub fn new() -> Self {
  133|     22|        Self
  134|     22|    }
  135|       |}
  136|       |
  137|       |impl DataReceiverFactory for NullDataReceiverFactory {
  138|      9|    fn create_receiver_for(&self, _channel: Arc<Channel>) -> Box<dyn DataReceiver + Send> {
  139|      9|        Box::new(NullDataReceiver::new())
  140|      9|    }
  141|       |}
  142|       |
  143|       |pub struct NullDataReceiver;
  144|       |
  145|       |impl NullDataReceiver {
  146|      9|    pub fn new() -> Self {
  147|      9|        Self
  148|      9|    }
  149|       |}
  150|       |
  151|       |impl DataReceiver for NullDataReceiver {
  152|      0|    fn receive(&mut self, _: &[u8]) -> ReceiveResult {
  153|      0|        ReceiveResult::Continue
  154|      0|    }
  155|       |
  156|      0|    fn try_unpause(&self) -> ReceiveResult {
  157|      0|        ReceiveResult::Continue
  158|      0|    }
  159|       |}

/home/gustav/code/nano/rsnano-node/network/src/network.rs:
    1|       |use super::ChannelDirection;
    2|       |use crate::{
    3|       |    attempt_container::AttemptContainer,
    4|       |    bandwidth_limiter::{BandwidthLimiter, BandwidthLimiterConfig},
    5|       |    peer_exclusion::PeerExclusion,
    6|       |    utils::{is_ipv4_mapped, map_address_to_subnetwork, reserved_address},
    7|       |    Channel, ChannelId, ChannelMode, DataReceiver, DataReceiverFactory, NetworkObserver,
    8|       |    NullDataReceiverFactory, NullNetworkObserver, TrafficType,
    9|       |};
   10|       |use rand::{seq::SliceRandom, thread_rng};
   11|       |use rsnano_core::{utils::ContainerInfo, Networks, NodeId};
   12|       |use rsnano_nullable_clock::Timestamp;
   13|       |use std::{
   14|       |    collections::HashMap,
   15|       |    net::{Ipv6Addr, SocketAddrV6},
   16|       |    sync::Arc,
   17|       |    time::Duration,
   18|       |};
   19|       |use tracing::{debug, warn};
   20|       |
   21|       |pub struct NetworkConfig {
   22|       |    pub max_inbound_connections: usize,
   23|       |    pub max_outbound_connections: usize,
   24|       |
   25|       |    /** Maximum number of peers per IP. It is also the max number of connections per IP*/
   26|       |    pub max_peers_per_ip: u16,
   27|       |
   28|       |    /** Maximum number of peers per subnetwork */
   29|       |    pub max_peers_per_subnetwork: u16,
   30|       |    pub max_attempts_per_ip: usize,
   31|       |
   32|       |    pub allow_local_peers: bool,
   33|       |    pub min_protocol_version: u8,
   34|       |    pub disable_max_peers_per_ip: bool,         // For testing only
   35|       |    pub disable_max_peers_per_subnetwork: bool, // For testing only
   36|       |    pub disable_network: bool,
   37|       |    pub listening_port: u16,
   38|       |    pub limiter: BandwidthLimiterConfig,
   39|       |}
   40|       |
   41|       |impl NetworkConfig {
   42|     19|    pub fn default_for(network: Networks) -> Self {
   43|     19|        let is_dev = network == Networks::NanoDevNetwork;
   44|     19|        Self {
   45|     19|            max_inbound_connections: if is_dev { 128 } else { 2048 },
                                                                            ^0
   46|     19|            max_outbound_connections: if is_dev { 128 } else { 2048 },
                                                                             ^0
   47|       |            allow_local_peers: true,
   48|     19|            max_peers_per_ip: match network {
   49|     19|                Networks::NanoDevNetwork | Networks::NanoBetaNetwork => 256,
   50|      0|                _ => 4,
   51|       |            },
   52|     19|            max_peers_per_subnetwork: match network {
   53|     19|                Networks::NanoDevNetwork | Networks::NanoBetaNetwork => 256,
   54|      0|                _ => 16,
   55|       |            },
   56|     19|            max_attempts_per_ip: if is_dev { 128 } else { 1 },
                                                                        ^0
   57|       |            min_protocol_version: 0x14, //TODO don't hard code
   58|       |            disable_max_peers_per_ip: false,
   59|       |            disable_max_peers_per_subnetwork: false,
   60|       |            disable_network: false,
   61|     19|            listening_port: match network {
   62|     19|                Networks::NanoDevNetwork => 44000,
   63|      0|                Networks::NanoBetaNetwork => 54000,
   64|      0|                Networks::NanoTestNetwork => 17076,
   65|      0|                _ => 7075,
   66|       |            },
   67|     19|            limiter: BandwidthLimiterConfig::default(),
   68|     19|        }
   69|     19|    }
   70|       |}
   71|       |
   72|       |#[derive(Debug, Clone, Copy)]
   73|       |pub enum NetworkError {
   74|       |    MaxConnections,
   75|       |    MaxConnectionsPerSubnetwork,
   76|       |    MaxConnectionsPerIp,
   77|       |    /// Peer is excluded due to bad behavior
   78|       |    PeerExcluded,
   79|       |    InvalidIp,
   80|       |    /// We are already connected to that peer and we tried to connect a second time
   81|       |    DuplicateConnection,
   82|       |}
   83|       |
   84|       |pub struct Network {
   85|       |    next_channel_id: usize,
   86|       |    channels: HashMap<ChannelId, Arc<Channel>>,
   87|       |    stopped: bool,
   88|       |    new_realtime_channel_observers: Vec<Arc<dyn Fn(Arc<Channel>) + Send + Sync>>,
   89|       |    attempts: AttemptContainer,
   90|       |    network_config: NetworkConfig,
   91|       |    excluded_peers: PeerExclusion,
   92|       |    bandwidth_limiter: Arc<BandwidthLimiter>,
   93|       |    observer: Arc<dyn NetworkObserver>,
   94|       |    data_receiver_factory: Box<dyn DataReceiverFactory + Send + Sync>,
   95|       |}
   96|       |
   97|       |impl Network {
   98|     22|    pub fn new(network_config: NetworkConfig) -> Self {
   99|     22|        Self {
  100|     22|            next_channel_id: 1,
  101|     22|            channels: HashMap::new(),
  102|     22|            stopped: false,
  103|     22|            new_realtime_channel_observers: Vec::new(),
  104|     22|            attempts: Default::default(),
  105|     22|            excluded_peers: PeerExclusion::new(),
  106|     22|            bandwidth_limiter: Arc::new(BandwidthLimiter::new(network_config.limiter.clone())),
  107|     22|            observer: Arc::new(NullNetworkObserver::new()),
  108|     22|            network_config,
  109|     22|            data_receiver_factory: Box::new(NullDataReceiverFactory::new()),
  110|     22|        }
  111|     22|    }
  112|       |
  113|       |    #[allow(dead_code)]
  114|     19|    pub fn new_test_instance() -> Self {
  115|     19|        Self::new(NetworkConfig::default_for(Networks::NanoDevNetwork))
  116|     19|    }
  117|       |
  118|      3|    pub fn set_observer(&mut self, observer: Arc<dyn NetworkObserver>) {
  119|      3|        self.observer = observer;
  120|      3|    }
  121|       |
  122|      3|    pub fn set_data_receiver_factory(
  123|      3|        &mut self,
  124|      3|        factory: Box<dyn DataReceiverFactory + Send + Sync>,
  125|      3|    ) {
  126|      3|        self.data_receiver_factory = factory;
  127|      3|    }
  128|       |
  129|      6|    pub fn on_new_realtime_channel(&mut self, callback: Arc<dyn Fn(Arc<Channel>) + Send + Sync>) {
  130|      6|        self.new_realtime_channel_observers.push(callback);
  131|      6|    }
  132|       |
  133|      0|    pub fn new_realtime_channel_observers(&self) -> Vec<Arc<dyn Fn(Arc<Channel>) + Send + Sync>> {
  134|      0|        self.new_realtime_channel_observers.clone()
  135|      0|    }
  136|       |
  137|      0|    pub fn is_inbound_slot_available(&self) -> bool {
  138|      0|        self.count_by_direction(ChannelDirection::Inbound)
  139|      0|            < self.network_config.max_inbound_connections
  140|      0|    }
  141|       |
  142|       |    /// Perma bans are used for prohibiting a node to connect to itself.
  143|      0|    pub fn perma_ban(&mut self, peer_addr: SocketAddrV6) {
  144|      0|        self.excluded_peers.perma_ban(peer_addr);
  145|      0|    }
  146|       |
  147|      0|    pub fn is_excluded(&mut self, peer_addr: &SocketAddrV6, now: Timestamp) -> bool {
  148|      0|        self.excluded_peers.is_excluded(peer_addr, now)
  149|      0|    }
  150|       |
  151|     11|    pub fn add_outbound_attempt(&mut self, peer: SocketAddrV6, now: Timestamp) -> bool {
  152|     11|        let result = self.validate_new_connection(&peer, ChannelDirection::Outbound, now);
  153|       |
  154|     11|        if let Err(e) = result {
                                 ^0
  155|      0|            self.observer.error(e, &peer, ChannelDirection::Outbound);
  156|      0|            return false;
  157|     11|        }
  158|     11|
  159|     11|        self.attempts.insert(peer, ChannelDirection::Outbound, now);
  160|       |
  161|     11|        if let Err(e) = self.validate_new_connection(&peer, ChannelDirection::Outbound, now) {
                                 ^0
  162|      0|            self.remove_attempt(&peer);
  163|      0|            self.observer.error(e, &peer, ChannelDirection::Outbound);
  164|      0|            return false;
  165|     11|        }
  166|     11|
  167|     11|        self.observer.connection_attempt(&peer);
  168|     11|        self.observer.merge_peer();
  169|     11|
  170|     11|        true
  171|     11|    }
  172|       |
  173|      0|    pub fn remove_attempt(&mut self, remote: &SocketAddrV6) {
  174|      0|        self.attempts.remove(&remote);
  175|      0|    }
  176|       |
  177|      9|    pub fn add(
  178|      9|        &mut self,
  179|      9|        local_addr: SocketAddrV6,
  180|      9|        peer_addr: SocketAddrV6,
  181|      9|        direction: ChannelDirection,
  182|      9|        now: Timestamp,
  183|      9|    ) -> Result<(Arc<Channel>, Box<dyn DataReceiver + Send>), NetworkError> {
  184|      9|        let result = self.validate_new_connection(&peer_addr, direction, now);
  185|      9|        if let Err(e) = result {
                                 ^0
  186|      0|            self.observer.error(e, &peer_addr, direction);
  187|      9|        }
  188|      9|        result?;
                            ^0
  189|       |
  190|      9|        let channel_id = self.get_next_channel_id();
  191|      9|        let channel = Arc::new(Channel::new(
  192|      9|            channel_id,
  193|      9|            local_addr,
  194|      9|            peer_addr,
  195|      9|            direction,
  196|      9|            self.network_config.min_protocol_version,
  197|      9|            now,
  198|      9|            self.bandwidth_limiter.clone(),
  199|      9|            self.observer.clone(),
  200|      9|        ));
  201|      9|        self.channels.insert(channel_id, channel.clone());
  202|      9|        self.observer.accepted(&peer_addr, direction);
  203|      9|        let receiver = self
  204|      9|            .data_receiver_factory
  205|      9|            .create_receiver_for(channel.clone());
  206|      9|
  207|      9|        Ok((channel, receiver))
  208|      9|    }
  209|       |
  210|      9|    fn get_next_channel_id(&mut self) -> ChannelId {
  211|      9|        let id = self.next_channel_id.into();
  212|      9|        self.next_channel_id += 1;
  213|      9|        id
  214|      9|    }
  215|       |
  216|     34|    pub fn listening_port(&self) -> u16 {
  217|     34|        self.network_config.listening_port
  218|     34|    }
  219|       |
  220|      0|    pub fn set_listening_port(&mut self, port: u16) {
  221|      0|        self.network_config.listening_port = port
  222|      0|    }
  223|       |
  224|      0|    pub fn get(&self, channel_id: ChannelId) -> Option<&Arc<Channel>> {
  225|      0|        self.channels.get(&channel_id)
  226|      0|    }
  227|       |
  228|      0|    pub fn remove(&mut self, channel_id: ChannelId) {
  229|      0|        self.channels.remove(&channel_id);
  230|      0|    }
  231|       |
  232|      0|    pub fn set_node_id(&self, channel_id: ChannelId, node_id: NodeId) {
  233|      0|        if let Some(channel) = self.channels.get(&channel_id) {
  234|      0|            channel.set_node_id(node_id);
  235|      0|        }
  236|      0|    }
  237|       |
  238|      0|    pub fn find_node_id(&self, node_id: &NodeId) -> Option<&Arc<Channel>> {
  239|      0|        self.channels
  240|      0|            .values()
  241|      0|            .find(|c| c.node_id() == Some(*node_id) && c.is_alive())
  242|      0|    }
  243|       |
  244|      0|    pub fn find_realtime_channel_by_remote_addr(
  245|      0|        &self,
  246|      0|        endpoint: &SocketAddrV6,
  247|      0|    ) -> Option<&Arc<Channel>> {
  248|      0|        self.channels.values().find(|c| {
  249|      0|            c.mode() == ChannelMode::Realtime && c.is_alive() && c.peer_addr() == *endpoint
  250|      0|        })
  251|      0|    }
  252|       |
  253|      0|    pub fn find_realtime_channel_by_peering_addr(
  254|      0|        &self,
  255|      0|        peering_addr: &SocketAddrV6,
  256|      0|    ) -> Option<ChannelId> {
  257|      0|        self.channels
  258|      0|            .values()
  259|      0|            .find(|c| {
  260|      0|                c.mode() == ChannelMode::Realtime
  261|      0|                    && c.is_alive()
  262|      0|                    && c.peering_addr() == Some(*peering_addr)
  263|      0|            })
  264|      0|            .map(|c| c.channel_id())
  265|      0|    }
  266|       |
  267|      3|    pub fn random_realtime_channels(&self, count: usize, min_version: u8) -> Vec<Arc<Channel>> {
  268|      3|        let mut channels = self.list_realtime(min_version);
  269|      3|        let mut rng = thread_rng();
  270|      3|        channels.shuffle(&mut rng);
  271|      3|        if count > 0 {
  272|      3|            channels.truncate(count)
  273|      0|        }
  274|      3|        channels
  275|      3|    }
  276|       |
  277|      0|    pub fn random_fanout_realtime(&self, scale: f32) -> Vec<Arc<Channel>> {
  278|      0|        self.random_realtime_channels(self.fanout(scale), 0)
  279|      0|    }
  280|       |
  281|     20|    pub fn list_realtime(&self, min_version: u8) -> Vec<Arc<Channel>> {
  282|     20|        self.channels
  283|     20|            .values()
  284|     20|            .filter(|c| {
  285|      9|                c.protocol_version() >= min_version
  286|      9|                    && c.is_alive()
  287|      9|                    && c.mode() == ChannelMode::Realtime
  288|     20|            })
                          ^9
  289|     20|            .map(|c| c.clone())
                                   ^9
  290|     20|            .collect()
  291|     20|    }
  292|       |
  293|     14|    pub fn list_realtime_channels(&self, min_version: u8) -> Vec<Arc<Channel>> {
  294|     14|        let mut result = self.list_realtime(min_version);
  295|     14|        result.sort_by_key(|i| i.peer_addr());
                                             ^4
  296|     14|        result
  297|     14|    }
  298|       |
  299|     31|    pub fn not_a_peer(&self, endpoint: &SocketAddrV6, allow_local_peers: bool) -> bool {
  300|     31|        endpoint.ip().is_unspecified()
  301|     31|            || reserved_address(endpoint, allow_local_peers)
  302|     31|            || endpoint == &SocketAddrV6::new(Ipv6Addr::LOCALHOST, self.listening_port(), 0, 0)
  303|     31|    }
  304|       |
  305|      3|    pub fn random_list_realtime(&self, count: usize, min_version: u8) -> Vec<Arc<Channel>> {
  306|      3|        let mut channels = self.list_realtime(min_version);
  307|      3|        let mut rng = thread_rng();
  308|      3|        channels.shuffle(&mut rng);
  309|      3|        if count > 0 {
  310|      3|            channels.truncate(count)
  311|      0|        }
  312|      3|        channels
  313|      3|    }
  314|       |
  315|      3|    pub fn random_list_realtime_ids(&self) -> Vec<ChannelId> {
  316|      3|        self.random_list_realtime(usize::MAX, 0)
  317|      3|            .iter()
  318|      3|            .map(|c| c.channel_id())
                                   ^0
  319|      3|            .collect()
  320|      3|    }
  321|       |
  322|       |    /// Returns channel IDs of removed channels
  323|      0|    pub fn purge(&mut self, now: Timestamp, cutoff_period: Duration) -> Vec<Arc<Channel>> {
  324|      0|        self.close_idle_channels(now, cutoff_period);
  325|      0|
  326|      0|        // Check if any tcp channels belonging to old protocol versions which may still be alive due to async operations
  327|      0|        self.close_old_protocol_versions(self.network_config.min_protocol_version);
  328|      0|
  329|      0|        // Remove channels with dead underlying sockets
  330|      0|        let purged_channels = self.remove_dead_channels();
  331|      0|
  332|      0|        // Remove keepalive attempt tracking for attempts older than cutoff
  333|      0|        self.attempts.purge(now, cutoff_period);
  334|      0|        purged_channels
  335|      0|    }
  336|       |
  337|      0|    fn close_idle_channels(&mut self, now: Timestamp, cutoff_period: Duration) {
  338|      0|        for entry in self.channels.values() {
  339|      0|            if now - entry.last_activity() >= cutoff_period {
  340|      0|                debug!(remote_addr = ?entry.peer_addr(), channel_id = %entry.channel_id(), mode = ?entry.mode(), "Closing idle channel");
  341|      0|                entry.close();
  342|      0|            }
  343|       |        }
  344|      0|    }
  345|       |
  346|      0|    fn close_old_protocol_versions(&mut self, min_version: u8) {
  347|      0|        for channel in self.channels.values() {
  348|      0|            if channel.protocol_version() < min_version {
  349|      0|                debug!(channel_id = %channel.channel_id(), peer_addr = ?channel.peer_addr(), version = channel.protocol_version(), min_version,
  350|      0|                    "Closing channel with old protocol version",
  351|       |                );
  352|      0|                channel.close();
  353|      0|            }
  354|       |        }
  355|      0|    }
  356|       |
  357|       |    /// Removes dead channels and returns their channel ids
  358|      0|    fn remove_dead_channels(&mut self) -> Vec<Arc<Channel>> {
  359|      0|        let dead_channels: Vec<_> = self
  360|      0|            .channels
  361|      0|            .values()
  362|      0|            .filter(|c| !c.is_alive())
  363|      0|            .cloned()
  364|      0|            .collect();
  365|       |
  366|      0|        for channel in &dead_channels {
  367|      0|            debug!("Removing dead channel: {}", channel.peer_addr());
  368|      0|            self.channels.remove(&channel.channel_id());
  369|       |        }
  370|       |
  371|      0|        dead_channels
  372|      0|    }
  373|       |
  374|      0|    pub fn should_drop(&self, channel_id: ChannelId, traffic_type: TrafficType) -> bool {
  375|      0|        self.channels
  376|      0|            .get(&channel_id)
  377|      0|            .map(|c| c.should_drop(traffic_type))
  378|      0|            .unwrap_or(true)
  379|      0|    }
  380|       |
  381|      3|    fn len_sqrt(&self) -> f32 {
  382|      3|        f32::sqrt(self.count_by_mode(ChannelMode::Realtime) as f32)
  383|      3|    }
  384|       |
  385|       |    /// Desired fanout for a given scale
  386|       |    /// Simulating with sqrt_broadcast_simulate shows we only need to broadcast to sqrt(total_peers) random peers in order to successfully publish to everyone with high probability
  387|      3|    pub fn fanout(&self, scale: f32) -> usize {
  388|      3|        (self.len_sqrt() * scale).ceil() as usize
  389|      3|    }
  390|       |
  391|     62|    fn count_by_ip(&self, ip: &Ipv6Addr) -> usize {
  392|     62|        self.channels
  393|     62|            .values()
  394|     62|            .filter(|c| c.is_alive() && c.ipv4_address_or_ipv6_subnet() == *ip)
                                      ^6              ^6                                   ^6
  395|     62|            .count()
  396|     62|    }
  397|       |
  398|     23|    fn count_by_subnet(&self, subnet: &Ipv6Addr) -> usize {
  399|     23|        self.channels
  400|     23|            .values()
  401|     23|            .filter(|c| c.is_alive() && c.subnetwork() == *subnet)
                                      ^3              ^3                      ^3
  402|     23|            .count()
  403|     23|    }
  404|       |
  405|     31|    pub fn count_by_direction(&self, direction: ChannelDirection) -> usize {
  406|     31|        self.channels
  407|     31|            .values()
  408|     31|            .filter(|c| c.is_alive() && c.direction() == direction)
                                      ^3              ^3                       ^3
  409|     31|            .count()
  410|     31|    }
  411|       |
  412|      6|    pub fn count_by_mode(&self, mode: ChannelMode) -> usize {
  413|      6|        self.channels
  414|      6|            .values()
  415|      6|            .filter(|c| c.is_alive() && c.mode() == mode)
                                      ^0              ^0             ^0
  416|      6|            .count()
  417|      6|    }
  418|       |
  419|      0|    pub fn bootstrap_peer(&mut self, now: Timestamp) -> SocketAddrV6 {
  420|      0|        let mut peering_endpoint = None;
  421|      0|        let mut channel = None;
  422|      0|        for i in self.iter_by_last_bootstrap_attempt() {
  423|      0|            if i.mode() == ChannelMode::Realtime
  424|      0|                && i.protocol_version() >= self.network_config.min_protocol_version
  425|       |            {
  426|      0|                if let Some(peering) = i.peering_addr() {
  427|      0|                    channel = Some(i);
  428|      0|                    peering_endpoint = Some(peering);
  429|      0|                    break;
  430|      0|                }
  431|      0|            }
  432|       |        }
  433|       |
  434|      0|        match (channel, peering_endpoint) {
  435|      0|            (Some(c), Some(peering)) => {
  436|      0|                c.set_last_bootstrap_attempt(now);
  437|      0|                peering
  438|       |            }
  439|      0|            _ => SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0),
  440|       |        }
  441|      0|    }
  442|       |
  443|      0|    pub fn iter_by_last_bootstrap_attempt(&self) -> Vec<Arc<Channel>> {
  444|      0|        let mut channels: Vec<_> = self
  445|      0|            .channels
  446|      0|            .values()
  447|      0|            .filter(|c| c.is_alive())
  448|      0|            .cloned()
  449|      0|            .collect();
  450|      0|        channels.sort_by(|a, b| a.last_bootstrap_attempt().cmp(&b.last_bootstrap_attempt()));
  451|      0|        channels
  452|      0|    }
  453|       |
  454|     31|    pub fn find_channels_by_remote_addr(&self, remote_addr: &SocketAddrV6) -> Vec<Arc<Channel>> {
  455|     31|        self.channels
  456|     31|            .values()
  457|     31|            .filter(|c| c.is_alive() && c.peer_addr() == *remote_addr)
                                      ^3              ^3                          ^3
  458|     31|            .cloned()
  459|     31|            .collect()
  460|     31|    }
  461|       |
  462|     31|    pub fn find_channels_by_peering_addr(&self, peering_addr: &SocketAddrV6) -> Vec<Arc<Channel>> {
  463|     31|        self.channels
  464|     31|            .values()
  465|     31|            .filter(|c| c.is_alive() && c.peering_addr() == Some(*peering_addr))
                                      ^3              ^3                                    ^3
  466|     31|            .cloned()
  467|     31|            .collect()
  468|     31|    }
  469|       |
  470|     31|    fn max_ip_connections(&self, endpoint: &SocketAddrV6) -> bool {
  471|     31|        if self.network_config.disable_max_peers_per_ip {
  472|      0|            return false;
  473|     31|        }
  474|     31|        let count =
  475|     31|            self.count_by_ip(&endpoint.ip()) + self.attempts.count_by_address(&endpoint.ip());
  476|     31|        count >= self.network_config.max_peers_per_ip as usize
  477|     31|    }
  478|       |
  479|     31|    fn max_subnetwork_connections(&self, peer: &SocketAddrV6) -> bool {
  480|     31|        if self.network_config.disable_max_peers_per_subnetwork {
  481|      0|            return false;
  482|     31|        }
  483|     31|
  484|     31|        // If the address is IPv4 we don't check for a network limit, since its address space isn't big as IPv6/64.
  485|     31|        if is_ipv4_mapped(&peer.ip()) {
  486|      8|            return false;
  487|     23|        }
  488|     23|
  489|     23|        let subnet = map_address_to_subnetwork(peer.ip());
  490|     23|        let subnet_count =
  491|     23|            self.count_by_subnet(&subnet) + self.attempts.count_by_subnetwork(&subnet);
  492|     23|
  493|     23|        subnet_count >= self.network_config.max_peers_per_subnetwork as usize
  494|     31|    }
  495|       |
  496|     31|    pub fn validate_new_connection(
  497|     31|        &mut self,
  498|     31|        peer: &SocketAddrV6,
  499|     31|        direction: ChannelDirection,
  500|     31|        now: Timestamp,
  501|     31|    ) -> Result<(), NetworkError> {
  502|     31|        if self.network_config.disable_network {
  503|      0|            return Err(NetworkError::MaxConnections);
  504|     31|        }
  505|     31|
  506|     31|        let count = self.count_by_direction(direction);
  507|     31|        if count >= self.max_connections(direction) {
  508|      0|            return Err(NetworkError::MaxConnections);
  509|     31|        }
  510|     31|
  511|     31|        if self.excluded_peers.is_excluded(peer, now) {
  512|      0|            return Err(NetworkError::PeerExcluded);
  513|     31|        }
  514|     31|
  515|     31|        if !self.network_config.disable_max_peers_per_ip {
  516|     31|            let count = self.count_by_ip(peer.ip());
  517|     31|            if count >= self.network_config.max_peers_per_ip as usize {
  518|      0|                return Err(NetworkError::MaxConnectionsPerIp);
  519|     31|            }
  520|      0|        }
  521|       |
  522|       |        // Don't overload single IP
  523|     31|        if self.max_ip_connections(peer) {
  524|      0|            return Err(NetworkError::MaxConnectionsPerIp);
  525|     31|        }
  526|     31|
  527|     31|        if self.max_subnetwork_connections(peer) {
  528|      0|            return Err(NetworkError::MaxConnectionsPerSubnetwork);
  529|     31|        }
  530|     31|
  531|     31|        // Don't contact invalid IPs
  532|     31|        if self.not_a_peer(peer, self.network_config.allow_local_peers) {
  533|      0|            return Err(NetworkError::InvalidIp);
  534|     31|        }
  535|     31|
  536|     31|        if direction == ChannelDirection::Outbound {
  537|       |            // Don't connect to nodes that already sent us something
  538|     31|            if self.find_channels_by_remote_addr(peer).len() > 0 {
  539|      0|                return Err(NetworkError::DuplicateConnection);
  540|     31|            }
  541|     31|            if self.find_channels_by_peering_addr(peer).len() > 0 {
  542|      0|                return Err(NetworkError::DuplicateConnection);
  543|     31|            }
  544|      0|        }
  545|       |
  546|     31|        Ok(())
  547|     31|    }
  548|       |
  549|     31|    fn max_connections(&self, direction: ChannelDirection) -> usize {
  550|     31|        match direction {
  551|      0|            ChannelDirection::Inbound => self.network_config.max_inbound_connections,
  552|     31|            ChannelDirection::Outbound => self.network_config.max_outbound_connections,
  553|       |        }
  554|     31|    }
  555|       |
  556|      0|    pub fn set_peering_addr(&self, channel_id: ChannelId, peering_addr: SocketAddrV6) {
  557|      0|        if let Some(channel) = self.channels.get(&channel_id) {
  558|      0|            channel.set_peering_addr(peering_addr);
  559|      0|        }
  560|      0|    }
  561|       |
  562|      0|    pub fn peer_misbehaved(&mut self, channel_id: ChannelId, now: Timestamp) {
  563|      0|        let Some(channel) = self.channels.get(&channel_id) else {
  564|      0|            return;
  565|       |        };
  566|      0|        let channel = channel.clone();
  567|      0|
  568|      0|        // Add to peer exclusion list
  569|      0|
  570|      0|        self.excluded_peers
  571|      0|            .peer_misbehaved(&channel.peer_addr(), now);
  572|      0|
  573|      0|        let peer_addr = channel.peer_addr();
  574|      0|        let mode = channel.mode();
  575|      0|        let direction = channel.direction();
  576|      0|
  577|      0|        channel.close();
  578|      0|        warn!(?peer_addr, ?mode, ?direction, "Peer misbehaved!");
  579|      0|    }
  580|       |
  581|      0|    pub fn close(&mut self) {}
  582|       |
  583|     25|    pub fn stop(&mut self) -> bool {
  584|     25|        if self.stopped {
  585|      3|            false
  586|       |        } else {
  587|     22|            for channel in self.channels.values() {
                              ^9
  588|      9|                channel.close();
  589|      9|            }
  590|     22|            self.channels.clear();
  591|     22|            self.stopped = true;
  592|     22|            true
  593|       |        }
  594|     25|    }
  595|       |
  596|      0|    pub fn random_fill_realtime(&self, endpoints: &mut [SocketAddrV6]) {
  597|      0|        let mut peers = self.list_realtime(0);
  598|      0|        // Don't include channels with ephemeral remote ports
  599|      0|        peers.retain(|c| c.peering_addr().is_some());
  600|      0|        let mut rng = thread_rng();
  601|      0|        peers.shuffle(&mut rng);
  602|      0|        peers.truncate(endpoints.len());
  603|      0|
  604|      0|        let null_endpoint = SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0);
  605|       |
  606|      0|        for (i, target) in endpoints.iter_mut().enumerate() {
  607|      0|            let endpoint = if i < peers.len() {
  608|      0|                peers[i].peering_addr().unwrap_or(null_endpoint)
  609|       |            } else {
  610|      0|                null_endpoint
  611|       |            };
  612|      0|            *target = endpoint;
  613|       |        }
  614|      0|    }
  615|       |
  616|      0|    pub fn upgrade_to_realtime_connection(
  617|      0|        &self,
  618|      0|        channel_id: ChannelId,
  619|      0|        node_id: NodeId,
  620|      0|    ) -> Option<(Arc<Channel>, Vec<Arc<dyn Fn(Arc<Channel>) + Send + Sync>>)> {
  621|      0|        if self.is_stopped() {
  622|      0|            return None;
  623|      0|        }
  624|       |
  625|      0|        let Some(channel) = self.channels.get(&channel_id) else {
  626|      0|            return None;
  627|       |        };
  628|       |
  629|      0|        if let Some(other) = self.find_node_id(&node_id) {
  630|      0|            if other.ipv4_address_or_ipv6_subnet() == channel.ipv4_address_or_ipv6_subnet() {
  631|       |                // We already have a connection to that node. We allow duplicate node ids, but
  632|       |                // only if they come from different IP addresses
  633|      0|                return None;
  634|      0|            }
  635|      0|        }
  636|       |
  637|      0|        channel.set_node_id(node_id);
  638|      0|        channel.set_mode(ChannelMode::Realtime);
  639|      0|
  640|      0|        let observers = self.new_realtime_channel_observers();
  641|      0|        let channel = channel.clone();
  642|      0|        Some((channel, observers))
  643|      0|    }
  644|       |
  645|      0|    pub fn idle_channels(&self, min_idle_time: Duration, now: Timestamp) -> Vec<ChannelId> {
  646|      0|        let mut result = Vec::new();
  647|      0|        for channel in self.channels.values() {
  648|      0|            if channel.mode() == ChannelMode::Realtime
  649|      0|                && now - channel.last_activity() >= min_idle_time
  650|      0|            {
  651|      0|                result.push(channel.channel_id());
  652|      0|            }
  653|       |        }
  654|       |
  655|      0|        result
  656|      0|    }
  657|       |
  658|      0|    pub fn channels_info(&self) -> ChannelsInfo {
  659|      0|        let mut info = ChannelsInfo::default();
  660|      0|        for channel in self.channels.values() {
  661|      0|            info.total += 1;
  662|      0|            match channel.mode() {
  663|      0|                ChannelMode::Realtime => info.realtime += 1,
  664|      0|                _ => {}
  665|       |            }
  666|      0|            match channel.direction() {
  667|      0|                ChannelDirection::Inbound => info.inbound += 1,
  668|      0|                ChannelDirection::Outbound => info.outbound += 1,
  669|       |            }
  670|       |        }
  671|      0|        info
  672|      0|    }
  673|       |
  674|      0|    pub fn try_send_buffer(
  675|      0|        &self,
  676|      0|        channel_id: ChannelId,
  677|      0|        buffer: &[u8],
  678|      0|        traffic_type: TrafficType,
  679|      0|    ) -> bool {
  680|      0|        let channel = self.channels.get(&channel_id);
  681|      0|        if let Some(channel) = channel {
  682|      0|            channel.send(buffer, traffic_type)
  683|       |        } else {
  684|      0|            false
  685|       |        }
  686|      0|    }
  687|       |
  688|      0|    pub fn len(&self) -> usize {
  689|      0|        self.channels.len()
  690|      0|    }
  691|       |
  692|      0|    pub fn is_stopped(&self) -> bool {
  693|      0|        self.stopped
  694|      0|    }
  695|       |
  696|      0|    pub fn container_info(&self) -> ContainerInfo {
  697|      0|        ContainerInfo::builder()
  698|      0|            .leaf("channels", self.channels.len(), size_of::<Arc<Channel>>())
  699|      0|            .leaf(
  700|      0|                "attempts",
  701|      0|                self.attempts.len(),
  702|      0|                AttemptContainer::ELEMENT_SIZE,
  703|      0|            )
  704|      0|            .node("excluded_peers", self.excluded_peers.container_info())
  705|      0|            .node("bandwidth", self.bandwidth_limiter.container_info())
  706|      0|            .finish()
  707|      0|    }
  708|       |}
  709|       |
  710|       |impl Drop for Network {
  711|     22|    fn drop(&mut self) {
  712|     22|        self.stop();
  713|     22|    }
  714|       |}
  715|       |
  716|       |#[derive(Default)]
  717|       |pub struct ChannelsInfo {
  718|       |    pub total: usize,
  719|       |    pub realtime: usize,
  720|       |    pub inbound: usize,
  721|       |    pub outbound: usize,
  722|       |}
  723|       |
  724|       |#[cfg(test)]
  725|       |mod tests {
  726|       |    use super::*;
  727|       |    use rsnano_core::utils::{NULL_ENDPOINT, TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3};
  728|       |
  729|       |    #[test]
  730|       |    fn newly_added_channel_is_not_a_realtime_channel() {
  731|       |        let mut network = Network::new_test_instance();
  732|       |        network
  733|       |            .add(
  734|       |                TEST_ENDPOINT_1,
  735|       |                TEST_ENDPOINT_2,
  736|       |                ChannelDirection::Inbound,
  737|       |                Timestamp::new_test_instance(),
  738|       |            )
  739|       |            .unwrap();
  740|       |        assert_eq!(network.list_realtime_channels(0).len(), 0);
  741|       |    }
  742|       |
  743|       |    #[test]
  744|       |    fn reserved_ip_is_not_a_peer() {
  745|       |        let network = Network::new_test_instance();
  746|       |
  747|       |        assert!(network.not_a_peer(
  748|       |            &SocketAddrV6::new(Ipv6Addr::new(0xff00u16, 0, 0, 0, 0, 0, 0, 0), 1000, 0, 0),
  749|       |            true
  750|       |        ));
  751|       |        assert!(network.not_a_peer(&SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 10000, 0, 0), true));
  752|       |        assert!(network.not_a_peer(
  753|       |            &SocketAddrV6::new(Ipv6Addr::LOCALHOST, network.listening_port(), 0, 0),
  754|       |            false
  755|       |        ));
  756|       |
  757|       |        // Test with a valid IP address
  758|       |        assert_eq!(
  759|       |            network.not_a_peer(
  760|       |                &SocketAddrV6::new(Ipv6Addr::from_bits(0x08080808), 10000, 0, 0),
  761|       |                true
  762|       |            ),
  763|       |            false
  764|       |        );
  765|       |    }
  766|       |
  767|       |    #[test]
  768|       |    fn upgrade_channel_to_realtime_channel() {
  769|       |        let mut network = Network::new_test_instance();
  770|       |        let (channel, _receiver) = network
  771|       |            .add(
  772|       |                TEST_ENDPOINT_1,
  773|       |                TEST_ENDPOINT_2,
  774|       |                ChannelDirection::Inbound,
  775|       |                Timestamp::new_test_instance(),
  776|       |            )
  777|       |            .unwrap();
  778|       |
  779|       |        assert!(network
  780|       |            .upgrade_to_realtime_connection(channel.channel_id(), NodeId::from(456))
  781|       |            .is_some());
  782|       |        assert_eq!(network.list_realtime_channels(0).len(), 1);
  783|       |    }
  784|       |
  785|       |    #[test]
  786|       |    fn random_fill_peering_endpoints_empty() {
  787|       |        let network = Network::new_test_instance();
  788|       |        let mut endpoints = [NULL_ENDPOINT; 3];
  789|       |        network.random_fill_realtime(&mut endpoints);
  790|       |        assert_eq!(endpoints, [NULL_ENDPOINT; 3]);
  791|       |    }
  792|       |
  793|       |    #[test]
  794|       |    fn random_fill_peering_endpoints_part() {
  795|       |        let mut network = Network::new_test_instance();
  796|       |        add_realtime_channel_with_peering_addr(&mut network, TEST_ENDPOINT_1);
  797|       |        add_realtime_channel_with_peering_addr(&mut network, TEST_ENDPOINT_2);
  798|       |        let mut endpoints = [NULL_ENDPOINT; 3];
  799|       |        network.random_fill_realtime(&mut endpoints);
  800|       |        assert!(endpoints.contains(&TEST_ENDPOINT_1));
  801|       |        assert!(endpoints.contains(&TEST_ENDPOINT_2));
  802|       |        assert_eq!(endpoints[2], NULL_ENDPOINT);
  803|       |    }
  804|       |
  805|       |    #[test]
  806|       |    fn random_fill_peering_endpoints() {
  807|       |        let mut network = Network::new_test_instance();
  808|       |        add_realtime_channel_with_peering_addr(&mut network, TEST_ENDPOINT_1);
  809|       |        add_realtime_channel_with_peering_addr(&mut network, TEST_ENDPOINT_2);
  810|       |        add_realtime_channel_with_peering_addr(&mut network, TEST_ENDPOINT_3);
  811|       |        let mut endpoints = [NULL_ENDPOINT; 3];
  812|       |        network.random_fill_realtime(&mut endpoints);
  813|       |        assert!(endpoints.contains(&TEST_ENDPOINT_1));
  814|       |        assert!(endpoints.contains(&TEST_ENDPOINT_2));
  815|       |        assert!(endpoints.contains(&TEST_ENDPOINT_3));
  816|       |    }
  817|       |
  818|       |    fn add_realtime_channel_with_peering_addr(network: &mut Network, peering_addr: SocketAddrV6) {
  819|       |        let (channel, _receiver) = network
  820|       |            .add(
  821|       |                TEST_ENDPOINT_1,
  822|       |                peering_addr,
  823|       |                ChannelDirection::Inbound,
  824|       |                Timestamp::new_test_instance(),
  825|       |            )
  826|       |            .unwrap();
  827|       |        channel.set_peering_addr(peering_addr);
  828|       |        network.upgrade_to_realtime_connection(
  829|       |            channel.channel_id(),
  830|       |            NodeId::from(peering_addr.ip().to_bits()),
  831|       |        );
  832|       |    }
  833|       |
  834|       |    mod purging {
  835|       |        use super::*;
  836|       |
  837|       |        #[test]
  838|       |        fn purge_empty() {
  839|       |            let mut network = Network::new_test_instance();
  840|       |            network.purge(Timestamp::new_test_instance(), Duration::from_secs(1));
  841|       |            assert_eq!(network.len(), 0);
  842|       |        }
  843|       |
  844|       |        #[test]
  845|       |        fn dont_purge_new_channel() {
  846|       |            let mut network = Network::new_test_instance();
  847|       |            let now = Timestamp::new_test_instance();
  848|       |            network
  849|       |                .add(
  850|       |                    TEST_ENDPOINT_1,
  851|       |                    TEST_ENDPOINT_2,
  852|       |                    ChannelDirection::Outbound,
  853|       |                    now,
  854|       |                )
  855|       |                .unwrap();
  856|       |            network.purge(now, Duration::from_secs(1));
  857|       |            assert_eq!(network.len(), 1);
  858|       |        }
  859|       |
  860|       |        #[test]
  861|       |        fn purge_if_last_activitiy_is_above_timeout() {
  862|       |            let mut network = Network::new_test_instance();
  863|       |            let now = Timestamp::new_test_instance();
  864|       |            let (channel, _) = network
  865|       |                .add(
  866|       |                    TEST_ENDPOINT_1,
  867|       |                    TEST_ENDPOINT_2,
  868|       |                    ChannelDirection::Outbound,
  869|       |                    now,
  870|       |                )
  871|       |                .unwrap();
  872|       |            channel.set_last_activity(now - Duration::from_secs(300));
  873|       |            network.purge(now, Duration::from_secs(1));
  874|       |            assert_eq!(network.len(), 0);
  875|       |        }
  876|       |
  877|       |        #[test]
  878|       |        fn dont_purge_if_packet_sent_within_timeout() {
  879|       |            let mut network = Network::new_test_instance();
  880|       |            let now = Timestamp::new_test_instance();
  881|       |            let (channel, _) = network
  882|       |                .add(
  883|       |                    TEST_ENDPOINT_1,
  884|       |                    TEST_ENDPOINT_2,
  885|       |                    ChannelDirection::Outbound,
  886|       |                    now,
  887|       |                )
  888|       |                .unwrap();
  889|       |            channel.set_last_activity(now);
  890|       |            network.purge(now, Duration::from_secs(1));
  891|       |            assert_eq!(network.len(), 1);
  892|       |        }
  893|       |    }
  894|       |}

/home/gustav/code/nano/rsnano-node/network/src/network_observer.rs:
    1|       |use anyhow::Error;
    2|       |
    3|       |use crate::{Channel, ChannelDirection, NetworkError, TrafficType};
    4|       |use std::net::SocketAddrV6;
    5|       |
    6|       |pub trait NetworkObserver: Send + Sync {
    7|      0|    fn send_succeeded(&self, _buf_size: usize, _traffic_type: TrafficType) {}
    8|      0|    fn send_failed(&self) {}
    9|      0|    fn read_succeeded(&self, _count: usize) {}
   10|      0|    fn read_failed(&self) {}
   11|      0|    fn channel_timed_out(&self, _channel: &Channel) {}
   12|     11|    fn connection_attempt(&self, _peer: &SocketAddrV6) {}
   13|      9|    fn accepted(&self, _peer: &SocketAddrV6, _direction: ChannelDirection) {}
   14|      0|    fn error(&self, _error: NetworkError, _peer: &SocketAddrV6, _direction: ChannelDirection) {}
   15|      0|    fn connect_error(&self, _peer: SocketAddrV6, _e: Error) {}
   16|      0|    fn attempt_timeout(&self, _peer: SocketAddrV6) {}
   17|      0|    fn attempt_cancelled(&self, _peer: SocketAddrV6) {}
   18|     11|    fn merge_peer(&self) {}
   19|      0|    fn accept_failure(&self) {}
   20|       |}
   21|       |
   22|       |pub struct NullNetworkObserver {}
   23|       |
   24|       |impl NullNetworkObserver {
   25|     31|    pub fn new() -> Self {
   26|     31|        Self {}
   27|     31|    }
   28|       |}
   29|       |
   30|       |impl NetworkObserver for NullNetworkObserver {}

/home/gustav/code/nano/rsnano-node/network/src/peer_connector.rs:
    1|       |use crate::{ChannelDirection, NetworkObserver, NullNetworkObserver, TcpNetworkAdapter};
    2|       |use rsnano_nullable_tcp::TcpStream;
    3|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
    4|       |use std::{net::SocketAddrV6, sync::Arc, time::Duration};
    5|       |use tokio_util::sync::CancellationToken;
    6|       |
    7|       |/// Establishes a network connection to a given peer
    8|       |pub struct PeerConnector {
    9|       |    connect_timeout: Duration,
   10|       |    network_adapter: Arc<TcpNetworkAdapter>,
   11|       |    network_observer: Arc<dyn NetworkObserver>,
   12|       |    tokio: tokio::runtime::Handle,
   13|       |    cancel_token: CancellationToken,
   14|       |    connect_listener: OutputListenerMt<SocketAddrV6>,
   15|       |}
   16|       |
   17|       |impl PeerConnector {
   18|       |    const DEFAULT_TIMEOUT: Duration = Duration::from_secs(5);
   19|       |
   20|      3|    pub fn new(
   21|      3|        connect_timeout: Duration,
   22|      3|        network_adapter: Arc<TcpNetworkAdapter>,
   23|      3|        network_observer: Arc<dyn NetworkObserver>,
   24|      3|        tokio: tokio::runtime::Handle,
   25|      3|    ) -> Self {
   26|      3|        Self {
   27|      3|            connect_timeout,
   28|      3|            network_adapter,
   29|      3|            network_observer,
   30|      3|            tokio,
   31|      3|            cancel_token: CancellationToken::new(),
   32|      3|            connect_listener: OutputListenerMt::new(),
   33|      3|        }
   34|      3|    }
   35|       |
   36|      8|    pub fn new_null(tokio: tokio::runtime::Handle) -> Self {
   37|      8|        Self {
   38|      8|            connect_timeout: Self::DEFAULT_TIMEOUT,
   39|      8|            network_adapter: Arc::new(TcpNetworkAdapter::new_null(tokio.clone())),
   40|      8|            network_observer: Arc::new(NullNetworkObserver::new()),
   41|      8|            tokio: tokio.clone(),
   42|      8|            cancel_token: CancellationToken::new(),
   43|      8|            connect_listener: OutputListenerMt::new(),
   44|      8|        }
   45|      8|    }
   46|       |
   47|      8|    pub fn track_connections(&self) -> Arc<OutputTrackerMt<SocketAddrV6>> {
   48|      8|        self.connect_listener.track()
   49|      8|    }
   50|       |
   51|       |    /// Establish a network connection to the given peer
   52|     11|    pub fn connect_to(&self, peer: SocketAddrV6) -> bool {
   53|     11|        self.connect_listener.emit(peer);
   54|     11|
   55|     11|        if self.cancel_token.is_cancelled() {
   56|      0|            return false;
   57|     11|        }
   58|     11|
   59|     11|        let added = self.network_adapter.add_outbound_attempt(peer);
   60|     11|
   61|     11|        if !added {
   62|      0|            return false;
   63|     11|        }
   64|     11|
   65|     11|        let network_l = self.network_adapter.clone();
   66|     11|        let connect_timeout = self.connect_timeout;
   67|     11|        let cancel_token = self.cancel_token.clone();
   68|     11|        let observer = self.network_observer.clone();
   69|     11|
   70|     11|        self.tokio.spawn(async move {
   71|      0|            tokio::select! {
   72|      0|                result =  connect_impl(peer, &network_l) =>{
   73|      0|                    if let Err(e) = result {
   74|      0|                        observer.connect_error(peer, e);
   75|      0|                    }
   76|       |
   77|       |                },
   78|      0|                _ = tokio::time::sleep(connect_timeout) =>{
   79|      0|                    observer.attempt_timeout(peer);
   80|      0|
   81|      0|                }
   82|      0|                _ = cancel_token.cancelled() =>{
   83|      0|                    observer.attempt_cancelled(peer);
   84|      0|
   85|      0|                }
   86|       |            }
   87|       |
   88|      0|            network_l.remove_attempt(&peer);
   89|     11|        });
   90|     11|
   91|     11|        true
   92|     11|    }
   93|       |
   94|      3|    pub fn stop(&self) {
   95|      3|        self.cancel_token.cancel();
   96|      3|    }
   97|       |}
   98|       |
   99|      0|async fn connect_impl(
  100|      0|    peer: SocketAddrV6,
  101|      0|    network_adapter: &TcpNetworkAdapter,
  102|      0|) -> anyhow::Result<()> {
  103|      0|    let tcp_stream = connect_stream(peer).await?;
  104|      0|    network_adapter.add(tcp_stream, ChannelDirection::Outbound)
  105|      0|}
  106|       |
  107|      0|async fn connect_stream(peer: SocketAddrV6) -> tokio::io::Result<TcpStream> {
  108|      0|    let socket = tokio::net::TcpSocket::new_v6()?;
  109|      0|    let tcp_stream = socket.connect(peer.into()).await?;
  110|      0|    Ok(TcpStream::new(tcp_stream))
  111|      0|}
  112|       |
  113|       |#[cfg(test)]
  114|       |mod tests {
  115|       |    use super::*;
  116|       |    use rsnano_core::utils::TEST_ENDPOINT_1;
  117|       |
  118|       |    #[tokio::test]
  119|       |    async fn track_connections() {
  120|       |        let peer_connector = Arc::new(PeerConnector::new_null(tokio::runtime::Handle::current()));
  121|       |        let connect_tracker = peer_connector.track_connections();
  122|       |
  123|       |        peer_connector.connect_to(TEST_ENDPOINT_1);
  124|       |
  125|       |        assert_eq!(connect_tracker.output(), vec![TEST_ENDPOINT_1]);
  126|       |    }
  127|       |}

/home/gustav/code/nano/rsnano-node/network/src/peer_exclusion.rs:
    1|       |use rsnano_core::utils::ContainerInfo;
    2|       |use rsnano_nullable_clock::Timestamp;
    3|       |use std::{
    4|       |    collections::{BTreeMap, HashMap, HashSet},
    5|       |    mem::size_of,
    6|       |    net::{Ipv6Addr, SocketAddrV6},
    7|       |    time::Duration,
    8|       |};
    9|       |
   10|       |/// Manages excluded peers.
   11|       |/// Peers are excluded for a while if they behave badly
   12|       |pub struct PeerExclusion {
   13|       |    ordered_by_date: PeersOrderedByExclusionDate,
   14|       |    by_ip: HashMap<Ipv6Addr, Peer>,
   15|       |    max_size: usize,
   16|       |    perma_bans: HashSet<SocketAddrV6>,
   17|       |}
   18|       |
   19|       |impl PeerExclusion {
   20|     22|    pub fn new() -> Self {
   21|     22|        Self::with_max_size(5000)
   22|     22|    }
   23|       |
   24|       |    /// Max size is for misbehaving peers and does not include perma bans
   25|     22|    pub fn with_max_size(max_size: usize) -> Self {
   26|     22|        Self {
   27|     22|            ordered_by_date: PeersOrderedByExclusionDate::new(),
   28|     22|            by_ip: HashMap::new(),
   29|     22|            max_size,
   30|     22|            perma_bans: HashSet::new(),
   31|     22|        }
   32|     22|    }
   33|       |
   34|       |    /// Excludes the given `endpoint` for a while. If the endpoint was already
   35|       |    /// excluded its exclusion duration gets increased.
   36|       |    /// Returns the new score for the peer.
   37|      0|    pub fn peer_misbehaved(&mut self, endpoint: &SocketAddrV6, now: Timestamp) -> u64 {
   38|      0|        if let Some(peer) = self.by_ip.get_mut(&endpoint.ip()) {
   39|      0|            let old_exclution_end = peer.exclude_until;
   40|      0|            peer.misbehaved(now);
   41|      0|            if peer.exclude_until != old_exclution_end {
   42|      0|                self.ordered_by_date
   43|      0|                    .update_exclusion_end(old_exclution_end, peer);
   44|      0|            }
   45|      0|            peer.score
   46|       |        } else {
   47|      0|            self.clean_old_peers();
   48|      0|            let peer = Peer::new(*endpoint, now);
   49|      0|            self.insert(&peer);
   50|      0|            peer.score
   51|       |        }
   52|      0|    }
   53|       |
   54|       |    /// Perma bans are used for prohibiting a node to connect to itself.
   55|      0|    pub fn perma_ban(&mut self, peer_addr: SocketAddrV6) {
   56|      0|        self.perma_bans.insert(peer_addr);
   57|      0|    }
   58|       |
   59|       |    #[allow(dead_code)]
   60|      0|    pub fn contains(&self, endpoint: &SocketAddrV6) -> bool {
   61|      0|        self.by_ip.contains_key(&endpoint.ip()) || self.perma_bans.contains(endpoint)
   62|      0|    }
   63|       |
   64|       |    #[allow(dead_code)]
   65|      0|    pub fn excluded_until(&self, endpoint: &SocketAddrV6) -> Option<Timestamp> {
   66|      0|        if self.perma_bans.contains(endpoint) {
   67|      0|            Some(Timestamp::MAX)
   68|       |        } else {
   69|      0|            self.by_ip
   70|      0|                .get(&endpoint.ip())
   71|      0|                .map(|item| item.exclude_until)
   72|       |        }
   73|      0|    }
   74|       |
   75|       |    /// Checks if an endpoint is currently excluded.
   76|     31|    pub fn is_excluded(&mut self, peer_addr: &SocketAddrV6, now: Timestamp) -> bool {
   77|     31|        if self.perma_bans.contains(&peer_addr) {
   78|      0|            return true;
   79|     31|        }
   80|       |
   81|     31|        if let Some(peer) = self.by_ip.get(&peer_addr.ip()).cloned() {
                                  ^0
   82|      0|            if peer.has_expired(now) {
   83|      0|                self.remove(&peer.address);
   84|      0|            }
   85|      0|            peer.is_excluded(now)
   86|       |        } else {
   87|     31|            false
   88|       |        }
   89|     31|    }
   90|       |
   91|      0|    fn remove(&mut self, endpoint: &SocketAddrV6) {
   92|      0|        if let Some(item) = self.by_ip.remove(&endpoint.ip()) {
   93|      0|            self.ordered_by_date
   94|      0|                .remove(&item.address.ip(), item.exclude_until);
   95|      0|        }
   96|      0|    }
   97|       |
   98|       |    #[allow(dead_code)]
   99|      0|    pub fn len(&self) -> usize {
  100|      0|        self.by_ip.len() + self.perma_bans.len()
  101|      0|    }
  102|       |
  103|      0|    fn clean_old_peers(&mut self) {
  104|      0|        while self.by_ip.len() > 1 && self.by_ip.len() >= self.max_size {
  105|      0|            let ip = self.ordered_by_date.pop().unwrap();
  106|      0|            self.by_ip.remove(&ip);
  107|      0|        }
  108|      0|    }
  109|       |
  110|      0|    fn insert(&mut self, peer: &Peer) {
  111|      0|        self.ordered_by_date
  112|      0|            .insert(*peer.address.ip(), peer.exclude_until);
  113|      0|        self.by_ip.insert(*peer.address.ip(), peer.clone());
  114|      0|    }
  115|       |
  116|      0|    pub fn container_info(&self) -> ContainerInfo {
  117|      0|        [("peers", self.by_ip.len(), size_of::<Peer>())].into()
  118|      0|    }
  119|       |}
  120|       |
  121|       |impl Default for PeerExclusion {
  122|      0|    fn default() -> Self {
  123|      0|        Self::new()
  124|      0|    }
  125|       |}
  126|       |
  127|       |/// Information about a peer and its exclusion status
  128|       |#[derive(Clone)]
  129|       |struct Peer {
  130|       |    exclude_until: Timestamp,
  131|       |    address: SocketAddrV6,
  132|       |
  133|       |    /// gets increased for each bad behaviour
  134|       |    score: u64,
  135|       |}
  136|       |
  137|       |impl Peer {
  138|       |    /// When `SCORE_LIMIT` is reached then a peer will be excluded
  139|       |    const SCORE_LIMIT: u64 = 2;
  140|       |    const EXCLUDE_TIME: Duration = Duration::from_secs(60 * 60);
  141|       |    const EXCLUDE_REMOVE: Duration = Duration::from_secs(60 * 60 * 24);
  142|       |
  143|      0|    fn new(address: SocketAddrV6, now: Timestamp) -> Self {
  144|      0|        let score = 1;
  145|      0|        Self {
  146|      0|            address,
  147|      0|            exclude_until: now + Self::EXCLUDE_TIME,
  148|      0|            score,
  149|      0|        }
  150|      0|    }
  151|       |
  152|      0|    fn misbehaved(&mut self, now: Timestamp) {
  153|      0|        self.score += 1;
  154|      0|        self.exclude_until = Self::exclusion_end(self.score, now);
  155|      0|    }
  156|       |
  157|      0|    fn exclusion_end(new_score: u64, now: Timestamp) -> Timestamp {
  158|      0|        now + Self::EXCLUDE_TIME * Self::exclusion_duration_factor(new_score)
  159|      0|    }
  160|       |
  161|      0|    fn exclusion_duration_factor(new_score: u64) -> u32 {
  162|      0|        if new_score <= Self::SCORE_LIMIT {
  163|      0|            1
  164|       |        } else {
  165|      0|            new_score as u32 * 2
  166|       |        }
  167|      0|    }
  168|       |
  169|      0|    fn is_excluded(&self, now: Timestamp) -> bool {
  170|      0|        self.score >= Self::SCORE_LIMIT && self.exclude_until > now
  171|      0|    }
  172|       |
  173|      0|    fn has_expired(&self, now: Timestamp) -> bool {
  174|      0|        (self.exclude_until + Self::EXCLUDE_REMOVE * self.score as u32) < now
  175|      0|    }
  176|       |}
  177|       |
  178|       |struct PeersOrderedByExclusionDate(BTreeMap<Timestamp, Vec<Ipv6Addr>>);
  179|       |
  180|       |impl PeersOrderedByExclusionDate {
  181|     22|    pub fn new() -> Self {
  182|     22|        Self(BTreeMap::new())
  183|     22|    }
  184|       |
  185|      0|    fn pop(&mut self) -> Option<Ipv6Addr> {
  186|      0|        let (&instant, ips) = self.0.iter_mut().next()?;
  187|      0|        let ip = ips.pop().unwrap(); // ips is never empty
  188|      0|        if ips.is_empty() {
  189|      0|            self.0.remove(&instant);
  190|      0|        }
  191|      0|        Some(ip)
  192|      0|    }
  193|       |
  194|      0|    fn update_exclusion_end(&mut self, old_date: Timestamp, peer: &Peer) {
  195|      0|        self.remove(&peer.address.ip(), old_date);
  196|      0|        self.insert(*peer.address.ip(), peer.exclude_until);
  197|      0|    }
  198|       |
  199|      0|    pub fn insert(&mut self, ip: Ipv6Addr, exclude_until: Timestamp) {
  200|      0|        let entries = self.0.entry(exclude_until).or_default();
  201|      0|        entries.push(ip);
  202|      0|    }
  203|       |
  204|      0|    pub fn remove(&mut self, ip: &Ipv6Addr, exclude_until: Timestamp) {
  205|      0|        let entries = self.0.get_mut(&exclude_until).unwrap();
  206|      0|        entries.retain(|x| x != ip);
  207|      0|        if entries.is_empty() {
  208|      0|            self.0.remove(&exclude_until);
  209|      0|        }
  210|      0|    }
  211|       |}
  212|       |
  213|       |#[cfg(test)]
  214|       |mod tests {
  215|       |    use super::*;
  216|       |    use std::net::Ipv6Addr;
  217|       |
  218|       |    #[test]
  219|       |    fn new_excluded_peers_excludes_nothing() {
  220|       |        let mut peers = PeerExclusion::new();
  221|       |        assert_eq!(peers.is_excluded(&test_endpoint(1), NOW), false);
  222|       |        assert_eq!(peers.is_excluded(&test_endpoint(2), NOW), false);
  223|       |    }
  224|       |
  225|       |    mod misbehavior {
  226|       |        use super::*;
  227|       |
  228|       |        #[test]
  229|       |        fn misbehaving_once_is_allowed() {
  230|       |            let mut peers = PeerExclusion::new();
  231|       |            let endpoint = test_endpoint(1);
  232|       |            peers.peer_misbehaved(&endpoint, NOW);
  233|       |            assert_eq!(peers.is_excluded(&endpoint, NOW), false);
  234|       |        }
  235|       |
  236|       |        #[test]
  237|       |        fn misbehaving_twice_leads_to_a_ban() {
  238|       |            let mut peers = PeerExclusion::new();
  239|       |            let endpoint = test_endpoint(1);
  240|       |            peers.peer_misbehaved(&endpoint, NOW);
  241|       |            peers.peer_misbehaved(&endpoint, NOW);
  242|       |            assert_eq!(peers.is_excluded(&endpoint, NOW), true);
  243|       |            assert_eq!(
  244|       |                peers.excluded_until(&endpoint),
  245|       |                Some(NOW + Peer::EXCLUDE_TIME)
  246|       |            );
  247|       |        }
  248|       |
  249|       |        #[test]
  250|       |        fn misbehaving_more_than_twice_increases_exclusion_time() {
  251|       |            let mut peers = PeerExclusion::new();
  252|       |            let endpoint = test_endpoint(1);
  253|       |            peers.peer_misbehaved(&endpoint, NOW);
  254|       |            peers.peer_misbehaved(&endpoint, NOW);
  255|       |            peers.peer_misbehaved(&endpoint, NOW);
  256|       |            assert_eq!(
  257|       |                peers.excluded_until(&endpoint),
  258|       |                Some(NOW + Peer::EXCLUDE_TIME * 6)
  259|       |            );
  260|       |            peers.peer_misbehaved(&endpoint, NOW);
  261|       |            assert_eq!(
  262|       |                peers.excluded_until(&endpoint),
  263|       |                Some(NOW + Peer::EXCLUDE_TIME * 8)
  264|       |            );
  265|       |        }
  266|       |
  267|       |        #[test]
  268|       |        fn peer_misbehavior_ignores_port() {
  269|       |            let mut endpoint1 = test_endpoint(1);
  270|       |            let mut endpoint2 = endpoint1.clone();
  271|       |            endpoint1.set_port(100);
  272|       |            endpoint2.set_port(200);
  273|       |
  274|       |            let mut peers = PeerExclusion::new();
  275|       |            peers.peer_misbehaved(&endpoint1, NOW);
  276|       |            peers.peer_misbehaved(&endpoint2, NOW);
  277|       |
  278|       |            assert!(peers.is_excluded(&endpoint1, NOW));
  279|       |            assert!(peers.is_excluded(&endpoint2, NOW));
  280|       |        }
  281|       |    }
  282|       |
  283|       |    mod max_size {
  284|       |        use super::*;
  285|       |
  286|       |        #[test]
  287|       |        fn remove_oldest_entry_when_size_limit_reached() {
  288|       |            let mut peers = PeerExclusion::with_max_size(6);
  289|       |            for i in 0..7 {
  290|       |                peers.peer_misbehaved(&test_endpoint(i), NOW + Duration::from_millis(i as u64));
  291|       |            }
  292|       |            assert_eq!(peers.len(), 6);
  293|       |            assert_eq!(peers.contains(&test_endpoint(0)), false);
  294|       |            assert_eq!(peers.contains(&test_endpoint(1)), true);
  295|       |        }
  296|       |
  297|       |        #[test]
  298|       |        fn remove_many_old_entries() {
  299|       |            let mut peers = PeerExclusion::with_max_size(2);
  300|       |            for i in 0..7 {
  301|       |                peers.peer_misbehaved(&test_endpoint(i), NOW + Duration::from_millis(i as u64));
  302|       |            }
  303|       |
  304|       |            assert_eq!(peers.len(), 2);
  305|       |            assert_eq!(peers.contains(&test_endpoint(4)), false);
  306|       |            assert_eq!(peers.contains(&test_endpoint(5)), true);
  307|       |            assert_eq!(peers.contains(&test_endpoint(6)), true);
  308|       |        }
  309|       |    }
  310|       |
  311|       |    mod perma_bans {
  312|       |        use super::*;
  313|       |
  314|       |        #[test]
  315|       |        fn perma_ban() {
  316|       |            let mut peers = PeerExclusion::new();
  317|       |            let endpoint = test_endpoint(1);
  318|       |            peers.perma_ban(endpoint);
  319|       |            assert!(peers.is_excluded(&endpoint, NOW));
  320|       |            assert!(peers.is_excluded(&endpoint, NOW + Duration::from_secs(60 * 60 * 24 * 365)));
  321|       |            assert_eq!(peers.excluded_until(&endpoint), Some(Timestamp::MAX));
  322|       |            assert!(peers.contains(&endpoint));
  323|       |            assert_eq!(peers.len(), 1);
  324|       |        }
  325|       |    }
  326|       |
  327|       |    fn test_endpoint(i: usize) -> SocketAddrV6 {
  328|       |        SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, i as u16), 0, 0, 0)
  329|       |    }
  330|       |
  331|       |    const NOW: Timestamp = Timestamp::new_test_instance();
  332|       |}

/home/gustav/code/nano/rsnano-node/network/src/tcp_channel_adapter.rs:
    1|       |use crate::{
    2|       |    bandwidth_limiter::BandwidthLimiter, Channel, ChannelDirection, ChannelId, NullNetworkObserver,
    3|       |};
    4|       |use rsnano_core::utils::{TEST_ENDPOINT_1, TEST_ENDPOINT_2};
    5|       |use rsnano_nullable_clock::{SteadyClock, Timestamp};
    6|       |use rsnano_nullable_tcp::TcpStream;
    7|       |use std::{
    8|       |    fmt::Display,
    9|       |    sync::{Arc, Weak},
   10|       |    time::Duration,
   11|       |};
   12|       |use tokio::{select, time::sleep};
   13|       |
   14|       |/// Connects a Channel with a TcpStream
   15|       |pub struct TcpChannelAdapter {
   16|       |    pub channel: Arc<Channel>,
   17|       |    stream: Weak<TcpStream>,
   18|       |    clock: Arc<SteadyClock>,
   19|       |}
   20|       |
   21|       |impl TcpChannelAdapter {
   22|      0|    fn new(channel: Arc<Channel>, stream: Weak<TcpStream>, clock: Arc<SteadyClock>) -> Self {
   23|      0|        Self {
   24|      0|            channel,
   25|      0|            stream,
   26|      0|            clock,
   27|      0|        }
   28|      0|    }
   29|       |
   30|      0|    pub fn new_null() -> Self {
   31|      0|        Self::new_null_with_id(42)
   32|      0|    }
   33|       |
   34|      0|    pub fn new_null_with_id(id: impl Into<ChannelId>) -> Self {
   35|      0|        let channel_id = id.into();
   36|      0|        let channel = Self::new(
   37|      0|            Arc::new(Channel::new(
   38|      0|                channel_id,
   39|      0|                TEST_ENDPOINT_1,
   40|      0|                TEST_ENDPOINT_2,
   41|      0|                ChannelDirection::Outbound,
   42|      0|                u8::MAX,
   43|      0|                Timestamp::new_test_instance(),
   44|      0|                Arc::new(BandwidthLimiter::default()),
   45|      0|                Arc::new(NullNetworkObserver::new()),
   46|      0|            )),
   47|      0|            Arc::downgrade(&Arc::new(TcpStream::new_null())),
   48|      0|            Arc::new(SteadyClock::new_null()),
   49|      0|        );
   50|      0|        channel
   51|      0|    }
   52|       |
   53|      0|    pub fn create(
   54|      0|        channel: Arc<Channel>,
   55|      0|        stream: TcpStream,
   56|      0|        clock: Arc<SteadyClock>,
   57|      0|        handle: &tokio::runtime::Handle,
   58|      0|    ) -> Arc<Self> {
   59|      0|        let stream = Arc::new(stream);
   60|      0|        let channel_adapter = Self::new(channel.clone(), Arc::downgrade(&stream), clock.clone());
   61|      0|
   62|      0|        // process write queue:
   63|      0|        handle.spawn(async move {
   64|       |            loop {
   65|      0|                let res = select! {
   66|      0|                    _ = channel.cancelled() =>{
   67|      0|                        return;
   68|       |                    },
   69|      0|                  res = channel.pop() => res
   70|       |                };
   71|       |
   72|      0|                if let Some(entry) = res {
   73|      0|                    let mut written = 0;
   74|      0|                    let buffer = &entry.buffer;
   75|       |                    loop {
   76|      0|                        select! {
   77|      0|                            _ = channel.cancelled() =>{
   78|      0|                                return;
   79|       |                            }
   80|      0|                            res = stream.writable() =>{
   81|      0|                            match res {
   82|      0|                            Ok(()) => match stream.try_write(&buffer[written..]) {
   83|      0|                                Ok(n) => {
   84|      0|                                    written += n;
   85|      0|                                    if written >= buffer.len() {
   86|      0|                                        channel.set_last_activity(clock.now());
   87|      0|                                        break;
   88|      0|                                    }
   89|       |                                }
   90|      0|                                Err(ref e) if e.kind() == std::io::ErrorKind::WouldBlock => {
   91|      0|                                    continue;
   92|       |                                }
   93|       |                                Err(_) => {
   94|      0|                                    channel.close();
   95|      0|                                    return;
   96|       |                                }
   97|       |                            },
   98|       |                            Err(_) => {
   99|      0|                                channel.close();
  100|      0|                                return;
  101|       |                            }
  102|       |                        }
  103|       |                            }
  104|       |                        }
  105|       |                    }
  106|       |                } else {
  107|      0|                    break;
  108|      0|                }
  109|      0|            }
  110|      0|            channel.close();
  111|      0|        });
  112|      0|
  113|      0|        let channel = Arc::new(channel_adapter);
  114|      0|        let channel_l = channel.clone();
  115|      0|        handle.spawn(async move { channel_l.ongoing_checkup().await });
  116|      0|        channel
  117|      0|    }
  118|       |
  119|      0|    pub async fn readable(&self) -> anyhow::Result<()> {
  120|      0|        if self.channel.is_closed() {
  121|      0|            return Err(anyhow!("Tried to read from a closed TcpStream"));
  122|      0|        }
  123|       |
  124|      0|        let Some(stream) = self.stream.upgrade() else {
  125|      0|            return Err(anyhow!("TCP stream dropped"));
  126|       |        };
  127|       |
  128|      0|        let res = select! {
  129|      0|            _  = self.channel.cancelled() =>{
  130|      0|                return Err(anyhow!("cancelled"));
  131|       |            },
  132|      0|            res = stream.readable() => res
  133|      0|        };
  134|      0|
  135|      0|        match res {
  136|      0|            Ok(_) => Ok(()),
  137|      0|            Err(e) => {
  138|      0|                self.channel.read_failed();
  139|      0|                return Err(e.into());
  140|       |            }
  141|       |        }
  142|      0|    }
  143|       |
  144|      0|    pub fn try_read(&self, buffer: &mut [u8]) -> anyhow::Result<usize> {
  145|      0|        let Some(stream) = self.stream.upgrade() else {
  146|      0|            return Err(anyhow!("TCP stream dropped"));
  147|       |        };
  148|       |
  149|      0|        match stream.try_read(buffer) {
  150|       |            Ok(0) => {
  151|      0|                self.channel.read_failed();
  152|      0|                Err(anyhow!("remote side closed the channel"))
  153|       |            }
  154|      0|            Ok(n) => {
  155|      0|                self.channel.read_succeeded(n, self.clock.now());
  156|      0|                Ok(n)
  157|       |            }
  158|      0|            Err(ref e) if e.kind() == std::io::ErrorKind::WouldBlock => Ok(0),
  159|      0|            Err(e) => {
  160|      0|                self.channel.read_failed();
  161|      0|                Err(e.into())
  162|       |            }
  163|       |        }
  164|      0|    }
  165|       |
  166|      0|    async fn ongoing_checkup(&self) {
  167|       |        loop {
  168|      0|            sleep(Duration::from_secs(2)).await;
  169|      0|            let now = self.clock.now();
  170|      0|            let timed_out = self.channel.check_timeout(now);
  171|      0|            if timed_out {
  172|      0|                break;
  173|      0|            }
  174|       |        }
  175|      0|    }
  176|       |}
  177|       |
  178|       |impl Display for TcpChannelAdapter {
  179|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  180|      0|        self.channel.peer_addr().fmt(f)
  181|      0|    }
  182|       |}
  183|       |
  184|       |impl Drop for TcpChannelAdapter {
  185|      0|    fn drop(&mut self) {
  186|      0|        self.channel.close();
  187|      0|    }
  188|       |}

/home/gustav/code/nano/rsnano-node/network/src/tcp_listener.rs:
    1|       |use crate::{ChannelDirection, NetworkObserver, TcpNetworkAdapter};
    2|       |use async_trait::async_trait;
    3|       |use rsnano_nullable_tcp::TcpStream;
    4|       |use std::{
    5|       |    net::{IpAddr, Ipv6Addr, SocketAddr, SocketAddrV6},
    6|       |    sync::{
    7|       |        atomic::{AtomicU16, Ordering},
    8|       |        Arc, Condvar, Mutex,
    9|       |    },
   10|       |    time::Duration,
   11|       |};
   12|       |use tokio::time::sleep;
   13|       |use tokio_util::sync::CancellationToken;
   14|       |use tracing::{debug, error, warn};
   15|       |
   16|       |/// Server side portion of tcp sessions. Listens for new socket connections and spawns tcp_server objects when connected.
   17|       |pub struct TcpListener {
   18|       |    port: AtomicU16,
   19|       |    network_adapter: Arc<TcpNetworkAdapter>,
   20|       |    network_observer: Arc<dyn NetworkObserver>,
   21|       |    tokio: tokio::runtime::Handle,
   22|       |    data: Mutex<TcpListenerData>,
   23|       |    condition: Condvar,
   24|       |    cancel_token: CancellationToken,
   25|       |}
   26|       |
   27|       |impl Drop for TcpListener {
   28|      3|    fn drop(&mut self) {
   29|      3|        debug_assert!(self.data.lock().unwrap().stopped);
   30|      3|    }
   31|       |}
   32|       |
   33|       |struct TcpListenerData {
   34|       |    stopped: bool,
   35|       |    local_addr: SocketAddrV6,
   36|       |}
   37|       |
   38|       |impl TcpListener {
   39|      3|    pub fn new(
   40|      3|        port: u16,
   41|      3|        network_adapter: Arc<TcpNetworkAdapter>,
   42|      3|        network_observer: Arc<dyn NetworkObserver>,
   43|      3|        tokio: tokio::runtime::Handle,
   44|      3|    ) -> Self {
   45|      3|        Self {
   46|      3|            port: AtomicU16::new(port),
   47|      3|            network_adapter,
   48|      3|            network_observer,
   49|      3|            data: Mutex::new(TcpListenerData {
   50|      3|                stopped: true,
   51|      3|                local_addr: SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0),
   52|      3|            }),
   53|      3|            tokio,
   54|      3|            condition: Condvar::new(),
   55|      3|            cancel_token: CancellationToken::new(),
   56|      3|        }
   57|      3|    }
   58|       |
   59|      3|    pub fn stop(&self) {
   60|      3|        self.data.lock().unwrap().stopped = true;
   61|      3|        self.cancel_token.cancel();
   62|      3|        self.condition.notify_all();
   63|      3|    }
   64|       |
   65|      0|    pub fn local_address(&self) -> SocketAddrV6 {
   66|      0|        let guard = self.data.lock().unwrap();
   67|      0|        if !guard.stopped {
   68|      0|            guard.local_addr
   69|       |        } else {
   70|      0|            SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0)
   71|       |        }
   72|      0|    }
   73|       |}
   74|       |
   75|       |#[async_trait]
   76|       |pub trait TcpListenerExt {
   77|       |    fn start(&self);
   78|       |    async fn run(&self, listener: tokio::net::TcpListener);
   79|       |}
   80|       |
   81|       |#[async_trait]
   82|       |impl TcpListenerExt for Arc<TcpListener> {
   83|      3|    fn start(&self) {
   84|      3|        self.data.lock().unwrap().stopped = false;
   85|      3|        let self_l = Arc::clone(self);
   86|      3|        self.tokio.spawn(async move {
   87|      0|            let port = self_l.port.load(Ordering::SeqCst);
   88|      0|            let Ok(listener) = tokio::net::TcpListener::bind(SocketAddr::new(
   89|      0|                IpAddr::V6(Ipv6Addr::UNSPECIFIED),
   90|      0|                port,
   91|      0|            ))
   92|      0|            .await
   93|       |            else {
   94|      0|                error!("Error while binding for incoming connections on: {}", port);
   95|      0|                return;
   96|       |            };
   97|       |
   98|      0|            let addr = listener
   99|      0|                .local_addr()
  100|      0|                .map(|a| match a {
  101|      0|                    SocketAddr::V6(v6) => v6,
  102|      0|                    _ => unreachable!(), // We only use V6 addresses
  103|      0|                })
  104|      0|                .unwrap_or(SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0));
  105|      0|
  106|      0|            debug!("Listening for incoming connections on: {}", addr);
  107|      0|            self_l.network_adapter.set_listening_port(addr.port());
  108|      0|
  109|      0|            self_l.data.lock().unwrap().local_addr =
  110|      0|                SocketAddrV6::new(Ipv6Addr::LOCALHOST, addr.port(), 0, 0);
  111|      0|
  112|      0|            self_l.run(listener).await
  113|      3|        });
                      ^0
  114|      3|    }
  115|       |
  116|      0|    async fn run(&self, listener: tokio::net::TcpListener) {
  117|      0|        let run_loop = async {
  118|       |            loop {
  119|      0|                self.network_adapter.wait_for_available_inbound_slot().await;
  120|       |
  121|      0|                let Ok((stream, _)) = listener.accept().await else {
  122|      0|                    warn!("Could not accept incoming connection");
  123|      0|                    self.network_observer.accept_failure();
  124|      0|                    continue;
  125|       |                };
  126|       |
  127|      0|                let tcp_stream = TcpStream::new(stream);
  128|      0|                match self
  129|      0|                    .network_adapter
  130|      0|                    .add(tcp_stream, ChannelDirection::Inbound)
  131|       |                {
  132|      0|                    Ok(()) => {}
  133|      0|                    Err(e) => {
  134|      0|                        warn!("Could not accept incoming connection: {:?}", e);
  135|       |                    }
  136|       |                };
  137|       |
  138|       |                // Sleep for a while to prevent busy loop
  139|      0|                sleep(Duration::from_millis(10)).await;
  140|       |            }
  141|       |        };
  142|       |
  143|      0|        tokio::select! {
  144|      0|            _ = self.cancel_token.cancelled() => { },
  145|      0|            _ = run_loop => {}
  146|       |        }
  147|      0|    }
  148|       |}

/home/gustav/code/nano/rsnano-node/network/src/tcp_network_adapter.rs:
    1|       |use crate::{
    2|       |    utils::into_ipv6_socket_address, ChannelDirection, ChannelId, DeadChannelCleanupStep, Network,
    3|       |    ReceiveResult, TcpChannelAdapter,
    4|       |};
    5|       |use rsnano_core::utils::NULL_ENDPOINT;
    6|       |use rsnano_nullable_clock::SteadyClock;
    7|       |use rsnano_nullable_tcp::TcpStream;
    8|       |use std::{
    9|       |    collections::HashMap,
   10|       |    net::SocketAddrV6,
   11|       |    sync::{Arc, Mutex, RwLock},
   12|       |    time::{Duration, Instant},
   13|       |};
   14|       |use tokio::time::sleep;
   15|       |use tracing::{debug, warn};
   16|       |
   17|       |/// Connects the Network to TcpStreams
   18|       |pub struct TcpNetworkAdapter {
   19|       |    channel_adapters: Mutex<HashMap<ChannelId, Arc<TcpChannelAdapter>>>,
   20|       |    network: Arc<RwLock<Network>>,
   21|       |    clock: Arc<SteadyClock>,
   22|       |    tokio: tokio::runtime::Handle,
   23|       |}
   24|       |
   25|       |impl TcpNetworkAdapter {
   26|     11|    pub fn new(
   27|     11|        network_info: Arc<RwLock<Network>>,
   28|     11|        clock: Arc<SteadyClock>,
   29|     11|        handle: tokio::runtime::Handle,
   30|     11|    ) -> Self {
   31|     11|        Self {
   32|     11|            channel_adapters: Mutex::new(HashMap::new()),
   33|     11|            clock,
   34|     11|            network: network_info,
   35|     11|            tokio: handle,
   36|     11|        }
   37|     11|    }
   38|       |
   39|      0|    pub async fn wait_for_available_inbound_slot(&self) {
   40|      0|        let last_log = Instant::now();
   41|      0|        let log_interval = Duration::from_secs(15);
   42|      0|        while self.should_wait_for_inbound_slot() {
   43|      0|            if last_log.elapsed() >= log_interval {
   44|      0|                warn!("Waiting for available slots to accept new connections");
   45|      0|            }
   46|       |
   47|      0|            tokio::time::sleep(Duration::from_millis(100)).await;
   48|       |        }
   49|      0|    }
   50|       |
   51|      0|    fn should_wait_for_inbound_slot(&self) -> bool {
   52|      0|        let network = self.network.read().unwrap();
   53|      0|        !network.is_inbound_slot_available() && !network.is_stopped()
   54|      0|    }
   55|       |
   56|      0|    pub fn add(&self, stream: TcpStream, direction: ChannelDirection) -> anyhow::Result<()> {
   57|      0|        let peer_addr = stream
   58|      0|            .peer_addr()
   59|      0|            .map(into_ipv6_socket_address)
   60|      0|            .unwrap_or(NULL_ENDPOINT);
   61|      0|
   62|      0|        let local_addr = stream
   63|      0|            .local_addr()
   64|      0|            .map(into_ipv6_socket_address)
   65|      0|            .unwrap_or(NULL_ENDPOINT);
   66|       |
   67|      0|        let (channel, mut receiver) = self
   68|      0|            .network
   69|      0|            .write()
   70|      0|            .unwrap()
   71|      0|            .add(local_addr, peer_addr, direction, self.clock.now())
   72|      0|            .map_err(|e| anyhow!("Could not add channel: {:?}", e))?;
   73|       |
   74|      0|        let channel_id = channel.channel_id();
   75|      0|        let channel_adapter =
   76|      0|            TcpChannelAdapter::create(channel, stream, self.clock.clone(), &self.tokio);
   77|      0|
   78|      0|        self.channel_adapters
   79|      0|            .lock()
   80|      0|            .unwrap()
   81|      0|            .insert(channel_id, channel_adapter.clone());
   82|      0|
   83|      0|        debug!(?peer_addr, ?direction, "Accepted connection");
   84|       |
   85|      0|        self.tokio.spawn(async move {
   86|      0|            let channel = channel_adapter.channel.clone();
   87|      0|            let mut buffer = [0u8; 1024];
   88|       |
   89|       |            loop {
   90|      0|                if channel.is_closed() {
   91|      0|                    return;
   92|      0|                }
   93|      0|
   94|      0|                tokio::select! {
   95|      0|                    result = channel_adapter.readable() => {
   96|      0|                        if let Err(e) = result {
   97|      0|                            debug!("Error reading buffer: {:?} ({})", e, channel.peer_addr());
   98|      0|                            return;
   99|      0|                        }
  100|       |                    },
  101|      0|                    _ = channel.cancelled() => {
  102|      0|                        return;
  103|       |                    }
  104|       |                }
  105|       |
  106|      0|                let read_count = match channel_adapter.try_read(&mut buffer) {
  107|      0|                    Ok(n) => n,
  108|      0|                    Err(e) => {
  109|      0|                        debug!("Error reading buffer: {:?} ({})", e, channel.peer_addr());
  110|      0|                        return;
  111|       |                    }
  112|       |                };
  113|       |
  114|      0|                let new_data = &buffer[..read_count];
  115|      0|
  116|      0|                match receiver.receive(new_data) {
  117|      0|                    ReceiveResult::Continue => {}
  118|      0|                    ReceiveResult::Abort => break,
  119|       |                    ReceiveResult::Pause => {
  120|       |                        loop {
  121|       |                            // TODO find better solution than sleep and polling
  122|      0|                            tokio::select! {
  123|      0|                                _ = sleep(Duration::from_millis(50)) => {},
  124|      0|                                _ = channel.cancelled() => { break;}
  125|       |                            }
  126|      0|                            match receiver.try_unpause() {
  127|      0|                                ReceiveResult::Continue => break,
  128|      0|                                ReceiveResult::Abort => return,
  129|      0|                                ReceiveResult::Pause => {}
  130|       |                            }
  131|       |                        }
  132|       |                    }
  133|       |                }
  134|       |            }
  135|      0|        });
  136|      0|
  137|      0|        Ok(())
  138|      0|    }
  139|       |
  140|     11|    pub fn add_outbound_attempt(&self, peer: SocketAddrV6) -> bool {
  141|     11|        self.network
  142|     11|            .write()
  143|     11|            .unwrap()
  144|     11|            .add_outbound_attempt(peer, self.clock.now())
  145|     11|    }
  146|       |
  147|      0|    pub fn remove_attempt(&self, peer: &SocketAddrV6) {
  148|      0|        self.network.write().unwrap().remove_attempt(peer);
  149|      0|    }
  150|       |
  151|      0|    pub fn set_listening_port(&self, port: u16) {
  152|      0|        self.network.write().unwrap().set_listening_port(port);
  153|      0|    }
  154|       |
  155|      8|    pub fn new_null(handle: tokio::runtime::Handle) -> Self {
  156|      8|        Self::new(
  157|      8|            Arc::new(RwLock::new(Network::new_test_instance())),
  158|      8|            Arc::new(SteadyClock::new_null()),
  159|      8|            handle,
  160|      8|        )
  161|      8|    }
  162|       |}
  163|       |
  164|       |pub struct NetworkCleanup(Arc<TcpNetworkAdapter>);
  165|       |
  166|       |impl NetworkCleanup {
  167|      3|    pub fn new(network: Arc<TcpNetworkAdapter>) -> Self {
  168|      3|        Self(network)
  169|      3|    }
  170|       |}
  171|       |
  172|       |impl DeadChannelCleanupStep for NetworkCleanup {
  173|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  174|      0|        let mut channels = self.0.channel_adapters.lock().unwrap();
  175|      0|        for channel_id in dead_channel_ids {
  176|      0|            channels.remove(channel_id);
  177|      0|        }
  178|      0|    }
  179|       |}

/home/gustav/code/nano/rsnano-node/network/src/token_bucket.rs:
    1|       |#[cfg(test)]
    2|       |use mock_instant::thread_local::Instant;
    3|       |use std::time::Duration;
    4|       |#[cfg(not(test))]
    5|       |use std::time::Instant;
    6|       |
    7|       |/**
    8|       | * Token bucket based rate limiting. This is suitable for rate limiting ipc/api calls
    9|       | * and network traffic, while allowing short bursts.
   10|       | *
   11|       | * Tokens are refilled at N tokens per second and there's a bucket capacity to limit
   12|       | * bursts.
   13|       | *
   14|       | * A bucket has low overhead and can be instantiated for various purposes, such as one
   15|       | * bucket per session, or one for bandwidth limiting. A token can represent bytes,
   16|       | * messages, or the cost of API invocations.
   17|       | */
   18|       |pub struct TokenBucket {
   19|       |    last_refill: Instant,
   20|       |    current_size: usize,
   21|       |    max_token_count: usize,
   22|       |
   23|       |    /** The minimum observed bucket size, from which the largest burst can be derived */
   24|       |    smallest_size: usize,
   25|       |    refill_rate: usize,
   26|       |}
   27|       |
   28|       |const UNLIMITED: usize = 1_000_000_000;
   29|       |
   30|       |impl TokenBucket {
   31|       |    /**
   32|       |     * Set up a token bucket.
   33|       |     * @param max_token_count Maximum number of tokens in this bucket, which limits bursts.
   34|       |     * @param refill_rate Token refill rate, which limits the long term rate (tokens per seconds)
   35|       |     */
   36|     64|    pub fn new(max_token_count: usize, refill_rate: usize) -> Self {
   37|     64|        let mut result = Self {
   38|     64|            last_refill: Instant::now(),
   39|     64|            max_token_count,
   40|     64|            refill_rate,
   41|     64|            current_size: 0,
   42|     64|            smallest_size: 0,
   43|     64|        };
   44|     64|
   45|     64|        result.reset(max_token_count, refill_rate);
   46|     64|        result
   47|     64|    }
   48|       |
   49|       |    /**
   50|       |     * Determine if an operation of cost \p tokens_required_a is possible, and deduct from the
   51|       |     * bucket if that's the case.
   52|       |     * The default cost is 1 token, but resource intensive operations may request
   53|       |     * more tokens to be available.
   54|       |     */
   55|     54|    pub fn try_consume(&mut self, tokens_required: usize) -> bool {
   56|     54|        debug_assert!(tokens_required <= UNLIMITED);
   57|     54|        self.refill();
   58|     54|        let possible = self.current_size >= tokens_required;
   59|     54|        if possible {
   60|     48|            self.current_size -= tokens_required;
   61|     48|        } else if tokens_required == UNLIMITED {
                                ^6
   62|      0|            self.current_size = 0;
   63|      6|        }
   64|       |
   65|       |        // Keep track of smallest observed bucket size so burst size can be computed (for tests and stats)
   66|     54|        self.smallest_size = std::cmp::min(self.smallest_size, self.current_size);
   67|     54|
   68|     54|        possible || self.refill_rate == UNLIMITED
                                  ^6
   69|     54|    }
   70|       |
   71|       |    /** Update the max_token_count and/or refill_rate_a parameters */
   72|     64|    pub fn reset(&mut self, mut max_token_count: usize, mut refill_rate: usize) {
   73|     64|        // A token count of 0 indicates unlimited capacity. We use 1e9 as
   74|     64|        // a sentinel, allowing largest burst to still be computed.
   75|     64|        if max_token_count == 0 || refill_rate == 0 {
   76|      0|            refill_rate = UNLIMITED;
   77|      0|            max_token_count = UNLIMITED;
   78|     64|        }
   79|     64|        self.smallest_size = max_token_count;
   80|     64|        self.max_token_count = max_token_count;
   81|     64|        self.current_size = max_token_count;
   82|     64|        self.refill_rate = refill_rate;
   83|     64|        self.last_refill = Instant::now()
   84|     64|    }
   85|       |
   86|       |    /** Returns the largest burst observed */
   87|       |    #[allow(dead_code)]
   88|      0|    pub fn largest_burst(&self) -> usize {
   89|      0|        self.max_token_count - self.smallest_size
   90|      0|    }
   91|       |
   92|      0|    pub fn size(&self) -> usize {
   93|      0|        self.current_size
   94|      0|    }
   95|       |
   96|     54|    fn refill(&mut self) {
   97|     54|        let tokens_to_add =
   98|     54|            (self.elapsed().as_nanos() as f64 / 1e9_f64 * self.refill_rate as f64) as usize;
   99|     54|        // Only update if there are any tokens to add
  100|     54|        if tokens_to_add > 0 {
  101|      9|            self.current_size =
  102|      9|                std::cmp::min(self.current_size + tokens_to_add, self.max_token_count);
  103|      9|            self.last_refill = Instant::now();
  104|     45|        }
  105|     54|    }
  106|       |
  107|     54|    fn elapsed(&mut self) -> Duration {
  108|     54|        Instant::now().duration_since(self.last_refill)
  109|     54|    }
  110|       |}
  111|       |
  112|       |#[cfg(test)]
  113|       |mod tests {
  114|       |    use super::*;
  115|       |    use mock_instant::thread_local::MockClock;
  116|       |
  117|       |    #[test]
  118|       |    fn basic() {
  119|       |        let mut bucket = TokenBucket::new(10, 10);
  120|       |
  121|       |        // Initial burst
  122|       |        assert_eq!(bucket.try_consume(10), true);
  123|       |        assert_eq!(bucket.try_consume(10), false);
  124|       |
  125|       |        // With a fill rate of 10 tokens/sec, await 1/3 sec and get 3 tokens
  126|       |        MockClock::advance(Duration::from_millis(300));
  127|       |        assert_eq!(bucket.try_consume(3), true);
  128|       |        assert_eq!(bucket.try_consume(10), false);
  129|       |
  130|       |        // Allow time for the bucket to completely refill and do a full burst
  131|       |        MockClock::advance(Duration::from_secs(1));
  132|       |        assert_eq!(bucket.try_consume(10), true);
  133|       |        assert_eq!(bucket.largest_burst(), 10);
  134|       |    }
  135|       |
  136|       |    #[test]
  137|       |    fn network() {
  138|       |        // For the purpose of the test, one token represents 1MB instead of one byte.
  139|       |        // Allow for 10 mb/s bursts (max bucket size), 5 mb/s long term rate
  140|       |        let mut bucket = TokenBucket::new(10, 5);
  141|       |
  142|       |        // Initial burst of 10 mb/s over two calls
  143|       |        assert_eq!(bucket.try_consume(5), true);
  144|       |        assert_eq!(bucket.largest_burst(), 5);
  145|       |        assert_eq!(bucket.try_consume(5), true);
  146|       |        assert_eq!(bucket.largest_burst(), 10);
  147|       |        assert_eq!(bucket.try_consume(5), false);
  148|       |
  149|       |        // After 200 ms, the 5 mb/s fillrate means we have 1 mb available
  150|       |        MockClock::advance(Duration::from_millis(200));
  151|       |        assert_eq!(bucket.try_consume(1), true);
  152|       |        assert_eq!(bucket.try_consume(1), false);
  153|       |    }
  154|       |
  155|       |    #[test]
  156|       |    fn reset() {
  157|       |        let mut bucket = TokenBucket::new(0, 0);
  158|       |
  159|       |        // consume lots of tokens, buckets should be unlimited
  160|       |        assert!(bucket.try_consume(1000000));
  161|       |        assert!(bucket.try_consume(1000000));
  162|       |
  163|       |        // set bucket to be limited
  164|       |        bucket.reset(1000, 1000);
  165|       |        assert_eq!(bucket.try_consume(1001), false);
  166|       |        assert_eq!(bucket.try_consume(1000), true);
  167|       |        assert_eq!(bucket.try_consume(1000), false);
  168|       |        MockClock::advance(Duration::from_millis(2));
  169|       |        assert_eq!(bucket.try_consume(2), true);
  170|       |
  171|       |        // reduce the limit
  172|       |        bucket.reset(100, 100 * 1000);
  173|       |        assert_eq!(bucket.try_consume(101), false);
  174|       |        assert_eq!(bucket.try_consume(100), true);
  175|       |        MockClock::advance(Duration::from_millis(1));
  176|       |        assert_eq!(bucket.try_consume(100), true);
  177|       |
  178|       |        // increase the limit
  179|       |        bucket.reset(2000, 1);
  180|       |        assert_eq!(bucket.try_consume(2001), false);
  181|       |        assert_eq!(bucket.try_consume(2000), true);
  182|       |
  183|       |        // back to unlimited
  184|       |        bucket.reset(0, 0);
  185|       |        assert_eq!(bucket.try_consume(1000000), true);
  186|       |        assert_eq!(bucket.try_consume(1000000), true);
  187|       |    }
  188|       |
  189|       |    #[test]
  190|       |    fn unlimited_rate() {
  191|       |        let mut bucket = TokenBucket::new(0, 0);
  192|       |        assert_eq!(bucket.try_consume(5), true);
  193|       |        assert_eq!(bucket.largest_burst(), 5);
  194|       |        assert_eq!(bucket.try_consume(1_000_000_000), true);
  195|       |        assert_eq!(bucket.largest_burst(), 1_000_000_000);
  196|       |
  197|       |        // With unlimited tokens, consuming always succeed
  198|       |        assert_eq!(bucket.try_consume(1_000_000_000), true);
  199|       |        assert_eq!(bucket.largest_burst(), 1_000_000_000);
  200|       |    }
  201|       |
  202|       |    #[test]
  203|       |    fn busy_spin() {
  204|       |        // Bucket should refill at a rate of 1 token per second
  205|       |        let mut bucket = TokenBucket::new(1, 1);
  206|       |
  207|       |        // Run a very tight loop for 5 seconds + a bit of wiggle room
  208|       |        let mut counter = 0;
  209|       |        let start = Instant::now();
  210|       |        let mut now = start;
  211|       |        while now < start + Duration::from_millis(5500) {
  212|       |            if bucket.try_consume(1) {
  213|       |                counter += 1;
  214|       |            }
  215|       |
  216|       |            MockClock::advance(Duration::from_millis(250));
  217|       |            now = Instant::now();
  218|       |        }
  219|       |
  220|       |        // Bucket starts fully refilled, therefore we see 1 additional request
  221|       |        assert_eq!(counter, 6);
  222|       |    }
  223|       |}

/home/gustav/code/nano/rsnano-node/network/src/utils.rs:
    1|       |use std::net::{IpAddr, Ipv4Addr, Ipv6Addr, SocketAddr, SocketAddrV6};
    2|       |
    3|     85|pub fn is_ipv4_mapped(input: &Ipv6Addr) -> bool {
    4|     69|    matches!(
    5|     85|        input.octets(),
    6|       |        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xff, 0xff, _, _, _, _]
    7|       |    )
    8|     85|}
    9|       |
   10|     37|pub fn map_address_to_subnetwork(input: &Ipv6Addr) -> Ipv6Addr {
   11|       |    const IPV6_SUBNET_PREFIX_LENGTH: u8 = 32; // Equivalent to network prefix /32.
   12|       |    const IPV4_SUBNET_PREFIX_LENGTH: u8 = (128 - 32) + 24; // Limits for /24 IPv4 subnetwork (we're using mapped IPv4 to IPv6 addresses, hence (128 - 32))
   13|     37|    if is_ipv4_mapped(input) {
   14|      4|        first_ipv6_subnet_address(input, IPV4_SUBNET_PREFIX_LENGTH)
   15|       |    } else {
   16|     33|        first_ipv6_subnet_address(input, IPV6_SUBNET_PREFIX_LENGTH)
   17|       |    }
   18|     37|}
   19|       |
   20|     17|pub fn ipv4_address_or_ipv6_subnet(input: &Ipv6Addr) -> Ipv6Addr {
   21|     17|    if is_ipv4_mapped(input) {
   22|      4|        input.clone()
   23|       |    } else {
   24|       |        // Assuming /48 subnet prefix for IPv6 as it's relatively easy to acquire such a /48 address range
   25|     13|        first_ipv6_subnet_address(input, 48)
   26|       |    }
   27|     17|}
   28|       |
   29|     50|fn first_ipv6_subnet_address(input: &Ipv6Addr, prefix_bits: u8) -> Ipv6Addr {
   30|     50|    fill_remaining_bits(input, prefix_bits, 0)
   31|     50|}
   32|       |
   33|     50|fn fill_remaining_bits(input: &Ipv6Addr, prefix_bits: u8, filler: u8) -> Ipv6Addr {
   34|     50|    debug_assert_eq!(prefix_bits % 8, 0);
   35|     50|    let index = (prefix_bits / 8) as usize;
   36|     50|    let mut octets = input.octets();
   37|     50|    octets[index..].fill(filler);
   38|     50|    Ipv6Addr::from(octets)
   39|     50|}
   40|       |
   41|      0|pub fn is_ipv4_or_v4_mapped_address(address: &IpAddr) -> bool {
   42|      0|    match address {
   43|      0|        IpAddr::V4(_) => true,
   44|      0|        IpAddr::V6(ip) => is_ipv4_mapped(ip),
   45|       |    }
   46|      0|}
   47|       |
   48|      0|pub fn into_ipv6_socket_address(input: SocketAddr) -> SocketAddrV6 {
   49|      0|    match input {
   50|      0|        SocketAddr::V4(a) => SocketAddrV6::new(a.ip().to_ipv6_mapped(), a.port(), 0, 0),
   51|      0|        SocketAddr::V6(a) => a,
   52|       |    }
   53|      0|}
   54|       |
   55|      0|pub fn into_ipv6_address(input: IpAddr) -> Ipv6Addr {
   56|      0|    match input {
   57|      0|        IpAddr::V4(ip) => ip.to_ipv6_mapped(),
   58|      0|        IpAddr::V6(ip) => ip,
   59|       |    }
   60|      0|}
   61|       |
   62|     31|pub fn reserved_address(endpoint: &SocketAddrV6, allow_local_peers: bool) -> bool {
   63|       |    const RFC1700_MIN: Ipv6Addr = Ipv4Addr::new(0, 0, 0, 0).to_ipv6_mapped();
   64|       |    const RFC1700_MAX: Ipv6Addr = Ipv4Addr::new(0, 0xff, 0xff, 0xff).to_ipv6_mapped();
   65|       |    const RFC1918_1_MIN: Ipv6Addr = Ipv4Addr::new(0x0a, 0, 0, 0).to_ipv6_mapped();
   66|       |    const RFC1918_1_MAX: Ipv6Addr = Ipv4Addr::new(0x0a, 0xff, 0xff, 0xff).to_ipv6_mapped();
   67|       |    const RFC1918_2_MIN: Ipv6Addr = Ipv4Addr::new(0xac, 0x10, 0x00, 0x00).to_ipv6_mapped();
   68|       |    const RFC1918_2_MAX: Ipv6Addr = Ipv4Addr::new(0xac, 0x1f, 0xff, 0xff).to_ipv6_mapped();
   69|       |    const RFC1918_3_MIN: Ipv6Addr = Ipv4Addr::new(0xc0, 0xa8, 0x00, 0x00).to_ipv6_mapped();
   70|       |    const RFC1918_3_MAX: Ipv6Addr = Ipv4Addr::new(0xc0, 0xa8, 0xff, 0xff).to_ipv6_mapped();
   71|       |    const RFC6598_MIN: Ipv6Addr = Ipv4Addr::new(0x64, 0x40, 0x00, 0x00).to_ipv6_mapped();
   72|       |    const RFC6598_MAX: Ipv6Addr = Ipv4Addr::new(0x64, 0x7f, 0xff, 0xff).to_ipv6_mapped();
   73|       |    const RFC5737_1_MIN: Ipv6Addr = Ipv4Addr::new(0xc0, 0x00, 0x02, 0x00).to_ipv6_mapped();
   74|       |    const RFC5737_1_MAX: Ipv6Addr = Ipv4Addr::new(0xc0, 0x00, 0x02, 0xff).to_ipv6_mapped();
   75|       |    const RFC5737_2_MIN: Ipv6Addr = Ipv4Addr::new(0xc6, 0x33, 0x64, 0x00).to_ipv6_mapped();
   76|       |    const RFC5737_2_MAX: Ipv6Addr = Ipv4Addr::new(0xc6, 0x33, 0x64, 0xff).to_ipv6_mapped();
   77|       |    const RFC5737_3_MIN: Ipv6Addr = Ipv4Addr::new(0xcb, 0x00, 0x71, 0x00).to_ipv6_mapped();
   78|       |    const RFC5737_3_MAX: Ipv6Addr = Ipv4Addr::new(0xcb, 0x00, 0x71, 0xff).to_ipv6_mapped();
   79|       |    const IPV4_MULTICAST_MIN: Ipv6Addr = Ipv4Addr::new(0xe0, 0x00, 0x00, 0x00).to_ipv6_mapped();
   80|       |    const IPV4_MULTICAST_MAX: Ipv6Addr = Ipv4Addr::new(0xef, 0xff, 0xff, 0xff).to_ipv6_mapped();
   81|       |    const RFC6890_MIN: Ipv6Addr = Ipv4Addr::new(0xf0, 0x00, 0x00, 0x00).to_ipv6_mapped();
   82|       |    const RFC6890_MAX: Ipv6Addr = Ipv4Addr::new(0xff, 0xff, 0xff, 0xff).to_ipv6_mapped();
   83|       |
   84|       |    const RFC6666_MIN: Ipv6Addr = Ipv6Addr::new(0x100, 0, 0, 0, 0, 0, 0, 0);
   85|       |    const RFC6666_MAX: Ipv6Addr = Ipv6Addr::new(0x100u16, 0, 0, 0, 0xffff, 0xffff, 0xffff, 0xffff);
   86|       |    const RFC3849_MIN: Ipv6Addr = Ipv6Addr::new(0x2001u16, 0xdb8, 0, 0, 0, 0, 0, 0);
   87|       |    const RFC3849_MAX: Ipv6Addr = Ipv6Addr::new(
   88|       |        0x2001u16, 0xdb8, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff,
   89|       |    );
   90|       |    const RFC4193_MIN: Ipv6Addr = Ipv6Addr::new(0xfc00u16, 0, 0, 0, 0, 0, 0, 0);
   91|       |    const RFC4193_MAX: Ipv6Addr = Ipv6Addr::new(
   92|       |        0xfd00u16, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff,
   93|       |    );
   94|       |    const IPV6_MULTICAST_MIN: Ipv6Addr = Ipv6Addr::new(0xff00u16, 0, 0, 0, 0, 0, 0, 0);
   95|       |    const IPV6_MULTICAST_MAX: Ipv6Addr = Ipv6Addr::new(
   96|       |        0xff00u16, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff,
   97|       |    );
   98|       |
   99|     31|    if endpoint.port() == 0 {
  100|      0|        return true;
  101|     31|    }
  102|     31|
  103|     31|    let ip = *endpoint.ip();
  104|     31|    if (ip >= RFC1700_MIN && ip <= RFC1700_MAX)
  105|     31|        || (ip >= RFC5737_1_MIN && ip <= RFC5737_1_MAX)
                                                 ^23
  106|     31|        || (ip >= RFC5737_2_MIN && ip <= RFC5737_2_MAX)
                                                 ^23
  107|     31|        || (ip >= RFC5737_3_MIN && ip <= RFC5737_3_MAX)
                                                 ^23
  108|     31|        || (ip >= IPV4_MULTICAST_MIN && ip <= IPV4_MULTICAST_MAX)
                                                      ^23
  109|     31|        || (ip >= RFC6890_MIN && ip <= RFC6890_MAX)
                                               ^23
  110|     31|        || (ip >= RFC6666_MIN && ip <= RFC6666_MAX)
                                               ^0
  111|     31|        || (ip >= RFC3849_MIN && ip <= RFC3849_MAX)
                                               ^0
  112|     31|        || (ip >= IPV6_MULTICAST_MIN && ip <= IPV6_MULTICAST_MAX)
                                                      ^0
  113|       |    {
  114|      0|        return true;
  115|     31|    }
  116|     31|
  117|     31|    if !allow_local_peers {
  118|      0|        if (ip >= RFC1918_1_MIN && ip <= RFC1918_1_MAX)
  119|      0|            || (ip >= RFC1918_2_MIN && ip <= RFC1918_2_MAX)
  120|      0|            || (ip >= RFC1918_3_MIN && ip <= RFC1918_3_MAX)
  121|      0|            || (ip >= RFC6598_MIN && ip <= RFC6598_MAX)
  122|      0|            || (ip >= RFC4193_MIN && ip <= RFC4193_MAX)
  123|       |        {
  124|      0|            return true;
  125|      0|        }
  126|     31|    }
  127|       |
  128|     31|    false
  129|     31|}
  130|       |
  131|       |#[cfg(test)]
  132|       |mod tests {
  133|       |    use super::*;
  134|       |
  135|       |    #[test]
  136|       |    fn test_first_ipv6_subnet_address() {
  137|       |        let address = Ipv6Addr::new(
  138|       |            0xa41d, 0xb7b2, 0x8298, 0xcf45, 0x672e, 0xbd1a, 0xe7fb, 0xf713,
  139|       |        );
  140|       |        let expected = Ipv6Addr::new(0xa41d, 0xb7b2, 0, 0, 0, 0, 0, 0);
  141|       |        assert_eq!(first_ipv6_subnet_address(&address, 32), expected);
  142|       |    }
  143|       |
  144|       |    #[test]
  145|       |    fn reserved_adresses() {
  146|       |        //valid
  147|       |        assert_eq!(
  148|       |            reserved_address(&"[2001::]:1".parse().unwrap(), false),
  149|       |            false
  150|       |        );
  151|       |
  152|       |        // 0 port
  153|       |        assert_eq!(
  154|       |            reserved_address(&"[2001::]:0".parse().unwrap(), false),
  155|       |            true
  156|       |        );
  157|       |
  158|       |        //loopback
  159|       |        assert_eq!(reserved_address(&"[::1]:1".parse().unwrap(), false), false);
  160|       |
  161|       |        //private network
  162|       |        assert_eq!(
  163|       |            reserved_address(&"[::ffff:10.0.0.0]:1".parse().unwrap(), false),
  164|       |            true
  165|       |        );
  166|       |        assert_eq!(
  167|       |            reserved_address(&"[::ffff:10.0.0.0]:1".parse().unwrap(), true),
  168|       |            false
  169|       |        );
  170|       |    }
  171|       |
  172|       |    #[test]
  173|       |    fn ipv6_bind_subnetwork() {
  174|       |        // IPv6 address within the same /48 subnet should return the network prefix
  175|       |        let address = "a41d:b7b2:8298:cf45:672e:bd1a:e7fb:f713".parse().unwrap();
  176|       |        let subnet = ipv4_address_or_ipv6_subnet(&address);
  177|       |        assert_eq!(subnet, "a41d:b7b2:8298::".parse::<Ipv6Addr>().unwrap());
  178|       |    }
  179|       |
  180|       |    #[test]
  181|       |    fn ipv4_subnetwork() {
  182|       |        // IPv4 mapped as IPv6 address should return the original IPv4 address
  183|       |        let address = "::ffff:192.168.1.1".parse().unwrap();
  184|       |        let subnet = ipv4_address_or_ipv6_subnet(&address);
  185|       |        assert_eq!(address, subnet);
  186|       |    }
  187|       |
  188|       |    #[test]
  189|       |    fn network_range_ipv6() {
  190|       |        let address = "a719:0f12:536e:d88a:1331:ba53:4598:04e5".parse().unwrap();
  191|       |        let subnet = map_address_to_subnetwork(&address);
  192|       |        assert_eq!(subnet, "a719:0f12::".parse::<Ipv6Addr>().unwrap());
  193|       |    }
  194|       |
  195|       |    #[test]
  196|       |    fn network_range_ipv4() {
  197|       |        // Default settings test
  198|       |        let address = "::ffff:80.67.148.225".parse().unwrap();
  199|       |        let subnet = map_address_to_subnetwork(&address);
  200|       |        assert_eq!(subnet, "::ffff:80.67.148.0".parse::<Ipv6Addr>().unwrap());
  201|       |    }
  202|       |}

/home/gustav/code/nano/rsnano-node/network/src/write_queue.rs:
    1|       |use crate::{NetworkObserver, TrafficType};
    2|       |use rsnano_core::utils::FairQueue;
    3|       |use std::sync::{
    4|       |    atomic::{AtomicBool, Ordering},
    5|       |    Arc, Mutex,
    6|       |};
    7|       |use tokio::sync::Notify;
    8|       |
    9|       |pub struct WriteQueue {
   10|       |    queue: Mutex<FairQueue<TrafficType, Entry>>,
   11|       |    notify_enqueued: Notify,
   12|       |    notify_dequeued: Notify,
   13|       |    closed: AtomicBool,
   14|       |    observer: Arc<dyn NetworkObserver>,
   15|       |}
   16|       |
   17|       |impl WriteQueue {
   18|     10|    pub fn new(max_size: usize, observer: Arc<dyn NetworkObserver>) -> Self {
   19|     10|        Self {
   20|     10|            queue: Mutex::new(FairQueue::new(
   21|     10|                move |_| max_size,
                                       ^0
   22|     10|                |traffic_type| match traffic_type {
                                             ^0
   23|      0|                    TrafficType::BlockBroadcast | TrafficType::VoteRebroadcast => 1,
   24|      0|                    _ => 4,
   25|     10|                },
                              ^0
   26|     10|            )),
   27|     10|            notify_enqueued: Notify::new(),
   28|     10|            notify_dequeued: Notify::new(),
   29|     10|            closed: AtomicBool::new(false),
   30|     10|            observer,
   31|     10|        }
   32|     10|    }
   33|       |
   34|      0|    pub async fn insert(&self, buffer: Arc<Vec<u8>>, traffic_type: TrafficType) {
   35|       |        loop {
   36|      0|            if self.closed.load(Ordering::SeqCst) {
   37|      0|                return;
   38|      0|            }
   39|      0|
   40|      0|            {
   41|      0|                let mut guard = self.queue.lock().unwrap();
   42|      0|                if guard.free_capacity(&traffic_type) > 0 {
   43|      0|                    let entry = Entry { buffer };
   44|      0|                    guard.push(traffic_type, entry);
   45|      0|                    break;
   46|      0|                }
   47|      0|            }
   48|      0|
   49|      0|            self.notify_dequeued.notified().await;
   50|       |        }
   51|       |
   52|      0|        self.notify_enqueued.notify_one();
   53|      0|    }
   54|       |
   55|       |    /// returns: inserted
   56|      0|    pub fn try_insert(&self, buffer: Arc<Vec<u8>>, traffic_type: TrafficType) -> bool {
   57|      0|        if self.closed.load(Ordering::SeqCst) {
   58|      0|            return false;
   59|      0|        }
   60|      0|        let entry = Entry { buffer };
   61|      0|        let inserted = self.queue.lock().unwrap().push(traffic_type, entry);
   62|      0|
   63|      0|        if inserted {
   64|      0|            self.notify_enqueued.notify_one();
   65|      0|        }
   66|       |
   67|      0|        inserted
   68|      0|    }
   69|       |
   70|      0|    pub fn free_capacity(&self, traffic_type: TrafficType) -> usize {
   71|      0|        self.queue.lock().unwrap().free_capacity(&traffic_type)
   72|      0|    }
   73|       |
   74|      0|    pub fn len(&self) -> usize {
   75|      0|        self.queue.lock().unwrap().len()
   76|      0|    }
   77|       |
   78|      0|    pub async fn pop(&self) -> Option<Entry> {
   79|       |        let entry;
   80|       |        let traffic_type;
   81|       |
   82|       |        loop {
   83|      0|            if self.closed.load(Ordering::SeqCst) {
   84|      0|                return None;
   85|      0|            }
   86|      0|
   87|      0|            let result = self.queue.lock().unwrap().next();
   88|      0|            if let Some((ttype, ent)) = result {
   89|      0|                traffic_type = ttype;
   90|      0|                entry = ent;
   91|      0|                break;
   92|      0|            }
   93|      0|
   94|      0|            self.notify_enqueued.notified().await;
   95|       |        }
   96|       |
   97|      0|        self.notify_dequeued.notify_one();
   98|      0|        self.observer
   99|      0|            .send_succeeded(entry.buffer.len(), traffic_type);
  100|      0|        Some(entry)
  101|      0|    }
  102|       |
  103|     19|    pub fn close(&self) {
  104|     19|        self.closed.store(true, Ordering::SeqCst);
  105|     19|        self.notify_enqueued.notify_one();
  106|     19|        self.notify_dequeued.notify_one();
  107|     19|    }
  108|       |}
  109|       |
  110|       |impl Drop for WriteQueue {
  111|     10|    fn drop(&mut self) {
  112|     10|        self.close();
  113|     10|    }
  114|       |}
  115|       |
  116|       |pub struct Entry {
  117|       |    pub buffer: Arc<Vec<u8>>,
  118|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/backlog_index.rs:
    1|       |use rsnano_core::{
    2|       |    utils::{ContainerInfo, UnixTimestamp},
    3|       |    Account, BlockHash,
    4|       |};
    5|       |use std::collections::{BTreeMap, HashMap};
    6|       |
    7|       |#[derive(Clone)]
    8|       |pub(super) struct BacklogEntry {
    9|       |    pub hash: BlockHash,
   10|       |    pub account: Account,
   11|       |    pub bucket_index: usize,
   12|       |    pub priority: UnixTimestamp,
   13|       |}
   14|       |
   15|       |impl BacklogEntry {
   16|       |    #[allow(dead_code)]
   17|     19|    pub fn new_test_instance() -> Self {
   18|     19|        Self {
   19|     19|            hash: 100.into(),
   20|     19|            account: 200.into(),
   21|     19|            bucket_index: 1,
   22|     19|            priority: UnixTimestamp::new(300),
   23|     19|        }
   24|     19|    }
   25|       |}
   26|       |
   27|       |pub(super) struct BacklogIndex {
   28|       |    by_hash: BTreeMap<BlockHash, BacklogEntry>,
   29|       |    by_account: HashMap<Account, Vec<BlockHash>>,
   30|       |    /// indexed by bucket index!
   31|       |    /// Ordered in ascending timestamp order which means descending priority!
   32|       |    by_priority: Vec<BTreeMap<UnixTimestamp, Vec<BlockHash>>>,
   33|       |    bucket_lens: Vec<usize>,
   34|       |}
   35|       |
   36|       |impl BacklogIndex {
   37|     14|    pub fn new(bucket_count: usize) -> Self {
   38|     14|        Self {
   39|     14|            by_hash: Default::default(),
   40|     14|            by_account: Default::default(),
   41|     14|            by_priority: vec![Default::default(); bucket_count],
   42|     14|            bucket_lens: vec![0; bucket_count],
   43|     14|        }
   44|     14|    }
   45|       |
   46|     28|    pub fn insert(&mut self, entry: BacklogEntry) -> bool {
   47|     28|        let mut inserted = true;
   48|     28|        self.by_hash
   49|     28|            .entry(entry.hash)
   50|     28|            .and_modify(|_| inserted = false)
                                          ^1
   51|     28|            .or_insert(entry.clone());
   52|     28|
   53|     28|        if inserted {
   54|     27|            self.by_account
   55|     27|                .entry(entry.account)
   56|     27|                .or_default()
   57|     27|                .push(entry.hash);
   58|     27|            self.by_priority[entry.bucket_index]
   59|     27|                .entry(entry.priority)
   60|     27|                .or_default()
   61|     27|                .push(entry.hash);
   62|     27|            self.bucket_lens[entry.bucket_index] += 1;
   63|     27|        }
                       ^1
   64|       |
   65|     28|        inserted
   66|     28|    }
   67|       |
   68|     32|    pub fn erase_account(&mut self, account: &Account) -> bool {
   69|     32|        let Some(hashes) = self.by_account.remove(account) else {
                               ^1
   70|     31|            return false;
   71|       |        };
   72|       |
   73|      4|        for hash in hashes {
                          ^3
   74|      3|            let entry = self.by_hash.remove(&hash).unwrap();
   75|      3|            let prio_hashes = self.by_priority[entry.bucket_index]
   76|      3|                .get_mut(&entry.priority)
   77|      3|                .unwrap();
   78|      3|            if prio_hashes.len() == 1 {
   79|      2|                self.by_priority[entry.bucket_index].remove(&entry.priority);
   80|      2|            } else {
   81|      2|                prio_hashes.retain(|h| *h != hash);
   82|      1|            }
   83|      3|            self.bucket_lens[entry.bucket_index] -= 1;
   84|       |        }
   85|      1|        true
   86|     32|    }
   87|       |
   88|      3|    pub fn erase_hash(&mut self, hash: &BlockHash) -> bool {
   89|      3|        let Some(entry) = self.by_hash.remove(hash) else {
                               ^2
   90|      1|            return false;
   91|       |        };
   92|      2|        let account_hashes = self.by_account.get_mut(&entry.account).unwrap();
   93|      2|        if account_hashes.len() == 1 {
   94|      1|            self.by_account.remove(&entry.account);
   95|      1|        } else {
   96|      2|            account_hashes.retain(|h| *h != entry.hash);
   97|      1|        }
   98|      2|        let prio_hashes = self.by_priority[entry.bucket_index]
   99|      2|            .get_mut(&entry.priority)
  100|      2|            .unwrap();
  101|      2|        if prio_hashes.len() == 1 {
  102|      1|            self.by_priority[entry.bucket_index].remove(&entry.priority);
  103|      1|        } else {
  104|      2|            prio_hashes.retain(|h| *h != entry.hash);
  105|      1|        }
  106|      2|        self.bucket_lens[entry.bucket_index] -= 1;
  107|      2|        true
  108|      3|    }
  109|       |
  110|      3|    pub fn top(
  111|      3|        &self,
  112|      3|        bucket_index: usize,
  113|      3|        count: usize,
  114|      3|        mut filter: impl FnMut(&BlockHash) -> bool,
  115|      3|    ) -> Vec<BlockHash> {
  116|      3|        self.by_priority[bucket_index]
  117|      3|            .iter()
  118|      3|            .rev()
  119|      5|            .flat_map(|(_, hashes)| hashes)
  120|      3|            .cloned()
  121|      6|            .filter(|hash| filter(hash))
  122|      3|            .take(count)
  123|      3|            .collect()
  124|      3|    }
  125|       |
  126|     10|    pub fn next(&self, last: &BlockHash, count: usize) -> Vec<BlockHash> {
  127|     10|        let Some(start) = last.inc() else {
                               ^9
  128|      1|            return Vec::new();
  129|       |        };
  130|      9|        self.by_hash
  131|      9|            .range(start..)
  132|      9|            .map(|(hash, _)| *hash)
                                           ^3
  133|      9|            .take(count)
  134|      9|            .collect()
  135|     10|    }
  136|       |
  137|      6|    pub fn contains(&self, hash: &BlockHash) -> bool {
  138|      6|        self.by_hash.contains_key(hash)
  139|      6|    }
  140|       |
  141|      8|    pub fn len(&self) -> usize {
  142|      8|        self.by_hash.len()
  143|      8|    }
  144|       |
  145|      3|    pub fn len_of_bucket(&self, bucket_index: usize) -> usize {
  146|      3|        self.bucket_lens[bucket_index]
  147|      3|    }
  148|       |
  149|      1|    pub fn container_info(&self) -> ContainerInfo {
  150|      1|        let mut bucket_sizes = ContainerInfo::builder();
  151|      5|        for (index, len) in self.bucket_lens.iter().enumerate() {
                                          ^1
  152|      5|            bucket_sizes = bucket_sizes.leaf(index.to_string(), *len, 0);
  153|      5|        }
  154|       |
  155|      1|        ContainerInfo::builder()
  156|      1|            .leaf("blocks", self.len(), 0)
  157|      1|            .node("sizes", bucket_sizes.finish())
  158|      1|            .finish()
  159|      1|    }
  160|       |}
  161|       |
  162|       |#[cfg(test)]
  163|       |mod tests {
  164|       |    use super::*;
  165|       |    const TEST_BUCKET_COUNT: usize = 5;
  166|       |
  167|       |    #[test]
  168|      1|    fn empty() {
  169|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  170|      1|        assert_eq!(index.len(), 0);
  171|      1|        assert_eq!(index.contains(&BlockHash::from(1)), false);
  172|       |
  173|      1|        assert!(index.top(0, 100, |_| unreachable!()).is_empty());
  174|      1|        assert!(index.next(&BlockHash::zero(), 100).is_empty());
  175|       |
  176|      1|        assert_eq!(index.erase_hash(&BlockHash::from(1)), false);
  177|      1|        assert_eq!(index.erase_account(&Account::from(1)), false);
  178|      1|    }
  179|       |
  180|       |    #[test]
  181|      1|    fn insert_one() {
  182|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  183|      1|        let entry = BacklogEntry::new_test_instance();
  184|      1|
  185|      1|        let inserted = index.insert(entry.clone());
  186|      1|
  187|      1|        assert!(inserted);
  188|      1|        assert_eq!(index.len(), 1);
  189|      1|        assert!(index.contains(&entry.hash));
  190|      1|        assert_eq!(index.len_of_bucket(entry.bucket_index), 1);
  191|      1|        assert_eq!(index.len_of_bucket(entry.bucket_index + 1), 0);
  192|      1|    }
  193|       |
  194|       |    #[test]
  195|      1|    fn insert_two() {
  196|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  197|      1|        let entry1 = BacklogEntry::new_test_instance();
  198|      1|        let entry2 = BacklogEntry {
  199|      1|            account: 1000.into(),
  200|      1|            hash: 1001.into(),
  201|      1|            ..BacklogEntry::new_test_instance()
  202|      1|        };
  203|      1|
  204|      1|        index.insert(entry1.clone());
  205|      1|        let inserted = index.insert(entry2.clone());
  206|      1|
  207|      1|        assert!(inserted);
  208|      1|        assert_eq!(index.len(), 2);
  209|      1|        assert!(index.contains(&entry1.hash));
  210|      1|        assert!(index.contains(&entry2.hash));
  211|      1|        assert_eq!(index.len_of_bucket(entry1.bucket_index), 2);
  212|      1|    }
  213|       |
  214|       |    #[test]
  215|      1|    fn insert_many() {
  216|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  217|      1|
  218|      1|        let entry1 = BacklogEntry {
  219|      1|            account: 1000.into(),
  220|      1|            hash: 1001.into(),
  221|      1|            ..BacklogEntry::new_test_instance()
  222|      1|        };
  223|      1|
  224|      1|        let entry2 = BacklogEntry {
  225|      1|            account: 2000.into(),
  226|      1|            hash: 2001.into(),
  227|      1|            priority: UnixTimestamp::new(1),
  228|      1|            ..BacklogEntry::new_test_instance()
  229|      1|        };
  230|      1|
  231|      1|        let entry3 = BacklogEntry {
  232|      1|            account: 2000.into(),
  233|      1|            hash: 2002.into(),
  234|      1|            priority: UnixTimestamp::new(1),
  235|      1|            ..BacklogEntry::new_test_instance()
  236|      1|        };
  237|      1|
  238|      1|        let entry4 = BacklogEntry {
  239|      1|            account: 2000.into(),
  240|      1|            hash: 2003.into(),
  241|      1|            priority: UnixTimestamp::new(2),
  242|      1|            ..BacklogEntry::new_test_instance()
  243|      1|        };
  244|      1|
  245|      1|        assert!(index.insert(entry1));
  246|      1|        assert!(index.insert(entry2));
  247|      1|        assert!(index.insert(entry3));
  248|      1|        assert!(index.insert(entry4));
  249|       |
  250|      1|        assert_eq!(index.len(), 4);
  251|      5|        assert_eq!(index.by_priority.iter().map(|i| i.len()).sum::<usize>(), 3);
                      ^1                                                 ^1
  252|      2|        assert_eq!(index.by_account.values().map(|i| i.len()).sum::<usize>(), 4);
                      ^1                                                  ^1
  253|      1|    }
  254|       |
  255|       |    #[test]
  256|      1|    fn dont_insert_duplicate() {
  257|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  258|      1|        let entry = BacklogEntry::new_test_instance();
  259|      1|
  260|      1|        index.insert(entry.clone());
  261|      1|        let inserted = index.insert(entry.clone());
  262|      1|
  263|      1|        assert!(!inserted);
  264|      1|        assert_eq!(index.len(), 1);
  265|      1|    }
  266|       |
  267|       |    #[test]
  268|      1|    fn erase_account() {
  269|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  270|      1|
  271|      1|        let entry1 = BacklogEntry {
  272|      1|            account: 1000.into(),
  273|      1|            hash: 1001.into(),
  274|      1|            ..BacklogEntry::new_test_instance()
  275|      1|        };
  276|      1|
  277|      1|        let entry2 = BacklogEntry {
  278|      1|            account: 2000.into(),
  279|      1|            hash: 2001.into(),
  280|      1|            priority: UnixTimestamp::new(1),
  281|      1|            ..BacklogEntry::new_test_instance()
  282|      1|        };
  283|      1|
  284|      1|        let entry3 = BacklogEntry {
  285|      1|            account: 2000.into(),
  286|      1|            hash: 2002.into(),
  287|      1|            priority: UnixTimestamp::new(1),
  288|      1|            ..BacklogEntry::new_test_instance()
  289|      1|        };
  290|      1|
  291|      1|        let entry4 = BacklogEntry {
  292|      1|            account: 2000.into(),
  293|      1|            hash: 2003.into(),
  294|      1|            priority: UnixTimestamp::new(2),
  295|      1|            ..BacklogEntry::new_test_instance()
  296|      1|        };
  297|      1|
  298|      1|        index.insert(entry1.clone());
  299|      1|        index.insert(entry2.clone());
  300|      1|        index.insert(entry3);
  301|      1|        index.insert(entry4);
  302|      1|
  303|      1|        index.erase_account(&entry2.account);
  304|      1|
  305|      1|        assert_eq!(index.len(), 1);
  306|      1|        assert!(index.contains(&entry1.hash));
  307|      5|        assert_eq!(index.by_priority.iter().map(|i| i.len()).sum::<usize>(), 1);
                      ^1                                                 ^1
  308|      1|        assert_eq!(index.by_account.values().map(|i| i.len()).sum::<usize>(), 1);
  309|      1|    }
  310|       |
  311|       |    #[test]
  312|      1|    fn erase_by_hash() {
  313|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  314|      1|
  315|      1|        let entry1 = BacklogEntry {
  316|      1|            account: 1000.into(),
  317|      1|            hash: 1001.into(),
  318|      1|            ..BacklogEntry::new_test_instance()
  319|      1|        };
  320|      1|
  321|      1|        let entry2 = BacklogEntry {
  322|      1|            account: 2000.into(),
  323|      1|            hash: 2001.into(),
  324|      1|            priority: UnixTimestamp::new(1),
  325|      1|            ..BacklogEntry::new_test_instance()
  326|      1|        };
  327|      1|
  328|      1|        let entry3 = BacklogEntry {
  329|      1|            account: 2000.into(),
  330|      1|            hash: 2002.into(),
  331|      1|            priority: UnixTimestamp::new(1),
  332|      1|            ..BacklogEntry::new_test_instance()
  333|      1|        };
  334|      1|
  335|      1|        index.insert(entry1.clone());
  336|      1|        index.insert(entry2.clone());
  337|      1|        index.insert(entry3.clone());
  338|      1|
  339|      1|        index.erase_hash(&entry1.hash);
  340|      1|        index.erase_hash(&entry2.hash);
  341|      1|
  342|      1|        assert_eq!(index.len(), 1);
  343|      1|        assert!(index.contains(&entry3.hash));
  344|      5|        assert_eq!(index.by_priority.iter().map(|i| i.len()).sum::<usize>(), 1);
                      ^1                                                 ^1
  345|      1|        assert_eq!(index.by_account.values().map(|i| i.len()).sum::<usize>(), 1);
  346|      1|    }
  347|       |
  348|       |    #[test]
  349|      1|    fn top() {
  350|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  351|      1|
  352|      1|        let entry1 = BacklogEntry {
  353|      1|            account: 1000.into(),
  354|      1|            hash: 1001.into(),
  355|      1|            bucket_index: 3,
  356|      1|            priority: UnixTimestamp::new(1),
  357|      1|        };
  358|      1|
  359|      1|        let entry2 = BacklogEntry {
  360|      1|            account: 2000.into(),
  361|      1|            hash: 2001.into(),
  362|      1|            bucket_index: 3,
  363|      1|            priority: UnixTimestamp::new(10000),
  364|      1|        };
  365|      1|
  366|      1|        // Same priority as entry2
  367|      1|        let entry3 = BacklogEntry {
  368|      1|            account: 3000.into(),
  369|      1|            hash: 3001.into(),
  370|      1|            bucket_index: 3,
  371|      1|            priority: UnixTimestamp::new(2),
  372|      1|        };
  373|      1|
  374|      1|        // filtered out!
  375|      1|        let entry4 = BacklogEntry {
  376|      1|            account: 4000.into(),
  377|      1|            hash: 4001.into(),
  378|      1|            bucket_index: 3,
  379|      1|            priority: UnixTimestamp::new(2),
  380|      1|        };
  381|      1|
  382|      1|        // different bucket
  383|      1|        let entry5 = BacklogEntry {
  384|      1|            account: 5000.into(),
  385|      1|            hash: 5001.into(),
  386|      1|            priority: UnixTimestamp::new(2),
  387|      1|            bucket_index: 1,
  388|      1|        };
  389|      1|
  390|      1|        index.insert(entry1.clone());
  391|      1|        index.insert(entry2.clone());
  392|      1|        index.insert(entry3.clone());
  393|      1|        index.insert(entry4.clone());
  394|      1|        index.insert(entry5.clone());
  395|      1|
  396|      4|        let top_all = index.top(3, usize::MAX, |h| *h != entry4.hash);
  397|      1|
  398|      1|        // ordered by ascending priority (=descending timestamp)
  399|      1|        assert_eq!(top_all, vec![entry2.hash, entry3.hash, entry1.hash]);
  400|       |
  401|      2|        let top_limit = index.top(3, 2, |h| *h != entry4.hash);
                          ^1
  402|      1|        assert_eq!(top_limit, vec![entry2.hash, entry3.hash]);
  403|      1|    }
  404|       |
  405|       |    #[test]
  406|      1|    fn next() {
  407|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  408|      1|
  409|      1|        let entry1 = BacklogEntry {
  410|      1|            account: 1000.into(),
  411|      1|            hash: 1001.into(),
  412|      1|            bucket_index: 3,
  413|      1|            priority: UnixTimestamp::new(1),
  414|      1|        };
  415|      1|
  416|      1|        let entry2 = BacklogEntry {
  417|      1|            account: 2000.into(),
  418|      1|            hash: 2001.into(),
  419|      1|            bucket_index: 3,
  420|      1|            priority: UnixTimestamp::new(10000),
  421|      1|        };
  422|      1|
  423|      1|        // Same priority as entry2
  424|      1|        let entry3 = BacklogEntry {
  425|      1|            account: 3000.into(),
  426|      1|            hash: 3001.into(),
  427|      1|            bucket_index: 3,
  428|      1|            priority: UnixTimestamp::new(2),
  429|      1|        };
  430|      1|
  431|      1|        index.insert(entry1.clone());
  432|      1|        index.insert(entry2.clone());
  433|      1|        index.insert(entry3.clone());
  434|      1|
  435|      1|        let next_all = index.next(&entry1.hash, usize::MAX);
  436|      1|        assert_eq!(next_all, vec![entry2.hash, entry3.hash]);
  437|       |
  438|      1|        let next_limit = index.next(&entry1.hash, 1);
  439|      1|        assert_eq!(next_limit, vec![entry2.hash]);
  440|      1|    }
  441|       |
  442|       |    #[test]
  443|      1|    fn next_max_hash() {
  444|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  445|      1|        index.insert(BacklogEntry::new_test_instance());
  446|      1|        let next = index.next(&BlockHash::MAX, usize::MAX);
  447|      1|        assert!(next.is_empty());
  448|      1|    }
  449|       |
  450|       |    #[test]
  451|      1|    fn container_info() {
  452|      1|        let mut index = BacklogIndex::new(TEST_BUCKET_COUNT);
  453|      1|
  454|      1|        let entry1 = BacklogEntry {
  455|      1|            account: 1000.into(),
  456|      1|            hash: 1001.into(),
  457|      1|            ..BacklogEntry::new_test_instance()
  458|      1|        };
  459|      1|
  460|      1|        let entry2 = BacklogEntry {
  461|      1|            account: 2000.into(),
  462|      1|            hash: 2001.into(),
  463|      1|            priority: UnixTimestamp::new(1),
  464|      1|            ..BacklogEntry::new_test_instance()
  465|      1|        };
  466|      1|
  467|      1|        let entry3 = BacklogEntry {
  468|      1|            account: 2000.into(),
  469|      1|            hash: 2002.into(),
  470|      1|            priority: UnixTimestamp::new(1),
  471|      1|            ..BacklogEntry::new_test_instance()
  472|      1|        };
  473|      1|
  474|      1|        index.insert(entry1.clone());
  475|      1|        index.insert(entry2.clone());
  476|      1|        index.insert(entry3.clone());
  477|      1|
  478|      1|        let container_info = index.container_info();
  479|      1|        let expected_sizes: ContainerInfo = [
  480|      1|            ("0", 0, 0),
  481|      1|            ("1", 3, 0),
  482|      1|            ("2", 0, 0),
  483|      1|            ("3", 0, 0),
  484|      1|            ("4", 0, 0),
  485|      1|        ]
  486|      1|        .into();
  487|      1|        let expected = ContainerInfo::builder()
  488|      1|            .leaf("blocks", 3, 0)
  489|      1|            .node("sizes", expected_sizes)
  490|      1|            .finish();
  491|      1|        assert_eq!(container_info, expected);
  492|      1|    }
  493|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/backlog_scan.rs:
    1|       |use crate::stats::{DetailType, StatType, Stats};
    2|       |use rsnano_core::{Account, AccountInfo, ConfirmationHeightInfo};
    3|       |use rsnano_ledger::Ledger;
    4|       |use rsnano_network::bandwidth_limiter::RateLimiter;
    5|       |use std::{
    6|       |    cmp::max,
    7|       |    sync::{Arc, Condvar, Mutex, MutexGuard, RwLock},
    8|       |    thread::{self, JoinHandle},
    9|       |    time::Duration,
   10|       |};
   11|       |
   12|       |#[derive(Clone, PartialEq, Eq, Debug)]
   13|       |pub struct BacklogScanConfig {
   14|       |    /// Control if ongoing backlog population is enabled. If not, backlog population can still be triggered by RPC
   15|       |    pub enabled: bool,
   16|       |
   17|       |    /// Number of accounts per second to process.
   18|       |    pub batch_size: usize,
   19|       |
   20|       |    /// Number of accounts to scan per second
   21|       |    pub rate_limit: usize,
   22|       |}
   23|       |
   24|       |impl Default for BacklogScanConfig {
   25|      9|    fn default() -> Self {
   26|      9|        Self {
   27|      9|            enabled: true,
   28|      9|            batch_size: 1000,
   29|      9|            rate_limit: 10_000,
   30|      9|        }
   31|      9|    }
   32|       |}
   33|       |
   34|       |struct BacklogScanFlags {
   35|       |    stopped: bool,
   36|       |    /** This is a manual trigger, the ongoing backlog population does not use this.
   37|       |     *  It can be triggered even when backlog population (frontiers confirmation) is disabled. */
   38|       |    triggered: bool,
   39|       |}
   40|       |
   41|       |pub struct BacklogScan {
   42|       |    ledger: Arc<Ledger>,
   43|       |    stats: Arc<Stats>,
   44|       |    /// Callback called for each backlogged account
   45|       |    activated_observers: Arc<RwLock<Vec<Box<dyn Fn(&[ActivatedInfo]) + Send + Sync>>>>,
   46|       |    scanned_observers: Arc<RwLock<Vec<Box<dyn Fn(&[ActivatedInfo]) + Send + Sync>>>>,
   47|       |
   48|       |    config: BacklogScanConfig,
   49|       |    mutex: Arc<Mutex<BacklogScanFlags>>,
   50|       |    condition: Arc<Condvar>,
   51|       |    /** Thread that runs the backlog implementation logic. The thread always runs, even if
   52|       |     *  backlog population is disabled, so that it can service a manual trigger (e.g. via RPC). */
   53|       |    thread: Mutex<Option<JoinHandle<()>>>,
   54|       |}
   55|       |
   56|       |impl BacklogScan {
   57|      3|    pub(crate) fn new(config: BacklogScanConfig, ledger: Arc<Ledger>, stats: Arc<Stats>) -> Self {
   58|      3|        Self {
   59|      3|            config,
   60|      3|            ledger,
   61|      3|            stats,
   62|      3|            activated_observers: Arc::new(RwLock::new(Vec::new())),
   63|      3|            scanned_observers: Arc::new(RwLock::new(Vec::new())),
   64|      3|            mutex: Arc::new(Mutex::new(BacklogScanFlags {
   65|      3|                stopped: false,
   66|      3|                triggered: false,
   67|      3|            })),
   68|      3|            condition: Arc::new(Condvar::new()),
   69|      3|            thread: Mutex::new(None),
   70|      3|        }
   71|      3|    }
   72|       |
   73|       |    /// Accounts activated
   74|      6|    pub fn on_batch_activated(&self, callback: impl Fn(&[ActivatedInfo]) + Send + Sync + 'static) {
   75|      6|        self.activated_observers
   76|      6|            .write()
   77|      6|            .unwrap()
   78|      6|            .push(Box::new(callback));
   79|      6|    }
   80|       |
   81|       |    /// Accounts scanned but not activated
   82|      3|    pub fn on_batch_scanned(&self, callback: impl Fn(&[ActivatedInfo]) + Send + Sync + 'static) {
   83|      3|        self.scanned_observers
   84|      3|            .write()
   85|      3|            .unwrap()
   86|      3|            .push(Box::new(callback));
   87|      3|    }
   88|       |
   89|      3|    pub fn start(&self) {
   90|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
   91|       |
   92|      3|        let thread = BacklogScanThread {
   93|      3|            ledger: self.ledger.clone(),
   94|      3|            stats: self.stats.clone(),
   95|      3|            activated_observers: self.activated_observers.clone(),
   96|      3|            scanned_observers: self.scanned_observers.clone(),
   97|      3|            config: self.config.clone(),
   98|      3|            mutex: self.mutex.clone(),
   99|      3|            condition: self.condition.clone(),
  100|      3|            limiter: RateLimiter::new(self.config.rate_limit),
  101|      3|        };
  102|      3|
  103|      3|        *self.thread.lock().unwrap() = Some(
  104|      3|            thread::Builder::new()
  105|      3|                .name("Backlog".to_owned())
  106|      3|                .spawn(move || {
  107|      3|                    thread.run();
  108|      3|                })
  109|      3|                .unwrap(),
  110|      3|        );
  111|      3|    }
  112|       |
  113|      6|    pub fn stop(&self) {
  114|      6|        let mut lock = self.mutex.lock().unwrap();
  115|      6|        lock.stopped = true;
  116|      6|        drop(lock);
  117|      6|        self.notify();
  118|      6|        let handle = self.thread.lock().unwrap().take();
  119|      6|        if let Some(handle) = handle {
                                  ^3
  120|      3|            handle.join().unwrap()
  121|      3|        }
  122|      6|    }
  123|       |
  124|       |    /** Manually trigger backlog population */
  125|      0|    pub fn trigger(&self) {
  126|      0|        {
  127|      0|            let mut lock = self.mutex.lock().unwrap();
  128|      0|            lock.triggered = true;
  129|      0|        }
  130|      0|        self.notify();
  131|      0|    }
  132|       |
  133|       |    /** Notify about AEC vacancy */
  134|      6|    pub fn notify(&self) {
  135|      6|        self.condition.notify_all();
  136|      6|    }
  137|       |}
  138|       |
  139|       |impl Drop for BacklogScan {
  140|      3|    fn drop(&mut self) {
  141|      3|        self.stop();
  142|      3|    }
  143|       |}
  144|       |
  145|       |struct BacklogScanThread {
  146|       |    ledger: Arc<Ledger>,
  147|       |    stats: Arc<Stats>,
  148|       |    activated_observers: Arc<RwLock<Vec<Box<dyn Fn(&[ActivatedInfo]) + Send + Sync>>>>,
  149|       |    scanned_observers: Arc<RwLock<Vec<Box<dyn Fn(&[ActivatedInfo]) + Send + Sync>>>>,
  150|       |    config: BacklogScanConfig,
  151|       |    mutex: Arc<Mutex<BacklogScanFlags>>,
  152|       |    condition: Arc<Condvar>,
  153|       |    limiter: RateLimiter,
  154|       |}
  155|       |
  156|       |impl BacklogScanThread {
  157|      3|    fn run(&self) {
  158|      3|        let mut lock = self.mutex.lock().unwrap();
  159|     36|        while !lock.stopped {
  160|     33|            if self.predicate(&lock) {
  161|     33|                self.stats.inc(StatType::BacklogScan, DetailType::Loop);
  162|     33|
  163|     33|                lock.triggered = false;
  164|     33|                // Does a single iteration over all accounts
  165|     33|                lock = self.populate_backlog(lock);
  166|     33|            } else {
  167|      0|                lock = self
  168|      0|                    .condition
  169|      0|                    .wait_while(lock, |l| !l.stopped && !self.predicate(l))
  170|      0|                    .unwrap();
  171|      0|            }
  172|       |        }
  173|      3|    }
  174|       |
  175|     33|    fn predicate(&self, lock: &BacklogScanFlags) -> bool {
  176|     33|        lock.triggered || self.config.enabled
  177|     33|    }
  178|       |
  179|     33|    fn populate_backlog<'a>(
  180|     33|        &'a self,
  181|     33|        mut lock: MutexGuard<'a, BacklogScanFlags>,
  182|     33|    ) -> MutexGuard<'a, BacklogScanFlags> {
  183|     33|        let mut next = Account::zero();
  184|     33|        let mut done = false;
  185|     63|        while !lock.stopped && !done {
  186|       |            // Wait for the rate limiter
  187|     33|            while !self.limiter.should_pass(self.config.batch_size) {
  188|      3|                let wait_time = Duration::from_millis(
  189|      3|                    1000 / max(self.config.rate_limit / self.config.batch_size, 1) as u64 / 2,
  190|      3|                );
  191|      3|
  192|      3|                lock = self
  193|      3|                    .condition
  194|      6|                    .wait_timeout_while(lock, max(wait_time, Duration::from_millis(10)), |i| {
  195|      6|                        !i.stopped
  196|      6|                    })
  197|      3|                    .unwrap()
  198|      3|                    .0;
  199|      3|                if lock.stopped {
  200|      3|                    return lock;
  201|      0|                }
  202|       |            }
  203|       |
  204|     30|            drop(lock);
  205|     30|
  206|     30|            let mut scanned = Vec::new();
  207|     30|            let mut activated = Vec::new();
  208|     30|            {
  209|     30|                let tx = self.ledger.store.tx_begin_read();
  210|     30|                let mut count = 0;
  211|     30|                let mut it = self.ledger.any().accounts_range(&tx, next..);
  212|     60|                while let Some((account, account_info)) = it.next() {
                                              ^30
  213|     30|                    if count >= self.config.batch_size {
  214|      0|                        break;
  215|     30|                    }
  216|     30|
  217|     30|                    self.stats.inc(StatType::BacklogScan, DetailType::Total);
  218|     30|
  219|     30|                    let conf_info = self
  220|     30|                        .ledger
  221|     30|                        .store
  222|     30|                        .confirmation_height
  223|     30|                        .get(&tx, &account)
  224|     30|                        .unwrap_or_default();
  225|     30|
  226|     30|                    let info = ActivatedInfo {
  227|     30|                        account,
  228|     30|                        account_info,
  229|     30|                        conf_info: conf_info.clone(),
  230|     30|                    };
  231|     30|
  232|     30|                    scanned.push(info.clone());
  233|     30|
  234|     30|                    if conf_info.height < info.account_info.block_count {
  235|      0|                        activated.push(info);
  236|     30|                    }
  237|       |
  238|     30|                    next = account.inc_or_max();
  239|     30|                    count += 1;
  240|       |                }
  241|     30|                done = self
  242|     30|                    .ledger
  243|     30|                    .any()
  244|     30|                    .accounts_range(&tx, next..)
  245|     30|                    .next()
  246|     30|                    .is_none();
  247|     30|            }
  248|     30|
  249|     30|            self.stats.add(
  250|     30|                StatType::BacklogScan,
  251|     30|                DetailType::Scanned,
  252|     30|                scanned.len() as u64,
  253|     30|            );
  254|     30|            self.stats.add(
  255|     30|                StatType::BacklogScan,
  256|     30|                DetailType::Activated,
  257|     30|                activated.len() as u64,
  258|     30|            );
  259|     30|
  260|     30|            // Notify about scanned and activated accounts without holding database transaction
  261|     30|            {
  262|     30|                let observers = self.scanned_observers.read().unwrap();
  263|     30|                for observer in &*observers {
  264|     30|                    observer(&scanned);
  265|     30|                }
  266|       |            }
  267|       |            {
  268|     30|                let observers = self.activated_observers.read().unwrap();
  269|     60|                for observer in &*observers {
                                               ^30
  270|     60|                    observer(&activated);
  271|     60|                }
  272|       |            }
  273|       |
  274|     30|            lock = self.mutex.lock().unwrap();
  275|       |        }
  276|     30|        lock
  277|     33|    }
  278|       |}
  279|       |
  280|       |#[derive(Clone)]
  281|       |pub struct ActivatedInfo {
  282|       |    pub account: Account,
  283|       |    pub account_info: AccountInfo,
  284|       |    pub conf_info: ConfirmationHeightInfo,
  285|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/block_context.rs:
    1|       |use crate::stats::DetailType;
    2|       |use rsnano_core::{Block, SavedBlock};
    3|       |use rsnano_ledger::BlockStatus;
    4|       |use std::{
    5|       |    sync::{Arc, Condvar, Mutex},
    6|       |    time::Instant,
    7|       |};
    8|       |use strum_macros::EnumIter;
    9|       |
   10|      0|#[derive(FromPrimitive, Copy, Clone, PartialEq, Eq, Debug, PartialOrd, Ord, EnumIter, Hash)]
   11|       |pub enum BlockSource {
   12|       |    Unknown = 0,
   13|       |    Live,
   14|       |    LiveOriginator,
   15|       |    Bootstrap,
   16|       |    BootstrapLegacy,
   17|       |    Unchecked,
   18|       |    Local,
   19|       |    Forced,
   20|       |    Election,
   21|       |}
   22|       |
   23|       |impl From<BlockSource> for DetailType {
   24|      0|    fn from(value: BlockSource) -> Self {
   25|      0|        match value {
   26|      0|            BlockSource::Unknown => DetailType::Unknown,
   27|      0|            BlockSource::Live => DetailType::Live,
   28|      0|            BlockSource::LiveOriginator => DetailType::LiveOriginator,
   29|      0|            BlockSource::Bootstrap => DetailType::Bootstrap,
   30|      0|            BlockSource::BootstrapLegacy => DetailType::BootstrapLegacy,
   31|      0|            BlockSource::Unchecked => DetailType::Unchecked,
   32|      0|            BlockSource::Local => DetailType::Local,
   33|      0|            BlockSource::Forced => DetailType::Forced,
   34|      0|            BlockSource::Election => DetailType::Election,
   35|       |        }
   36|      0|    }
   37|       |}
   38|       |
   39|       |pub type BlockProcessorCallback = Box<dyn Fn(BlockStatus) + Send + Sync>;
   40|       |
   41|       |pub struct BlockContext {
   42|       |    pub block: Mutex<Block>,
   43|       |    pub saved_block: Mutex<Option<SavedBlock>>,
   44|       |    pub source: BlockSource,
   45|       |    pub callback: Option<BlockProcessorCallback>,
   46|       |    pub arrival: Instant,
   47|       |    pub waiter: Arc<BlockProcessorWaiter>,
   48|       |}
   49|       |
   50|       |impl BlockContext {
   51|      0|    pub fn new(
   52|      0|        block: Block,
   53|      0|        source: BlockSource,
   54|      0|        callback: Option<BlockProcessorCallback>,
   55|      0|    ) -> Self {
   56|      0|        Self {
   57|      0|            block: Mutex::new(block),
   58|      0|            saved_block: Mutex::new(None),
   59|      0|            source,
   60|      0|            arrival: Instant::now(),
   61|      0|            callback,
   62|      0|            waiter: Arc::new(BlockProcessorWaiter::new()),
   63|      0|        }
   64|      0|    }
   65|       |
   66|      0|    pub fn set_result(&self, result: BlockStatus) {
   67|      0|        self.waiter.set_result(result);
   68|      0|    }
   69|       |
   70|      0|    pub fn get_waiter(&self) -> Arc<BlockProcessorWaiter> {
   71|      0|        self.waiter.clone()
   72|      0|    }
   73|       |}
   74|       |
   75|       |impl Drop for BlockContext {
   76|      0|    fn drop(&mut self) {
   77|      0|        self.waiter.cancel()
   78|      0|    }
   79|       |}
   80|       |
   81|       |pub struct BlockProcessorWaiter {
   82|       |    result: Mutex<(Option<BlockStatus>, bool)>, // (status, done)
   83|       |    condition: Condvar,
   84|       |}
   85|       |
   86|       |impl BlockProcessorWaiter {
   87|      0|    pub fn new() -> Self {
   88|      0|        Self {
   89|      0|            result: Mutex::new((None, false)),
   90|      0|            condition: Condvar::new(),
   91|      0|        }
   92|      0|    }
   93|       |
   94|      0|    pub fn set_result(&self, result: BlockStatus) {
   95|      0|        *self.result.lock().unwrap() = (Some(result), true);
   96|      0|        self.condition.notify_all();
   97|      0|    }
   98|       |
   99|      0|    pub fn cancel(&self) {
  100|      0|        self.result.lock().unwrap().1 = true;
  101|      0|        self.condition.notify_all();
  102|      0|    }
  103|       |
  104|      0|    pub fn wait_result(&self) -> Option<BlockStatus> {
  105|      0|        let guard = self.result.lock().unwrap();
  106|      0|        if guard.1 {
  107|      0|            return guard.0;
  108|      0|        }
  109|      0|
  110|      0|        self.condition.wait_while(guard, |i| !i.1).unwrap().0
  111|      0|    }
  112|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/block_processor.rs:
    1|       |use super::{
    2|       |    BlockContext, BlockProcessorCallback, BlockSource, LedgerNotificationQueue, UncheckedMap,
    3|       |};
    4|       |use crate::stats::{DetailType, StatType, Stats};
    5|       |use rsnano_core::{
    6|       |    utils::{ContainerInfo, FairQueue, FairQueueInfo},
    7|       |    work::WorkThresholds,
    8|       |    Block, BlockHash, BlockType, Epoch, Networks, SavedBlock, UncheckedInfo,
    9|       |};
   10|       |use rsnano_ledger::{BlockStatus, Ledger, Writer};
   11|       |use rsnano_network::{ChannelId, DeadChannelCleanupStep};
   12|       |use rsnano_store_lmdb::LmdbWriteTransaction;
   13|       |use std::{
   14|       |    collections::VecDeque,
   15|       |    mem::size_of,
   16|       |    sync::{Arc, Condvar, Mutex, MutexGuard, RwLock},
   17|       |    thread::JoinHandle,
   18|       |    time::{Duration, Instant},
   19|       |};
   20|       |use strum::IntoEnumIterator;
   21|       |use tracing::{debug, error, info, trace};
   22|       |
   23|       |#[derive(Clone, Debug, PartialEq)]
   24|       |pub struct BlockProcessorConfig {
   25|       |    // Maximum number of blocks to queue from network peers
   26|       |    pub max_peer_queue: usize,
   27|       |    //
   28|       |    // Maximum number of blocks to queue from system components (local RPC, bootstrap)
   29|       |    pub max_system_queue: usize,
   30|       |
   31|       |    // Higher priority gets processed more frequently
   32|       |    pub priority_live: usize,
   33|       |    pub priority_bootstrap: usize,
   34|       |    pub priority_local: usize,
   35|       |    pub priority_system: usize,
   36|       |    pub batch_max_time: Duration,
   37|       |    pub full_size: usize,
   38|       |    pub batch_size: usize,
   39|       |    pub work_thresholds: WorkThresholds,
   40|       |}
   41|       |
   42|       |impl BlockProcessorConfig {
   43|       |    pub const DEFAULT_BATCH_SIZE: usize = 0;
   44|       |    pub const DEFAULT_FULL_SIZE: usize = 65536;
   45|       |
   46|     10|    pub fn new(work_thresholds: WorkThresholds) -> Self {
   47|     10|        Self {
   48|     10|            work_thresholds,
   49|     10|            max_peer_queue: 128,
   50|     10|            max_system_queue: 16 * 1024,
   51|     10|            priority_live: 1,
   52|     10|            priority_bootstrap: 8,
   53|     10|            priority_local: 16,
   54|     10|            priority_system: 32,
   55|     10|            batch_max_time: Duration::from_millis(500),
   56|     10|            full_size: Self::DEFAULT_FULL_SIZE,
   57|     10|            batch_size: 256,
   58|     10|        }
   59|     10|    }
   60|       |
   61|      0|    pub fn new_for(network: Networks) -> Self {
   62|      0|        Self::new(WorkThresholds::default_for(network))
   63|      0|    }
   64|       |}
   65|       |
   66|       |pub struct BlockProcessor {
   67|       |    thread: Mutex<Option<JoinHandle<()>>>,
   68|       |    pub(crate) processor_loop: Arc<BlockProcessorLoopImpl>,
   69|       |}
   70|       |
   71|       |impl BlockProcessor {
   72|      4|    pub(crate) fn new(
   73|      4|        config: BlockProcessorConfig,
   74|      4|        ledger: Arc<Ledger>,
   75|      4|        unchecked_map: Arc<UncheckedMap>,
   76|      4|        stats: Arc<Stats>,
   77|      4|        notifier: Arc<LedgerNotificationQueue>,
   78|      4|    ) -> Self {
   79|      4|        let config_l = config.clone();
   80|      4|        let max_size_query = move |origin: &(BlockSource, ChannelId)| match origin.0 {
                                                                                    ^0
   81|      0|            BlockSource::Live | BlockSource::LiveOriginator => config_l.max_peer_queue,
   82|      0|            _ => config_l.max_system_queue,
   83|      0|        };
   84|       |
   85|      4|        let config_l = config.clone();
   86|      4|        let priority_query = move |origin: &(BlockSource, ChannelId)| match origin.0 {
                                                                                    ^0
   87|      0|            BlockSource::Live | BlockSource::LiveOriginator => config.priority_live,
   88|       |            BlockSource::Bootstrap | BlockSource::BootstrapLegacy | BlockSource::Unchecked => {
   89|      0|                config_l.priority_bootstrap
   90|       |            }
   91|      0|            BlockSource::Local => config_l.priority_local,
   92|       |            BlockSource::Election | BlockSource::Forced | BlockSource::Unknown => {
   93|      0|                config.priority_system
   94|       |            }
   95|      0|        };
   96|       |
   97|      4|        Self {
   98|      4|            processor_loop: Arc::new(BlockProcessorLoopImpl {
   99|      4|                mutex: Mutex::new(BlockProcessorImpl {
  100|      4|                    add_queue: FairQueue::new(max_size_query, priority_query),
  101|      4|                    rollback_queue: VecDeque::new(),
  102|      4|                    last_log: None,
  103|      4|                    stopped: false,
  104|      4|                }),
  105|      4|                condition: Condvar::new(),
  106|      4|                ledger,
  107|      4|                unchecked: unchecked_map,
  108|      4|                config,
  109|      4|                stats,
  110|      4|                notifier,
  111|      4|                can_roll_back: RwLock::new(Box::new(|_| true)),
                                                                      ^0
  112|      4|            }),
  113|      4|            thread: Mutex::new(None),
  114|      4|        }
  115|      4|    }
  116|       |
  117|      0|    pub fn new_test_instance(ledger: Arc<Ledger>) -> Self {
  118|      0|        let (queue, _, _) = LedgerNotificationQueue::new(8);
  119|      0|        BlockProcessor::new(
  120|      0|            BlockProcessorConfig::new_for(Networks::NanoDevNetwork),
  121|      0|            ledger,
  122|      0|            Arc::new(UncheckedMap::default()),
  123|      0|            Arc::new(Stats::default()),
  124|      0|            Arc::new(queue),
  125|      0|        )
  126|      0|    }
  127|       |
  128|      0|    pub fn new_null() -> Self {
  129|      0|        Self::new_test_instance(Arc::new(Ledger::new_null()))
  130|      0|    }
  131|       |
  132|       |    // Give other components a chance to veto a rollback
  133|      3|    pub fn on_rolling_back(&self, f: impl Fn(&BlockHash) -> bool + Send + Sync + 'static) {
  134|      3|        *self.processor_loop.can_roll_back.write().unwrap() = Box::new(f);
  135|      3|    }
  136|       |
  137|      3|    pub fn start(&self) {
  138|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  139|      3|        let processor_loop = Arc::clone(&self.processor_loop);
  140|      3|        *self.thread.lock().unwrap() = Some(
  141|      3|            std::thread::Builder::new()
  142|      3|                .name("Blck processing".to_string())
  143|      3|                .spawn(move || {
  144|      3|                    processor_loop.run();
  145|      3|                })
  146|      3|                .unwrap(),
  147|      3|        );
  148|      3|    }
  149|       |
  150|      3|    pub fn stop(&self) {
  151|      3|        self.processor_loop.mutex.lock().unwrap().stopped = true;
  152|      3|        self.processor_loop.condition.notify_all();
  153|      3|        let join_handle = self.thread.lock().unwrap().take();
  154|      3|        if let Some(join_handle) = join_handle {
  155|      3|            join_handle.join().unwrap();
  156|      3|        }
                       ^0
  157|      3|        let mut guard = self.processor_loop.mutex.lock().unwrap();
  158|      3|        for req in guard.rollback_queue.drain(..) {
                          ^0
  159|      0|            *req.result.rolled_back.lock().unwrap() = Some(Vec::new());
  160|      0|            req.result.done.notify_all();
  161|      0|        }
  162|      3|    }
  163|       |
  164|      1|    pub fn total_queue_len(&self) -> usize {
  165|      1|        self.processor_loop.total_queue_len()
  166|      1|    }
  167|       |
  168|      3|    pub fn queue_len(&self, source: BlockSource) -> usize {
  169|      3|        self.processor_loop.queue_len(source)
  170|      3|    }
  171|       |
  172|      1|    pub fn add(&self, block: Block, source: BlockSource, channel_id: ChannelId) -> bool {
  173|      1|        self.processor_loop.add(block, source, channel_id, None)
  174|      1|    }
  175|       |
  176|      0|    pub fn add_with_callback(
  177|      0|        &self,
  178|      0|        block: Block,
  179|      0|        source: BlockSource,
  180|      0|        channel_id: ChannelId,
  181|      0|        callback: BlockProcessorCallback,
  182|      0|    ) -> bool {
  183|      0|        self.processor_loop
  184|      0|            .add(block, source, channel_id, Some(callback))
  185|      0|    }
  186|       |
  187|      0|    pub fn add_blocking(
  188|      0|        &self,
  189|      0|        block: Arc<Block>,
  190|      0|        source: BlockSource,
  191|      0|    ) -> anyhow::Result<Result<SavedBlock, BlockStatus>> {
  192|      0|        self.processor_loop.add_blocking(block, source)
  193|      0|    }
  194|       |
  195|      0|    pub fn roll_back_blocking(
  196|      0|        &self,
  197|      0|        targets: Vec<BlockHash>,
  198|      0|        max_rollbacks: usize,
  199|      0|    ) -> Vec<BlockHash> {
  200|      0|        self.processor_loop
  201|      0|            .roll_back_blocking(targets, max_rollbacks)
  202|      0|    }
  203|       |
  204|      0|    pub fn process_active(&self, block: Block) {
  205|      0|        self.processor_loop.process_active(block);
  206|      0|    }
  207|       |
  208|      0|    pub fn force(&self, block: Block) {
  209|      0|        self.processor_loop.force(block);
  210|      0|    }
  211|       |
  212|      0|    pub fn wait(&self) -> bool {
  213|      0|        self.processor_loop.notifier.wait()
  214|      0|    }
  215|       |
  216|      0|    pub fn info(&self) -> FairQueueInfo<BlockSource> {
  217|      0|        self.processor_loop.info()
  218|      0|    }
  219|       |
  220|      0|    pub fn container_info(&self) -> ContainerInfo {
  221|      0|        self.processor_loop.container_info()
  222|      0|    }
  223|       |}
  224|       |
  225|       |impl Drop for BlockProcessor {
  226|      4|    fn drop(&mut self) {
  227|      4|        // Thread must be stopped before destruction
  228|      4|        debug_assert!(self.thread.lock().unwrap().is_none());
  229|      4|    }
  230|       |}
  231|       |
  232|       |pub(crate) struct BlockProcessorLoopImpl {
  233|       |    mutex: Mutex<BlockProcessorImpl>,
  234|       |    condition: Condvar,
  235|       |    ledger: Arc<Ledger>,
  236|       |    unchecked: Arc<UncheckedMap>,
  237|       |    config: BlockProcessorConfig,
  238|       |    stats: Arc<Stats>,
  239|       |    notifier: Arc<LedgerNotificationQueue>,
  240|       |    can_roll_back: RwLock<Box<dyn Fn(&BlockHash) -> bool + Send + Sync>>,
  241|       |}
  242|       |
  243|       |trait BlockProcessorLoop {
  244|       |    fn run(&self);
  245|       |}
  246|       |
  247|       |impl BlockProcessorLoop for Arc<BlockProcessorLoopImpl> {
  248|      3|    fn run(&self) {
  249|      3|        let mut guard = self.mutex.lock().unwrap();
  250|      6|        while !guard.stopped {
  251|      3|            if !guard.add_queue.is_empty() || !guard.rollback_queue.is_empty() {
  252|      0|                drop(guard);
  253|      0|                // It's possible that ledger processing happens faster than the
  254|      0|                // notifications can be processed by other components, cooldown here
  255|      0|                if self.notifier.wait() {
  256|      0|                    self.stats
  257|      0|                        .inc(StatType::BlockProcessor, DetailType::Cooldown);
  258|      0|                }
  259|      0|                guard = self.mutex.lock().unwrap();
  260|      0|                if guard.stopped {
  261|      0|                    return;
  262|      0|                }
  263|      3|            }
  264|       |
  265|      3|            if !guard.rollback_queue.is_empty() {
  266|      0|                let request = guard.rollback_queue.pop_front().unwrap();
  267|      0|                drop(guard);
  268|      0|                self.process_rollback(request);
  269|      0|                guard = self.mutex.lock().unwrap();
  270|      3|            } else if !guard.add_queue.is_empty() {
  271|      0|                if guard.should_log() {
  272|      0|                    info!(
  273|      0|                        "{} blocks (+ {} forced) in processing_queue",
  274|      0|                        guard.add_queue.len(),
  275|      0|                        guard
  276|      0|                            .add_queue
  277|      0|                            .queue_len(&(BlockSource::Forced, ChannelId::LOOPBACK))
  278|       |                    );
  279|      0|                }
  280|       |
  281|      0|                let mut processed = self.process_batch(guard);
  282|       |                // Set results for futures when not holding the lock
  283|      0|                for (result, context) in processed.iter_mut() {
  284|      0|                    if let Some(cb) = &context.callback {
  285|      0|                        cb(*result);
  286|      0|                    }
  287|      0|                    context.set_result(*result);
  288|       |                }
  289|      0|                self.notifier.notify_batch_processed(processed);
  290|      0|
  291|      0|                guard = self.mutex.lock().unwrap();
  292|      3|            } else {
  293|      3|                guard = self
  294|      3|                    .condition
  295|      6|                    .wait_while(guard, |i| {
  296|      6|                        !i.stopped && i.add_queue.is_empty() && i.rollback_queue.is_empty()
                                                    ^3                        ^3
  297|      6|                    })
  298|      3|                    .unwrap();
  299|      3|            }
  300|       |        }
  301|      3|    }
  302|       |}
  303|       |
  304|       |impl BlockProcessorLoopImpl {
  305|      0|    pub fn process_active(&self, block: Block) {
  306|      0|        self.add(block, BlockSource::Live, ChannelId::LOOPBACK, None);
  307|      0|    }
  308|       |
  309|      1|    pub fn add(
  310|      1|        &self,
  311|      1|        block: Block,
  312|      1|        source: BlockSource,
  313|      1|        channel_id: ChannelId,
  314|      1|        callback: Option<BlockProcessorCallback>,
  315|      1|    ) -> bool {
  316|      1|        if !self.config.work_thresholds.validate_entry_block(&block) {
  317|      1|            self.stats
  318|      1|                .inc(StatType::BlockProcessor, DetailType::InsufficientWork);
  319|      1|            return false; // Not added
  320|      0|        }
  321|      0|
  322|      0|        self.stats
  323|      0|            .inc(StatType::BlockProcessor, DetailType::Process);
  324|      0|        debug!(
  325|      0|            "Processing block (async): {} (source: {:?} channel id: {})",
  326|      0|            block.hash(),
  327|       |            source,
  328|       |            channel_id
  329|       |        );
  330|       |
  331|      0|        self.add_impl(
  332|      0|            Arc::new(BlockContext::new(block, source, callback)),
  333|      0|            channel_id,
  334|      0|        )
  335|      1|    }
  336|       |
  337|      0|    pub fn add_blocking(
  338|      0|        &self,
  339|      0|        block: Arc<Block>,
  340|      0|        source: BlockSource,
  341|      0|    ) -> anyhow::Result<Result<SavedBlock, BlockStatus>> {
  342|      0|        self.stats
  343|      0|            .inc(StatType::BlockProcessor, DetailType::ProcessBlocking);
  344|      0|        debug!(
  345|      0|            "Processing block (blocking): {} (source: {:?})",
  346|      0|            block.hash(),
  347|       |            source
  348|       |        );
  349|       |
  350|      0|        let hash = block.hash();
  351|      0|        let ctx = Arc::new(BlockContext::new(block.as_ref().clone(), source, None));
  352|      0|        let waiter = ctx.get_waiter();
  353|      0|        self.add_impl(ctx.clone(), ChannelId::LOOPBACK);
  354|      0|
  355|      0|        match waiter.wait_result() {
  356|      0|            Some(BlockStatus::Progress) => Ok(Ok(ctx.saved_block.lock().unwrap().clone().unwrap())),
  357|      0|            Some(status) => Ok(Err(status)),
  358|       |            None => {
  359|      0|                self.stats
  360|      0|                    .inc(StatType::BlockProcessor, DetailType::ProcessBlockingTimeout);
  361|      0|                error!("Block dropped when processing: {}", hash);
  362|      0|                Err(anyhow!("Block dropped when processing"))
  363|       |            }
  364|       |        }
  365|      0|    }
  366|       |
  367|      0|    fn roll_back_blocking(&self, targets: Vec<BlockHash>, max_rollbacks: usize) -> Vec<BlockHash> {
  368|      0|        let result = Arc::new(RollbackResult::new());
  369|      0|        {
  370|      0|            let mut guard = self.mutex.lock().unwrap();
  371|      0|            if guard.stopped {
  372|      0|                return Vec::new();
  373|      0|            }
  374|      0|
  375|      0|            let request = RollbackRequest {
  376|      0|                targets,
  377|      0|                max_rollbacks,
  378|      0|                result: result.clone(),
  379|      0|            };
  380|      0|            guard.rollback_queue.push_back(request);
  381|      0|        }
  382|      0|        self.condition.notify_all();
  383|      0|
  384|      0|        let mut guard = result.rolled_back.lock().unwrap();
  385|      0|        guard = result.done.wait_while(guard, |i| i.is_none()).unwrap();
  386|      0|        guard.take().unwrap()
  387|      0|    }
  388|       |
  389|      0|    pub fn force(&self, block: Block) {
  390|      0|        self.stats.inc(StatType::BlockProcessor, DetailType::Force);
  391|      0|        debug!("Forcing block: {}", block.hash());
  392|      0|        let ctx = Arc::new(BlockContext::new(block, BlockSource::Forced, None));
  393|      0|        self.add_impl(ctx, ChannelId::LOOPBACK);
  394|      0|    }
  395|       |
  396|       |    // TODO: Remove and replace all checks with calls to size (block_source)
  397|      1|    pub fn total_queue_len(&self) -> usize {
  398|      1|        self.mutex.lock().unwrap().add_queue.len()
  399|      1|    }
  400|       |
  401|      3|    pub fn queue_len(&self, source: BlockSource) -> usize {
  402|      3|        self.mutex
  403|      3|            .lock()
  404|      3|            .unwrap()
  405|      3|            .add_queue
  406|      3|            .sum_queue_len((source, ChannelId::MIN)..=(source, ChannelId::MAX))
  407|      3|    }
  408|       |
  409|      0|    fn add_impl(&self, context: Arc<BlockContext>, channel_id: ChannelId) -> bool {
  410|      0|        let source = context.source;
  411|      0|        let added;
  412|      0|        {
  413|      0|            let mut guard = self.mutex.lock().unwrap();
  414|      0|            added = guard.add_queue.push((source, channel_id), context);
  415|      0|        }
  416|      0|        if added {
  417|      0|            self.condition.notify_all();
  418|      0|        } else {
  419|      0|            self.stats
  420|      0|                .inc(StatType::BlockProcessor, DetailType::Overfill);
  421|      0|            self.stats
  422|      0|                .inc(StatType::BlockProcessorOverfill, source.into());
  423|      0|        }
  424|      0|        added
  425|      0|    }
  426|       |
  427|      0|    fn next_batch(
  428|      0|        &self,
  429|      0|        data: &mut BlockProcessorImpl,
  430|      0|        max_count: usize,
  431|      0|    ) -> VecDeque<Arc<BlockContext>> {
  432|      0|        let mut results = VecDeque::new();
  433|      0|        while !data.add_queue.is_empty() && results.len() < max_count {
  434|      0|            results.push_back(data.next());
  435|      0|        }
  436|      0|        results
  437|      0|    }
  438|       |
  439|      0|    fn process_rollback(&self, request: RollbackRequest) {
  440|      0|        self.stats
  441|      0|            .inc(StatType::BoundedBacklog, DetailType::PerformingRollbacks);
  442|      0|
  443|      0|        let mut rolled_back_count = 0;
  444|      0|        let mut processed = Vec::new();
  445|      0|        let mut processed_hashes = Vec::new();
  446|      0|        {
  447|      0|            let can_roll_back = self.can_roll_back.read().unwrap();
  448|      0|            let _guard = self.ledger.write_queue.wait(Writer::BoundedBacklog);
  449|      0|            let mut tx = self.ledger.rw_txn();
  450|       |
  451|      0|            for hash in &request.targets {
  452|       |                // Skip the rollback if the block is being used by the node, this should be race free as it's checked while holding the ledger write lock
  453|      0|                if !can_roll_back(hash) {
  454|      0|                    self.stats
  455|      0|                        .inc(StatType::BoundedBacklog, DetailType::RollbackSkipped);
  456|      0|                    continue;
  457|      0|                }
  458|       |
  459|       |                // Here we check that the block is still OK to rollback, there could be a delay between gathering the targets and performing the rollbacks
  460|      0|                if let Some(block) = self.ledger.any().get_block(&tx, hash) {
  461|      0|                    debug!(
  462|      0|                        "Rolling back: {}, account: {}",
  463|      0|                        hash,
  464|      0|                        block.account().encode_account()
  465|       |                    );
  466|       |
  467|      0|                    let rollback_list = match self.ledger.rollback(&mut tx, &block.hash()) {
  468|      0|                        Ok(rollback_list) => {
  469|      0|                            self.stats
  470|      0|                                .inc(StatType::BoundedBacklog, DetailType::Rollback);
  471|      0|                            rollback_list
  472|       |                        }
  473|      0|                        Err((_, rollback_list)) => {
  474|      0|                            self.stats
  475|      0|                                .inc(StatType::BoundedBacklog, DetailType::RollbackFailed);
  476|      0|                            rollback_list
  477|       |                        }
  478|       |                    };
  479|       |
  480|      0|                    rolled_back_count += rollback_list.len();
  481|      0|                    for b in &rollback_list {
  482|      0|                        processed_hashes.push(b.hash());
  483|      0|                    }
  484|      0|                    processed.push((rollback_list, block.qualified_root()));
  485|      0|
  486|      0|                    // Return early if we reached the maximum number of rollbacks
  487|      0|                    if rolled_back_count >= request.max_rollbacks {
  488|      0|                        break;
  489|      0|                    }
  490|      0|                } else {
  491|      0|                    self.stats
  492|      0|                        .inc(StatType::BoundedBacklog, DetailType::RollbackMissingBlock);
  493|      0|                    rolled_back_count += 1;
  494|      0|                    processed_hashes.push(*hash);
  495|      0|                }
  496|       |            }
  497|       |        }
  498|       |
  499|      0|        for (rolled_back, root) in processed {
  500|      0|            self.notifier.notify_rollback(rolled_back, root);
  501|      0|        }
  502|       |
  503|      0|        *request.result.rolled_back.lock().unwrap() = Some(processed_hashes);
  504|      0|        request.result.done.notify_all();
  505|      0|    }
  506|       |
  507|      0|    fn process_batch(
  508|      0|        &self,
  509|      0|        mut guard: MutexGuard<BlockProcessorImpl>,
  510|      0|    ) -> Vec<(BlockStatus, Arc<BlockContext>)> {
  511|      0|        let batch = self.next_batch(&mut guard, self.config.batch_size);
  512|      0|        drop(guard);
  513|      0|
  514|      0|        let mut write_guard = self.ledger.write_queue.wait(Writer::BlockProcessor);
  515|      0|        let mut tx = self.ledger.rw_txn();
  516|      0|
  517|      0|        let timer = Instant::now();
  518|      0|
  519|      0|        // Processing blocks
  520|      0|        let mut number_of_blocks_processed = 0;
  521|      0|        let mut number_of_forced_processed = 0;
  522|      0|
  523|      0|        let mut processed = Vec::new();
  524|      0|        for ctx in batch {
  525|      0|            let force = ctx.source == BlockSource::Forced;
  526|      0|
  527|      0|            (write_guard, tx) = self.ledger.refresh_if_needed(write_guard, tx);
  528|      0|
  529|      0|            if force {
  530|      0|                number_of_forced_processed += 1;
  531|      0|                let block = ctx.block.lock().unwrap().clone();
  532|      0|                self.rollback_competitor(&mut tx, &block);
  533|      0|            }
  534|       |
  535|      0|            number_of_blocks_processed += 1;
  536|      0|
  537|      0|            let result = self.process_one(&mut tx, &ctx);
  538|      0|            processed.push((result, ctx));
  539|       |        }
  540|       |
  541|      0|        if number_of_blocks_processed != 0 && timer.elapsed() > Duration::from_millis(100) {
  542|      0|            debug!(
  543|      0|                "Processed {} blocks ({} blocks were forced) in {} ms",
  544|      0|                number_of_blocks_processed,
  545|      0|                number_of_forced_processed,
  546|      0|                timer.elapsed().as_millis(),
  547|       |            );
  548|      0|        }
  549|      0|        processed
  550|      0|    }
  551|       |
  552|      0|    pub fn process_one(
  553|      0|        &self,
  554|      0|        txn: &mut LmdbWriteTransaction,
  555|      0|        context: &BlockContext,
  556|      0|    ) -> BlockStatus {
  557|      0|        let mut block = context.block.lock().unwrap().clone();
  558|      0|        let hash = block.hash();
  559|      0|        let mut saved_block = None;
  560|       |
  561|      0|        let result = match self.ledger.process(txn, &mut block) {
  562|      0|            Ok(saved) => {
  563|      0|                saved_block = Some(saved.clone());
  564|      0|                *context.saved_block.lock().unwrap() = Some(saved);
  565|      0|                BlockStatus::Progress
  566|       |            }
  567|      0|            Err(r) => r,
  568|       |        };
  569|       |
  570|       |        // reassign to copy sideband
  571|      0|        *context.block.lock().unwrap() = block.clone();
  572|      0|
  573|      0|        self.stats
  574|      0|            .inc(StatType::BlockProcessorResult, result.into());
  575|      0|        self.stats
  576|      0|            .inc(StatType::BlockProcessorSource, context.source.into());
  577|      0|        trace!(?result, block = %block.hash(), source = ?context.source, "Block processed");
  578|       |
  579|      0|        match result {
  580|       |            BlockStatus::Progress => {
  581|      0|                self.unchecked.trigger(&hash.into());
  582|      0|
  583|      0|                /*
  584|      0|                 * For send blocks check epoch open unchecked (gap pending).
  585|      0|                 * For state blocks check only send subtype and only if block epoch is not last epoch.
  586|      0|                 * If epoch is last, then pending entry shouldn't trigger same epoch open block for destination account.
  587|      0|                 * */
  588|      0|                let block = saved_block.unwrap();
  589|      0|                if block.block_type() == BlockType::LegacySend
  590|      0|                    || block.block_type() == BlockType::State
  591|      0|                        && block.is_send()
  592|      0|                        && block.epoch() < Epoch::MAX
  593|      0|                {
  594|      0|                    self.unchecked.trigger(&block.destination_or_link().into());
  595|      0|                }
  596|       |            }
  597|      0|            BlockStatus::GapPrevious => {
  598|      0|                self.unchecked
  599|      0|                    .put(block.previous().into(), UncheckedInfo::new(block));
  600|      0|                self.stats.inc(StatType::Ledger, DetailType::GapPrevious);
  601|      0|            }
  602|      0|            BlockStatus::GapSource => {
  603|      0|                self.unchecked.put(
  604|      0|                    block
  605|      0|                        .source_field()
  606|      0|                        .unwrap_or(block.link_field().unwrap_or_default().into())
  607|      0|                        .into(),
  608|      0|                    UncheckedInfo::new(block),
  609|      0|                );
  610|      0|                self.stats.inc(StatType::Ledger, DetailType::GapSource);
  611|      0|            }
  612|      0|            BlockStatus::GapEpochOpenPending => {
  613|      0|                // Specific unchecked key starting with epoch open block account public key
  614|      0|                self.unchecked.put(
  615|      0|                    block.account_field().unwrap().into(),
  616|      0|                    UncheckedInfo::new(block),
  617|      0|                );
  618|      0|                self.stats.inc(StatType::Ledger, DetailType::GapSource);
  619|      0|            }
  620|      0|            BlockStatus::Old => {
  621|      0|                self.stats.inc(StatType::Ledger, DetailType::Old);
  622|      0|            }
  623|       |            // These are unexpected and indicate erroneous/malicious behavior, log debug info to highlight the issue
  624|       |            BlockStatus::BadSignature => {
  625|      0|                debug!("Block signature is invalid: {}", hash)
  626|       |            }
  627|       |            BlockStatus::NegativeSpend => {
  628|      0|                debug!("Block spends negative amount: {}", hash)
  629|       |            }
  630|       |            BlockStatus::Unreceivable => {
  631|      0|                debug!("Block is unreceivable: {}", hash)
  632|       |            }
  633|       |            BlockStatus::Fork => {
  634|      0|                self.stats.inc(StatType::Ledger, DetailType::Fork);
  635|      0|                debug!("Block is a fork: {}", hash)
  636|       |            }
  637|       |            BlockStatus::OpenedBurnAccount => {
  638|      0|                debug!("Block opens burn account: {}", hash)
  639|       |            }
  640|       |            BlockStatus::BalanceMismatch => {
  641|      0|                debug!("Block balance mismatch: {}", hash)
  642|       |            }
  643|       |            BlockStatus::RepresentativeMismatch => {
  644|      0|                debug!("Block representative mismatch: {}", hash)
  645|       |            }
  646|       |            BlockStatus::BlockPosition => {
  647|      0|                debug!("Block is in incorrect position: {}", hash)
  648|       |            }
  649|       |            BlockStatus::InsufficientWork => {
  650|      0|                debug!("Block has insufficient work: {}", hash)
  651|       |            }
  652|       |        }
  653|       |
  654|      0|        result
  655|      0|    }
  656|       |
  657|      0|    fn rollback_competitor(&self, transaction: &mut LmdbWriteTransaction, fork_block: &Block) {
  658|      0|        let hash = fork_block.hash();
  659|      0|        if let Some(successor) = self
  660|      0|            .ledger
  661|      0|            .any()
  662|      0|            .block_successor_by_qualified_root(transaction, &fork_block.qualified_root())
  663|       |        {
  664|      0|            if successor != hash {
  665|       |                // Replace our block with the winner and roll back any dependent blocks
  666|      0|                debug!("Rolling back: {} and replacing with: {}", successor, hash);
  667|      0|                let rollback_list = match self.ledger.rollback(transaction, &successor) {
  668|      0|                    Ok(rollback_list) => {
  669|      0|                        self.stats.inc(StatType::Ledger, DetailType::Rollback);
  670|      0|                        debug!("Blocks rolled back: {}", rollback_list.len());
  671|      0|                        rollback_list
  672|       |                    }
  673|      0|                    Err((e, rollback_list)) => {
  674|      0|                        self.stats.inc(StatType::Ledger, DetailType::RollbackFailed);
  675|      0|                        error!(
  676|       |                            ?e,
  677|      0|                            "Failed to roll back: {} because it or a successor was confirmed",
  678|       |                            successor
  679|       |                        );
  680|      0|                        rollback_list
  681|       |                    }
  682|       |                };
  683|       |
  684|      0|                if !rollback_list.is_empty() {
  685|      0|                    // Notify observers of the rolled back blocks on a background thread while not holding the ledger write lock
  686|      0|                    self.notifier
  687|      0|                        .notify_rollback(rollback_list, fork_block.qualified_root());
  688|      0|                }
  689|      0|            }
  690|      0|        }
  691|      0|    }
  692|       |
  693|      0|    pub fn info(&self) -> FairQueueInfo<BlockSource> {
  694|      0|        let guard = self.mutex.lock().unwrap();
  695|      0|        guard.info()
  696|      0|    }
  697|       |
  698|      0|    pub fn container_info(&self) -> ContainerInfo {
  699|      0|        let guard = self.mutex.lock().unwrap();
  700|      0|        ContainerInfo::builder()
  701|      0|            .leaf("blocks", guard.add_queue.len(), size_of::<Arc<Block>>())
  702|      0|            .leaf(
  703|      0|                "forced",
  704|      0|                guard
  705|      0|                    .add_queue
  706|      0|                    .queue_len(&(BlockSource::Forced, ChannelId::LOOPBACK)),
  707|      0|                size_of::<Arc<Block>>(),
  708|      0|            )
  709|      0|            .node("queue", guard.add_queue.container_info())
  710|      0|            .finish()
  711|      0|    }
  712|       |}
  713|       |
  714|       |struct BlockProcessorImpl {
  715|       |    add_queue: FairQueue<(BlockSource, ChannelId), Arc<BlockContext>>,
  716|       |    rollback_queue: VecDeque<RollbackRequest>,
  717|       |    last_log: Option<Instant>,
  718|       |    stopped: bool,
  719|       |}
  720|       |
  721|       |impl BlockProcessorImpl {
  722|      0|    fn next(&mut self) -> Arc<BlockContext> {
  723|      0|        debug_assert!(!self.add_queue.is_empty()); // This should be checked before calling next
  724|      0|        if !self.add_queue.is_empty() {
  725|      0|            let ((source, _), request) = self.add_queue.next().unwrap();
  726|      0|            assert!(source != BlockSource::Forced || request.source == BlockSource::Forced);
  727|      0|            return request;
  728|      0|        }
  729|      0|
  730|      0|        panic!("next() called when no blocks are ready");
  731|      0|    }
  732|       |
  733|      0|    pub fn should_log(&mut self) -> bool {
  734|      0|        if let Some(last) = &self.last_log {
  735|      0|            if last.elapsed() >= Duration::from_secs(15) {
  736|      0|                self.last_log = Some(Instant::now());
  737|      0|                return true;
  738|      0|            }
  739|      0|        }
  740|       |
  741|      0|        false
  742|      0|    }
  743|       |
  744|      0|    pub fn info(&self) -> FairQueueInfo<BlockSource> {
  745|      0|        self.add_queue.compacted_info(|(source, _)| *source)
  746|      0|    }
  747|       |}
  748|       |
  749|       |pub(crate) struct BlockProcessorCleanup(Arc<BlockProcessorLoopImpl>);
  750|       |
  751|       |impl BlockProcessorCleanup {
  752|      3|    pub fn new(processor_loop: Arc<BlockProcessorLoopImpl>) -> Self {
  753|      3|        Self(processor_loop)
  754|      3|    }
  755|       |}
  756|       |
  757|       |impl DeadChannelCleanupStep for BlockProcessorCleanup {
  758|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  759|      0|        let mut guard = self.0.mutex.lock().unwrap();
  760|      0|        for channel_id in dead_channel_ids {
  761|      0|            for source in BlockSource::iter() {
  762|      0|                guard.add_queue.remove(&(source, *channel_id))
  763|       |            }
  764|       |        }
  765|      0|    }
  766|       |}
  767|       |
  768|       |pub struct RollbackRequest {
  769|       |    targets: Vec<BlockHash>,
  770|       |    max_rollbacks: usize,
  771|       |    result: Arc<RollbackResult>,
  772|       |}
  773|       |
  774|       |struct RollbackResult {
  775|       |    rolled_back: Mutex<Option<Vec<BlockHash>>>,
  776|       |    done: Condvar,
  777|       |}
  778|       |
  779|       |impl RollbackResult {
  780|      0|    fn new() -> Self {
  781|      0|        Self {
  782|      0|            rolled_back: Mutex::new(None),
  783|      0|            done: Condvar::new(),
  784|      0|        }
  785|      0|    }
  786|       |}
  787|       |
  788|       |#[cfg(test)]
  789|       |mod tests {
  790|       |    use super::*;
  791|       |    use crate::stats::Direction;
  792|       |
  793|       |    #[test]
  794|      1|    fn insufficient_work() {
  795|      1|        let config = BlockProcessorConfig::new(WorkThresholds::new_stub());
  796|      1|        let ledger = Arc::new(Ledger::new_null());
  797|      1|        let unchecked = Arc::new(UncheckedMap::default());
  798|      1|        let stats = Arc::new(Stats::default());
  799|      1|        let (notifier, _, _) = LedgerNotificationQueue::new(8);
  800|      1|        let block_processor =
  801|      1|            BlockProcessor::new(config, ledger, unchecked, stats.clone(), notifier.into());
  802|      1|
  803|      1|        let mut block = Block::new_test_instance();
  804|      1|        block.set_work(3);
  805|      1|
  806|      1|        block_processor.add(block, BlockSource::Live, ChannelId::LOOPBACK);
  807|      1|
  808|      1|        assert_eq!(
  809|      1|            stats.count(
  810|      1|                StatType::BlockProcessor,
  811|      1|                DetailType::InsufficientWork,
  812|      1|                Direction::In
  813|      1|            ),
  814|      1|            1
  815|      1|        );
  816|       |
  817|      1|        assert_eq!(block_processor.total_queue_len(), 0);
  818|      1|    }
  819|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/bounded_backlog.rs:
    1|       |use super::{
    2|       |    backlog_index::{BacklogEntry, BacklogIndex},
    3|       |    backlog_scan::ActivatedInfo,
    4|       |    BlockContext, BlockProcessor,
    5|       |};
    6|       |use crate::{
    7|       |    consensus::Bucketing,
    8|       |    stats::{DetailType, StatType, Stats},
    9|       |};
   10|       |use rsnano_core::{
   11|       |    utils::ContainerInfo, Account, AccountInfo, BlockHash, ConfirmationHeightInfo, SavedBlock,
   12|       |};
   13|       |use rsnano_ledger::{BlockStatus, Ledger};
   14|       |use rsnano_network::bandwidth_limiter::RateLimiter;
   15|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   16|       |use std::{
   17|       |    cmp::min,
   18|       |    sync::{Arc, Condvar, Mutex, RwLock},
   19|       |    thread::JoinHandle,
   20|       |    time::Duration,
   21|       |};
   22|       |
   23|       |#[derive(Clone, Debug, PartialEq)]
   24|       |pub struct BoundedBacklogConfig {
   25|       |    pub max_backlog: usize,
   26|       |    pub batch_size: usize,
   27|       |    pub scan_rate: usize,
   28|       |}
   29|       |
   30|       |impl Default for BoundedBacklogConfig {
   31|      9|    fn default() -> Self {
   32|      9|        Self {
   33|      9|            max_backlog: 100_000,
   34|      9|            batch_size: 32,
   35|      9|            scan_rate: 64,
   36|      9|        }
   37|      9|    }
   38|       |}
   39|       |
   40|       |pub struct BoundedBacklog {
   41|       |    thread: Mutex<Option<JoinHandle<()>>>,
   42|       |    scan_thread: Mutex<Option<JoinHandle<()>>>,
   43|       |    backlog_impl: Arc<BoundedBacklogImpl>,
   44|       |    bucketing: Bucketing,
   45|       |}
   46|       |
   47|       |impl BoundedBacklog {
   48|      3|    pub(crate) fn new(
   49|      3|        bucketing: Bucketing,
   50|      3|        config: BoundedBacklogConfig,
   51|      3|        ledger: Arc<Ledger>,
   52|      3|        block_processor: Arc<BlockProcessor>,
   53|      3|        stats: Arc<Stats>,
   54|      3|    ) -> Self {
   55|      3|        let backlog_impl = Arc::new(BoundedBacklogImpl {
   56|      3|            condition: Condvar::new(),
   57|      3|            mutex: Mutex::new(BacklogData {
   58|      3|                stopped: false,
   59|      3|                index: BacklogIndex::new(bucketing.bucket_count()),
   60|      3|                ledger: ledger.clone(),
   61|      3|                config: config.clone(),
   62|      3|                bucket_count: bucketing.bucket_count(),
   63|      3|                scan_limiter: RateLimiter::new(config.scan_rate),
   64|      3|            }),
   65|      3|            config,
   66|      3|            stats,
   67|      3|            ledger,
   68|      3|            block_processor,
   69|      3|            can_rollback: RwLock::new(Box::new(|_| true)),
                                                                 ^0
   70|      3|        });
   71|      3|
   72|      3|        Self {
   73|      3|            backlog_impl,
   74|      3|            thread: Mutex::new(None),
   75|      3|            scan_thread: Mutex::new(None),
   76|      3|            bucketing,
   77|      3|        }
   78|      3|    }
   79|       |
   80|      3|    pub fn start(&self) {
   81|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
   82|       |
   83|      3|        let backlog_impl = self.backlog_impl.clone();
   84|      3|        let handle = std::thread::Builder::new()
   85|      3|            .name("Bounded backlog".to_owned())
   86|      3|            .spawn(move || backlog_impl.run())
   87|      3|            .unwrap();
   88|      3|        *self.thread.lock().unwrap() = Some(handle);
   89|      3|
   90|      3|        let backlog_impl = self.backlog_impl.clone();
   91|      3|        let handle = std::thread::Builder::new()
   92|      3|            .name("Bounded b scan".to_owned())
   93|      3|            .spawn(move || backlog_impl.run_scan())
   94|      3|            .unwrap();
   95|      3|        *self.scan_thread.lock().unwrap() = Some(handle);
   96|      3|    }
   97|       |
   98|      3|    pub fn stop(&self) {
   99|      3|        self.backlog_impl.mutex.lock().unwrap().stopped = true;
  100|      3|        self.backlog_impl.condition.notify_all();
  101|      3|
  102|      3|        let handle = self.thread.lock().unwrap().take();
  103|      3|        if let Some(handle) = handle {
  104|      3|            handle.join().unwrap();
  105|      3|        }
                       ^0
  106|       |
  107|      3|        let handle = self.scan_thread.lock().unwrap().take();
  108|      3|        if let Some(handle) = handle {
  109|      3|            handle.join().unwrap();
  110|      3|        }
                       ^0
  111|      3|    }
  112|       |
  113|       |    // Give other components a chance to veto a rollback
  114|      3|    pub fn on_rolling_back(&self, f: impl Fn(&BlockHash) -> bool + Send + Sync + 'static) {
  115|      3|        *self.backlog_impl.can_rollback.write().unwrap() = Box::new(f);
  116|      3|    }
  117|       |
  118|     30|    pub fn activate_batch(&self, batch: &[ActivatedInfo]) {
  119|     30|        let mut tx = self.backlog_impl.ledger.read_txn();
  120|     30|        for info in batch {
                          ^0
  121|      0|            self.activate(&mut tx, &info.account, &info.account_info, &info.conf_info);
  122|      0|        }
  123|     30|    }
  124|       |
  125|      0|    pub fn insert_batch(&self, batch: &[(BlockStatus, Arc<BlockContext>)]) {
  126|      0|        let tx = self.backlog_impl.ledger.read_txn();
  127|      0|        for (result, context) in batch {
  128|      0|            if *result == BlockStatus::Progress {
  129|      0|                if let Some(block) = context.saved_block.lock().unwrap().clone() {
  130|      0|                    self.insert(&tx, &block);
  131|      0|                }
  132|      0|            }
  133|       |        }
  134|      0|    }
  135|       |
  136|     30|    pub fn erase_accounts(&self, accounts: impl IntoIterator<Item = Account>) {
  137|     30|        let mut guard = self.backlog_impl.mutex.lock().unwrap();
  138|     30|        for account in accounts.into_iter() {
  139|     30|            guard.index.erase_account(&account);
  140|     30|        }
  141|     30|    }
  142|       |
  143|      0|    pub fn erase_hashes(&self, accounts: impl IntoIterator<Item = BlockHash>) {
  144|      0|        let mut guard = self.backlog_impl.mutex.lock().unwrap();
  145|      0|        for account in accounts.into_iter() {
  146|      0|            guard.index.erase_hash(&account);
  147|      0|        }
  148|      0|    }
  149|       |
  150|      0|    fn contains(&self, hash: &BlockHash) -> bool {
  151|      0|        let guard = self.backlog_impl.mutex.lock().unwrap();
  152|      0|        guard.index.contains(hash)
  153|      0|    }
  154|       |
  155|      0|    fn activate(
  156|      0|        &self,
  157|      0|        tx: &mut LmdbReadTransaction,
  158|      0|        _account: &Account,
  159|      0|        account_info: &AccountInfo,
  160|      0|        conf_info: &ConfirmationHeightInfo,
  161|      0|    ) {
  162|      0|        debug_assert!(conf_info.frontier != account_info.head);
  163|       |
  164|       |        // Insert blocks into the index starting from the account head block
  165|      0|        let mut block = self
  166|      0|            .backlog_impl
  167|      0|            .ledger
  168|      0|            .any()
  169|      0|            .get_block(tx, &account_info.head);
  170|       |
  171|      0|        while let Some(blk) = block {
  172|       |            // We reached the confirmed frontier, no need to track more blocks
  173|      0|            if blk.hash() == conf_info.frontier {
  174|      0|                break;
  175|      0|            }
  176|      0|
  177|      0|            // Check if the block is already in the backlog, avoids unnecessary ledger lookups
  178|      0|            if self.contains(&blk.hash()) {
  179|      0|                break;
  180|      0|            }
  181|      0|
  182|      0|            let inserted = self.insert(tx, &blk);
  183|      0|
  184|      0|            // If the block was not inserted, we already have it in the backlog
  185|      0|            if !inserted {
  186|      0|                break;
  187|      0|            }
  188|      0|
  189|      0|            tx.refresh_if_needed();
  190|      0|
  191|      0|            block = self
  192|      0|                .backlog_impl
  193|      0|                .ledger
  194|      0|                .any()
  195|      0|                .get_block(tx, &blk.previous());
  196|       |        }
  197|      0|    }
  198|       |
  199|      0|    pub fn insert(&self, tx: &LmdbReadTransaction, block: &SavedBlock) -> bool {
  200|      0|        let (priority_balance, priority_timestamp) =
  201|      0|            self.backlog_impl.ledger.block_priority(tx, block);
  202|      0|        let bucket_index = self.bucketing.bucket_index(priority_balance);
  203|      0|
  204|      0|        self.backlog_impl
  205|      0|            .mutex
  206|      0|            .lock()
  207|      0|            .unwrap()
  208|      0|            .index
  209|      0|            .insert(BacklogEntry {
  210|      0|                hash: block.hash(),
  211|      0|                account: block.account(),
  212|      0|                bucket_index,
  213|      0|                priority: priority_timestamp,
  214|      0|            })
  215|      0|    }
  216|       |
  217|      0|    pub fn container_info(&self) -> ContainerInfo {
  218|      0|        let guard = self.backlog_impl.mutex.lock().unwrap();
  219|      0|        ContainerInfo::builder()
  220|      0|            .leaf("backlog", guard.index.len(), 0)
  221|      0|            .node("index", guard.index.container_info())
  222|      0|            .finish()
  223|      0|    }
  224|       |}
  225|       |
  226|       |impl Drop for BoundedBacklog {
  227|      3|    fn drop(&mut self) {
  228|      3|        // Thread must be stopped before destruction
  229|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  230|      3|        debug_assert!(self.scan_thread.lock().unwrap().is_none());
  231|      3|    }
  232|       |}
  233|       |
  234|       |struct BoundedBacklogImpl {
  235|       |    mutex: Mutex<BacklogData>,
  236|       |    condition: Condvar,
  237|       |    config: BoundedBacklogConfig,
  238|       |    stats: Arc<Stats>,
  239|       |    ledger: Arc<Ledger>,
  240|       |    block_processor: Arc<BlockProcessor>,
  241|       |    can_rollback: RwLock<Box<dyn Fn(&BlockHash) -> bool + Send + Sync>>,
  242|       |}
  243|       |
  244|       |impl BoundedBacklogImpl {
  245|      3|    fn run(&self) {
  246|      3|        let mut guard = self.mutex.lock().unwrap();
  247|      3|        while !guard.stopped {
  248|      3|            guard = self
  249|      3|                .condition
  250|      6|                .wait_timeout_while(guard, Duration::from_secs(1), |i| {
  251|      6|                    !i.stopped && !i.predicate()
                                                ^3
  252|      6|                })
  253|      3|                .unwrap()
  254|      3|                .0;
  255|      3|
  256|      3|            if guard.stopped {
  257|      3|                return;
  258|      0|            }
  259|      0|
  260|      0|            // Wait until all notification about the previous rollbacks are processed
  261|      0|            if self.block_processor.wait() {
  262|      0|                self.stats
  263|      0|                    .inc(StatType::BoundedBacklog, DetailType::Cooldown);
  264|      0|            }
  265|       |
  266|      0|            self.stats.inc(StatType::BoundedBacklog, DetailType::Loop);
  267|      0|
  268|      0|            // Calculate the number of targets to rollback
  269|      0|            let backlog = self.ledger.backlog_count() as usize;
  270|       |
  271|      0|            let target_count = if backlog > self.config.max_backlog {
  272|      0|                backlog - self.config.max_backlog
  273|       |            } else {
  274|      0|                0
  275|       |            };
  276|       |
  277|      0|            let targets = guard.gather_targets(
  278|      0|                min(target_count, self.config.batch_size),
  279|      0|                &*self.can_rollback.read().unwrap(),
  280|      0|            );
  281|      0|
  282|      0|            if !targets.is_empty() {
  283|      0|                drop(guard);
  284|      0|                self.stats.add(
  285|      0|                    StatType::BoundedBacklog,
  286|      0|                    DetailType::GatheredTargets,
  287|      0|                    targets.len() as u64,
  288|      0|                );
  289|      0|                let processed = self
  290|      0|                    .block_processor
  291|      0|                    .roll_back_blocking(targets, target_count);
  292|      0|                guard = self.mutex.lock().unwrap();
  293|       |
  294|       |                // Erase rolled back blocks from the index
  295|      0|                for hash in &processed {
  296|      0|                    guard.index.erase_hash(hash);
  297|      0|                }
  298|      0|            } else {
  299|      0|                // Cooldown, this should not happen in normal operation
  300|      0|                self.stats
  301|      0|                    .inc(StatType::BoundedBacklog, DetailType::NoTargets);
  302|      0|                guard = self
  303|      0|                    .condition
  304|      0|                    .wait_timeout_while(guard, Duration::from_millis(100), |i| !i.stopped)
  305|      0|                    .unwrap()
  306|      0|                    .0;
  307|      0|            }
  308|       |        }
  309|      3|    }
  310|       |
  311|      3|    fn run_scan(&self) {
  312|      3|        let mut guard = self.mutex.lock().unwrap();
  313|      9|        while !guard.stopped {
  314|      9|            let mut last = BlockHash::zero();
  315|      9|            while !guard.stopped {
  316|       |                //	wait
  317|      9|                while !guard.scan_limiter.should_pass(self.config.batch_size) {
  318|      3|                    guard = self
  319|      3|                        .condition
  320|      3|                        .wait_timeout(guard, Duration::from_millis(100))
  321|      3|                        .unwrap()
  322|      3|                        .0;
  323|      3|                    if guard.stopped {
  324|      3|                        return;
  325|      0|                    }
  326|       |                }
  327|       |
  328|      6|                self.stats
  329|      6|                    .inc(StatType::BoundedBacklog, DetailType::LoopScan);
  330|      6|
  331|      6|                let batch = guard.index.next(&last, self.config.batch_size);
  332|      6|                // If batch is empty, we iterated over all accounts in the index
  333|      6|                if batch.is_empty() {
  334|      6|                    break;
  335|      0|                }
  336|      0|
  337|      0|                drop(guard);
  338|      0|                {
  339|      0|                    let tx = self.ledger.read_txn();
  340|      0|                    for hash in batch {
  341|      0|                        self.stats
  342|      0|                            .inc(StatType::BoundedBacklog, DetailType::Scanned);
  343|      0|                        self.update(&tx, &hash);
  344|      0|                        last = hash;
  345|      0|                    }
  346|       |                }
  347|      0|                guard = self.mutex.lock().unwrap();
  348|       |            }
  349|       |        }
  350|      3|    }
  351|       |
  352|      0|    fn update(&self, tx: &LmdbReadTransaction, hash: &BlockHash) {
  353|      0|        // Erase if the block is either confirmed or missing
  354|      0|        if !self.ledger.unconfirmed_exists(tx, hash) {
  355|      0|            self.mutex.lock().unwrap().index.erase_hash(hash);
  356|      0|        }
  357|      0|    }
  358|       |}
  359|       |
  360|       |struct BacklogData {
  361|       |    stopped: bool,
  362|       |    index: BacklogIndex,
  363|       |    ledger: Arc<Ledger>,
  364|       |    config: BoundedBacklogConfig,
  365|       |    bucket_count: usize,
  366|       |    scan_limiter: RateLimiter,
  367|       |}
  368|       |
  369|       |impl BacklogData {
  370|      3|    fn predicate(&self) -> bool {
  371|      3|        // Both ledger and tracked backlog must be over the threshold
  372|      3|        self.ledger.backlog_count() as usize > self.config.max_backlog
  373|      0|            && self.index.len() > self.config.max_backlog
  374|      3|    }
  375|       |
  376|      0|    fn gather_targets(
  377|      0|        &self,
  378|      0|        max_count: usize,
  379|      0|        can_rollback: impl Fn(&BlockHash) -> bool,
  380|      0|    ) -> Vec<BlockHash> {
  381|      0|        let mut targets = Vec::new();
  382|       |
  383|       |        // Start rolling back from lowest index buckets first
  384|      0|        for bucket in 0..self.bucket_count {
  385|       |            // Only start rolling back if the bucket is over the threshold of unconfirmed blocks
  386|      0|            if self.index.len_of_bucket(bucket) > self.bucket_threshold() {
  387|      0|                let count = min(max_count, self.config.batch_size);
  388|      0|                let top = self.index.top(bucket, count, |hash| {
  389|      0|                    // Only rollback if the block is not being used by the node
  390|      0|                    can_rollback(hash)
  391|      0|                });
  392|      0|                targets.extend(top);
  393|      0|            }
  394|       |        }
  395|      0|        targets
  396|      0|    }
  397|       |
  398|      0|    fn bucket_threshold(&self) -> usize {
  399|      0|        self.config.max_backlog / self.bucket_count
  400|      0|    }
  401|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/ledger_notifications.rs:
    1|       |use super::BlockContext;
    2|       |use rsnano_core::{QualifiedRoot, SavedBlock};
    3|       |use rsnano_ledger::BlockStatus;
    4|       |use std::{
    5|       |    collections::VecDeque,
    6|       |    sync::{
    7|       |        atomic::{AtomicBool, Ordering},
    8|       |        Arc, Condvar, Mutex, RwLock,
    9|       |    },
   10|       |    thread::JoinHandle,
   11|       |};
   12|       |
   13|       |#[derive(Clone)]
   14|       |pub struct LedgerNotifications {
   15|       |    callbacks: Arc<RwLock<Callbacks>>,
   16|       |}
   17|       |
   18|       |impl LedgerNotifications {
   19|      9|    pub(crate) fn new() -> (Self, LedgerNotifier) {
   20|      9|        let callbacks = Arc::new(RwLock::new(Callbacks::default()));
   21|      9|        let notifier = LedgerNotifier {
   22|      9|            callbacks: callbacks.clone(),
   23|      9|        };
   24|      9|        let notifications = Self { callbacks };
   25|      9|        (notifications, notifier)
   26|      9|    }
   27|       |
   28|       |    #[allow(dead_code)]
   29|      0|    pub fn on_block_processed(
   30|      0|        &self,
   31|      0|        observer: Box<dyn Fn(BlockStatus, &BlockContext) + Send + Sync>,
   32|      0|    ) {
   33|      0|        self.callbacks
   34|      0|            .write()
   35|      0|            .unwrap()
   36|      0|            .block_processed
   37|      0|            .push(observer);
   38|      0|    }
   39|       |
   40|       |    /// All processed blocks including forks, rejected etc
   41|     21|    pub fn on_blocks_processed(
   42|     21|        &self,
   43|     21|        observer: Box<dyn Fn(&[(BlockStatus, Arc<BlockContext>)]) + Send + Sync>,
   44|     21|    ) {
   45|     21|        self.callbacks
   46|     21|            .write()
   47|     21|            .unwrap()
   48|     21|            .batch_processed
   49|     21|            .push(observer);
   50|     21|    }
   51|       |
   52|       |    /// Rolled back blocks <rolled back block, root of rollback>
   53|     12|    pub fn on_blocks_rolled_back(
   54|     12|        &self,
   55|     12|        callback: impl Fn(&[SavedBlock], QualifiedRoot) + Send + Sync + 'static,
   56|     12|    ) {
   57|     12|        self.callbacks
   58|     12|            .write()
   59|     12|            .unwrap()
   60|     12|            .rollback_observers
   61|     12|            .push(Box::new(callback));
   62|     12|    }
   63|       |}
   64|       |
   65|       |#[derive(Default)]
   66|       |struct Callbacks {
   67|       |    block_processed: Vec<Box<dyn Fn(BlockStatus, &BlockContext) + Send + Sync>>,
   68|       |    batch_processed: Vec<Box<dyn Fn(&[(BlockStatus, Arc<BlockContext>)]) + Send + Sync>>,
   69|       |    rollback_observers: Vec<Box<dyn Fn(&[SavedBlock], QualifiedRoot) + Send + Sync>>,
   70|       |}
   71|       |
   72|       |/// publishes ledger notifications
   73|       |// TODO: Remove clone!
   74|       |#[derive(Clone)]
   75|       |pub(crate) struct LedgerNotifier {
   76|       |    callbacks: Arc<RwLock<Callbacks>>,
   77|       |}
   78|       |
   79|       |impl LedgerNotifier {
   80|      4|    pub fn notify_batch_processed(&self, blocks: &[(BlockStatus, Arc<BlockContext>)]) {
   81|      4|        let guard = self.callbacks.read().unwrap();
   82|      4|        for observer in guard.block_processed.iter() {
                          ^0
   83|      0|            for (status, context) in blocks {
   84|      0|                observer(*status, context);
   85|      0|            }
   86|       |        }
   87|      4|        for observer in guard.batch_processed.iter() {
   88|      4|            observer(&blocks);
   89|      4|        }
   90|      4|    }
   91|       |
   92|      0|    pub fn notify_rollback(&self, rolled_back: &[SavedBlock], root: QualifiedRoot) {
   93|      0|        let guard = self.callbacks.read().unwrap();
   94|      0|        for callback in guard.rollback_observers.iter() {
   95|      0|            callback(rolled_back, root.clone());
   96|      0|        }
   97|      0|    }
   98|       |}
   99|       |
  100|       |pub(crate) enum Event {
  101|       |    BatchProcessed(Vec<(BlockStatus, Arc<BlockContext>)>),
  102|       |    RolledBack(Vec<SavedBlock>, QualifiedRoot),
  103|       |}
  104|       |
  105|       |pub(crate) struct LedgerNotificationQueue {
  106|       |    events: Arc<Mutex<VecDeque<Event>>>,
  107|       |    changed: Condvar,
  108|       |    stopped: AtomicBool,
  109|       |    max_size: usize,
  110|       |}
  111|       |
  112|       |impl LedgerNotificationQueue {
  113|      9|    pub(crate) fn new(max_size: usize) -> (Self, LedgerNotifications, LedgerNotifier) {
  114|      9|        let (notifications, notifier) = LedgerNotifications::new();
  115|      9|        let queue = Self {
  116|      9|            events: Arc::new(Mutex::new(VecDeque::new())),
  117|      9|            changed: Condvar::new(),
  118|      9|            stopped: AtomicBool::new(false),
  119|      9|            max_size,
  120|      9|        };
  121|      9|        (queue, notifications, notifier)
  122|      9|    }
  123|       |
  124|      8|    pub fn pop(&self) -> Option<Event> {
  125|      8|        let mut guard = self.events.lock().unwrap();
  126|      8|        if guard.is_empty() {
  127|      4|            guard = self
  128|      4|                .changed
  129|      6|                .wait_while(guard, |i| {
  130|      6|                    i.is_empty() && !self.stopped.load(Ordering::SeqCst)
  131|      6|                })
  132|      4|                .unwrap();
  133|      4|        }
  134|      8|        if self.stopped.load(Ordering::SeqCst) {
  135|      4|            return None;
  136|      4|        }
  137|      4|        let result = guard.pop_front();
  138|      4|        drop(guard);
  139|      4|        self.changed.notify_all();
  140|      4|        result
  141|      8|    }
  142|       |
  143|       |    /// Returns if waiting happened
  144|      0|    pub fn wait(&self) -> bool {
  145|      0|        let guard = self.events.lock().unwrap();
  146|      0|        let predicate =
  147|      0|            |i: &VecDeque<Event>| i.len() >= self.max_size && !self.stopped.load(Ordering::SeqCst);
  148|       |
  149|      0|        if predicate(&guard) {
  150|      0|            return false;
  151|      0|        }
  152|      0|        drop(self.changed.wait_while(guard, |g| predicate(g)).unwrap());
  153|      0|        true
  154|      0|    }
  155|       |
  156|       |    #[allow(dead_code)]
  157|      4|    pub fn len(&self) -> usize {
  158|      4|        self.events.lock().unwrap().len()
  159|      4|    }
  160|       |
  161|      5|    pub fn notify_batch_processed(&self, blocks: Vec<(BlockStatus, Arc<BlockContext>)>) {
  162|      5|        self.push_event(Event::BatchProcessed(blocks));
  163|      5|    }
  164|       |
  165|      1|    pub fn notify_rollback(&self, rolled_back: Vec<SavedBlock>, root: QualifiedRoot) {
  166|      1|        self.push_event(Event::RolledBack(rolled_back, root));
  167|      1|    }
  168|       |
  169|      6|    fn push_event(&self, event: Event) {
  170|      6|        if self.stopped.load(Ordering::SeqCst) {
  171|      0|            return;
  172|      6|        }
  173|      6|        self.events.lock().unwrap().push_back(event);
  174|      6|        self.changed.notify_one();
  175|      6|    }
  176|       |
  177|      4|    fn stop(&self) {
  178|      4|        {
  179|      4|            let mut guard = self.events.lock().unwrap();
  180|      4|            guard.clear();
  181|      4|            self.stopped.store(true, Ordering::SeqCst);
  182|      4|        }
  183|      4|        self.changed.notify_one();
  184|      4|    }
  185|       |}
  186|       |
  187|       |pub(crate) struct LedgerNotificationProcessor {
  188|       |    queue: Arc<LedgerNotificationQueue>,
  189|       |    notifier: LedgerNotifier,
  190|       |}
  191|       |
  192|       |impl LedgerNotificationProcessor {
  193|      5|    pub(crate) fn new(
  194|      5|        max_queue_len: usize,
  195|      5|    ) -> (Self, Arc<LedgerNotificationQueue>, LedgerNotifications) {
  196|      5|        let (queue, notifications, notifier) = LedgerNotificationQueue::new(max_queue_len);
  197|      5|        let queue = Arc::new(queue);
  198|      5|        let processor = Self {
  199|      5|            queue: queue.clone(),
  200|      5|            notifier,
  201|      5|        };
  202|      5|        (processor, queue, notifications)
  203|      5|    }
  204|       |
  205|      8|    pub fn process_one(&self) -> bool {
  206|      8|        let Some(event) = self.queue.pop() else {
                               ^4
  207|      4|            return false;
  208|       |        };
  209|       |
  210|      4|        match event {
  211|      4|            Event::BatchProcessed(batch) => self.notifier.notify_batch_processed(&batch),
  212|      0|            Event::RolledBack(rolled_back, root) => {
  213|      0|                self.notifier.notify_rollback(&rolled_back, root)
  214|       |            }
  215|       |        }
  216|       |
  217|      4|        true
  218|      8|    }
  219|       |
  220|      4|    pub fn stop(&self) {
  221|      4|        self.queue.stop();
  222|      4|    }
  223|       |}
  224|       |
  225|       |pub(crate) struct LedgerNotificationThread {
  226|       |    processor: Arc<LedgerNotificationProcessor>,
  227|       |    handle: Option<JoinHandle<()>>,
  228|       |}
  229|       |
  230|       |impl LedgerNotificationThread {
  231|      4|    pub(crate) fn new(
  232|      4|        max_queue_len: usize,
  233|      4|    ) -> (Self, Arc<LedgerNotificationQueue>, LedgerNotifications) {
  234|      4|        let (processor, queue, notifications) = LedgerNotificationProcessor::new(max_queue_len);
  235|      4|        let thread = Self {
  236|      4|            processor: Arc::new(processor),
  237|      4|            handle: None,
  238|      4|        };
  239|      4|        (thread, queue, notifications)
  240|      4|    }
  241|       |
  242|      4|    pub fn start(&mut self) {
  243|      4|        let processor = self.processor.clone();
  244|      4|        self.handle = Some(
  245|      4|            std::thread::Builder::new()
  246|      4|                .name("Ledger notif".to_owned())
  247|      7|                .spawn(move || while processor.process_one() {})
                                             ^4                            ^3^4
  248|      4|                .unwrap(),
  249|      4|        );
  250|      4|    }
  251|       |
  252|      7|    pub fn stop(&mut self) {
  253|      7|        let Some(handle) = self.handle.take() else {
                               ^4
  254|      3|            return;
  255|       |        };
  256|      4|        self.processor.stop();
  257|      4|        handle.join().unwrap();
  258|      7|    }
  259|       |}
  260|       |
  261|       |impl Drop for LedgerNotificationThread {
  262|      4|    fn drop(&mut self) {
  263|      4|        self.stop()
  264|      4|    }
  265|       |}
  266|       |
  267|       |#[cfg(test)]
  268|       |mod tests {
  269|       |    use super::*;
  270|       |    use std::{
  271|       |        sync::{
  272|       |            atomic::{AtomicBool, Ordering},
  273|       |            Condvar,
  274|       |        },
  275|       |        time::Duration,
  276|       |    };
  277|       |
  278|       |    #[test]
  279|      1|    fn empty() {
  280|      1|        let (queue, _, _) = LedgerNotificationQueue::new(8);
  281|      1|        assert_eq!(queue.len(), 0);
  282|      1|    }
  283|       |
  284|       |    #[test]
  285|      1|    fn enqueue_batch_processed() {
  286|      1|        let (queue, notifications, _) = LedgerNotificationQueue::new(8);
  287|      1|        let notified = Arc::new(AtomicBool::new(false));
  288|      1|        let notified2 = notified.clone();
  289|      1|        notifications.on_blocks_processed(Box::new(move |_| {
  290|      0|            notified2.store(true, Ordering::SeqCst);
  291|      1|        }));
  292|      1|
  293|      1|        queue.notify_batch_processed(vec![]);
  294|      1|
  295|      1|        assert_eq!(queue.len(), 1);
  296|      1|        assert_eq!(notified.load(Ordering::SeqCst), false);
  297|      1|    }
  298|       |
  299|       |    #[test]
  300|      1|    fn enqueue_rolled_back() {
  301|      1|        let (queue, _, _) = LedgerNotificationQueue::new(8);
  302|      1|        queue.notify_rollback(vec![], QualifiedRoot::new_test_instance());
  303|      1|        assert_eq!(queue.len(), 1);
  304|      1|    }
  305|       |
  306|       |    #[test]
  307|      1|    fn process_event() {
  308|      1|        let (processor, queue, notifications) = LedgerNotificationProcessor::new(8);
  309|      1|
  310|      1|        let notified = Arc::new(AtomicBool::new(false));
  311|      1|        let notified2 = notified.clone();
  312|      1|        notifications.on_blocks_processed(Box::new(move |_| {
  313|      1|            notified2.store(true, Ordering::SeqCst);
  314|      1|        }));
  315|      1|
  316|      1|        queue.notify_batch_processed(vec![]);
  317|      1|
  318|      1|        processor.process_one();
  319|      1|
  320|      1|        assert_eq!(queue.len(), 0, "queue wasn't drained");
                                                 ^0
  321|      1|        assert!(
  322|      1|            notified.load(Ordering::SeqCst),
  323|      0|            "event handler wasn't called"
  324|       |        );
  325|      1|    }
  326|       |
  327|       |    #[test]
  328|      1|    fn notification_thread() {
  329|      1|        let (mut thread, queue, notifications) = LedgerNotificationThread::new(8);
  330|      1|
  331|      1|        let notified = Arc::new((Condvar::new(), Mutex::new(0)));
  332|      1|        let notified2 = notified.clone();
  333|      3|        notifications.on_blocks_processed(Box::new(move |_| {
  334|      3|            *notified2.1.lock().unwrap() += 1;
  335|      3|            notified2.0.notify_one();
  336|      3|        }));
  337|      1|
  338|      1|        queue.notify_batch_processed(vec![]);
  339|      1|
  340|      1|        thread.start();
  341|      1|
  342|      1|        queue.notify_batch_processed(vec![]);
  343|      1|        queue.notify_batch_processed(vec![]);
  344|      1|
  345|      1|        let guard = notified.1.lock().unwrap();
  346|      1|        let result = notified
  347|      1|            .0
  348|      2|            .wait_timeout_while(guard, Duration::from_secs(5), |i| *i < 3)
  349|      1|            .unwrap()
  350|      1|            .1;
  351|      1|
  352|      1|        assert_eq!(*notified.1.lock().unwrap(), 3);
  353|      1|        assert!(!result.timed_out());
  354|      1|    }
  355|       |}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/local_block_broadcaster.rs:
    1|       |use super::{BlockSource, LedgerNotifications};
    2|       |use crate::{
    3|       |    cementation::ConfirmingSet,
    4|       |    stats::{DetailType, Direction, StatType, Stats},
    5|       |    transport::MessageFlooder,
    6|       |};
    7|       |use rsnano_core::{utils::ContainerInfo, Block, BlockHash, Networks};
    8|       |use rsnano_ledger::{BlockStatus, Ledger};
    9|       |use rsnano_messages::{Message, Publish};
   10|       |use rsnano_network::{bandwidth_limiter::RateLimiter, TrafficType};
   11|       |use std::{
   12|       |    cmp::min,
   13|       |    collections::{BTreeMap, HashMap, HashSet, VecDeque},
   14|       |    mem::size_of,
   15|       |    sync::{Arc, Condvar, Mutex, MutexGuard},
   16|       |    thread::JoinHandle,
   17|       |    time::{Duration, Instant},
   18|       |};
   19|       |use tracing::debug;
   20|       |
   21|       |#[derive(Clone, Debug, PartialEq)]
   22|       |pub struct LocalBlockBroadcasterConfig {
   23|       |    pub max_size: usize,
   24|       |    pub rebroadcast_interval: Duration,
   25|       |    pub max_rebroadcast_interval: Duration,
   26|       |    pub broadcast_rate_limit: usize,
   27|       |    pub broadcast_rate_burst_ratio: f64,
   28|       |    pub cleanup_interval: Duration,
   29|       |}
   30|       |
   31|       |impl LocalBlockBroadcasterConfig {
   32|      9|    pub fn new(network: Networks) -> Self {
   33|      9|        match network {
   34|      5|            Networks::NanoDevNetwork => Self::default_for_dev_network(),
   35|      4|            _ => Default::default(),
   36|       |        }
   37|      9|    }
   38|       |
   39|      5|    fn default_for_dev_network() -> Self {
   40|      5|        Self {
   41|      5|            rebroadcast_interval: Duration::from_secs(1),
   42|      5|            cleanup_interval: Duration::from_secs(1),
   43|      5|            ..Default::default()
   44|      5|        }
   45|      5|    }
   46|       |}
   47|       |
   48|       |impl Default for LocalBlockBroadcasterConfig {
   49|      9|    fn default() -> Self {
   50|      9|        Self {
   51|      9|            max_size: 1024 * 8,
   52|      9|            rebroadcast_interval: Duration::from_secs(3),
   53|      9|            max_rebroadcast_interval: Duration::from_secs(60),
   54|      9|            broadcast_rate_limit: 32,
   55|      9|            broadcast_rate_burst_ratio: 3.0,
   56|      9|            cleanup_interval: Duration::from_secs(60),
   57|      9|        }
   58|      9|    }
   59|       |}
   60|       |
   61|       |///  Broadcasts blocks to the network
   62|       |/// Tracks local blocks for more aggressive propagation
   63|       |pub struct LocalBlockBroadcaster {
   64|       |    config: LocalBlockBroadcasterConfig,
   65|       |    notifications: LedgerNotifications,
   66|       |    stats: Arc<Stats>,
   67|       |    ledger: Arc<Ledger>,
   68|       |    confirming_set: Arc<ConfirmingSet>,
   69|       |    thread: Mutex<Option<JoinHandle<()>>>,
   70|       |    enabled: bool,
   71|       |    mutex: Mutex<LocalBlockBroadcasterData>,
   72|       |    condition: Condvar,
   73|       |    limiter: RateLimiter,
   74|       |    message_flooder: Mutex<MessageFlooder>,
   75|       |}
   76|       |
   77|       |impl LocalBlockBroadcaster {
   78|      3|    pub(crate) fn new(
   79|      3|        config: LocalBlockBroadcasterConfig,
   80|      3|        notifications: LedgerNotifications,
   81|      3|        stats: Arc<Stats>,
   82|      3|        ledger: Arc<Ledger>,
   83|      3|        confirming_set: Arc<ConfirmingSet>,
   84|      3|        message_flooder: MessageFlooder,
   85|      3|        enabled: bool,
   86|      3|    ) -> Self {
   87|      3|        Self {
   88|      3|            limiter: RateLimiter::with_burst_ratio(
   89|      3|                config.broadcast_rate_limit,
   90|      3|                config.broadcast_rate_burst_ratio,
   91|      3|            ),
   92|      3|            config,
   93|      3|            notifications,
   94|      3|            stats,
   95|      3|            ledger,
   96|      3|            confirming_set,
   97|      3|            thread: Mutex::new(None),
   98|      3|            enabled,
   99|      3|            mutex: Mutex::new(LocalBlockBroadcasterData {
  100|      3|                stopped: false,
  101|      3|                local_blocks: Default::default(),
  102|      3|                cleanup_interval: Instant::now(),
  103|      3|            }),
  104|      3|            condition: Condvar::new(),
  105|      3|            message_flooder: Mutex::new(message_flooder),
  106|      3|        }
  107|      3|    }
  108|       |
  109|      3|    pub fn stop(&self) {
  110|      3|        self.mutex.lock().unwrap().stopped = true;
  111|      3|        self.condition.notify_all();
  112|      3|        let handle = self.thread.lock().unwrap().take();
  113|      3|        if let Some(handle) = handle {
  114|      3|            handle.join().unwrap();
  115|      3|        }
                       ^0
  116|      3|    }
  117|       |
  118|      0|    pub fn len(&self) -> usize {
  119|      0|        self.mutex.lock().unwrap().local_blocks.len()
  120|      0|    }
  121|       |
  122|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
  123|      0|        self.mutex.lock().unwrap().local_blocks.contains(hash)
  124|      0|    }
  125|       |
  126|      3|    fn run(&self) {
  127|      3|        let mut guard = self.mutex.lock().unwrap();
  128|      6|        while !guard.stopped {
  129|      3|            guard = self
  130|      3|                .condition
  131|      3|                .wait_timeout(guard, Duration::from_secs(1))
  132|      3|                .unwrap()
  133|      3|                .0;
  134|      3|
  135|      3|            if !guard.stopped && !guard.local_blocks.is_empty() {
                                               ^0
  136|      0|                self.stats
  137|      0|                    .inc(StatType::LocalBlockBroadcaster, DetailType::Loop);
  138|      0|
  139|      0|                if guard.cleanup_interval.elapsed() >= self.config.cleanup_interval {
  140|      0|                    guard.cleanup_interval = Instant::now();
  141|      0|                    guard = self.cleanup(guard);
  142|      0|                }
  143|       |
  144|      0|                guard = self.run_broadcasts(guard);
  145|      3|            }
  146|       |        }
  147|      3|    }
  148|       |
  149|      0|    fn rebroadcast_interval(&self, rebroadcasts: u32) -> Duration {
  150|      0|        min(
  151|      0|            self.config.rebroadcast_interval * rebroadcasts,
  152|      0|            self.config.max_rebroadcast_interval,
  153|      0|        )
  154|      0|    }
  155|       |
  156|      0|    fn run_broadcasts<'a>(
  157|      0|        &'a self,
  158|      0|        mut guard: MutexGuard<'a, LocalBlockBroadcasterData>,
  159|      0|    ) -> MutexGuard<'a, LocalBlockBroadcasterData> {
  160|      0|        let mut to_broadcast = Vec::new();
  161|       |
  162|       |        // Iterate blocks with next_broadcast <= now
  163|      0|        for entry in guard.local_blocks.iter_by_next_broadcast(Instant::now()) {
  164|      0|            to_broadcast.push(entry.clone());
  165|      0|        }
  166|       |
  167|       |        // Modify multi index container outside of the loop to avoid invalidating iterators
  168|      0|        for entry in &to_broadcast {
  169|      0|            guard.local_blocks.modify_entry(&entry.block.hash(), |i| {
  170|      0|                i.rebroadcasts += 1;
  171|      0|                let now = Instant::now();
  172|      0|                i.last_broadcast = Some(now);
  173|      0|                i.next_broadcast = now + self.rebroadcast_interval(i.rebroadcasts);
  174|      0|            });
  175|      0|        }
  176|       |
  177|      0|        drop(guard);
  178|       |
  179|      0|        for entry in to_broadcast {
  180|      0|            while !self.limiter.should_pass(1) {
  181|      0|                guard = self.mutex.lock().unwrap();
  182|      0|                guard = self
  183|      0|                    .condition
  184|      0|                    .wait_timeout_while(guard, Duration::from_millis(100), |g| !g.stopped)
  185|      0|                    .unwrap()
  186|      0|                    .0;
  187|      0|                if guard.stopped {
  188|      0|                    return guard;
  189|      0|                }
  190|       |            }
  191|       |
  192|      0|            debug!(
  193|      0|                "Broadcasting block: {} (rebroadcasts so far: {})",
  194|      0|                entry.block.hash(),
  195|      0|                entry.rebroadcasts + 1,
  196|       |            );
  197|       |
  198|      0|            self.stats.inc_dir(
  199|      0|                StatType::LocalBlockBroadcaster,
  200|      0|                DetailType::Broadcast,
  201|      0|                Direction::Out,
  202|      0|            );
  203|      0|
  204|      0|            self.flood_block_initial((*entry.block).clone());
  205|       |        }
  206|       |
  207|      0|        self.mutex.lock().unwrap()
  208|      0|    }
  209|       |
  210|      0|    fn cleanup<'a>(
  211|      0|        &'a self,
  212|      0|        mut data: MutexGuard<'a, LocalBlockBroadcasterData>,
  213|      0|    ) -> MutexGuard<'a, LocalBlockBroadcasterData> {
  214|      0|        // Copy the local blocks to avoid holding the mutex during IO
  215|      0|        let local_blocks_copy = data.local_blocks.all_entries();
  216|      0|        drop(data);
  217|      0|        let mut already_confirmed = HashSet::new();
  218|      0|        {
  219|      0|            let tx = self.ledger.read_txn();
  220|      0|            for entry in local_blocks_copy {
  221|       |                // This block has never been broadcasted, keep it so it's broadcasted at least once
  222|      0|                if entry.last_broadcast.is_none() {
  223|      0|                    continue;
  224|      0|                }
  225|      0|
  226|      0|                if self.confirming_set.contains(&entry.block.hash())
  227|      0|                    || self
  228|      0|                        .ledger
  229|      0|                        .confirmed()
  230|      0|                        .block_exists_or_pruned(&tx, &entry.block.hash())
  231|      0|                {
  232|      0|                    self.stats.inc(
  233|      0|                        StatType::LocalBlockBroadcaster,
  234|      0|                        DetailType::AlreadyConfirmed,
  235|      0|                    );
  236|      0|                    already_confirmed.insert(entry.block.hash());
  237|      0|                }
  238|       |            }
  239|       |        }
  240|       |
  241|      0|        data = self.mutex.lock().unwrap();
  242|      0|        // Erase blocks that have been confirmed
  243|      0|
  244|      0|        data.local_blocks
  245|      0|            .retain(|e| !already_confirmed.contains(&e.block.hash()));
  246|      0|
  247|      0|        data
  248|      0|    }
  249|       |
  250|      0|    pub fn container_info(&self) -> ContainerInfo {
  251|      0|        let guard = self.mutex.lock().unwrap();
  252|      0|        [(
  253|      0|            "local",
  254|      0|            guard.local_blocks.len(),
  255|      0|            OrderedLocals::ELEMENT_SIZE,
  256|      0|        )]
  257|      0|        .into()
  258|      0|    }
  259|       |
  260|       |    /// Flood block to all PRs and a random selection of non-PRs
  261|      0|    pub fn flood_block_initial(&self, block: Block) {
  262|      0|        let message = Message::Publish(Publish::new_from_originator(block));
  263|      0|        let mut publisher = self.message_flooder.lock().unwrap();
  264|      0|        publisher.flood_prs_and_some_non_prs(&message, TrafficType::BlockBroadcastInitial, 1.0);
  265|      0|    }
  266|       |}
  267|       |
  268|       |impl Drop for LocalBlockBroadcaster {
  269|      3|    fn drop(&mut self) {
  270|      3|        // Thread must be stopped before destruction
  271|      3|        debug_assert!(self.thread.lock().unwrap().is_none())
  272|      3|    }
  273|       |}
  274|       |
  275|       |pub trait LocalBlockBroadcasterExt {
  276|       |    fn initialize(&self);
  277|       |    fn start(&self);
  278|       |}
  279|       |
  280|       |impl LocalBlockBroadcasterExt for Arc<LocalBlockBroadcaster> {
  281|      3|    fn initialize(&self) {
  282|      3|        if !self.enabled {
  283|      0|            return;
  284|      3|        }
  285|      3|
  286|      3|        let self_w = Arc::downgrade(self);
  287|      3|        self.notifications
  288|      3|            .on_blocks_processed(Box::new(move |batch| {
                                                                     ^0
  289|      0|                let Some(self_l) = self_w.upgrade() else {
  290|      0|                    return;
  291|       |                };
  292|      0|                let mut should_notify = false;
  293|      0|                for (result, context) in batch {
  294|       |                    // Only rebroadcast local blocks that were successfully processed (no forks or gaps)
  295|      0|                    if *result == BlockStatus::Progress && context.source == BlockSource::Local {
  296|      0|                        let mut guard = self_l.mutex.lock().unwrap();
  297|      0|                        guard.local_blocks.push_back(LocalEntry {
  298|      0|                            block: Arc::new(context.block.lock().unwrap().clone()),
  299|      0|                            last_broadcast: None,
  300|      0|                            next_broadcast: Instant::now(),
  301|      0|                            rebroadcasts: 0,
  302|      0|                        });
  303|      0|                        self_l
  304|      0|                            .stats
  305|      0|                            .inc(StatType::LocalBlockBroadcaster, DetailType::Insert);
  306|       |
  307|       |                        // Erase oldest blocks if the queue gets too big
  308|      0|                        while guard.local_blocks.len() > self_l.config.max_size {
  309|      0|                            self_l
  310|      0|                                .stats
  311|      0|                                .inc(StatType::LocalBlockBroadcaster, DetailType::EraseOldest);
  312|      0|                            guard.local_blocks.pop_front();
  313|      0|                        }
  314|       |
  315|      0|                        should_notify = true;
  316|      0|                    }
  317|       |                }
  318|      0|                if should_notify {
  319|      0|                    self_l.condition.notify_all();
  320|      0|                }
  321|      3|            }));
                          ^0
  322|      3|
  323|      3|        let self_w = Arc::downgrade(self);
  324|      3|        self.notifications
  325|      3|            .on_blocks_rolled_back(move |blocks, _rollback_root| {
                                                                               ^0
  326|      0|                let Some(self_l) = self_w.upgrade() else {
  327|      0|                    return;
  328|       |                };
  329|       |
  330|      0|                let mut guard = self_l.mutex.lock().unwrap();
  331|      0|                for block in blocks {
  332|      0|                    if guard.local_blocks.remove(&block.hash()) {
  333|      0|                        self_l.stats.inc_dir(
  334|      0|                            StatType::LocalBlockBroadcaster,
  335|      0|                            DetailType::Rollback,
  336|      0|                            Direction::In,
  337|      0|                        );
  338|      0|                    }
  339|       |                }
  340|      3|            });
                          ^0
  341|      3|
  342|      3|        let self_w = Arc::downgrade(self);
  343|      3|        self.confirming_set.on_cemented(Box::new(move |block| {
                                                                            ^0
  344|      0|            let Some(self_l) = self_w.upgrade() else {
  345|      0|                return;
  346|       |            };
  347|       |
  348|      0|            let mut guard = self_l.mutex.lock().unwrap();
  349|      0|            if guard.local_blocks.remove(&block.hash()) {
  350|      0|                self_l
  351|      0|                    .stats
  352|      0|                    .inc(StatType::LocalBlockBroadcaster, DetailType::Cemented);
  353|      0|            }
  354|      3|        }));
                      ^0
  355|      3|    }
  356|       |
  357|      3|    fn start(&self) {
  358|      3|        if !self.enabled {
  359|      0|            return;
  360|      3|        }
  361|      3|
  362|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  363|      3|        let self_l = Arc::clone(self);
  364|      3|        *self.thread.lock().unwrap() = Some(
  365|      3|            std::thread::Builder::new()
  366|      3|                .name("Local broadcast".to_string())
  367|      3|                .spawn(move || self_l.run())
  368|      3|                .unwrap(),
  369|      3|        );
  370|      3|    }
  371|       |}
  372|       |
  373|       |struct LocalBlockBroadcasterData {
  374|       |    stopped: bool,
  375|       |    local_blocks: OrderedLocals,
  376|       |    cleanup_interval: Instant,
  377|       |}
  378|       |
  379|       |#[derive(Clone)]
  380|       |struct LocalEntry {
  381|       |    block: Arc<Block>,
  382|       |    last_broadcast: Option<Instant>,
  383|       |    next_broadcast: Instant,
  384|       |    rebroadcasts: u32,
  385|       |}
  386|       |
  387|       |#[derive(Default)]
  388|       |struct OrderedLocals {
  389|       |    by_hash: HashMap<BlockHash, LocalEntry>,
  390|       |    sequenced: VecDeque<BlockHash>,
  391|       |    by_next_broadcast: BTreeMap<Instant, Vec<BlockHash>>,
  392|       |}
  393|       |
  394|       |impl OrderedLocals {
  395|       |    pub const ELEMENT_SIZE: usize = size_of::<LocalEntry>() + size_of::<BlockHash>() * 2;
  396|      0|    fn len(&self) -> usize {
  397|      0|        self.sequenced.len()
  398|      0|    }
  399|       |
  400|      0|    fn is_empty(&self) -> bool {
  401|      0|        self.sequenced.is_empty()
  402|      0|    }
  403|       |
  404|      0|    fn contains(&self, hash: &BlockHash) -> bool {
  405|      0|        self.by_hash.contains_key(hash)
  406|      0|    }
  407|       |
  408|      0|    fn push_back(&mut self, entry: LocalEntry) {
  409|      0|        let hash = entry.block.hash();
  410|      0|        let next_broadcast = entry.next_broadcast;
  411|      0|        if let Some(old) = self.by_hash.insert(entry.block.hash(), entry) {
  412|      0|            self.sequenced.retain(|i| *i != old.block.hash());
  413|      0|        }
  414|      0|        self.sequenced.push_back(hash);
  415|      0|        self.by_next_broadcast
  416|      0|            .entry(next_broadcast)
  417|      0|            .or_default()
  418|      0|            .push(hash);
  419|      0|    }
  420|       |
  421|      0|    fn iter_by_next_broadcast(&self, upper_bound: Instant) -> impl Iterator<Item = &LocalEntry> {
  422|      0|        self.by_next_broadcast
  423|      0|            .values()
  424|      0|            .flat_map(|hashes| hashes.iter().map(|h| self.by_hash.get(h).unwrap()))
  425|      0|            .take_while(move |i| i.next_broadcast <= upper_bound)
  426|      0|    }
  427|       |
  428|      0|    fn modify_entry(&mut self, hash: &BlockHash, mut f: impl FnMut(&mut LocalEntry)) {
  429|      0|        if let Some(entry) = self.by_hash.get_mut(hash) {
  430|      0|            let old_next_broadcast = entry.next_broadcast;
  431|      0|            f(entry);
  432|      0|            if entry.next_broadcast != old_next_broadcast {
  433|      0|                remove_by_next_broadcast(&mut self.by_next_broadcast, old_next_broadcast, hash);
  434|      0|                self.by_next_broadcast
  435|      0|                    .entry(entry.next_broadcast)
  436|      0|                    .or_default()
  437|      0|                    .push(*hash);
  438|      0|            }
  439|      0|        }
  440|      0|    }
  441|       |
  442|      0|    fn pop_front(&mut self) -> Option<LocalEntry> {
  443|      0|        let hash = self.sequenced.pop_front()?;
  444|      0|        let entry = self.by_hash.remove(&hash).unwrap();
  445|      0|        remove_by_next_broadcast(&mut self.by_next_broadcast, entry.next_broadcast, &hash);
  446|      0|        Some(entry)
  447|      0|    }
  448|       |
  449|      0|    fn remove(&mut self, hash: &BlockHash) -> bool {
  450|      0|        if let Some(entry) = self.by_hash.remove(hash) {
  451|      0|            self.sequenced.retain(|i| i != hash);
  452|      0|            remove_by_next_broadcast(&mut self.by_next_broadcast, entry.next_broadcast, hash);
  453|      0|            true
  454|       |        } else {
  455|      0|            false
  456|       |        }
  457|      0|    }
  458|       |
  459|      0|    fn retain(&mut self, mut f: impl FnMut(&LocalEntry) -> bool) {
  460|      0|        self.by_hash.retain(|hash, entry| {
  461|      0|            let retain = f(entry);
  462|      0|            if !retain {
  463|      0|                self.sequenced.retain(|i| i != hash);
  464|      0|                remove_by_next_broadcast(&mut self.by_next_broadcast, entry.next_broadcast, hash);
  465|      0|            }
  466|      0|            retain
  467|      0|        });
  468|      0|    }
  469|       |
  470|      0|    fn all_entries(&self) -> Vec<LocalEntry> {
  471|      0|        self.by_hash.values().cloned().collect()
  472|      0|    }
  473|       |}
  474|       |
  475|      0|fn remove_by_next_broadcast(
  476|      0|    map: &mut BTreeMap<Instant, Vec<BlockHash>>,
  477|      0|    next: Instant,
  478|      0|    hash: &BlockHash,
  479|      0|) {
  480|      0|    let mut hashes = map.remove(&next).unwrap();
  481|      0|
  482|      0|    if hashes.len() > 1 {
  483|      0|        hashes.retain(|i| i != hash);
  484|      0|        map.insert(next, hashes);
  485|      0|    }
  486|      0|}

/home/gustav/code/nano/rsnano-node/node/src/block_processing/unchecked_map.rs:
    1|       |use crate::stats::{DetailType, StatType, Stats};
    2|       |use rsnano_core::{utils::ContainerInfo, BlockHash, HashOrAccount, UncheckedInfo, UncheckedKey};
    3|       |use std::{
    4|       |    cmp::Ordering,
    5|       |    collections::{BTreeMap, VecDeque},
    6|       |    mem::size_of,
    7|       |    ops::DerefMut,
    8|       |    sync::{Arc, Condvar, Mutex},
    9|       |    thread::JoinHandle,
   10|       |};
   11|       |
   12|       |pub struct UncheckedMap {
   13|       |    join_handle: Mutex<Option<JoinHandle<()>>>,
   14|       |    thread: Arc<UncheckedMapThread>,
   15|       |    mutable: Arc<Mutex<ThreadMutableData>>,
   16|       |    condition: Arc<Condvar>,
   17|       |    stats: Arc<Stats>,
   18|       |    max_unchecked_blocks: usize,
   19|       |}
   20|       |
   21|       |impl UncheckedMap {
   22|      4|    pub fn new(max_unchecked_blocks: usize, stats: Arc<Stats>, disable_delete: bool) -> Self {
   23|      4|        let mutable = Arc::new(Mutex::new(ThreadMutableData::new()));
   24|      4|        let condition = Arc::new(Condvar::new());
   25|      4|
   26|      4|        let thread = Arc::new(UncheckedMapThread {
   27|      4|            disable_delete,
   28|      4|            mutable: mutable.clone(),
   29|      4|            condition: condition.clone(),
   30|      4|            stats: stats.clone(),
   31|      4|            back_buffer: Mutex::new(VecDeque::new()),
   32|      4|        });
   33|      4|
   34|      4|        Self {
   35|      4|            join_handle: Mutex::new(None),
   36|      4|            thread,
   37|      4|            mutable,
   38|      4|            condition,
   39|      4|            stats,
   40|      4|            max_unchecked_blocks,
   41|      4|        }
   42|      4|    }
   43|       |
   44|      3|    pub fn start(&self) {
   45|      3|        debug_assert!(self.join_handle.lock().unwrap().is_none());
   46|      3|        let thread_clone = Arc::clone(&self.thread);
   47|      3|        *self.join_handle.lock().unwrap() = Some(
   48|      3|            std::thread::Builder::new()
   49|      3|                .name("Unchecked".to_string())
   50|      3|                .spawn(move || {
   51|      3|                    thread_clone.run();
   52|      3|                })
   53|      3|                .unwrap(),
   54|      3|        );
   55|      3|    }
   56|       |
   57|      7|    pub fn stop(&self) {
   58|      7|        self.mutable.lock().unwrap().stopped = true;
   59|      7|        self.condition.notify_all();
   60|      7|        let handle = self.join_handle.lock().unwrap().take();
   61|      7|        if let Some(handle) = handle {
                                  ^3
   62|      3|            handle.join().unwrap();
   63|      4|        }
   64|      7|    }
   65|       |
   66|      0|    pub fn exists(&self, key: &UncheckedKey) -> bool {
   67|      0|        let lock = self.mutable.lock().unwrap();
   68|      0|        lock.entries_container.exists(key)
   69|      0|    }
   70|       |
   71|      0|    pub fn put(&self, dependency: HashOrAccount, info: UncheckedInfo) {
   72|      0|        let mut lock = self.mutable.lock().unwrap();
   73|      0|        let key = UncheckedKey::new(dependency.into(), info.block.hash());
   74|      0|        let inserted = lock.entries_container.insert(Entry::new(key, info));
   75|      0|        if lock.entries_container.len() > self.max_unchecked_blocks {
   76|      0|            lock.entries_container.pop_front();
   77|      0|        }
   78|      0|        if inserted {
   79|      0|            self.stats.inc(StatType::Unchecked, DetailType::Put);
   80|      0|        }
   81|      0|    }
   82|       |
   83|      0|    pub fn get(&self, hash: &HashOrAccount) -> Vec<UncheckedInfo> {
   84|      0|        let lock = self.mutable.lock().unwrap();
   85|      0|        let mut result = Vec::new();
   86|      0|        lock.entries_container.for_each_with_dependency(
   87|      0|            hash,
   88|      0|            |_, info| {
   89|      0|                result.push(info.clone());
   90|      0|            },
   91|      0|            || true,
   92|      0|        );
   93|      0|        result
   94|      0|    }
   95|       |
   96|      0|    pub fn clear(&self) {
   97|      0|        let mut lock = self.mutable.lock().unwrap();
   98|      0|        lock.entries_container.clear();
   99|      0|    }
  100|       |
  101|      0|    pub fn trigger(&self, dependency: &HashOrAccount) {
  102|      0|        let mut lock = self.mutable.lock().unwrap();
  103|      0|        lock.buffer.push_back(*dependency);
  104|      0|        drop(lock);
  105|      0|        self.stats.inc(StatType::Unchecked, DetailType::Trigger);
  106|      0|        self.condition.notify_all(); // Notify run ()
  107|      0|    }
  108|       |
  109|      0|    pub fn remove(&self, key: &UncheckedKey) {
  110|      0|        let mut lock = self.mutable.lock().unwrap();
  111|      0|        lock.entries_container.remove(key);
  112|      0|    }
  113|       |
  114|      3|    pub fn len(&self) -> usize {
  115|      3|        let lock = self.mutable.lock().unwrap();
  116|      3|        lock.entries_container.len()
  117|      3|    }
  118|       |
  119|      0|    pub fn is_empty(&self) -> bool {
  120|      0|        let lock = self.mutable.lock().unwrap();
  121|      0|        lock.entries_container.is_empty()
  122|      0|    }
  123|       |
  124|      0|    pub fn entries_size() -> usize {
  125|      0|        EntriesContainer::entry_size()
  126|      0|    }
  127|       |
  128|      0|    pub fn buffer_count(&self) -> usize {
  129|      0|        let lock = self.mutable.lock().unwrap();
  130|      0|        lock.buffer.len()
  131|      0|    }
  132|       |
  133|      0|    pub fn buffer_entry_size() -> usize {
  134|      0|        size_of::<HashOrAccount>()
  135|      0|    }
  136|       |
  137|      0|    pub fn for_each(
  138|      0|        &self,
  139|      0|        action: impl FnMut(&UncheckedKey, &UncheckedInfo),
  140|      0|        predicate: impl FnMut() -> bool,
  141|      0|    ) {
  142|      0|        let lock = self.mutable.lock().unwrap();
  143|      0|        lock.entries_container.for_each(action, predicate)
  144|      0|    }
  145|       |
  146|      0|    pub fn for_each_with_dependency(
  147|      0|        &self,
  148|      0|        dependency: &HashOrAccount,
  149|      0|        action: impl FnMut(&UncheckedKey, &UncheckedInfo),
  150|      0|        predicate: impl FnMut() -> bool,
  151|      0|    ) {
  152|      0|        let lock = self.mutable.lock().unwrap();
  153|      0|        lock.entries_container
  154|      0|            .for_each_with_dependency(dependency, action, predicate)
  155|      0|    }
  156|       |
  157|      3|    pub fn set_satisfied_observer(&self, callback: Box<dyn Fn(&UncheckedInfo) + Send>) {
  158|      3|        self.mutable.lock().unwrap().satisfied_callback = Some(callback);
  159|      3|    }
  160|       |
  161|      0|    pub fn container_info(&self) -> ContainerInfo {
  162|      0|        [
  163|      0|            ("entries", self.len(), Self::entries_size()),
  164|      0|            ("queries", self.buffer_count(), Self::buffer_entry_size()),
  165|      0|        ]
  166|      0|        .into()
  167|      0|    }
  168|       |}
  169|       |
  170|       |impl Default for UncheckedMap {
  171|      1|    fn default() -> Self {
  172|      1|        Self::new(65536, Arc::new(Stats::default()), false)
  173|      1|    }
  174|       |}
  175|       |
  176|       |impl Drop for UncheckedMap {
  177|      4|    fn drop(&mut self) {
  178|      4|        debug_assert!(self.join_handle.lock().unwrap().is_none());
  179|      4|        self.stop()
  180|      4|    }
  181|       |}
  182|       |
  183|       |struct ThreadMutableData {
  184|       |    stopped: bool,
  185|       |    buffer: VecDeque<HashOrAccount>,
  186|       |    writing_back_buffer: bool,
  187|       |    entries_container: EntriesContainer,
  188|       |    satisfied_callback: Option<Box<dyn Fn(&UncheckedInfo) + Send>>,
  189|       |}
  190|       |
  191|       |impl ThreadMutableData {
  192|      4|    fn new() -> Self {
  193|      4|        Self {
  194|      4|            stopped: false,
  195|      4|            buffer: VecDeque::new(),
  196|      4|            writing_back_buffer: false,
  197|      4|            entries_container: EntriesContainer::new(),
  198|      4|            satisfied_callback: None,
  199|      4|        }
  200|      4|    }
  201|       |}
  202|       |
  203|       |pub struct UncheckedMapThread {
  204|       |    disable_delete: bool,
  205|       |    mutable: Arc<Mutex<ThreadMutableData>>,
  206|       |    condition: Arc<Condvar>,
  207|       |    stats: Arc<Stats>,
  208|       |    back_buffer: Mutex<VecDeque<HashOrAccount>>,
  209|       |}
  210|       |
  211|       |impl UncheckedMapThread {
  212|      3|    fn run(&self) {
  213|      3|        let mut lock = self.mutable.lock().unwrap();
  214|      6|        while !lock.stopped {
  215|      3|            if !lock.buffer.is_empty() {
  216|      0|                let mut back_buffer_lock = self.back_buffer.lock().unwrap();
  217|      0|                std::mem::swap(&mut lock.buffer, back_buffer_lock.deref_mut());
  218|      0|                lock.writing_back_buffer = true;
  219|      0|                drop(lock);
  220|      0|                self.process_queries(&back_buffer_lock);
  221|      0|                lock = self.mutable.lock().unwrap();
  222|      0|                lock.writing_back_buffer = false;
  223|      0|                back_buffer_lock.clear();
  224|      3|            } else {
  225|      3|                lock = self
  226|      3|                    .condition
  227|      6|                    .wait_while(lock, |other_lock| {
  228|      6|                        !other_lock.stopped && other_lock.buffer.is_empty()
                                                             ^3
  229|      6|                    })
  230|      3|                    .unwrap();
  231|      3|            }
  232|       |        }
  233|      3|    }
  234|       |
  235|      0|    fn process_queries(&self, back_buffer: &VecDeque<HashOrAccount>) {
  236|      0|        for item in back_buffer {
  237|      0|            self.query_impl(item);
  238|      0|        }
  239|      0|    }
  240|       |
  241|      0|    pub fn query_impl(&self, hash: &HashOrAccount) {
  242|      0|        let mut delete_queue = Vec::new();
  243|      0|        let mut lock = self.mutable.lock().unwrap();
  244|      0|        lock.entries_container.for_each_with_dependency(
  245|      0|            hash,
  246|      0|            |key, info| {
  247|      0|                delete_queue.push(key.clone());
  248|      0|                self.stats.inc(StatType::Unchecked, DetailType::Satisfied);
  249|      0|                if let Some(callback) = &lock.satisfied_callback {
  250|      0|                    callback(info);
  251|      0|                }
  252|      0|            },
  253|      0|            || true,
  254|      0|        );
  255|      0|        if !self.disable_delete {
  256|      0|            for key in &delete_queue {
  257|      0|                lock.entries_container.remove(key);
  258|      0|            }
  259|      0|        }
  260|      0|    }
  261|       |}
  262|       |
  263|       |#[derive(Clone, Debug)]
  264|       |pub struct Entry {
  265|       |    key: UncheckedKey,
  266|       |    info: UncheckedInfo,
  267|       |}
  268|       |
  269|       |impl Entry {
  270|     10|    fn new(key: UncheckedKey, info: UncheckedInfo) -> Self {
  271|     10|        Self { key, info }
  272|     10|    }
  273|       |}
  274|       |
  275|       |impl PartialEq for Entry {
  276|      1|    fn eq(&self, other: &Self) -> bool {
  277|      1|        self.key.eq(&other.key)
  278|      1|    }
  279|       |}
  280|       |
  281|       |impl Eq for Entry {}
  282|       |
  283|       |impl PartialOrd for Entry {
  284|      0|    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
  285|      0|        self.key.partial_cmp(&other.key)
  286|      0|    }
  287|       |}
  288|       |
  289|       |impl Ord for Entry {
  290|      0|    fn cmp(&self, other: &Self) -> Ordering {
  291|      0|        self.key.cmp(&other.key)
  292|      0|    }
  293|       |}
  294|       |
  295|       |#[derive(Default, Clone, Debug)]
  296|       |pub struct EntriesContainer {
  297|       |    next_id: usize,
  298|       |    by_key: BTreeMap<UncheckedKey, usize>,
  299|       |    by_id: BTreeMap<usize, Entry>,
  300|       |}
  301|       |
  302|       |impl EntriesContainer {
  303|     11|    fn new() -> Self {
  304|     11|        Self {
  305|     11|            by_id: BTreeMap::new(),
  306|     11|            by_key: BTreeMap::new(),
  307|     11|            next_id: 0,
  308|     11|        }
  309|     11|    }
  310|       |
  311|      0|    pub fn iter(&self) -> impl Iterator<Item = &Entry> {
  312|      0|        self.by_id.values()
  313|      0|    }
  314|       |
  315|     11|    pub fn insert(&mut self, entry: Entry) -> bool {
  316|     11|        match self.by_key.get(&entry.key) {
  317|      1|            Some(_key) => false,
  318|       |            None => {
  319|     10|                self.by_key.insert(entry.key.clone(), self.next_id);
  320|     10|                self.by_id.insert(self.next_id, entry);
  321|     10|
  322|     10|                self.next_id = self.next_id.wrapping_add(1);
  323|     10|
  324|     10|                true
  325|       |            }
  326|       |        }
  327|     11|    }
  328|       |
  329|      0|    fn is_empty(&self) -> bool {
  330|      0|        self.len() == 0
  331|      0|    }
  332|       |
  333|      1|    fn remove(&mut self, key: &UncheckedKey) -> Option<Entry> {
  334|      1|        if let Some(id) = self.by_key.remove(key) {
  335|      1|            self.by_id.remove(&id)
  336|       |        } else {
  337|      0|            None
  338|       |        }
  339|      1|    }
  340|       |
  341|      6|    fn len(&self) -> usize {
  342|      6|        self.by_id.len()
  343|      6|    }
  344|       |
  345|      3|    fn pop_front(&mut self) -> Option<Entry> {
  346|      3|        if let Some((_id, entry)) = self.by_id.pop_first() {
  347|      3|            self.by_key.remove(&entry.key);
  348|      3|            Some(entry)
  349|       |        } else {
  350|      0|            None
  351|       |        }
  352|      3|    }
  353|       |
  354|      0|    fn clear(&mut self) {
  355|      0|        self.by_id.clear();
  356|      0|        self.by_key.clear();
  357|      0|        self.next_id = 0;
  358|      0|    }
  359|       |
  360|      1|    fn exists(&self, key: &UncheckedKey) -> bool {
  361|      1|        self.by_key.contains_key(key)
  362|      1|    }
  363|       |
  364|      0|    fn entry_size() -> usize {
  365|      0|        size_of::<UncheckedKey>() + size_of::<Entry>() + size_of::<usize>() * 2
  366|      0|    }
  367|       |
  368|      0|    pub fn for_each(
  369|      0|        &self,
  370|      0|        mut action: impl FnMut(&UncheckedKey, &UncheckedInfo),
  371|      0|        mut predicate: impl FnMut() -> bool,
  372|      0|    ) {
  373|      0|        for entry in self.by_id.values() {
  374|      0|            if !predicate() {
  375|      0|                break;
  376|      0|            }
  377|      0|            action(&entry.key, &entry.info);
  378|       |        }
  379|      0|    }
  380|       |
  381|      0|    pub fn for_each_with_dependency(
  382|      0|        &self,
  383|      0|        dependency: &HashOrAccount,
  384|      0|        mut action: impl FnMut(&UncheckedKey, &UncheckedInfo),
  385|      0|        mut predicate: impl FnMut() -> bool,
  386|      0|    ) {
  387|      0|        let key = UncheckedKey::new(dependency.into(), BlockHash::zero());
  388|      0|        for (key, id) in self.by_key.range(key..) {
  389|      0|            if !predicate() || key.previous != dependency.into() {
  390|      0|                break;
  391|      0|            }
  392|      0|            let entry = self.by_id.get(id).unwrap();
  393|      0|            action(&entry.key, &entry.info);
  394|       |        }
  395|      0|    }
  396|       |}
  397|       |
  398|       |#[cfg(test)]
  399|       |mod tests {
  400|       |    use rsnano_core::Block;
  401|       |
  402|       |    use super::*;
  403|       |
  404|       |    #[test]
  405|      1|    fn empty_container() {
  406|      1|        let container = EntriesContainer::new();
  407|      1|        assert_eq!(container.next_id, 0);
  408|      1|        assert_eq!(container.by_id.len(), 0);
  409|      1|        assert_eq!(container.by_key.len(), 0);
  410|      1|    }
  411|       |
  412|       |    #[test]
  413|      1|    fn insert_one_entry() {
  414|      1|        let mut container = EntriesContainer::new();
  415|      1|
  416|      1|        let entry = test_entry(1);
  417|      1|        let new_insert = container.insert(entry.clone());
  418|      1|
  419|      1|        assert_eq!(container.next_id, 1);
  420|      1|        assert_eq!(container.by_id.len(), 1);
  421|      1|        assert_eq!(container.by_id.get(&0).unwrap(), &entry);
  422|      1|        assert_eq!(container.by_key.len(), 1);
  423|      1|        assert_eq!(container.by_key.get(&entry.key).unwrap(), &0);
  424|      1|        assert_eq!(new_insert, true);
  425|      1|    }
  426|       |
  427|       |    #[test]
  428|      1|    fn insert_two_entries_with_same_key() {
  429|      1|        let mut container = EntriesContainer::new();
  430|      1|
  431|      1|        let entry = test_entry(1);
  432|      1|        let new_insert1 = container.insert(entry.clone());
  433|      1|        let new_insert2 = container.insert(entry);
  434|      1|
  435|      1|        assert_eq!(container.next_id, 1);
  436|      1|        assert_eq!(container.by_id.len(), 1);
  437|      1|        assert_eq!(container.by_key.len(), 1);
  438|      1|        assert_eq!(new_insert1, true);
  439|      1|        assert_eq!(new_insert2, false);
  440|      1|    }
  441|       |
  442|       |    #[test]
  443|      1|    fn insert_two_entries_with_different_key() {
  444|      1|        let mut container = EntriesContainer::new();
  445|      1|
  446|      1|        let new_insert1 = container.insert(test_entry(1));
  447|      1|        let new_insert2 = container.insert(test_entry(2));
  448|      1|
  449|      1|        assert_eq!(container.next_id, 2);
  450|      1|        assert_eq!(container.by_id.len(), 2);
  451|      1|        assert_eq!(container.by_key.len(), 2);
  452|      1|        assert_eq!(new_insert1, true);
  453|      1|        assert_eq!(new_insert2, true);
  454|      1|    }
  455|       |
  456|       |    #[test]
  457|      1|    fn pop_front() {
  458|      1|        let mut container = EntriesContainer::new();
  459|      1|
  460|      1|        container.insert(test_entry(1));
  461|      1|        let entry = test_entry(2);
  462|      1|        container.insert(entry.clone());
  463|      1|
  464|      1|        container.pop_front();
  465|      1|
  466|      1|        assert_eq!(container.next_id, 2);
  467|      1|        assert_eq!(container.by_id.len(), 1);
  468|      1|        assert_eq!(container.by_id.get(&1).is_some(), true);
  469|      1|        assert_eq!(container.by_key.len(), 1);
  470|      1|        assert_eq!(container.by_key.get(&entry.key).unwrap(), &1);
  471|      1|        assert_eq!(container.len(), 1);
  472|      1|    }
  473|       |
  474|       |    #[test]
  475|      1|    fn pop_front_twice() {
  476|      1|        let mut container = EntriesContainer::new();
  477|      1|
  478|      1|        container.insert(test_entry(1));
  479|      1|        container.insert(test_entry(2));
  480|      1|
  481|      1|        container.pop_front();
  482|      1|        container.pop_front();
  483|      1|
  484|      1|        assert_eq!(container.len(), 0);
  485|      1|    }
  486|       |
  487|       |    #[test]
  488|      1|    fn remove_by_key() {
  489|      1|        let mut container = EntriesContainer::new();
  490|      1|        container.insert(test_entry(1));
  491|      1|        let entry = test_entry(2);
  492|      1|        container.insert(entry.clone());
  493|      1|
  494|      1|        container.remove(&entry.key);
  495|      1|
  496|      1|        assert_eq!(container.len(), 1);
  497|      1|        assert_eq!(container.by_id.len(), 1);
  498|      1|        assert_eq!(container.by_key.len(), 1);
  499|      1|        assert_eq!(container.exists(&entry.key), false);
  500|      1|    }
  501|       |
  502|     10|    fn test_entry<T: Into<BlockHash>>(hash: T) -> Entry {
  503|     10|        Entry::new(
  504|     10|            UncheckedKey::new(hash.into(), BlockHash::default()),
  505|     10|            UncheckedInfo::new(Block::new_test_instance()),
  506|     10|        )
  507|     10|    }
  508|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/account_sets.rs:
    1|       |use super::{
    2|       |    ordered_blocking::{BlockingEntry, OrderedBlocking},
    3|       |    ordered_priorities::{ChangePriorityResult, OrderedPriorities},
    4|       |    priority::Priority,
    5|       |};
    6|       |use crate::bootstrap::ordered_priorities::PriorityEntry;
    7|       |use rsnano_core::{utils::ContainerInfo, Account, BlockHash};
    8|       |use rsnano_nullable_clock::Timestamp;
    9|       |use std::{cmp::min, time::Duration};
   10|       |
   11|       |#[derive(Clone, Debug, PartialEq)]
   12|       |pub struct AccountSetsConfig {
   13|       |    pub consideration_count: usize,
   14|       |    pub priorities_max: usize,
   15|       |    pub blocking_max: usize,
   16|       |    pub cooldown: Duration,
   17|       |}
   18|       |
   19|       |impl Default for AccountSetsConfig {
   20|     30|    fn default() -> Self {
   21|     30|        Self {
   22|     30|            consideration_count: 4,
   23|     30|            priorities_max: 256 * 1024,
   24|     30|            blocking_max: 256 * 1024,
   25|     30|            cooldown: Duration::from_secs(3),
   26|     30|        }
   27|     30|    }
   28|       |}
   29|       |
   30|       |/// This struct tracks various account sets which are shared among the multiple bootstrap threads
   31|       |pub(crate) struct AccountSets {
   32|       |    config: AccountSetsConfig,
   33|       |    priorities: OrderedPriorities,
   34|       |    blocking: OrderedBlocking,
   35|       |}
   36|       |
   37|       |#[derive(Debug, PartialEq, Eq)]
   38|       |pub(crate) enum PriorityUpResult {
   39|       |    Inserted,
   40|       |    Updated,
   41|       |    InvalidAccount,
   42|       |    AccountBlocked,
   43|       |}
   44|       |
   45|       |#[derive(Debug, PartialEq, Eq)]
   46|       |pub(crate) enum PriorityDownResult {
   47|       |    Deprioritized,
   48|       |    Erased,
   49|       |    AccountNotFound,
   50|       |    InvalidAccount,
   51|       |}
   52|       |
   53|       |impl AccountSets {
   54|       |    pub const PRIORITY_INITIAL: Priority = Priority::new(2.0);
   55|       |    pub const PRIORITY_INCREASE: Priority = Priority::new(2.0);
   56|       |    pub const PRIORITY_DIVIDE: f64 = 2.0;
   57|       |    pub const PRIORITY_MAX: Priority = Priority::new(128.0);
   58|       |    pub const PRIORITY_CUTOFF: Priority = Priority::new(0.15);
   59|       |    pub const MAX_FAILS: usize = 3;
   60|       |
   61|     13|    pub fn new(config: AccountSetsConfig) -> Self {
   62|     13|        Self {
   63|     13|            config,
   64|     13|            priorities: Default::default(),
   65|     13|            blocking: Default::default(),
   66|     13|        }
   67|     13|    }
   68|       |
   69|    105|    pub fn priority_up(&mut self, account: &Account) -> PriorityUpResult {
   70|    105|        if account.is_zero() {
   71|      0|            return PriorityUpResult::InvalidAccount;
   72|    105|        }
   73|    105|
   74|    105|        if !self.blocked(account) {
   75|    105|            let updated = self.priorities.modify(account, |entry| {
   76|     99|                entry.priority = Self::higher_priority(entry.priority);
   77|     99|                entry.fails = 0;
   78|     99|                true // keep this entry
   79|    105|            });
   80|    105|
   81|    105|            match updated {
   82|       |                ChangePriorityResult::Updated | ChangePriorityResult::Deleted => {
   83|     99|                    PriorityUpResult::Updated
   84|       |                }
   85|       |                ChangePriorityResult::NotFound => {
   86|      6|                    self.priorities
   87|      6|                        .insert(PriorityEntry::new(*account, Self::PRIORITY_INITIAL));
   88|      6|
   89|      6|                    self.trim_overflow();
   90|      6|                    PriorityUpResult::Inserted
   91|       |                }
   92|       |            }
   93|       |        } else {
   94|      0|            PriorityUpResult::AccountBlocked
   95|       |        }
   96|    105|    }
   97|       |
   98|     99|    fn higher_priority(priority: Priority) -> Priority {
   99|     99|        min(priority + Self::PRIORITY_INCREASE, Self::PRIORITY_MAX)
  100|     99|    }
  101|       |
  102|     12|    pub fn priority_down(&mut self, account: &Account) -> PriorityDownResult {
  103|     12|        if account.is_zero() {
  104|      0|            return PriorityDownResult::InvalidAccount;
  105|     12|        }
  106|     12|
  107|     12|        let change_result = self.priorities.modify(account, |entry| {
  108|      3|            let priority = entry.priority / Self::PRIORITY_DIVIDE;
  109|      3|            if entry.fails >= AccountSets::MAX_FAILS
  110|      3|                || entry.fails as f64 >= entry.priority.as_f64()
  111|      2|                || priority <= Self::PRIORITY_CUTOFF
  112|       |            {
  113|      1|                false // delete entry
  114|       |            } else {
  115|      2|                entry.fails += 1;
  116|      2|                entry.priority = priority;
  117|      2|                true // keep
  118|       |            }
  119|     12|        });
                      ^3
  120|     12|
  121|     12|        match change_result {
  122|      2|            ChangePriorityResult::Updated => PriorityDownResult::Deprioritized,
  123|      1|            ChangePriorityResult::Deleted => PriorityDownResult::Erased,
  124|      9|            ChangePriorityResult::NotFound => PriorityDownResult::AccountNotFound,
  125|       |        }
  126|     12|    }
  127|       |
  128|      3|    pub fn priority_set_initial(&mut self, account: &Account) -> bool {
  129|      3|        self.priority_set(account, Self::PRIORITY_INITIAL)
  130|      3|    }
  131|       |
  132|      4|    pub fn priority_set(&mut self, account: &Account, priority: Priority) -> bool {
  133|      4|        let inserted =
  134|      4|            Self::priority_set_impl(account, priority, &self.blocking, &mut self.priorities);
  135|      4|        self.trim_overflow();
  136|      4|        inserted
  137|      4|    }
  138|       |
  139|      4|    fn priority_set_impl(
  140|      4|        account: &Account,
  141|      4|        priority: Priority,
  142|      4|        blocking: &OrderedBlocking,
  143|      4|        priorities: &mut OrderedPriorities,
  144|      4|    ) -> bool {
  145|      4|        if account.is_zero() {
  146|      0|            return false;
  147|      4|        }
  148|      4|
  149|      4|        if !blocking.contains(account) && !priorities.contains(account) {
  150|      4|            priorities.insert(PriorityEntry::new(*account, priority));
  151|      4|            true
  152|       |        } else {
  153|      0|            false
  154|       |        }
  155|      4|    }
  156|       |
  157|      0|    pub fn priority_erase(&mut self, account: &Account) -> bool {
  158|      0|        if account.is_zero() {
  159|      0|            return false;
  160|      0|        }
  161|      0|
  162|      0|        self.priorities.remove(account).is_some()
  163|      0|    }
  164|       |
  165|      3|    pub fn block(&mut self, account: Account, dependency: BlockHash) -> bool {
  166|      3|        debug_assert!(!account.is_zero());
  167|       |
  168|      3|        let removed = self.priorities.remove(&account);
  169|      3|
  170|      3|        if removed.is_some() {
  171|      3|            self.blocking.insert(BlockingEntry {
  172|      3|                account,
  173|      3|                dependency,
  174|      3|                dependency_account: Account::zero(),
  175|      3|            });
  176|      3|
  177|      3|            self.trim_overflow();
  178|      3|            true
  179|       |        } else {
  180|      0|            false
  181|       |        }
  182|      3|    }
  183|       |
  184|      2|    pub fn unblock(&mut self, account: Account, hash: Option<BlockHash>) -> bool {
  185|      2|        if account.is_zero() {
  186|      0|            return false;
  187|      2|        }
  188|       |
  189|       |        // Unblock only if the dependency is fulfilled
  190|      2|        if let Some(existing) = self.blocking.get(&account) {
  191|      2|            let hash_matches = if let Some(hash) = hash {
                                                         ^0
  192|      0|                hash == existing.dependency
  193|       |            } else {
  194|      2|                true
  195|       |            };
  196|       |
  197|      2|            if hash_matches {
  198|      2|                debug_assert!(!self.priorities.contains(&account));
  199|      2|                self.priorities
  200|      2|                    .insert(PriorityEntry::new(account, Self::PRIORITY_INITIAL));
  201|      2|                self.blocking.remove(&account);
  202|      2|                self.trim_overflow();
  203|      2|                return true;
  204|      0|            }
  205|      0|        }
  206|       |
  207|      0|        false
  208|      2|    }
  209|       |
  210|      0|    pub fn timestamp_set(&mut self, account: &Account, now: Timestamp) {
  211|      0|        debug_assert!(!account.is_zero());
  212|      0|        self.priorities.change_timestamp(account, Some(now));
  213|      0|    }
  214|       |
  215|      0|    pub fn timestamp_reset(&mut self, account: &Account) {
  216|      0|        debug_assert!(!account.is_zero());
  217|       |
  218|      0|        self.priorities.change_timestamp(account, None);
  219|      0|    }
  220|       |
  221|       |    /// Sets information about the account chain that contains the block hash
  222|      0|    pub fn dependency_update(
  223|      0|        &mut self,
  224|      0|        dependency: &BlockHash,
  225|      0|        dependency_account: Account,
  226|      0|    ) -> usize {
  227|      0|        debug_assert!(!dependency_account.is_zero());
  228|      0|        let updated = self
  229|      0|            .blocking
  230|      0|            .modify_dependency_account(dependency, dependency_account);
  231|      0|        updated
  232|      0|    }
  233|       |
  234|       |    /// Erase the oldest entries
  235|     15|    fn trim_overflow(&mut self) {
  236|     15|        while !self.priorities.is_empty() && self.priorities.len() > self.config.priorities_max {
                                                           ^12
  237|      0|            self.priorities.pop_lowest_prio();
  238|      0|        }
  239|     15|        while self.blocking.len() > self.config.blocking_max {
  240|      0|            self.blocking.pop_oldest();
  241|      0|        }
  242|     15|    }
  243|       |
  244|       |    /// Sampling
  245|      0|    pub fn next_priority(
  246|      0|        &self,
  247|      0|        now: Timestamp,
  248|      0|        filter: impl Fn(&Account) -> bool,
  249|      0|    ) -> PriorityResult {
  250|      0|        if self.priorities.is_empty() {
  251|      0|            return Default::default();
  252|      0|        }
  253|      0|
  254|      0|        let cutoff = now - self.config.cooldown;
  255|       |
  256|      0|        let Some(entry) = self.priorities.next_priority(cutoff, filter) else {
  257|      0|            return Default::default();
  258|       |        };
  259|       |
  260|      0|        PriorityResult {
  261|      0|            account: entry.account,
  262|      0|            priority: entry.priority,
  263|      0|            fails: entry.fails,
  264|      0|        }
  265|      0|    }
  266|       |
  267|      0|    pub fn next_blocking(&self, filter: impl Fn(&BlockHash) -> bool) -> BlockHash {
  268|      0|        if self.blocking.len() == 0 {
  269|      0|            return BlockHash::zero();
  270|      0|        }
  271|      0|
  272|      0|        self.blocking.next(filter).unwrap_or_default()
  273|      0|    }
  274|       |
  275|       |    /// Sets information about the account chain that contains the block hash
  276|      0|    pub fn sync_dependencies(&mut self) -> (usize, usize) {
  277|      0|        let mut inserted = 0;
  278|      0|        let mut insert_failed = 0;
  279|      0|
  280|      0|        // Sample all accounts with a known dependency account (> account 0)
  281|      0|        let begin = Account::zero().inc().unwrap();
  282|      0|        for entry in self.blocking.iter_start_dep_account(begin) {
  283|      0|            if self.priorities.len() >= self.config.priorities_max {
  284|      0|                break;
  285|      0|            }
  286|      0|
  287|      0|            if !self.blocked(&entry.dependency_account)
  288|      0|                && !self.prioritized(&entry.dependency_account)
  289|       |            {
  290|      0|                if Self::priority_set_impl(
  291|      0|                    &entry.dependency_account,
  292|      0|                    Self::PRIORITY_INITIAL,
  293|      0|                    &self.blocking,
  294|      0|                    &mut self.priorities,
  295|      0|                ) {
  296|      0|                    inserted += 1;
  297|      0|                } else {
  298|      0|                    insert_failed += 1;
  299|      0|                }
  300|      0|            }
  301|       |        }
  302|       |
  303|      0|        self.trim_overflow();
  304|      0|        (inserted, insert_failed)
  305|      0|    }
  306|       |
  307|    118|    pub fn blocked(&self, account: &Account) -> bool {
  308|    118|        self.blocking.contains(account)
  309|    118|    }
  310|       |
  311|      1|    pub fn prioritized(&self, account: &Account) -> bool {
  312|      1|        self.priorities.contains(account)
  313|      1|    }
  314|       |
  315|      0|    pub fn priority_len(&self) -> usize {
  316|      0|        self.priorities.len()
  317|      0|    }
  318|       |
  319|      0|    pub fn blocked_len(&self) -> usize {
  320|      0|        self.blocking.len()
  321|      0|    }
  322|       |
  323|      3|    pub fn priority_half_full(&self) -> bool {
  324|      3|        self.priorities.len() > self.config.priorities_max / 2
  325|      3|    }
  326|       |
  327|      0|    pub fn blocked_half_full(&self) -> bool {
  328|      0|        self.blocking.len() > self.config.blocking_max / 2
  329|      0|    }
  330|       |
  331|       |    /// Accounts in the ledger but not in priority list are assumed priority 1.0f
  332|       |    /// Blocked accounts are assumed priority 0.0f
  333|       |    #[allow(dead_code)]
  334|     10|    pub fn priority(&self, account: &Account) -> Priority {
  335|     10|        if !self.blocked(account) {
  336|      9|            if let Some(existing) = self.priorities.get(account) {
                                      ^7
  337|      7|                return existing.priority;
  338|      2|            }
  339|      1|        }
  340|      3|        return Priority::ZERO;
  341|     10|    }
  342|       |
  343|      0|    pub fn container_info(&self) -> ContainerInfo {
  344|      0|        // Count blocking entries with their dependency account unknown
  345|      0|        let blocking_unknown = self.blocking.count_by_dependency_account(&Account::zero());
  346|      0|        [
  347|      0|            (
  348|      0|                "priorities",
  349|      0|                self.priorities.len(),
  350|      0|                OrderedPriorities::ELEMENT_SIZE,
  351|      0|            ),
  352|      0|            (
  353|      0|                "blocking",
  354|      0|                self.blocking.len(),
  355|      0|                OrderedBlocking::ELEMENT_SIZE,
  356|      0|            ),
  357|      0|            ("blocking_unknown", blocking_unknown, 0),
  358|      0|        ]
  359|      0|        .into()
  360|      0|    }
  361|       |}
  362|       |
  363|       |impl Default for AccountSets {
  364|     10|    fn default() -> Self {
  365|     10|        Self::new(Default::default())
  366|     10|    }
  367|       |}
  368|       |
  369|       |#[derive(Default)]
  370|       |pub struct PriorityResult {
  371|       |    pub account: Account,
  372|       |    pub priority: Priority,
  373|       |    pub fails: usize,
  374|       |}
  375|       |
  376|       |#[cfg(test)]
  377|       |mod tests {
  378|       |    use super::*;
  379|       |
  380|       |    #[test]
  381|      1|    fn empty_blocked() {
  382|      1|        let sets = AccountSets::default();
  383|      1|        assert_eq!(sets.blocked(&Account::from(1)), false);
  384|      1|    }
  385|       |
  386|       |    #[test]
  387|      1|    fn block() {
  388|      1|        let mut sets = AccountSets::default();
  389|      1|        let account = Account::from(1);
  390|      1|        let hash = BlockHash::from(2);
  391|      1|        sets.priority_up(&account);
  392|      1|
  393|      1|        sets.block(account, hash);
  394|      1|
  395|      1|        assert!(sets.blocked(&account));
  396|      1|        assert_eq!(sets.priority(&account), Priority::ZERO);
  397|      1|    }
  398|       |
  399|       |    #[test]
  400|      1|    fn unblock() {
  401|      1|        let mut sets = AccountSets::default();
  402|      1|        let account = Account::from(1);
  403|      1|        let hash = BlockHash::from(2);
  404|      1|        sets.priority_up(&account);
  405|      1|
  406|      1|        sets.block(account, hash);
  407|      1|
  408|      1|        assert!(sets.unblock(account, None));
  409|      1|        assert_eq!(sets.blocked(&account), false);
  410|      1|    }
  411|       |
  412|       |    #[test]
  413|      1|    fn priority_base() {
  414|      1|        let sets = AccountSets::default();
  415|      1|        assert_eq!(sets.priority(&Account::from(1)), Priority::ZERO);
  416|      1|    }
  417|       |
  418|       |    #[test]
  419|      1|    fn priority_unblock() {
  420|      1|        let mut sets = AccountSets::default();
  421|      1|        let account = Account::from(1);
  422|      1|        let hash = BlockHash::from(2);
  423|      1|
  424|      1|        assert_eq!(sets.priority_up(&account), PriorityUpResult::Inserted);
  425|      1|        assert_eq!(sets.priority(&account), AccountSets::PRIORITY_INITIAL);
  426|       |
  427|      1|        sets.block(account, hash);
  428|      1|        sets.unblock(account, None);
  429|      1|
  430|      1|        assert_eq!(sets.priority(&account), AccountSets::PRIORITY_INITIAL);
  431|      1|    }
  432|       |
  433|       |    #[test]
  434|      1|    fn priority_up_down() {
  435|      1|        let mut sets = AccountSets::default();
  436|      1|        let account = Account::from(1);
  437|      1|
  438|      1|        sets.priority_up(&account);
  439|      1|        assert_eq!(sets.priority(&account), AccountSets::PRIORITY_INITIAL);
  440|       |
  441|      1|        sets.priority_down(&account);
  442|      1|        assert_eq!(
  443|      1|            sets.priority(&account),
  444|      1|            AccountSets::PRIORITY_INITIAL / AccountSets::PRIORITY_DIVIDE
  445|      1|        );
  446|      1|    }
  447|       |
  448|       |    #[test]
  449|      1|    fn priority_down_empty() {
  450|      1|        let mut sets = AccountSets::default();
  451|      1|        let account = Account::from(1);
  452|      1|
  453|      1|        sets.priority_down(&account);
  454|      1|
  455|      1|        assert_eq!(sets.priority(&account), Priority::ZERO);
  456|      1|    }
  457|       |
  458|       |    // Ensure priority value is bounded
  459|       |    #[test]
  460|      1|    fn saturate_priority() {
  461|      1|        let mut sets = AccountSets::default();
  462|      1|        let account = Account::from(1);
  463|       |
  464|    101|        for _ in 0..100 {
  465|    100|            sets.priority_up(&account);
  466|    100|        }
  467|      1|        assert_eq!(sets.priority(&account), AccountSets::PRIORITY_MAX);
  468|      1|    }
  469|       |
  470|       |    #[test]
  471|      1|    fn priority_down_saturate() {
  472|      1|        let mut sets = AccountSets::default();
  473|      1|        let account = Account::from(1);
  474|      1|        sets.priority_up(&account);
  475|      1|        assert_eq!(sets.priority(&account), AccountSets::PRIORITY_INITIAL);
  476|     11|        for _ in 0..10 {
  477|     10|            sets.priority_down(&account);
  478|     10|        }
  479|      1|        assert_eq!(sets.prioritized(&account), false);
  480|      1|    }
  481|       |
  482|       |    #[test]
  483|      1|    fn priority_set() {
  484|      1|        let mut sets = AccountSets::default();
  485|      1|        let account = Account::from(1);
  486|      1|        let prio = Priority::new(10.0);
  487|      1|        sets.priority_set(&account, prio);
  488|      1|        assert_eq!(sets.priority(&account), prio);
  489|      1|    }
  490|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/bootstrap_responder.rs:
    1|       |use crate::{
    2|       |    stats::{DetailType, Direction, StatType, Stats},
    3|       |    transport::MessageSender,
    4|       |};
    5|       |use rsnano_core::{utils::FairQueue, Block, BlockHash, Frontier};
    6|       |use rsnano_ledger::Ledger;
    7|       |use rsnano_messages::{
    8|       |    AccountInfoAckPayload, AccountInfoReqPayload, AscPullAck, AscPullAckType, AscPullReq,
    9|       |    AscPullReqType, BlocksAckPayload, BlocksReqPayload, FrontiersReqPayload, HashType, Message,
   10|       |};
   11|       |use rsnano_network::{Channel, ChannelId, DeadChannelCleanupStep, TrafficType};
   12|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   13|       |use std::{
   14|       |    cmp::min,
   15|       |    collections::VecDeque,
   16|       |    sync::{
   17|       |        atomic::{AtomicBool, Ordering},
   18|       |        Arc, Condvar, Mutex, MutexGuard,
   19|       |    },
   20|       |    thread::JoinHandle,
   21|       |};
   22|       |
   23|       |#[derive(Clone, Debug, PartialEq)]
   24|       |pub struct BootstrapResponderConfig {
   25|       |    pub max_queue: usize,
   26|       |    pub threads: usize,
   27|       |    pub batch_size: usize,
   28|       |}
   29|       |
   30|       |impl Default for BootstrapResponderConfig {
   31|     10|    fn default() -> Self {
   32|     10|        Self {
   33|     10|            max_queue: 16,
   34|     10|            threads: 1,
   35|     10|            batch_size: 64,
   36|     10|        }
   37|     10|    }
   38|       |}
   39|       |
   40|       |/**
   41|       | * Processes bootstrap requests (`asc_pull_req` messages) and replies with bootstrap responses (`asc_pull_ack`)
   42|       | */
   43|       |pub struct BootstrapResponder {
   44|       |    config: BootstrapResponderConfig,
   45|       |    stats: Arc<Stats>,
   46|       |    threads: Mutex<Vec<JoinHandle<()>>>,
   47|       |    pub(crate) server_impl: Arc<BootstrapResponderImpl>,
   48|       |}
   49|       |
   50|       |impl BootstrapResponder {
   51|       |    /** Maximum number of blocks to send in a single response, cannot be higher than capacity of a single `asc_pull_ack` message */
   52|       |    pub const MAX_BLOCKS: usize = BlocksAckPayload::MAX_BLOCKS;
   53|       |    pub const MAX_FRONTIERS: usize = AscPullAck::MAX_FRONTIERS;
   54|       |
   55|      3|    pub(crate) fn new(
   56|      3|        config: BootstrapResponderConfig,
   57|      3|        stats: Arc<Stats>,
   58|      3|        ledger: Arc<Ledger>,
   59|      3|        message_sender: MessageSender,
   60|      3|    ) -> Self {
   61|      3|        let max_queue = config.max_queue;
   62|      3|        let server_impl = Arc::new(BootstrapResponderImpl {
   63|      3|            stats: Arc::clone(&stats),
   64|      3|            ledger,
   65|      3|            batch_size: config.batch_size,
   66|      3|            on_response: Arc::new(Mutex::new(None)),
   67|      3|            condition: Condvar::new(),
   68|      3|            stopped: AtomicBool::new(false),
   69|      3|            queue: Mutex::new(FairQueue::new(move |_| max_queue, |_| 1)),
                                                                    ^0             ^0
   70|      3|            message_sender: Mutex::new(message_sender),
   71|      3|        });
   72|      3|
   73|      3|        Self {
   74|      3|            config,
   75|      3|            stats: Arc::clone(&stats),
   76|      3|            threads: Mutex::new(Vec::new()),
   77|      3|            server_impl,
   78|      3|        }
   79|      3|    }
   80|       |
   81|      3|    pub fn start(&self) {
   82|      3|        debug_assert!(self.threads.lock().unwrap().is_empty());
   83|       |
   84|      3|        let mut threads = self.threads.lock().unwrap();
   85|      3|        for _ in 0..self.config.threads {
   86|      3|            let server_impl = Arc::clone(&self.server_impl);
   87|      3|            threads.push(
   88|      3|                std::thread::Builder::new()
   89|      3|                    .name("Bootstrap serv".to_string())
   90|      3|                    .spawn(move || {
   91|      3|                        server_impl.run();
   92|      3|                    })
   93|      3|                    .unwrap(),
   94|      3|            );
   95|      3|        }
   96|      3|    }
   97|       |
   98|      3|    pub fn stop(&self) {
   99|      3|        self.server_impl.stopped.store(true, Ordering::SeqCst);
  100|      3|        self.server_impl.condition.notify_all();
  101|      3|
  102|      3|        let mut threads = self.threads.lock().unwrap();
  103|      3|        for thread in threads.drain(..) {
  104|      3|            thread.join().unwrap();
  105|      3|        }
  106|      3|    }
  107|       |
  108|      0|    pub fn set_response_callback(&self, cb: Box<dyn Fn(&AscPullAck, ChannelId) + Send + Sync>) {
  109|      0|        *self.server_impl.on_response.lock().unwrap() = Some(cb);
  110|      0|    }
  111|       |
  112|      0|    pub fn enqueue(&self, message: AscPullReq, channel: Arc<Channel>) -> bool {
  113|      0|        if !self.verify(&message) {
  114|      0|            self.stats
  115|      0|                .inc(StatType::BootstrapServer, DetailType::Invalid);
  116|      0|            return false;
  117|      0|        }
  118|      0|
  119|      0|        // If channel is full our response will be dropped anyway, so filter that early
  120|      0|        if channel.should_drop(TrafficType::BootstrapServer) {
  121|      0|            self.stats.inc_dir(
  122|      0|                StatType::BootstrapServer,
  123|      0|                DetailType::ChannelFull,
  124|      0|                Direction::In,
  125|      0|            );
  126|      0|            return false;
  127|      0|        }
  128|      0|
  129|      0|        let req_type = DetailType::from(&message.req_type);
  130|      0|        let added = {
  131|      0|            let mut guard = self.server_impl.queue.lock().unwrap();
  132|      0|            guard.push(channel.channel_id(), (message, channel.clone()))
  133|      0|        };
  134|      0|
  135|      0|        if added {
  136|      0|            self.stats
  137|      0|                .inc(StatType::BootstrapServer, DetailType::Request);
  138|      0|            self.stats.inc(StatType::BootstrapServerRequest, req_type);
  139|      0|
  140|      0|            self.server_impl.condition.notify_one();
  141|      0|        } else {
  142|      0|            self.stats
  143|      0|                .inc(StatType::BootstrapServer, DetailType::Overfill);
  144|      0|            self.stats.inc(StatType::BootstrapServerOverfill, req_type);
  145|      0|        }
  146|       |
  147|      0|        added
  148|      0|    }
  149|       |
  150|      0|    fn verify(&self, message: &AscPullReq) -> bool {
  151|      0|        match &message.req_type {
  152|      0|            AscPullReqType::Blocks(i) => i.count > 0 && i.count as usize <= Self::MAX_BLOCKS,
  153|      0|            AscPullReqType::AccountInfo(i) => !i.target.is_zero(),
  154|      0|            AscPullReqType::Frontiers(i) => i.count > 0 && i.count as usize <= Self::MAX_FRONTIERS,
  155|       |        }
  156|      0|    }
  157|       |}
  158|       |
  159|       |impl Drop for BootstrapResponder {
  160|      3|    fn drop(&mut self) {
  161|      3|        debug_assert!(self.threads.lock().unwrap().is_empty());
  162|      3|    }
  163|       |}
  164|       |
  165|       |pub(crate) struct BootstrapResponderImpl {
  166|       |    stats: Arc<Stats>,
  167|       |    ledger: Arc<Ledger>,
  168|       |    on_response: Arc<Mutex<Option<Box<dyn Fn(&AscPullAck, ChannelId) + Send + Sync>>>>,
  169|       |    stopped: AtomicBool,
  170|       |    condition: Condvar,
  171|       |    queue: Mutex<FairQueue<ChannelId, (AscPullReq, Arc<Channel>)>>,
  172|       |    batch_size: usize,
  173|       |    message_sender: Mutex<MessageSender>,
  174|       |}
  175|       |
  176|       |impl BootstrapResponderImpl {
  177|      3|    fn run(&self) {
  178|      3|        let mut queue = self.queue.lock().unwrap();
  179|      6|        while !self.stopped.load(Ordering::SeqCst) {
  180|      3|            if !queue.is_empty() {
  181|      0|                self.stats.inc(StatType::BootstrapServer, DetailType::Loop);
  182|      0|                queue = self.run_batch(queue);
  183|      3|            } else {
  184|      3|                queue = self
  185|      3|                    .condition
  186|      6|                    .wait_while(queue, |q| {
  187|      6|                        q.is_empty() && !self.stopped.load(Ordering::SeqCst)
  188|      6|                    })
  189|      3|                    .unwrap();
  190|      3|            }
  191|       |        }
  192|      3|    }
  193|       |
  194|      0|    fn run_batch<'a>(
  195|      0|        &'a self,
  196|      0|        mut queue: MutexGuard<'a, FairQueue<ChannelId, (AscPullReq, Arc<Channel>)>>,
  197|      0|    ) -> MutexGuard<'a, FairQueue<ChannelId, (AscPullReq, Arc<Channel>)>> {
  198|      0|        let batch = queue.next_batch(self.batch_size);
  199|      0|        drop(queue);
  200|      0|
  201|      0|        let mut tx = self.ledger.read_txn();
  202|      0|        for (_, (request, channel)) in batch {
  203|      0|            tx.refresh_if_needed();
  204|      0|
  205|      0|            if !channel.should_drop(TrafficType::BootstrapServer) {
  206|      0|                let response = self.process(&tx, request);
  207|      0|                self.respond(response, channel.channel_id());
  208|      0|            } else {
  209|      0|                self.stats.inc_dir(
  210|      0|                    StatType::BootstrapServer,
  211|      0|                    DetailType::ChannelFull,
  212|      0|                    Direction::Out,
  213|      0|                );
  214|      0|            }
  215|       |        }
  216|       |
  217|      0|        self.queue.lock().unwrap()
  218|      0|    }
  219|       |
  220|      0|    fn process(&self, tx: &LmdbReadTransaction, message: AscPullReq) -> AscPullAck {
  221|      0|        match message.req_type {
  222|      0|            AscPullReqType::Blocks(blocks) => self.process_blocks(tx, message.id, blocks),
  223|      0|            AscPullReqType::AccountInfo(account) => self.process_account(tx, message.id, account),
  224|      0|            AscPullReqType::Frontiers(frontiers) => {
  225|      0|                self.process_frontiers(tx, message.id, frontiers)
  226|       |            }
  227|       |        }
  228|      0|    }
  229|       |
  230|      0|    fn process_blocks(
  231|      0|        &self,
  232|      0|        tx: &LmdbReadTransaction,
  233|      0|        id: u64,
  234|      0|        request: BlocksReqPayload,
  235|      0|    ) -> AscPullAck {
  236|      0|        let count = min(request.count as usize, BootstrapResponder::MAX_BLOCKS);
  237|      0|
  238|      0|        match request.start_type {
  239|       |            HashType::Account => {
  240|      0|                if let Some(info) = self.ledger.account_info(tx, &request.start.into()) {
  241|       |                    // Start from open block if pulling by account
  242|      0|                    return self.prepare_response(tx, id, info.open_block, count);
  243|      0|                }
  244|       |            }
  245|       |            HashType::Block => {
  246|      0|                if self.ledger.any().block_exists(tx, &request.start.into()) {
  247|      0|                    return self.prepare_response(tx, id, request.start.into(), count);
  248|      0|                }
  249|       |            }
  250|       |        }
  251|       |
  252|       |        // Neither block nor account found, send empty response to indicate that
  253|      0|        self.prepare_empty_blocks_response(id)
  254|      0|    }
  255|       |
  256|       |    /*
  257|       |     * Account info request
  258|       |     */
  259|       |
  260|      0|    fn process_account(
  261|      0|        &self,
  262|      0|        tx: &LmdbReadTransaction,
  263|      0|        id: u64,
  264|      0|        request: AccountInfoReqPayload,
  265|      0|    ) -> AscPullAck {
  266|      0|        let target = match request.target_type {
  267|      0|            HashType::Account => request.target.into(),
  268|       |            HashType::Block => {
  269|       |                // Try to lookup account assuming target is block hash
  270|      0|                self.ledger
  271|      0|                    .any()
  272|      0|                    .block_account(tx, &request.target.into())
  273|      0|                    .unwrap_or_default()
  274|       |            }
  275|       |        };
  276|       |
  277|      0|        let mut response_payload = AccountInfoAckPayload {
  278|      0|            account: target,
  279|      0|            ..Default::default()
  280|      0|        };
  281|       |
  282|      0|        if let Some(account_info) = self.ledger.account_info(tx, &target) {
  283|      0|            response_payload.account_open = account_info.open_block;
  284|      0|            response_payload.account_head = account_info.head;
  285|      0|            response_payload.account_block_count = account_info.block_count;
  286|       |
  287|      0|            if let Some(conf_info) = self.ledger.store.confirmation_height.get(tx, &target) {
  288|      0|                response_payload.account_conf_frontier = conf_info.frontier;
  289|      0|                response_payload.account_conf_height = conf_info.height;
  290|      0|            }
  291|      0|        }
  292|       |        // If account is missing the response payload will contain all 0 fields, except for the target
  293|       |        //
  294|      0|        AscPullAck {
  295|      0|            id,
  296|      0|            pull_type: AscPullAckType::AccountInfo(response_payload),
  297|      0|        }
  298|      0|    }
  299|       |
  300|       |    /*
  301|       |     * Frontiers request
  302|       |     */
  303|      0|    fn process_frontiers(
  304|      0|        &self,
  305|      0|        tx: &LmdbReadTransaction,
  306|      0|        id: u64,
  307|      0|        request: FrontiersReqPayload,
  308|      0|    ) -> AscPullAck {
  309|      0|        let frontiers = self
  310|      0|            .ledger
  311|      0|            .any()
  312|      0|            .accounts_range(tx, request.start..)
  313|      0|            .map(|(account, info)| Frontier::new(account, info.head))
  314|      0|            .take(request.count as usize)
  315|      0|            .collect();
  316|      0|
  317|      0|        AscPullAck {
  318|      0|            id,
  319|      0|            pull_type: AscPullAckType::Frontiers(frontiers),
  320|      0|        }
  321|      0|    }
  322|       |
  323|      0|    fn prepare_response(
  324|      0|        &self,
  325|      0|        tx: &LmdbReadTransaction,
  326|      0|        id: u64,
  327|      0|        start_block: BlockHash,
  328|      0|        count: usize,
  329|      0|    ) -> AscPullAck {
  330|      0|        let blocks = self.prepare_blocks(tx, start_block, count);
  331|      0|        let response_payload = BlocksAckPayload::new(blocks);
  332|      0|
  333|      0|        AscPullAck {
  334|      0|            id,
  335|      0|            pull_type: AscPullAckType::Blocks(response_payload),
  336|      0|        }
  337|      0|    }
  338|       |
  339|      0|    fn prepare_empty_blocks_response(&self, id: u64) -> AscPullAck {
  340|      0|        AscPullAck {
  341|      0|            id,
  342|      0|            pull_type: AscPullAckType::Blocks(BlocksAckPayload::new(VecDeque::new())),
  343|      0|        }
  344|      0|    }
  345|       |
  346|      0|    fn prepare_blocks(
  347|      0|        &self,
  348|      0|        tx: &LmdbReadTransaction,
  349|      0|        start_block: BlockHash,
  350|      0|        count: usize,
  351|      0|    ) -> VecDeque<Block> {
  352|      0|        let mut result = VecDeque::new();
  353|      0|        if !start_block.is_zero() {
  354|      0|            let mut current = self.ledger.any().get_block(tx, &start_block);
  355|      0|            while let Some(c) = current.take() {
  356|      0|                let successor = c.successor().unwrap_or_default();
  357|      0|                result.push_back(c.into());
  358|      0|
  359|      0|                if result.len() == count {
  360|      0|                    break;
  361|      0|                }
  362|      0|                current = self.ledger.any().get_block(tx, &successor);
  363|       |            }
  364|      0|        }
  365|      0|        result
  366|      0|    }
  367|       |
  368|      0|    fn respond(&self, response: AscPullAck, channel_id: ChannelId) {
  369|      0|        self.stats.inc_dir(
  370|      0|            StatType::BootstrapServer,
  371|      0|            DetailType::Response,
  372|      0|            Direction::Out,
  373|      0|        );
  374|      0|        self.stats.inc(
  375|      0|            StatType::BootstrapServerResponse,
  376|      0|            DetailType::from(&response.pull_type),
  377|      0|        );
  378|      0|
  379|      0|        // Increase relevant stats depending on payload type
  380|      0|        match &response.pull_type {
  381|      0|            AscPullAckType::Blocks(blocks) => {
  382|      0|                self.stats.add_dir(
  383|      0|                    StatType::BootstrapServer,
  384|      0|                    DetailType::Blocks,
  385|      0|                    Direction::Out,
  386|      0|                    blocks.blocks().len() as u64,
  387|      0|                );
  388|      0|            }
  389|      0|            AscPullAckType::AccountInfo(_) => {
  390|      0|                self.stats.inc_dir(
  391|      0|                    StatType::BootstrapServer,
  392|      0|                    DetailType::AccountInfo,
  393|      0|                    Direction::Out,
  394|      0|                );
  395|      0|            }
  396|      0|            AscPullAckType::Frontiers(frontiers) => {
  397|      0|                self.stats.add_dir(
  398|      0|                    StatType::BootstrapServer,
  399|      0|                    DetailType::Frontiers,
  400|      0|                    Direction::Out,
  401|      0|                    frontiers.len() as u64,
  402|      0|                );
  403|      0|            }
  404|       |        }
  405|       |
  406|       |        {
  407|      0|            let callback = self.on_response.lock().unwrap();
  408|      0|            if let Some(cb) = &*callback {
  409|      0|                (cb)(&response, channel_id);
  410|      0|            }
  411|       |        }
  412|       |
  413|      0|        let msg = Message::AscPullAck(response);
  414|      0|        self.message_sender.lock().unwrap().try_send(
  415|      0|            channel_id,
  416|      0|            &msg,
  417|      0|            TrafficType::BootstrapServer,
  418|      0|        );
  419|      0|    }
  420|       |}
  421|       |
  422|       |impl From<&AscPullAckType> for DetailType {
  423|      0|    fn from(value: &AscPullAckType) -> Self {
  424|      0|        match value {
  425|      0|            AscPullAckType::Blocks(_) => DetailType::Blocks,
  426|      0|            AscPullAckType::AccountInfo(_) => DetailType::AccountInfo,
  427|      0|            AscPullAckType::Frontiers(_) => DetailType::Frontiers,
  428|       |        }
  429|      0|    }
  430|       |}
  431|       |
  432|       |impl From<&AscPullReqType> for DetailType {
  433|      0|    fn from(value: &AscPullReqType) -> Self {
  434|      0|        match value {
  435|      0|            AscPullReqType::Blocks(_) => DetailType::Blocks,
  436|      0|            AscPullReqType::AccountInfo(_) => DetailType::AccountInfo,
  437|      0|            AscPullReqType::Frontiers(_) => DetailType::Frontiers,
  438|       |        }
  439|      0|    }
  440|       |}
  441|       |
  442|       |pub(crate) struct BootstrapResponderCleanup(Arc<BootstrapResponderImpl>);
  443|       |
  444|       |impl BootstrapResponderCleanup {
  445|      3|    pub fn new(server: Arc<BootstrapResponderImpl>) -> Self {
  446|      3|        Self(server)
  447|      3|    }
  448|       |}
  449|       |
  450|       |impl DeadChannelCleanupStep for BootstrapResponderCleanup {
  451|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  452|      0|        let mut queue = self.0.queue.lock().unwrap();
  453|      0|        for channel_id in dead_channel_ids {
  454|      0|            queue.remove(channel_id);
  455|      0|        }
  456|      0|    }
  457|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/bootstrapper.rs:
    1|       |use super::{
    2|       |    account_sets::{AccountSets, PriorityDownResult, PriorityResult, PriorityUpResult},
    3|       |    crawlers::{AccountDatabaseCrawler, PendingDatabaseCrawler},
    4|       |    database_scan::DatabaseScan,
    5|       |    frontier_scan::{FrontierScan, FrontierScanConfig},
    6|       |    peer_scoring::PeerScoring,
    7|       |    running_query_container::{QuerySource, QueryType, RunningQuery, RunningQueryContainer},
    8|       |    throttle::Throttle,
    9|       |    AccountSetsConfig,
   10|       |};
   11|       |use crate::{
   12|       |    block_processing::{BlockContext, BlockProcessor, BlockSource, LedgerNotifications},
   13|       |    bootstrap::BootstrapResponder,
   14|       |    stats::{DetailType, Direction, Sample, StatType, Stats},
   15|       |    transport::MessageSender,
   16|       |    utils::{ThreadPool, ThreadPoolImpl},
   17|       |};
   18|       |use num::clamp;
   19|       |use rand::{thread_rng, Rng, RngCore};
   20|       |use rsnano_core::{
   21|       |    utils::ContainerInfo, Account, AccountInfo, Block, BlockHash, BlockType, Frontier,
   22|       |    HashOrAccount, SavedBlock,
   23|       |};
   24|       |use rsnano_ledger::{BlockStatus, Ledger};
   25|       |use rsnano_messages::{
   26|       |    AccountInfoAckPayload, AccountInfoReqPayload, AscPullAck, AscPullAckType, AscPullReq,
   27|       |    AscPullReqType, BlocksAckPayload, BlocksReqPayload, FrontiersReqPayload, HashType, Message,
   28|       |};
   29|       |use rsnano_network::{bandwidth_limiter::RateLimiter, ChannelId, Network, TrafficType};
   30|       |use rsnano_nullable_clock::{SteadyClock, Timestamp};
   31|       |use std::{
   32|       |    cmp::{max, min},
   33|       |    sync::{Arc, Condvar, Mutex, RwLock},
   34|       |    thread::JoinHandle,
   35|       |    time::{Duration, Instant},
   36|       |};
   37|       |use tracing::{debug, warn};
   38|       |
   39|       |enum VerifyResult {
   40|       |    Ok,
   41|       |    NothingNew,
   42|       |    Invalid,
   43|       |}
   44|       |
   45|       |pub struct Bootstrapper {
   46|       |    block_processor: Arc<BlockProcessor>,
   47|       |    notifications: LedgerNotifications,
   48|       |    ledger: Arc<Ledger>,
   49|       |    stats: Arc<Stats>,
   50|       |    message_sender: Mutex<MessageSender>,
   51|       |    threads: Mutex<Option<Threads>>,
   52|       |    mutex: Arc<Mutex<BootstrapLogic>>,
   53|       |    condition: Arc<Condvar>,
   54|       |    config: BootstrapConfig,
   55|       |    /// Requests for accounts from database have much lower hitrate and could introduce strain on the network
   56|       |    /// A separate (lower) limiter ensures that we always reserve resources for querying accounts from priority queue
   57|       |    database_limiter: RateLimiter,
   58|       |    /// Rate limiter for frontier requests
   59|       |    frontiers_limiter: RateLimiter,
   60|       |    clock: Arc<SteadyClock>,
   61|       |    workers: ThreadPoolImpl,
   62|       |}
   63|       |
   64|       |struct Threads {
   65|       |    cleanup: JoinHandle<()>,
   66|       |    priorities: Option<JoinHandle<()>>,
   67|       |    database: Option<JoinHandle<()>>,
   68|       |    dependencies: Option<JoinHandle<()>>,
   69|       |    frontiers: Option<JoinHandle<()>>,
   70|       |}
   71|       |
   72|       |impl Bootstrapper {
   73|      3|    pub(crate) fn new(
   74|      3|        block_processor: Arc<BlockProcessor>,
   75|      3|        notifications: LedgerNotifications,
   76|      3|        ledger: Arc<Ledger>,
   77|      3|        stats: Arc<Stats>,
   78|      3|        network: Arc<RwLock<Network>>,
   79|      3|        message_sender: MessageSender,
   80|      3|        config: BootstrapConfig,
   81|      3|        clock: Arc<SteadyClock>,
   82|      3|    ) -> Self {
   83|      3|        Self {
   84|      3|            block_processor,
   85|      3|            notifications,
   86|      3|            threads: Mutex::new(None),
   87|      3|            mutex: Arc::new(Mutex::new(BootstrapLogic {
   88|      3|                stopped: false,
   89|      3|                accounts: AccountSets::new(config.account_sets.clone()),
   90|      3|                scoring: PeerScoring::new(config.clone()),
   91|      3|                database_scan: DatabaseScan::new(ledger.clone()),
   92|      3|                frontiers: FrontierScan::new(config.frontier_scan.clone(), stats.clone()),
   93|      3|                running_queries: RunningQueryContainer::default(),
   94|      3|                throttle: Throttle::new(compute_throttle_size(
   95|      3|                    ledger.account_count(),
   96|      3|                    config.throttle_coefficient,
   97|      3|                )),
   98|      3|                sync_dependencies_interval: Instant::now(),
   99|      3|                config: config.clone(),
  100|      3|                network,
  101|      3|                limiter: RateLimiter::new(config.rate_limit),
  102|      3|            })),
  103|      3|            condition: Arc::new(Condvar::new()),
  104|      3|            database_limiter: RateLimiter::new(config.database_rate_limit),
  105|      3|            frontiers_limiter: RateLimiter::new(config.frontier_rate_limit),
  106|      3|            config,
  107|      3|            stats,
  108|      3|            ledger,
  109|      3|            message_sender: Mutex::new(message_sender),
  110|      3|            clock,
  111|      3|            workers: ThreadPoolImpl::create(1, "Bootstrap work"),
  112|      3|        }
  113|      3|    }
  114|       |
  115|      3|    pub fn stop(&self) {
  116|      3|        self.mutex.lock().unwrap().stopped = true;
  117|      3|        self.condition.notify_all();
  118|      3|        let threads = self.threads.lock().unwrap().take();
  119|      3|        if let Some(threads) = threads {
  120|      3|            if let Some(handle) = threads.priorities {
  121|      3|                handle.join().unwrap();
  122|      3|            }
                           ^0
  123|      3|            threads.cleanup.join().unwrap();
  124|      3|            if let Some(database) = threads.database {
                                      ^0
  125|      0|                database.join().unwrap();
  126|      3|            }
  127|      3|            if let Some(dependencies) = threads.dependencies {
  128|      3|                dependencies.join().unwrap();
  129|      3|            }
                           ^0
  130|      3|            if let Some(frontiers) = threads.frontiers {
  131|      3|                frontiers.join().unwrap();
  132|      3|            }
                           ^0
  133|      0|        }
  134|      3|    }
  135|       |
  136|      0|    fn send(&self, channel_id: ChannelId, request: &Message, id: u64) -> bool {
  137|      0|        let sent = self.message_sender.lock().unwrap().try_send(
  138|      0|            channel_id,
  139|      0|            &request,
  140|      0|            TrafficType::BootstrapRequests,
  141|      0|        );
  142|      0|
  143|      0|        if sent {
  144|      0|            self.stats.inc(StatType::Bootstrap, DetailType::Request);
  145|      0|            let query_type = QueryType::from(request);
  146|      0|            self.stats
  147|      0|                .inc(StatType::BootstrapRequest, query_type.into());
  148|      0|        } else {
  149|      0|            self.stats
  150|      0|                .inc(StatType::Bootstrap, DetailType::RequestFailed);
  151|      0|        }
  152|       |
  153|      0|        let mut guard = self.mutex.lock().unwrap();
  154|      0|        if sent {
  155|      0|            guard.running_queries.modify(id, |query| {
  156|      0|                // After the request has been sent, the peer has a limited time to respond
  157|      0|                query.cutoff = self.clock.now() + self.config.request_timeout;
  158|      0|            });
  159|      0|        } else {
  160|      0|            guard.running_queries.remove(id);
  161|      0|        }
  162|       |
  163|      0|        sent
  164|      0|    }
  165|       |
  166|      0|    fn create_asc_pull_request(&self, query: &RunningQuery) -> Message {
  167|      0|        debug_assert!(query.source != QuerySource::Invalid);
  168|       |
  169|       |        {
  170|      0|            let mut guard = self.mutex.lock().unwrap();
  171|      0|            debug_assert!(!guard.running_queries.contains(query.id));
  172|      0|            guard.running_queries.insert(query.clone());
  173|       |        }
  174|       |
  175|      0|        let req_type = match query.query_type {
  176|       |            QueryType::BlocksByHash | QueryType::BlocksByAccount => {
  177|      0|                let start_type = if query.query_type == QueryType::BlocksByHash {
  178|      0|                    HashType::Block
  179|       |                } else {
  180|      0|                    HashType::Account
  181|       |                };
  182|       |
  183|      0|                AscPullReqType::Blocks(BlocksReqPayload {
  184|      0|                    start_type,
  185|      0|                    start: query.start,
  186|      0|                    count: query.count as u8,
  187|      0|                })
  188|       |            }
  189|      0|            QueryType::AccountInfoByHash => AscPullReqType::AccountInfo(AccountInfoReqPayload {
  190|      0|                target: query.start,
  191|      0|                target_type: HashType::Block, // Query account info by block hash
  192|      0|            }),
  193|      0|            QueryType::Invalid => panic!("invalid query type"),
  194|       |            QueryType::Frontiers => {
  195|      0|                AscPullReqType::Frontiers(rsnano_messages::FrontiersReqPayload {
  196|      0|                    start: query.start.into(),
  197|      0|                    count: FrontiersReqPayload::MAX_FRONTIERS,
  198|      0|                })
  199|       |            }
  200|       |        };
  201|       |
  202|      0|        Message::AscPullReq(AscPullReq {
  203|      0|            id: query.id,
  204|      0|            req_type,
  205|      0|        })
  206|      0|    }
  207|       |
  208|      0|    pub fn priority_len(&self) -> usize {
  209|      0|        self.mutex.lock().unwrap().accounts.priority_len()
  210|      0|    }
  211|       |
  212|      0|    pub fn blocked_len(&self) -> usize {
  213|      0|        self.mutex.lock().unwrap().accounts.blocked_len()
  214|      0|    }
  215|       |
  216|      0|    pub fn score_len(&self) -> usize {
  217|      0|        self.mutex.lock().unwrap().scoring.len()
  218|      0|    }
  219|       |
  220|      0|    pub fn prioritized(&self, account: &Account) -> bool {
  221|      0|        self.mutex.lock().unwrap().accounts.prioritized(account)
  222|      0|    }
  223|       |
  224|      0|    pub fn blocked(&self, account: &Account) -> bool {
  225|      0|        self.mutex.lock().unwrap().accounts.blocked(account)
  226|      0|    }
  227|       |
  228|       |    /* Waits for a condition to be satisfied with incremental backoff */
  229|     39|    fn wait(&self, mut predicate: impl FnMut(&mut BootstrapLogic) -> bool) {
  230|     39|        let mut guard = self.mutex.lock().unwrap();
  231|     39|        let mut interval = Duration::from_millis(5);
  232|     54|        while !guard.stopped && !predicate(&mut guard) {
                                              ^45
  233|     15|            guard = self
  234|     15|                .condition
  235|     30|                .wait_timeout_while(guard, interval, |g| !g.stopped)
  236|     15|                .unwrap()
  237|     15|                .0;
  238|     15|            interval = min(interval * 2, self.config.throttle_wait);
  239|       |        }
  240|     39|    }
  241|       |
  242|       |    /* Ensure there is enough space in blockprocessor for queuing new blocks */
  243|      3|    fn wait_blockprocessor(&self) {
  244|      3|        self.wait(|_| {
  245|      3|            self.block_processor.queue_len(BlockSource::Bootstrap)
  246|      3|                < self.config.block_processor_theshold
  247|      3|        });
  248|      3|    }
  249|       |
  250|       |    /* Waits for a channel that is not full */
  251|      9|    fn wait_channel(&self) -> Option<ChannelId> {
  252|      9|        // Limit the number of in-flight requests
  253|      9|        self.wait(|l| l.running_queries.len() < l.config.max_requests);
  254|      9|
  255|      9|        // Wait until more requests can be sent
  256|      9|        self.wait(|l| l.limiter.should_pass(1));
  257|      9|
  258|      9|        // Wait until a channel is available
  259|      9|
  260|      9|        let mut channel_id: Option<ChannelId> = None;
  261|     15|        self.wait(|i| {
  262|     15|            channel_id = i.scoring.channel().map(|c| c.channel_id());
                                                                   ^0
  263|     15|            channel_id.is_some() // Wait until a channel is available
  264|     15|        });
  265|      9|
  266|      9|        channel_id
  267|      9|    }
  268|       |
  269|      0|    fn wait_priority(&self) -> PriorityResult {
  270|      0|        let mut result = PriorityResult::default();
  271|      0|        self.wait(|i| {
  272|      0|            result = i.next_priority(&self.stats, self.clock.now());
  273|      0|            !result.account.is_zero()
  274|      0|        });
  275|      0|        result
  276|      0|    }
  277|       |
  278|      0|    fn wait_database(&self, should_throttle: bool) -> Account {
  279|      0|        let mut result = Account::zero();
  280|      0|        self.wait(|i| {
  281|      0|            result = i.next_database(
  282|      0|                should_throttle,
  283|      0|                &self.database_limiter,
  284|      0|                &self.stats,
  285|      0|                self.config.database_warmup_ratio,
  286|      0|            );
  287|      0|            !result.is_zero()
  288|      0|        });
  289|      0|
  290|      0|        result
  291|      0|    }
  292|       |
  293|      0|    fn wait_blocking(&self) -> BlockHash {
  294|      0|        let mut result = BlockHash::zero();
  295|      0|        self.wait(|i| {
  296|      0|            result = i.next_blocking(&self.stats);
  297|      0|            !result.is_zero()
  298|      0|        });
  299|      0|        result
  300|      0|    }
  301|       |
  302|      0|    fn request(
  303|      0|        &self,
  304|      0|        account: Account,
  305|      0|        count: usize,
  306|      0|        channel_id: ChannelId,
  307|      0|        source: QuerySource,
  308|      0|    ) -> bool {
  309|      0|        let account_info = {
  310|      0|            let tx = self.ledger.read_txn();
  311|      0|            self.ledger.store.account.get(&tx, &account)
  312|      0|        };
  313|      0|        let id = thread_rng().next_u64();
  314|      0|        let now = self.clock.now();
  315|      0|
  316|      0|        let request = self.create_blocks_request(id, account, account_info, count, source, now);
  317|      0|
  318|      0|        self.send(channel_id, &request, id)
  319|      0|    }
  320|       |
  321|      0|    fn create_blocks_request(
  322|      0|        &self,
  323|      0|        id: u64,
  324|      0|        account: Account,
  325|      0|        account_info: Option<AccountInfo>,
  326|      0|        count: usize,
  327|      0|        source: QuerySource,
  328|      0|        now: Timestamp,
  329|      0|    ) -> Message {
  330|      0|        // Limit the max number of blocks to pull
  331|      0|        debug_assert!(count > 0);
  332|      0|        debug_assert!(count <= BootstrapResponder::MAX_BLOCKS);
  333|      0|        let count = min(count, self.config.max_pull_count);
  334|      0|
  335|      0|        let tx = self.ledger.read_txn();
  336|       |        // Check if the account picked has blocks, if it does, start the pull from the highest block
  337|      0|        let (query_type, start, hash) = match account_info {
  338|      0|            Some(info) => {
  339|      0|                // Probabilistically choose between requesting blocks from account frontier or confirmed frontier
  340|      0|                // Optimistic requests start from the (possibly unconfirmed) account frontier and are vulnerable to bootstrap poisoning
  341|      0|                // Safe requests start from the confirmed frontier and given enough time will eventually resolve forks
  342|      0|                let optimistic_request =
  343|      0|                    thread_rng().gen_range(0..100) < self.config.optimistic_request_percentage;
  344|      0|
  345|      0|                if optimistic_request {
  346|      0|                    self.stats
  347|      0|                        .inc(StatType::BootstrapRequestBlocks, DetailType::Optimistic);
  348|      0|                    (
  349|      0|                        QueryType::BlocksByHash,
  350|      0|                        HashOrAccount::from(info.head),
  351|      0|                        info.head,
  352|      0|                    )
  353|       |                } else {
  354|       |                    // Pessimistic (safe) request case
  355|      0|                    self.stats
  356|      0|                        .inc(StatType::BootstrapRequestBlocks, DetailType::Safe);
  357|      0|
  358|      0|                    let conf_info = self.ledger.store.confirmation_height.get(&tx, &account);
  359|      0|                    if let Some(conf_info) = conf_info {
  360|      0|                        (
  361|      0|                            QueryType::BlocksByHash,
  362|      0|                            HashOrAccount::from(conf_info.frontier),
  363|      0|                            BlockHash::from(conf_info.height),
  364|      0|                        )
  365|       |                    } else {
  366|      0|                        (
  367|      0|                            QueryType::BlocksByAccount,
  368|      0|                            account.into(),
  369|      0|                            BlockHash::zero(),
  370|      0|                        )
  371|       |                    }
  372|       |                }
  373|       |            }
  374|       |            None => {
  375|      0|                self.stats
  376|      0|                    .inc(StatType::BootstrapRequestBlocks, DetailType::Base);
  377|      0|                (
  378|      0|                    QueryType::BlocksByAccount,
  379|      0|                    HashOrAccount::from(account),
  380|      0|                    BlockHash::zero(),
  381|      0|                )
  382|       |            }
  383|       |        };
  384|       |
  385|      0|        let query = RunningQuery {
  386|      0|            id,
  387|      0|            account,
  388|      0|            timestamp: now,
  389|      0|            cutoff: now + self.config.request_timeout * 4,
  390|      0|            query_type,
  391|      0|            start,
  392|      0|            source,
  393|      0|            hash,
  394|      0|            count,
  395|      0|        };
  396|      0|
  397|      0|        self.create_asc_pull_request(&query)
  398|      0|    }
  399|       |
  400|      0|    fn create_account_info_request(
  401|      0|        &self,
  402|      0|        id: u64,
  403|      0|        hash: BlockHash,
  404|      0|        source: QuerySource,
  405|      0|        now: Timestamp,
  406|      0|    ) -> Message {
  407|      0|        let query = RunningQuery {
  408|      0|            query_type: QueryType::AccountInfoByHash,
  409|      0|            source,
  410|      0|            start: hash.into(),
  411|      0|            account: Account::zero(),
  412|      0|            hash,
  413|      0|            count: 0,
  414|      0|            id,
  415|      0|            cutoff: now + self.config.request_timeout * 4,
  416|      0|            timestamp: now,
  417|      0|        };
  418|      0|
  419|      0|        self.create_asc_pull_request(&query)
  420|      0|    }
  421|       |
  422|      3|    fn run_one_priority(&self) {
  423|      3|        self.wait_blockprocessor();
  424|      3|        let Some(channel_id) = self.wait_channel() else {
                               ^0
  425|      3|            return;
  426|       |        };
  427|       |
  428|      0|        let result = self.wait_priority();
  429|      0|        if result.account.is_zero() {
  430|      0|            return;
  431|      0|        }
  432|      0|
  433|      0|        // Decide how many blocks to request
  434|      0|        let min_pull_count = 2;
  435|      0|        let pull_count = clamp(
  436|      0|            f64::from(result.priority) as usize,
  437|      0|            min_pull_count,
  438|      0|            BootstrapResponder::MAX_BLOCKS,
  439|      0|        );
  440|      0|
  441|      0|        let sent = self.request(
  442|      0|            result.account,
  443|      0|            pull_count,
  444|      0|            channel_id,
  445|      0|            QuerySource::Priority,
  446|      0|        );
  447|      0|
  448|      0|        // Only cooldown accounts that are likely to have more blocks
  449|      0|        // This is to avoid requesting blocks from the same frontier multiple times, before the block processor had a chance to process them
  450|      0|        // Not throttling accounts that are probably up-to-date allows us to evict them from the priority set faster
  451|      0|        if sent && result.fails == 0 {
  452|      0|            self.mutex
  453|      0|                .lock()
  454|      0|                .unwrap()
  455|      0|                .accounts
  456|      0|                .timestamp_set(&result.account, self.clock.now());
  457|      0|        }
  458|      3|    }
  459|       |
  460|      3|    fn run_priorities(&self) {
  461|      3|        let mut guard = self.mutex.lock().unwrap();
  462|      6|        while !guard.stopped {
  463|      3|            drop(guard);
  464|      3|            self.stats.inc(StatType::Bootstrap, DetailType::Loop);
  465|      3|            self.run_one_priority();
  466|      3|            guard = self.mutex.lock().unwrap();
  467|      3|        }
  468|      3|    }
  469|       |
  470|      0|    fn run_one_database(&self, should_throttle: bool) {
  471|      0|        self.wait_blockprocessor();
  472|      0|        let Some(channel_id) = self.wait_channel() else {
  473|      0|            return;
  474|       |        };
  475|      0|        let account = self.wait_database(should_throttle);
  476|      0|        if account.is_zero() {
  477|      0|            return;
  478|      0|        }
  479|      0|        self.request(account, 2, channel_id, QuerySource::Database);
  480|      0|    }
  481|       |
  482|      0|    fn run_database(&self) {
  483|      0|        let mut guard = self.mutex.lock().unwrap();
  484|      0|        while !guard.stopped {
  485|       |            // Avoid high churn rate of database requests
  486|      0|            let should_throttle = !guard.database_scan.warmed_up() && guard.throttle.throttled();
  487|      0|            drop(guard);
  488|      0|            self.stats
  489|      0|                .inc(StatType::Bootstrap, DetailType::LoopDatabase);
  490|      0|            self.run_one_database(should_throttle);
  491|      0|            guard = self.mutex.lock().unwrap();
  492|       |        }
  493|      0|    }
  494|       |
  495|      3|    fn run_one_dependency(&self) {
  496|       |        // No need to wait for blockprocessor, as we are not processing blocks
  497|      3|        let Some(channel_id) = self.wait_channel() else {
                               ^0
  498|      3|            return;
  499|       |        };
  500|      0|        let blocking = self.wait_blocking();
  501|      0|        if blocking.is_zero() {
  502|      0|            return;
  503|      0|        }
  504|      0|
  505|      0|        let now = self.clock.now();
  506|      0|        let id = thread_rng().next_u64();
  507|      0|        let request =
  508|      0|            self.create_account_info_request(id, blocking, QuerySource::Dependencies, now);
  509|      0|
  510|      0|        self.send(channel_id, &request, id);
  511|      3|    }
  512|       |
  513|      3|    fn run_frontiers(&self) {
  514|      3|        let mut guard = self.mutex.lock().unwrap();
  515|      6|        while !guard.stopped {
  516|      3|            drop(guard);
  517|      3|
  518|      3|            self.stats
  519|      3|                .inc(StatType::Bootstrap, DetailType::LoopFrontiers);
  520|      3|            self.run_one_frontier();
  521|      3|
  522|      3|            guard = self.mutex.lock().unwrap();
  523|      3|        }
  524|      3|    }
  525|       |
  526|      3|    fn run_one_frontier(&self) {
  527|      3|        // No need to wait for blockprocessor, as we are not processing blocks
  528|      3|        self.wait(|i| !i.accounts.priority_half_full());
  529|      3|        self.wait(|_| self.frontiers_limiter.should_pass(1));
  530|      3|        self.wait(|_| self.workers.num_queued_tasks() < self.config.frontier_scan.max_pending);
  531|      3|        let Some(channel) = self.wait_channel() else {
                               ^0
  532|      3|            return;
  533|       |        };
  534|      0|        let frontier = self.wait_frontier();
  535|      0|        if frontier.is_zero() {
  536|      0|            return;
  537|      0|        }
  538|      0|        self.request_frontiers(frontier, channel, QuerySource::Frontiers);
  539|      3|    }
  540|       |
  541|      0|    fn request_frontiers(&self, start: Account, channel: ChannelId, source: QuerySource) {
  542|      0|        let id = thread_rng().next_u64();
  543|      0|        let timestamp = self.clock.now();
  544|      0|        let query = RunningQuery {
  545|      0|            query_type: QueryType::Frontiers,
  546|      0|            source,
  547|      0|            start: start.into(),
  548|      0|            account: Account::zero(),
  549|      0|            hash: BlockHash::zero(),
  550|      0|            count: 0,
  551|      0|            id,
  552|      0|            cutoff: timestamp + self.config.request_timeout * 4,
  553|      0|            timestamp,
  554|      0|        };
  555|      0|        let message = self.create_asc_pull_request(&query);
  556|      0|        self.send(channel, &message, id);
  557|      0|    }
  558|       |
  559|      0|    fn wait_frontier(&self) -> Account {
  560|      0|        let mut result = Account::zero();
  561|      0|        self.wait(|i| {
  562|      0|            result = i.frontiers.next(self.clock.now());
  563|      0|            if !result.is_zero() {
  564|      0|                self.stats
  565|      0|                    .inc(StatType::BootstrapNext, DetailType::NextFrontier);
  566|      0|                true
  567|       |            } else {
  568|      0|                false
  569|       |            }
  570|      0|        });
  571|      0|
  572|      0|        result
  573|      0|    }
  574|       |
  575|      3|    fn run_dependencies(&self) {
  576|      3|        let mut guard = self.mutex.lock().unwrap();
  577|      6|        while !guard.stopped {
  578|      3|            drop(guard);
  579|      3|            self.stats
  580|      3|                .inc(StatType::Bootstrap, DetailType::LoopDependencies);
  581|      3|            self.run_one_dependency();
  582|      3|            guard = self.mutex.lock().unwrap();
  583|      3|        }
  584|      3|    }
  585|       |
  586|      3|    fn run_timeouts(&self) {
  587|      3|        let mut guard = self.mutex.lock().unwrap();
  588|      6|        while !guard.stopped {
  589|      3|            self.stats.inc(StatType::Bootstrap, DetailType::LoopCleanup);
  590|      3|
  591|      3|            guard.cleanup_and_sync(self.ledger.account_count(), &self.stats, self.clock.now());
  592|      3|
  593|      3|            guard = self
  594|      3|                .condition
  595|      6|                .wait_timeout_while(guard, Duration::from_secs(1), |g| !g.stopped)
  596|      3|                .unwrap()
  597|      3|                .0;
  598|       |        }
  599|      3|    }
  600|       |
  601|       |    /// Process `asc_pull_ack` message coming from network
  602|      0|    pub fn process(&self, message: AscPullAck, channel_id: ChannelId) {
  603|      0|        let mut guard = self.mutex.lock().unwrap();
  604|       |
  605|       |        // Only process messages that have a known tag
  606|      0|        let Some(tag) = guard.running_queries.remove(message.id) else {
  607|      0|            self.stats.inc(StatType::Bootstrap, DetailType::MissingTag);
  608|      0|            return;
  609|       |        };
  610|       |
  611|      0|        self.stats.inc(StatType::Bootstrap, DetailType::Reply);
  612|       |
  613|      0|        let valid = match message.pull_type {
  614|      0|            AscPullAckType::Blocks(_) => matches!(
  615|      0|                tag.query_type,
  616|       |                QueryType::BlocksByHash | QueryType::BlocksByAccount
  617|       |            ),
  618|      0|            AscPullAckType::AccountInfo(_) => tag.query_type == QueryType::AccountInfoByHash,
  619|      0|            AscPullAckType::Frontiers(_) => tag.query_type == QueryType::Frontiers,
  620|       |        };
  621|       |
  622|      0|        if !valid {
  623|      0|            self.stats
  624|      0|                .inc(StatType::Bootstrap, DetailType::InvalidResponseType);
  625|      0|            return;
  626|      0|        }
  627|      0|
  628|      0|        // Track bootstrap request response time
  629|      0|        self.stats
  630|      0|            .inc(StatType::BootstrapReply, tag.query_type.into());
  631|      0|
  632|      0|        self.stats.sample(
  633|      0|            Sample::BootstrapTagDuration,
  634|      0|            tag.timestamp.elapsed(self.clock.now()).as_millis() as i64,
  635|      0|            (0, self.config.request_timeout.as_millis() as i64),
  636|      0|        );
  637|      0|
  638|      0|        drop(guard);
  639|       |
  640|       |        // Process the response payload
  641|      0|        let ok = match message.pull_type {
  642|      0|            AscPullAckType::Blocks(blocks) => self.process_blocks(&blocks, &tag),
  643|      0|            AscPullAckType::AccountInfo(info) => self.process_accounts(&info, &tag),
  644|      0|            AscPullAckType::Frontiers(frontiers) => self.process_frontiers(frontiers, &tag),
  645|       |        };
  646|       |
  647|      0|        if ok {
  648|      0|            self.mutex
  649|      0|                .lock()
  650|      0|                .unwrap()
  651|      0|                .scoring
  652|      0|                .received_message(channel_id);
  653|      0|        } else {
  654|      0|            self.stats
  655|      0|                .inc(StatType::Bootstrap, DetailType::InvalidResponse);
  656|      0|        }
  657|       |
  658|      0|        self.condition.notify_all();
  659|      0|    }
  660|       |
  661|      0|    fn process_frontiers(&self, frontiers: Vec<Frontier>, query: &RunningQuery) -> bool {
  662|      0|        debug_assert_eq!(query.query_type, QueryType::Frontiers);
  663|      0|        debug_assert!(!query.start.is_zero());
  664|       |
  665|      0|        if frontiers.is_empty() {
  666|      0|            self.stats
  667|      0|                .inc(StatType::BootstrapProcess, DetailType::FrontiersEmpty);
  668|      0|            // OK, but nothing to do
  669|      0|            return true;
  670|      0|        }
  671|      0|
  672|      0|        self.stats
  673|      0|            .inc(StatType::BootstrapProcess, DetailType::Frontiers);
  674|      0|
  675|      0|        let result = self.verify_frontiers(&frontiers, query);
  676|      0|        match result {
  677|       |            VerifyResult::Ok => {
  678|      0|                self.stats
  679|      0|                    .inc(StatType::BootstrapVerifyFrontiers, DetailType::Ok);
  680|      0|                self.stats.add_dir(
  681|      0|                    StatType::Bootstrap,
  682|      0|                    DetailType::Frontiers,
  683|      0|                    Direction::In,
  684|      0|                    frontiers.len() as u64,
  685|      0|                );
  686|      0|
  687|      0|                {
  688|      0|                    let mut guard = self.mutex.lock().unwrap();
  689|      0|                    guard.frontiers.process(query.start.into(), &frontiers);
  690|      0|                }
  691|      0|
  692|      0|                // Allow some overfill to avoid unnecessarily dropping responses
  693|      0|                if self.workers.num_queued_tasks() < self.config.frontier_scan.max_pending * 4 {
  694|      0|                    let stats = self.stats.clone();
  695|      0|                    let ledger = self.ledger.clone();
  696|      0|                    let mutex = self.mutex.clone();
  697|      0|                    self.workers.post(Box::new(move || {
  698|      0|                        process_frontiers(ledger, stats, frontiers, mutex)
  699|      0|                    }));
  700|      0|                } else {
  701|      0|                    self.stats.add(
  702|      0|                        StatType::Bootstrap,
  703|      0|                        DetailType::FrontiersDropped,
  704|      0|                        frontiers.len() as u64,
  705|      0|                    );
  706|      0|                }
  707|      0|                true
  708|       |            }
  709|       |            VerifyResult::NothingNew => {
  710|      0|                self.stats
  711|      0|                    .inc(StatType::BootstrapVerifyFrontiers, DetailType::NothingNew);
  712|      0|                true
  713|       |            }
  714|       |            VerifyResult::Invalid => {
  715|      0|                self.stats
  716|      0|                    .inc(StatType::BootstrapVerifyFrontiers, DetailType::Invalid);
  717|      0|                false
  718|       |            }
  719|       |        }
  720|      0|    }
  721|       |
  722|      0|    fn verify_frontiers(&self, frontiers: &[Frontier], query: &RunningQuery) -> VerifyResult {
  723|      0|        if frontiers.is_empty() {
  724|      0|            return VerifyResult::NothingNew;
  725|      0|        }
  726|      0|
  727|      0|        // Ensure frontiers accounts are in ascending order
  728|      0|        let mut previous = Account::zero();
  729|      0|        for f in frontiers {
  730|      0|            if f.account.number() <= previous.number() {
  731|      0|                return VerifyResult::Invalid;
  732|      0|            }
  733|      0|            previous = f.account;
  734|       |        }
  735|       |
  736|       |        // Ensure the frontiers are larger or equal to the requested frontier
  737|      0|        if frontiers[0].account.number() < query.start.number() {
  738|      0|            return VerifyResult::Invalid;
  739|      0|        }
  740|      0|
  741|      0|        VerifyResult::Ok
  742|      0|    }
  743|       |
  744|      0|    fn process_blocks(&self, response: &BlocksAckPayload, query: &RunningQuery) -> bool {
  745|      0|        self.stats
  746|      0|            .inc(StatType::BootstrapProcess, DetailType::Blocks);
  747|      0|
  748|      0|        let result = verify_response(response, query);
  749|      0|        match result {
  750|       |            VerifyResult::Ok => {
  751|      0|                self.stats
  752|      0|                    .inc(StatType::BootstrapVerifyBlocks, DetailType::Ok);
  753|      0|                self.stats.add_dir(
  754|      0|                    StatType::Bootstrap,
  755|      0|                    DetailType::Blocks,
  756|      0|                    Direction::In,
  757|      0|                    response.blocks().len() as u64,
  758|      0|                );
  759|      0|
  760|      0|                let mut blocks = response.blocks().clone();
  761|      0|
  762|      0|                // Avoid re-processing the block we already have
  763|      0|                assert!(blocks.len() >= 1);
  764|      0|                if blocks.front().unwrap().hash() == query.start.into() {
  765|      0|                    blocks.pop_front();
  766|      0|                }
  767|       |
  768|      0|                while let Some(block) = blocks.pop_front() {
  769|      0|                    if blocks.is_empty() {
  770|      0|                        // It's the last block submitted for this account chain, reset timestamp to allow more requests
  771|      0|                        let stats = self.stats.clone();
  772|      0|                        let data = self.mutex.clone();
  773|      0|                        let condition = self.condition.clone();
  774|      0|                        let account = query.account;
  775|      0|                        self.block_processor.add_with_callback(
  776|      0|                            block,
  777|      0|                            BlockSource::Bootstrap,
  778|      0|                            ChannelId::LOOPBACK,
  779|      0|                            Box::new(move |_| {
  780|      0|                                stats.inc(StatType::Bootstrap, DetailType::TimestampReset);
  781|      0|                                {
  782|      0|                                    let mut guard = data.lock().unwrap();
  783|      0|                                    guard.accounts.timestamp_reset(&account);
  784|      0|                                }
  785|      0|                                condition.notify_all();
  786|      0|                            }),
  787|      0|                        );
  788|      0|                    } else {
  789|      0|                        self.block_processor.add(
  790|      0|                            block,
  791|      0|                            BlockSource::Bootstrap,
  792|      0|                            ChannelId::LOOPBACK,
  793|      0|                        );
  794|      0|                    }
  795|       |                }
  796|       |
  797|      0|                if query.source == QuerySource::Database {
  798|      0|                    self.mutex.lock().unwrap().throttle.add(true);
  799|      0|                }
  800|      0|                true
  801|       |            }
  802|       |            VerifyResult::NothingNew => {
  803|      0|                self.stats
  804|      0|                    .inc(StatType::BootstrapVerifyBlocks, DetailType::NothingNew);
  805|      0|
  806|      0|                {
  807|      0|                    let mut guard = self.mutex.lock().unwrap();
  808|      0|                    match guard.accounts.priority_down(&query.account) {
  809|      0|                        PriorityDownResult::Deprioritized => {
  810|      0|                            self.stats
  811|      0|                                .inc(StatType::BootstrapAccountSets, DetailType::Deprioritize);
  812|      0|                        }
  813|      0|                        PriorityDownResult::Erased => {
  814|      0|                            self.stats
  815|      0|                                .inc(StatType::BootstrapAccountSets, DetailType::Deprioritize);
  816|      0|                            self.stats.inc(
  817|      0|                                StatType::BootstrapAccountSets,
  818|      0|                                DetailType::PriorityEraseThreshold,
  819|      0|                            );
  820|      0|                        }
  821|      0|                        PriorityDownResult::AccountNotFound => {
  822|      0|                            self.stats.inc(
  823|      0|                                StatType::BootstrapAccountSets,
  824|      0|                                DetailType::DeprioritizeFailed,
  825|      0|                            );
  826|      0|                        }
  827|      0|                        PriorityDownResult::InvalidAccount => {}
  828|       |                    }
  829|       |
  830|      0|                    guard.accounts.timestamp_reset(&query.account);
  831|      0|
  832|      0|                    if query.source == QuerySource::Database {
  833|      0|                        guard.throttle.add(false);
  834|      0|                    }
  835|       |                }
  836|      0|                self.condition.notify_all();
  837|      0|                true
  838|       |            }
  839|       |            VerifyResult::Invalid => {
  840|      0|                self.stats
  841|      0|                    .inc(StatType::BootstrapVerifyBlocks, DetailType::Invalid);
  842|      0|                false
  843|       |            }
  844|       |        }
  845|      0|    }
  846|       |
  847|      0|    fn process_accounts(&self, response: &AccountInfoAckPayload, query: &RunningQuery) -> bool {
  848|      0|        if response.account.is_zero() {
  849|      0|            self.stats
  850|      0|                .inc(StatType::BootstrapProcess, DetailType::AccountInfoEmpty);
  851|      0|            // OK, but nothing to do
  852|      0|            return true;
  853|      0|        }
  854|      0|
  855|      0|        self.stats
  856|      0|            .inc(StatType::BootstrapProcess, DetailType::AccountInfo);
  857|      0|
  858|      0|        // Prioritize account containing the dependency
  859|      0|        {
  860|      0|            let mut guard = self.mutex.lock().unwrap();
  861|      0|            let updated = guard
  862|      0|                .accounts
  863|      0|                .dependency_update(&query.hash, response.account);
  864|      0|            if updated > 0 {
  865|      0|                self.stats.add(
  866|      0|                    StatType::BootstrapAccountSets,
  867|      0|                    DetailType::DependencyUpdate,
  868|      0|                    updated as u64,
  869|      0|                );
  870|      0|            } else {
  871|      0|                self.stats.inc(
  872|      0|                    StatType::BootstrapAccountSets,
  873|      0|                    DetailType::DependencyUpdateFailed,
  874|      0|                );
  875|      0|            }
  876|       |
  877|      0|            if guard
  878|      0|                .accounts
  879|      0|                .priority_set(&response.account, AccountSets::PRIORITY_CUTOFF)
  880|      0|            {
  881|      0|                self.priority_inserted();
  882|      0|            } else {
  883|      0|                self.priority_insertion_failed()
  884|       |            };
  885|       |        }
  886|       |        // OK, no way to verify the response
  887|      0|        true
  888|      0|    }
  889|       |
  890|      3|    fn priority_inserted(&self) {
  891|      3|        self.stats
  892|      3|            .inc(StatType::BootstrapAccountSets, DetailType::PriorityInsert);
  893|      3|    }
  894|       |
  895|      0|    fn priority_insertion_failed(&self) {
  896|      0|        self.stats
  897|      0|            .inc(StatType::BootstrapAccountSets, DetailType::PrioritizeFailed);
  898|      0|    }
  899|       |
  900|      0|    fn batch_processed(&self, batch: &[(BlockStatus, Arc<BlockContext>)]) {
  901|      0|        {
  902|      0|            let mut guard = self.mutex.lock().unwrap();
  903|      0|            let tx = self.ledger.read_txn();
  904|      0|            for (result, context) in batch {
  905|      0|                let block = context.block.lock().unwrap().clone();
  906|      0|                let saved_block = context.saved_block.lock().unwrap().clone();
  907|      0|                let account = block.account_field().unwrap_or_else(|| {
  908|      0|                    self.ledger
  909|      0|                        .any()
  910|      0|                        .block_account(&tx, &block.previous())
  911|      0|                        .unwrap_or_default()
  912|      0|                });
  913|      0|
  914|      0|                guard.inspect(
  915|      0|                    &self.stats,
  916|      0|                    *result,
  917|      0|                    &block,
  918|      0|                    saved_block,
  919|      0|                    context.source,
  920|      0|                    &account,
  921|      0|                );
  922|      0|            }
  923|       |        }
  924|       |
  925|      0|        self.condition.notify_all();
  926|      0|    }
  927|       |
  928|      0|    pub fn container_info(&self) -> ContainerInfo {
  929|      0|        self.mutex
  930|      0|            .lock()
  931|      0|            .unwrap()
  932|      0|            .container_info(&self.database_limiter, &self.frontiers_limiter)
  933|      0|    }
  934|       |}
  935|       |
  936|       |impl Drop for Bootstrapper {
  937|      3|    fn drop(&mut self) {
  938|      3|        // All threads must be stopped before destruction
  939|      3|        debug_assert!(self.threads.lock().unwrap().is_none());
  940|      3|    }
  941|       |}
  942|       |
  943|       |pub trait BootstrapExt {
  944|       |    fn initialize(&self, genesis_account: &Account);
  945|       |    fn start(&self);
  946|       |}
  947|       |
  948|       |impl BootstrapExt for Arc<Bootstrapper> {
  949|      3|    fn initialize(&self, genesis_account: &Account) {
  950|      3|        let self_w = Arc::downgrade(self);
  951|      3|        // Inspect all processed blocks
  952|      3|        self.notifications
  953|      3|            .on_blocks_processed(Box::new(move |batch| {
                                                                     ^0
  954|      0|                if let Some(self_l) = self_w.upgrade() {
  955|      0|                    self_l.batch_processed(batch);
  956|      0|                }
  957|      3|            }));
                          ^0
  958|      3|
  959|      3|        // Unblock rolled back accounts as the dependency is no longer valid
  960|      3|        let self_w = Arc::downgrade(self);
  961|      3|        self.notifications
  962|      3|            .on_blocks_rolled_back(move |blocks, _rollback_root| {
                                                                               ^0
  963|      0|                let Some(self_l) = self_w.upgrade() else {
  964|      0|                    return;
  965|       |                };
  966|      0|                let mut guard = self_l.mutex.lock().unwrap();
  967|      0|                for block in blocks {
  968|      0|                    guard.accounts.unblock(block.account(), None);
  969|      0|                }
  970|      3|            });
                          ^0
  971|      3|
  972|      3|        let inserted = self
  973|      3|            .mutex
  974|      3|            .lock()
  975|      3|            .unwrap()
  976|      3|            .accounts
  977|      3|            .priority_set_initial(genesis_account);
  978|      3|
  979|      3|        if inserted {
  980|      3|            self.priority_inserted()
  981|       |        } else {
  982|      0|            self.priority_insertion_failed()
  983|       |        };
  984|      3|    }
  985|       |
  986|      3|    fn start(&self) {
  987|      3|        debug_assert!(self.threads.lock().unwrap().is_none());
  988|       |
  989|      3|        if !self.config.enable {
  990|      0|            warn!("Ascending bootstrap is disabled");
  991|      0|            return;
  992|      3|        }
  993|       |
  994|      3|        let priorities = if self.config.enable_scan {
  995|      3|            let self_l = Arc::clone(self);
  996|      3|            Some(
  997|      3|                std::thread::Builder::new()
  998|      3|                    .name("Bootstrap".to_string())
  999|      3|                    .spawn(Box::new(move || self_l.run_priorities()))
 1000|      3|                    .unwrap(),
 1001|      3|            )
 1002|       |        } else {
 1003|      0|            None
 1004|       |        };
 1005|       |
 1006|      3|        let database = if self.config.enable_database_scan {
 1007|      0|            let self_l = Arc::clone(self);
 1008|      0|            Some(
 1009|      0|                std::thread::Builder::new()
 1010|      0|                    .name("Bootstrap db".to_string())
 1011|      0|                    .spawn(Box::new(move || self_l.run_database()))
 1012|      0|                    .unwrap(),
 1013|      0|            )
 1014|       |        } else {
 1015|      3|            None
 1016|       |        };
 1017|       |
 1018|      3|        let dependencies = if self.config.enable_dependency_walker {
 1019|      3|            let self_l = Arc::clone(self);
 1020|      3|            Some(
 1021|      3|                std::thread::Builder::new()
 1022|      3|                    .name("Bootstrap walkr".to_string())
 1023|      3|                    .spawn(Box::new(move || self_l.run_dependencies()))
 1024|      3|                    .unwrap(),
 1025|      3|            )
 1026|       |        } else {
 1027|      0|            None
 1028|       |        };
 1029|       |
 1030|      3|        let frontiers = if self.config.enable_frontier_scan {
 1031|      3|            let self_l = Arc::clone(self);
 1032|      3|            Some(
 1033|      3|                std::thread::Builder::new()
 1034|      3|                    .name("Bootstrap front".to_string())
 1035|      3|                    .spawn(Box::new(move || self_l.run_frontiers()))
 1036|      3|                    .unwrap(),
 1037|      3|            )
 1038|       |        } else {
 1039|      0|            None
 1040|       |        };
 1041|       |
 1042|      3|        let self_l = Arc::clone(self);
 1043|      3|        let timeout = std::thread::Builder::new()
 1044|      3|            .name("Bootstrap clean".to_string())
 1045|      3|            .spawn(Box::new(move || self_l.run_timeouts()))
 1046|      3|            .unwrap();
 1047|      3|
 1048|      3|        *self.threads.lock().unwrap() = Some(Threads {
 1049|      3|            cleanup: timeout,
 1050|      3|            priorities,
 1051|      3|            database,
 1052|      3|            frontiers,
 1053|      3|            dependencies,
 1054|      3|        });
 1055|      3|    }
 1056|       |}
 1057|       |
 1058|       |struct BootstrapLogic {
 1059|       |    stopped: bool,
 1060|       |    accounts: AccountSets,
 1061|       |    scoring: PeerScoring,
 1062|       |    database_scan: DatabaseScan,
 1063|       |    running_queries: RunningQueryContainer,
 1064|       |    throttle: Throttle,
 1065|       |    frontiers: FrontierScan,
 1066|       |    sync_dependencies_interval: Instant,
 1067|       |    config: BootstrapConfig,
 1068|       |    network: Arc<RwLock<Network>>,
 1069|       |    /// Rate limiter for all types of requests
 1070|       |    limiter: RateLimiter,
 1071|       |}
 1072|       |
 1073|       |impl BootstrapLogic {
 1074|       |    /// Inspects a block that has been processed by the block processor
 1075|       |    /// - Marks an account as blocked if the result code is gap source as there is no reason request additional blocks for this account until the dependency is resolved
 1076|       |    /// - Marks an account as forwarded if it has been recently referenced by a block that has been inserted.
 1077|      0|    fn inspect(
 1078|      0|        &mut self,
 1079|      0|        stats: &Stats,
 1080|      0|        status: BlockStatus,
 1081|      0|        block: &Block,
 1082|      0|        saved_block: Option<SavedBlock>,
 1083|      0|        source: BlockSource,
 1084|      0|        account: &Account,
 1085|      0|    ) {
 1086|      0|        let hash = block.hash();
 1087|      0|
 1088|      0|        match status {
 1089|       |            BlockStatus::Progress => {
 1090|       |                // Progress blocks from live traffic don't need further bootstrapping
 1091|      0|                if source != BlockSource::Live {
 1092|      0|                    let saved_block = saved_block.unwrap();
 1093|      0|                    let account = saved_block.account();
 1094|      0|                    // If we've inserted any block in to an account, unmark it as blocked
 1095|      0|                    if self.accounts.unblock(account, None) {
 1096|      0|                        stats.inc(StatType::BootstrapAccountSets, DetailType::Unblock);
 1097|      0|                        stats.inc(
 1098|      0|                            StatType::BootstrapAccountSets,
 1099|      0|                            DetailType::PriorityUnblocked,
 1100|      0|                        );
 1101|      0|                    } else {
 1102|      0|                        stats.inc(StatType::BootstrapAccountSets, DetailType::UnblockFailed);
 1103|      0|                    }
 1104|       |
 1105|      0|                    match self.accounts.priority_up(&account) {
 1106|      0|                        PriorityUpResult::Updated => {
 1107|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::Prioritize);
 1108|      0|                        }
 1109|      0|                        PriorityUpResult::Inserted => {
 1110|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::Prioritize);
 1111|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PriorityInsert);
 1112|      0|                        }
 1113|      0|                        PriorityUpResult::AccountBlocked => {
 1114|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PrioritizeFailed);
 1115|      0|                        }
 1116|      0|                        PriorityUpResult::InvalidAccount => {}
 1117|       |                    }
 1118|       |
 1119|      0|                    if saved_block.is_send() {
 1120|      0|                        let destination = saved_block.destination().unwrap();
 1121|      0|                        // Unblocking automatically inserts account into priority set
 1122|      0|                        if self.accounts.unblock(destination, Some(hash)) {
 1123|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::Unblock);
 1124|      0|                            stats.inc(
 1125|      0|                                StatType::BootstrapAccountSets,
 1126|      0|                                DetailType::PriorityUnblocked,
 1127|      0|                            );
 1128|      0|                        } else {
 1129|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::UnblockFailed);
 1130|      0|                        }
 1131|      0|                        if self.accounts.priority_set_initial(&destination) {
 1132|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PriorityInsert);
 1133|      0|                        } else {
 1134|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PrioritizeFailed);
 1135|      0|                        };
 1136|      0|                    }
 1137|      0|                }
 1138|       |            }
 1139|       |            BlockStatus::GapSource => {
 1140|       |                // Prevent malicious live traffic from filling up the blocked set
 1141|      0|                if source == BlockSource::Bootstrap {
 1142|      0|                    let source = block.source_or_link();
 1143|      0|
 1144|      0|                    if !account.is_zero() && !source.is_zero() {
 1145|       |                        // Mark account as blocked because it is missing the source block
 1146|      0|                        let blocked = self.accounts.block(*account, source);
 1147|      0|                        if blocked {
 1148|      0|                            stats.inc(
 1149|      0|                                StatType::BootstrapAccountSets,
 1150|      0|                                DetailType::PriorityEraseBlock,
 1151|      0|                            );
 1152|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::Block);
 1153|      0|                        } else {
 1154|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::BlockFailed);
 1155|      0|                        }
 1156|      0|                    }
 1157|      0|                }
 1158|       |            }
 1159|       |            BlockStatus::GapPrevious => {
 1160|       |                // Prevent live traffic from evicting accounts from the priority list
 1161|      0|                if source == BlockSource::Live
 1162|      0|                    && !self.accounts.priority_half_full()
 1163|      0|                    && !self.accounts.blocked_half_full()
 1164|       |                {
 1165|      0|                    if block.block_type() == BlockType::State {
 1166|      0|                        let account = block.account_field().unwrap();
 1167|      0|                        if self.accounts.priority_set_initial(&account) {
 1168|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PriorityInsert);
 1169|      0|                        } else {
 1170|      0|                            stats.inc(StatType::BootstrapAccountSets, DetailType::PrioritizeFailed);
 1171|      0|                        }
 1172|      0|                    }
 1173|      0|                }
 1174|       |            }
 1175|       |            BlockStatus::GapEpochOpenPending => {
 1176|       |                // Epoch open blocks for accounts that don't have any pending blocks yet
 1177|      0|                if self.accounts.priority_erase(account) {
 1178|      0|                    stats.inc(StatType::BootstrapAccountSets, DetailType::PriorityErase);
 1179|      0|                }
 1180|       |            }
 1181|      0|            _ => {
 1182|      0|                // No need to handle other cases
 1183|      0|                // TODO: If we receive blocks that are invalid (bad signature, fork, etc.),
 1184|      0|                // we should penalize the peer that sent them
 1185|      0|            }
 1186|       |        }
 1187|      0|    }
 1188|       |
 1189|      0|    fn count_tags_by_hash(&self, hash: &BlockHash, source: QuerySource) -> usize {
 1190|      0|        self.running_queries
 1191|      0|            .iter_hash(hash)
 1192|      0|            .filter(|i| i.source == source)
 1193|      0|            .count()
 1194|      0|    }
 1195|       |
 1196|      0|    fn next_priority(&mut self, stats: &Stats, now: Timestamp) -> PriorityResult {
 1197|      0|        let next = self.accounts.next_priority(now, |account| {
 1198|      0|            self.running_queries
 1199|      0|                .count_by_account(account, QuerySource::Priority)
 1200|      0|                < 4
 1201|      0|        });
 1202|      0|
 1203|      0|        if next.account.is_zero() {
 1204|      0|            return Default::default();
 1205|      0|        }
 1206|      0|
 1207|      0|        stats.inc(StatType::BootstrapNext, DetailType::NextPriority);
 1208|      0|
 1209|      0|        next
 1210|      0|    }
 1211|       |
 1212|       |    /* Gets the next account from the database */
 1213|      0|    fn next_database(
 1214|      0|        &mut self,
 1215|      0|        should_throttle: bool,
 1216|      0|        database_limiter: &RateLimiter,
 1217|      0|        stats: &Stats,
 1218|      0|        warmup_ratio: usize,
 1219|      0|    ) -> Account {
 1220|      0|        debug_assert!(warmup_ratio > 0);
 1221|       |
 1222|       |        // Throttling increases the weight of database requests
 1223|      0|        if !database_limiter.should_pass(if should_throttle { warmup_ratio } else { 1 }) {
 1224|      0|            return Account::zero();
 1225|      0|        }
 1226|      0|
 1227|      0|        let account = self.database_scan.next(|account| {
 1228|      0|            self.running_queries
 1229|      0|                .count_by_account(account, QuerySource::Database)
 1230|      0|                == 0
 1231|      0|        });
 1232|      0|
 1233|      0|        if account.is_zero() {
 1234|      0|            return account;
 1235|      0|        }
 1236|      0|
 1237|      0|        stats.inc(StatType::BootstrapNext, DetailType::NextDatabase);
 1238|      0|
 1239|      0|        account
 1240|      0|    }
 1241|       |
 1242|       |    /* Waits for next available blocking block */
 1243|      0|    fn next_blocking(&self, stats: &Stats) -> BlockHash {
 1244|      0|        let blocking = self
 1245|      0|            .accounts
 1246|      0|            .next_blocking(|hash| self.count_tags_by_hash(hash, QuerySource::Dependencies) == 0);
 1247|      0|
 1248|      0|        if blocking.is_zero() {
 1249|      0|            return blocking;
 1250|      0|        }
 1251|      0|
 1252|      0|        stats.inc(StatType::BootstrapNext, DetailType::NextBlocking);
 1253|      0|
 1254|      0|        blocking
 1255|      0|    }
 1256|       |
 1257|      3|    fn cleanup_and_sync(&mut self, account_count: u64, stats: &Stats, now: Timestamp) {
 1258|      3|        let channels = self.network.read().unwrap().list_realtime_channels(0);
 1259|      3|        self.scoring.sync(channels);
 1260|      3|        self.scoring.timeout();
 1261|      3|
 1262|      3|        self.throttle.resize(compute_throttle_size(
 1263|      3|            account_count,
 1264|      3|            self.config.throttle_coefficient,
 1265|      3|        ));
 1266|      3|
 1267|      3|        let should_timeout = |query: &RunningQuery| query.cutoff < now;
                                                                  ^0
 1268|       |
 1269|      3|        while let Some(front) = self.running_queries.front() {
                                     ^0
 1270|      0|            if !should_timeout(front) {
 1271|      0|                break;
 1272|      0|            }
 1273|      0|
 1274|      0|            stats.inc(StatType::Bootstrap, DetailType::Timeout);
 1275|      0|            stats.inc(StatType::BootstrapTimeout, front.query_type.into());
 1276|      0|            self.running_queries.pop_front();
 1277|       |        }
 1278|       |
 1279|      3|        if self.sync_dependencies_interval.elapsed() >= Duration::from_secs(60) {
 1280|      0|            self.sync_dependencies_interval = Instant::now();
 1281|      0|            stats.inc(StatType::Bootstrap, DetailType::SyncDependencies);
 1282|      0|            let (inserted, insert_failed) = self.accounts.sync_dependencies();
 1283|      0|            stats.add(
 1284|      0|                StatType::BootstrapAccountSets,
 1285|      0|                DetailType::PriorityInsert,
 1286|      0|                inserted as u64,
 1287|      0|            );
 1288|      0|            stats.add(
 1289|      0|                StatType::BootstrapAccountSets,
 1290|      0|                DetailType::PrioritizeFailed,
 1291|      0|                insert_failed as u64,
 1292|      0|            );
 1293|      3|        }
 1294|      3|    }
 1295|       |
 1296|      0|    pub fn container_info(
 1297|      0|        &self,
 1298|      0|        database_limiter: &RateLimiter,
 1299|      0|        frontiers_limiter: &RateLimiter,
 1300|      0|    ) -> ContainerInfo {
 1301|      0|        let limiters: ContainerInfo = [
 1302|      0|            ("total", self.limiter.size(), 0),
 1303|      0|            ("database", database_limiter.size(), 0),
 1304|      0|            ("frontiers", frontiers_limiter.size(), 0),
 1305|      0|        ]
 1306|      0|        .into();
 1307|      0|
 1308|      0|        ContainerInfo::builder()
 1309|      0|            .leaf(
 1310|      0|                "tags",
 1311|      0|                self.running_queries.len(),
 1312|      0|                RunningQueryContainer::ELEMENT_SIZE,
 1313|      0|            )
 1314|      0|            .leaf("throttle", self.throttle.len(), 0)
 1315|      0|            .leaf("throttle_success", self.throttle.successes(), 0)
 1316|      0|            .node("accounts", self.accounts.container_info())
 1317|      0|            .node("database_scan", self.database_scan.container_info())
 1318|      0|            .node("frontiers", self.frontiers.container_info())
 1319|      0|            .node("peers", self.scoring.container_info())
 1320|      0|            .node("limiters", limiters)
 1321|      0|            .finish()
 1322|      0|    }
 1323|       |}
 1324|       |
 1325|       |// Calculates a lookback size based on the size of the ledger where larger ledgers have a larger sample count
 1326|      6|fn compute_throttle_size(account_count: u64, throttle_coefficient: usize) -> usize {
 1327|      6|    let target = if account_count > 0 {
 1328|      6|        throttle_coefficient * ((account_count as f64).ln() as usize)
 1329|       |    } else {
 1330|      0|        0
 1331|       |    };
 1332|       |    const MIN_SIZE: usize = 16;
 1333|      6|    max(target, MIN_SIZE)
 1334|      6|}
 1335|       |
 1336|       |/// Verifies whether the received response is valid. Returns:
 1337|       |/// - invalid: when received blocks do not correspond to requested hash/account or they do not make a valid chain
 1338|       |/// - nothing_new: when received response indicates that the account chain does not have more blocks
 1339|       |/// - ok: otherwise, if all checks pass
 1340|      0|fn verify_response(response: &BlocksAckPayload, query: &RunningQuery) -> VerifyResult {
 1341|      0|    let blocks = response.blocks();
 1342|      0|    if blocks.is_empty() {
 1343|      0|        return VerifyResult::NothingNew;
 1344|      0|    }
 1345|      0|    if blocks.len() == 1 && blocks.front().unwrap().hash() == query.start.into() {
 1346|      0|        return VerifyResult::NothingNew;
 1347|      0|    }
 1348|      0|    if blocks.len() > query.count {
 1349|      0|        return VerifyResult::Invalid;
 1350|      0|    }
 1351|      0|
 1352|      0|    let first = blocks.front().unwrap();
 1353|      0|    match query.query_type {
 1354|       |        QueryType::BlocksByHash => {
 1355|      0|            if first.hash() != query.start.into() {
 1356|       |                // TODO: Stat & log
 1357|      0|                return VerifyResult::Invalid;
 1358|      0|            }
 1359|       |        }
 1360|       |        QueryType::BlocksByAccount => {
 1361|       |            // Open & state blocks always contain account field
 1362|      0|            if first.account_field().unwrap() != query.start.into() {
 1363|       |                // TODO: Stat & log
 1364|      0|                return VerifyResult::Invalid;
 1365|      0|            }
 1366|       |        }
 1367|       |        QueryType::AccountInfoByHash | QueryType::Frontiers | QueryType::Invalid => {
 1368|      0|            return VerifyResult::Invalid;
 1369|       |        }
 1370|       |    }
 1371|       |
 1372|       |    // Verify blocks make a valid chain
 1373|      0|    let mut previous_hash = first.hash();
 1374|      0|    for block in blocks.iter().skip(1) {
 1375|      0|        if block.previous() != previous_hash {
 1376|       |            // TODO: Stat & log
 1377|      0|            return VerifyResult::Invalid; // Blocks do not make a chain
 1378|      0|        }
 1379|      0|        previous_hash = block.hash();
 1380|       |    }
 1381|       |
 1382|      0|    VerifyResult::Ok
 1383|      0|}
 1384|       |
 1385|       |#[derive(Clone, Debug, PartialEq)]
 1386|       |pub struct BootstrapConfig {
 1387|       |    pub enable: bool,
 1388|       |    pub enable_scan: bool,
 1389|       |    pub enable_database_scan: bool,
 1390|       |    pub enable_dependency_walker: bool,
 1391|       |    pub enable_frontier_scan: bool,
 1392|       |    /// Maximum number of un-responded requests per channel, should be lower or equal to bootstrap server max queue size
 1393|       |    pub channel_limit: usize,
 1394|       |    pub rate_limit: usize,
 1395|       |    pub database_rate_limit: usize,
 1396|       |    pub frontier_rate_limit: usize,
 1397|       |    pub database_warmup_ratio: usize,
 1398|       |    pub max_pull_count: usize,
 1399|       |    pub request_timeout: Duration,
 1400|       |    pub throttle_coefficient: usize,
 1401|       |    pub throttle_wait: Duration,
 1402|       |    pub block_processor_theshold: usize,
 1403|       |    /** Minimum accepted protocol version used when bootstrapping */
 1404|       |    pub min_protocol_version: u8,
 1405|       |    pub max_requests: usize,
 1406|       |    pub optimistic_request_percentage: u8,
 1407|       |    pub account_sets: AccountSetsConfig,
 1408|       |    pub frontier_scan: FrontierScanConfig,
 1409|       |}
 1410|       |
 1411|       |impl Default for BootstrapConfig {
 1412|     18|    fn default() -> Self {
 1413|     18|        Self {
 1414|     18|            enable: true,
 1415|     18|            enable_scan: true,
 1416|     18|            enable_database_scan: false,
 1417|     18|            enable_dependency_walker: true,
 1418|     18|            enable_frontier_scan: true,
 1419|     18|            channel_limit: 16,
 1420|     18|            rate_limit: 500,
 1421|     18|            database_rate_limit: 256,
 1422|     18|            frontier_rate_limit: 8,
 1423|     18|            database_warmup_ratio: 10,
 1424|     18|            max_pull_count: BlocksAckPayload::MAX_BLOCKS,
 1425|     18|            request_timeout: Duration::from_secs(15),
 1426|     18|            throttle_coefficient: 8 * 1024,
 1427|     18|            throttle_wait: Duration::from_millis(100),
 1428|     18|            block_processor_theshold: 1000,
 1429|     18|            min_protocol_version: 0x14, // TODO don't hard code
 1430|     18|            max_requests: 1024,
 1431|     18|            optimistic_request_percentage: 75,
 1432|     18|            account_sets: Default::default(),
 1433|     18|            frontier_scan: Default::default(),
 1434|     18|        }
 1435|     18|    }
 1436|       |}
 1437|       |
 1438|       |impl From<&Message> for QueryType {
 1439|      0|    fn from(value: &Message) -> Self {
 1440|      0|        if let Message::AscPullReq(req) = value {
 1441|      0|            match &req.req_type {
 1442|      0|                AscPullReqType::Blocks(b) => match b.start_type {
 1443|      0|                    HashType::Account => QueryType::BlocksByAccount,
 1444|      0|                    HashType::Block => QueryType::BlocksByHash,
 1445|       |                },
 1446|      0|                AscPullReqType::AccountInfo(_) => QueryType::AccountInfoByHash,
 1447|      0|                AscPullReqType::Frontiers(_) => QueryType::Frontiers,
 1448|       |            }
 1449|       |        } else {
 1450|      0|            QueryType::Invalid
 1451|       |        }
 1452|      0|    }
 1453|       |}
 1454|       |
 1455|      0|fn process_frontiers(
 1456|      0|    ledger: Arc<Ledger>,
 1457|      0|    stats: Arc<Stats>,
 1458|      0|    frontiers: Vec<Frontier>,
 1459|      0|    mutex: Arc<Mutex<BootstrapLogic>>,
 1460|      0|) {
 1461|      0|    assert!(!frontiers.is_empty());
 1462|       |
 1463|      0|    stats.inc(StatType::Bootstrap, DetailType::ProcessingFrontiers);
 1464|      0|    let mut outdated = 0;
 1465|      0|    let mut pending = 0;
 1466|      0|
 1467|      0|    // Accounts with outdated frontiers to sync
 1468|      0|    let mut result = Vec::new();
 1469|      0|    {
 1470|      0|        let tx = ledger.read_txn();
 1471|      0|
 1472|      0|        let start = frontiers[0].account;
 1473|      0|        let mut account_crawler = AccountDatabaseCrawler::new(&ledger, &tx);
 1474|      0|        let mut pending_crawler = PendingDatabaseCrawler::new(&ledger, &tx);
 1475|      0|        account_crawler.initialize(start);
 1476|      0|        pending_crawler.initialize(start);
 1477|      0|
 1478|      0|        let mut should_prioritize = |frontier: &Frontier| {
 1479|      0|            account_crawler.advance_to(&frontier.account);
 1480|      0|            pending_crawler.advance_to(&frontier.account);
 1481|       |
 1482|       |            // Check if account exists in our ledger
 1483|      0|            if let Some((cur_acc, info)) = &account_crawler.current {
 1484|      0|                if *cur_acc == frontier.account {
 1485|       |                    // Check for frontier mismatch
 1486|      0|                    if info.head != frontier.hash {
 1487|       |                        // Check if frontier block exists in our ledger
 1488|      0|                        if !ledger.any().block_exists_or_pruned(&tx, &frontier.hash) {
 1489|      0|                            outdated += 1;
 1490|      0|                            return true; // Frontier is outdated
 1491|      0|                        }
 1492|      0|                    }
 1493|      0|                    return false; // Account exists and frontier is up-to-date
 1494|      0|                }
 1495|      0|            }
 1496|       |
 1497|       |            // Check if account has pending blocks in our ledger
 1498|      0|            if let Some((key, _)) = &pending_crawler.current {
 1499|      0|                if key.receiving_account == frontier.account {
 1500|      0|                    pending += 1;
 1501|      0|                    return true; // Account doesn't exist but has pending blocks in the ledger
 1502|      0|                }
 1503|      0|            }
 1504|       |
 1505|      0|            false // Account doesn't exist in the ledger and has no pending blocks, can't be prioritized right now
 1506|      0|        };
 1507|       |
 1508|      0|        for frontier in &frontiers {
 1509|      0|            if should_prioritize(frontier) {
 1510|      0|                result.push(frontier.account);
 1511|      0|            }
 1512|       |        }
 1513|       |    }
 1514|       |
 1515|      0|    stats.add(
 1516|      0|        StatType::BootstrapFrontiers,
 1517|      0|        DetailType::Processed,
 1518|      0|        frontiers.len() as u64,
 1519|      0|    );
 1520|      0|    stats.add(
 1521|      0|        StatType::BootstrapFrontiers,
 1522|      0|        DetailType::Prioritized,
 1523|      0|        result.len() as u64,
 1524|      0|    );
 1525|      0|    stats.add(StatType::BootstrapFrontiers, DetailType::Outdated, outdated);
 1526|      0|    stats.add(StatType::BootstrapFrontiers, DetailType::Pending, pending);
 1527|      0|
 1528|      0|    debug!(
 1529|      0|        "Processed {} frontiers of which outdated: {}, pending: {}",
 1530|      0|        frontiers.len(),
 1531|       |        outdated,
 1532|       |        pending
 1533|       |    );
 1534|       |
 1535|      0|    let mut guard = mutex.lock().unwrap();
 1536|      0|    for account in result {
 1537|      0|        // Use the lowest possible priority here
 1538|      0|        guard
 1539|      0|            .accounts
 1540|      0|            .priority_set(&account, AccountSets::PRIORITY_CUTOFF);
 1541|      0|    }
 1542|      0|}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/crawlers.rs:
    1|       |use rsnano_core::{Account, AccountInfo, BlockHash, PendingInfo, PendingKey};
    2|       |use rsnano_ledger::Ledger;
    3|       |use rsnano_store_lmdb::LmdbReadTransaction;
    4|       |
    5|       |pub(super) struct AccountDatabaseCrawler<'a> {
    6|       |    ledger: &'a Ledger,
    7|       |    tx: &'a LmdbReadTransaction,
    8|       |    it: Option<Box<dyn Iterator<Item = (Account, AccountInfo)> + 'a>>,
    9|       |    pub current: Option<(Account, AccountInfo)>,
   10|       |}
   11|       |
   12|       |impl<'a> AccountDatabaseCrawler<'a> {
   13|       |    const SEQUENTIAL_ATTEMPTS: usize = 10;
   14|       |
   15|      4|    pub fn new(ledger: &'a Ledger, tx: &'a LmdbReadTransaction) -> Self {
   16|      4|        Self {
   17|      4|            ledger,
   18|      4|            tx,
   19|      4|            it: None,
   20|      4|            current: None,
   21|      4|        }
   22|      4|    }
   23|       |
   24|      4|    pub fn initialize(&mut self, start: Account) {
   25|      4|        self.seek(start);
   26|      4|    }
   27|       |
   28|      4|    fn seek(&mut self, start: Account) {
   29|      4|        self.it = Some(Box::new(
   30|      4|            self.ledger.store.account.iter_range(self.tx, start..),
   31|      4|        ));
   32|      4|        self.advance();
   33|      4|    }
   34|       |
   35|     14|    pub fn advance(&mut self) {
   36|     14|        if let Some(it) = &mut self.it {
   37|     14|            self.current = it.next();
   38|     14|            if self.current.is_none() {
   39|      2|                self.it = None;
   40|     12|            }
   41|      0|        } else {
   42|      0|            self.current = None;
   43|      0|        }
   44|     14|    }
   45|       |
   46|      0|    pub fn advance_to(&mut self, account: &Account) {
   47|      0|        let Some(it) = &mut self.it else {
   48|      0|            return;
   49|       |        };
   50|       |
   51|      0|        if let Some((acc, _)) = &self.current {
   52|      0|            if acc == account {
   53|      0|                return; // already at correct account
   54|      0|            }
   55|      0|        }
   56|       |
   57|       |        // First try advancing sequentially
   58|      0|        for _ in 0..Self::SEQUENTIAL_ATTEMPTS {
   59|      0|            self.current = it.next();
   60|      0|            match &self.current {
   61|      0|                Some((acc, _)) => {
   62|      0|                    // Break if we've reached or overshoot the target account
   63|      0|                    if acc.number() >= account.number() {
   64|      0|                        return;
   65|      0|                    }
   66|       |                }
   67|       |                None => {
   68|      0|                    self.it = None;
   69|      0|                    self.current = None;
   70|      0|                    break;
   71|       |                }
   72|       |            }
   73|       |        }
   74|       |
   75|       |        // If that fails, perform a fresh lookup
   76|      0|        self.seek(*account);
   77|      0|    }
   78|       |}
   79|       |
   80|       |pub(super) struct PendingDatabaseCrawler<'a> {
   81|       |    ledger: &'a Ledger,
   82|       |    tx: &'a LmdbReadTransaction,
   83|       |    it: Option<Box<dyn Iterator<Item = (PendingKey, PendingInfo)> + 'a>>,
   84|       |    pub current: Option<(PendingKey, PendingInfo)>,
   85|       |}
   86|       |
   87|       |impl<'a> PendingDatabaseCrawler<'a> {
   88|       |    const SEQUENTIAL_ATTEMPTS: usize = 10;
   89|       |
   90|      4|    pub fn new(ledger: &'a Ledger, tx: &'a LmdbReadTransaction) -> Self {
   91|      4|        Self {
   92|      4|            ledger,
   93|      4|            tx,
   94|      4|            it: None,
   95|      4|            current: None,
   96|      4|        }
   97|      4|    }
   98|       |
   99|      4|    pub fn initialize(&mut self, start: Account) {
  100|      4|        self.seek(start);
  101|      4|    }
  102|       |
  103|      6|    fn seek(&mut self, start: Account) {
  104|      6|        self.it =
  105|      6|            Some(Box::new(self.ledger.store.pending.iter_range(
  106|      6|                self.tx,
  107|      6|                PendingKey::new(start, BlockHash::zero())..,
  108|      6|            )));
  109|      6|        if let Some(it) = &mut self.it {
  110|      6|            self.current = it.next();
  111|      6|            if self.current.is_none() {
  112|      0|                self.it = None;
  113|      6|            }
  114|      0|        } else {
  115|      0|            self.current = None;
  116|      0|        }
  117|      6|    }
  118|       |
  119|       |    // Advance to the next account
  120|      8|    pub fn advance(&mut self) {
  121|      8|        let Some(it) = &mut self.it else {
  122|      0|            return;
  123|       |        };
  124|       |
  125|      8|        let starting_account = self.current.as_ref().unwrap().0.receiving_account;
  126|       |
  127|       |        // First try advancing sequentially
  128|     28|        for _ in 0..Self::SEQUENTIAL_ATTEMPTS {
  129|     26|            self.current = it.next();
  130|     26|            match &self.current {
  131|     24|                Some((key, _)) => {
  132|     24|                    // Break if we've reached the next account
  133|     24|                    if key.receiving_account != starting_account {
  134|      4|                        return;
  135|     20|                    }
  136|       |                }
  137|       |                None => {
  138|      2|                    self.it = None;
  139|      2|                    self.current = None;
  140|      2|                    break;
  141|       |                }
  142|       |            }
  143|       |        }
  144|       |
  145|      4|        if self.it.is_some() {
  146|      2|            // If that fails, perform a fresh lookup
  147|      2|            self.seek(starting_account.inc_or_max());
  148|      2|        }
  149|      8|    }
  150|       |
  151|      0|    pub fn advance_to(&mut self, account: &Account) {
  152|      0|        let Some(it) = &mut self.it else {
  153|      0|            return;
  154|       |        };
  155|       |
  156|      0|        if let Some((key, _)) = &self.current {
  157|      0|            if key.receiving_account == *account {
  158|      0|                return; // already at correct account
  159|      0|            }
  160|      0|        }
  161|       |
  162|       |        // First try advancing sequentially
  163|      0|        for _ in 0..Self::SEQUENTIAL_ATTEMPTS {
  164|      0|            self.current = it.next();
  165|      0|            match &self.current {
  166|      0|                Some((key, _)) => {
  167|      0|                    // Break if we've reached or overshoot the target account
  168|      0|                    if key.receiving_account.number() >= account.number() {
  169|      0|                        return;
  170|      0|                    }
  171|       |                }
  172|       |                None => {
  173|      0|                    self.it = None;
  174|      0|                    self.current = None;
  175|      0|                    break;
  176|       |                }
  177|       |            }
  178|       |        }
  179|       |
  180|       |        // If that fails, perform a fresh lookup
  181|      0|        self.seek(*account);
  182|      0|    }
  183|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/database_scan.rs:
    1|       |use super::crawlers::{AccountDatabaseCrawler, PendingDatabaseCrawler};
    2|       |use rsnano_core::{utils::ContainerInfo, Account};
    3|       |use rsnano_ledger::Ledger;
    4|       |use rsnano_store_lmdb::LmdbReadTransaction;
    5|       |use std::{collections::VecDeque, sync::Arc};
    6|       |
    7|       |const BATCH_SIZE: usize = 512;
    8|       |
    9|       |pub(crate) struct DatabaseScan {
   10|       |    queue: VecDeque<Account>,
   11|       |    account_scanner: AccountDatabaseScanner,
   12|       |    pending_scanner: PendingDatabaseScanner,
   13|       |    ledger: Arc<Ledger>,
   14|       |}
   15|       |
   16|       |impl DatabaseScan {
   17|      3|    pub fn new(ledger: Arc<Ledger>) -> Self {
   18|      3|        Self {
   19|      3|            account_scanner: AccountDatabaseScanner::new(ledger.clone()),
   20|      3|            pending_scanner: PendingDatabaseScanner::new(ledger.clone()),
   21|      3|            ledger,
   22|      3|            queue: Default::default(),
   23|      3|        }
   24|      3|    }
   25|       |
   26|      0|    pub fn next(&mut self, filter: impl Fn(&Account) -> bool) -> Account {
   27|      0|        if self.queue.is_empty() {
   28|      0|            self.fill();
   29|      0|        }
   30|       |
   31|      0|        while let Some(result) = self.queue.pop_front() {
   32|      0|            if filter(&result) {
   33|      0|                return result;
   34|      0|            }
   35|       |        }
   36|       |
   37|      0|        Account::zero()
   38|      0|    }
   39|       |
   40|      0|    fn fill(&mut self) {
   41|      0|        let tx = self.ledger.read_txn();
   42|      0|        let set1 = self.account_scanner.next_batch(&tx, BATCH_SIZE);
   43|      0|        let set2 = self.pending_scanner.next_batch(&tx, BATCH_SIZE);
   44|      0|        self.queue.extend(set1);
   45|      0|        self.queue.extend(set2);
   46|      0|    }
   47|       |
   48|      0|    pub fn warmed_up(&self) -> bool {
   49|      0|        self.account_scanner.completed > 0 && self.pending_scanner.completed > 0
   50|      0|    }
   51|       |
   52|      0|    pub fn container_info(&self) -> ContainerInfo {
   53|      0|        [
   54|      0|            ("accounts_iterator", self.account_scanner.completed, 0),
   55|      0|            ("pending_iterator", self.pending_scanner.completed, 0),
   56|      0|        ]
   57|      0|        .into()
   58|      0|    }
   59|       |}
   60|       |
   61|       |struct AccountDatabaseScanner {
   62|       |    ledger: Arc<Ledger>,
   63|       |    next: Account,
   64|       |    completed: usize,
   65|       |}
   66|       |
   67|       |impl AccountDatabaseScanner {
   68|      5|    fn new(ledger: Arc<Ledger>) -> Self {
   69|      5|        Self {
   70|      5|            ledger,
   71|      5|            next: Account::zero(),
   72|      5|            completed: 0,
   73|      5|        }
   74|      5|    }
   75|       |
   76|      4|    fn next_batch(&mut self, tx: &LmdbReadTransaction, batch_size: usize) -> Vec<Account> {
   77|      4|        let mut result = Vec::new();
   78|      4|        let mut crawler = AccountDatabaseCrawler::new(&self.ledger, tx);
   79|      4|        crawler.initialize(self.next);
   80|      4|
   81|      4|        for _ in 0..batch_size {
   82|     11|            let Some((account, _)) = &crawler.current else {
                                    ^10
   83|      1|                break;
   84|       |            };
   85|       |
   86|     10|            result.push(*account);
   87|     10|            self.next = account.inc_or_max(); // TODO: Handle account number overflow
   88|     10|
   89|     10|            crawler.advance();
   90|       |        }
   91|       |
   92|       |        // Empty current value indicates the end of the table
   93|      4|        if crawler.current.is_none() {
   94|      2|            // Reset for the next ledger iteration
   95|      2|            self.next = Account::zero();
   96|      2|            self.completed += 1;
   97|      2|        }
   98|       |
   99|      4|        result
  100|      4|    }
  101|       |}
  102|       |
  103|       |struct PendingDatabaseScanner {
  104|       |    ledger: Arc<Ledger>,
  105|       |    next: Account,
  106|       |    completed: usize,
  107|       |}
  108|       |
  109|       |impl PendingDatabaseScanner {
  110|      5|    fn new(ledger: Arc<Ledger>) -> Self {
  111|      5|        Self {
  112|      5|            ledger,
  113|      5|            next: Account::zero(),
  114|      5|            completed: 0,
  115|      5|        }
  116|      5|    }
  117|       |
  118|      4|    fn next_batch(&mut self, tx: &LmdbReadTransaction, batch_size: usize) -> Vec<Account> {
  119|      4|        let mut result = Vec::new();
  120|      4|        let mut crawler = PendingDatabaseCrawler::new(&self.ledger, tx);
  121|      4|        crawler.initialize(self.next);
  122|      4|
  123|      4|        for _ in 0..batch_size {
  124|      9|            let Some((key, _)) = crawler.current else {
                                    ^8
  125|      1|                break;
  126|       |            };
  127|      8|            result.push(key.receiving_account);
  128|      8|
  129|      8|            // TODO: Handle account number overflow
  130|      8|            self.next = key.receiving_account.inc_or_max();
  131|      8|            crawler.advance();
  132|       |        }
  133|       |
  134|       |        // Empty current value indicates the end of the table
  135|      4|        if crawler.current.is_none() {
  136|      2|            // Reset for the next ledger iteration
  137|      2|            self.next = Account::zero();
  138|      2|            self.completed += 1;
  139|      2|        }
  140|       |
  141|      4|        result
  142|      4|    }
  143|       |}
  144|       |
  145|       |#[cfg(test)]
  146|       |mod tests {
  147|       |    use super::*;
  148|       |    use rsnano_core::{PrivateKey, UnsavedBlockLatticeBuilder};
  149|       |    use rsnano_ledger::LedgerContext;
  150|       |
  151|       |    #[test]
  152|      1|    fn pending_database_scanner() {
  153|      1|        // Prepare pending sends from genesis
  154|      1|        // 1 account with 1 pending
  155|      1|        // 1 account with 21 pendings
  156|      1|        // 2 accounts with 1 pending each
  157|      1|        let mut lattice = UnsavedBlockLatticeBuilder::new();
  158|      1|        let mut blocks = Vec::new();
  159|      1|        let key1 = PrivateKey::from(1);
  160|      1|        let key2 = PrivateKey::from(2);
  161|      1|        let key3 = PrivateKey::from(3);
  162|      1|        let key4 = PrivateKey::from(4);
  163|      1|        {
  164|      1|            // 1 account with 1 pending
  165|      1|            blocks.push(lattice.genesis().send(&key1, 1));
  166|       |
  167|       |            // 1 account with 21 pendings
  168|     22|            for _ in 0..21 {
  169|     21|                blocks.push(lattice.genesis().send(&key2, 1));
  170|     21|            }
  171|       |            // 2 accounts with 1 pending each
  172|      1|            blocks.push(lattice.genesis().send(&key3, 1));
  173|      1|            blocks.push(lattice.genesis().send(&key4, 1));
  174|      1|
  175|      1|            let ledger_ctx = LedgerContext::empty_dev();
  176|     25|            for mut block in blocks {
                              ^24
  177|     24|                let mut txn = ledger_ctx.ledger.rw_txn();
  178|     24|                ledger_ctx.ledger.process(&mut txn, &mut block).unwrap();
  179|     24|            }
  180|       |            // Single batch
  181|       |            {
  182|      1|                let mut scanner = PendingDatabaseScanner::new(ledger_ctx.ledger.clone());
  183|      1|                let tx = ledger_ctx.ledger.read_txn();
  184|      1|                let accounts = scanner.next_batch(&tx, 256);
  185|      1|
  186|      1|                // Check that account set contains all keys
  187|      1|                assert_eq!(accounts.len(), 4);
  188|      1|                assert!(accounts.contains(&key1.account()));
  189|      1|                assert!(accounts.contains(&key2.account()));
  190|      1|                assert!(accounts.contains(&key3.account()));
  191|      1|                assert!(accounts.contains(&key4.account()));
  192|       |
  193|      1|                assert_eq!(scanner.completed, 1);
  194|       |            }
  195|       |
  196|       |            // Multi batch
  197|       |            {
  198|      1|                let mut scanner = PendingDatabaseScanner::new(ledger_ctx.ledger.clone());
  199|      1|                let tx = ledger_ctx.ledger.read_txn();
  200|      1|
  201|      1|                // Request accounts in multiple batches
  202|      1|                let accounts1 = scanner.next_batch(&tx, 2);
  203|      1|                let accounts2 = scanner.next_batch(&tx, 1);
  204|      1|                let accounts3 = scanner.next_batch(&tx, 1);
  205|      1|
  206|      1|                assert_eq!(accounts1.len(), 2);
  207|      1|                assert_eq!(accounts2.len(), 1);
  208|      1|                assert_eq!(accounts3.len(), 1);
  209|       |
  210|       |                // Check that account set contains all keys
  211|      1|                let mut accounts = accounts1;
  212|      1|                accounts.extend(accounts2);
  213|      1|                accounts.extend(accounts3);
  214|      1|                assert!(accounts.contains(&key1.account()));
  215|      1|                assert!(accounts.contains(&key2.account()));
  216|      1|                assert!(accounts.contains(&key3.account()));
  217|      1|                assert!(accounts.contains(&key4.account()));
  218|       |
  219|      1|                assert_eq!(scanner.completed, 1);
  220|       |            }
  221|       |        }
  222|      1|    }
  223|       |
  224|       |    #[test]
  225|      1|    fn account_database_scanner() {
  226|       |        const COUNT: usize = 4;
  227|       |
  228|       |        // Prepare some accounts
  229|      1|        let mut lattice = UnsavedBlockLatticeBuilder::new();
  230|      1|        let mut blocks = Vec::new();
  231|      1|        let mut keys = Vec::new();
  232|       |        {
  233|      5|            for _ in 0..COUNT {
  234|      4|                let key = PrivateKey::new();
  235|      4|                let send = lattice.genesis().send(&key, 1);
  236|      4|                let open = lattice.account(&key).receive(&send);
  237|      4|                blocks.push(send);
  238|      4|                blocks.push(open);
  239|      4|                keys.push(key);
  240|      4|            }
  241|       |        }
  242|       |
  243|      1|        let ledger_ctx = LedgerContext::empty_dev();
  244|      9|        for mut block in blocks {
                          ^8
  245|      8|            let mut txn = ledger_ctx.ledger.rw_txn();
  246|      8|            ledger_ctx.ledger.process(&mut txn, &mut block).unwrap();
  247|      8|        }
  248|       |
  249|       |        // Single batch
  250|       |        {
  251|      1|            let mut scanner = AccountDatabaseScanner::new(ledger_ctx.ledger.clone());
  252|      1|            let tx = ledger_ctx.ledger.read_txn();
  253|      1|            let accounts = scanner.next_batch(&tx, 256);
  254|      1|
  255|      1|            // Check that account set contains all keys
  256|      1|            assert_eq!(accounts.len(), keys.len() + 1); // +1 for genesis
  257|      5|            for key in &keys {
                              ^4
  258|      4|                assert!(accounts.contains(&key.account()));
  259|       |            }
  260|      1|            assert_eq!(scanner.completed, 1);
  261|       |        }
  262|       |
  263|       |        // Multi batch
  264|       |        {
  265|      1|            let mut scanner = AccountDatabaseScanner::new(ledger_ctx.ledger.clone());
  266|      1|            let tx = ledger_ctx.ledger.read_txn();
  267|      1|
  268|      1|            // Request accounts in multiple batches
  269|      1|            let accounts1 = scanner.next_batch(&tx, 2);
  270|      1|            let accounts2 = scanner.next_batch(&tx, 2);
  271|      1|            let accounts3 = scanner.next_batch(&tx, 1);
  272|      1|
  273|      1|            assert_eq!(accounts1.len(), 2);
  274|      1|            assert_eq!(accounts2.len(), 2);
  275|      1|            assert_eq!(accounts3.len(), 1);
  276|       |
  277|      1|            let mut accounts = accounts1;
  278|      1|            accounts.extend(accounts2);
  279|      1|            accounts.extend(accounts3);
  280|       |
  281|       |            // Check that account set contains all keys
  282|      5|            for key in &keys {
                              ^4
  283|      4|                assert!(accounts.contains(&key.account()));
  284|       |            }
  285|      1|            assert_eq!(scanner.completed, 1);
  286|       |        }
  287|      1|    }
  288|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/frontier_scan.rs:
    1|       |use super::ordered_heads::OrderedHeads;
    2|       |use crate::{
    3|       |    bootstrap::ordered_heads::FrontierHead,
    4|       |    stats::{DetailType, StatType, Stats},
    5|       |};
    6|       |use primitive_types::U256;
    7|       |use rsnano_core::{utils::ContainerInfo, Account, Frontier};
    8|       |use rsnano_nullable_clock::Timestamp;
    9|       |use std::{sync::Arc, time::Duration};
   10|       |
   11|       |#[derive(Clone, PartialEq, Eq, Debug)]
   12|       |pub struct FrontierScanConfig {
   13|       |    pub head_parallelism: usize,
   14|       |    pub consideration_count: usize,
   15|       |    pub candidates: usize,
   16|       |    pub cooldown: Duration,
   17|       |    pub max_pending: usize,
   18|       |}
   19|       |
   20|       |impl Default for FrontierScanConfig {
   21|     26|    fn default() -> Self {
   22|     26|        Self {
   23|     26|            head_parallelism: 128,
   24|     26|            consideration_count: 4,
   25|     26|            candidates: 1000,
   26|     26|            cooldown: Duration::from_secs(5),
   27|     26|            max_pending: 16,
   28|     26|        }
   29|     26|    }
   30|       |}
   31|       |
   32|       |/// Frontier scan divides the account space into ranges and scans each range for
   33|       |/// outdated frontiers in parallel.
   34|       |/// This class is used to track the progress of each range.
   35|       |pub struct FrontierScan {
   36|       |    config: FrontierScanConfig,
   37|       |    stats: Arc<Stats>,
   38|       |    heads: OrderedHeads,
   39|       |}
   40|       |
   41|       |impl FrontierScan {
   42|     11|    pub fn new(config: FrontierScanConfig, stats: Arc<Stats>) -> Self {
   43|     11|        // Divide nano::account numeric range into consecutive and equal ranges
   44|     11|        let max_account = Account::MAX.number();
   45|     11|        let range_size = max_account / config.head_parallelism;
   46|     11|        let mut heads = OrderedHeads::default();
   47|       |
   48|    396|        for i in 0..config.head_parallelism {
                                  ^11
   49|       |            // Start at 1 to avoid the burn account
   50|    396|            let start = if i == 0 {
   51|     11|                U256::from(1)
   52|       |            } else {
   53|    385|                range_size * i
   54|       |            };
   55|    396|            let end = if i == config.head_parallelism - 1 {
   56|     11|                max_account
   57|       |            } else {
   58|    385|                start + range_size
   59|       |            };
   60|    396|            heads.push_back(FrontierHead::new(start, end));
   61|       |        }
   62|       |
   63|     11|        assert!(!heads.len() > 0);
   64|       |
   65|     11|        Self {
   66|     11|            config,
   67|     11|            stats,
   68|     11|            heads,
   69|     11|        }
   70|     11|    }
   71|       |
   72|     24|    pub fn next(&mut self, now: Timestamp) -> Account {
   73|     24|        let cutoff = now - self.config.cooldown;
   74|     24|        let mut next_account = Account::zero();
   75|     24|        let mut it = Account::zero();
   76|     24|        for head in self.heads.ordered_by_timestamp() {
   77|     24|            if head.requests < self.config.consideration_count || head.timestamp < cutoff {
                                                                                ^2
   78|     23|                debug_assert!(head.next.number() >= head.start.number());
   79|     23|                debug_assert!(head.next.number() < head.end.number());
   80|       |
   81|     23|                self.stats.inc(
   82|     23|                    StatType::BootstrapFrontierScan,
   83|     23|                    if head.requests < self.config.consideration_count {
   84|     22|                        DetailType::NextByRequests
   85|       |                    } else {
   86|      1|                        DetailType::NextByTimestamp
   87|       |                    },
   88|       |                );
   89|       |
   90|     23|                next_account = head.next;
   91|     23|                it = head.start;
   92|     23|                break;
   93|      1|            }
   94|       |        }
   95|       |
   96|     24|        if next_account.is_zero() {
   97|      1|            self.stats
   98|      1|                .inc(StatType::BootstrapFrontierScan, DetailType::NextNone);
   99|     23|        } else {
  100|     23|            self.heads.modify(&it, |head| {
  101|     23|                head.requests += 1;
  102|     23|                head.timestamp = now
  103|     23|            });
  104|     23|        }
  105|       |
  106|     24|        next_account
  107|     24|    }
  108|       |
  109|     14|    pub fn process(&mut self, start: Account, response: &[Frontier]) -> bool {
  110|     14|        debug_assert!(response
  111|     14|            .iter()
  112|     19|            .all(|f| f.account.number() >= start.number()));
                                                                       ^14
  113|       |
  114|     14|        self.stats
  115|     14|            .inc(StatType::BootstrapFrontierScan, DetailType::Process);
  116|     14|
  117|     14|        // Find the first head with head.start <= start
  118|     14|        let it = self.heads.find_first_less_than_or_equal_to(start).unwrap();
  119|     14|
  120|     14|        let mut done = false;
  121|     14|        self.heads.modify(&it, |entry| {
  122|     14|            entry.completed += 1;
  123|       |
  124|     33|            for frontier in response {
                              ^19
  125|       |                // Only consider candidates that actually advance the current frontier
  126|     19|                if frontier.account.number() > entry.next.number() {
  127|     17|                    entry.candidates.insert(frontier.account);
  128|     17|                }
                               ^2
  129|       |            }
  130|       |
  131|       |            // Trim the candidates
  132|     17|            while entry.candidates.len() > self.config.candidates {
  133|      3|                entry.candidates.pop_last();
  134|      3|            }
  135|       |
  136|       |            // Special case for the last frontier head that won't receive larger than max frontier
  137|     14|            if entry.completed >= self.config.consideration_count * 2 && entry.candidates.is_empty()
                                                                                       ^1
  138|      1|            {
  139|      1|                self.stats
  140|      1|                    .inc(StatType::BootstrapFrontierScan, DetailType::DoneEmpty);
  141|      1|                entry.candidates.insert(entry.end);
  142|     13|            }
  143|       |
  144|       |            // Check if done
  145|     14|            if entry.completed >= self.config.consideration_count && !entry.candidates.is_empty() {
                                                                                   ^9
  146|      6|                self.stats
  147|      6|                    .inc(StatType::BootstrapFrontierScan, DetailType::Done);
  148|      6|
  149|      6|                // Take the last candidate as the next frontier
  150|      6|                assert!(!entry.candidates.is_empty());
  151|      6|                let last = entry.candidates.last().unwrap();
  152|      6|                debug_assert!(entry.next.number() < last.number());
  153|      6|                entry.next = *last;
  154|      6|                entry.processed += entry.candidates.len();
  155|      6|                entry.candidates.clear();
  156|      6|                entry.requests = 0;
  157|      6|                entry.completed = 0;
  158|      6|                entry.timestamp = Timestamp::default();
  159|      6|
  160|      6|                // Bound the search range
  161|      6|                if entry.next.number() >= entry.end.number() {
  162|      2|                    self.stats
  163|      2|                        .inc(StatType::BootstrapFrontierScan, DetailType::DoneRange);
  164|      2|                    entry.next = entry.start;
  165|      4|                }
  166|       |
  167|      6|                done = true;
  168|      8|            }
  169|     14|        });
  170|     14|
  171|     14|        done
  172|     14|    }
  173|       |
  174|      0|    pub fn container_info(&self) -> ContainerInfo {
  175|      0|        // TODO port the detailed container info from nano_node
  176|      0|        let total_processed = self.heads.iter().map(|i| i.processed).sum();
  177|      0|        [("total_processed", total_processed, 0)].into()
  178|      0|    }
  179|       |}
  180|       |
  181|       |#[cfg(test)]
  182|       |mod tests {
  183|       |    use super::*;
  184|       |    use rsnano_core::BlockHash;
  185|       |
  186|       |    #[test]
  187|      1|    fn next_basic() {
  188|      1|        let config = FrontierScanConfig {
  189|      1|            head_parallelism: 2,
  190|      1|            consideration_count: 3,
  191|      1|            ..Default::default()
  192|      1|        };
  193|      1|        let stats = Arc::new(Stats::default());
  194|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  195|      1|        let now = Timestamp::new_test_instance();
  196|      1|
  197|      1|        // First call should return first head, account number 1 (avoiding burn account 0)
  198|      1|        let first = frontier_scan.next(now);
  199|      1|        assert_eq!(first, Account::from(1));
  200|       |
  201|       |        // Second call should return second head, account number 0x7FF... (half the range)
  202|      1|        let second = frontier_scan.next(now);
  203|      1|        assert_eq!(
  204|      1|            second,
  205|      1|            Account::decode_hex("7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF")
  206|      1|                .unwrap()
  207|      1|        );
  208|       |
  209|       |        // Third call should return first head again, sequentially iterating through heads
  210|      1|        let third = frontier_scan.next(now);
  211|      1|        assert_eq!(third, Account::from(1));
  212|      1|    }
  213|       |
  214|       |    #[test]
  215|      1|    fn process_basic() {
  216|      1|        let config = FrontierScanConfig {
  217|      1|            head_parallelism: 1,
  218|      1|            consideration_count: 3,
  219|      1|            candidates: 5,
  220|      1|            ..Default::default()
  221|      1|        };
  222|      1|        let stats = Arc::new(Stats::default());
  223|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  224|      1|        let now = Timestamp::new_test_instance();
  225|      1|
  226|      1|        // Get initial account to scan
  227|      1|        let start = frontier_scan.next(now);
  228|      1|        assert_eq!(start, Account::from(1));
  229|       |
  230|       |        // Create response with some frontiers
  231|      1|        let response = [
  232|      1|            Frontier::new(Account::from(2), BlockHash::from(1)),
  233|      1|            Frontier::new(Account::from(3), BlockHash::from(2)),
  234|      1|        ];
  235|      1|
  236|      1|        // Process should not be done until consideration_count is reached
  237|      1|        assert!(!frontier_scan.process(start, &response));
  238|      1|        assert!(!frontier_scan.process(start, &response));
  239|       |
  240|       |        // Head should not advance before reaching `consideration_count` responses
  241|      1|        assert_eq!(frontier_scan.next(now), Account::from(1));
  242|       |
  243|       |        // After consideration_count responses, should be done
  244|      1|        assert!(frontier_scan.process(start, &response));
  245|       |
  246|       |        // Head should advance to next account and start subsequent scan from there
  247|      1|        assert_eq!(frontier_scan.next(now), Account::from(3));
  248|      1|    }
  249|       |
  250|       |    #[test]
  251|      1|    fn range_wrap_around() {
  252|      1|        let config = FrontierScanConfig {
  253|      1|            head_parallelism: 1,
  254|      1|            consideration_count: 1,
  255|      1|            candidates: 1,
  256|      1|            ..Default::default()
  257|      1|        };
  258|      1|        let stats = Arc::new(Stats::default());
  259|      1|        let now = Timestamp::new_test_instance();
  260|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  261|      1|
  262|      1|        let start = frontier_scan.next(now);
  263|      1|
  264|      1|        // Create response that would push next beyond the range end
  265|      1|        let response = [Frontier::new(Account::MAX, BlockHash::from(1))];
  266|      1|
  267|      1|        // Process should succeed and wrap around
  268|      1|        assert!(frontier_scan.process(start, &response));
  269|       |
  270|       |        // Next account should be back at start of range
  271|      1|        let next = frontier_scan.next(now);
  272|      1|        assert_eq!(next, Account::from(1));
  273|      1|    }
  274|       |
  275|       |    #[test]
  276|      1|    fn cooldown() {
  277|      1|        let config = FrontierScanConfig {
  278|      1|            head_parallelism: 1,
  279|      1|            consideration_count: 1,
  280|      1|            cooldown: Duration::from_millis(250),
  281|      1|            ..Default::default()
  282|      1|        };
  283|      1|        let stats = Arc::new(Stats::default());
  284|      1|        let now = Timestamp::new_test_instance();
  285|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  286|      1|
  287|      1|        // First call should succeed
  288|      1|        let first = frontier_scan.next(now);
  289|      1|        assert!(!first.is_zero());
  290|       |
  291|       |        // Immediate second call should fail (return 0)
  292|      1|        let second = frontier_scan.next(now);
  293|      1|        assert!(second.is_zero());
  294|       |
  295|       |        // After cooldown, should succeed again
  296|      1|        let third = frontier_scan.next(now + Duration::from_millis(251));
  297|      1|        assert!(!third.is_zero());
  298|      1|    }
  299|       |
  300|       |    #[test]
  301|      1|    fn candidate_trimming() {
  302|      1|        let config = FrontierScanConfig {
  303|      1|            head_parallelism: 1,
  304|      1|            consideration_count: 2,
  305|      1|            candidates: 3, // Only keep the lowest candidates
  306|      1|            ..Default::default()
  307|      1|        };
  308|      1|        let stats = Arc::new(Stats::default());
  309|      1|        let now = Timestamp::new_test_instance();
  310|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  311|      1|
  312|      1|        let start = frontier_scan.next(now);
  313|      1|        // Create response with more candidates than limit
  314|      1|        let response1 = [
  315|      1|            Frontier::new(Account::from(1), BlockHash::from(0)),
  316|      1|            Frontier::new(Account::from(4), BlockHash::from(3)),
  317|      1|            Frontier::new(Account::from(7), BlockHash::from(6)),
  318|      1|            Frontier::new(Account::from(10), BlockHash::from(9)),
  319|      1|        ];
  320|      1|
  321|      1|        assert!(!frontier_scan.process(start, &response1));
  322|       |
  323|      1|        let response2 = [
  324|      1|            Frontier::new(Account::from(1), BlockHash::from(0)),
  325|      1|            Frontier::new(Account::from(3), BlockHash::from(2)),
  326|      1|            Frontier::new(Account::from(5), BlockHash::from(4)),
  327|      1|            Frontier::new(Account::from(7), BlockHash::from(6)),
  328|      1|            Frontier::new(Account::from(9), BlockHash::from(8)),
  329|      1|        ];
  330|      1|        assert!(frontier_scan.process(start, &response2));
  331|       |
  332|       |        // After processing replies candidates should be ordered and trimmed
  333|      1|        let next = frontier_scan.next(now);
  334|      1|        assert_eq!(next, Account::from(5));
  335|      1|    }
  336|       |
  337|       |    #[test]
  338|      1|    fn heads_distribution() {
  339|      1|        let config = FrontierScanConfig {
  340|      1|            head_parallelism: 4,
  341|      1|            ..Default::default()
  342|      1|        };
  343|      1|        let stats = Arc::new(Stats::default());
  344|      1|        let now = Timestamp::new_test_instance();
  345|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  346|      1|
  347|      1|        // Collect initial accounts from each head
  348|      1|        let first0 = frontier_scan.next(now);
  349|      1|        let first1 = frontier_scan.next(now);
  350|      1|        let first2 = frontier_scan.next(now);
  351|      1|        let first3 = frontier_scan.next(now);
  352|      1|
  353|      1|        // Verify accounts are properly distributed across the range
  354|      1|        assert!(first1 > first0);
  355|      1|        assert!(first2 > first1);
  356|      1|        assert!(first3 > first2);
  357|      1|    }
  358|       |
  359|       |    #[test]
  360|      1|    fn invalid_response_ordering() {
  361|      1|        let config = FrontierScanConfig {
  362|      1|            head_parallelism: 1,
  363|      1|            consideration_count: 1,
  364|      1|            ..Default::default()
  365|      1|        };
  366|      1|        let stats = Arc::new(Stats::default());
  367|      1|        let now = Timestamp::new_test_instance();
  368|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  369|      1|
  370|      1|        let start = frontier_scan.next(now);
  371|      1|
  372|      1|        // Create response with out-of-order accounts
  373|      1|        let response = [
  374|      1|            Frontier::new(Account::from(3), BlockHash::from(1)),
  375|      1|            Frontier::new(Account::from(2), BlockHash::from(2)),
  376|      1|        ];
  377|      1|
  378|      1|        // Should still process successfully
  379|      1|        assert!(frontier_scan.process(start, &response));
  380|      1|        assert_eq!(frontier_scan.next(now), Account::from(3));
  381|      1|    }
  382|       |
  383|       |    #[test]
  384|      1|    fn empty_responses() {
  385|      1|        let config = FrontierScanConfig {
  386|      1|            head_parallelism: 1,
  387|      1|            consideration_count: 2,
  388|      1|            ..Default::default()
  389|      1|        };
  390|      1|        let stats = Arc::new(Stats::default());
  391|      1|        let now = Timestamp::new_test_instance();
  392|      1|        let mut frontier_scan = FrontierScan::new(config, stats);
  393|      1|
  394|      1|        let start = frontier_scan.next(now);
  395|      1|
  396|      1|        // Empty response should not advance head even after receiving `consideration_count` responses
  397|      1|        assert!(!frontier_scan.process(start, &[]));
  398|      1|        assert!(!frontier_scan.process(start, &[]));
  399|      1|        assert_eq!(frontier_scan.next(now), start);
  400|       |
  401|       |        // Let the head advance
  402|      1|        let response = [Frontier::new(Account::from(2), BlockHash::from(1))];
  403|      1|        assert!(frontier_scan.process(start, &response));
  404|      1|        assert_eq!(frontier_scan.next(now), Account::from(2));
  405|       |
  406|       |        // However, after receiving enough empty responses, head should wrap around to the start
  407|      1|        assert!(!frontier_scan.process(start, &[]));
  408|      1|        assert!(!frontier_scan.process(start, &[]));
  409|      1|        assert!(!frontier_scan.process(start, &[]));
  410|      1|        assert_eq!(frontier_scan.next(now), Account::from(2));
  411|      1|        assert!(frontier_scan.process(start, &[]));
  412|       |        // Wraps around:
  413|      1|        assert_eq!(frontier_scan.next(now), Account::from(1));
  414|      1|    }
  415|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/ordered_blocking.rs:
    1|       |use rsnano_core::{Account, BlockHash};
    2|       |use std::{
    3|       |    collections::{BTreeMap, VecDeque},
    4|       |    mem::size_of,
    5|       |};
    6|       |
    7|       |#[derive(Clone)]
    8|       |pub(crate) struct BlockingEntry {
    9|       |    pub account: Account,
   10|       |    pub dependency: BlockHash,
   11|       |    pub dependency_account: Account,
   12|       |}
   13|       |
   14|       |/// A blocked account is an account that has failed to insert a new block because the source block is not currently present in the ledger
   15|       |/// An account is unblocked once it has a block successfully inserted
   16|       |#[derive(Default)]
   17|       |pub(crate) struct OrderedBlocking {
   18|       |    by_account: BTreeMap<Account, BlockingEntry>,
   19|       |    sequenced: VecDeque<Account>,
   20|       |    by_dependency: BTreeMap<BlockHash, Vec<Account>>,
   21|       |    by_dependency_account: BTreeMap<Account, Vec<Account>>,
   22|       |}
   23|       |
   24|       |impl OrderedBlocking {
   25|       |    pub const ELEMENT_SIZE: usize =
   26|       |        size_of::<BlockingEntry>() + size_of::<Account>() * 3 + size_of::<f32>();
   27|       |
   28|     20|    pub fn len(&self) -> usize {
   29|     20|        self.sequenced.len()
   30|     20|    }
   31|       |
   32|       |    #[allow(dead_code)]
   33|      2|    pub fn is_empty(&self) -> bool {
   34|      2|        self.len() == 0
   35|      2|    }
   36|       |
   37|     14|    pub fn insert(&mut self, entry: BlockingEntry) -> bool {
   38|     14|        let account = entry.account;
   39|     14|        let dependency = entry.dependency;
   40|     14|        let dependency_account = entry.dependency_account;
   41|     14|        if self.by_account.contains_key(&account) {
   42|      1|            return false;
   43|     13|        }
   44|     13|
   45|     13|        self.by_account.insert(account, entry);
   46|     13|        self.sequenced.push_back(account);
   47|     13|        self.by_dependency
   48|     13|            .entry(dependency)
   49|     13|            .or_default()
   50|     13|            .push(account);
   51|     13|        self.by_dependency_account
   52|     13|            .entry(dependency_account)
   53|     13|            .or_default()
   54|     13|            .push(account);
   55|     13|        true
   56|     14|    }
   57|       |
   58|    124|    pub fn contains(&self, account: &Account) -> bool {
   59|    124|        self.by_account.contains_key(account)
   60|    124|    }
   61|       |
   62|      2|    pub fn count_by_dependency_account(&self, dep_account: &Account) -> usize {
   63|      2|        self.by_dependency_account
   64|      2|            .get(dep_account)
   65|      2|            .map(|accs| accs.len())
                                      ^1
   66|      2|            .unwrap_or_default()
   67|      2|    }
   68|       |
   69|      4|    pub fn next(&self, filter: impl Fn(&BlockHash) -> bool) -> Option<BlockHash> {
   70|       |        // Scan all entries with unknown dependency account
   71|      4|        let accounts = self.by_dependency_account.get(&Account::zero())?;
                          ^2                                                         ^2
   72|      2|        accounts
   73|      2|            .iter()
   74|      4|            .map(|a| self.by_account.get(a).unwrap())
   75|      4|            .find(|e| filter(&e.dependency))
   76|      2|            .map(|e| e.dependency)
   77|      4|    }
   78|       |
   79|      0|    pub fn iter_start_dep_account(&self, start: Account) -> impl Iterator<Item = &BlockingEntry> {
   80|      0|        self.by_dependency_account
   81|      0|            .range(start..)
   82|      0|            .flat_map(|(_, accs)| accs)
   83|      0|            .map(|acc| self.by_account.get(acc).unwrap())
   84|      0|    }
   85|       |
   86|      5|    pub fn get(&self, account: &Account) -> Option<&BlockingEntry> {
   87|      5|        self.by_account.get(account)
   88|      5|    }
   89|       |
   90|      4|    pub fn pop_oldest(&mut self) -> Option<BlockingEntry> {
   91|      4|        let oldest = self.sequenced.front()?.clone();
                          ^2                             ^2
   92|      2|        self.remove(&oldest)
   93|      4|    }
   94|       |
   95|      5|    pub fn remove(&mut self, account: &Account) -> Option<BlockingEntry> {
   96|      5|        let entry = self.by_account.remove(account)?;
                          ^4                                     ^1
   97|      4|        self.remove_indexes(&entry);
   98|      4|        Some(entry)
   99|      5|    }
  100|       |
  101|      1|    pub fn modify_dependency_account(
  102|      1|        &mut self,
  103|      1|        dependency: &BlockHash,
  104|      1|        new_dependency_account: Account,
  105|      1|    ) -> usize {
  106|      1|        let Some(accounts) = self.by_dependency.get(dependency) else {
  107|      0|            return 0;
  108|       |        };
  109|       |
  110|      1|        let mut updated = 0;
  111|       |
  112|      2|        for account in accounts {
                          ^1
  113|      1|            let entry = self.by_account.get_mut(account).unwrap();
  114|      1|            if entry.dependency_account != new_dependency_account {
  115|      1|                let old_dependency_account = entry.dependency_account;
  116|      1|                entry.dependency_account = new_dependency_account;
  117|      1|                let old = self
  118|      1|                    .by_dependency_account
  119|      1|                    .get_mut(&old_dependency_account)
  120|      1|                    .unwrap();
  121|      1|                if old.len() == 1 {
  122|      1|                    self.by_dependency_account.remove(&old_dependency_account);
  123|      1|                } else {
  124|      0|                    old.retain(|a| *a != entry.account);
  125|      0|                }
  126|      1|                self.by_dependency_account
  127|      1|                    .entry(new_dependency_account)
  128|      1|                    .or_default()
  129|      1|                    .push(entry.account);
  130|      1|
  131|      1|                updated += 1;
  132|      0|            }
  133|       |        }
  134|       |
  135|      1|        updated
  136|      1|    }
  137|       |
  138|      4|    fn remove_indexes(&mut self, entry: &BlockingEntry) {
  139|      5|        self.sequenced.retain(|i| *i != entry.account);
  140|      4|        let accounts = self.by_dependency.get_mut(&entry.dependency).unwrap();
  141|      4|        if accounts.len() > 1 {
  142|      0|            accounts.retain(|i| *i != entry.account);
  143|      4|        } else {
  144|      4|            self.by_dependency.remove(&entry.dependency);
  145|      4|        }
  146|      4|        let accounts = self
  147|      4|            .by_dependency_account
  148|      4|            .get_mut(&entry.dependency_account)
  149|      4|            .unwrap();
  150|      4|        if accounts.len() > 1 {
  151|      2|            accounts.retain(|i| *i != entry.account);
  152|      3|        } else {
  153|      3|            self.by_dependency_account.remove(&entry.dependency_account);
  154|      3|        }
  155|      4|    }
  156|       |}
  157|       |
  158|       |#[cfg(test)]
  159|       |mod tests {
  160|       |    use super::*;
  161|       |
  162|       |    #[test]
  163|      1|    fn empty() {
  164|      1|        let mut blocking = OrderedBlocking::default();
  165|      1|        assert_eq!(blocking.len(), 0);
  166|      1|        assert_eq!(blocking.is_empty(), true);
  167|      1|        assert_eq!(blocking.contains(&Account::from(1)), false);
  168|      1|        assert_eq!(blocking.count_by_dependency_account(&Account::from(1)), 0);
  169|      1|        assert!(blocking.next(|_| true).is_none());
                                                ^0
  170|      1|        assert!(blocking.get(&Account::from(1)).is_none());
  171|      1|        assert!(blocking.remove(&Account::from(1)).is_none());
  172|      1|        assert!(blocking.pop_oldest().is_none());
  173|      1|    }
  174|       |
  175|       |    #[test]
  176|      1|    fn insert_one() {
  177|      1|        let mut blocking = OrderedBlocking::default();
  178|      1|
  179|      1|        let entry = BlockingEntry {
  180|      1|            account: Account::from(5),
  181|      1|            dependency: BlockHash::from(100),
  182|      1|            dependency_account: Account::from(13),
  183|      1|        };
  184|      1|        let inserted = blocking.insert(entry.clone());
  185|      1|
  186|      1|        assert_eq!(inserted, true);
  187|      1|        assert_eq!(blocking.len(), 1);
  188|      1|        assert_eq!(blocking.is_empty(), false);
  189|      1|        assert_eq!(blocking.contains(&entry.account), true);
  190|      1|        assert!(blocking.get(&entry.account).is_some());
  191|      1|        assert_eq!(
  192|      1|            blocking.count_by_dependency_account(&entry.dependency_account),
  193|      1|            1
  194|      1|        );
  195|      1|    }
  196|       |
  197|       |    #[test]
  198|      1|    fn dont_insert_if_account_already_present() {
  199|      1|        let mut blocking = OrderedBlocking::default();
  200|      1|
  201|      1|        let entry = BlockingEntry {
  202|      1|            account: Account::from(5),
  203|      1|            dependency: BlockHash::from(100),
  204|      1|            dependency_account: Account::from(13),
  205|      1|        };
  206|      1|        blocking.insert(entry.clone());
  207|      1|
  208|      1|        let inserted = blocking.insert(entry.clone());
  209|      1|
  210|      1|        assert_eq!(inserted, false);
  211|      1|        assert_eq!(blocking.len(), 1);
  212|      1|    }
  213|       |
  214|       |    #[test]
  215|      1|    fn next() {
  216|      1|        let mut blocking = OrderedBlocking::default();
  217|      1|
  218|      1|        let entry = BlockingEntry {
  219|      1|            account: Account::from(5),
  220|      1|            dependency: BlockHash::from(100),
  221|      1|            dependency_account: Account::zero(),
  222|      1|        };
  223|      1|        blocking.insert(entry.clone());
  224|      1|
  225|      1|        assert!(blocking.next(|_| true).is_some());
  226|      1|    }
  227|       |
  228|       |    #[test]
  229|      1|    fn next_returns_none_when_all_dependency_accounts_are_known() {
  230|      1|        let mut blocking = OrderedBlocking::default();
  231|      1|
  232|      1|        let entry = BlockingEntry {
  233|      1|            account: Account::from(5),
  234|      1|            dependency: BlockHash::from(100),
  235|      1|            dependency_account: Account::from(13),
  236|      1|        };
  237|      1|        blocking.insert(entry.clone());
  238|      1|
  239|      1|        assert!(blocking.next(|_| true).is_none());
                                                ^0
  240|      1|    }
  241|       |
  242|       |    #[test]
  243|      1|    fn next_with_filter() {
  244|      1|        let mut blocking = OrderedBlocking::default();
  245|      1|
  246|      1|        blocking.insert(BlockingEntry {
  247|      1|            account: Account::from(1000),
  248|      1|            dependency: BlockHash::from(100),
  249|      1|            dependency_account: Account::zero(),
  250|      1|        });
  251|      1|
  252|      1|        blocking.insert(BlockingEntry {
  253|      1|            account: Account::from(2000),
  254|      1|            dependency: BlockHash::from(200),
  255|      1|            dependency_account: Account::zero(),
  256|      1|        });
  257|      1|
  258|      1|        blocking.insert(BlockingEntry {
  259|      1|            account: Account::from(3000),
  260|      1|            dependency: BlockHash::from(300),
  261|      1|            dependency_account: Account::zero(),
  262|      1|        });
  263|      1|
  264|      1|        assert_eq!(
  265|      3|            blocking.next(|dep| *dep == BlockHash::from(300)),
  266|      1|            Some(BlockHash::from(300))
  267|      1|        );
  268|      1|    }
  269|       |
  270|       |    #[test]
  271|      1|    fn pop_front() {
  272|      1|        let mut blocking = OrderedBlocking::default();
  273|      1|
  274|      1|        blocking.insert(BlockingEntry {
  275|      1|            account: Account::from(1000),
  276|      1|            dependency: BlockHash::from(100),
  277|      1|            dependency_account: Account::zero(),
  278|      1|        });
  279|      1|
  280|      1|        blocking.insert(BlockingEntry {
  281|      1|            account: Account::from(2000),
  282|      1|            dependency: BlockHash::from(200),
  283|      1|            dependency_account: Account::zero(),
  284|      1|        });
  285|      1|
  286|      1|        assert_eq!(blocking.pop_oldest().unwrap().account, Account::from(1000));
  287|      1|        assert_eq!(blocking.pop_oldest().unwrap().account, Account::from(2000));
  288|      1|        assert!(blocking.pop_oldest().is_none());
  289|      1|    }
  290|       |
  291|       |    #[test]
  292|      1|    fn modify_dependency_account() {
  293|      1|        let mut blocking = OrderedBlocking::default();
  294|      1|
  295|      1|        let dependency = BlockHash::from(100);
  296|      1|        blocking.insert(BlockingEntry {
  297|      1|            account: Account::from(1000),
  298|      1|            dependency,
  299|      1|            dependency_account: Account::zero(),
  300|      1|        });
  301|      1|
  302|      1|        let new_dep_account = Account::from(5000);
  303|      1|        let updated = blocking.modify_dependency_account(&dependency, new_dep_account);
  304|      1|
  305|      1|        assert_eq!(updated, 1);
  306|      1|        assert_eq!(
  307|      1|            blocking
  308|      1|                .get(&Account::from(1000))
  309|      1|                .unwrap()
  310|      1|                .dependency_account,
  311|      1|            new_dep_account
  312|      1|        );
  313|      1|    }
  314|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/ordered_heads.rs:
    1|       |use rsnano_core::Account;
    2|       |use rsnano_nullable_clock::Timestamp;
    3|       |use std::collections::{BTreeMap, BTreeSet};
    4|       |
    5|       |/// Represents a range of accounts to scan, once the full range is scanned (goes past `end`)
    6|       |/// the head wraps around (to the `start`)
    7|       |pub(super) struct FrontierHead {
    8|       |    /// The range of accounts to scan is [start, end)
    9|       |    pub start: Account,
   10|       |    pub end: Account,
   11|       |
   12|       |    /// We scan the range by querying frontiers starting at 'next' and gathering candidates
   13|       |    pub next: Account,
   14|       |    pub candidates: BTreeSet<Account>,
   15|       |
   16|       |    pub requests: usize,
   17|       |    pub completed: usize,
   18|       |    pub timestamp: Timestamp,
   19|       |
   20|       |    /// Total number of accounts processed
   21|       |    pub processed: usize,
   22|       |}
   23|       |
   24|       |impl FrontierHead {
   25|    411|    pub fn new(start: impl Into<Account>, end: impl Into<Account>) -> Self {
   26|    411|        let start = start.into();
   27|    411|        Self {
   28|    411|            start,
   29|    411|            end: end.into(),
   30|    411|            next: start,
   31|    411|            candidates: Default::default(),
   32|    411|            requests: 0,
   33|    411|            completed: 0,
   34|    411|            timestamp: Timestamp::default(),
   35|    411|            processed: 0,
   36|    411|        }
   37|    411|    }
   38|       |}
   39|       |
   40|       |#[derive(Default)]
   41|       |pub(super) struct OrderedHeads {
   42|       |    sequenced: Vec<Account>,
   43|       |    by_start: BTreeMap<Account, FrontierHead>,
   44|       |    by_timestamp: BTreeMap<Timestamp, Vec<Account>>,
   45|       |}
   46|       |
   47|       |impl OrderedHeads {
   48|    411|    pub fn push_back(&mut self, head: FrontierHead) {
   49|    411|        let start = head.start;
   50|    411|        let timestamp = head.timestamp;
   51|    411|        let mut inserted = true;
   52|    411|        self.by_start
   53|    411|            .entry(start)
   54|    411|            .and_modify(|_| inserted = false)
                                          ^1
   55|    411|            .or_insert(head);
   56|    411|
   57|    411|        if !inserted {
   58|      1|            return;
   59|    410|        }
   60|    410|        self.sequenced.push(start);
   61|    410|        self.by_timestamp.entry(timestamp).or_default().push(start);
   62|    411|    }
   63|       |
   64|     28|    pub fn ordered_by_timestamp(&self) -> impl Iterator<Item = &FrontierHead> {
   65|     28|        self.by_timestamp
   66|     28|            .values()
   67|     28|            .flatten()
   68|     31|            .map(|start| self.by_start.get(start).unwrap())
   69|     28|    }
   70|       |
   71|     41|    pub fn modify<F>(&mut self, start: &Account, mut f: F)
   72|     41|    where
   73|     41|        F: FnMut(&mut FrontierHead),
   74|     41|    {
   75|     41|        if let Some(head) = self.by_start.get_mut(start) {
                                  ^40
   76|     40|            let old_timestamp = head.timestamp;
   77|     40|            f(head);
   78|     40|            if head.timestamp != old_timestamp {
   79|     27|                let accounts = self.by_timestamp.get_mut(&old_timestamp).unwrap();
   80|     27|                if accounts.len() == 1 {
   81|     22|                    self.by_timestamp.remove(&old_timestamp);
   82|     22|                } else {
   83|     13|                    accounts.retain(|a| a != start);
   84|      5|                }
   85|     27|                self.by_timestamp
   86|     27|                    .entry(head.timestamp)
   87|     27|                    .or_default()
   88|     27|                    .push(*start);
   89|     13|            }
   90|       |        } else {
   91|      1|            panic!("head not found: {}", start.encode_account());
   92|       |        }
   93|     40|    }
   94|       |
   95|     22|    pub fn find_first_less_than_or_equal_to(&self, account: impl Into<Account>) -> Option<Account> {
   96|     22|        self.by_start
   97|     22|            .range(..=account.into())
   98|     22|            .last()
   99|     22|            .map(|(start, _)| *start)
                                            ^21
  100|     22|    }
  101|       |
  102|      5|    pub fn iter(&self) -> impl Iterator<Item = &FrontierHead> {
  103|      5|        self.by_start.values()
  104|      5|    }
  105|       |
  106|     15|    pub fn len(&self) -> usize {
  107|     15|        self.sequenced.len()
  108|     15|    }
  109|       |}
  110|       |
  111|       |#[cfg(test)]
  112|       |mod tests {
  113|       |    use super::*;
  114|       |    use std::time::Duration;
  115|       |
  116|       |    #[test]
  117|      1|    fn empty() {
  118|      1|        let heads = OrderedHeads::default();
  119|      1|
  120|      1|        assert_eq!(heads.len(), 0);
  121|      1|        assert!(heads.iter().next().is_none());
  122|      1|        assert!(heads.ordered_by_timestamp().next().is_none());
  123|      1|    }
  124|       |
  125|       |    #[test]
  126|      1|    fn push_back_one_head() {
  127|      1|        let mut heads = OrderedHeads::default();
  128|      1|
  129|      1|        heads.push_back(FrontierHead::new(1, 10));
  130|      1|
  131|      1|        assert_eq!(heads.len(), 1);
  132|      1|        assert_eq!(heads.iter().count(), 1);
  133|      1|        assert_eq!(heads.ordered_by_timestamp().count(), 1);
  134|      1|    }
  135|       |
  136|       |    #[test]
  137|      1|    fn push_back_multiple() {
  138|      1|        let mut heads = OrderedHeads::default();
  139|      1|
  140|      1|        heads.push_back(FrontierHead::new(1, 10));
  141|      1|        heads.push_back(FrontierHead::new(10, 20));
  142|      1|        heads.push_back(FrontierHead::new(20, 30));
  143|      1|
  144|      1|        assert_eq!(heads.len(), 3);
  145|      1|        assert_eq!(heads.iter().count(), 3);
  146|      1|        assert_eq!(heads.ordered_by_timestamp().count(), 3);
  147|      1|    }
  148|       |
  149|       |    #[test]
  150|      1|    fn order_by_timestamp() {
  151|      1|        let mut heads = OrderedHeads::default();
  152|      1|
  153|      1|        let now = Timestamp::new_test_instance();
  154|      1|
  155|      1|        heads.push_back(FrontierHead {
  156|      1|            timestamp: now + Duration::from_secs(100),
  157|      1|            ..FrontierHead::new(1, 10)
  158|      1|        });
  159|      1|        heads.push_back(FrontierHead {
  160|      1|            timestamp: now + Duration::from_secs(99),
  161|      1|            ..FrontierHead::new(10, 20)
  162|      1|        });
  163|      1|        heads.push_back(FrontierHead {
  164|      1|            timestamp: now + Duration::from_secs(101),
  165|      1|            ..FrontierHead::new(20, 30)
  166|      1|        });
  167|      1|
  168|      1|        let ordered: Vec<_> = heads.ordered_by_timestamp().collect();
  169|      1|        assert_eq!(ordered[0].start, 10.into());
  170|      1|        assert_eq!(ordered[1].start, 1.into());
  171|      1|        assert_eq!(ordered[2].start, 20.into());
  172|      1|    }
  173|       |
  174|       |    #[test]
  175|       |    #[should_panic = "head not found"]
  176|      1|    fn modify_unknown_start_panics() {
  177|      1|        let mut heads = OrderedHeads::default();
  178|      1|        heads.modify(&Account::from(123), |_| {});
                                                            ^0
  179|      1|    }
  180|       |
  181|       |    #[test]
  182|      1|    fn modify_nothing() {
  183|      1|        let mut heads = OrderedHeads::default();
  184|      1|        heads.push_back(FrontierHead::new(1, 10));
  185|      1|
  186|      1|        heads.modify(&Account::from(1), |_| {});
  187|      1|
  188|      1|        assert_eq!(heads.iter().next().unwrap().timestamp, Default::default());
  189|      1|        assert_eq!(heads.sequenced.len(), 1);
  190|      1|        assert_eq!(heads.by_timestamp.len(), 1);
  191|      1|        assert_eq!(heads.by_start.len(), 1);
  192|      1|    }
  193|       |
  194|       |    #[test]
  195|      1|    fn modify_timestamp() {
  196|      1|        let mut heads = OrderedHeads::default();
  197|      1|        heads.push_back(FrontierHead::new(1, 10));
  198|      1|
  199|      1|        let now = Timestamp::new_test_instance();
  200|      1|        heads.modify(&Account::from(1), |head| head.timestamp = now);
  201|      1|
  202|      1|        assert_eq!(heads.iter().next().unwrap().timestamp, now);
  203|      1|        assert_eq!(heads.sequenced.len(), 1);
  204|      1|        assert_eq!(heads.by_start.len(), 1);
  205|      1|        assert_eq!(heads.by_timestamp.len(), 1);
  206|      1|        assert_eq!(*heads.by_timestamp.first_key_value().unwrap().0, now);
  207|      1|    }
  208|       |
  209|       |    #[test]
  210|      1|    fn modify_duplicate_timestamp() {
  211|      1|        let mut heads = OrderedHeads::default();
  212|      1|        heads.push_back(FrontierHead::new(1, 10));
  213|      1|        heads.push_back(FrontierHead::new(10, 20));
  214|      1|
  215|      1|        let now = Timestamp::new_test_instance();
  216|      1|        heads.modify(&Account::from(1), |head| head.timestamp = now);
  217|      1|
  218|      1|        assert_eq!(heads.by_timestamp.len(), 2);
  219|      1|        assert_eq!(
  220|      1|            heads.by_timestamp.get(&Default::default()).unwrap(),
  221|      1|            &vec![Account::from(10)]
  222|      1|        );
  223|      1|        assert_eq!(
  224|      1|            heads.by_timestamp.get(&now).unwrap(),
  225|      1|            &vec![Account::from(1)]
  226|      1|        );
  227|      1|    }
  228|       |
  229|       |    #[test]
  230|      1|    fn find_first_less_than_or_equal_to() {
  231|      1|        let mut heads = OrderedHeads::default();
  232|      1|        heads.push_back(FrontierHead::new(1, 10));
  233|      1|        heads.push_back(FrontierHead::new(10, 20));
  234|      1|
  235|      1|        assert_eq!(heads.find_first_less_than_or_equal_to(0), None);
  236|      1|        assert_eq!(
  237|      1|            heads.find_first_less_than_or_equal_to(1),
  238|      1|            Some(Account::from(1))
  239|      1|        );
  240|      1|        assert_eq!(
  241|      1|            heads.find_first_less_than_or_equal_to(2),
  242|      1|            Some(Account::from(1))
  243|      1|        );
  244|      1|        assert_eq!(
  245|      1|            heads.find_first_less_than_or_equal_to(9),
  246|      1|            Some(Account::from(1))
  247|      1|        );
  248|      1|        assert_eq!(
  249|      1|            heads.find_first_less_than_or_equal_to(10),
  250|      1|            Some(Account::from(10))
  251|      1|        );
  252|      1|        assert_eq!(
  253|      1|            heads.find_first_less_than_or_equal_to(10),
  254|      1|            Some(Account::from(10))
  255|      1|        );
  256|      1|        assert_eq!(
  257|      1|            heads.find_first_less_than_or_equal_to(20),
  258|      1|            Some(Account::from(10))
  259|      1|        );
  260|      1|        assert_eq!(
  261|      1|            heads.find_first_less_than_or_equal_to(30),
  262|      1|            Some(Account::from(10))
  263|      1|        );
  264|      1|    }
  265|       |
  266|       |    #[test]
  267|      1|    fn ignore_duplicate_insert() {
  268|      1|        let mut heads = OrderedHeads::default();
  269|      1|        heads.push_back(FrontierHead::new(1, 10));
  270|      1|        heads.push_back(FrontierHead::new(1, 10));
  271|      1|        assert_eq!(heads.len(), 1);
  272|      1|        assert_eq!(heads.sequenced.len(), 1);
  273|      1|        assert_eq!(heads.by_start.len(), 1);
  274|      1|    }
  275|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/ordered_priorities.rs:
    1|       |use super::priority::{Priority, PriorityKeyDesc};
    2|       |use rsnano_core::Account;
    3|       |use rsnano_nullable_clock::Timestamp;
    4|       |use std::collections::BTreeMap;
    5|       |use std::mem::size_of;
    6|       |
    7|       |#[derive(Clone, Default)]
    8|       |pub(crate) struct PriorityEntry {
    9|       |    pub account: Account,
   10|       |    pub priority: Priority,
   11|       |    pub fails: usize,
   12|       |    pub timestamp: Option<Timestamp>,
   13|       |}
   14|       |
   15|       |impl PriorityEntry {
   16|     38|    pub fn new(account: Account, priority: Priority) -> Self {
   17|     38|        Self {
   18|     38|            account,
   19|     38|            priority,
   20|     38|            fails: 0,
   21|     38|            timestamp: None,
   22|     38|        }
   23|     38|    }
   24|       |
   25|       |    #[allow(dead_code)]
   26|      0|    pub fn new_test_instance() -> Self {
   27|      0|        Self {
   28|      0|            account: Account::from(7),
   29|      0|            priority: Priority::new(3.0),
   30|      0|            fails: 0,
   31|      0|            timestamp: None,
   32|      0|        }
   33|      0|    }
   34|       |}
   35|       |
   36|       |/// Tracks the ongoing account priorities
   37|       |/// This only stores account priorities > 1.0f.
   38|       |#[derive(Default)]
   39|       |pub(crate) struct OrderedPriorities {
   40|       |    by_account: BTreeMap<Account, PriorityEntry>,
   41|       |    by_priority: BTreeMap<PriorityKeyDesc, Vec<Account>>, // descending
   42|       |}
   43|       |
   44|       |pub(crate) enum ChangePriorityResult {
   45|       |    Updated,
   46|       |    Deleted,
   47|       |    NotFound,
   48|       |}
   49|       |
   50|       |impl OrderedPriorities {
   51|       |    pub const ELEMENT_SIZE: usize =
   52|       |        size_of::<PriorityEntry>() + size_of::<Account>() + size_of::<f32>() + size_of::<u64>() * 4;
   53|       |
   54|     21|    pub fn len(&self) -> usize {
   55|     21|        self.by_account.len()
   56|     21|    }
   57|       |
   58|     18|    pub fn is_empty(&self) -> bool {
   59|     18|        self.by_account.is_empty()
   60|     18|    }
   61|       |
   62|     13|    pub fn get(&self, account: &Account) -> Option<&PriorityEntry> {
   63|     13|        self.by_account.get(account)
   64|     13|    }
   65|       |
   66|     11|    pub fn contains(&self, account: &Account) -> bool {
   67|     11|        self.by_account.contains_key(account)
   68|     11|    }
   69|       |
   70|     38|    pub fn insert(&mut self, entry: PriorityEntry) -> bool {
   71|     38|        let account = entry.account;
   72|     38|        let priority = entry.priority;
   73|     38|
   74|     38|        if self.by_account.contains_key(&account) {
   75|      1|            return false;
   76|     37|        }
   77|     37|
   78|     37|        self.by_account.insert(account, entry);
   79|     37|        self.by_priority
   80|     37|            .entry(priority.into())
   81|     37|            .or_default()
   82|     37|            .push(account);
   83|     37|        true
   84|     38|    }
   85|       |
   86|      5|    pub fn pop_lowest_prio(&mut self) -> Option<PriorityEntry> {
   87|      3|        let lowest_prio_account = {
   88|      5|            let (_, v) = self.by_priority.last_key_value()?;
                                                                        ^2
   89|      3|            v.first().unwrap().clone()
   90|      3|        };
   91|      3|        Some(self.remove_account(&lowest_prio_account))
   92|      5|    }
   93|       |
   94|      1|    pub fn change_timestamp(&mut self, account: &Account, timestamp: Option<Timestamp>) {
   95|      1|        if let Some(entry) = self.by_account.get_mut(account) {
   96|      1|            entry.timestamp = timestamp;
   97|      1|        }
                       ^0
   98|      1|    }
   99|       |
  100|    119|    pub fn modify(
  101|    119|        &mut self,
  102|    119|        account: &Account,
  103|    119|        mut f: impl FnMut(&mut PriorityEntry) -> bool,
  104|    119|    ) -> ChangePriorityResult {
  105|    119|        if let Some(entry) = self.by_account.get_mut(account) {
                                  ^104
  106|    104|            let old_prio = entry.priority;
  107|    104|            if f(entry) {
  108|    102|                if entry.priority != old_prio {
  109|     66|                    let new_prio = entry.priority;
  110|     66|                    self.change_priority_internal(account, old_prio, new_prio)
  111|     36|                }
  112|    102|                ChangePriorityResult::Updated
  113|       |            } else {
  114|      2|                self.remove_account(account);
  115|      2|                ChangePriorityResult::Deleted
  116|       |            }
  117|       |        } else {
  118|     15|            ChangePriorityResult::NotFound
  119|       |        }
  120|    119|    }
  121|       |
  122|      6|    pub fn next_priority(
  123|      6|        &self,
  124|      6|        cutoff: Timestamp,
  125|      6|        filter: impl Fn(&Account) -> bool,
  126|      6|    ) -> Option<&PriorityEntry> {
  127|      6|        self.by_priority
  128|      6|            .values()
  129|      6|            .flatten()
  130|      8|            .map(|account| self.by_account.get(account).unwrap())
  131|      8|            .find(|entry| {
  132|      8|                if let Some(ts) = entry.timestamp {
                                          ^2
  133|      2|                    if ts > cutoff {
  134|      1|                        return false;
  135|      1|                    }
  136|      6|                }
  137|      7|                filter(&entry.account)
  138|      8|            })
  139|      6|    }
  140|       |
  141|      5|    pub fn remove(&mut self, account: &Account) -> Option<PriorityEntry> {
  142|      5|        if let Some(entry) = self.by_account.remove(account) {
                                  ^4
  143|      4|            self.remove_priority(account, entry.priority);
  144|      4|            Some(entry)
  145|       |        } else {
  146|      1|            None
  147|       |        }
  148|      5|    }
  149|       |
  150|     66|    fn change_priority_internal(
  151|     66|        &mut self,
  152|     66|        account: &Account,
  153|     66|        old_prio: Priority,
  154|     66|        new_prio: Priority,
  155|     66|    ) {
  156|     66|        self.remove_priority(account, old_prio);
  157|     66|        self.by_priority
  158|     66|            .entry(new_prio.into())
  159|     66|            .or_default()
  160|     66|            .push(*account);
  161|     66|    }
  162|       |
  163|      5|    fn remove_account(&mut self, account: &Account) -> PriorityEntry {
  164|      5|        let entry = self.by_account.remove(account).unwrap();
  165|      5|        self.remove_priority(account, entry.priority);
  166|      5|        entry
  167|      5|    }
  168|       |
  169|     75|    fn remove_priority(&mut self, account: &Account, priority: Priority) {
  170|     75|        let ids = self.by_priority.get_mut(&priority.into()).unwrap();
  171|     75|        if ids.len() > 1 {
  172|      5|            ids.retain(|i| i != account);
  173|     73|        } else {
  174|     73|            self.by_priority.remove(&priority.into());
  175|     73|        }
  176|     75|    }
  177|       |}
  178|       |
  179|       |#[cfg(test)]
  180|       |mod tests {
  181|       |    use super::*;
  182|       |
  183|       |    #[test]
  184|      1|    fn empty() {
  185|      1|        let mut priorities = OrderedPriorities::default();
  186|      1|        assert_eq!(priorities.len(), 0);
  187|      1|        assert!(priorities.is_empty());
  188|      1|        assert!(priorities.get(&Account::from(1)).is_none());
  189|      1|        assert_eq!(priorities.contains(&Account::from(1)), false);
  190|      1|        assert!(priorities.pop_lowest_prio().is_none());
  191|      1|        assert!(priorities.remove(&Account::from(1)).is_none());
  192|      1|    }
  193|       |
  194|       |    #[test]
  195|      1|    fn insert_one() {
  196|      1|        let mut priorities = OrderedPriorities::default();
  197|      1|        let account = Account::from(1);
  198|      1|        assert!(priorities.insert(PriorityEntry::new(account, Priority::new(2.5))));
  199|      1|        assert_eq!(priorities.len(), 1);
  200|      1|        assert_eq!(priorities.is_empty(), false);
  201|      1|        assert_eq!(priorities.contains(&account), true);
  202|      1|        assert!(priorities.get(&account).is_some());
  203|      1|    }
  204|       |
  205|       |    #[test]
  206|      1|    fn insert_two() {
  207|      1|        let mut priorities = OrderedPriorities::default();
  208|      1|        assert!(priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5))));
  209|      1|        assert!(priorities.insert(PriorityEntry::new(Account::from(2), Priority::new(3.5))));
  210|      1|        assert_eq!(priorities.len(), 2);
  211|      1|        assert_eq!(priorities.is_empty(), false);
  212|      1|        assert_eq!(priorities.contains(&Account::from(1)), true);
  213|      1|        assert_eq!(priorities.contains(&Account::from(2)), true);
  214|      1|    }
  215|       |
  216|       |    #[test]
  217|      1|    fn dont_insert_when_account_already_present() {
  218|      1|        let mut priorities = OrderedPriorities::default();
  219|      1|        priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5)));
  220|      1|        let inserted = priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(3.5)));
  221|      1|        assert_eq!(inserted, false);
  222|      1|        assert_eq!(priorities.len(), 1);
  223|      1|    }
  224|       |
  225|       |    #[test]
  226|      1|    fn pop_front() {
  227|      1|        let mut priorities = OrderedPriorities::default();
  228|      1|        priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5)));
  229|      1|        priorities.insert(PriorityEntry::new(Account::from(2), Priority::new(2.5)));
  230|      1|        priorities.insert(PriorityEntry::new(Account::from(3), Priority::new(2.5)));
  231|      1|
  232|      1|        assert_eq!(
  233|      1|            priorities.pop_lowest_prio().unwrap().account,
  234|      1|            Account::from(1)
  235|      1|        );
  236|      1|        assert_eq!(
  237|      1|            priorities.pop_lowest_prio().unwrap().account,
  238|      1|            Account::from(2)
  239|      1|        );
  240|      1|        assert_eq!(
  241|      1|            priorities.pop_lowest_prio().unwrap().account,
  242|      1|            Account::from(3)
  243|      1|        );
  244|      1|        assert!(priorities.pop_lowest_prio().is_none());
  245|      1|    }
  246|       |
  247|       |    #[test]
  248|      1|    fn change_timestamp() {
  249|      1|        let account = Account::from(1);
  250|      1|        let mut priorities = OrderedPriorities::default();
  251|      1|        priorities.insert(PriorityEntry::new(account, Priority::new(2.5)));
  252|      1|        let now = Timestamp::new_test_instance();
  253|      1|
  254|      1|        priorities.change_timestamp(&account, Some(now));
  255|      1|
  256|      1|        assert_eq!(priorities.get(&account).unwrap().timestamp, Some(now));
  257|      1|    }
  258|       |
  259|       |    mod next_priority {
  260|       |        use super::*;
  261|       |        use std::time::Duration;
  262|       |
  263|       |        #[test]
  264|      1|        fn empty() {
  265|      1|            let priorities = OrderedPriorities::default();
  266|      1|            let next = priorities.next_priority(Timestamp::new_test_instance(), |_account| true);
                                                                                                         ^0
  267|      1|            assert!(next.is_none());
  268|      1|        }
  269|       |
  270|       |        #[test]
  271|      1|        fn one_item() {
  272|      1|            let mut priorities = OrderedPriorities::default();
  273|      1|            let account = Account::from(1);
  274|      1|            priorities.insert(PriorityEntry::new(account, Priority::new(2.5)));
  275|      1|
  276|      1|            let next = priorities
  277|      1|                .next_priority(Timestamp::new_test_instance(), |_account| true)
  278|      1|                .unwrap();
  279|      1|
  280|      1|            assert_eq!(next.account, account);
  281|      1|        }
  282|       |
  283|       |        #[test]
  284|      1|        fn ordered_by_priority_desc() {
  285|      1|            let mut priorities = OrderedPriorities::default();
  286|      1|            priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5)));
  287|      1|            priorities.insert(PriorityEntry::new(Account::from(2), Priority::new(10.0)));
  288|      1|            priorities.insert(PriorityEntry::new(Account::from(3), Priority::new(3.5)));
  289|      1|
  290|      1|            let next = priorities
  291|      1|                .next_priority(Timestamp::new_test_instance(), |_account| true)
  292|      1|                .unwrap();
  293|      1|
  294|      1|            assert_eq!(next.account, Account::from(2));
  295|      1|        }
  296|       |
  297|       |        #[test]
  298|      1|        fn cutoff() {
  299|      1|            let now = Timestamp::new_test_instance();
  300|      1|            let a = PriorityEntry::new(Account::from(1), Priority::new(2.5));
  301|      1|            let mut b = PriorityEntry::new(Account::from(2), Priority::new(10.0));
  302|      1|            b.timestamp = Some(now);
  303|      1|            let mut c = PriorityEntry::new(Account::from(3), Priority::new(3.5));
  304|      1|            c.timestamp = Some(now - Duration::from_secs(60));
  305|      1|            let mut priorities = OrderedPriorities::default();
  306|      1|            priorities.insert(a);
  307|      1|            priorities.insert(b);
  308|      1|            priorities.insert(c);
  309|      1|
  310|      1|            let next = priorities
  311|      1|                .next_priority(now - Duration::from_secs(30), |_account| true)
  312|      1|                .unwrap();
  313|      1|
  314|      1|            assert_eq!(next.account, Account::from(3));
  315|      1|        }
  316|       |
  317|       |        #[test]
  318|      1|        fn filter() {
  319|      1|            let a = PriorityEntry::new(Account::from(1), Priority::new(2.5));
  320|      1|            let b = PriorityEntry::new(Account::from(2), Priority::new(10.0));
  321|      1|            let c = PriorityEntry::new(Account::from(3), Priority::new(3.5));
  322|      1|            let mut priorities = OrderedPriorities::default();
  323|      1|            priorities.insert(a);
  324|      1|            priorities.insert(b);
  325|      1|            priorities.insert(c);
  326|      1|
  327|      1|            let next = priorities
  328|      3|                .next_priority(Timestamp::new_test_instance(), |account| {
  329|      3|                    *account == Account::from(1)
  330|      3|                })
  331|      1|                .unwrap();
  332|      1|
  333|      1|            assert_eq!(next.account, Account::from(1));
  334|      1|        }
  335|       |    }
  336|       |
  337|       |    #[test]
  338|      1|    fn change_priority() {
  339|      1|        let mut priorities = OrderedPriorities::default();
  340|      1|        priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5)));
  341|      1|        priorities.insert(PriorityEntry::new(Account::from(2), Priority::new(3.0)));
  342|      1|        priorities.insert(PriorityEntry::new(Account::from(3), Priority::new(3.5)));
  343|      1|
  344|      1|        let mut old_priority = Priority::ZERO;
  345|      1|        let new_priority = Priority::new(10.0);
  346|      1|
  347|      1|        priorities.modify(&Account::from(2), |entry| {
  348|      1|            old_priority = entry.priority;
  349|      1|            entry.priority = new_priority;
  350|      1|            true
  351|      1|        });
  352|      1|
  353|      1|        assert_eq!(old_priority, Priority::new(3.0));
  354|      1|        assert_eq!(
  355|      1|            priorities.get(&Account::from(2)).unwrap().priority,
  356|      1|            new_priority
  357|      1|        );
  358|       |
  359|      1|        let next = priorities
  360|      1|            .next_priority(Timestamp::new_test_instance(), |_| true)
  361|      1|            .unwrap();
  362|      1|        assert_eq!(next.account, Account::from(2));
  363|      1|    }
  364|       |
  365|       |    #[test]
  366|      1|    fn remove_by_priority_change() {
  367|      1|        let mut priorities = OrderedPriorities::default();
  368|      1|        let account = Account::from(1);
  369|      1|        priorities.insert(PriorityEntry::new(account, Priority::new(2.5)));
  370|      1|
  371|      1|        priorities.modify(&account, |_| false);
  372|      1|
  373|      1|        assert_eq!(priorities.len(), 0);
  374|      1|    }
  375|       |
  376|       |    #[test]
  377|      1|    fn remove() {
  378|      1|        let mut priorities = OrderedPriorities::default();
  379|      1|        priorities.insert(PriorityEntry::new(Account::from(1), Priority::new(2.5)));
  380|      1|        priorities.insert(PriorityEntry::new(Account::from(2), Priority::new(3.0)));
  381|      1|        priorities.insert(PriorityEntry::new(Account::from(3), Priority::new(3.5)));
  382|      1|
  383|      1|        let removed = priorities.remove(&Account::from(2)).unwrap();
  384|      1|
  385|      1|        assert_eq!(removed.account, Account::from(2));
  386|      1|        assert_eq!(priorities.len(), 2);
  387|      1|    }
  388|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/peer_scoring.rs:
    1|       |use super::BootstrapConfig;
    2|       |use rsnano_core::utils::ContainerInfo;
    3|       |use rsnano_network::{Channel, ChannelId, TrafficType};
    4|       |use std::{
    5|       |    collections::{BTreeMap, HashMap},
    6|       |    sync::{Arc, Weak},
    7|       |};
    8|       |
    9|       |/// Container for tracking and scoring peers with respect to bootstrapping
   10|       |pub(crate) struct PeerScoring {
   11|       |    scoring: OrderedScoring,
   12|       |    config: BootstrapConfig,
   13|       |    channels: Vec<Arc<Channel>>,
   14|       |}
   15|       |
   16|       |impl PeerScoring {
   17|      3|    pub fn new(config: BootstrapConfig) -> Self {
   18|      3|        Self {
   19|      3|            scoring: OrderedScoring::default(),
   20|      3|            config,
   21|      3|            channels: Vec::new(),
   22|      3|        }
   23|      3|    }
   24|       |
   25|      0|    pub fn received_message(&mut self, channel_id: ChannelId) {
   26|      0|        self.scoring.modify(channel_id, |i| {
   27|      0|            if i.outstanding > 1 {
   28|      0|                i.outstanding -= 1;
   29|      0|                i.response_count_total += 1;
   30|      0|            }
   31|      0|        });
   32|      0|    }
   33|       |
   34|     15|    pub fn channel(&mut self) -> Option<Arc<Channel>> {
   35|     15|        self.channels
   36|     15|            .iter()
   37|     15|            .find(|c| {
   38|      0|                if !c.should_drop(TrafficType::BootstrapRequests) {
   39|      0|                    if !Self::try_send_message(&mut self.scoring, c, &self.config) {
   40|      0|                        true
   41|       |                    } else {
   42|      0|                        false
   43|       |                    }
   44|       |                } else {
   45|      0|                    false
   46|       |                }
   47|     15|            })
                          ^0
   48|     15|            .cloned()
   49|     15|    }
   50|       |
   51|      0|    fn try_send_message(
   52|      0|        scoring: &mut OrderedScoring,
   53|      0|        channel: &Arc<Channel>,
   54|      0|        config: &BootstrapConfig,
   55|      0|    ) -> bool {
   56|      0|        let mut result = false;
   57|      0|        let modified = scoring.modify(channel.channel_id(), |i| {
   58|      0|            if i.outstanding < config.channel_limit {
   59|      0|                i.outstanding += 1;
   60|      0|                i.request_count_total += 1;
   61|      0|            } else {
   62|      0|                result = true;
   63|      0|            }
   64|      0|        });
   65|      0|        if !modified {
   66|      0|            scoring.insert(PeerScore::new(channel));
   67|      0|        }
   68|      0|        result
   69|      0|    }
   70|       |
   71|      0|    pub fn len(&self) -> usize {
   72|      0|        self.scoring.len()
   73|      0|    }
   74|       |
   75|      0|    pub fn available(&self) -> usize {
   76|      0|        self.channels
   77|      0|            .iter()
   78|      0|            .filter(|c| !self.limit_exceeded(c))
   79|      0|            .count()
   80|      0|    }
   81|       |
   82|      0|    fn limit_exceeded(&self, channel: &Channel) -> bool {
   83|      0|        if let Some(existing) = self.scoring.get(channel.channel_id()) {
   84|      0|            existing.outstanding >= self.config.channel_limit
   85|       |        } else {
   86|      0|            false
   87|       |        }
   88|      0|    }
   89|       |
   90|      3|    pub fn timeout(&mut self) {
   91|      3|        self.scoring.retain(|i| i.is_alive());
                                              ^0
   92|      3|        self.scoring.modify_all(|i| i.decay());
                                                  ^0
   93|      3|    }
   94|       |
   95|       |    // Synchronize channels with the network, passed channels should be shuffled
   96|      3|    pub fn sync(&mut self, channels: Vec<Arc<Channel>>) {
   97|      3|        self.channels = channels;
   98|      3|    }
   99|       |
  100|      0|    pub fn container_info(&self) -> ContainerInfo {
  101|      0|        [
  102|      0|            ("scores", self.len(), 0),
  103|      0|            ("available", self.available(), 0),
  104|      0|            ("channels", self.channels.len(), 0),
  105|      0|        ]
  106|      0|        .into()
  107|      0|    }
  108|       |}
  109|       |
  110|       |struct PeerScore {
  111|       |    channel_id: ChannelId,
  112|       |    channel: Weak<Channel>,
  113|       |    /// Number of outstanding requests to a peer
  114|       |    outstanding: usize,
  115|       |    request_count_total: usize,
  116|       |    response_count_total: usize,
  117|       |}
  118|       |
  119|       |impl PeerScore {
  120|      0|    fn new(channel: &Arc<Channel>) -> Self {
  121|      0|        Self {
  122|      0|            channel_id: channel.channel_id(),
  123|      0|            channel: Arc::downgrade(channel),
  124|      0|            outstanding: 1,
  125|      0|            request_count_total: 1,
  126|      0|            response_count_total: 0,
  127|      0|        }
  128|      0|    }
  129|       |
  130|      0|    fn is_alive(&self) -> bool {
  131|      0|        self.channel
  132|      0|            .upgrade()
  133|      0|            .map(|i| i.is_alive())
  134|      0|            .unwrap_or(false)
  135|      0|    }
  136|       |
  137|      0|    fn decay(&mut self) {
  138|      0|        if self.outstanding > 0 {
  139|      0|            self.outstanding -= 1;
  140|      0|        }
  141|      0|    }
  142|       |}
  143|       |
  144|       |#[derive(Default)]
  145|       |struct OrderedScoring {
  146|       |    by_channel: HashMap<ChannelId, PeerScore>,
  147|       |    by_outstanding: BTreeMap<usize, Vec<ChannelId>>,
  148|       |}
  149|       |
  150|       |impl OrderedScoring {
  151|      0|    fn len(&self) -> usize {
  152|      0|        self.by_channel.len()
  153|      0|    }
  154|       |
  155|       |    #[allow(dead_code)]
  156|      0|    fn get(&self, channel_id: ChannelId) -> Option<&PeerScore> {
  157|      0|        self.by_channel.get(&channel_id)
  158|      0|    }
  159|       |
  160|      0|    fn insert(&mut self, score: PeerScore) -> Option<PeerScore> {
  161|      0|        let outstanding = score.outstanding;
  162|      0|        let channel_id = score.channel_id;
  163|      0|
  164|      0|        let old = self.by_channel.insert(score.channel_id, score);
  165|       |
  166|      0|        if let Some(old) = &old {
  167|      0|            self.remove_outstanding(old.channel_id, old.outstanding);
  168|      0|        }
  169|       |
  170|      0|        self.insert_outstanding(channel_id, outstanding);
  171|      0|        old
  172|      0|    }
  173|       |
  174|      0|    fn modify(&mut self, channel_id: ChannelId, mut f: impl FnMut(&mut PeerScore)) -> bool {
  175|      0|        if let Some(scoring) = self.by_channel.get_mut(&channel_id) {
  176|      0|            let old_outstanding = scoring.outstanding;
  177|      0|            f(scoring);
  178|      0|            let new_outstanding = scoring.outstanding;
  179|      0|            if new_outstanding != old_outstanding {
  180|      0|                self.remove_outstanding(channel_id, old_outstanding);
  181|      0|                self.insert_outstanding(channel_id, new_outstanding);
  182|      0|            }
  183|      0|            true
  184|       |        } else {
  185|      0|            false
  186|       |        }
  187|      0|    }
  188|       |
  189|      3|    fn modify_all(&mut self, mut f: impl FnMut(&mut PeerScore)) {
  190|      3|        let channel_ids: Vec<ChannelId> = self.by_channel.keys().cloned().collect();
  191|      3|        for id in channel_ids {
                          ^0
  192|      0|            self.modify(id, &mut f);
  193|      0|        }
  194|      3|    }
  195|       |
  196|      3|    fn retain(&mut self, mut f: impl FnMut(&PeerScore) -> bool) {
  197|      3|        let to_delete = self
  198|      3|            .by_channel
  199|      3|            .values()
  200|      3|            .filter(|i| !f(i))
                                      ^0
  201|      3|            .map(|i| i.channel_id)
                                   ^0
  202|      3|            .collect::<Vec<_>>();
  203|       |
  204|      3|        for channel_id in to_delete {
                          ^0
  205|      0|            self.remove(channel_id);
  206|      0|        }
  207|      3|    }
  208|       |
  209|      0|    fn remove(&mut self, channel_id: ChannelId) {
  210|      0|        if let Some(scoring) = self.by_channel.remove(&channel_id) {
  211|      0|            self.remove_outstanding(channel_id, scoring.outstanding);
  212|      0|        }
  213|      0|    }
  214|       |
  215|      0|    fn insert_outstanding(&mut self, channel_id: ChannelId, outstanding: usize) {
  216|      0|        self.by_outstanding
  217|      0|            .entry(outstanding)
  218|      0|            .or_default()
  219|      0|            .push(channel_id);
  220|      0|    }
  221|       |
  222|      0|    fn remove_outstanding(&mut self, channel_id: ChannelId, outstanding: usize) {
  223|      0|        let channel_ids = self.by_outstanding.get_mut(&outstanding).unwrap();
  224|      0|        if channel_ids.len() > 1 {
  225|      0|            channel_ids.retain(|i| *i != channel_id);
  226|      0|        } else {
  227|      0|            self.by_outstanding.remove(&outstanding);
  228|      0|        }
  229|      0|    }
  230|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/priority.rs:
    1|       |use ordered_float::OrderedFloat;
    2|       |use std::ops::{Add, Deref, Div, Mul, Sub};
    3|       |
    4|       |#[derive(PartialEq, Eq, Default, Clone, Copy, Ord, PartialOrd)]
    5|       |pub struct Priority(OrderedFloat<f64>);
    6|       |
    7|       |impl Priority {
    8|     46|    pub const fn new(value: f64) -> Self {
    9|     46|        Self(OrderedFloat(value))
   10|     46|    }
   11|       |
   12|       |    pub const ZERO: Self = Self(OrderedFloat(0.0));
   13|       |
   14|     14|    pub fn as_f64(&self) -> f64 {
   15|     14|        self.0 .0
   16|     14|    }
   17|       |}
   18|       |
   19|       |impl Add for Priority {
   20|       |    type Output = Priority;
   21|       |
   22|    100|    fn add(self, rhs: Self) -> Self::Output {
   23|    100|        Self(self.0 + rhs.0)
   24|    100|    }
   25|       |}
   26|       |
   27|       |impl Sub for Priority {
   28|       |    type Output = Priority;
   29|       |
   30|      1|    fn sub(self, rhs: Self) -> Self::Output {
   31|      1|        Self(self.0 - rhs.0)
   32|      1|    }
   33|       |}
   34|       |
   35|       |impl Mul<f64> for Priority {
   36|       |    type Output = Priority;
   37|       |
   38|      1|    fn mul(self, rhs: f64) -> Self::Output {
   39|      1|        Self(self.0 * rhs)
   40|      1|    }
   41|       |}
   42|       |
   43|       |impl Div<f64> for Priority {
   44|       |    type Output = Priority;
   45|       |
   46|      5|    fn div(self, rhs: f64) -> Self::Output {
   47|      5|        Self(self.0 / rhs)
   48|      5|    }
   49|       |}
   50|       |
   51|       |impl From<Priority> for f64 {
   52|      0|    fn from(value: Priority) -> Self {
   53|      0|        value.as_f64()
   54|      0|    }
   55|       |}
   56|       |
   57|       |impl std::fmt::Debug for Priority {
   58|      1|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   59|      1|        std::fmt::Debug::fmt(&self.0 .0, f)
   60|      1|    }
   61|       |}
   62|       |
   63|       |impl std::fmt::Display for Priority {
   64|      1|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   65|      1|        std::fmt::Display::fmt(&self.0 .0, f)
   66|      1|    }
   67|       |}
   68|       |
   69|       |/// Priority in descending order
   70|       |#[derive(PartialEq, Eq, Default, Clone, Copy)]
   71|       |pub(crate) struct PriorityKeyDesc(pub Priority);
   72|       |
   73|       |impl Ord for PriorityKeyDesc {
   74|    169|    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
   75|    169|        // order descending
   76|    169|        other.0.cmp(&self.0)
   77|    169|    }
   78|       |}
   79|       |
   80|       |impl PartialOrd for PriorityKeyDesc {
   81|      0|    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
   82|      0|        Some(self.cmp(other))
   83|      0|    }
   84|       |}
   85|       |
   86|       |impl Deref for PriorityKeyDesc {
   87|       |    type Target = Priority;
   88|       |
   89|      0|    fn deref(&self) -> &Self::Target {
   90|      0|        &self.0
   91|      0|    }
   92|       |}
   93|       |
   94|       |impl From<Priority> for PriorityKeyDesc {
   95|    251|    fn from(value: Priority) -> Self {
   96|    251|        Self(value)
   97|    251|    }
   98|       |}
   99|       |
  100|       |#[cfg(test)]
  101|       |mod tests {
  102|       |    use super::*;
  103|       |
  104|       |    #[test]
  105|      1|    fn create() {
  106|      1|        assert_priority_eq(Priority::new(1.0), Priority::new(1.0));
  107|      1|        assert!(Priority::new(1.0) != Priority::new(1.1));
  108|      1|        assert_eq!(Priority::new(1.23).as_f64(), 1.23);
  109|      1|    }
  110|       |
  111|       |    #[test]
  112|      1|    fn add() {
  113|      1|        assert_priority_eq(Priority::new(1.0) + Priority::new(2.5), Priority::new(3.5));
  114|      1|    }
  115|       |
  116|       |    #[test]
  117|      1|    fn sub() {
  118|      1|        assert_priority_eq(Priority::new(2.4) - Priority::new(1.1), Priority::new(1.3));
  119|      1|    }
  120|       |
  121|       |    #[test]
  122|      1|    fn mul() {
  123|      1|        assert_priority_eq(Priority::new(2.4) * 2.0, Priority::new(4.8));
  124|      1|    }
  125|       |
  126|       |    #[test]
  127|      1|    fn div() {
  128|      1|        assert_priority_eq(Priority::new(2.4) / 2.0, Priority::new(1.2));
  129|      1|    }
  130|       |
  131|       |    #[test]
  132|      1|    fn format() {
  133|      1|        assert_eq!(format!("{}", Priority::new(1.23)), "1.23");
  134|      1|        assert_eq!(format!("{:?}", Priority::new(1.23)), "1.23");
  135|      1|    }
  136|       |
  137|      5|    fn assert_priority_eq(actual: Priority, expected: Priority) {
  138|      5|        let actual = actual.as_f64();
  139|      5|        let expected = expected.as_f64();
  140|      5|        let diff = actual - expected;
  141|      5|        assert!(
  142|      5|            diff.abs() < 0.001,
  143|      0|            "expected priority {} to be equal to {}",
  144|       |            actual,
  145|       |            expected
  146|       |        );
  147|      5|    }
  148|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/running_query_container.rs:
    1|       |use rsnano_core::{Account, BlockHash, HashOrAccount};
    2|       |use rsnano_nullable_clock::Timestamp;
    3|       |use std::{
    4|       |    collections::{HashMap, VecDeque},
    5|       |    mem::size_of,
    6|       |    time::Duration,
    7|       |};
    8|       |
    9|       |use crate::stats::DetailType;
   10|       |
   11|       |#[derive(Default, PartialEq, Eq, Debug, Clone, Copy)]
   12|       |pub(crate) enum QueryType {
   13|       |    #[default]
   14|       |    Invalid,
   15|       |    BlocksByHash,
   16|       |    BlocksByAccount,
   17|       |    AccountInfoByHash,
   18|       |    Frontiers,
   19|       |}
   20|       |
   21|       |impl From<QueryType> for DetailType {
   22|      5|    fn from(value: QueryType) -> Self {
   23|      5|        match value {
   24|      1|            QueryType::Invalid => DetailType::Invalid,
   25|      1|            QueryType::BlocksByHash => DetailType::BlocksByHash,
   26|      1|            QueryType::BlocksByAccount => DetailType::BlocksByAccount,
   27|      1|            QueryType::AccountInfoByHash => DetailType::AccountInfoByHash,
   28|      1|            QueryType::Frontiers => DetailType::Frontiers,
   29|       |        }
   30|      5|    }
   31|       |}
   32|       |
   33|       |#[derive(Default, PartialEq, Eq, Debug, Clone, Copy)]
   34|       |pub(crate) enum QuerySource {
   35|       |    #[default]
   36|       |    Invalid,
   37|       |    Priority,
   38|       |    Database,
   39|       |    Dependencies,
   40|       |    Frontiers,
   41|       |}
   42|       |
   43|       |/// Information about a running query that hasn't been responded yet
   44|       |#[derive(Clone, Debug, PartialEq, Eq)]
   45|       |pub(crate) struct RunningQuery {
   46|       |    pub query_type: QueryType,
   47|       |    pub source: QuerySource,
   48|       |    pub start: HashOrAccount,
   49|       |    pub account: Account,
   50|       |    pub hash: BlockHash,
   51|       |    pub count: usize,
   52|       |    pub cutoff: Timestamp,
   53|       |    pub timestamp: Timestamp,
   54|       |    pub id: u64,
   55|       |}
   56|       |
   57|       |impl RunningQuery {
   58|       |    #[allow(dead_code)]
   59|     15|    pub fn new_test_instance() -> Self {
   60|     15|        Self {
   61|     15|            query_type: QueryType::BlocksByHash,
   62|     15|            source: QuerySource::Database,
   63|     15|            start: HashOrAccount::from(1),
   64|     15|            account: Account::from(2),
   65|     15|            hash: BlockHash::from(3),
   66|     15|            count: 4,
   67|     15|            cutoff: Timestamp::new_test_instance() + Duration::from_secs(30),
   68|     15|            timestamp: Timestamp::new_test_instance(),
   69|     15|            id: 42,
   70|     15|        }
   71|     15|    }
   72|       |}
   73|       |
   74|       |#[derive(Default)]
   75|       |pub(crate) struct RunningQueryContainer {
   76|       |    by_id: HashMap<u64, RunningQuery>,
   77|       |    by_account: HashMap<Account, Vec<u64>>,
   78|       |    by_hash: HashMap<BlockHash, Vec<u64>>,
   79|       |    sequenced: VecDeque<u64>,
   80|       |}
   81|       |
   82|       |static EMPTY_IDS: Vec<u64> = Vec::new();
   83|       |
   84|       |impl RunningQueryContainer {
   85|       |    pub const ELEMENT_SIZE: usize =
   86|       |        size_of::<RunningQuery>() + size_of::<Account>() + size_of::<u64>() * 3;
   87|       |
   88|     19|    pub(crate) fn len(&self) -> usize {
   89|     19|        self.sequenced.len()
   90|     19|    }
   91|       |
   92|      4|    pub fn contains(&self, id: u64) -> bool {
   93|      4|        self.by_id.contains_key(&id)
   94|      4|    }
   95|       |
   96|       |    #[allow(dead_code)]
   97|      4|    pub fn get(&self, id: u64) -> Option<&RunningQuery> {
   98|      4|        self.by_id.get(&id)
   99|      4|    }
  100|       |
  101|      5|    pub fn modify(&mut self, id: u64, mut f: impl FnMut(&mut RunningQuery)) -> bool {
  102|      5|        let Some(query) = self.by_id.get_mut(&id) else {
                               ^4
  103|      1|            return false;
  104|       |        };
  105|       |
  106|      4|        let old_id = query.id;
  107|      4|        let old_account = query.account;
  108|      4|        let old_hash = query.hash;
  109|      4|        f(query);
  110|      4|        assert_eq!(query.id, old_id, "query id must not be changed");
                                                   ^1
  111|      3|        assert_eq!(query.account, old_account, "account must not be changed");
                                                             ^1
  112|      2|        assert_eq!(query.hash, old_hash, "hash must not be changed");
                                                       ^1
  113|       |
  114|      1|        true
  115|      2|    }
  116|       |
  117|      2|    pub fn count_by_account(&self, account: &Account, source: QuerySource) -> usize {
  118|      2|        self.iter_account(account)
  119|      2|            .filter(|i| i.source == source)
                                      ^1
  120|      2|            .count()
  121|      2|    }
  122|       |
  123|      3|    pub fn iter_hash(&self, hash: &BlockHash) -> impl Iterator<Item = &RunningQuery> {
  124|      3|        self.iter_ids(self.by_hash.get(hash))
  125|      3|    }
  126|       |
  127|      5|    pub fn iter_account(&self, account: &Account) -> impl Iterator<Item = &RunningQuery> {
  128|      5|        self.iter_ids(self.by_account.get(account))
  129|      5|    }
  130|       |
  131|      8|    fn iter_ids<'a>(&'a self, ids: Option<&'a Vec<u64>>) -> impl Iterator<Item = &'a RunningQuery> {
  132|      8|        let ids = ids.unwrap_or(&EMPTY_IDS);
  133|      8|        ids.iter().map(|id| self.by_id.get(id).unwrap())
                                          ^5
  134|      8|    }
  135|       |
  136|      4|    pub fn remove(&mut self, id: u64) -> Option<RunningQuery> {
  137|      4|        if let Some(tag) = self.by_id.remove(&id) {
                                  ^3
  138|      3|            self.remove_by_account(id, &tag.account);
  139|      3|            self.remove_by_hash(id, &tag.hash);
  140|      5|            self.sequenced.retain(|i| *i != id);
  141|      3|            Some(tag)
  142|       |        } else {
  143|      1|            None
  144|       |        }
  145|      4|    }
  146|       |
  147|      8|    pub fn front(&self) -> Option<&RunningQuery> {
  148|      8|        self.sequenced.front().map(|id| self.by_id.get(id).unwrap())
                                                      ^4
  149|      8|    }
  150|       |
  151|      3|    pub fn pop_front(&mut self) -> Option<RunningQuery> {
  152|      3|        if let Some(id) = self.sequenced.pop_front() {
                                  ^2
  153|      2|            let result = self.by_id.remove(&id).unwrap();
  154|      2|            self.remove_by_account(id, &result.account);
  155|      2|            self.remove_by_hash(id, &result.hash);
  156|      2|            Some(result)
  157|       |        } else {
  158|      1|            None
  159|       |        }
  160|      3|    }
  161|       |
  162|     18|    pub(crate) fn insert(&mut self, query: RunningQuery) {
  163|     18|        let id = query.id;
  164|     18|        let account = query.account;
  165|     18|        let hash = query.hash;
  166|     18|        if let Some(old) = self.by_id.insert(id, query) {
                                  ^1
  167|      1|            self.remove_internal(old.id, &old.account, &old.hash);
  168|     17|        }
  169|     18|        self.by_account.entry(account).or_default().push(id);
  170|     18|        self.by_hash.entry(hash).or_default().push(id);
  171|     18|        self.sequenced.push_back(id);
  172|     18|    }
  173|       |
  174|      1|    fn remove_internal(&mut self, id: u64, account: &Account, hash: &BlockHash) {
  175|      1|        self.remove_by_account(id, account);
  176|      1|        self.remove_by_hash(id, hash);
  177|      1|        self.sequenced.retain(|i| *i != id);
  178|      1|    }
  179|       |
  180|      7|    fn remove_by_account(&mut self, id: u64, account: &Account) {
  181|      7|        match self.by_account.get_mut(account) {
  182|      6|            Some(ids) => {
  183|      6|                if ids.len() == 1 {
  184|      4|                    self.by_account.remove(account);
  185|      4|                } else {
  186|      5|                    ids.retain(|i| *i != id)
                                  ^2                     ^2
  187|       |                }
  188|       |            }
  189|      1|            None => unreachable!(), // The account entry must exist
  190|       |        }
  191|      6|    }
  192|      7|    fn remove_by_hash(&mut self, id: u64, hash: &BlockHash) {
  193|      7|        match self.by_hash.get_mut(hash) {
  194|      6|            Some(ids) => {
  195|      6|                if ids.len() == 1 {
  196|      4|                    self.by_hash.remove(hash);
  197|      4|                } else {
  198|      5|                    ids.retain(|i| *i != id)
                                  ^2                     ^2
  199|       |                }
  200|       |            }
  201|      1|            None => unreachable!(), // The hash entry must exist
  202|       |        }
  203|      6|    }
  204|       |}
  205|       |
  206|       |#[cfg(test)]
  207|       |mod tests {
  208|       |    use super::*;
  209|       |
  210|       |    #[test]
  211|      1|    fn empty() {
  212|      1|        let mut container = RunningQueryContainer::default();
  213|      1|        assert_eq!(container.len(), 0);
  214|      1|        assert_eq!(container.contains(123), false);
  215|      1|        assert_eq!(container.get(123), None);
  216|      1|        assert_eq!(
  217|      1|            container.count_by_account(&Account::from(1), QuerySource::Priority),
  218|      1|            0
  219|      1|        );
  220|      1|        assert_eq!(container.iter_hash(&BlockHash::from(1)).next(), None);
  221|      1|        assert_eq!(container.iter_account(&Account::from(1)).next(), None);
  222|      1|        assert_eq!(container.front(), None);
  223|      1|        assert_eq!(container.pop_front(), None);
  224|      1|    }
  225|       |
  226|       |    #[test]
  227|      1|    fn insert_one() {
  228|      1|        let mut container = RunningQueryContainer::default();
  229|      1|        let query = RunningQuery::new_test_instance();
  230|      1|
  231|      1|        container.insert(query.clone());
  232|      1|
  233|      1|        assert_eq!(container.len(), 1);
  234|      1|        assert_eq!(container.contains(query.id), true);
  235|      1|        assert_eq!(container.get(query.id), Some(&query));
  236|      1|        assert_eq!(container.count_by_account(&query.account, query.source), 1);
  237|      1|        assert_eq!(container.front(), Some(&query));
  238|      1|        assert_eq!(
  239|      1|            container
  240|      1|                .iter_hash(&query.hash)
  241|      1|                .cloned()
  242|      1|                .collect::<Vec<_>>(),
  243|      1|            vec![query.clone()]
  244|      1|        );
  245|      1|        assert_eq!(
  246|      1|            container
  247|      1|                .iter_account(&query.account)
  248|      1|                .cloned()
  249|      1|                .collect::<Vec<_>>(),
  250|      1|            vec![query]
  251|      1|        );
  252|      1|    }
  253|       |
  254|       |    #[test]
  255|      1|    fn insert_two() {
  256|      1|        let mut container = RunningQueryContainer::default();
  257|      1|        let query1 = RunningQuery::new_test_instance();
  258|      1|        let query2 = RunningQuery {
  259|      1|            id: 999,
  260|      1|            ..RunningQuery::new_test_instance()
  261|      1|        };
  262|      1|
  263|      1|        container.insert(query1.clone());
  264|      1|        container.insert(query2.clone());
  265|      1|
  266|      1|        assert_eq!(container.len(), 2);
  267|      1|        assert_eq!(container.contains(query1.id), true);
  268|      1|        assert_eq!(container.contains(query2.id), true);
  269|      1|    }
  270|       |
  271|       |    #[test]
  272|      1|    fn when_same_query_inserted_twice_should_replace_first_insert() {
  273|      1|        let mut container = RunningQueryContainer::default();
  274|      1|        let query_a = RunningQuery::new_test_instance();
  275|      1|        let query_b = RunningQuery {
  276|      1|            count: 99999,
  277|      1|            ..query_a
  278|      1|        };
  279|      1|
  280|      1|        container.insert(query_a);
  281|      1|        container.insert(query_b.clone());
  282|      1|
  283|      1|        assert_eq!(container.len(), 1);
  284|      1|        assert_eq!(container.get(query_b.id), Some(&query_b));
  285|      1|    }
  286|       |
  287|       |    #[test]
  288|      1|    fn modify() {
  289|      1|        let mut container = RunningQueryContainer::default();
  290|      1|        let query = RunningQuery::new_test_instance();
  291|      1|        container.insert(query.clone());
  292|      1|        let new_cutoff = Timestamp::new_test_instance() + Duration::from_secs(999);
  293|      1|        let modified = container.modify(query.id, |q| q.cutoff = new_cutoff);
  294|      1|        assert!(modified);
  295|      1|        assert_eq!(
  296|      1|            container.get(query.id),
  297|      1|            Some(&RunningQuery {
  298|      1|                cutoff: new_cutoff,
  299|      1|                ..query
  300|      1|            })
  301|      1|        );
  302|      1|    }
  303|       |
  304|       |    #[test]
  305|      1|    fn modify_non_existant() {
  306|      1|        let mut container = RunningQueryContainer::default();
  307|      1|        let modified = container.modify(123, |_| unreachable!());
  308|      1|        assert!(!modified);
  309|      1|    }
  310|       |
  311|       |    #[test]
  312|       |    #[should_panic]
  313|      1|    fn modify_panics_when_account_changed() {
  314|      1|        let mut container = RunningQueryContainer::default();
  315|      1|        let query = RunningQuery::new_test_instance();
  316|      1|        container.insert(query.clone());
  317|      1|
  318|      1|        container.modify(query.id, |q| q.account = Account::from(1000));
  319|      1|    }
  320|       |
  321|       |    #[test]
  322|       |    #[should_panic]
  323|      1|    fn modify_panics_when_hash_changed() {
  324|      1|        let mut container = RunningQueryContainer::default();
  325|      1|        let query = RunningQuery::new_test_instance();
  326|      1|        container.insert(query.clone());
  327|      1|
  328|      1|        container.modify(query.id, |q| q.hash = BlockHash::from(1000));
  329|      1|    }
  330|       |
  331|       |    #[test]
  332|       |    #[should_panic]
  333|      1|    fn modify_panics_when_id_changed() {
  334|      1|        let mut container = RunningQueryContainer::default();
  335|      1|        let query = RunningQuery::new_test_instance();
  336|      1|        container.insert(query.clone());
  337|      1|
  338|      1|        container.modify(query.id, |q| q.id = 1000);
  339|      1|    }
  340|       |
  341|       |    #[test]
  342|      1|    fn remove() {
  343|      1|        let mut container = RunningQueryContainer::default();
  344|      1|        let query = RunningQuery::new_test_instance();
  345|      1|        container.insert(query.clone());
  346|      1|
  347|      1|        container.remove(query.id);
  348|      1|
  349|      1|        assert_eq!(container.len(), 0);
  350|      1|        assert_eq!(container.sequenced.len(), 0);
  351|      1|        assert_eq!(container.by_id.len(), 0);
  352|      1|        assert_eq!(container.by_hash.len(), 0);
  353|      1|        assert_eq!(container.by_account.len(), 0);
  354|      1|    }
  355|       |
  356|       |    #[test]
  357|      1|    fn remove_none() {
  358|      1|        let mut container = RunningQueryContainer::default();
  359|      1|        container.remove(123);
  360|      1|        assert_eq!(container.len(), 0);
  361|      1|    }
  362|       |
  363|       |    #[test]
  364|      1|    fn remove_one_of_two_queries_with_same_hash() {
  365|      1|        let mut container = RunningQueryContainer::default();
  366|      1|        let query_a = RunningQuery::new_test_instance();
  367|      1|        let query_b = RunningQuery {
  368|      1|            id: 999,
  369|      1|            account: Account::from(999),
  370|      1|            ..query_a
  371|      1|        };
  372|      1|        container.insert(query_a.clone());
  373|      1|        container.insert(query_b.clone());
  374|      1|
  375|      1|        container.remove(query_a.id);
  376|      1|
  377|      1|        assert_eq!(container.len(), 1);
  378|      1|        assert_eq!(
  379|      1|            container.iter_hash(&query_b.hash).collect::<Vec<_>>(),
  380|      1|            vec![&query_b]
  381|      1|        )
  382|      1|    }
  383|       |
  384|       |    #[test]
  385|      1|    fn remove_one_of_two_queries_with_same_account() {
  386|      1|        let mut container = RunningQueryContainer::default();
  387|      1|        let query_a = RunningQuery::new_test_instance();
  388|      1|        let query_b = RunningQuery {
  389|      1|            id: 999,
  390|      1|            hash: BlockHash::from(999),
  391|      1|            ..query_a
  392|      1|        };
  393|      1|        container.insert(query_a.clone());
  394|      1|        container.insert(query_b.clone());
  395|      1|
  396|      1|        container.remove(query_a.id);
  397|      1|
  398|      1|        assert_eq!(container.len(), 1);
  399|      1|        assert_eq!(
  400|      1|            container.iter_account(&query_b.account).collect::<Vec<_>>(),
  401|      1|            vec![&query_b]
  402|      1|        )
  403|      1|    }
  404|       |
  405|       |    #[test]
  406|      1|    fn pop_front_the_only_entry() {
  407|      1|        let mut container = RunningQueryContainer::default();
  408|      1|        let query = RunningQuery::new_test_instance();
  409|      1|        container.insert(query.clone());
  410|      1|
  411|      1|        assert_eq!(container.front(), Some(&query));
  412|      1|        let popped = container.pop_front();
  413|      1|
  414|      1|        assert_eq!(container.len(), 0);
  415|      1|        assert_eq!(popped, Some(query));
  416|      1|    }
  417|       |
  418|       |    #[test]
  419|      1|    fn pop_front_with_multiple_entries() {
  420|      1|        let mut container = RunningQueryContainer::default();
  421|      1|        let query_a = RunningQuery::new_test_instance();
  422|      1|        let query_b = RunningQuery {
  423|      1|            id: 1000,
  424|      1|            ..RunningQuery::new_test_instance()
  425|      1|        };
  426|      1|        let query_c = RunningQuery {
  427|      1|            id: 2000,
  428|      1|            ..RunningQuery::new_test_instance()
  429|      1|        };
  430|      1|        container.insert(query_a.clone());
  431|      1|        container.insert(query_b.clone());
  432|      1|        container.insert(query_c.clone());
  433|      1|
  434|      1|        assert_eq!(container.front(), Some(&query_a));
  435|      1|        let popped = container.pop_front();
  436|      1|
  437|      1|        assert_eq!(container.len(), 2);
  438|      1|        assert_eq!(popped, Some(query_a));
  439|      1|        assert_eq!(container.front(), Some(&query_b));
  440|      1|    }
  441|       |
  442|       |    #[test]
  443|       |    #[should_panic]
  444|      1|    fn remove_by_account_panics_when_account_not_found() {
  445|      1|        let mut container = RunningQueryContainer::default();
  446|      1|        container.remove_by_account(123, &Account::from(1000));
  447|      1|    }
  448|       |
  449|       |    #[test]
  450|       |    #[should_panic]
  451|      1|    fn remove_by_hash_panics_when_hash_not_found() {
  452|      1|        let mut container = RunningQueryContainer::default();
  453|      1|        container.remove_by_hash(123, &BlockHash::from(1000));
  454|      1|    }
  455|       |
  456|       |    #[test]
  457|      1|    fn query_type_to_detail_type() {
  458|      1|        let expectations = [
  459|      1|            (QueryType::Invalid, DetailType::Invalid),
  460|      1|            (QueryType::BlocksByHash, DetailType::BlocksByHash),
  461|      1|            (QueryType::BlocksByAccount, DetailType::BlocksByAccount),
  462|      1|            (QueryType::AccountInfoByHash, DetailType::AccountInfoByHash),
  463|      1|            (QueryType::Frontiers, DetailType::Frontiers),
  464|      1|        ];
  465|       |
  466|      6|        for (qt, dt) in expectations {
                           ^5
  467|      5|            assert_eq!(DetailType::from(qt), dt);
  468|       |        }
  469|      1|    }
  470|       |}

/home/gustav/code/nano/rsnano-node/node/src/bootstrap/throttle.rs:
    1|       |use std::collections::VecDeque;
    2|       |
    3|       |/// Used to throttle the ascending bootstrapper once it reaches a steady state
    4|       |/// Tracks verify_result samples and signals throttling if no tracked samples have gotten results
    5|       |pub(crate) struct Throttle {
    6|       |    /// Bit set that tracks sample results. True when something was retrieved, false otherwise
    7|       |    samples: VecDeque<bool>,
    8|       |    successes: usize,
    9|       |}
   10|       |
   11|       |impl Throttle {
   12|      7|    pub fn new(size: usize) -> Self {
   13|      7|        debug_assert!(size > 0);
   14|      7|        Self {
   15|      7|            samples: vec![true; size].into(),
   16|      7|            successes: size,
   17|      7|        }
   18|      7|    }
   19|       |
   20|      7|    pub fn throttled(&self) -> bool {
   21|      7|        self.successes == 0
   22|      7|    }
   23|       |
   24|      6|    pub fn add(&mut self, sample: bool) {
   25|      6|        self.pop();
   26|      6|        self.samples.push_back(sample);
   27|      6|        if sample {
   28|      0|            self.successes += 1;
   29|      6|        }
   30|      6|    }
   31|       |
   32|       |    /// Resizes the number of samples tracked
   33|       |    /// Drops the oldest samples if the size decreases
   34|       |    /// Adds false samples if the size increases
   35|      5|    pub fn resize(&mut self, size: usize) {
   36|      5|        debug_assert!(size > 0);
   37|      7|        while self.samples.len() > size {
   38|      2|            self.pop();
   39|      2|        }
   40|      7|        while self.samples.len() < size {
   41|      2|            self.samples.push_back(false);
   42|      2|        }
   43|      5|    }
   44|       |
   45|      0|    pub fn len(&self) -> usize {
   46|      0|        self.samples.len()
   47|      0|    }
   48|       |
   49|      0|    pub fn successes(&self) -> usize {
   50|      0|        self.successes
   51|      0|    }
   52|       |
   53|      8|    fn pop(&mut self) {
   54|      8|        if let Some(sample) = self.samples.pop_front() {
   55|      8|            if sample {
   56|      8|                self.successes -= 1;
   57|      8|            }
                           ^0
   58|      0|        }
   59|      8|    }
   60|       |}
   61|       |
   62|       |#[cfg(test)]
   63|       |mod tests {
   64|       |    use super::*;
   65|       |
   66|       |    #[test]
   67|      1|    fn empty() {
   68|      1|        let throttle = Throttle::new(2);
   69|      1|        assert_eq!(throttle.throttled(), false);
   70|      1|    }
   71|       |
   72|       |    #[test]
   73|      1|    fn throttled() {
   74|      1|        let mut throttle = Throttle::new(2);
   75|      1|        throttle.add(false);
   76|      1|        assert_eq!(throttle.throttled(), false);
   77|      1|        throttle.add(false);
   78|      1|        assert_eq!(throttle.throttled(), true);
   79|      1|    }
   80|       |
   81|       |    #[test]
   82|      1|    fn resize_up() {
   83|      1|        let mut throttle = Throttle::new(2);
   84|      1|        throttle.add(false);
   85|      1|        throttle.resize(4);
   86|      1|        assert_eq!(throttle.throttled(), false);
   87|      1|        throttle.add(false);
   88|      1|        assert_eq!(throttle.throttled(), true);
   89|      1|    }
   90|       |
   91|       |    #[test]
   92|      1|    fn resize_down() {
   93|      1|        let mut throttle = Throttle::new(4);
   94|      1|        throttle.add(false);
   95|      1|        throttle.resize(2);
   96|      1|        assert_eq!(throttle.throttled(), false);
   97|      1|        throttle.add(false);
   98|      1|        assert_eq!(throttle.throttled(), true);
   99|      1|    }
  100|       |}

/home/gustav/code/nano/rsnano-node/node/src/cementation/confirming_set.rs:
    1|       |use crate::{
    2|       |    block_processing::BlockContext,
    3|       |    consensus::Election,
    4|       |    stats::{DetailType, StatType, Stats},
    5|       |    utils::{ThreadPool, ThreadPoolImpl},
    6|       |};
    7|       |use rsnano_core::{utils::ContainerInfo, BlockHash, SavedBlock};
    8|       |use rsnano_ledger::{BlockStatus, Ledger, WriteGuard, Writer};
    9|       |use rsnano_store_lmdb::LmdbWriteTransaction;
   10|       |use std::{
   11|       |    collections::{HashSet, VecDeque},
   12|       |    sync::{
   13|       |        atomic::{AtomicBool, Ordering},
   14|       |        Arc, Condvar, Mutex,
   15|       |    },
   16|       |    thread::JoinHandle,
   17|       |    time::{Duration, Instant},
   18|       |};
   19|       |use tracing::debug;
   20|       |
   21|       |use super::ordered_entries::{Entry, OrderedEntries};
   22|       |
   23|       |#[derive(Clone, Debug, PartialEq)]
   24|       |pub struct ConfirmingSetConfig {
   25|       |    pub batch_size: usize,
   26|       |    /// Maximum number of dependent blocks to be stored in memory during processing
   27|       |    pub max_blocks: usize,
   28|       |    pub max_queued_notifications: usize,
   29|       |
   30|       |    /// Maximum number of failed blocks to wait for requeuing
   31|       |    pub max_deferred: usize,
   32|       |    /// Max age of deferred blocks before they are dropped
   33|       |    pub deferred_age_cutoff: Duration,
   34|       |}
   35|       |
   36|       |impl Default for ConfirmingSetConfig {
   37|     11|    fn default() -> Self {
   38|     11|        Self {
   39|     11|            batch_size: 256,
   40|     11|            max_blocks: 128 * 128,
   41|     11|            max_queued_notifications: 8,
   42|     11|            max_deferred: 16 * 1024,
   43|     11|            deferred_age_cutoff: Duration::from_secs(15 * 60),
   44|     11|        }
   45|     11|    }
   46|       |}
   47|       |
   48|       |/// Set of blocks to be durably confirmed
   49|       |pub struct ConfirmingSet {
   50|       |    thread: Arc<ConfirmingSetThread>,
   51|       |    join_handle: Mutex<Option<JoinHandle<()>>>,
   52|       |}
   53|       |
   54|       |impl ConfirmingSet {
   55|      5|    pub fn new(config: ConfirmingSetConfig, ledger: Arc<Ledger>, stats: Arc<Stats>) -> Self {
   56|      5|        Self {
   57|      5|            join_handle: Mutex::new(None),
   58|      5|            thread: Arc::new(ConfirmingSetThread {
   59|      5|                mutex: Mutex::new(ConfirmingSetImpl {
   60|      5|                    set: OrderedEntries::default(),
   61|      5|                    deferred: OrderedEntries::default(),
   62|      5|                    current: HashSet::new(),
   63|      5|                    stats: stats.clone(),
   64|      5|                    config: config.clone(),
   65|      5|                }),
   66|      5|                stopped: AtomicBool::new(false),
   67|      5|                condition: Condvar::new(),
   68|      5|                ledger,
   69|      5|                stats,
   70|      5|                config,
   71|      5|                observers: Arc::new(Mutex::new(Observers::default())),
   72|      5|                workers: ThreadPoolImpl::create(1, "Conf notif"),
   73|      5|            }),
   74|      5|        }
   75|      5|    }
   76|       |
   77|      9|    pub(crate) fn on_batch_cemented(&self, callback: BatchCementedCallback) {
   78|      9|        self.thread
   79|      9|            .observers
   80|      9|            .lock()
   81|      9|            .unwrap()
   82|      9|            .batch_cemented
   83|      9|            .push(callback);
   84|      9|    }
   85|       |
   86|      7|    pub fn on_cemented(&self, callback: BlockCallback) {
   87|      7|        self.thread
   88|      7|            .observers
   89|      7|            .lock()
   90|      7|            .unwrap()
   91|      7|            .cemented
   92|      7|            .push(callback);
   93|      7|    }
   94|       |
   95|      0|    pub fn on_already_cemented(&self, callback: AlreadyCementedCallback) {
   96|      0|        self.thread
   97|      0|            .observers
   98|      0|            .lock()
   99|      0|            .unwrap()
  100|      0|            .already_cemented
  101|      0|            .push(callback);
  102|      0|    }
  103|       |
  104|      3|    pub fn on_cementing_failed(&self, callback: impl FnMut(&BlockHash) + Send + 'static) {
  105|      3|        self.thread
  106|      3|            .observers
  107|      3|            .lock()
  108|      3|            .unwrap()
  109|      3|            .cementing_failed
  110|      3|            .push(Box::new(callback));
  111|      3|    }
  112|       |
  113|       |    /// Adds a block to the set of blocks to be confirmed
  114|      2|    pub fn add(&self, hash: BlockHash) {
  115|      2|        self.add_with_election(hash, None)
  116|      2|    }
  117|       |
  118|      2|    pub fn add_with_election(&self, hash: BlockHash, election: Option<Arc<Election>>) {
  119|      2|        self.thread.add(hash, election);
  120|      2|    }
  121|       |
  122|      4|    pub fn start(&self) {
  123|      4|        debug_assert!(self.join_handle.lock().unwrap().is_none());
  124|       |
  125|      4|        let thread = Arc::clone(&self.thread);
  126|      4|        *self.join_handle.lock().unwrap() = Some(
  127|      4|            std::thread::Builder::new()
  128|      4|                .name("Conf height".to_string())
  129|      4|                .spawn(move || thread.run())
  130|      4|                .unwrap(),
  131|      4|        );
  132|      4|    }
  133|       |
  134|      8|    pub fn stop(&self) {
  135|      8|        self.thread.stop();
  136|      8|        let handle = self.join_handle.lock().unwrap().take();
  137|      8|        if let Some(handle) = handle {
                                  ^4
  138|      4|            handle.join().unwrap();
  139|      4|        }
  140|      8|        self.thread.workers.stop();
  141|      8|    }
  142|       |
  143|       |    /// Added blocks will remain in this set until after ledger has them marked as confirmed.
  144|      1|    pub fn contains(&self, hash: &BlockHash) -> bool {
  145|      1|        self.thread.contains(hash)
  146|      1|    }
  147|       |
  148|     12|    pub fn len(&self) -> usize {
  149|     12|        self.thread.len()
  150|     12|    }
  151|       |
  152|      0|    pub fn info(&self) -> ConfirmingSetInfo {
  153|      0|        let guard = self.thread.mutex.lock().unwrap();
  154|      0|        ConfirmingSetInfo {
  155|      0|            size: guard.set.len(),
  156|      0|            max_size: self.thread.config.max_blocks,
  157|      0|        }
  158|      0|    }
  159|       |
  160|       |    /// Requeue blocks that failed to cement immediately due to missing ledger blocks
  161|      0|    pub fn requeue_blocks(&self, batch: &[(BlockStatus, Arc<BlockContext>)]) {
  162|      0|        let mut should_notify = false;
  163|      0|        {
  164|      0|            let mut guard = self.thread.mutex.lock().unwrap();
  165|      0|            for (_, context) in batch {
  166|      0|                if let Some(entry) = guard.deferred.remove(&context.block.lock().unwrap().hash()) {
  167|      0|                    self.thread
  168|      0|                        .stats
  169|      0|                        .inc(StatType::ConfirmingSet, DetailType::Requeued);
  170|      0|                    guard.set.push_back(entry);
  171|      0|                    should_notify = true;
  172|      0|                }
  173|       |            }
  174|       |        }
  175|       |
  176|      0|        if should_notify {
  177|      0|            self.thread.condition.notify_all();
  178|      0|        }
  179|      0|    }
  180|       |
  181|      0|    pub fn container_info(&self) -> ContainerInfo {
  182|      0|        let guard = self.thread.mutex.lock().unwrap();
  183|      0|        [
  184|      0|            ("set", guard.set.len(), 0),
  185|      0|            ("deferred", guard.deferred.len(), 0),
  186|      0|        ]
  187|      0|        .into()
  188|      0|    }
  189|       |}
  190|       |
  191|       |#[derive(Default)]
  192|       |pub struct ConfirmingSetInfo {
  193|       |    pub size: usize,
  194|       |    pub max_size: usize,
  195|       |}
  196|       |
  197|       |impl Drop for ConfirmingSet {
  198|      5|    fn drop(&mut self) {
  199|      5|        self.stop();
  200|      5|    }
  201|       |}
  202|       |
  203|       |struct ConfirmingSetThread {
  204|       |    mutex: Mutex<ConfirmingSetImpl>,
  205|       |    stopped: AtomicBool,
  206|       |    condition: Condvar,
  207|       |    ledger: Arc<Ledger>,
  208|       |    stats: Arc<Stats>,
  209|       |    config: ConfirmingSetConfig,
  210|       |    workers: ThreadPoolImpl,
  211|       |    observers: Arc<Mutex<Observers>>,
  212|       |}
  213|       |
  214|       |impl ConfirmingSetThread {
  215|      8|    fn stop(&self) {
  216|      8|        {
  217|      8|            let _guard = self.mutex.lock().unwrap();
  218|      8|            self.stopped.store(true, Ordering::SeqCst);
  219|      8|        }
  220|      8|        self.condition.notify_all();
  221|      8|    }
  222|       |
  223|      2|    fn add(&self, hash: BlockHash, election: Option<Arc<Election>>) {
  224|      2|        let added = {
  225|      2|            let mut guard = self.mutex.lock().unwrap();
  226|      2|            guard.set.push_back(Entry {
  227|      2|                hash,
  228|      2|                election,
  229|      2|                timestamp: Instant::now(),
  230|      2|            })
  231|      2|        };
  232|      2|
  233|      2|        if added {
  234|      2|            self.condition.notify_all();
  235|      2|            self.stats.inc(StatType::ConfirmingSet, DetailType::Insert);
  236|      2|        } else {
  237|      0|            self.stats
  238|      0|                .inc(StatType::ConfirmingSet, DetailType::Duplicate);
  239|      0|        }
  240|      2|    }
  241|       |
  242|      1|    fn contains(&self, hash: &BlockHash) -> bool {
  243|      1|        let guard = self.mutex.lock().unwrap();
  244|      1|        guard.set.contains(hash) || guard.deferred.contains(hash) || guard.current.contains(hash)
                                                  ^0                               ^0
  245|      1|    }
  246|       |
  247|     12|    fn len(&self) -> usize {
  248|     12|        // Do not report deferred blocks, as they are not currently being processed (and might never be requeued)
  249|     12|        let guard = self.mutex.lock().unwrap();
  250|     12|        guard.set.len() + guard.current.len()
  251|     12|    }
  252|       |
  253|      4|    fn run(&self) {
  254|      4|        let mut guard = self.mutex.lock().unwrap();
  255|      8|        while !self.stopped.load(Ordering::SeqCst) {
  256|      4|            self.stats.inc(StatType::ConfirmingSet, DetailType::Loop);
  257|      4|            let evicted = guard.cleanup();
  258|      4|
  259|      4|            // Notify about evicted blocks so that other components can perform necessary cleanup
  260|      4|            if !evicted.is_empty() {
  261|      0|                drop(guard);
  262|      0|                {
  263|      0|                    let mut observers = self.observers.lock().unwrap();
  264|      0|                    for entry in evicted {
  265|      0|                        observers.notify_cementing_failed(&entry.hash);
  266|      0|                    }
  267|       |                }
  268|      0|                guard = self.mutex.lock().unwrap();
  269|      4|            }
  270|       |
  271|      4|            if !guard.set.is_empty() {
  272|      1|                let batch = guard.next_batch(self.config.batch_size);
  273|      1|
  274|      1|                // Keep track of the blocks we're currently cementing, so that the .contains (...) check is accurate
  275|      1|                debug_assert!(guard.current.is_empty());
  276|      2|                for entry in &batch {
                                  ^1
  277|      1|                    guard.current.insert(entry.hash);
  278|      1|                }
  279|       |
  280|      1|                drop(guard);
  281|      1|
  282|      1|                self.run_batch(batch);
  283|      1|                guard = self.mutex.lock().unwrap();
  284|      3|            } else {
  285|      3|                guard = self
  286|      3|                    .condition
  287|      6|                    .wait_while(guard, |i| {
  288|      6|                        i.set.is_empty() && !self.stopped.load(Ordering::SeqCst)
  289|      6|                    })
  290|      3|                    .unwrap();
  291|      3|            }
  292|       |        }
  293|      4|    }
  294|       |
  295|      1|    fn notify(&self, cemented: &mut VecDeque<Context>) {
  296|      1|        let mut batch = VecDeque::new();
  297|      1|        std::mem::swap(&mut batch, cemented);
  298|      1|
  299|      1|        let mut guard = self.mutex.lock().unwrap();
  300|       |
  301|       |        // It's possible that ledger cementing happens faster than the notifications can be processed by other components, cooldown here
  302|      1|        while self.workers.num_queued_tasks() >= self.config.max_queued_notifications {
  303|      0|            self.stats
  304|      0|                .inc(StatType::ConfirmingSet, DetailType::Cooldown);
  305|      0|            guard = self
  306|      0|                .condition
  307|      0|                .wait_timeout_while(guard, Duration::from_millis(100), |_| {
  308|      0|                    !self.stopped.load(Ordering::SeqCst)
  309|      0|                })
  310|      0|                .unwrap()
  311|      0|                .0;
  312|      0|            if self.stopped.load(Ordering::Relaxed) {
  313|      0|                return;
  314|      0|            }
  315|       |        }
  316|       |
  317|      1|        let observers = self.observers.clone();
  318|      1|        let stats = self.stats.clone();
  319|      1|        self.workers.post(Box::new(move || {
  320|      1|            stats.inc(StatType::ConfirmingSet, DetailType::Notify);
  321|      1|            observers.lock().unwrap().notify_batch(batch);
  322|      1|        }));
  323|      1|    }
  324|       |
  325|       |    /// We might need to issue multiple notifications if the block we're confirming implicitly confirms more
  326|  16.3k|    fn notify_maybe(
  327|  16.3k|        &self,
  328|  16.3k|        mut write_guard: WriteGuard,
  329|  16.3k|        mut tx: LmdbWriteTransaction,
  330|  16.3k|        cemented: &mut VecDeque<Context>,
  331|  16.3k|    ) -> (WriteGuard, LmdbWriteTransaction) {
  332|  16.3k|        if cemented.len() >= self.config.max_blocks {
  333|      1|            self.stats
  334|      1|                .inc(StatType::ConfirmingSet, DetailType::NotifyIntermediate);
  335|      1|            drop(write_guard);
  336|      1|            tx.commit();
  337|      1|
  338|      1|            self.notify(cemented);
  339|      1|
  340|      1|            write_guard = self.ledger.write_queue.wait(Writer::ConfirmationHeight);
  341|      1|            tx.renew();
  342|  16.3k|        }
  343|  16.3k|        (write_guard, tx)
  344|  16.3k|    }
  345|       |
  346|      1|    fn run_batch(&self, batch: VecDeque<Entry>) {
  347|      1|        let mut cemented = VecDeque::new();
  348|      1|        let mut already_cemented = VecDeque::new();
  349|      1|
  350|      1|        {
  351|      1|            let mut write_guard = self.ledger.write_queue.wait(Writer::ConfirmationHeight);
  352|      1|            let mut tx = self.ledger.rw_txn();
  353|       |
  354|      1|            for entry in batch {
  355|      1|                let hash = entry.hash;
  356|      1|                let election = entry.election.clone();
  357|      1|                let mut cemented_count = 0;
  358|      1|                let mut success = false;
  359|       |                loop {
  360|  16.3k|                    (write_guard, tx) = self.ledger.refresh_if_needed(write_guard, tx);
  361|  16.3k|
  362|  16.3k|                    // Cementing deep dependency chains might take a long time, allow for graceful shutdown, ignore notifications
  363|  16.3k|                    if self.stopped.load(Ordering::Relaxed) {
  364|      1|                        return;
  365|  16.3k|                    }
  366|  16.3k|
  367|  16.3k|                    // Issue notifications here, so that `cemented` set is not too large before we add more blocks
  368|  16.3k|                    (write_guard, tx) = self.notify_maybe(write_guard, tx, &mut cemented);
  369|  16.3k|
  370|  16.3k|                    self.stats
  371|  16.3k|                        .inc(StatType::ConfirmingSet, DetailType::Cementing);
  372|  16.3k|
  373|  16.3k|                    // The block might be rolled back before it's fully cemented
  374|  16.3k|                    if !self.ledger.any().block_exists(&tx, &hash) {
  375|      0|                        self.stats
  376|      0|                            .inc(StatType::ConfirmingSet, DetailType::MissingBlock);
  377|      0|                        break;
  378|  16.3k|                    }
  379|  16.3k|
  380|  16.3k|                    let added = self
  381|  16.3k|                        .ledger
  382|  16.3k|                        .confirm_max(&mut tx, hash, self.config.max_blocks);
  383|  16.3k|                    let added_len = added.len();
  384|  16.3k|                    if !added.is_empty() {
  385|       |                        // Confirming this block may implicitly confirm more
  386|  16.3k|                        self.stats.add(
  387|  16.3k|                            StatType::ConfirmingSet,
  388|  16.3k|                            DetailType::Cemented,
  389|  16.3k|                            added_len as u64,
  390|  16.3k|                        );
  391|  16.3k|                        cemented_count += added.len();
  392|  32.7k|                        for block in added {
                                          ^16.3k
  393|  16.3k|                            cemented.push_back(Context {
  394|  16.3k|                                block,
  395|  16.3k|                                confirmation_root: hash,
  396|  16.3k|                                election: election.clone(),
  397|  16.3k|                            });
  398|  16.3k|                        }
  399|      0|                    } else {
  400|      0|                        self.stats
  401|      0|                            .inc(StatType::ConfirmingSet, DetailType::AlreadyCemented);
  402|      0|                        already_cemented.push_back(hash);
  403|      0|                    }
  404|       |
  405|  16.3k|                    success = self.ledger.confirmed().block_exists(&tx, &hash);
  406|  16.3k|                    if success {
  407|      0|                        break;
  408|  16.3k|                    }
  409|       |                }
  410|       |
  411|      0|                if success {
  412|      0|                    self.stats
  413|      0|                        .inc(StatType::ConfirmingSet, DetailType::CementedHash);
  414|      0|                    debug!(
  415|      0|                        "Cemented block: {} (total cemented: {})",
  416|       |                        hash, cemented_count
  417|       |                    );
  418|       |                } else {
  419|      0|                    self.stats
  420|      0|                        .inc(StatType::ConfirmingSet, DetailType::CementingFailed);
  421|      0|                    debug!("Failed to cement block: {}", hash);
  422|       |
  423|       |                    // Requeue failed blocks for processing later
  424|       |                    // Add them to the deferred set while still holding the exclusive database write transaction to avoid block processor races
  425|      0|                    self.mutex.lock().unwrap().deferred.push_back(entry);
  426|       |                }
  427|       |            }
  428|       |        }
  429|       |
  430|      0|        self.notify(&mut cemented);
  431|      0|
  432|      0|        {
  433|      0|            let mut guard = self.observers.lock().unwrap();
  434|      0|            for callback in &mut guard.already_cemented {
  435|      0|                callback(&already_cemented)
  436|       |            }
  437|       |        }
  438|       |
  439|       |        // Clear current set only after the transaction is committed
  440|      0|        self.mutex.lock().unwrap().current.clear();
  441|      1|    }
  442|       |}
  443|       |
  444|       |struct ConfirmingSetImpl {
  445|       |    /// Blocks that are ready to be cemented
  446|       |    set: OrderedEntries,
  447|       |    /// Blocks that could not be cemented immediately (e.g. waiting for rollbacks to complete)
  448|       |    deferred: OrderedEntries,
  449|       |    /// Blocks that are being cemented in the current batch
  450|       |    current: HashSet<BlockHash>,
  451|       |
  452|       |    stats: Arc<Stats>,
  453|       |    config: ConfirmingSetConfig,
  454|       |}
  455|       |
  456|       |impl ConfirmingSetImpl {
  457|      1|    fn next_batch(&mut self, max_count: usize) -> VecDeque<Entry> {
  458|      1|        let mut results = VecDeque::new();
  459|       |        // TODO: use extract_if once it is stablized
  460|      2|        while let Some(entry) = self.set.pop_front() {
                                     ^1
  461|      1|            if results.len() >= max_count {
  462|      0|                break;
  463|      1|            }
  464|      1|            results.push_back(entry);
  465|       |        }
  466|      1|        results
  467|      1|    }
  468|       |
  469|      4|    fn cleanup(&mut self) -> Vec<Entry> {
  470|      4|        let mut evicted = Vec::new();
  471|      4|
  472|      4|        let cutoff = Instant::now() - self.config.deferred_age_cutoff;
  473|      4|        let should_evict = |entry: &Entry| entry.timestamp < cutoff;
                                                         ^0
  474|       |
  475|       |        // Iterate in sequenced (insertion) order
  476|       |        loop {
  477|      4|            let Some(entry) = self.deferred.front() else {
                                   ^0
  478|      4|                break;
  479|       |            };
  480|       |
  481|      0|            if should_evict(entry) || self.deferred.len() > self.config.max_deferred {
  482|      0|                self.stats.inc(StatType::ConfirmingSet, DetailType::Evicted);
  483|      0|                let entry = self.deferred.pop_front().unwrap();
  484|      0|                evicted.push(entry);
  485|      0|            } else {
  486|       |                // Entries are sequenced, so we can stop here and avoid unnecessary iteration
  487|      0|                break;
  488|       |            }
  489|       |        }
  490|      4|        evicted
  491|      4|    }
  492|       |}
  493|       |
  494|       |type BlockCallback = Box<dyn FnMut(&SavedBlock) + Send>;
  495|       |
  496|       |/// block + confirmation root
  497|       |type BatchCementedCallback = Box<dyn FnMut(&VecDeque<Context>) + Send>;
  498|       |type AlreadyCementedCallback = Box<dyn FnMut(&VecDeque<BlockHash>) + Send>;
  499|       |
  500|       |#[derive(Default)]
  501|       |struct Observers {
  502|       |    cemented: Vec<BlockCallback>,
  503|       |    batch_cemented: Vec<BatchCementedCallback>,
  504|       |    already_cemented: Vec<AlreadyCementedCallback>,
  505|       |    cementing_failed: Vec<Box<dyn FnMut(&BlockHash) + Send>>,
  506|       |}
  507|       |
  508|       |impl Observers {
  509|      1|    fn notify_batch(&mut self, cemented: VecDeque<Context>) {
  510|  16.3k|        for context in &cemented {
                          ^16.3k
  511|  32.7k|            for observer in &mut self.cemented {
                              ^16.3k
  512|  16.3k|                observer(&context.block);
  513|  16.3k|            }
  514|       |        }
  515|       |
  516|      1|        for observer in &mut self.batch_cemented {
                          ^0
  517|      0|            observer(&cemented);
  518|      0|        }
  519|      1|    }
  520|       |
  521|      0|    fn notify_cementing_failed(&mut self, hash: &BlockHash) {
  522|      0|        for observer in &mut self.cementing_failed {
  523|      0|            observer(hash);
  524|      0|        }
  525|      0|    }
  526|       |}
  527|       |
  528|       |pub(crate) struct Context {
  529|       |    pub block: SavedBlock,
  530|       |    pub confirmation_root: BlockHash,
  531|       |    pub election: Option<Arc<Election>>,
  532|       |}
  533|       |
  534|       |#[cfg(test)]
  535|       |mod tests {
  536|       |    use super::*;
  537|       |    use rsnano_core::{ConfirmationHeightInfo, SavedAccountChain};
  538|       |    use std::time::Duration;
  539|       |
  540|       |    #[test]
  541|      1|    fn add_exists() {
  542|      1|        let ledger = Arc::new(Ledger::new_null());
  543|      1|        let confirming_set =
  544|      1|            ConfirmingSet::new(Default::default(), ledger, Arc::new(Stats::default()));
  545|      1|        let hash = BlockHash::from(1);
  546|      1|        confirming_set.add(hash);
  547|      1|        assert!(confirming_set.contains(&hash));
  548|      1|    }
  549|       |
  550|       |    #[test]
  551|      1|    fn process_one() {
  552|      1|        let mut chain = SavedAccountChain::genesis();
  553|      1|        let block_hash = chain.add_state().hash();
  554|      1|        let ledger = Arc::new(
  555|      1|            Ledger::new_null_builder()
  556|      1|                .blocks(chain.blocks())
  557|      1|                .confirmation_height(
  558|      1|                    &chain.account(),
  559|      1|                    &ConfirmationHeightInfo {
  560|      1|                        height: 1,
  561|      1|                        frontier: chain.open(),
  562|      1|                    },
  563|      1|                )
  564|      1|                .finish(),
  565|      1|        );
  566|      1|        let confirming_set =
  567|      1|            ConfirmingSet::new(Default::default(), ledger, Arc::new(Stats::default()));
  568|      1|        confirming_set.start();
  569|      1|        let count = Arc::new(Mutex::new(0));
  570|      1|        let condition = Arc::new(Condvar::new());
  571|      1|        let count_clone = Arc::clone(&count);
  572|      1|        let condition_clone = Arc::clone(&condition);
  573|  16.3k|        confirming_set.on_cemented(Box::new(move |_block| {
  574|  16.3k|            {
  575|  16.3k|                *count_clone.lock().unwrap() += 1;
  576|  16.3k|            }
  577|  16.3k|            condition_clone.notify_all();
  578|  16.3k|        }));
  579|      1|
  580|      1|        confirming_set.add(block_hash);
  581|      1|
  582|      1|        let guard = count.lock().unwrap();
  583|      1|        let result = condition
  584|      2|            .wait_timeout_while(guard, Duration::from_secs(5), |i| *i < 1)
  585|      1|            .unwrap()
  586|      1|            .1;
  587|      1|        assert_eq!(result.timed_out(), false);
  588|      1|    }
  589|       |}

/home/gustav/code/nano/rsnano-node/node/src/cementation/ordered_entries.rs:
    1|       |use crate::consensus::Election;
    2|       |use rsnano_core::BlockHash;
    3|       |use std::{
    4|       |    collections::{HashMap, VecDeque},
    5|       |    sync::Arc,
    6|       |    time::Instant,
    7|       |};
    8|       |
    9|       |#[derive(Default)]
   10|       |pub(super) struct OrderedEntries {
   11|       |    sequenced: VecDeque<BlockHash>,
   12|       |    by_hash: HashMap<BlockHash, Entry>,
   13|       |}
   14|       |
   15|       |impl OrderedEntries {
   16|      2|    pub fn push_back(&mut self, entry: Entry) -> bool {
   17|      2|        let hash = entry.hash;
   18|      2|        let mut inserted = true;
   19|      2|
   20|      2|        self.by_hash
   21|      2|            .entry(hash)
   22|      2|            .and_modify(|_| {
   23|      0|                inserted = false;
   24|      2|            })
   25|      2|            .or_insert(entry);
   26|      2|
   27|      2|        if inserted {
   28|      2|            self.sequenced.push_back(hash);
   29|      2|        }
                       ^0
   30|       |
   31|      2|        inserted
   32|      2|    }
   33|       |
   34|      1|    pub(crate) fn contains(&self, hash: &BlockHash) -> bool {
   35|      1|        self.by_hash.contains_key(hash)
   36|      1|    }
   37|       |
   38|     12|    pub(crate) fn len(&self) -> usize {
   39|     12|        self.sequenced.len()
   40|     12|    }
   41|       |
   42|      4|    pub(crate) fn front(&mut self) -> Option<&Entry> {
   43|      4|        if let Some(hash) = self.sequenced.front() {
                                  ^0
   44|      0|            self.by_hash.get(hash)
   45|       |        } else {
   46|      4|            None
   47|       |        }
   48|      4|    }
   49|       |
   50|      2|    pub(crate) fn pop_front(&mut self) -> Option<Entry> {
   51|      2|        if let Some(hash) = self.sequenced.pop_front() {
                                  ^1
   52|      1|            self.by_hash.remove(&hash)
   53|       |        } else {
   54|      1|            None
   55|       |        }
   56|      2|    }
   57|       |
   58|      0|    pub(crate) fn remove(&mut self, hash: &BlockHash) -> Option<Entry> {
   59|      0|        if let Some(entry) = self.by_hash.remove(hash) {
   60|      0|            self.sequenced.retain(|h| *h != entry.hash);
   61|      0|            Some(entry)
   62|       |        } else {
   63|      0|            None
   64|       |        }
   65|      0|    }
   66|       |
   67|     10|    pub(crate) fn is_empty(&self) -> bool {
   68|     10|        self.sequenced.is_empty()
   69|     10|    }
   70|       |}
   71|       |
   72|       |pub(super) struct Entry {
   73|       |    pub hash: BlockHash,
   74|       |    pub election: Option<Arc<Election>>,
   75|       |    pub timestamp: Instant,
   76|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/converters.rs:
    1|       |use super::GlobalConfig;
    2|       |use crate::block_processing::{BacklogScanConfig, BlockProcessorConfig};
    3|       |use rsnano_network::{bandwidth_limiter::BandwidthLimiterConfig, NetworkConfig};
    4|       |use std::time::Duration;
    5|       |
    6|       |impl From<&GlobalConfig> for BlockProcessorConfig {
    7|      3|    fn from(value: &GlobalConfig) -> Self {
    8|      3|        let config = &value.node_config.block_processor;
    9|      3|        Self {
   10|      3|            max_peer_queue: config.max_peer_queue,
   11|      3|            priority_local: config.priority_local,
   12|      3|            priority_bootstrap: config.priority_bootstrap,
   13|      3|            priority_live: config.priority_live,
   14|      3|            priority_system: config.priority_system,
   15|      3|            max_system_queue: config.max_system_queue,
   16|      3|            batch_max_time: Duration::from_millis(
   17|      3|                value.node_config.block_processor_batch_max_time_ms as u64,
   18|      3|            ),
   19|      3|            full_size: value.flags.block_processor_full_size,
   20|      3|            batch_size: 256,
   21|      3|            work_thresholds: value.network_params.work.clone(),
   22|      3|        }
   23|      3|    }
   24|       |}
   25|       |
   26|       |impl From<&GlobalConfig> for BacklogScanConfig {
   27|      3|    fn from(value: &GlobalConfig) -> Self {
   28|      3|        value.node_config.backlog_scan.clone()
   29|      3|    }
   30|       |}
   31|       |
   32|       |impl From<&GlobalConfig> for NetworkConfig {
   33|      3|    fn from(value: &GlobalConfig) -> Self {
   34|      3|        Self {
   35|      3|            max_inbound_connections: value.node_config.tcp.max_inbound_connections,
   36|      3|            max_outbound_connections: value.node_config.tcp.max_outbound_connections,
   37|      3|            max_peers_per_ip: value.node_config.max_peers_per_ip,
   38|      3|            max_peers_per_subnetwork: value.node_config.max_peers_per_subnetwork,
   39|      3|            max_attempts_per_ip: value.node_config.tcp.max_attempts_per_ip,
   40|      3|            allow_local_peers: value.node_config.allow_local_peers,
   41|      3|            disable_max_peers_per_ip: value.flags.disable_max_peers_per_ip,
   42|      3|            disable_max_peers_per_subnetwork: value.flags.disable_max_peers_per_subnetwork,
   43|      3|            disable_network: value.flags.disable_tcp_realtime,
   44|      3|            min_protocol_version: value.network_params.network.protocol_info().version_min,
   45|      3|            listening_port: value.node_config.peering_port.unwrap_or(0),
   46|      3|            limiter: value.into(),
   47|      3|        }
   48|      3|    }
   49|       |}
   50|       |
   51|       |impl From<&GlobalConfig> for BandwidthLimiterConfig {
   52|      3|    fn from(value: &GlobalConfig) -> Self {
   53|      3|        Self {
   54|      3|            generic_limit: value.node_config.bandwidth_limit,
   55|      3|            generic_burst_ratio: value.node_config.bandwidth_limit_burst_ratio,
   56|      3|            bootstrap_limit: value.node_config.bootstrap_bandwidth_limit,
   57|      3|            bootstrap_burst_ratio: value.node_config.bootstrap_bandwidth_burst_ratio,
   58|      3|        }
   59|      3|    }
   60|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/daemon_config.rs:
    1|       |use super::{
    2|       |    get_node_toml_config_path, read_toml_file, DaemonToml, NodeConfig, NodeRpcConfig, OpenclConfig,
    3|       |};
    4|       |use crate::NetworkParams;
    5|       |use rsnano_core::Networks;
    6|       |use std::path::Path;
    7|       |
    8|       |#[derive(Debug, PartialEq)]
    9|       |pub struct DaemonConfig {
   10|       |    pub rpc_enable: bool,
   11|       |    pub rpc: NodeRpcConfig,
   12|       |    pub node: NodeConfig,
   13|       |    pub opencl: OpenclConfig,
   14|       |    pub opencl_enable: bool,
   15|       |}
   16|       |
   17|       |impl DaemonConfig {
   18|      0|    pub fn new(network_params: &NetworkParams, parallelism: usize) -> Self {
   19|      0|        Self {
   20|      0|            rpc_enable: false,
   21|      0|            node: NodeConfig::new(
   22|      0|                Some(network_params.network.default_node_port),
   23|      0|                network_params,
   24|      0|                parallelism,
   25|      0|            ),
   26|      0|            opencl: OpenclConfig::new(),
   27|      0|            opencl_enable: false,
   28|      0|            rpc: NodeRpcConfig::new(),
   29|      0|        }
   30|      0|    }
   31|       |
   32|      4|    pub fn new2(network: Networks, parallelism: usize) -> Self {
   33|      4|        Self {
   34|      4|            rpc_enable: false,
   35|      4|            node: NodeConfig::default_for(network, parallelism),
   36|      4|            opencl: OpenclConfig::new(),
   37|      4|            opencl_enable: false,
   38|      4|            rpc: NodeRpcConfig::new(),
   39|      4|        }
   40|      4|    }
   41|       |
   42|      0|    pub fn load_from_data_path(
   43|      0|        network: Networks,
   44|      0|        parallelism: usize,
   45|      0|        data_path: impl AsRef<Path>,
   46|      0|    ) -> anyhow::Result<Self> {
   47|      0|        let file_path = get_node_toml_config_path(data_path.as_ref());
   48|      0|        let mut result = Self::new2(network, parallelism);
   49|      0|        if file_path.exists() {
   50|      0|            let toml: DaemonToml = read_toml_file(file_path)?;
   51|      0|            result.merge_toml(&toml);
   52|      0|        }
   53|      0|        Ok(result)
   54|      0|    }
   55|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/diagnostics_config.rs:
    1|       |use crate::utils::TxnTrackingConfig;
    2|       |
    3|       |#[derive(Clone, Debug, PartialEq)]
    4|       |pub struct DiagnosticsConfig {
    5|       |    pub txn_tracking: TxnTrackingConfig,
    6|       |}
    7|       |
    8|       |impl Default for DiagnosticsConfig {
    9|     10|    fn default() -> Self {
   10|     10|        Self {
   11|     10|            txn_tracking: TxnTrackingConfig::new(),
   12|     10|        }
   13|     10|    }
   14|       |}
   15|       |
   16|       |impl DiagnosticsConfig {
   17|      9|    pub fn new() -> Self {
   18|      9|        Default::default()
   19|      9|    }
   20|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/mod.rs:
    1|       |mod converters;
    2|       |mod daemon_config;
    3|       |mod diagnostics_config;
    4|       |mod network_constants;
    5|       |mod node_config;
    6|       |mod node_flags;
    7|       |mod node_rpc_config;
    8|       |mod opencl_config;
    9|       |mod toml;
   10|       |mod websocket_config;
   11|       |
   12|       |use crate::NetworkParams;
   13|       |pub use daemon_config::*;
   14|       |pub use diagnostics_config::*;
   15|       |pub use network_constants::*;
   16|       |pub use node_config::*;
   17|       |pub use node_flags::*;
   18|       |pub use node_rpc_config::*;
   19|       |pub use opencl_config::*;
   20|       |pub use rsnano_core::Networks;
   21|       |use serde::de::DeserializeOwned;
   22|       |use std::path::{Path, PathBuf};
   23|       |pub use toml::DaemonToml;
   24|       |pub use websocket_config::WebsocketConfig;
   25|       |
   26|      0|pub fn get_node_toml_config_path(data_path: impl Into<PathBuf>) -> PathBuf {
   27|      0|    let mut node_toml = data_path.into();
   28|      0|    node_toml.push("config-node.toml");
   29|      0|    node_toml
   30|      0|}
   31|       |
   32|      0|pub fn get_rpc_toml_config_path(data_path: impl Into<PathBuf>) -> PathBuf {
   33|      0|    let mut rpc_toml = data_path.into();
   34|      0|    rpc_toml.push("config-rpc.toml");
   35|      0|    rpc_toml
   36|      0|}
   37|       |
   38|      5|pub fn get_default_rpc_filepath() -> PathBuf {
   39|      5|    get_default_rpc_filepath_from(std::env::current_exe().unwrap_or_default().as_path())
   40|      5|}
   41|       |
   42|      5|pub fn get_default_rpc_filepath_from(node_exe_path: &Path) -> PathBuf {
   43|      5|    let mut result = node_exe_path.to_path_buf();
   44|      5|    result.pop();
   45|      5|    result.push("nano_rpc");
   46|      5|    if let Some(ext) = node_exe_path.extension() {
                              ^0
   47|      0|        result.set_extension(ext);
   48|      5|    }
   49|      5|    result
   50|      5|}
   51|       |
   52|      0|pub fn force_nano_dev_network() {
   53|      0|    NetworkConstants::set_active_network(Networks::NanoDevNetwork);
   54|      0|}
   55|       |
   56|       |pub struct GlobalConfig {
   57|       |    pub node_config: NodeConfig,
   58|       |    pub flags: NodeFlags,
   59|       |    pub network_params: NetworkParams,
   60|       |}
   61|       |
   62|      0|pub fn read_toml_file<T: DeserializeOwned>(path: impl AsRef<Path>) -> anyhow::Result<T> {
   63|      0|    let toml_str = std::fs::read_to_string(path)?;
   64|      0|    ::toml::from_str(&toml_str).map_err(|e| e.into())
   65|      0|}

/home/gustav/code/nano/rsnano-node/node/src/config/network_constants.rs:
    1|       |use crate::bootstrap::BootstrapConfig;
    2|       |use anyhow::Result;
    3|       |use rsnano_core::{utils::get_env_or_default, work::WorkThresholds, Networks, ACTIVE_NETWORK};
    4|       |use rsnano_messages::ProtocolInfo;
    5|       |use std::time::Duration;
    6|       |
    7|       |#[derive(Clone, Debug, PartialEq)]
    8|       |pub struct NetworkConstants {
    9|       |    pub work: WorkThresholds,
   10|       |    pub default_node_port: u16,
   11|       |    pub default_rpc_port: u16,
   12|       |    pub default_ipc_port: u16,
   13|       |    pub default_websocket_port: u16,
   14|       |    pub aec_loop_interval: Duration,
   15|       |    pub cleanup_period: Duration,
   16|       |    /** How often to send keepalive messages */
   17|       |    pub keepalive_period: Duration,
   18|       |    /// How often to connect to other peers
   19|       |    pub merge_period: Duration,
   20|       |    /** Default maximum idle time for a socket before it's automatically closed */
   21|       |    pub idle_timeout: Duration,
   22|       |    pub sync_cookie_cutoff: Duration,
   23|       |    pub bootstrap_interval_s: i64,
   24|       |    /** Maximum number of peers per IP. It is also the max number of connections per IP*/
   25|       |    pub max_peers_per_ip: usize,
   26|       |    /** Maximum number of peers per subnetwork */
   27|       |    pub max_peers_per_subnetwork: usize,
   28|       |    pub peer_dump_interval: Duration,
   29|       |
   30|       |    pub current_network: Networks,
   31|       |    /** Current protocol version */
   32|       |    pub protocol_version: u8,
   33|       |    /** Minimum accepted protocol version */
   34|       |    pub protocol_version_min: u8,
   35|       |    /** Minimum accepted protocol version used when bootstrapping */
   36|       |    pub bootstrap_protocol_version_min: u8,
   37|       |    pub ipv6_subnetwork_prefix_for_limiting: usize,
   38|       |    pub silent_connection_tolerance_time_s: i64,
   39|       |    /// Time to wait before vote rebroadcasts for active elections (milliseconds)
   40|       |    pub vote_broadcast_interval: Duration,
   41|       |    pub block_broadcast_interval: Duration,
   42|       |
   43|       |    /** We do not reply to telemetry requests made within cooldown period */
   44|       |    pub telemetry_request_cooldown: Duration,
   45|       |    /** How often to request telemetry from peers */
   46|       |    pub telemetry_request_interval_ms: i64,
   47|       |    /** How often to broadcast telemetry to peers */
   48|       |    pub telemetry_broadcast_interval_ms: i64,
   49|       |    /** Telemetry data older than this value is considered stale */
   50|       |    pub telemetry_cache_cutoff_ms: i64, // 2 * `telemetry_broadcast_interval` + some margin
   51|       |    /// How much to delay activation of optimistic elections to avoid interfering with election scheduler
   52|       |    pub optimistic_activation_delay: Duration,
   53|       |    pub rep_crawler_normal_interval: Duration,
   54|       |    pub rep_crawler_warmup_interval: Duration,
   55|       |}
   56|       |
   57|       |impl NetworkConstants {
   58|      0|    pub fn empty() -> Self {
   59|      0|        Self::new(WorkThresholds::publish_dev().clone(), Networks::Invalid)
   60|      0|    }
   61|       |
   62|      9|    pub fn new(work: WorkThresholds, network: Networks) -> Self {
   63|      9|        match network {
   64|      4|            Networks::NanoDevNetwork => Self::dev(work),
   65|      4|            Networks::NanoBetaNetwork => Self::beta(work),
   66|      1|            Networks::NanoLiveNetwork | Networks::Invalid => Self::live(work),
   67|      0|            Networks::NanoTestNetwork => Self::test(work),
   68|       |        }
   69|      9|    }
   70|       |
   71|      0|    pub fn for_network(network: Networks) -> Self {
   72|      0|        Self::new(WorkThresholds::default_for(network), network)
   73|      0|    }
   74|       |
   75|      9|    pub fn protocol_info(&self) -> ProtocolInfo {
   76|      9|        ProtocolInfo {
   77|      9|            version_using: self.protocol_version,
   78|      9|            version_max: self.protocol_version,
   79|      9|            version_min: self.protocol_version_min,
   80|      9|            network: self.current_network,
   81|      9|        }
   82|      9|    }
   83|       |
   84|      9|    fn live(work: WorkThresholds) -> Self {
   85|      9|        let cleanup_period = Duration::from_secs(60);
   86|      9|        let protocol_info = ProtocolInfo::default();
   87|      9|        Self {
   88|      9|            work,
   89|      9|            current_network: Networks::NanoLiveNetwork,
   90|      9|            protocol_version: protocol_info.version_using,
   91|      9|            protocol_version_min: protocol_info.version_min,
   92|      9|            bootstrap_protocol_version_min: BootstrapConfig::default().min_protocol_version,
   93|      9|            default_node_port: 7075,
   94|      9|            default_rpc_port: 7076,
   95|      9|            default_ipc_port: 7077,
   96|      9|            default_websocket_port: 7078,
   97|      9|            aec_loop_interval: Duration::from_millis(300),
   98|      9|            cleanup_period,
   99|      9|            keepalive_period: Duration::from_secs(15),
  100|      9|            merge_period: Duration::from_millis(250),
  101|      9|            idle_timeout: cleanup_period * 2,
  102|      9|            sync_cookie_cutoff: Duration::from_secs(5),
  103|      9|            bootstrap_interval_s: 15 * 60,
  104|      9|            max_peers_per_ip: 4,
  105|      9|            max_peers_per_subnetwork: 16,
  106|      9|            peer_dump_interval: Duration::from_secs(5 * 60),
  107|      9|            ipv6_subnetwork_prefix_for_limiting: 64,
  108|      9|            silent_connection_tolerance_time_s: 120,
  109|      9|            vote_broadcast_interval: Duration::from_secs(15),
  110|      9|            block_broadcast_interval: Duration::from_secs(150),
  111|      9|            telemetry_request_cooldown: Duration::from_secs(15),
  112|      9|            telemetry_request_interval_ms: 1000 * 60,
  113|      9|            telemetry_broadcast_interval_ms: 1000 * 60,
  114|      9|            telemetry_cache_cutoff_ms: 1000 * 130, //  2 * `telemetry_broadcast_interval` + some margin
  115|      9|            optimistic_activation_delay: Duration::from_secs(30),
  116|      9|            rep_crawler_normal_interval: Duration::from_secs(7),
  117|      9|            rep_crawler_warmup_interval: Duration::from_secs(3),
  118|      9|        }
  119|      9|    }
  120|       |
  121|      0|    pub fn for_beta() -> Self {
  122|      0|        Self {
  123|      0|            current_network: Networks::NanoBetaNetwork,
  124|      0|            default_node_port: 54000,
  125|      0|            default_rpc_port: 55000,
  126|      0|            default_ipc_port: 56000,
  127|      0|            default_websocket_port: 57000,
  128|      0|            max_peers_per_ip: 256,
  129|      0|            max_peers_per_subnetwork: 256,
  130|      0|            ..Self::live(WorkThresholds::publish_beta().clone())
  131|      0|        }
  132|      0|    }
  133|       |
  134|      4|    fn beta(work: WorkThresholds) -> Self {
  135|      4|        Self {
  136|      4|            current_network: Networks::NanoBetaNetwork,
  137|      4|            default_node_port: 54000,
  138|      4|            default_rpc_port: 55000,
  139|      4|            default_ipc_port: 56000,
  140|      4|            default_websocket_port: 57000,
  141|      4|            max_peers_per_ip: 256,
  142|      4|            max_peers_per_subnetwork: 256,
  143|      4|            ..Self::live(work)
  144|      4|        }
  145|      4|    }
  146|       |
  147|      0|    fn test(work: WorkThresholds) -> Self {
  148|      0|        Self {
  149|      0|            current_network: Networks::NanoTestNetwork,
  150|      0|            default_node_port: test_node_port(),
  151|      0|            default_rpc_port: test_rpc_port(),
  152|      0|            default_ipc_port: test_ipc_port(),
  153|      0|            default_websocket_port: test_websocket_port(),
  154|      0|            ..Self::live(work)
  155|      0|        }
  156|      0|    }
  157|       |
  158|      4|    fn dev(work: WorkThresholds) -> Self {
  159|      4|        let cleanup_period = Duration::from_secs(1);
  160|      4|        Self {
  161|      4|            current_network: Networks::NanoDevNetwork,
  162|      4|            default_node_port: 44000,
  163|      4|            default_rpc_port: 45000,
  164|      4|            default_ipc_port: 46000,
  165|      4|            default_websocket_port: 47000,
  166|      4|            aec_loop_interval: Duration::from_millis(20),
  167|      4|            cleanup_period,
  168|      4|            keepalive_period: Duration::from_secs(1),
  169|      4|            merge_period: Duration::from_millis(10),
  170|      4|            idle_timeout: cleanup_period * 15,
  171|      4|            max_peers_per_ip: 256, // During tests, all peers are on localhost
  172|      4|            max_peers_per_subnetwork: 256,
  173|      4|            peer_dump_interval: Duration::from_secs(1),
  174|      4|            vote_broadcast_interval: Duration::from_millis(500),
  175|      4|            block_broadcast_interval: Duration::from_millis(500),
  176|      4|            telemetry_request_cooldown: Duration::from_millis(500),
  177|      4|            telemetry_cache_cutoff_ms: 2000,
  178|      4|            telemetry_request_interval_ms: 500,
  179|      4|            telemetry_broadcast_interval_ms: 500,
  180|      4|            optimistic_activation_delay: Duration::from_secs(2),
  181|      4|            rep_crawler_normal_interval: Duration::from_millis(500),
  182|      4|            rep_crawler_warmup_interval: Duration::from_millis(500),
  183|      4|            ..Self::live(work)
  184|      4|        }
  185|      4|    }
  186|       |
  187|     12|    pub fn is_live_network(&self) -> bool {
  188|     12|        self.current_network == Networks::NanoLiveNetwork
  189|     12|    }
  190|       |
  191|     12|    pub fn is_beta_network(&self) -> bool {
  192|     12|        self.current_network == Networks::NanoBetaNetwork
  193|     12|    }
  194|       |
  195|    150|    pub fn is_dev_network(&self) -> bool {
  196|    150|        self.current_network == Networks::NanoDevNetwork
  197|    150|    }
  198|       |
  199|      9|    pub fn is_test_network(&self) -> bool {
  200|      9|        self.current_network == Networks::NanoTestNetwork
  201|      9|    }
  202|       |
  203|       |    /** Initial value is ACTIVE_NETWORK compile flag, but can be overridden by a CLI flag */
  204|      0|    pub fn active_network() -> Networks {
  205|      0|        *ACTIVE_NETWORK.lock().unwrap()
  206|      0|    }
  207|       |
  208|       |    /**
  209|       |     * Optionally called on startup to override the global active network.
  210|       |     * If not called, the compile-time option will be used.
  211|       |     * @param network The new active network
  212|       |     */
  213|      0|    pub fn set_active_network(network: Networks) {
  214|      0|        *ACTIVE_NETWORK.lock().unwrap() = network;
  215|      0|    }
  216|       |
  217|       |    /**
  218|       |     * Optionally called on startup to override the global active network.
  219|       |     * If not called, the compile-time option will be used.
  220|       |     * @param network The new active network. Valid values are "live", "beta" and "dev"
  221|       |     */
  222|      0|    pub fn set_active_network_from_str(network: impl AsRef<str>) -> Result<()> {
  223|      0|        let net = match network.as_ref() {
  224|      0|            "live" => Networks::NanoLiveNetwork,
  225|      0|            "beta" => Networks::NanoBetaNetwork,
  226|      0|            "dev" => Networks::NanoDevNetwork,
  227|      0|            "test" => Networks::NanoTestNetwork,
  228|      0|            _ => bail!("invalid network"),
  229|       |        };
  230|      0|        Self::set_active_network(net);
  231|      0|        Ok(())
  232|      0|    }
  233|       |
  234|      3|    pub fn cleanup_cutoff(&self) -> Duration {
  235|      3|        self.cleanup_period * 5
  236|      3|    }
  237|       |
  238|      3|    pub fn get_current_network_as_string(&self) -> &str {
  239|      3|        match self.current_network {
  240|      3|            Networks::NanoDevNetwork => "dev",
  241|      0|            Networks::NanoBetaNetwork => "beta",
  242|      0|            Networks::NanoLiveNetwork => "live",
  243|      0|            Networks::NanoTestNetwork => "test",
  244|      0|            Networks::Invalid => panic!("invalid network"),
  245|       |        }
  246|      3|    }
  247|       |
  248|      0|    pub fn default_for(network: Networks) -> Self {
  249|      0|        match network {
  250|      0|            Networks::Invalid => Self::empty(),
  251|      0|            Networks::NanoBetaNetwork => Self::new(
  252|      0|                WorkThresholds::publish_beta().clone(),
  253|      0|                Networks::NanoBetaNetwork,
  254|      0|            ),
  255|      0|            Networks::NanoDevNetwork => Self::new(
  256|      0|                WorkThresholds::publish_dev().clone(),
  257|      0|                Networks::NanoDevNetwork,
  258|      0|            ),
  259|      0|            Networks::NanoLiveNetwork => Self::new(
  260|      0|                WorkThresholds::publish_full().clone(),
  261|      0|                Networks::NanoLiveNetwork,
  262|      0|            ),
  263|      0|            Networks::NanoTestNetwork => Self::new(
  264|      0|                WorkThresholds::publish_test().clone(),
  265|      0|                Networks::NanoTestNetwork,
  266|      0|            ),
  267|       |        }
  268|      0|    }
  269|       |}
  270|       |
  271|      0|pub fn test_node_port() -> u16 {
  272|      0|    get_env_or_default("NANO_TEST_NODE_PORT", 17075)
  273|      0|}
  274|       |
  275|      0|fn test_rpc_port() -> u16 {
  276|      0|    get_env_or_default("NANO_TEST_RPC_PORT", 17076)
  277|      0|}
  278|       |
  279|      0|fn test_ipc_port() -> u16 {
  280|      0|    get_env_or_default("NANO_TEST_IPC_PORT", 17077)
  281|      0|}
  282|       |
  283|      0|fn test_websocket_port() -> u16 {
  284|      0|    get_env_or_default("NANO_TEST_WEBSOCKET_PORT", 17078)
  285|      0|}

/home/gustav/code/nano/rsnano-node/node/src/config/node_config.rs:
    1|       |use super::{websocket_config::WebsocketConfig, DiagnosticsConfig, Networks};
    2|       |use crate::{
    3|       |    block_processing::{
    4|       |        BacklogScanConfig, BlockProcessorConfig, BoundedBacklogConfig, LocalBlockBroadcasterConfig,
    5|       |    },
    6|       |    bootstrap::{BootstrapConfig, BootstrapResponderConfig},
    7|       |    cementation::ConfirmingSetConfig,
    8|       |    consensus::{
    9|       |        ActiveElectionsConfig, HintedSchedulerConfig, OptimisticSchedulerConfig,
   10|       |        PriorityBucketConfig, RequestAggregatorConfig, VoteCacheConfig, VoteProcessorConfig,
   11|       |    },
   12|       |    stats::StatsConfig,
   13|       |    transport::MessageProcessorConfig,
   14|       |    NetworkParams, DEV_NETWORK_PARAMS,
   15|       |};
   16|       |use once_cell::sync::Lazy;
   17|       |use rand::{thread_rng, Rng};
   18|       |use rsnano_core::{
   19|       |    utils::{get_env_or_default_string, Peer},
   20|       |    Account, Amount, PublicKey,
   21|       |};
   22|       |use rsnano_nullable_http_client::Url;
   23|       |use rsnano_store_lmdb::LmdbConfig;
   24|       |use std::{cmp::max, net::Ipv6Addr, time::Duration};
   25|       |
   26|       |#[derive(Clone, Debug, PartialEq)]
   27|       |pub struct NodeConfig {
   28|       |    pub peering_port: Option<u16>,
   29|       |    pub default_peering_port: u16,
   30|       |    pub optimistic_scheduler: OptimisticSchedulerConfig,
   31|       |    pub hinted_scheduler: HintedSchedulerConfig,
   32|       |    pub priority_bucket: PriorityBucketConfig,
   33|       |    pub bootstrap_fraction_numerator: u32,
   34|       |    pub receive_minimum: Amount,
   35|       |    pub online_weight_minimum: Amount,
   36|       |    /// The minimum vote weight that a representative must have for its vote to be counted.
   37|       |    /// All representatives above this weight will be kept in memory!
   38|       |    pub representative_vote_weight_minimum: Amount,
   39|       |    pub password_fanout: u32,
   40|       |    pub io_threads: u32,
   41|       |    pub network_threads: u32,
   42|       |    pub work_threads: u32,
   43|       |    pub background_threads: u32,
   44|       |    pub signature_checker_threads: u32,
   45|       |    pub enable_voting: bool,
   46|       |    pub enable_vote_processor: bool,
   47|       |    pub enable_priority_scheduler: bool,
   48|       |    pub enable_optimistic_scheduler: bool,
   49|       |    pub enable_hinted_scheduler: bool,
   50|       |    pub enable_monitor: bool,
   51|       |    pub enable_bounded_backlog: bool,
   52|       |    pub bootstrap_initiator_threads: u32,
   53|       |    pub bootstrap_serving_threads: u32,
   54|       |    pub block_processor_batch_max_time_ms: i64,
   55|       |    pub allow_local_peers: bool,
   56|       |    pub vote_minimum: Amount,
   57|       |    pub vote_generator_delay: Duration,
   58|       |    pub unchecked_cutoff_time_s: i64,
   59|       |    pub pow_sleep_interval_ns: i64,
   60|       |    pub external_address: String,
   61|       |    pub external_port: u16,
   62|       |    pub use_memory_pools: bool,
   63|       |    pub bandwidth_limit: usize,
   64|       |    pub bandwidth_limit_burst_ratio: f64,
   65|       |    pub max_peers_per_ip: u16,
   66|       |    pub max_peers_per_subnetwork: u16,
   67|       |    pub bootstrap: BootstrapConfig,
   68|       |    pub bootstrap_responder: BootstrapResponderConfig,
   69|       |    pub bootstrap_bandwidth_limit: usize,
   70|       |    pub bootstrap_bandwidth_burst_ratio: f64,
   71|       |    pub confirming_set_batch_time: Duration,
   72|       |    pub backup_before_upgrade: bool,
   73|       |    pub max_work_generate_multiplier: f64,
   74|       |    pub max_queued_requests: u32,
   75|       |    pub request_aggregator_threads: u32,
   76|       |    pub max_unchecked_blocks: u32,
   77|       |    pub rep_crawler_weight_minimum: Amount,
   78|       |    pub work_peers: Vec<Peer>,
   79|       |    pub secondary_work_peers: Vec<Peer>,
   80|       |    pub preconfigured_peers: Vec<Peer>,
   81|       |    pub preconfigured_representatives: Vec<PublicKey>,
   82|       |    pub max_pruning_age_s: i64,
   83|       |    pub max_pruning_depth: u64,
   84|       |    pub callback_address: String,
   85|       |    pub callback_port: u16,
   86|       |    pub callback_target: String,
   87|       |    pub websocket_config: WebsocketConfig,
   88|       |    pub diagnostics_config: DiagnosticsConfig,
   89|       |    pub stat_config: StatsConfig,
   90|       |    pub lmdb_config: LmdbConfig,
   91|       |    pub vote_cache: VoteCacheConfig,
   92|       |    pub rep_crawler_query_timeout: Duration,
   93|       |    pub block_processor: BlockProcessorConfig,
   94|       |    pub active_elections: ActiveElectionsConfig,
   95|       |    pub vote_processor: VoteProcessorConfig,
   96|       |    pub tcp: TcpConfig,
   97|       |    pub request_aggregator: RequestAggregatorConfig,
   98|       |    pub message_processor: MessageProcessorConfig,
   99|       |    pub local_block_broadcaster: LocalBlockBroadcasterConfig,
  100|       |    pub confirming_set: ConfirmingSetConfig,
  101|       |    pub monitor: MonitorConfig,
  102|       |    pub backlog_scan: BacklogScanConfig,
  103|       |    pub bounded_backlog: BoundedBacklogConfig,
  104|       |    pub network_duplicate_filter_cutoff: u64,
  105|       |    pub max_ledger_notifications: usize,
  106|       |}
  107|       |
  108|       |static DEFAULT_LIVE_PEER_NETWORK: Lazy<String> =
  109|      0|    Lazy::new(|| get_env_or_default_string("NANO_DEFAULT_PEER", "peering.nano.org"));
  110|       |
  111|       |static DEFAULT_BETA_PEER_NETWORK: Lazy<String> =
  112|      1|    Lazy::new(|| get_env_or_default_string("NANO_DEFAULT_PEER", "peering-beta.nano.org"));
  113|       |
  114|       |static DEFAULT_TEST_PEER_NETWORK: Lazy<String> =
  115|      0|    Lazy::new(|| get_env_or_default_string("NANO_DEFAULT_PEER", "peering-test.nano.org"));
  116|       |
  117|       |impl NodeConfig {
  118|      4|    pub fn default_for(network: Networks, parallelism: usize) -> Self {
  119|      4|        let net_params = NetworkParams::new(network);
  120|      4|        Self::new(
  121|      4|            Some(net_params.network.default_node_port),
  122|      4|            &net_params,
  123|      4|            parallelism,
  124|      4|        )
  125|      4|    }
  126|       |
  127|      9|    pub fn new(
  128|      9|        peering_port: Option<u16>,
  129|      9|        network_params: &NetworkParams,
  130|      9|        parallelism: usize,
  131|      9|    ) -> Self {
  132|      9|        if peering_port == Some(0) {
  133|      0|            // comment for posterity:
  134|      0|            // - we used to consider ports being 0 a sentinel that meant to use a default port for that specific purpose
  135|      0|            // - the actual default value was determined based on the active network (e.g. dev network peering port = 44000)
  136|      0|            // - now, the 0 value means something different instead: user wants to let the OS pick a random port
  137|      0|            // - for the specific case of the peering port, after it gets picked, it can be retrieved by client code via
  138|      0|            //   node.network.endpoint ().port ()
  139|      0|            // - the config value does not get back-propagated because it represents the choice of the user, and that was 0
  140|      9|        }
  141|       |
  142|      9|        let mut enable_voting = false;
  143|      9|        let mut preconfigured_peers = Vec::new();
  144|      9|        let mut preconfigured_representatives = Vec::new();
  145|      9|        let default_port = network_params.network.default_node_port;
  146|      9|        match network_params.network.current_network {
  147|      5|            Networks::NanoDevNetwork => {
  148|      5|                enable_voting = true;
  149|      5|                preconfigured_representatives.push(network_params.ledger.genesis_account.into());
  150|      5|            }
  151|      4|            Networks::NanoBetaNetwork => {
  152|      4|                preconfigured_peers
  153|      4|                    .push(Peer::new(DEFAULT_BETA_PEER_NETWORK.clone(), default_port));
  154|      4|                preconfigured_representatives.push(
  155|      4|                    Account::decode_account(
  156|      4|                        "nano_1defau1t9off1ine9rep99999999999999999999999999999999wgmuzxxy",
  157|      4|                    )
  158|      4|                    .unwrap()
  159|      4|                    .into(),
  160|      4|                );
  161|      4|            }
  162|      0|            Networks::NanoLiveNetwork => {
  163|      0|                preconfigured_peers
  164|      0|                    .push(Peer::new(DEFAULT_LIVE_PEER_NETWORK.clone(), default_port));
  165|      0|                preconfigured_representatives.push(
  166|      0|                    PublicKey::decode_hex(
  167|      0|                        "A30E0A32ED41C8607AA9212843392E853FCBCB4E7CB194E35C94F07F91DE59EF",
  168|      0|                    )
  169|      0|                    .unwrap(),
  170|      0|                );
  171|      0|                preconfigured_representatives.push(
  172|      0|                    PublicKey::decode_hex(
  173|      0|                        "67556D31DDFC2A440BF6147501449B4CB9572278D034EE686A6BEE29851681DF",
  174|      0|                    )
  175|      0|                    .unwrap(),
  176|      0|                );
  177|      0|                preconfigured_representatives.push(
  178|      0|                    PublicKey::decode_hex(
  179|      0|                        "5C2FBB148E006A8E8BA7A75DD86C9FE00C83F5FFDBFD76EAA09531071436B6AF",
  180|      0|                    )
  181|      0|                    .unwrap(),
  182|      0|                );
  183|      0|                preconfigured_representatives.push(
  184|      0|                    PublicKey::decode_hex(
  185|      0|                        "AE7AC63990DAAAF2A69BF11C913B928844BF5012355456F2F164166464024B29",
  186|      0|                    )
  187|      0|                    .unwrap(),
  188|      0|                );
  189|      0|                preconfigured_representatives.push(
  190|      0|                    PublicKey::decode_hex(
  191|      0|                        "BD6267D6ECD8038327D2BCC0850BDF8F56EC0414912207E81BCF90DFAC8A4AAA",
  192|      0|                    )
  193|      0|                    .unwrap(),
  194|      0|                );
  195|      0|                preconfigured_representatives.push(
  196|      0|                    PublicKey::decode_hex(
  197|      0|                        "2399A083C600AA0572F5E36247D978FCFC840405F8D4B6D33161C0066A55F431",
  198|      0|                    )
  199|      0|                    .unwrap(),
  200|      0|                );
  201|      0|                preconfigured_representatives.push(
  202|      0|                    PublicKey::decode_hex(
  203|      0|                        "2298FAB7C61058E77EA554CB93EDEEDA0692CBFCC540AB213B2836B29029E23A",
  204|      0|                    )
  205|      0|                    .unwrap(),
  206|      0|                );
  207|      0|                preconfigured_representatives.push(
  208|      0|                    PublicKey::decode_hex(
  209|      0|                        "3FE80B4BC842E82C1C18ABFEEC47EA989E63953BC82AC411F304D13833D52A56",
  210|      0|                    )
  211|      0|                    .unwrap(),
  212|      0|                );
  213|      0|            }
  214|      0|            Networks::NanoTestNetwork => {
  215|      0|                preconfigured_peers
  216|      0|                    .push(Peer::new(DEFAULT_TEST_PEER_NETWORK.clone(), default_port));
  217|      0|                preconfigured_representatives.push(network_params.ledger.genesis_account.into());
  218|      0|            }
  219|      0|            Networks::Invalid => panic!("invalid network"),
  220|       |        }
  221|       |
  222|      9|        let block_processor_cfg = BlockProcessorConfig::new(network_params.work.clone());
  223|      9|
  224|      9|        Self {
  225|      9|            peering_port,
  226|      9|            default_peering_port: network_params.network.default_node_port,
  227|      9|            bootstrap_fraction_numerator: 1,
  228|      9|            receive_minimum: Amount::micronano(1),
  229|      9|            online_weight_minimum: Amount::nano(60_000_000),
  230|      9|            representative_vote_weight_minimum: Amount::nano(10),
  231|      9|            password_fanout: 1024,
  232|      9|            io_threads: max(parallelism, 4) as u32,
  233|      9|            network_threads: max(parallelism, 4) as u32,
  234|      9|            work_threads: max(parallelism, 4) as u32,
  235|      9|            background_threads: max(parallelism, 4) as u32,
  236|      9|            /* Use half available threads on the system for signature checking. The calling thread does checks as well, so these are extra worker threads */
  237|      9|            signature_checker_threads: (parallelism / 2) as u32,
  238|      9|            enable_voting,
  239|      9|            enable_vote_processor: true,
  240|      9|            enable_priority_scheduler: true,
  241|      9|            enable_optimistic_scheduler: true,
  242|      9|            enable_hinted_scheduler: true,
  243|      9|            enable_monitor: true,
  244|      9|            enable_bounded_backlog: true,
  245|      9|            bootstrap_initiator_threads: 1,
  246|      9|            bootstrap_serving_threads: 1,
  247|      9|            block_processor_batch_max_time_ms: block_processor_cfg.batch_max_time.as_millis()
  248|      9|                as i64,
  249|      9|            allow_local_peers: !(network_params.network.is_live_network()
  250|      9|                || network_params.network.is_test_network()), // disable by default for live network
  251|      9|            vote_minimum: Amount::nano(1000),
  252|      9|            vote_generator_delay: Duration::from_millis(100),
  253|      9|            unchecked_cutoff_time_s: 4 * 60 * 60, // 4 hours
  254|      9|            pow_sleep_interval_ns: 0,
  255|      9|            external_address: Ipv6Addr::UNSPECIFIED.to_string(),
  256|      9|            external_port: 0,
  257|      9|            use_memory_pools: true,
  258|      9|            // Default outbound traffic shaping is 10MB/s
  259|      9|            bandwidth_limit: 10 * 1024 * 1024,
  260|      9|            // By default, allow bursts of 15MB/s (not sustainable)
  261|      9|            bandwidth_limit_burst_ratio: 3_f64,
  262|      9|            max_peers_per_ip: network_params.network.max_peers_per_ip as u16,
  263|      9|            max_peers_per_subnetwork: network_params.network.max_peers_per_subnetwork as u16,
  264|      9|            // Default bootstrap outbound traffic limit is 5MB/s
  265|      9|            bootstrap_bandwidth_limit: 5 * 1024 * 1024,
  266|      9|            // Bootstrap traffic does not need bursts
  267|      9|            bootstrap_bandwidth_burst_ratio: 1.,
  268|      9|            bootstrap: Default::default(),
  269|      9|            bootstrap_responder: Default::default(),
  270|      9|            confirming_set_batch_time: Duration::from_millis(250),
  271|      9|            backup_before_upgrade: false,
  272|      9|            max_work_generate_multiplier: 64_f64,
  273|      9|            max_queued_requests: 512,
  274|      9|            request_aggregator_threads: max(parallelism, 4) as u32,
  275|      9|            max_unchecked_blocks: 65536,
  276|      9|            rep_crawler_weight_minimum: Amount::decode_hex("FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF")
  277|      9|                .unwrap(),
  278|      9|            work_peers: Vec::new(),
  279|      9|            secondary_work_peers: vec![Peer::new("127.0.0.1", 8076)],
  280|      9|            preconfigured_peers,
  281|      9|            preconfigured_representatives,
  282|      9|            max_pruning_age_s: if !network_params.network.is_beta_network() {
  283|      5|                24 * 60 * 60
  284|       |            } else {
  285|      4|                5 * 60
  286|       |            }, // 1 day; 5 minutes for beta network
  287|       |            max_pruning_depth: 0,
  288|      9|            callback_address: String::new(),
  289|      9|            callback_port: 0,
  290|      9|            callback_target: String::new(),
  291|      9|            websocket_config: WebsocketConfig::new(&network_params.network),
  292|      9|            diagnostics_config: DiagnosticsConfig::new(),
  293|      9|            stat_config: StatsConfig::new(),
  294|      9|            lmdb_config: LmdbConfig::new(),
  295|      9|            optimistic_scheduler: OptimisticSchedulerConfig::new(),
  296|      9|            hinted_scheduler: if network_params.network.is_dev_network() {
  297|      5|                HintedSchedulerConfig::default_for_dev_network()
  298|       |            } else {
  299|      4|                HintedSchedulerConfig::default()
  300|       |            },
  301|      9|            priority_bucket: Default::default(),
  302|      9|            vote_cache: Default::default(),
  303|      9|            active_elections: Default::default(),
  304|      9|            rep_crawler_query_timeout: if network_params.network.is_dev_network() {
  305|      5|                Duration::from_secs(1)
  306|       |            } else {
  307|      4|                Duration::from_secs(60)
  308|       |            },
  309|      9|            block_processor: block_processor_cfg,
  310|      9|            vote_processor: VoteProcessorConfig::new(parallelism),
  311|      9|            tcp: if network_params.network.is_dev_network() {
  312|      5|                TcpConfig::for_dev_network()
  313|       |            } else {
  314|      4|                Default::default()
  315|       |            },
  316|      9|            request_aggregator: RequestAggregatorConfig::new(parallelism),
  317|      9|            message_processor: MessageProcessorConfig::new(parallelism),
  318|      9|            local_block_broadcaster: LocalBlockBroadcasterConfig::new(
  319|      9|                network_params.network.current_network,
  320|      9|            ),
  321|      9|            confirming_set: Default::default(),
  322|      9|            monitor: Default::default(),
  323|      9|            backlog_scan: Default::default(),
  324|      9|            bounded_backlog: Default::default(),
  325|      9|            network_duplicate_filter_cutoff: 60,
  326|      9|            max_ledger_notifications: 8,
  327|      9|        }
  328|      9|    }
  329|       |
  330|      5|    pub fn new_test_instance() -> Self {
  331|      5|        Self::new(None, &DEV_NETWORK_PARAMS, 1)
  332|      5|    }
  333|       |
  334|      0|    pub fn random_representative(&self) -> PublicKey {
  335|      0|        let i = thread_rng().gen_range(0..self.preconfigured_representatives.len());
  336|      0|        return self.preconfigured_representatives[i];
  337|      0|    }
  338|       |
  339|      3|    pub fn rpc_callback_url(&self) -> Option<Url> {
  340|      3|        format!(
  341|      3|            "http://{}:{}{}",
  342|      3|            self.callback_address, self.callback_port, self.callback_target
  343|      3|        )
  344|      3|        .parse()
  345|      3|        .ok()
  346|      3|    }
  347|       |}
  348|       |
  349|       |#[derive(Clone, Debug, PartialEq)]
  350|       |pub struct MonitorConfig {
  351|       |    pub interval: Duration,
  352|       |}
  353|       |
  354|       |impl Default for MonitorConfig {
  355|      9|    fn default() -> Self {
  356|      9|        Self {
  357|      9|            interval: Duration::from_secs(60),
  358|      9|        }
  359|      9|    }
  360|       |}
  361|       |
  362|       |#[derive(Clone, Debug, PartialEq)]
  363|       |pub struct TcpConfig {
  364|       |    pub max_inbound_connections: usize,
  365|       |    pub max_outbound_connections: usize,
  366|       |    pub max_attempts: usize,
  367|       |    pub max_attempts_per_ip: usize,
  368|       |    pub connect_timeout: Duration,
  369|       |}
  370|       |
  371|       |impl TcpConfig {
  372|      5|    pub fn for_dev_network() -> Self {
  373|      5|        Self {
  374|      5|            max_inbound_connections: 128,
  375|      5|            max_outbound_connections: 128,
  376|      5|            max_attempts: 128,
  377|      5|            max_attempts_per_ip: 128,
  378|      5|            connect_timeout: Duration::from_secs(5),
  379|      5|        }
  380|      5|    }
  381|       |}
  382|       |
  383|       |impl Default for TcpConfig {
  384|      4|    fn default() -> Self {
  385|      4|        Self {
  386|      4|            max_inbound_connections: 2048,
  387|      4|            max_outbound_connections: 2048,
  388|      4|            max_attempts: 60,
  389|      4|            max_attempts_per_ip: 1,
  390|      4|            connect_timeout: Duration::from_secs(60),
  391|      4|        }
  392|      4|    }
  393|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/node_flags.rs:
    1|       |use crate::block_processing::BlockProcessorConfig;
    2|       |use rsnano_ledger::GenerateCacheFlags;
    3|       |
    4|       |#[derive(Clone)]
    5|       |pub struct NodeFlags {
    6|       |    pub config_overrides: Vec<String>,
    7|       |    pub rpc_config_overrides: Vec<String>,
    8|       |    pub disable_activate_successors: bool,
    9|       |    pub disable_backup: bool,
   10|       |    pub disable_lazy_bootstrap: bool,
   11|       |    pub disable_legacy_bootstrap: bool,
   12|       |    pub disable_wallet_bootstrap: bool,
   13|       |    pub disable_bootstrap_listener: bool,
   14|       |    pub disable_bootstrap_bulk_pull_server: bool,
   15|       |    pub disable_bootstrap_bulk_push_client: bool,
   16|       |    pub disable_ongoing_bootstrap: bool, // For testing only
   17|       |    pub disable_rep_crawler: bool,
   18|       |    pub disable_request_loop: bool, // For testing only
   19|       |    pub disable_tcp_realtime: bool,
   20|       |    pub disable_providing_telemetry_metrics: bool,
   21|       |    pub disable_block_processor_unchecked_deletion: bool,
   22|       |    pub disable_block_processor_republishing: bool,
   23|       |    pub allow_bootstrap_peers_duplicates: bool,
   24|       |    pub disable_max_peers_per_ip: bool,         // For testing only
   25|       |    pub disable_max_peers_per_subnetwork: bool, // For testing only
   26|       |    pub disable_search_pending: bool,           // For testing only
   27|       |    pub enable_pruning: bool,
   28|       |    pub fast_bootstrap: bool,
   29|       |    pub read_only: bool,
   30|       |    pub disable_connection_cleanup: bool,
   31|       |    pub generate_cache: GenerateCacheFlags,
   32|       |    pub inactive_node: bool,
   33|       |    pub block_processor_batch_size: usize,
   34|       |    pub block_processor_full_size: usize,
   35|       |    pub block_processor_verification_size: usize,
   36|       |    pub vote_processor_capacity: usize,
   37|       |    pub bootstrap_interval: usize, // For testing only
   38|       |}
   39|       |
   40|       |impl NodeFlags {
   41|      3|    pub fn new() -> Self {
   42|      3|        Self {
   43|      3|            config_overrides: Vec::new(),
   44|      3|            rpc_config_overrides: Vec::new(),
   45|      3|            disable_activate_successors: false,
   46|      3|            disable_backup: false,
   47|      3|            disable_lazy_bootstrap: false,
   48|      3|            disable_legacy_bootstrap: false,
   49|      3|            disable_wallet_bootstrap: false,
   50|      3|            disable_bootstrap_listener: false,
   51|      3|            disable_bootstrap_bulk_pull_server: false,
   52|      3|            disable_bootstrap_bulk_push_client: false,
   53|      3|            disable_ongoing_bootstrap: false,
   54|      3|            disable_rep_crawler: false,
   55|      3|            disable_request_loop: false,
   56|      3|            disable_tcp_realtime: false,
   57|      3|            disable_providing_telemetry_metrics: false,
   58|      3|            disable_block_processor_unchecked_deletion: false,
   59|      3|            disable_block_processor_republishing: false,
   60|      3|            allow_bootstrap_peers_duplicates: false,
   61|      3|            disable_max_peers_per_ip: false,
   62|      3|            disable_max_peers_per_subnetwork: false,
   63|      3|            disable_search_pending: false,
   64|      3|            enable_pruning: false,
   65|      3|            fast_bootstrap: false,
   66|      3|            read_only: false,
   67|      3|            disable_connection_cleanup: false,
   68|      3|            generate_cache: GenerateCacheFlags::new(),
   69|      3|            inactive_node: false,
   70|      3|            block_processor_batch_size: BlockProcessorConfig::DEFAULT_BATCH_SIZE,
   71|      3|            block_processor_full_size: BlockProcessorConfig::DEFAULT_FULL_SIZE,
   72|      3|            block_processor_verification_size: 0,
   73|      3|            vote_processor_capacity: 144 * 1024,
   74|      3|            bootstrap_interval: 0,
   75|      3|        }
   76|      3|    }
   77|       |}
   78|       |
   79|       |impl Default for NodeFlags {
   80|      3|    fn default() -> Self {
   81|      3|        Self::new()
   82|      3|    }
   83|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/node_rpc_config.rs:
    1|       |use super::get_default_rpc_filepath;
    2|       |use std::path::PathBuf;
    3|       |
    4|       |#[derive(Debug, PartialEq)]
    5|       |pub struct RpcChildProcessConfig {
    6|       |    pub enable: bool,
    7|       |    pub rpc_path: PathBuf,
    8|       |}
    9|       |
   10|       |impl RpcChildProcessConfig {
   11|      5|    pub fn new() -> Self {
   12|      5|        Self {
   13|      5|            enable: false,
   14|      5|            rpc_path: get_default_rpc_filepath(),
   15|      5|        }
   16|      5|    }
   17|       |}
   18|       |
   19|       |#[derive(Debug, PartialEq)]
   20|       |pub struct NodeRpcConfig {
   21|       |    pub enable_sign_hash: bool,
   22|       |    pub child_process: RpcChildProcessConfig,
   23|       |}
   24|       |
   25|       |impl NodeRpcConfig {
   26|      4|    pub fn new() -> Self {
   27|      4|        Self {
   28|      4|            enable_sign_hash: false,
   29|      4|            child_process: RpcChildProcessConfig::new(),
   30|      4|        }
   31|      4|    }
   32|       |}
   33|       |
   34|       |impl Default for NodeRpcConfig {
   35|      0|    fn default() -> Self {
   36|      0|        Self {
   37|      0|            enable_sign_hash: false,
   38|      0|            child_process: RpcChildProcessConfig::new(),
   39|      0|        }
   40|      0|    }
   41|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/opencl_config.rs:
    1|       |#[derive(Debug, PartialEq)]
    2|       |pub struct OpenclConfig {
    3|       |    pub platform: u32,
    4|       |    pub device: u32,
    5|       |    pub threads: u32,
    6|       |}
    7|       |
    8|       |impl OpenclConfig {
    9|      4|    pub fn new() -> Self {
   10|      4|        Default::default()
   11|      4|    }
   12|       |}
   13|       |
   14|       |impl Default for OpenclConfig {
   15|      4|    fn default() -> Self {
   16|      4|        Self {
   17|      4|            platform: 0,
   18|      4|            device: 0,
   19|      4|            threads: 1024 * 1024,
   20|      4|        }
   21|      4|    }
   22|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/active_elections_toml.rs:
    1|       |use crate::consensus::ActiveElectionsConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      6|#[derive(Deserialize, Serialize)]
    5|       |pub struct ActiveElectionsToml {
    6|       |    pub confirmation_cache: Option<usize>,
    7|       |    pub confirmation_history_size: Option<usize>,
    8|       |    pub hinted_limit_percentage: Option<usize>,
    9|       |    pub optimistic_limit_percentage: Option<usize>,
   10|       |    pub size: Option<usize>,
   11|       |}
   12|       |
   13|       |impl Default for ActiveElectionsToml {
   14|      0|    fn default() -> Self {
   15|      0|        let config = ActiveElectionsConfig::default();
   16|      0|        (&config).into()
   17|      0|    }
   18|       |}
   19|       |
   20|       |impl From<&ActiveElectionsToml> for ActiveElectionsConfig {
   21|      1|    fn from(toml: &ActiveElectionsToml) -> Self {
   22|      1|        let mut config = ActiveElectionsConfig::default();
   23|       |
   24|      1|        if let Some(size) = toml.size {
   25|      1|            config.size = size
   26|      0|        };
   27|      1|        if let Some(hinted_limit_percentage) = toml.hinted_limit_percentage {
   28|      1|            config.hinted_limit_percentage = hinted_limit_percentage
   29|      0|        };
   30|      1|        if let Some(optimistic_limit_percentage) = toml.optimistic_limit_percentage {
   31|      1|            config.optimistic_limit_percentage = optimistic_limit_percentage
   32|      0|        };
   33|      1|        if let Some(confirmation_history_size) = toml.confirmation_history_size {
   34|      1|            config.confirmation_history_size = confirmation_history_size
   35|      0|        };
   36|      1|        if let Some(confirmation_cache) = toml.confirmation_cache {
   37|      1|            config.confirmation_cache = confirmation_cache
   38|      0|        };
   39|       |
   40|      1|        config
   41|      1|    }
   42|       |}
   43|       |
   44|       |impl From<&ActiveElectionsConfig> for ActiveElectionsToml {
   45|      1|    fn from(config: &ActiveElectionsConfig) -> Self {
   46|      1|        Self {
   47|      1|            size: Some(config.size),
   48|      1|            hinted_limit_percentage: Some(config.hinted_limit_percentage),
   49|      1|            optimistic_limit_percentage: Some(config.optimistic_limit_percentage),
   50|      1|            confirmation_history_size: Some(config.confirmation_history_size),
   51|      1|            confirmation_cache: Some(config.confirmation_cache),
   52|      1|        }
   53|      1|    }
   54|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/backlog_scan_toml.rs:
    1|       |use crate::block_processing::BacklogScanConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct BacklogScanToml {
    6|       |    pub enable: Option<bool>,
    7|       |    pub batch_size: Option<usize>,
    8|       |    pub rate_limit: Option<usize>,
    9|       |}
   10|       |
   11|       |impl From<&BacklogScanConfig> for BacklogScanToml {
   12|      1|    fn from(value: &BacklogScanConfig) -> Self {
   13|      1|        Self {
   14|      1|            enable: Some(value.enabled),
   15|      1|            batch_size: Some(value.batch_size),
   16|      1|            rate_limit: Some(value.rate_limit),
   17|      1|        }
   18|      1|    }
   19|       |}
   20|       |
   21|       |impl BacklogScanConfig {
   22|      1|    pub(crate) fn merge_toml(&mut self, toml: &BacklogScanToml) {
   23|      1|        if let Some(enable) = toml.enable {
   24|      1|            self.enabled = enable;
   25|      1|        }
                       ^0
   26|       |
   27|      1|        if let Some(size) = toml.batch_size {
   28|      1|            self.batch_size = size;
   29|      1|        }
                       ^0
   30|       |
   31|      1|        if let Some(freq) = toml.rate_limit {
   32|      1|            self.rate_limit = freq;
   33|      1|        }
                       ^0
   34|      1|    }
   35|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/block_processor_toml.rs:
    1|       |use crate::block_processing::BlockProcessorConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      6|#[derive(Deserialize, Serialize)]
    5|       |pub struct BlockProcessorToml {
    6|       |    pub max_peer_queue: Option<usize>,
    7|       |    pub max_system_queue: Option<usize>,
    8|       |    pub priority_bootstrap: Option<usize>,
    9|       |    pub priority_live: Option<usize>,
   10|       |    pub priority_local: Option<usize>,
   11|       |}
   12|       |
   13|       |impl From<&BlockProcessorConfig> for BlockProcessorToml {
   14|      1|    fn from(config: &BlockProcessorConfig) -> Self {
   15|      1|        Self {
   16|      1|            max_peer_queue: Some(config.max_peer_queue),
   17|      1|            max_system_queue: Some(config.max_system_queue),
   18|      1|            priority_live: Some(config.priority_live),
   19|      1|            priority_bootstrap: Some(config.priority_bootstrap),
   20|      1|            priority_local: Some(config.priority_local),
   21|      1|        }
   22|      1|    }
   23|       |}
   24|       |
   25|       |impl BlockProcessorConfig {
   26|      1|    pub fn merge_toml(&mut self, toml: &BlockProcessorToml) {
   27|      1|        if let Some(max_peer_queue) = toml.max_peer_queue {
   28|      1|            self.max_peer_queue = max_peer_queue;
   29|      1|        }
                       ^0
   30|      1|        if let Some(max_system_queue) = toml.max_system_queue {
   31|      1|            self.max_system_queue = max_system_queue;
   32|      1|        }
                       ^0
   33|      1|        if let Some(priority_live) = toml.priority_live {
   34|      1|            self.priority_live = priority_live;
   35|      1|        }
                       ^0
   36|      1|        if let Some(priority_local) = toml.priority_local {
   37|      1|            self.priority_local = priority_local;
   38|      1|        }
                       ^0
   39|      1|        if let Some(priority_bootstrap) = toml.priority_bootstrap {
   40|      1|            self.priority_bootstrap = priority_bootstrap;
   41|      1|        }
                       ^0
   42|      1|    }
   43|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/bootstrap_server_toml.rs:
    1|       |use crate::bootstrap::BootstrapResponderConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct BootstrapServerToml {
    6|       |    pub batch_size: Option<usize>,
    7|       |    pub max_queue: Option<usize>,
    8|       |    pub threads: Option<usize>,
    9|       |}
   10|       |
   11|       |impl Default for BootstrapServerToml {
   12|      0|    fn default() -> Self {
   13|      0|        let config = BootstrapResponderConfig::default();
   14|      0|        (&config).into()
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl From<&BootstrapServerToml> for BootstrapResponderConfig {
   19|      1|    fn from(toml: &BootstrapServerToml) -> Self {
   20|      1|        let mut config = BootstrapResponderConfig::default();
   21|       |
   22|      1|        if let Some(max_queue) = toml.max_queue {
   23|      1|            config.max_queue = max_queue;
   24|      1|        }
                       ^0
   25|      1|        if let Some(threads) = toml.threads {
   26|      1|            config.threads = threads;
   27|      1|        }
                       ^0
   28|      1|        if let Some(batch_size) = toml.batch_size {
   29|      1|            config.batch_size = batch_size;
   30|      1|        }
                       ^0
   31|      1|        config
   32|      1|    }
   33|       |}
   34|       |
   35|       |impl From<&BootstrapResponderConfig> for BootstrapServerToml {
   36|      1|    fn from(config: &BootstrapResponderConfig) -> Self {
   37|      1|        Self {
   38|      1|            max_queue: Some(config.max_queue),
   39|      1|            threads: Some(config.threads),
   40|      1|            batch_size: Some(config.batch_size),
   41|      1|        }
   42|      1|    }
   43|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/bootstrap_toml.rs:
    1|       |use crate::bootstrap::{AccountSetsConfig, BootstrapConfig};
    2|       |use serde::{Deserialize, Serialize};
    3|       |use std::time::Duration;
    4|       |
    5|     14|#[derive(Deserialize, Serialize)]
    6|       |pub struct BootstrapToml {
    7|       |    pub enable: Option<bool>,
    8|       |    pub enable_databaser_scan: Option<bool>,
    9|       |    pub enable_dependency_walker: Option<bool>,
   10|       |    pub enable_frontier_scan: Option<bool>,
   11|       |    pub block_processor_threshold: Option<usize>,
   12|       |    pub database_rate_limit: Option<usize>,
   13|       |    pub database_warmup_ratio: Option<usize>,
   14|       |    pub max_pull_count: Option<usize>,
   15|       |    pub channel_limit: Option<usize>,
   16|       |    pub rate_limit: Option<usize>,
   17|       |    pub throttle_coefficient: Option<usize>,
   18|       |    pub throttle_wait: Option<u64>,
   19|       |    pub request_timeout: Option<u64>,
   20|       |    pub max_requests: Option<usize>,
   21|       |    pub optimistic_request_percentage: Option<u8>,
   22|       |    pub account_sets: Option<AccountSetsToml>,
   23|       |}
   24|       |
   25|       |impl From<&BootstrapConfig> for BootstrapToml {
   26|      1|    fn from(config: &BootstrapConfig) -> Self {
   27|      1|        Self {
   28|      1|            enable: Some(config.enable),
   29|      1|            enable_databaser_scan: Some(config.enable_database_scan),
   30|      1|            enable_dependency_walker: Some(config.enable_dependency_walker),
   31|      1|            enable_frontier_scan: Some(config.enable_frontier_scan),
   32|      1|            channel_limit: Some(config.channel_limit),
   33|      1|            rate_limit: Some(config.rate_limit),
   34|      1|            database_rate_limit: Some(config.database_rate_limit),
   35|      1|            database_warmup_ratio: Some(config.database_warmup_ratio),
   36|      1|            max_pull_count: Some(config.max_pull_count),
   37|      1|            request_timeout: Some(config.request_timeout.as_millis() as u64),
   38|      1|            throttle_coefficient: Some(config.throttle_coefficient),
   39|      1|            throttle_wait: Some(config.throttle_wait.as_millis() as u64),
   40|      1|            account_sets: Some((&config.account_sets).into()),
   41|      1|            block_processor_threshold: Some(config.block_processor_theshold),
   42|      1|            max_requests: Some(config.max_requests),
   43|      1|            optimistic_request_percentage: Some(config.optimistic_request_percentage),
   44|      1|        }
   45|      1|    }
   46|       |}
   47|       |
   48|      5|#[derive(Clone, Deserialize, Serialize)]
   49|       |pub struct AccountSetsToml {
   50|       |    pub blocking_max: Option<usize>,
   51|       |    pub consideration_count: Option<usize>,
   52|       |    pub cooldown: Option<u64>,
   53|       |    pub priorities_max: Option<usize>,
   54|       |}
   55|       |
   56|       |impl Default for AccountSetsToml {
   57|      0|    fn default() -> Self {
   58|      0|        let config = AccountSetsConfig::default();
   59|      0|        Self {
   60|      0|            consideration_count: Some(config.consideration_count),
   61|      0|            priorities_max: Some(config.priorities_max),
   62|      0|            blocking_max: Some(config.blocking_max),
   63|      0|            cooldown: Some(config.cooldown.as_millis() as u64),
   64|      0|        }
   65|      0|    }
   66|       |}
   67|       |
   68|       |impl From<&AccountSetsConfig> for AccountSetsToml {
   69|      1|    fn from(value: &AccountSetsConfig) -> Self {
   70|      1|        Self {
   71|      1|            consideration_count: Some(value.consideration_count),
   72|      1|            priorities_max: Some(value.priorities_max),
   73|      1|            blocking_max: Some(value.blocking_max),
   74|      1|            cooldown: Some(value.cooldown.as_millis() as u64),
   75|      1|        }
   76|      1|    }
   77|       |}
   78|       |
   79|       |impl From<&AccountSetsToml> for AccountSetsConfig {
   80|      2|    fn from(toml: &AccountSetsToml) -> Self {
   81|      2|        let mut config = AccountSetsConfig::default();
   82|       |
   83|      2|        if let Some(blocking_max) = toml.blocking_max {
   84|      2|            config.blocking_max = blocking_max;
   85|      2|        }
                       ^0
   86|      2|        if let Some(consideration_count) = toml.consideration_count {
   87|      2|            config.consideration_count = consideration_count;
   88|      2|        }
                       ^0
   89|      2|        if let Some(priorities_max) = toml.priorities_max {
   90|      2|            config.priorities_max = priorities_max;
   91|      2|        }
                       ^0
   92|      2|        if let Some(cooldown) = &toml.cooldown {
   93|      2|            config.cooldown = Duration::from_millis(*cooldown);
   94|      2|        }
                       ^0
   95|      2|        config
   96|      2|    }
   97|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/bounded_backlog_toml.rs:
    1|       |use super::NodeToml;
    2|       |use crate::{block_processing::BoundedBacklogConfig, config::NodeConfig};
    3|       |use serde::{Deserialize, Serialize};
    4|       |
    5|      5|#[derive(Deserialize, Serialize)]
    6|       |pub struct BoundedBacklogToml {
    7|       |    pub enable: Option<bool>,
    8|       |    pub batch_size: Option<usize>,
    9|       |    pub scan_rate: Option<usize>,
   10|       |}
   11|       |
   12|       |impl BoundedBacklogConfig {
   13|      2|    pub(crate) fn merge_toml(&mut self, toml: &NodeToml) {
   14|      2|        if let Some(max) = toml.max_backlog {
                                  ^1
   15|      1|            self.max_backlog = max;
   16|      1|        }
   17|      2|        let Some(backlog_toml) = &toml.bounded_backlog else {
                               ^1
   18|      1|            return;
   19|       |        };
   20|       |
   21|      1|        if let Some(size) = backlog_toml.batch_size {
   22|      1|            self.batch_size = size;
   23|      1|        }
                       ^0
   24|      1|        if let Some(rate) = backlog_toml.scan_rate {
   25|      1|            self.scan_rate = rate;
   26|      1|        }
                       ^0
   27|      2|    }
   28|       |}
   29|       |
   30|       |impl From<&NodeConfig> for BoundedBacklogToml {
   31|      1|    fn from(value: &NodeConfig) -> Self {
   32|      1|        Self {
   33|      1|            enable: Some(value.enable_bounded_backlog),
   34|      1|            batch_size: Some(value.bounded_backlog.batch_size),
   35|      1|            scan_rate: Some(value.bounded_backlog.scan_rate),
   36|      1|        }
   37|      1|    }
   38|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/daemon_toml.rs:
    1|       |use super::{NodeRpcToml, NodeToml, OpenclToml};
    2|       |use crate::config::DaemonConfig;
    3|       |use serde::{Deserialize, Serialize};
    4|       |
    5|      5|#[derive(Deserialize, Serialize)]
    6|       |pub struct DaemonToml {
    7|       |    pub node: Option<NodeToml>,
    8|       |    pub opencl: Option<OpenclToml>,
    9|       |    pub rpc: Option<NodeRpcToml>,
   10|       |}
   11|       |
   12|       |impl DaemonConfig {
   13|      2|    pub fn merge_toml(&mut self, toml: &DaemonToml) {
   14|      2|        if let Some(node_toml) = &toml.node {
                                  ^1
   15|      1|            self.node.merge_toml(node_toml);
   16|      1|        }
   17|      2|        if let Some(opencl) = &toml.opencl {
                                  ^1
   18|      1|            if let Some(enable) = opencl.enable {
   19|      1|                self.opencl_enable = enable;
   20|      1|            }
                           ^0
   21|      1|            self.opencl.merge_toml(opencl);
   22|      1|        }
   23|      2|        if let Some(rpc) = &toml.rpc {
                                  ^1
   24|      1|            if let Some(enable) = rpc.enable {
   25|      1|                self.rpc_enable = enable;
   26|      1|            }
                           ^0
   27|      1|            self.rpc.merge_toml(rpc);
   28|      1|        }
   29|      2|    }
   30|       |}
   31|       |
   32|       |impl From<&DaemonConfig> for DaemonToml {
   33|      0|    fn from(config: &DaemonConfig) -> Self {
   34|      0|        Self {
   35|      0|            node: Some((&config.node).into()),
   36|      0|            rpc: Some(config.into()),
   37|      0|            opencl: Some(config.into()),
   38|      0|        }
   39|      0|    }
   40|       |}
   41|       |
   42|       |impl From<&DaemonConfig> for NodeRpcToml {
   43|      0|    fn from(config: &DaemonConfig) -> Self {
   44|      0|        Self {
   45|      0|            enable: Some(config.rpc_enable),
   46|      0|            enable_sign_hash: Some(config.rpc.enable_sign_hash),
   47|      0|            child_process: Some((&config.rpc.child_process).into()),
   48|      0|        }
   49|      0|    }
   50|       |}
   51|       |
   52|       |impl From<&DaemonConfig> for OpenclToml {
   53|      0|    fn from(config: &DaemonConfig) -> Self {
   54|      0|        Self {
   55|      0|            enable: Some(config.opencl_enable),
   56|      0|            platform: Some(config.opencl.platform),
   57|      0|            device: Some(config.opencl.device),
   58|      0|            threads: Some(config.opencl.threads),
   59|      0|        }
   60|      0|    }
   61|       |}
   62|       |
   63|       |#[cfg(test)]
   64|       |mod tests {
   65|       |    use crate::config::{DaemonConfig, DaemonToml};
   66|       |    use rsnano_core::Networks;
   67|       |    use std::path::PathBuf;
   68|       |
   69|       |    static CUSTOM_TOML_STR: &str = r#"[node]
   70|       |        allow_local_peers = false
   71|       |        backup_before_upgrade = true
   72|       |        bandwidth_limit = 999
   73|       |        bandwidth_limit_burst_ratio = 999.9
   74|       |        bootstrap_bandwidth_limit = 999
   75|       |        bootstrap_bandwidth_burst_ratio = 999.9
   76|       |        block_processor_batch_max_time = 999
   77|       |        bootstrap_connections = 999
   78|       |        bootstrap_connections_max = 999
   79|       |        bootstrap_initiator_threads = 999
   80|       |        bootstrap_serving_threads = 999
   81|       |        bootstrap_frontier_request_count = 9999
   82|       |        bootstrap_fraction_numerator = 999
   83|       |        confirming_set_batch_time = 999
   84|       |        enable_voting = true
   85|       |        external_address = "0:0:0:0:0:ffff:7f01:101"
   86|       |        external_port = 999
   87|       |        io_threads = 999
   88|       |        max_queued_requests = 999
   89|       |        network_threads = 999
   90|       |        background_threads = 999
   91|       |        online_weight_minimum = "999"
   92|       |        representative_vote_weight_minimum = "999"
   93|       |        rep_crawler_weight_minimum = "999"
   94|       |        password_fanout = 999
   95|       |        peering_port = 999
   96|       |        pow_sleep_interval = 999
   97|       |        preconfigured_peers = ["dev.org"]
   98|       |        preconfigured_representatives = ["nano_3arg3asgtigae3xckabaaewkx3bzsh7nwz7jkmjos79ihyaxwphhm6qgjps4"]
   99|       |        receive_minimum = "999"
  100|       |        signature_checker_threads = 999
  101|       |        tcp_io_timeout = 999
  102|       |        unchecked_cutoff_time = 999
  103|       |        use_memory_pools = false
  104|       |        vote_generator_delay = 999
  105|       |        vote_minimum = "999"
  106|       |        work_peers = ["dev.org:999"]
  107|       |        work_threads = 999
  108|       |        max_work_generate_multiplier = 999
  109|       |        request_aggregator_threads = 999
  110|       |        max_unchecked_blocks = 999
  111|       |        max_backlog = 999
  112|       |        frontiers_confirmation = "always"
  113|       |
  114|       |        [node.backlog_scan]
  115|       |        enable = false
  116|       |        batch_size = 999
  117|       |        rate_limit = 999
  118|       |
  119|       |        [node.bounded_backlog]
  120|       |        enable = false
  121|       |        batch_size = 999
  122|       |        max_queued_notifications = 999
  123|       |        scan_rate = 999
  124|       |
  125|       |        [node.block_processor]
  126|       |        max_peer_queue = 999
  127|       |        max_system_queue = 999
  128|       |        priority_live = 999
  129|       |        priority_bootstrap = 999
  130|       |        priority_local = 999
  131|       |
  132|       |        [node.active_elections]
  133|       |        size = 999
  134|       |        hinted_limit_percentage = 90
  135|       |        optimistic_limit_percentage = 90
  136|       |        confirmation_history_size = 999
  137|       |        confirmation_cache = 999
  138|       |
  139|       |        [node.diagnostics.txn_tracking]
  140|       |        enable = true
  141|       |        ignore_writes_below_block_processor_max_time = false
  142|       |        min_read_txn_time = 999
  143|       |        min_write_txn_time = 999
  144|       |
  145|       |        [node.httpcallback]
  146|       |        address = "dev.org"
  147|       |        port = 999
  148|       |        target = "/dev"
  149|       |
  150|       |        [node.priority_bucket]
  151|       |        max_blocks = 999
  152|       |        max_elections = 999
  153|       |        reserved_elections = 999
  154|       |
  155|       |        [node.rep_crawler]
  156|       |        query_timeout = 999
  157|       |
  158|       |        [node.monitor]
  159|       |        enable = false
  160|       |        interval = 999
  161|       |
  162|       |        [node.statistics]
  163|       |        max_samples = 999
  164|       |
  165|       |        [node.statistics.log]
  166|       |        filename_counters = "devcounters.stat"
  167|       |        filename_samples = "devsamples.stat"
  168|       |        headers = false
  169|       |        interval_counters = 999
  170|       |        interval_samples = 999
  171|       |        rotation_count = 999
  172|       |
  173|       |        [node.websocket]
  174|       |        address = "0:0:0:0:0:ffff:7f01:101"
  175|       |        enable = true
  176|       |        port = 999
  177|       |
  178|       |        [node.lmdb]
  179|       |        sync = "nosync_safe"
  180|       |        max_databases = 999
  181|       |        map_size = 999
  182|       |
  183|       |        [node.optimistic_scheduler]
  184|       |        enable = false
  185|       |        gap_threshold = 999
  186|       |        max_size = 999
  187|       |
  188|       |        [node.hinted_scheduler]
  189|       |        enable = false
  190|       |        hinting_threshold = 99
  191|       |        check_interval = 999
  192|       |        block_cooldown = 999
  193|       |        vacancy_threshold = 99
  194|       |
  195|       |        [node.experimental]
  196|       |        secondary_work_peers = ["dev.org:998"]
  197|       |        max_pruning_age = 999
  198|       |        max_pruning_depth = 999
  199|       |
  200|       |        [node.vote_cache]
  201|       |        age_cutoff = 999
  202|       |        max_size = 999
  203|       |        max_voters = 999
  204|       |
  205|       |        [node.vote_processor]
  206|       |        max_pr_queue = 999
  207|       |        max_non_pr_queue = 999
  208|       |        pr_priority = 999
  209|       |        threads = 999
  210|       |        batch_size = 999
  211|       |
  212|       |        [node.bootstrap]
  213|       |        enable = false
  214|       |        enable_database_scan = false
  215|       |        enable_dependency_walker = false
  216|       |        block_processor_threshold = 999
  217|       |        database_rate_limit = 999
  218|       |        max_pull_count = 999
  219|       |        channel_limit = 999
  220|       |        rate_limit = 999
  221|       |        throttle_coefficient = 999
  222|       |        throttle_wait = 999
  223|       |        request_timeout = 999
  224|       |        max_requests = 999
  225|       |
  226|       |        [node.bootstrap.account_sets]
  227|       |        blocking_max = 999
  228|       |        consideration_count = 999
  229|       |        cooldown = 999
  230|       |        priorities_max = 999
  231|       |
  232|       |        [node.bootstrap_server]
  233|       |        max_queue = 999
  234|       |        threads = 999
  235|       |        batch_size = 999
  236|       |
  237|       |        [node.request_aggregator]
  238|       |        max_queue = 999
  239|       |        threads = 999
  240|       |        batch_size = 999
  241|       |
  242|       |        [node.message_processor]
  243|       |        threads = 999
  244|       |        max_queue = 999
  245|       |
  246|       |        [node.tcp]
  247|       |        max_inbound_connections = 999
  248|       |	    max_outbound_connections = 999
  249|       |	    max_attempts = 999
  250|       |	    max_attempts_per_ip = 999
  251|       |	    connect_timeout = 999
  252|       |	    handshake_timeout = 999
  253|       |	    io_timeout = 999
  254|       |
  255|       |        [opencl]
  256|       |        device = 999
  257|       |        enable = true
  258|       |        platform = 999
  259|       |        threads = 999
  260|       |
  261|       |        [rpc]
  262|       |        enable = true
  263|       |        enable_sign_hash = true
  264|       |
  265|       |        [rpc.child_process]
  266|       |        enable = true
  267|       |        rpc_path = "/dev/nano_rpc""#;
  268|       |
  269|       |    #[test]
  270|      1|    fn deserialize_no_defaults() {
  271|      1|        let daemon_toml: DaemonToml =
  272|      1|            toml::from_str(CUSTOM_TOML_STR).expect("Failed to deserialize TOML");
  273|      1|
  274|      1|        let mut deserialized = create_default_daemon_config();
  275|      1|        deserialized.merge_toml(&daemon_toml);
  276|      1|
  277|      1|        let default_cfg = create_default_daemon_config();
  278|      1|
  279|      1|        // Node section
  280|      1|        assert_ne!(
  281|      1|            deserialized.node.allow_local_peers,
  282|      1|            default_cfg.node.allow_local_peers
  283|      1|        );
  284|      1|        assert_ne!(
  285|      1|            deserialized.node.backup_before_upgrade,
  286|      1|            default_cfg.node.backup_before_upgrade
  287|      1|        );
  288|      1|        assert_ne!(
  289|      1|            deserialized.node.bandwidth_limit,
  290|      1|            default_cfg.node.bandwidth_limit
  291|      1|        );
  292|      1|        assert_ne!(
  293|      1|            deserialized.node.bandwidth_limit_burst_ratio,
  294|      1|            default_cfg.node.bandwidth_limit_burst_ratio
  295|      1|        );
  296|      1|        assert_ne!(
  297|      1|            deserialized.node.bootstrap_bandwidth_limit,
  298|      1|            default_cfg.node.bootstrap_bandwidth_limit
  299|      1|        );
  300|      1|        assert_ne!(
  301|      1|            deserialized.node.bootstrap_bandwidth_burst_ratio,
  302|      1|            default_cfg.node.bootstrap_bandwidth_burst_ratio
  303|      1|        );
  304|      1|        assert_ne!(
  305|      1|            deserialized.node.block_processor_batch_max_time_ms,
  306|      1|            default_cfg.node.block_processor_batch_max_time_ms
  307|      1|        );
  308|      1|        assert_ne!(
  309|      1|            deserialized.node.bootstrap_initiator_threads,
  310|      1|            default_cfg.node.bootstrap_initiator_threads
  311|      1|        );
  312|      1|        assert_ne!(
  313|      1|            deserialized.node.bootstrap_serving_threads,
  314|      1|            default_cfg.node.bootstrap_serving_threads
  315|      1|        );
  316|      1|        assert_ne!(
  317|      1|            deserialized.node.bootstrap_fraction_numerator,
  318|      1|            default_cfg.node.bootstrap_fraction_numerator
  319|      1|        );
  320|      1|        assert_ne!(
  321|      1|            deserialized.node.confirming_set_batch_time,
  322|      1|            default_cfg.node.confirming_set_batch_time
  323|      1|        );
  324|      1|        assert_ne!(
  325|      1|            deserialized.node.enable_voting,
  326|      1|            default_cfg.node.enable_voting
  327|      1|        );
  328|      1|        assert_ne!(
  329|      1|            deserialized.node.external_address,
  330|      1|            default_cfg.node.external_address
  331|      1|        );
  332|      1|        assert_ne!(
  333|      1|            deserialized.node.external_port,
  334|      1|            default_cfg.node.external_port
  335|      1|        );
  336|      1|        assert_ne!(deserialized.node.io_threads, default_cfg.node.io_threads);
  337|      1|        assert_ne!(
  338|      1|            deserialized.node.max_queued_requests,
  339|      1|            default_cfg.node.max_queued_requests
  340|      1|        );
  341|      1|        assert_ne!(
  342|      1|            deserialized.node.network_threads,
  343|      1|            default_cfg.node.network_threads
  344|      1|        );
  345|      1|        assert_ne!(
  346|      1|            deserialized.node.background_threads,
  347|      1|            default_cfg.node.background_threads
  348|      1|        );
  349|      1|        assert_ne!(
  350|      1|            deserialized.node.online_weight_minimum,
  351|      1|            default_cfg.node.online_weight_minimum
  352|      1|        );
  353|      1|        assert_ne!(
  354|      1|            deserialized.node.representative_vote_weight_minimum,
  355|      1|            default_cfg.node.representative_vote_weight_minimum
  356|      1|        );
  357|      1|        assert_ne!(
  358|      1|            deserialized.node.rep_crawler_weight_minimum,
  359|      1|            default_cfg.node.rep_crawler_weight_minimum
  360|      1|        );
  361|      1|        assert_ne!(
  362|      1|            deserialized.node.password_fanout,
  363|      1|            default_cfg.node.password_fanout
  364|      1|        );
  365|      1|        assert_ne!(
  366|      1|            deserialized.node.peering_port,
  367|      1|            default_cfg.node.peering_port
  368|      1|        );
  369|      1|        assert_ne!(
  370|      1|            deserialized.node.pow_sleep_interval_ns,
  371|      1|            default_cfg.node.pow_sleep_interval_ns
  372|      1|        );
  373|      1|        assert_ne!(
  374|      1|            deserialized.node.preconfigured_peers,
  375|      1|            default_cfg.node.preconfigured_peers
  376|      1|        );
  377|      1|        assert_ne!(
  378|      1|            deserialized.node.preconfigured_representatives,
  379|      1|            default_cfg.node.preconfigured_representatives
  380|      1|        );
  381|      1|        assert_ne!(
  382|      1|            deserialized.node.receive_minimum,
  383|      1|            default_cfg.node.receive_minimum
  384|      1|        );
  385|      1|        assert_ne!(
  386|      1|            deserialized.node.signature_checker_threads,
  387|      1|            default_cfg.node.signature_checker_threads
  388|      1|        );
  389|      1|        assert_ne!(
  390|      1|            deserialized.node.unchecked_cutoff_time_s,
  391|      1|            default_cfg.node.unchecked_cutoff_time_s
  392|      1|        );
  393|      1|        assert_ne!(
  394|      1|            deserialized.node.use_memory_pools,
  395|      1|            default_cfg.node.use_memory_pools
  396|      1|        );
  397|      1|        assert_ne!(
  398|      1|            deserialized.node.vote_generator_delay,
  399|      1|            default_cfg.node.vote_generator_delay
  400|      1|        );
  401|      1|        assert_ne!(
  402|      1|            deserialized.node.vote_minimum,
  403|      1|            default_cfg.node.vote_minimum
  404|      1|        );
  405|      1|        assert_ne!(deserialized.node.work_peers, default_cfg.node.work_peers);
  406|      1|        assert_ne!(
  407|      1|            deserialized.node.work_threads,
  408|      1|            default_cfg.node.work_threads
  409|      1|        );
  410|      1|        assert_ne!(
  411|      1|            deserialized.node.max_work_generate_multiplier,
  412|      1|            default_cfg.node.max_work_generate_multiplier
  413|      1|        );
  414|      1|        assert_ne!(
  415|      1|            deserialized.node.request_aggregator_threads,
  416|      1|            default_cfg.node.request_aggregator_threads
  417|      1|        );
  418|      1|        assert_ne!(
  419|      1|            deserialized.node.max_unchecked_blocks,
  420|      1|            default_cfg.node.max_unchecked_blocks
  421|      1|        );
  422|      1|        assert_ne!(
  423|      1|            deserialized.node.backlog_scan.enabled,
  424|      1|            default_cfg.node.backlog_scan.enabled
  425|      1|        );
  426|      1|        assert_ne!(
  427|      1|            deserialized.node.backlog_scan.rate_limit,
  428|      1|            default_cfg.node.backlog_scan.rate_limit
  429|      1|        );
  430|       |
  431|       |        // Block Processor section
  432|      1|        assert_ne!(
  433|      1|            deserialized.node.block_processor.max_peer_queue,
  434|      1|            default_cfg.node.block_processor.max_peer_queue
  435|      1|        );
  436|      1|        assert_ne!(
  437|      1|            deserialized.node.block_processor.max_system_queue,
  438|      1|            default_cfg.node.block_processor.max_system_queue
  439|      1|        );
  440|      1|        assert_ne!(
  441|      1|            deserialized.node.block_processor.priority_live,
  442|      1|            default_cfg.node.block_processor.priority_live
  443|      1|        );
  444|      1|        assert_ne!(
  445|      1|            deserialized.node.block_processor.priority_bootstrap,
  446|      1|            default_cfg.node.block_processor.priority_bootstrap
  447|      1|        );
  448|      1|        assert_ne!(
  449|      1|            deserialized.node.block_processor.priority_local,
  450|      1|            default_cfg.node.block_processor.priority_local
  451|      1|        );
  452|       |
  453|       |        // Active Elections section
  454|      1|        assert_ne!(
  455|      1|            deserialized.node.active_elections.size,
  456|      1|            default_cfg.node.active_elections.size
  457|      1|        );
  458|      1|        assert_ne!(
  459|      1|            deserialized.node.active_elections.hinted_limit_percentage,
  460|      1|            default_cfg.node.active_elections.hinted_limit_percentage
  461|      1|        );
  462|      1|        assert_ne!(
  463|      1|            deserialized
  464|      1|                .node
  465|      1|                .active_elections
  466|      1|                .optimistic_limit_percentage,
  467|      1|            default_cfg
  468|      1|                .node
  469|      1|                .active_elections
  470|      1|                .optimistic_limit_percentage
  471|      1|        );
  472|      1|        assert_ne!(
  473|      1|            deserialized.node.active_elections.confirmation_history_size,
  474|      1|            default_cfg.node.active_elections.confirmation_history_size
  475|      1|        );
  476|      1|        assert_ne!(
  477|      1|            deserialized.node.active_elections.confirmation_cache,
  478|      1|            default_cfg.node.active_elections.confirmation_cache
  479|      1|        );
  480|       |
  481|       |        // Diagnostics section
  482|      1|        assert_ne!(
  483|      1|            deserialized.node.diagnostics_config.txn_tracking.enable,
  484|      1|            default_cfg.node.diagnostics_config.txn_tracking.enable
  485|      1|        );
  486|      1|        assert_ne!(
  487|      1|            deserialized
  488|      1|                .node
  489|      1|                .diagnostics_config
  490|      1|                .txn_tracking
  491|      1|                .ignore_writes_below_block_processor_max_time,
  492|      1|            default_cfg
  493|      1|                .node
  494|      1|                .diagnostics_config
  495|      1|                .txn_tracking
  496|      1|                .ignore_writes_below_block_processor_max_time
  497|      1|        );
  498|      1|        assert_ne!(
  499|      1|            deserialized
  500|      1|                .node
  501|      1|                .diagnostics_config
  502|      1|                .txn_tracking
  503|      1|                .min_read_txn_time_ms,
  504|      1|            default_cfg
  505|      1|                .node
  506|      1|                .diagnostics_config
  507|      1|                .txn_tracking
  508|      1|                .min_read_txn_time_ms
  509|      1|        );
  510|      1|        assert_ne!(
  511|      1|            deserialized
  512|      1|                .node
  513|      1|                .diagnostics_config
  514|      1|                .txn_tracking
  515|      1|                .min_write_txn_time_ms,
  516|      1|            default_cfg
  517|      1|                .node
  518|      1|                .diagnostics_config
  519|      1|                .txn_tracking
  520|      1|                .min_write_txn_time_ms
  521|      1|        );
  522|       |
  523|       |        // HTTP Callback section
  524|      1|        assert_ne!(
  525|      1|            deserialized.node.callback_address,
  526|      1|            default_cfg.node.callback_address
  527|      1|        );
  528|      1|        assert_ne!(
  529|      1|            deserialized.node.callback_port,
  530|      1|            default_cfg.node.callback_port
  531|      1|        );
  532|      1|        assert_ne!(
  533|      1|            deserialized.node.callback_target,
  534|      1|            default_cfg.node.callback_target
  535|      1|        );
  536|       |
  537|       |        // Priority Bucket section
  538|      1|        assert_ne!(
  539|      1|            deserialized.node.priority_bucket.max_blocks,
  540|      1|            default_cfg.node.priority_bucket.max_blocks
  541|      1|        );
  542|      1|        assert_ne!(
  543|      1|            deserialized.node.priority_bucket.max_elections,
  544|      1|            default_cfg.node.priority_bucket.max_elections
  545|      1|        );
  546|      1|        assert_ne!(
  547|      1|            deserialized.node.priority_bucket.reserved_elections,
  548|      1|            default_cfg.node.priority_bucket.reserved_elections
  549|      1|        );
  550|       |
  551|       |        // Rep Crawler section
  552|      1|        assert_ne!(
  553|      1|            deserialized.node.rep_crawler_query_timeout,
  554|      1|            default_cfg.node.rep_crawler_query_timeout
  555|      1|        );
  556|       |
  557|       |        // Monitor section
  558|      1|        assert_ne!(
  559|      1|            deserialized.node.enable_monitor,
  560|      1|            default_cfg.node.enable_monitor
  561|      1|        );
  562|      1|        assert_ne!(
  563|      1|            deserialized.node.monitor.interval,
  564|      1|            default_cfg.node.monitor.interval
  565|      1|        );
  566|       |
  567|       |        // Statistics section
  568|      1|        assert_ne!(
  569|      1|            deserialized.node.stat_config.max_samples,
  570|      1|            default_cfg.node.stat_config.max_samples
  571|      1|        );
  572|       |
  573|       |        // Statistics Log section
  574|      1|        assert_ne!(
  575|      1|            deserialized.node.stat_config.log_counters_filename,
  576|      1|            default_cfg.node.stat_config.log_counters_filename
  577|      1|        );
  578|      1|        assert_ne!(
  579|      1|            deserialized.node.stat_config.log_samples_filename,
  580|      1|            default_cfg.node.stat_config.log_samples_filename
  581|      1|        );
  582|      1|        assert_ne!(
  583|      1|            deserialized.node.stat_config.log_headers,
  584|      1|            default_cfg.node.stat_config.log_headers
  585|      1|        );
  586|      1|        assert_ne!(
  587|      1|            deserialized.node.stat_config.log_counters_interval,
  588|      1|            default_cfg.node.stat_config.log_counters_interval
  589|      1|        );
  590|      1|        assert_ne!(
  591|      1|            deserialized.node.stat_config.log_samples_interval,
  592|      1|            default_cfg.node.stat_config.log_samples_interval
  593|      1|        );
  594|      1|        assert_ne!(
  595|      1|            deserialized.node.stat_config.log_rotation_count,
  596|      1|            default_cfg.node.stat_config.log_rotation_count
  597|      1|        );
  598|       |
  599|       |        // WebSocket section
  600|      1|        assert_ne!(
  601|      1|            deserialized.node.websocket_config.address,
  602|      1|            default_cfg.node.websocket_config.address
  603|      1|        );
  604|      1|        assert_ne!(
  605|      1|            deserialized.node.websocket_config.enabled,
  606|      1|            default_cfg.node.websocket_config.enabled
  607|      1|        );
  608|      1|        assert_ne!(
  609|      1|            deserialized.node.websocket_config.port,
  610|      1|            default_cfg.node.websocket_config.port
  611|      1|        );
  612|       |
  613|       |        // LMDB section
  614|      1|        assert_ne!(
  615|      1|            deserialized.node.lmdb_config.sync,
  616|      1|            default_cfg.node.lmdb_config.sync
  617|      1|        );
  618|      1|        assert_ne!(
  619|      1|            deserialized.node.lmdb_config.max_databases,
  620|      1|            default_cfg.node.lmdb_config.max_databases
  621|      1|        );
  622|      1|        assert_ne!(
  623|      1|            deserialized.node.lmdb_config.map_size,
  624|      1|            default_cfg.node.lmdb_config.map_size
  625|      1|        );
  626|       |
  627|       |        // Optimistic Scheduler section
  628|      1|        assert_ne!(
  629|      1|            deserialized.node.enable_optimistic_scheduler,
  630|      1|            default_cfg.node.enable_optimistic_scheduler
  631|      1|        );
  632|      1|        assert_ne!(
  633|      1|            deserialized.node.optimistic_scheduler.gap_threshold,
  634|      1|            default_cfg.node.optimistic_scheduler.gap_threshold
  635|      1|        );
  636|      1|        assert_ne!(
  637|      1|            deserialized.node.optimistic_scheduler.max_size,
  638|      1|            default_cfg.node.optimistic_scheduler.max_size
  639|      1|        );
  640|       |
  641|       |        // Hinted Scheduler section
  642|      1|        assert_ne!(
  643|      1|            deserialized.node.enable_hinted_scheduler,
  644|      1|            default_cfg.node.enable_hinted_scheduler
  645|      1|        );
  646|      1|        assert_ne!(
  647|      1|            deserialized.node.hinted_scheduler.hinting_threshold_percent,
  648|      1|            default_cfg.node.hinted_scheduler.hinting_threshold_percent
  649|      1|        );
  650|      1|        assert_ne!(
  651|      1|            deserialized.node.hinted_scheduler.check_interval,
  652|      1|            default_cfg.node.hinted_scheduler.check_interval
  653|      1|        );
  654|      1|        assert_ne!(
  655|      1|            deserialized.node.hinted_scheduler.block_cooldown,
  656|      1|            default_cfg.node.hinted_scheduler.block_cooldown
  657|      1|        );
  658|      1|        assert_ne!(
  659|      1|            deserialized.node.hinted_scheduler.vacancy_threshold_percent,
  660|      1|            default_cfg.node.hinted_scheduler.vacancy_threshold_percent
  661|      1|        );
  662|       |
  663|       |        // Vote Cache section
  664|      1|        assert_ne!(
  665|      1|            deserialized.node.vote_cache.age_cutoff,
  666|      1|            default_cfg.node.vote_cache.age_cutoff
  667|      1|        );
  668|      1|        assert_ne!(
  669|      1|            deserialized.node.vote_cache.max_size,
  670|      1|            default_cfg.node.vote_cache.max_size
  671|      1|        );
  672|      1|        assert_ne!(
  673|      1|            deserialized.node.vote_cache.max_voters,
  674|      1|            default_cfg.node.vote_cache.max_voters
  675|      1|        );
  676|       |
  677|       |        // Vote Processor section
  678|      1|        assert_ne!(
  679|      1|            deserialized.node.vote_processor.max_pr_queue,
  680|      1|            default_cfg.node.vote_processor.max_pr_queue
  681|      1|        );
  682|      1|        assert_ne!(
  683|      1|            deserialized.node.vote_processor.max_non_pr_queue,
  684|      1|            default_cfg.node.vote_processor.max_non_pr_queue
  685|      1|        );
  686|      1|        assert_ne!(
  687|      1|            deserialized.node.vote_processor.pr_priority,
  688|      1|            default_cfg.node.vote_processor.pr_priority
  689|      1|        );
  690|      1|        assert_ne!(
  691|      1|            deserialized.node.vote_processor.threads,
  692|      1|            default_cfg.node.vote_processor.threads
  693|      1|        );
  694|      1|        assert_ne!(
  695|      1|            deserialized.node.vote_processor.batch_size,
  696|      1|            default_cfg.node.vote_processor.batch_size
  697|      1|        );
  698|       |
  699|       |        // Bootstrap Ascending section
  700|      1|        assert_ne!(
  701|      1|            deserialized.node.bootstrap.block_processor_theshold,
  702|      1|            default_cfg.node.bootstrap.block_processor_theshold
  703|      1|        );
  704|      1|        assert_ne!(
  705|      1|            deserialized.node.bootstrap.database_rate_limit,
  706|      1|            default_cfg.node.bootstrap.database_rate_limit
  707|      1|        );
  708|      1|        assert_ne!(
  709|      1|            deserialized.node.bootstrap.max_pull_count,
  710|      1|            default_cfg.node.bootstrap.max_pull_count
  711|      1|        );
  712|      1|        assert_ne!(
  713|      1|            deserialized.node.bootstrap.channel_limit,
  714|      1|            default_cfg.node.bootstrap.channel_limit
  715|      1|        );
  716|      1|        assert_ne!(
  717|      1|            deserialized.node.bootstrap.rate_limit,
  718|      1|            default_cfg.node.bootstrap.rate_limit
  719|      1|        );
  720|      1|        assert_ne!(
  721|      1|            deserialized.node.bootstrap.throttle_coefficient,
  722|      1|            default_cfg.node.bootstrap.throttle_coefficient
  723|      1|        );
  724|      1|        assert_ne!(
  725|      1|            deserialized.node.bootstrap.throttle_wait,
  726|      1|            default_cfg.node.bootstrap.throttle_wait
  727|      1|        );
  728|      1|        assert_ne!(
  729|      1|            deserialized.node.bootstrap.request_timeout,
  730|      1|            default_cfg.node.bootstrap.request_timeout
  731|      1|        );
  732|       |
  733|       |        // Bootstrap Ascending Account Sets section
  734|      1|        assert_ne!(
  735|      1|            deserialized.node.bootstrap.account_sets.blocking_max,
  736|      1|            default_cfg.node.bootstrap.account_sets.blocking_max
  737|      1|        );
  738|      1|        assert_ne!(
  739|      1|            deserialized.node.bootstrap.account_sets.consideration_count,
  740|      1|            default_cfg.node.bootstrap.account_sets.consideration_count
  741|      1|        );
  742|      1|        assert_ne!(
  743|      1|            deserialized.node.bootstrap.account_sets.cooldown,
  744|      1|            default_cfg.node.bootstrap.account_sets.cooldown
  745|      1|        );
  746|      1|        assert_ne!(
  747|      1|            deserialized.node.bootstrap.account_sets.priorities_max,
  748|      1|            default_cfg.node.bootstrap.account_sets.priorities_max
  749|      1|        );
  750|       |
  751|       |        // Bootstrap Server section
  752|      1|        assert_ne!(
  753|      1|            deserialized.node.bootstrap_responder.max_queue,
  754|      1|            default_cfg.node.bootstrap_responder.max_queue
  755|      1|        );
  756|      1|        assert_ne!(
  757|      1|            deserialized.node.bootstrap_responder.threads,
  758|      1|            default_cfg.node.bootstrap_responder.threads
  759|      1|        );
  760|      1|        assert_ne!(
  761|      1|            deserialized.node.bootstrap_responder.batch_size,
  762|      1|            default_cfg.node.bootstrap_responder.batch_size
  763|      1|        );
  764|       |
  765|       |        // Request Aggregator section
  766|      1|        assert_ne!(
  767|      1|            deserialized.node.request_aggregator.max_queue,
  768|      1|            default_cfg.node.request_aggregator.max_queue
  769|      1|        );
  770|      1|        assert_ne!(
  771|      1|            deserialized.node.request_aggregator.threads,
  772|      1|            default_cfg.node.request_aggregator.threads
  773|      1|        );
  774|      1|        assert_ne!(
  775|      1|            deserialized.node.request_aggregator.batch_size,
  776|      1|            default_cfg.node.request_aggregator.batch_size
  777|      1|        );
  778|       |
  779|       |        // Message Processor section
  780|      1|        assert_ne!(
  781|      1|            deserialized.node.message_processor.threads,
  782|      1|            default_cfg.node.message_processor.threads
  783|      1|        );
  784|      1|        assert_ne!(
  785|      1|            deserialized.node.message_processor.max_queue,
  786|      1|            default_cfg.node.message_processor.max_queue
  787|      1|        );
  788|       |
  789|       |        // OpenCL section
  790|      1|        assert_ne!(deserialized.opencl.device, default_cfg.opencl.device);
  791|      1|        assert_ne!(deserialized.opencl_enable, default_cfg.opencl_enable);
  792|      1|        assert_ne!(deserialized.opencl.platform, default_cfg.opencl.platform);
  793|      1|        assert_ne!(deserialized.opencl.threads, default_cfg.opencl.threads);
  794|       |
  795|       |        // RPC section
  796|      1|        assert_ne!(deserialized.rpc_enable, default_cfg.rpc_enable);
  797|      1|        assert_ne!(
  798|      1|            deserialized.rpc.enable_sign_hash,
  799|      1|            default_cfg.rpc.enable_sign_hash
  800|      1|        );
  801|       |
  802|       |        // RPC Child Process section
  803|      1|        assert_ne!(
  804|      1|            deserialized.rpc.child_process.enable,
  805|      1|            default_cfg.rpc.child_process.enable
  806|      1|        );
  807|      1|        assert_ne!(
  808|      1|            deserialized.rpc.child_process.rpc_path,
  809|      1|            default_cfg.rpc.child_process.rpc_path
  810|      1|        );
  811|      1|        assert_ne!(
  812|      1|            deserialized.node.bounded_backlog.max_backlog,
  813|      1|            default_cfg.node.bounded_backlog.max_backlog
  814|      1|        );
  815|      1|        assert_ne!(
  816|      1|            deserialized.node.enable_bounded_backlog,
  817|      1|            default_cfg.node.enable_bounded_backlog
  818|      1|        );
  819|      1|        assert_ne!(
  820|      1|            deserialized.node.bounded_backlog.batch_size,
  821|      1|            default_cfg.node.bounded_backlog.batch_size
  822|      1|        );
  823|      1|        assert_ne!(
  824|      1|            deserialized.node.bounded_backlog.scan_rate,
  825|      1|            default_cfg.node.bounded_backlog.scan_rate
  826|      1|        );
  827|       |
  828|       |        // TCP
  829|      1|        assert_ne!(
  830|      1|            deserialized.node.tcp.max_inbound_connections,
  831|      1|            default_cfg.node.tcp.max_inbound_connections
  832|      1|        );
  833|      1|        assert_ne!(
  834|      1|            deserialized.node.tcp.max_outbound_connections,
  835|      1|            default_cfg.node.tcp.max_outbound_connections
  836|      1|        );
  837|      1|        assert_ne!(
  838|      1|            deserialized.node.tcp.max_attempts,
  839|      1|            default_cfg.node.tcp.max_attempts
  840|      1|        );
  841|      1|        assert_ne!(
  842|      1|            deserialized.node.tcp.max_attempts_per_ip,
  843|      1|            default_cfg.node.tcp.max_attempts_per_ip
  844|      1|        );
  845|      1|        assert_ne!(
  846|      1|            deserialized.node.tcp.connect_timeout,
  847|      1|            default_cfg.node.tcp.connect_timeout
  848|      1|        );
  849|      1|    }
  850|       |
  851|       |    #[test]
  852|      1|    fn deserialize_empty() {
  853|      1|        let toml_str = "";
  854|      1|        let daemon_toml: DaemonToml = toml::from_str(toml_str).expect("Failed to deserialize TOML");
  855|      1|
  856|      1|        let mut deserialized_daemon_config = create_default_daemon_config();
  857|      1|        deserialized_daemon_config.merge_toml(&daemon_toml);
  858|      1|        let default_daemon_config = create_default_daemon_config();
  859|      1|
  860|      1|        assert_eq!(&deserialized_daemon_config, &default_daemon_config);
  861|      1|    }
  862|       |
  863|      4|    fn create_default_daemon_config() -> DaemonConfig {
  864|      4|        let mut config = DaemonConfig::new2(Networks::NanoBetaNetwork, 8);
  865|      4|        config.rpc.child_process.rpc_path = PathBuf::from("/home/foo/nano_rpc");
  866|      4|        config
  867|      4|    }
  868|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/diagnostics_toml.rs:
    1|       |use crate::{config::DiagnosticsConfig, utils::TxnTrackingConfig};
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      2|#[derive(Deserialize, Serialize)]
    5|       |pub struct DiagnosticsToml {
    6|       |    pub txn_tracking: Option<TxnTrackingConfigToml>,
    7|       |}
    8|       |
    9|       |impl Default for DiagnosticsToml {
   10|      0|    fn default() -> Self {
   11|      0|        let config = DiagnosticsConfig::default();
   12|      0|        (&config).into()
   13|      0|    }
   14|       |}
   15|       |
   16|       |impl From<&DiagnosticsConfig> for DiagnosticsToml {
   17|      1|    fn from(config: &DiagnosticsConfig) -> Self {
   18|      1|        Self {
   19|      1|            txn_tracking: Some((&config.txn_tracking).into()),
   20|      1|        }
   21|      1|    }
   22|       |}
   23|       |
   24|       |impl From<&DiagnosticsToml> for DiagnosticsConfig {
   25|      1|    fn from(toml: &DiagnosticsToml) -> Self {
   26|      1|        let mut config = DiagnosticsConfig::default();
   27|      1|        if let Some(txn_tracking_toml) = &toml.txn_tracking {
   28|      1|            config.txn_tracking = txn_tracking_toml.into();
   29|      1|        }
                       ^0
   30|      1|        config
   31|      1|    }
   32|       |}
   33|       |
   34|      5|#[derive(Deserialize, Serialize)]
   35|       |pub struct TxnTrackingConfigToml {
   36|       |    pub enable: Option<bool>,
   37|       |    pub ignore_writes_below_block_processor_max_time: Option<bool>,
   38|       |    pub min_read_txn_time: Option<i64>,
   39|       |    pub min_write_txn_time: Option<i64>,
   40|       |}
   41|       |
   42|       |impl Default for TxnTrackingConfigToml {
   43|      0|    fn default() -> Self {
   44|      0|        let config = TxnTrackingConfig::default();
   45|      0|        (&config).into()
   46|      0|    }
   47|       |}
   48|       |
   49|       |impl From<&TxnTrackingConfigToml> for TxnTrackingConfig {
   50|      1|    fn from(toml: &TxnTrackingConfigToml) -> Self {
   51|      1|        let mut config = TxnTrackingConfig::default();
   52|       |
   53|      1|        if let Some(enable) = toml.enable {
   54|      1|            config.enable = enable;
   55|      1|        }
                       ^0
   56|      1|        if let Some(ignore_writes_below_block_processor_max_time) =
   57|      1|            toml.ignore_writes_below_block_processor_max_time
   58|      1|        {
   59|      1|            config.ignore_writes_below_block_processor_max_time =
   60|      1|                ignore_writes_below_block_processor_max_time;
   61|      1|        }
                       ^0
   62|      1|        if let Some(min_read_txn_time_ms) = toml.min_read_txn_time {
   63|      1|            config.min_read_txn_time_ms = min_read_txn_time_ms;
   64|      1|        }
                       ^0
   65|      1|        if let Some(min_write_txn_time_ms) = toml.min_write_txn_time {
   66|      1|            config.min_write_txn_time_ms = min_write_txn_time_ms;
   67|      1|        }
                       ^0
   68|       |
   69|      1|        config
   70|      1|    }
   71|       |}
   72|       |
   73|       |impl From<&TxnTrackingConfig> for TxnTrackingConfigToml {
   74|      1|    fn from(config: &TxnTrackingConfig) -> Self {
   75|      1|        Self {
   76|      1|            enable: Some(config.enable),
   77|      1|            min_read_txn_time: Some(config.min_read_txn_time_ms),
   78|      1|            min_write_txn_time: Some(config.min_write_txn_time_ms),
   79|      1|            ignore_writes_below_block_processor_max_time: Some(
   80|      1|                config.ignore_writes_below_block_processor_max_time,
   81|      1|            ),
   82|      1|        }
   83|      1|    }
   84|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/experimental_toml.rs:
    1|       |use crate::config::NodeConfig;
    2|       |use rsnano_core::utils::Peer;
    3|       |use serde::{Deserialize, Serialize};
    4|       |use std::str::FromStr;
    5|       |
    6|      4|#[derive(Deserialize, Serialize)]
    7|       |pub struct ExperimentalToml {
    8|       |    pub max_pruning_age: Option<u64>,
    9|       |    pub max_pruning_depth: Option<u64>,
   10|       |    pub secondary_work_peers: Option<Vec<String>>,
   11|       |}
   12|       |
   13|       |impl NodeConfig {
   14|      0|    pub fn merge_experimental_toml(&mut self, toml: &ExperimentalToml) {
   15|      0|        if let Some(max_pruning_age) = toml.max_pruning_age {
   16|      0|            self.max_pruning_age_s = max_pruning_age as i64;
   17|      0|        }
   18|      0|        if let Some(max_pruning_depth) = toml.max_pruning_depth {
   19|      0|            self.max_pruning_depth = max_pruning_depth;
   20|      0|        }
   21|      0|        if let Some(secondary_work_peers) = &toml.secondary_work_peers {
   22|      0|            self.secondary_work_peers = secondary_work_peers
   23|      0|                .iter()
   24|      0|                .map(|string| Peer::from_str(&string).expect("Invalid secondary work peer"))
   25|      0|                .collect();
   26|      0|        }
   27|      0|    }
   28|       |}
   29|       |
   30|       |impl From<&NodeConfig> for ExperimentalToml {
   31|      1|    fn from(config: &NodeConfig) -> Self {
   32|      1|        Self {
   33|      1|            secondary_work_peers: Some(
   34|      1|                config
   35|      1|                    .secondary_work_peers
   36|      1|                    .iter()
   37|      1|                    .map(|peer| peer.to_string())
   38|      1|                    .collect(),
   39|      1|            ),
   40|      1|            max_pruning_age: Some(config.max_pruning_age_s as u64),
   41|      1|            max_pruning_depth: Some(config.max_pruning_depth),
   42|      1|        }
   43|      1|    }
   44|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/hinted_scheduler_toml.rs:
    1|       |use serde::{Deserialize, Serialize};
    2|       |use std::time::Duration;
    3|       |
    4|       |use crate::consensus::HintedSchedulerConfig;
    5|       |
    6|      6|#[derive(Deserialize, Serialize)]
    7|       |pub struct HintedSchedulerToml {
    8|       |    pub enable: Option<bool>,
    9|       |    pub hinting_threshold: Option<u32>,
   10|       |    pub check_interval: Option<u64>,
   11|       |    pub block_cooldown: Option<u64>,
   12|       |    pub vacancy_threshold: Option<u32>,
   13|       |}
   14|       |
   15|       |impl Default for HintedSchedulerToml {
   16|      0|    fn default() -> Self {
   17|      0|        let config = HintedSchedulerConfig::default();
   18|      0|        Self {
   19|      0|            enable: Some(true),
   20|      0|            hinting_threshold: Some(config.hinting_threshold_percent),
   21|      0|            block_cooldown: Some(config.block_cooldown.as_millis() as u64),
   22|      0|            check_interval: Some(config.check_interval.as_millis() as u64),
   23|      0|            vacancy_threshold: Some(config.vacancy_threshold_percent),
   24|      0|        }
   25|      0|    }
   26|       |}
   27|       |
   28|       |impl HintedSchedulerConfig {
   29|      1|    pub fn merge_toml(&mut self, toml: &HintedSchedulerToml) {
   30|      1|        if let Some(block_cooldown) = toml.block_cooldown {
   31|      1|            self.block_cooldown = Duration::from_millis(block_cooldown);
   32|      1|        }
                       ^0
   33|      1|        if let Some(check_interval) = toml.check_interval {
   34|      1|            self.check_interval = Duration::from_millis(check_interval);
   35|      1|        }
                       ^0
   36|      1|        if let Some(hinting_threshold) = toml.hinting_threshold {
   37|      1|            self.hinting_threshold_percent = hinting_threshold;
   38|      1|        }
                       ^0
   39|      1|        if let Some(vacancy_threshold) = toml.vacancy_threshold {
   40|      1|            self.vacancy_threshold_percent = vacancy_threshold;
   41|      1|        }
                       ^0
   42|      1|    }
   43|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/httpcallback_toml.rs:
    1|       |use crate::config::NodeConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct HttpcallbackToml {
    6|       |    pub address: Option<String>,
    7|       |    pub port: Option<u16>,
    8|       |    pub target: Option<String>,
    9|       |}
   10|       |
   11|       |impl From<&NodeConfig> for HttpcallbackToml {
   12|      1|    fn from(config: &NodeConfig) -> Self {
   13|      1|        Self {
   14|      1|            address: Some(config.callback_address.clone()),
   15|      1|            port: Some(config.callback_port.clone()),
   16|      1|            target: Some(config.callback_target.clone()),
   17|      1|        }
   18|      1|    }
   19|       |}
   20|       |
   21|       |impl NodeConfig {
   22|      0|    pub fn merge_http_callback_toml(&mut self, toml: &HttpcallbackToml) {
   23|      0|        if let Some(address) = &toml.address {
   24|      0|            self.callback_address = address.clone();
   25|      0|        }
   26|      0|        if let Some(port) = &toml.port {
   27|      0|            self.callback_port = port.clone();
   28|      0|        }
   29|      0|        if let Some(target) = &toml.target {
   30|      0|            self.callback_target = target.clone();
   31|      0|        }
   32|      0|    }
   33|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/lmdb_toml.rs:
    1|       |use rsnano_store_lmdb::{LmdbConfig, SyncStrategy};
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct LmdbToml {
    6|       |    pub map_size: Option<usize>,
    7|       |    pub max_databases: Option<u32>,
    8|       |    pub sync: Option<String>,
    9|       |}
   10|       |
   11|       |impl Default for LmdbToml {
   12|      0|    fn default() -> Self {
   13|      0|        let config = LmdbConfig::default();
   14|      0|        (&config).into()
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl From<&LmdbToml> for LmdbConfig {
   19|      1|    fn from(toml: &LmdbToml) -> Self {
   20|      1|        let mut config = LmdbConfig::default();
   21|       |
   22|      1|        if let Some(sync) = &toml.sync {
   23|      1|            config.sync = match sync.as_str() {
   24|      1|                "always" => SyncStrategy::Always,
                                          ^0
   25|      1|                "nosync_safe" => SyncStrategy::NosyncSafe,
   26|      0|                "nosync_unsafe" => SyncStrategy::NosyncUnsafe,
   27|      0|                "nosync_unsafe_large_memory" => SyncStrategy::NosyncUnsafeLargeMemory,
   28|      0|                _ => panic!("Invalid sync value"),
   29|       |            }
   30|      0|        }
   31|      1|        if let Some(max_databases) = toml.max_databases {
   32|      1|            config.max_databases = max_databases;
   33|      1|        }
                       ^0
   34|      1|        if let Some(map_size) = toml.map_size {
   35|      1|            config.map_size = map_size;
   36|      1|        }
                       ^0
   37|      1|        config
   38|      1|    }
   39|       |}
   40|       |
   41|       |impl From<&LmdbConfig> for LmdbToml {
   42|      1|    fn from(config: &LmdbConfig) -> Self {
   43|      1|        Self {
   44|      1|            sync: Some(match config.sync {
   45|      1|                SyncStrategy::Always => "always".to_string(),
   46|      0|                SyncStrategy::NosyncSafe => "nosync_safe".to_string(),
   47|      0|                SyncStrategy::NosyncUnsafe => "nosync_unsafe".to_string(),
   48|      0|                SyncStrategy::NosyncUnsafeLargeMemory => "nosync_unsafe_large_memory".to_string(),
   49|       |            }),
   50|      1|            max_databases: Some(config.max_databases),
   51|      1|            map_size: Some(config.map_size),
   52|      1|        }
   53|      1|    }
   54|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/message_processor_toml.rs:
    1|       |use crate::transport::MessageProcessorConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      3|#[derive(Deserialize, Serialize)]
    5|       |pub struct MessageProcessorToml {
    6|       |    pub max_queue: Option<usize>,
    7|       |    pub threads: Option<usize>,
    8|       |}
    9|       |
   10|       |impl MessageProcessorConfig {
   11|      1|    pub fn merge_toml(&mut self, toml: &MessageProcessorToml) {
   12|      1|        if let Some(threads) = toml.threads {
   13|      1|            self.threads = threads;
   14|      1|        }
                       ^0
   15|      1|        if let Some(max_queue) = toml.max_queue {
   16|      1|            self.max_queue = max_queue;
   17|      1|        }
                       ^0
   18|      1|    }
   19|       |}
   20|       |
   21|       |impl From<&MessageProcessorConfig> for MessageProcessorToml {
   22|      1|    fn from(config: &MessageProcessorConfig) -> Self {
   23|      1|        Self {
   24|      1|            threads: Some(config.threads),
   25|      1|            max_queue: Some(config.max_queue),
   26|      1|        }
   27|      1|    }
   28|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/monitor_toml.rs:
    1|       |use crate::config::MonitorConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      3|#[derive(Deserialize, Serialize)]
    5|       |pub struct MonitorToml {
    6|       |    pub enable: Option<bool>,
    7|       |    pub interval: Option<u64>,
    8|       |}
    9|       |
   10|       |impl Default for MonitorToml {
   11|      0|    fn default() -> Self {
   12|      0|        let config = MonitorConfig::default();
   13|      0|        Self {
   14|      0|            enable: Some(true),
   15|      0|            interval: Some(config.interval.as_secs()),
   16|      0|        }
   17|      0|    }
   18|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/node_rpc_toml.rs:
    1|       |use crate::config::{NodeRpcConfig, RpcChildProcessConfig};
    2|       |use serde::{Deserialize, Serialize};
    3|       |use std::path::PathBuf;
    4|       |
    5|      3|#[derive(Deserialize, Serialize)]
    6|       |pub struct RpcChildProcessToml {
    7|       |    pub enable: Option<bool>,
    8|       |    pub rpc_path: Option<PathBuf>,
    9|       |}
   10|       |
   11|       |impl RpcChildProcessToml {
   12|      0|    pub fn new() -> Self {
   13|      0|        let config = RpcChildProcessConfig::new();
   14|      0|        Self {
   15|      0|            enable: Some(config.enable),
   16|      0|            rpc_path: Some(config.rpc_path),
   17|      0|        }
   18|      0|    }
   19|       |}
   20|       |
   21|       |impl From<&RpcChildProcessConfig> for RpcChildProcessToml {
   22|      0|    fn from(config: &RpcChildProcessConfig) -> Self {
   23|      0|        Self {
   24|      0|            enable: Some(config.enable),
   25|      0|            rpc_path: Some(config.rpc_path.clone()),
   26|      0|        }
   27|      0|    }
   28|       |}
   29|       |
   30|       |impl From<&RpcChildProcessToml> for RpcChildProcessConfig {
   31|      1|    fn from(toml: &RpcChildProcessToml) -> Self {
   32|      1|        let mut config = RpcChildProcessConfig::new();
   33|      1|        if let Some(enable) = toml.enable {
   34|      1|            config.enable = enable;
   35|      1|        }
                       ^0
   36|      1|        if let Some(rpc_path) = &toml.rpc_path {
   37|      1|            config.rpc_path = rpc_path.clone();
   38|      1|        }
                       ^0
   39|      1|        config
   40|      1|    }
   41|       |}
   42|       |
   43|      4|#[derive(Deserialize, Serialize)]
   44|       |pub struct NodeRpcToml {
   45|       |    pub enable: Option<bool>,
   46|       |    pub enable_sign_hash: Option<bool>,
   47|       |    pub child_process: Option<RpcChildProcessToml>,
   48|       |}
   49|       |
   50|       |impl NodeRpcConfig {
   51|      1|    pub fn merge_toml(&mut self, toml: &NodeRpcToml) {
   52|      1|        if let Some(enable_sign_hash) = toml.enable_sign_hash {
   53|      1|            self.enable_sign_hash = enable_sign_hash;
   54|      1|        }
                       ^0
   55|      1|        if let Some(child_process) = &toml.child_process {
   56|      1|            self.child_process = child_process.into();
   57|      1|        }
                       ^0
   58|      1|    }
   59|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/node_toml.rs:
    1|       |use super::*;
    2|       |use crate::config::NodeConfig;
    3|       |use bounded_backlog_toml::BoundedBacklogToml;
    4|       |use rsnano_core::{utils::Peer, Account, Amount};
    5|       |use serde::{Deserialize, Serialize};
    6|       |use std::{str::FromStr, time::Duration};
    7|       |use tcp_toml::TcpToml;
    8|       |
    9|     66|#[derive(Serialize, Deserialize, Default)]
   10|       |pub struct NodeToml {
   11|       |    pub allow_local_peers: Option<bool>,
   12|       |    pub background_threads: Option<u32>,
   13|       |    pub backup_before_upgrade: Option<bool>,
   14|       |    pub bandwidth_limit: Option<usize>,
   15|       |    pub bandwidth_limit_burst_ratio: Option<f64>,
   16|       |    pub max_peers_per_ip: Option<u16>,
   17|       |    pub max_peers_per_subnetwork: Option<u16>,
   18|       |    pub block_processor_batch_max_time: Option<i64>,
   19|       |    pub bootstrap_bandwidth_burst_ratio: Option<f64>,
   20|       |    pub bootstrap_bandwidth_limit: Option<usize>,
   21|       |    pub bootstrap_fraction_numerator: Option<u32>,
   22|       |    pub bootstrap_initiator_threads: Option<u32>,
   23|       |    pub bootstrap_serving_threads: Option<u32>,
   24|       |    pub confirming_set_batch_time: Option<u64>,
   25|       |    pub enable_voting: Option<bool>,
   26|       |    pub external_address: Option<String>,
   27|       |    pub external_port: Option<u16>,
   28|       |    pub io_threads: Option<u32>,
   29|       |    pub max_queued_requests: Option<u32>,
   30|       |    pub max_unchecked_blocks: Option<u32>,
   31|       |    pub max_backlog: Option<usize>,
   32|       |    pub max_work_generate_multiplier: Option<f64>,
   33|       |    pub network_threads: Option<u32>,
   34|       |    pub online_weight_minimum: Option<String>,
   35|       |    pub password_fanout: Option<u32>,
   36|       |    pub peering_port: Option<u16>,
   37|       |    pub pow_sleep_interval: Option<i64>,
   38|       |    pub preconfigured_peers: Option<Vec<String>>,
   39|       |    pub preconfigured_representatives: Option<Vec<String>>,
   40|       |    pub receive_minimum: Option<String>,
   41|       |    pub rep_crawler_weight_minimum: Option<String>,
   42|       |    pub representative_vote_weight_minimum: Option<String>,
   43|       |    pub request_aggregator_threads: Option<u32>,
   44|       |    pub signature_checker_threads: Option<u32>,
   45|       |    pub unchecked_cutoff_time: Option<i64>,
   46|       |    pub use_memory_pools: Option<bool>,
   47|       |    pub vote_generator_delay: Option<u64>,
   48|       |    pub vote_minimum: Option<String>,
   49|       |    pub work_peers: Option<Vec<String>>,
   50|       |    pub work_threads: Option<u32>,
   51|       |    pub active_elections: Option<ActiveElectionsToml>,
   52|       |    pub block_processor: Option<BlockProcessorToml>,
   53|       |    pub bootstrap: Option<BootstrapToml>,
   54|       |    pub bootstrap_server: Option<BootstrapServerToml>,
   55|       |    pub diagnostics: Option<DiagnosticsToml>,
   56|       |    pub experimental: Option<ExperimentalToml>,
   57|       |    pub httpcallback: Option<HttpcallbackToml>,
   58|       |    pub lmdb: Option<LmdbToml>,
   59|       |    pub message_processor: Option<MessageProcessorToml>,
   60|       |    pub monitor: Option<MonitorToml>,
   61|       |    pub optimistic_scheduler: Option<OptimisticSchedulerToml>,
   62|       |    pub hinted_scheduler: Option<HintedSchedulerToml>,
   63|       |    pub priority_bucket: Option<PriorityBucketToml>,
   64|       |    pub rep_crawler: Option<RepCrawlerToml>,
   65|       |    pub request_aggregator: Option<RequestAggregatorToml>,
   66|       |    pub statistics: Option<StatsToml>,
   67|       |    pub vote_cache: Option<VoteCacheToml>,
   68|       |    pub vote_processor: Option<VoteProcessorToml>,
   69|       |    pub websocket: Option<WebsocketToml>,
   70|       |    pub backlog_scan: Option<BacklogScanToml>,
   71|       |    pub bounded_backlog: Option<BoundedBacklogToml>,
   72|       |    pub tcp: Option<TcpToml>,
   73|       |    pub max_ledger_notifications: Option<usize>,
   74|       |}
   75|       |
   76|       |impl NodeConfig {
   77|      2|    pub fn merge_toml(&mut self, toml: &NodeToml) {
   78|      2|        if let Some(allow_local_peers) = toml.allow_local_peers {
                                  ^1
   79|      1|            self.allow_local_peers = allow_local_peers;
   80|      1|        }
   81|      2|        if let Some(background_threads) = toml.background_threads {
                                  ^1
   82|      1|            self.background_threads = background_threads;
   83|      1|        }
   84|      2|        if let Some(backup_before_upgrade) = toml.backup_before_upgrade {
                                  ^1
   85|      1|            self.backup_before_upgrade = backup_before_upgrade;
   86|      1|        }
   87|      2|        if let Some(bandwidth_limit) = toml.bandwidth_limit {
                                  ^1
   88|      1|            self.bandwidth_limit = bandwidth_limit;
   89|      1|        }
   90|      2|        if let Some(max) = toml.max_peers_per_ip {
                                  ^0
   91|      0|            self.max_peers_per_ip = max;
   92|      2|        }
   93|      2|        if let Some(max) = toml.max_peers_per_subnetwork {
                                  ^0
   94|      0|            self.max_peers_per_subnetwork = max;
   95|      2|        }
   96|      2|        if let Some(bandwidth_limit_burst_ratio) = toml.bandwidth_limit_burst_ratio {
                                  ^1
   97|      1|            self.bandwidth_limit_burst_ratio = bandwidth_limit_burst_ratio;
   98|      1|        }
   99|      2|        if let Some(block_processor_batch_max_time_ms) = toml.block_processor_batch_max_time {
                                  ^1
  100|      1|            self.block_processor_batch_max_time_ms = block_processor_batch_max_time_ms;
  101|      1|        }
  102|      2|        if let Some(bootstrap_bandwidth_burst_ratio) = toml.bootstrap_bandwidth_burst_ratio {
                                  ^1
  103|      1|            self.bootstrap_bandwidth_burst_ratio = bootstrap_bandwidth_burst_ratio;
  104|      1|        }
  105|      2|        if let Some(bootstrap_bandwidth_limit) = toml.bootstrap_bandwidth_limit {
                                  ^1
  106|      1|            self.bootstrap_bandwidth_limit = bootstrap_bandwidth_limit;
  107|      1|        }
  108|      2|        if let Some(bootstrap_fraction_numerator) = toml.bootstrap_fraction_numerator {
                                  ^1
  109|      1|            self.bootstrap_fraction_numerator = bootstrap_fraction_numerator;
  110|      1|        }
  111|      2|        if let Some(bootstrap_initiator_threads) = toml.bootstrap_initiator_threads {
                                  ^1
  112|      1|            self.bootstrap_initiator_threads = bootstrap_initiator_threads;
  113|      1|        }
  114|      2|        if let Some(bootstrap_serving_threads) = toml.bootstrap_serving_threads {
                                  ^1
  115|      1|            self.bootstrap_serving_threads = bootstrap_serving_threads;
  116|      1|        }
  117|      2|        if let Some(confirming_set_batch_time) = &toml.confirming_set_batch_time {
                                  ^1
  118|      1|            self.confirming_set_batch_time = Duration::from_millis(*confirming_set_batch_time);
  119|      1|        }
  120|      2|        if let Some(enable_voting) = toml.enable_voting {
                                  ^1
  121|      1|            self.enable_voting = enable_voting;
  122|      1|        }
  123|      2|        if let Some(opt) = &toml.optimistic_scheduler {
                                  ^1
  124|      1|            if let Some(enable) = opt.enable {
  125|      1|                self.enable_optimistic_scheduler = enable;
  126|      1|            }
                           ^0
  127|      1|        }
  128|      2|        if let Some(external_address) = &toml.external_address {
                                  ^1
  129|      1|            self.external_address = external_address.clone();
  130|      1|        }
  131|      2|        if let Some(external_port) = toml.external_port {
                                  ^1
  132|      1|            self.external_port = external_port;
  133|      1|        }
  134|      2|        if let Some(io_threads) = toml.io_threads {
                                  ^1
  135|      1|            self.io_threads = io_threads;
  136|      1|        }
  137|      2|        if let Some(max_queued_requests) = toml.max_queued_requests {
                                  ^1
  138|      1|            self.max_queued_requests = max_queued_requests;
  139|      1|        }
  140|      2|        if let Some(max_unchecked_blocks) = toml.max_unchecked_blocks {
                                  ^1
  141|      1|            self.max_unchecked_blocks = max_unchecked_blocks;
  142|      1|        }
  143|      2|        if let Some(max) = toml.max_backlog {
                                  ^1
  144|      1|            self.bounded_backlog.max_backlog = max;
  145|      1|        }
  146|      2|        if let Some(max_work_generate_multiplier) = toml.max_work_generate_multiplier {
                                  ^1
  147|      1|            self.max_work_generate_multiplier = max_work_generate_multiplier;
  148|      1|        }
  149|      2|        if let Some(network_threads) = toml.network_threads {
                                  ^1
  150|      1|            self.network_threads = network_threads;
  151|      1|        }
  152|      2|        if let Some(online_weight_minimum) = &toml.online_weight_minimum {
                                  ^1
  153|      1|            self.online_weight_minimum =
  154|      1|                Amount::decode_dec(&online_weight_minimum).expect("Invalid online weight minimum");
  155|      1|        }
  156|      2|        if let Some(password_fanout) = toml.password_fanout {
                                  ^1
  157|      1|            self.password_fanout = password_fanout;
  158|      1|        }
  159|      2|        if let Some(peering_port) = toml.peering_port {
                                  ^1
  160|      1|            self.peering_port = Some(peering_port);
  161|      1|        }
  162|      2|        if let Some(pow_sleep_interval_ns) = toml.pow_sleep_interval {
                                  ^1
  163|      1|            self.pow_sleep_interval_ns = pow_sleep_interval_ns;
  164|      1|        }
  165|      2|        if let Some(preconfigured_peers) = &toml.preconfigured_peers {
                                  ^1
  166|      1|            self.preconfigured_peers =
  167|      1|                Peer::parse_list(preconfigured_peers, self.default_peering_port);
  168|      1|        }
  169|      2|        if let Some(preconfigured_representatives) = &toml.preconfigured_representatives {
                                  ^1
  170|      1|            self.preconfigured_representatives = preconfigured_representatives
  171|      1|                .iter()
  172|      1|                .map(|string| {
  173|      1|                    Account::decode_account(&string)
  174|      1|                        .expect("Invalid representative")
  175|      1|                        .into()
  176|      1|                })
  177|      1|                .collect();
  178|      1|        }
  179|      2|        if let Some(receive_minimum) = &toml.receive_minimum {
                                  ^1
  180|      1|            self.receive_minimum =
  181|      1|                Amount::decode_dec(&receive_minimum).expect("Invalid receive minimum");
  182|      1|        }
  183|      2|        if let Some(rep_crawler) = &toml.rep_crawler {
                                  ^1
  184|      1|            if let Some(query_timeout) = rep_crawler.query_timeout {
  185|      1|                self.rep_crawler_query_timeout = Duration::from_millis(query_timeout);
  186|      1|            }
                           ^0
  187|      1|        }
  188|      2|        if let Some(representative_vote_weight_minimum) = &toml.representative_vote_weight_minimum {
                                  ^1
  189|      1|            self.representative_vote_weight_minimum =
  190|      1|                Amount::decode_dec(&representative_vote_weight_minimum)
  191|      1|                    .expect("Invalid representative vote weight minimum");
  192|      1|        }
  193|      2|        if let Some(request_aggregator_threads) = toml.request_aggregator_threads {
                                  ^1
  194|      1|            self.request_aggregator_threads = request_aggregator_threads;
  195|      1|        }
  196|      2|        if let Some(signature_checker_threads) = toml.signature_checker_threads {
                                  ^1
  197|      1|            self.signature_checker_threads = signature_checker_threads;
  198|      1|        }
  199|      2|        if let Some(unchecked_cutoff_time_s) = toml.unchecked_cutoff_time {
                                  ^1
  200|      1|            self.unchecked_cutoff_time_s = unchecked_cutoff_time_s;
  201|      1|        }
  202|      2|        if let Some(use_memory_pools) = toml.use_memory_pools {
                                  ^1
  203|      1|            self.use_memory_pools = use_memory_pools;
  204|      1|        }
  205|      2|        if let Some(delay) = toml.vote_generator_delay {
                                  ^1
  206|      1|            self.vote_generator_delay = Duration::from_millis(delay);
  207|      1|        }
  208|      2|        if let Some(vote_minimum) = &toml.vote_minimum {
                                  ^1
  209|      1|            self.vote_minimum = Amount::decode_dec(&vote_minimum).expect("Invalid vote minimum");
  210|      1|        }
  211|      2|        if let Some(work_peers) = &toml.work_peers {
                                  ^1
  212|      1|            self.work_peers = work_peers
  213|      1|                .iter()
  214|      1|                .map(|string| Peer::from_str(&string).expect("Invalid work peer"))
  215|      1|                .collect();
  216|      1|        }
  217|      2|        if let Some(work_threads) = toml.work_threads {
                                  ^1
  218|      1|            self.work_threads = work_threads;
  219|      1|        }
  220|      2|        if let Some(cfg) = &toml.optimistic_scheduler {
                                  ^1
  221|      1|            if let Some(enable) = cfg.enable {
  222|      1|                self.enable_optimistic_scheduler = enable;
  223|      1|            }
                           ^0
  224|      1|            self.optimistic_scheduler.merge_toml(cfg);
  225|      1|        }
  226|      2|        if let Some(cfg) = &toml.hinted_scheduler {
                                  ^1
  227|      1|            if let Some(enable) = cfg.enable {
  228|      1|                self.enable_hinted_scheduler = enable;
  229|      1|            }
                           ^0
  230|      1|            self.hinted_scheduler.merge_toml(&cfg);
  231|      1|        }
  232|      2|        if let Some(priority_bucket_toml) = &toml.priority_bucket {
                                  ^1
  233|      1|            self.priority_bucket = priority_bucket_toml.into();
  234|      1|        }
  235|      2|        if let Some(ascending_toml) = &toml.bootstrap {
  236|      2|            let config = &mut self.bootstrap;
  237|      2|            if let Some(enable) = &ascending_toml.enable {
  238|      2|                config.enable = *enable;
  239|      2|            }
                           ^0
  240|      2|            if let Some(enable) = &ascending_toml.enable_dependency_walker {
  241|      2|                config.enable_dependency_walker = *enable;
  242|      2|            }
                           ^0
  243|      2|            if let Some(enable) = &ascending_toml.enable_databaser_scan {
                                      ^1
  244|      1|                config.enable_database_scan = *enable;
  245|      1|            }
  246|      2|            if let Some(enable) = &ascending_toml.enable_frontier_scan {
                                      ^1
  247|      1|                config.enable_frontier_scan = *enable;
  248|      1|            }
  249|      2|            if let Some(account_sets) = &ascending_toml.account_sets {
  250|      2|                config.account_sets = account_sets.into();
  251|      2|            }
                           ^0
  252|      2|            if let Some(block_wait_count) = ascending_toml.block_processor_threshold {
  253|      2|                config.block_processor_theshold = block_wait_count;
  254|      2|            }
                           ^0
  255|      2|            if let Some(database_rate_limit) = ascending_toml.database_rate_limit {
  256|      2|                config.database_rate_limit = database_rate_limit;
  257|      2|            }
                           ^0
  258|      2|            if let Some(database_warmup_ratio) = ascending_toml.database_warmup_ratio {
                                      ^1
  259|      1|                config.database_warmup_ratio = database_warmup_ratio;
  260|      1|            }
  261|      2|            if let Some(pull_count) = ascending_toml.max_pull_count {
  262|      2|                config.max_pull_count = pull_count;
  263|      2|            }
                           ^0
  264|      2|            if let Some(limit) = ascending_toml.channel_limit {
  265|      2|                config.channel_limit = limit;
  266|      2|            }
                           ^0
  267|      2|            if let Some(limit) = ascending_toml.rate_limit {
  268|      2|                config.rate_limit = limit;
  269|      2|            }
                           ^0
  270|      2|            if let Some(timeout) = &ascending_toml.request_timeout {
  271|      2|                config.request_timeout = Duration::from_millis(*timeout);
  272|      2|            }
                           ^0
  273|      2|            if let Some(throttle_wait) = &ascending_toml.throttle_wait {
  274|      2|                config.throttle_wait = Duration::from_millis(*throttle_wait);
  275|      2|            }
                           ^0
  276|      2|            if let Some(throttle_coefficient) = ascending_toml.throttle_coefficient {
  277|      2|                config.throttle_coefficient = throttle_coefficient;
  278|      2|            }
                           ^0
  279|      2|            if let Some(max) = ascending_toml.max_requests {
  280|      2|                config.max_requests = max;
  281|      2|            }
                           ^0
  282|      2|            if let Some(percent) = ascending_toml.optimistic_request_percentage {
                                      ^1
  283|      1|                config.optimistic_request_percentage = percent;
  284|      1|            }
  285|      0|        }
  286|      2|        if let Some(bootstrap_server_toml) = &toml.bootstrap_server {
                                  ^1
  287|      1|            self.bootstrap_responder = bootstrap_server_toml.into();
  288|      1|        }
  289|      2|        if let Some(websocket_config_toml) = &toml.websocket {
                                  ^1
  290|      1|            self.websocket_config.merge_toml(&websocket_config_toml);
  291|      1|        }
  292|      2|        if let Some(diagnostics_config_toml) = &toml.diagnostics {
                                  ^1
  293|      1|            self.diagnostics_config = diagnostics_config_toml.into();
  294|      1|        }
  295|      2|        if let Some(stat_config_toml) = &toml.statistics {
                                  ^1
  296|      1|            self.stat_config = stat_config_toml.into();
  297|      1|        }
  298|      2|        if let Some(lmdb_config_toml) = &toml.lmdb {
                                  ^1
  299|      1|            self.lmdb_config = lmdb_config_toml.into();
  300|      1|        }
  301|      2|        if let Some(vote_cache_toml) = &toml.vote_cache {
                                  ^1
  302|      1|            self.vote_cache = vote_cache_toml.into();
  303|      1|        }
  304|      2|        if let Some(block_processor_toml) = &toml.block_processor {
                                  ^1
  305|      1|            self.block_processor.merge_toml(block_processor_toml);
  306|      1|        }
  307|      2|        if let Some(active_elections_toml) = &toml.active_elections {
                                  ^1
  308|      1|            self.active_elections = active_elections_toml.into();
  309|      1|        }
  310|      2|        if let Some(vote_processor_toml) = &toml.vote_processor {
                                  ^1
  311|      1|            self.vote_processor.merge_toml(&vote_processor_toml);
  312|      1|        }
  313|      2|        if let Some(request_aggregator_toml) = &toml.request_aggregator {
                                  ^1
  314|      1|            self.request_aggregator.merge_toml(request_aggregator_toml);
  315|      1|        }
  316|      2|        if let Some(message_processor_toml) = &toml.message_processor {
                                  ^1
  317|      1|            self.message_processor.merge_toml(message_processor_toml);
  318|      1|        }
  319|      2|        if let Some(cfg) = &toml.monitor {
                                  ^1
  320|      1|            if let Some(enable) = cfg.enable {
  321|      1|                self.enable_monitor = enable;
  322|      1|            }
                           ^0
  323|      1|            if let Some(secs) = cfg.interval {
  324|      1|                self.monitor.interval = Duration::from_secs(secs);
  325|      1|            }
                           ^0
  326|      1|        }
  327|      2|        if let Some(rep_crawler_weight_minimum) = &toml.rep_crawler_weight_minimum {
                                  ^1
  328|      1|            self.rep_crawler_weight_minimum = Amount::decode_dec(&rep_crawler_weight_minimum)
  329|      1|                .expect("Invalid rep crawler weight minimum");
  330|      1|        }
  331|      2|        if let Some(httpcallback) = &toml.httpcallback {
                                  ^1
  332|      1|            if let Some(address) = &httpcallback.address {
  333|      1|                self.callback_address = address.clone();
  334|      1|            }
                           ^0
  335|      1|            if let Some(port) = &httpcallback.port {
  336|      1|                self.callback_port = port.clone();
  337|      1|            }
                           ^0
  338|      1|            if let Some(target) = &httpcallback.target {
  339|      1|                self.callback_target = target.clone();
  340|      1|            }
                           ^0
  341|      1|        }
  342|      2|        if let Some(toml) = &toml.backlog_scan {
                                  ^1
  343|      1|            self.backlog_scan.merge_toml(toml);
  344|      1|        }
  345|      2|        self.bounded_backlog.merge_toml(toml);
  346|      2|        if let Some(toml) = &toml.bounded_backlog {
                                  ^1
  347|      1|            if let Some(enable) = toml.enable {
  348|      1|                self.enable_bounded_backlog = enable;
  349|      1|            }
                           ^0
  350|      1|        }
  351|       |
  352|      2|        if let Some(toml) = &toml.tcp {
                                  ^1
  353|      1|            self.tcp.merge_toml(toml);
  354|      1|        }
  355|       |
  356|      2|        if let Some(i) = toml.max_ledger_notifications {
                                  ^0
  357|      0|            self.max_ledger_notifications = i;
  358|      2|        }
  359|      2|    }
  360|       |}
  361|       |
  362|       |impl From<&NodeConfig> for NodeToml {
  363|      1|    fn from(config: &NodeConfig) -> Self {
  364|      1|        Self {
  365|      1|            allow_local_peers: Some(config.allow_local_peers),
  366|      1|            background_threads: Some(config.background_threads),
  367|      1|            backup_before_upgrade: Some(config.backup_before_upgrade),
  368|      1|            bandwidth_limit: Some(config.bandwidth_limit),
  369|      1|            bandwidth_limit_burst_ratio: Some(config.bandwidth_limit_burst_ratio),
  370|      1|            max_peers_per_ip: Some(config.max_peers_per_ip),
  371|      1|            max_peers_per_subnetwork: Some(config.max_peers_per_subnetwork),
  372|      1|            block_processor_batch_max_time: Some(config.block_processor_batch_max_time_ms),
  373|      1|            bootstrap_bandwidth_burst_ratio: Some(config.bootstrap_bandwidth_burst_ratio),
  374|      1|            bootstrap_bandwidth_limit: Some(config.bootstrap_bandwidth_limit),
  375|      1|            bootstrap_fraction_numerator: Some(config.bootstrap_fraction_numerator),
  376|      1|            bootstrap_initiator_threads: Some(config.bootstrap_initiator_threads),
  377|      1|            bootstrap_serving_threads: Some(config.bootstrap_serving_threads),
  378|      1|            confirming_set_batch_time: Some(config.confirming_set_batch_time.as_millis() as u64),
  379|      1|            enable_voting: Some(config.enable_voting),
  380|      1|            external_address: Some(config.external_address.clone()),
  381|      1|            external_port: Some(config.external_port),
  382|      1|            io_threads: Some(config.io_threads),
  383|      1|            max_queued_requests: Some(config.max_queued_requests),
  384|      1|            max_unchecked_blocks: Some(config.max_unchecked_blocks),
  385|      1|            max_backlog: Some(config.bounded_backlog.max_backlog),
  386|      1|            max_work_generate_multiplier: Some(config.max_work_generate_multiplier),
  387|      1|            network_threads: Some(config.network_threads),
  388|      1|            online_weight_minimum: Some(config.online_weight_minimum.to_string_dec()),
  389|      1|            password_fanout: Some(config.password_fanout),
  390|      1|            peering_port: config.peering_port,
  391|      1|            pow_sleep_interval: Some(config.pow_sleep_interval_ns),
  392|      1|            preconfigured_peers: Some(
  393|      1|                config
  394|      1|                    .preconfigured_peers
  395|      1|                    .iter()
  396|      1|                    .map(|p| p.to_string())
                                           ^0
  397|      1|                    .collect(),
  398|      1|            ),
  399|      1|            preconfigured_representatives: Some(
  400|      1|                config
  401|      1|                    .preconfigured_representatives
  402|      1|                    .iter()
  403|      1|                    .map(|pk| Account::from(pk).encode_account())
  404|      1|                    .collect(),
  405|      1|            ),
  406|      1|            receive_minimum: Some(config.receive_minimum.to_string_dec()),
  407|      1|            rep_crawler_weight_minimum: Some(config.rep_crawler_weight_minimum.to_string_dec()),
  408|      1|            representative_vote_weight_minimum: Some(
  409|      1|                config.representative_vote_weight_minimum.to_string_dec(),
  410|      1|            ),
  411|      1|            request_aggregator_threads: Some(config.request_aggregator_threads),
  412|      1|            signature_checker_threads: Some(config.signature_checker_threads),
  413|      1|            unchecked_cutoff_time: Some(config.unchecked_cutoff_time_s),
  414|      1|            use_memory_pools: Some(config.use_memory_pools),
  415|      1|            vote_generator_delay: Some(config.vote_generator_delay.as_millis() as u64),
  416|      1|            vote_minimum: Some(config.vote_minimum.to_string_dec()),
  417|      1|            work_peers: Some(
  418|      1|                config
  419|      1|                    .work_peers
  420|      1|                    .iter()
  421|      1|                    .map(|peer| peer.to_string())
                                              ^0
  422|      1|                    .collect(),
  423|      1|            ),
  424|      1|            work_threads: Some(config.work_threads),
  425|      1|            optimistic_scheduler: Some(OptimisticSchedulerToml {
  426|      1|                enable: Some(config.enable_optimistic_scheduler),
  427|      1|                gap_threshold: Some(config.optimistic_scheduler.gap_threshold),
  428|      1|                max_size: Some(config.optimistic_scheduler.max_size),
  429|      1|            }),
  430|      1|            hinted_scheduler: Some(HintedSchedulerToml {
  431|      1|                enable: Some(config.enable_hinted_scheduler),
  432|      1|                hinting_threshold: Some(config.hinted_scheduler.hinting_threshold_percent),
  433|      1|                check_interval: Some(config.hinted_scheduler.check_interval.as_millis() as u64),
  434|      1|                block_cooldown: Some(config.hinted_scheduler.block_cooldown.as_millis() as u64),
  435|      1|                vacancy_threshold: Some(config.hinted_scheduler.vacancy_threshold_percent),
  436|      1|            }),
  437|      1|            priority_bucket: Some((&config.priority_bucket).into()),
  438|      1|            bootstrap: Some((&config.bootstrap).into()),
  439|      1|            bootstrap_server: Some((&config.bootstrap_responder).into()),
  440|      1|            websocket: Some((&config.websocket_config).into()),
  441|      1|            diagnostics: Some((&config.diagnostics_config).into()),
  442|      1|            statistics: Some((&config.stat_config).into()),
  443|      1|            lmdb: Some((&config.lmdb_config).into()),
  444|      1|            vote_cache: Some((&config.vote_cache).into()),
  445|      1|            block_processor: Some((&config.block_processor).into()),
  446|      1|            active_elections: Some((&config.active_elections).into()),
  447|      1|            vote_processor: Some((&config.vote_processor).into()),
  448|      1|            request_aggregator: Some((&config.request_aggregator).into()),
  449|      1|            message_processor: Some((&config.message_processor).into()),
  450|      1|            monitor: Some(MonitorToml {
  451|      1|                enable: Some(config.enable_monitor),
  452|      1|                interval: Some(config.monitor.interval.as_secs()),
  453|      1|            }),
  454|      1|            httpcallback: Some(config.into()),
  455|      1|            rep_crawler: Some(config.into()),
  456|      1|            experimental: Some(config.into()),
  457|      1|            backlog_scan: Some((&config.backlog_scan).into()),
  458|      1|            bounded_backlog: Some(config.into()),
  459|      1|            tcp: Some((&config.tcp).into()),
  460|      1|            max_ledger_notifications: Some(config.max_ledger_notifications),
  461|      1|        }
  462|      1|    }
  463|       |}
  464|       |
  465|       |#[cfg(test)]
  466|       |mod tests {
  467|       |    use super::*;
  468|       |    use crate::config::toml::AccountSetsToml;
  469|       |
  470|       |    #[test]
  471|      1|    fn merge_bootstrap_ascending_toml() {
  472|      1|        let sets_toml = AccountSetsToml {
  473|      1|            blocking_max: Some(200),
  474|      1|            consideration_count: Some(201),
  475|      1|            cooldown: Some(203),
  476|      1|            priorities_max: Some(204),
  477|      1|        };
  478|      1|
  479|      1|        let ascending_toml = BootstrapToml {
  480|      1|            enable: Some(false),
  481|      1|            enable_databaser_scan: Some(false),
  482|      1|            enable_dependency_walker: Some(false),
  483|      1|            enable_frontier_scan: Some(false),
  484|      1|            block_processor_threshold: Some(100),
  485|      1|            database_rate_limit: Some(101),
  486|      1|            max_pull_count: Some(102),
  487|      1|            channel_limit: Some(103),
  488|      1|            rate_limit: Some(200),
  489|      1|            throttle_coefficient: Some(104),
  490|      1|            throttle_wait: Some(105),
  491|      1|            request_timeout: Some(106),
  492|      1|            max_requests: Some(107),
  493|      1|            optimistic_request_percentage: Some(42),
  494|      1|            database_warmup_ratio: Some(108),
  495|      1|            account_sets: Some(sets_toml),
  496|      1|        };
  497|      1|
  498|      1|        let toml = NodeToml {
  499|      1|            bootstrap: Some(ascending_toml),
  500|      1|            ..Default::default()
  501|      1|        };
  502|      1|
  503|      1|        let mut cfg = NodeConfig::new_test_instance();
  504|      1|        cfg.merge_toml(&toml);
  505|      1|
  506|      1|        let ascending = &cfg.bootstrap;
  507|      1|        assert_eq!(ascending.enable, false);
  508|      1|        assert_eq!(ascending.enable_database_scan, false);
  509|      1|        assert_eq!(ascending.enable_dependency_walker, false);
  510|      1|        assert_eq!(ascending.enable_frontier_scan, false);
  511|      1|        assert_eq!(ascending.block_processor_theshold, 100);
  512|      1|        assert_eq!(ascending.database_rate_limit, 101);
  513|      1|        assert_eq!(ascending.max_pull_count, 102);
  514|      1|        assert_eq!(ascending.channel_limit, 103);
  515|      1|        assert_eq!(ascending.rate_limit, 200);
  516|      1|        assert_eq!(ascending.throttle_coefficient, 104);
  517|      1|        assert_eq!(ascending.throttle_wait, Duration::from_millis(105));
  518|      1|        assert_eq!(ascending.request_timeout, Duration::from_millis(106));
  519|      1|        assert_eq!(ascending.max_requests, 107);
  520|      1|        assert_eq!(ascending.optimistic_request_percentage, 42);
  521|      1|        assert_eq!(ascending.database_warmup_ratio, 108);
  522|       |
  523|      1|        let sets = &cfg.bootstrap.account_sets;
  524|      1|        assert_eq!(sets.blocking_max, 200);
  525|      1|        assert_eq!(sets.consideration_count, 201);
  526|      1|        assert_eq!(sets.cooldown, Duration::from_millis(203));
  527|      1|        assert_eq!(sets.priorities_max, 204);
  528|      1|    }
  529|       |
  530|       |    #[test]
  531|      1|    fn create_bootstrap_ascending_toml() {
  532|      1|        let cfg = NodeConfig::new_test_instance();
  533|      1|        let toml = NodeToml::from(&cfg);
  534|      1|        let ascending_toml = toml.bootstrap.as_ref().unwrap();
  535|      1|        assert_eq!(ascending_toml.enable, Some(true));
  536|      1|        assert_eq!(ascending_toml.enable_databaser_scan, Some(false));
  537|      1|        assert_eq!(ascending_toml.enable_frontier_scan, Some(true));
  538|      1|        assert_eq!(ascending_toml.enable_dependency_walker, Some(true));
  539|      1|        assert_eq!(ascending_toml.block_processor_threshold, Some(1000));
  540|      1|        assert_eq!(ascending_toml.database_rate_limit, Some(256));
  541|      1|        assert_eq!(ascending_toml.database_warmup_ratio, Some(10));
  542|      1|        assert_eq!(ascending_toml.max_pull_count, Some(128));
  543|      1|        assert_eq!(ascending_toml.channel_limit, Some(16));
  544|      1|        assert_eq!(ascending_toml.throttle_coefficient, Some(1024 * 8));
  545|      1|        assert_eq!(ascending_toml.throttle_wait, Some(100));
  546|      1|        assert_eq!(ascending_toml.request_timeout, Some(15000));
  547|      1|        assert_eq!(ascending_toml.max_requests, Some(1024));
  548|      1|        assert_eq!(ascending_toml.optimistic_request_percentage, Some(75));
  549|       |
  550|      1|        let sets_toml = ascending_toml.account_sets.as_ref().unwrap();
  551|      1|        assert_eq!(sets_toml.consideration_count, Some(4));
  552|      1|        assert_eq!(sets_toml.priorities_max, Some(1024 * 256));
  553|      1|        assert_eq!(sets_toml.blocking_max, Some(1024 * 256));
  554|      1|        assert_eq!(sets_toml.cooldown, Some(3000));
  555|      1|    }
  556|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/opencl_toml.rs:
    1|       |use crate::config::OpenclConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      5|#[derive(Deserialize, Serialize)]
    5|       |pub struct OpenclToml {
    6|       |    pub device: Option<u32>,
    7|       |    pub enable: Option<bool>,
    8|       |    pub platform: Option<u32>,
    9|       |    pub threads: Option<u32>,
   10|       |}
   11|       |
   12|       |impl OpenclConfig {
   13|      1|    pub fn merge_toml(&mut self, toml: &OpenclToml) {
   14|      1|        if let Some(device) = toml.device {
   15|      1|            self.device = device;
   16|      1|        }
                       ^0
   17|      1|        if let Some(platform) = toml.platform {
   18|      1|            self.platform = platform;
   19|      1|        }
                       ^0
   20|      1|        if let Some(threads) = toml.threads {
   21|      1|            self.threads = threads;
   22|      1|        }
                       ^0
   23|      1|    }
   24|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/optimistic_scheduler_toml.rs:
    1|       |use crate::consensus::OptimisticSchedulerConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct OptimisticSchedulerToml {
    6|       |    pub enable: Option<bool>,
    7|       |    pub gap_threshold: Option<u64>,
    8|       |    pub max_size: Option<usize>,
    9|       |}
   10|       |
   11|       |impl Default for OptimisticSchedulerToml {
   12|      0|    fn default() -> Self {
   13|      0|        let config = OptimisticSchedulerConfig::new();
   14|      0|        Self {
   15|      0|            enable: Some(true),
   16|      0|            gap_threshold: Some(config.gap_threshold),
   17|      0|            max_size: Some(config.max_size),
   18|      0|        }
   19|      0|    }
   20|       |}
   21|       |
   22|       |impl OptimisticSchedulerConfig {
   23|      1|    pub fn merge_toml(&mut self, toml: &OptimisticSchedulerToml) {
   24|      1|        if let Some(gap_threshold) = toml.gap_threshold {
   25|      1|            self.gap_threshold = gap_threshold;
   26|      1|        }
                       ^0
   27|      1|        if let Some(max_size) = toml.max_size {
   28|      1|            self.max_size = max_size;
   29|      1|        }
                       ^0
   30|      1|    }
   31|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/priority_bucket_toml.rs:
    1|       |use crate::consensus::PriorityBucketConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct PriorityBucketToml {
    6|       |    pub max_blocks: Option<usize>,
    7|       |    pub max_elections: Option<usize>,
    8|       |    pub reserved_elections: Option<usize>,
    9|       |}
   10|       |
   11|       |impl Default for PriorityBucketToml {
   12|      0|    fn default() -> Self {
   13|      0|        let config = PriorityBucketConfig::default();
   14|      0|        (&config).into()
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl From<&PriorityBucketToml> for PriorityBucketConfig {
   19|      1|    fn from(toml: &PriorityBucketToml) -> Self {
   20|      1|        let mut config = PriorityBucketConfig::default();
   21|       |
   22|      1|        if let Some(max_blocks) = toml.max_blocks {
   23|      1|            config.max_blocks = max_blocks;
   24|      1|        }
                       ^0
   25|      1|        if let Some(max_elections) = toml.max_elections {
   26|      1|            config.max_elections = max_elections;
   27|      1|        }
                       ^0
   28|      1|        if let Some(reserved_elections) = toml.reserved_elections {
   29|      1|            config.reserved_elections = reserved_elections;
   30|      1|        }
                       ^0
   31|      1|        config
   32|      1|    }
   33|       |}
   34|       |
   35|       |impl From<&PriorityBucketConfig> for PriorityBucketToml {
   36|      1|    fn from(config: &PriorityBucketConfig) -> Self {
   37|      1|        Self {
   38|      1|            max_blocks: Some(config.max_blocks),
   39|      1|            reserved_elections: Some(config.reserved_elections),
   40|      1|            max_elections: Some(config.max_elections),
   41|      1|        }
   42|      1|    }
   43|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/rep_crawler_toml.rs:
    1|       |use crate::config::NodeConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |use std::time::Duration;
    4|       |
    5|      2|#[derive(Deserialize, Serialize)]
    6|       |pub struct RepCrawlerToml {
    7|       |    pub query_timeout: Option<u64>,
    8|       |}
    9|       |
   10|       |impl NodeConfig {
   11|      0|    pub fn merge_rep_crawler_toml(&mut self, toml: &RepCrawlerToml) {
   12|      0|        if let Some(query_timeout) = toml.query_timeout {
   13|      0|            self.rep_crawler_query_timeout = Duration::from_millis(query_timeout);
   14|      0|        }
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl From<&NodeConfig> for RepCrawlerToml {
   19|      1|    fn from(config: &NodeConfig) -> Self {
   20|      1|        Self {
   21|      1|            query_timeout: Some(config.rep_crawler_query_timeout.as_millis() as u64),
   22|      1|        }
   23|      1|    }
   24|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/request_aggregator_toml.rs:
    1|       |use crate::consensus::RequestAggregatorConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct RequestAggregatorToml {
    6|       |    pub batch_size: Option<usize>,
    7|       |    pub max_queue: Option<usize>,
    8|       |    pub threads: Option<usize>,
    9|       |}
   10|       |
   11|       |impl RequestAggregatorConfig {
   12|      1|    pub fn merge_toml(&mut self, toml: &RequestAggregatorToml) {
   13|      1|        if let Some(threads) = toml.threads {
   14|      1|            self.threads = threads;
   15|      1|        }
                       ^0
   16|      1|        if let Some(max_queue) = toml.max_queue {
   17|      1|            self.max_queue = max_queue;
   18|      1|        }
                       ^0
   19|      1|        if let Some(batch_size) = toml.batch_size {
   20|      1|            self.batch_size = batch_size;
   21|      1|        }
                       ^0
   22|      1|    }
   23|       |}
   24|       |
   25|       |impl From<&RequestAggregatorConfig> for RequestAggregatorToml {
   26|      1|    fn from(config: &RequestAggregatorConfig) -> Self {
   27|      1|        Self {
   28|      1|            threads: Some(config.threads),
   29|      1|            max_queue: Some(config.max_queue),
   30|      1|            batch_size: Some(config.batch_size),
   31|      1|        }
   32|      1|    }
   33|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/stats_toml.rs:
    1|       |use crate::stats::StatsConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |use std::time::Duration;
    4|       |
    5|      7|#[derive(Deserialize, Serialize)]
    6|       |pub struct LogToml {
    7|       |    pub filename_counters: Option<String>,
    8|       |    pub filename_samples: Option<String>,
    9|       |    pub headers: Option<bool>,
   10|       |    pub interval_counters: Option<u64>,
   11|       |    pub interval_samples: Option<u64>,
   12|       |    pub rotation_count: Option<usize>,
   13|       |}
   14|       |
   15|       |impl Default for LogToml {
   16|      0|    fn default() -> Self {
   17|      0|        let config = StatsConfig::default();
   18|      0|        (&config).into()
   19|      0|    }
   20|       |}
   21|       |
   22|      3|#[derive(Deserialize, Serialize)]
   23|       |pub struct StatsToml {
   24|       |    pub max_samples: Option<usize>,
   25|       |    pub log: Option<LogToml>,
   26|       |}
   27|       |
   28|       |impl Default for StatsToml {
   29|      0|    fn default() -> Self {
   30|      0|        let config = StatsConfig::default();
   31|      0|        (&config).into()
   32|      0|    }
   33|       |}
   34|       |
   35|       |impl From<&StatsToml> for StatsConfig {
   36|      1|    fn from(toml: &StatsToml) -> Self {
   37|      1|        let mut config = StatsConfig::default();
   38|       |
   39|      1|        if let Some(max_samples) = toml.max_samples {
   40|      1|            config.max_samples = max_samples;
   41|      1|        }
                       ^0
   42|      1|        if let Some(log) = &toml.log {
   43|      1|            if let Some(log_counters_filename) = &log.filename_counters {
   44|      1|                config.log_counters_filename = log_counters_filename.clone();
   45|      1|            }
                           ^0
   46|      1|            if let Some(log_counters_interval) = &log.interval_counters {
   47|      1|                config.log_counters_interval = Duration::from_millis(*log_counters_interval);
   48|      1|            }
                           ^0
   49|      1|            if let Some(log_headers) = log.headers {
   50|      1|                config.log_headers = log_headers;
   51|      1|            }
                           ^0
   52|      1|            if let Some(log_rotation_count) = log.rotation_count {
   53|      1|                config.log_rotation_count = log_rotation_count;
   54|      1|            }
                           ^0
   55|      1|            if let Some(log_samples_filename) = &log.filename_samples {
   56|      1|                config.log_samples_filename = log_samples_filename.clone();
   57|      1|            }
                           ^0
   58|      1|            if let Some(log_samples_interval) = &log.interval_samples {
   59|      1|                config.log_samples_interval = Duration::from_millis(*log_samples_interval);
   60|      1|            }
                           ^0
   61|      0|        }
   62|      1|        config
   63|      1|    }
   64|       |}
   65|       |
   66|       |impl From<&StatsConfig> for StatsToml {
   67|      1|    fn from(config: &StatsConfig) -> Self {
   68|      1|        Self {
   69|      1|            max_samples: Some(config.max_samples),
   70|      1|            log: Some(config.into()),
   71|      1|        }
   72|      1|    }
   73|       |}
   74|       |
   75|       |impl From<&StatsConfig> for LogToml {
   76|      1|    fn from(config: &StatsConfig) -> Self {
   77|      1|        Self {
   78|      1|            interval_samples: Some(config.log_samples_interval.as_millis() as u64),
   79|      1|            interval_counters: Some(config.log_counters_interval.as_millis() as u64),
   80|      1|            rotation_count: Some(config.log_rotation_count),
   81|      1|            headers: Some(config.log_headers),
   82|      1|            filename_counters: Some(config.log_counters_filename.clone()),
   83|      1|            filename_samples: Some(config.log_samples_filename.clone()),
   84|      1|        }
   85|      1|    }
   86|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/tcp_toml.rs:
    1|       |use std::time::Duration;
    2|       |
    3|       |use crate::config::TcpConfig;
    4|       |use serde::{Deserialize, Serialize};
    5|       |
    6|      8|#[derive(Deserialize, Serialize)]
    7|       |pub struct TcpToml {
    8|       |    pub max_inbound_connections: Option<usize>,
    9|       |    pub max_outbound_connections: Option<usize>,
   10|       |    pub max_attempts: Option<usize>,
   11|       |    pub max_attempts_per_ip: Option<usize>,
   12|       |    pub connect_timeout: Option<usize>,
   13|       |    pub handshake_timeout: Option<usize>,
   14|       |    pub io_timeout: Option<usize>,
   15|       |}
   16|       |
   17|       |impl From<&TcpConfig> for TcpToml {
   18|      1|    fn from(value: &TcpConfig) -> Self {
   19|      1|        Self {
   20|      1|            max_inbound_connections: Some(value.max_inbound_connections),
   21|      1|            max_outbound_connections: Some(value.max_outbound_connections),
   22|      1|            max_attempts: Some(value.max_attempts),
   23|      1|            max_attempts_per_ip: Some(value.max_attempts_per_ip),
   24|      1|            connect_timeout: None,
   25|      1|            handshake_timeout: None,
   26|      1|            io_timeout: None,
   27|      1|        }
   28|      1|    }
   29|       |}
   30|       |
   31|       |impl TcpConfig {
   32|      1|    pub fn merge_toml(&mut self, toml: &TcpToml) {
   33|      1|        if let Some(i) = toml.max_inbound_connections {
   34|      1|            self.max_inbound_connections = i;
   35|      1|        }
                       ^0
   36|      1|        if let Some(i) = toml.max_outbound_connections {
   37|      1|            self.max_outbound_connections = i;
   38|      1|        }
                       ^0
   39|      1|        if let Some(i) = toml.max_attempts {
   40|      1|            self.max_attempts = i;
   41|      1|        }
                       ^0
   42|      1|        if let Some(i) = toml.max_attempts_per_ip {
   43|      1|            self.max_attempts_per_ip = i;
   44|      1|        }
                       ^0
   45|      1|        if let Some(i) = toml.connect_timeout {
   46|      1|            self.connect_timeout = Duration::from_secs(i as u64)
   47|      0|        }
   48|      1|    }
   49|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/vote_cache_toml.rs:
    1|       |use crate::consensus::VoteCacheConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |use std::time::Duration;
    4|       |
    5|      4|#[derive(Deserialize, Serialize)]
    6|       |pub struct VoteCacheToml {
    7|       |    pub age_cutoff: Option<u64>,
    8|       |    pub max_size: Option<usize>,
    9|       |    pub max_voters: Option<usize>,
   10|       |}
   11|       |
   12|       |impl Default for VoteCacheToml {
   13|      0|    fn default() -> Self {
   14|      0|        let config = VoteCacheConfig::default();
   15|      0|        (&config).into()
   16|      0|    }
   17|       |}
   18|       |
   19|       |impl From<&VoteCacheToml> for VoteCacheConfig {
   20|      1|    fn from(toml: &VoteCacheToml) -> Self {
   21|      1|        let mut config = VoteCacheConfig::default();
   22|       |
   23|      1|        if let Some(max_size) = toml.max_size {
   24|      1|            config.max_size = max_size;
   25|      1|        }
                       ^0
   26|      1|        if let Some(max_voters) = toml.max_voters {
   27|      1|            config.max_voters = max_voters;
   28|      1|        }
                       ^0
   29|      1|        if let Some(age_cutoff) = &toml.age_cutoff {
   30|      1|            config.age_cutoff = Duration::from_secs(*age_cutoff);
   31|      1|        }
                       ^0
   32|      1|        config
   33|      1|    }
   34|       |}
   35|       |
   36|       |impl From<&VoteCacheConfig> for VoteCacheToml {
   37|      1|    fn from(config: &VoteCacheConfig) -> Self {
   38|      1|        Self {
   39|      1|            max_size: Some(config.max_size),
   40|      1|            max_voters: Some(config.max_voters),
   41|      1|            age_cutoff: Some(config.age_cutoff.as_secs() as u64),
   42|      1|        }
   43|      1|    }
   44|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/vote_processor_toml.rs:
    1|       |use crate::consensus::VoteProcessorConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      6|#[derive(Deserialize, Serialize)]
    5|       |pub struct VoteProcessorToml {
    6|       |    pub batch_size: Option<usize>,
    7|       |    pub max_non_pr_queue: Option<usize>,
    8|       |    pub max_pr_queue: Option<usize>,
    9|       |    pub pr_priority: Option<usize>,
   10|       |    pub threads: Option<usize>,
   11|       |    //pub max_triggered: Option<usize>,
   12|       |}
   13|       |
   14|       |impl VoteProcessorConfig {
   15|      1|    pub fn merge_toml(&mut self, toml: &VoteProcessorToml) {
   16|      1|        if let Some(max_pr_queue) = toml.max_pr_queue {
   17|      1|            self.max_pr_queue = max_pr_queue;
   18|      1|        }
                       ^0
   19|      1|        if let Some(max_non_pr_queue) = toml.max_non_pr_queue {
   20|      1|            self.max_non_pr_queue = max_non_pr_queue;
   21|      1|        }
                       ^0
   22|      1|        if let Some(pr_priority) = toml.pr_priority {
   23|      1|            self.pr_priority = pr_priority;
   24|      1|        }
                       ^0
   25|      1|        if let Some(threads) = toml.threads {
   26|      1|            self.threads = threads;
   27|      1|        }
                       ^0
   28|      1|        if let Some(batch_size) = toml.batch_size {
   29|      1|            self.batch_size = batch_size;
   30|      1|        }
                       ^0
   31|       |        //if let Some(max_triggered) = toml.max_triggered {
   32|       |        //self.max_triggered = max_triggered;
   33|       |        //}
   34|      1|    }
   35|       |}
   36|       |
   37|       |impl From<&VoteProcessorConfig> for VoteProcessorToml {
   38|      1|    fn from(config: &VoteProcessorConfig) -> Self {
   39|      1|        Self {
   40|      1|            max_pr_queue: Some(config.max_pr_queue),
   41|      1|            max_non_pr_queue: Some(config.max_non_pr_queue),
   42|      1|            pr_priority: Some(config.pr_priority),
   43|      1|            threads: Some(config.threads),
   44|      1|            batch_size: Some(config.batch_size),
   45|      1|            //max_triggered: Some(config.max_triggered),
   46|      1|        }
   47|      1|    }
   48|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/toml/websocket_toml.rs:
    1|       |use crate::config::websocket_config::WebsocketConfig;
    2|       |use serde::{Deserialize, Serialize};
    3|       |
    4|      4|#[derive(Deserialize, Serialize)]
    5|       |pub struct WebsocketToml {
    6|       |    pub address: Option<String>,
    7|       |    pub enable: Option<bool>,
    8|       |    pub port: Option<u16>,
    9|       |}
   10|       |
   11|       |impl WebsocketConfig {
   12|      1|    pub fn merge_toml(&mut self, toml: &WebsocketToml) {
   13|      1|        if let Some(enabled) = toml.enable {
   14|      1|            self.enabled = enabled;
   15|      1|        }
                       ^0
   16|      1|        if let Some(port) = toml.port {
   17|      1|            self.port = port;
   18|      1|        }
                       ^0
   19|      1|        if let Some(address) = &toml.address {
   20|      1|            self.address = address.clone();
   21|      1|        }
                       ^0
   22|      1|    }
   23|       |}
   24|       |
   25|       |impl From<&WebsocketConfig> for WebsocketToml {
   26|      1|    fn from(websocket_config: &WebsocketConfig) -> Self {
   27|      1|        Self {
   28|      1|            enable: Some(websocket_config.enabled),
   29|      1|            port: Some(websocket_config.port),
   30|      1|            address: Some(websocket_config.address.clone()),
   31|      1|        }
   32|      1|    }
   33|       |}

/home/gustav/code/nano/rsnano-node/node/src/config/websocket_config.rs:
    1|       |use crate::config::NetworkConstants;
    2|       |use std::net::Ipv6Addr;
    3|       |
    4|       |#[derive(Clone, Debug, PartialEq)]
    5|       |pub struct WebsocketConfig {
    6|       |    pub enabled: bool,
    7|       |    pub port: u16,
    8|       |    pub address: String,
    9|       |}
   10|       |
   11|       |impl WebsocketConfig {
   12|     10|    pub fn new(network: &NetworkConstants) -> Self {
   13|     10|        Self {
   14|     10|            enabled: false,
   15|     10|            port: network.default_websocket_port,
   16|     10|            address: Ipv6Addr::LOCALHOST.to_string(),
   17|     10|        }
   18|     10|    }
   19|       |}
   20|       |
   21|       |#[cfg(test)]
   22|       |mod tests {
   23|       |    use super::*;
   24|       |    use rsnano_core::work::WorkThresholds;
   25|       |
   26|       |    #[test]
   27|      1|    fn websocket_config() {
   28|      1|        let cfg = WebsocketConfig::new(&NetworkConstants::new(
   29|      1|            WorkThresholds::publish_full().clone(),
   30|      1|            crate::config::Networks::NanoLiveNetwork,
   31|      1|        ));
   32|      1|        assert_eq!(cfg.enabled, false);
   33|      1|        assert_eq!(cfg.port, 7078);
   34|      1|        assert_eq!(cfg.address, "::1");
   35|      1|    }
   36|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/active_elections.rs:
    1|       |use super::{
    2|       |    confirmation_solicitor::ConfirmationSolicitor, Election, ElectionBehavior, ElectionData,
    3|       |    ElectionState, ElectionStatus, ElectionStatusType, RecentlyConfirmedCache, VoteApplier,
    4|       |    VoteCache, VoteCacheProcessor, VoteGenerators, VoteRouter, NEXT_ELECTION_ID,
    5|       |};
    6|       |use crate::{
    7|       |    block_processing::LedgerNotifications,
    8|       |    cementation::ConfirmingSet,
    9|       |    config::{NodeConfig, NodeFlags},
   10|       |    consensus::VoteApplierExt,
   11|       |    representatives::OnlineReps,
   12|       |    stats::{DetailType, Direction, Sample, StatType, Stats},
   13|       |    transport::MessageFlooder,
   14|       |    utils::HardenedConstants,
   15|       |    wallets::Wallets,
   16|       |    NetworkParams,
   17|       |};
   18|       |use bounded_vec_deque::BoundedVecDeque;
   19|       |use rsnano_core::{
   20|       |    utils::{ContainerInfo, MemoryStream},
   21|       |    Account, Amount, Block, BlockHash, BlockType, MaybeSavedBlock, QualifiedRoot, SavedBlock, Vote,
   22|       |    VoteWithWeightInfo,
   23|       |};
   24|       |use rsnano_ledger::{BlockStatus, Ledger};
   25|       |use rsnano_messages::{Message, NetworkFilter, Publish};
   26|       |use rsnano_network::{Network, TrafficType};
   27|       |use rsnano_nullable_clock::SteadyClock;
   28|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   29|       |use std::{
   30|       |    cmp::{max, min},
   31|       |    collections::{BTreeMap, HashMap},
   32|       |    mem::size_of,
   33|       |    ops::Deref,
   34|       |    sync::{atomic::Ordering, Arc, Condvar, Mutex, MutexGuard, RwLock},
   35|       |    thread::JoinHandle,
   36|       |    time::{Duration, Instant},
   37|       |};
   38|       |use tracing::{debug, trace};
   39|       |
   40|       |const ELECTION_MAX_BLOCKS: usize = 10;
   41|       |
   42|       |pub type ElectionEndCallback = Box<
   43|       |    dyn Fn(&ElectionStatus, &Vec<VoteWithWeightInfo>, Account, &SavedBlock, Amount, bool, bool)
   44|       |        + Send
   45|       |        + Sync,
   46|       |>;
   47|       |
   48|       |#[derive(Clone, Debug, PartialEq)]
   49|       |pub struct ActiveElectionsConfig {
   50|       |    /// Maximum number of simultaneous active elections (AEC size)
   51|       |    pub size: usize,
   52|       |    /// Limit of hinted elections as percentage of `active_elections_size`
   53|       |    pub hinted_limit_percentage: usize,
   54|       |    /// Limit of optimistic elections as percentage of `active_elections_size`
   55|       |    pub optimistic_limit_percentage: usize,
   56|       |    /// Maximum confirmation history size
   57|       |    pub confirmation_history_size: usize,
   58|       |    /// Maximum cache size for recently_confirmed
   59|       |    pub confirmation_cache: usize,
   60|       |    /// Maximum size of election winner details set
   61|       |    pub max_election_winners: usize,
   62|       |}
   63|       |
   64|       |impl Default for ActiveElectionsConfig {
   65|     10|    fn default() -> Self {
   66|     10|        Self {
   67|     10|            size: 5000,
   68|     10|            hinted_limit_percentage: 20,
   69|     10|            optimistic_limit_percentage: 10,
   70|     10|            confirmation_history_size: 2048,
   71|     10|            confirmation_cache: 65536,
   72|     10|            max_election_winners: 1024 * 16,
   73|     10|        }
   74|     10|    }
   75|       |}
   76|       |
   77|       |pub struct ActiveElections {
   78|       |    steady_clock: Arc<SteadyClock>,
   79|       |    mutex: Mutex<ActiveElectionsState>,
   80|       |    condition: Condvar,
   81|       |    network_params: NetworkParams,
   82|       |    wallets: Arc<Wallets>,
   83|       |    node_config: NodeConfig,
   84|       |    config: ActiveElectionsConfig,
   85|       |    ledger: Arc<Ledger>,
   86|       |    confirming_set: Arc<ConfirmingSet>,
   87|       |    pub recently_confirmed: Arc<RecentlyConfirmedCache>,
   88|       |    /// Helper container for storing recently cemented elections (a block from election might be confirmed but not yet cemented by confirmation height processor)
   89|       |    recently_cemented: Arc<Mutex<BoundedVecDeque<ElectionStatus>>>,
   90|       |    notifications: LedgerNotifications,
   91|       |    vote_generators: Arc<VoteGenerators>,
   92|       |    network_filter: Arc<NetworkFilter>,
   93|       |    network: Arc<RwLock<Network>>,
   94|       |    vote_cache: Arc<Mutex<VoteCache>>,
   95|       |    stats: Arc<Stats>,
   96|       |    active_started_observer: Mutex<Vec<Box<dyn Fn(BlockHash) + Send + Sync>>>,
   97|       |    active_stopped_observer: Mutex<Vec<Box<dyn Fn(BlockHash) + Send + Sync>>>,
   98|       |    election_ended_observers: RwLock<Vec<ElectionEndCallback>>,
   99|       |    online_reps: Arc<Mutex<OnlineReps>>,
  100|       |    thread: Mutex<Option<JoinHandle<()>>>,
  101|       |    flags: NodeFlags,
  102|       |    pub vote_applier: Arc<VoteApplier>,
  103|       |    pub vote_router: Arc<VoteRouter>,
  104|       |    vote_cache_processor: Arc<VoteCacheProcessor>,
  105|       |    message_flooder: Mutex<MessageFlooder>,
  106|       |    vacancy_updated_observers: RwLock<Vec<Box<dyn Fn() + Send + Sync>>>,
  107|       |}
  108|       |
  109|       |impl ActiveElections {
  110|      3|    pub(crate) fn new(
  111|      3|        network_params: NetworkParams,
  112|      3|        wallets: Arc<Wallets>,
  113|      3|        node_config: NodeConfig,
  114|      3|        ledger: Arc<Ledger>,
  115|      3|        confirming_set: Arc<ConfirmingSet>,
  116|      3|        notifications: LedgerNotifications,
  117|      3|        vote_generators: Arc<VoteGenerators>,
  118|      3|        network_filter: Arc<NetworkFilter>,
  119|      3|        network: Arc<RwLock<Network>>,
  120|      3|        vote_cache: Arc<Mutex<VoteCache>>,
  121|      3|        stats: Arc<Stats>,
  122|      3|        online_reps: Arc<Mutex<OnlineReps>>,
  123|      3|        flags: NodeFlags,
  124|      3|        recently_confirmed: Arc<RecentlyConfirmedCache>,
  125|      3|        vote_applier: Arc<VoteApplier>,
  126|      3|        vote_router: Arc<VoteRouter>,
  127|      3|        vote_cache_processor: Arc<VoteCacheProcessor>,
  128|      3|        steady_clock: Arc<SteadyClock>,
  129|      3|        message_flooder: MessageFlooder,
  130|      3|    ) -> Self {
  131|      3|        Self {
  132|      3|            mutex: Mutex::new(ActiveElectionsState {
  133|      3|                roots: OrderedRoots::default(),
  134|      3|                stopped: false,
  135|      3|                manual_count: 0,
  136|      3|                priority_count: 0,
  137|      3|                hinted_count: 0,
  138|      3|                optimistic_count: 0,
  139|      3|            }),
  140|      3|            condition: Condvar::new(),
  141|      3|            network_params,
  142|      3|            wallets,
  143|      3|            ledger,
  144|      3|            confirming_set,
  145|      3|            recently_confirmed,
  146|      3|            recently_cemented: Arc::new(Mutex::new(BoundedVecDeque::new(
  147|      3|                node_config.active_elections.confirmation_history_size,
  148|      3|            ))),
  149|      3|            config: node_config.active_elections.clone(),
  150|      3|            node_config,
  151|      3|            notifications,
  152|      3|            vote_generators,
  153|      3|            network_filter,
  154|      3|            network,
  155|      3|            vote_cache,
  156|      3|            stats,
  157|      3|            active_started_observer: Mutex::new(Vec::new()),
  158|      3|            active_stopped_observer: Mutex::new(Vec::new()),
  159|      3|            election_ended_observers: RwLock::new(Vec::new()),
  160|      3|            online_reps,
  161|      3|            thread: Mutex::new(None),
  162|      3|            flags,
  163|      3|            vote_applier,
  164|      3|            vote_router,
  165|      3|            vote_cache_processor,
  166|      3|            steady_clock,
  167|      3|            message_flooder: Mutex::new(message_flooder),
  168|      3|            vacancy_updated_observers: RwLock::new(Vec::new()),
  169|      3|        }
  170|      3|    }
  171|       |
  172|      0|    pub fn len(&self) -> usize {
  173|      0|        self.mutex.lock().unwrap().roots.len()
  174|      0|    }
  175|       |
  176|      0|    pub fn info(&self) -> ActiveElectionsInfo {
  177|      0|        let guard = self.mutex.lock().unwrap();
  178|      0|        ActiveElectionsInfo {
  179|      0|            max_queue: self.config.size,
  180|      0|            total: guard.roots.len(),
  181|      0|            priority: guard.priority_count,
  182|      0|            hinted: guard.hinted_count,
  183|      0|            optimistic: guard.optimistic_count,
  184|      0|        }
  185|      0|    }
  186|       |
  187|      0|    pub fn on_election_ended(&self, f: ElectionEndCallback) {
  188|      0|        self.election_ended_observers.write().unwrap().push(f);
  189|      0|    }
  190|       |
  191|      0|    pub fn on_active_started(&self, f: Box<dyn Fn(BlockHash) + Send + Sync>) {
  192|      0|        self.active_started_observer.lock().unwrap().push(f);
  193|      0|    }
  194|       |
  195|      0|    pub fn on_active_stopped(&self, f: Box<dyn Fn(BlockHash) + Send + Sync>) {
  196|      0|        self.active_stopped_observer.lock().unwrap().push(f);
  197|      0|    }
  198|       |
  199|      3|    pub fn on_vacancy_updated(&self, f: Box<dyn Fn() + Send + Sync>) {
  200|      3|        self.vacancy_updated_observers.write().unwrap().push(f);
  201|      3|    }
  202|       |
  203|      0|    pub fn clear_recently_confirmed(&self) {
  204|      0|        self.recently_confirmed.clear();
  205|      0|    }
  206|       |
  207|      0|    pub fn recently_confirmed_count(&self) -> usize {
  208|      0|        self.recently_confirmed.len()
  209|      0|    }
  210|       |
  211|      0|    pub fn recently_cemented_count(&self) -> usize {
  212|      0|        self.recently_cemented.lock().unwrap().len()
  213|      0|    }
  214|       |
  215|      0|    pub fn was_recently_confirmed(&self, hash: &BlockHash) -> bool {
  216|      0|        self.recently_confirmed.hash_exists(hash)
  217|      0|    }
  218|       |
  219|      0|    pub fn latest_recently_confirmed(&self) -> Option<(QualifiedRoot, BlockHash)> {
  220|      0|        self.recently_confirmed.back()
  221|      0|    }
  222|       |
  223|      0|    pub fn insert_recently_confirmed(&self, block: &Block) {
  224|      0|        self.recently_confirmed
  225|      0|            .put(block.qualified_root(), block.hash());
  226|      0|    }
  227|       |
  228|      0|    pub fn insert_recently_cemented(&self, status: ElectionStatus) {
  229|      0|        let MaybeSavedBlock::Saved(block) = status.winner.as_ref().unwrap() else {
  230|      0|            return;
  231|       |        };
  232|      0|        self.recently_cemented
  233|      0|            .lock()
  234|      0|            .unwrap()
  235|      0|            .push_back(status.clone());
  236|      0|
  237|      0|        // Trigger callback for confirmed block
  238|      0|        let account = block.account();
  239|      0|        let amount = {
  240|      0|            let txn = self.ledger.read_txn();
  241|      0|            self.ledger.any().block_amount_for(&txn, &block)
  242|      0|        };
  243|      0|        let mut is_state_send = false;
  244|      0|        let mut is_state_epoch = false;
  245|      0|        if amount.is_some() {
  246|      0|            if block.block_type() == BlockType::State {
  247|      0|                is_state_send = block.is_send();
  248|      0|                is_state_epoch = block.is_epoch();
  249|      0|            }
  250|      0|        }
  251|       |
  252|      0|        let callbacks = self.election_ended_observers.read().unwrap();
  253|      0|        for callback in callbacks.iter() {
  254|      0|            (callback)(
  255|      0|                &status,
  256|      0|                &Vec::new(),
  257|      0|                account,
  258|      0|                block,
  259|      0|                amount.unwrap_or_default(),
  260|      0|                is_state_send,
  261|      0|                is_state_epoch,
  262|      0|            );
  263|      0|        }
  264|      0|    }
  265|       |
  266|      0|    pub fn recently_cemented_list(&self) -> BoundedVecDeque<ElectionStatus> {
  267|      0|        self.recently_cemented.lock().unwrap().clone()
  268|      0|    }
  269|       |
  270|       |    //--------------------------------------------------------------------------------
  271|       |
  272|      0|    pub fn notify_observers(
  273|      0|        &self,
  274|      0|        tx: &LmdbReadTransaction,
  275|      0|        status: &ElectionStatus,
  276|      0|        votes: &Vec<VoteWithWeightInfo>,
  277|      0|    ) {
  278|      0|        let block = status.winner.as_ref().unwrap();
  279|      0|        let MaybeSavedBlock::Saved(block) = block else {
  280|      0|            return;
  281|       |        };
  282|      0|        let account = block.account();
  283|      0|
  284|      0|        match status.election_status_type {
  285|      0|            ElectionStatusType::ActiveConfirmedQuorum => self.stats.inc_dir(
  286|      0|                StatType::ConfirmationObserver,
  287|      0|                DetailType::ActiveQuorum,
  288|      0|                Direction::Out,
  289|      0|            ),
  290|      0|            ElectionStatusType::ActiveConfirmationHeight => self.stats.inc_dir(
  291|      0|                StatType::ConfirmationObserver,
  292|      0|                DetailType::ActiveConfHeight,
  293|      0|                Direction::Out,
  294|      0|            ),
  295|      0|            ElectionStatusType::InactiveConfirmationHeight => self.stats.inc_dir(
  296|      0|                StatType::ConfirmationObserver,
  297|      0|                DetailType::InactiveConfHeight,
  298|      0|                Direction::Out,
  299|      0|            ),
  300|      0|            _ => {}
  301|       |        }
  302|       |
  303|      0|        let ended_callbacks = self.election_ended_observers.read().unwrap();
  304|      0|        if ended_callbacks.is_empty() {
  305|      0|            return;
  306|      0|        }
  307|      0|
  308|      0|        let amount = self
  309|      0|            .ledger
  310|      0|            .any()
  311|      0|            .block_amount_for(tx, &block)
  312|      0|            .unwrap_or_default();
  313|      0|
  314|      0|        let mut is_state_send = false;
  315|      0|        let mut is_state_epoch = false;
  316|      0|        if block.block_type() == BlockType::State {
  317|      0|            is_state_send = block.block_type() == BlockType::State && block.is_send();
  318|      0|            is_state_epoch = block.block_type() == BlockType::State && block.is_epoch();
  319|      0|        }
  320|       |
  321|      0|        for callback in ended_callbacks.iter() {
  322|      0|            (callback)(
  323|      0|                status,
  324|      0|                votes,
  325|      0|                account,
  326|      0|                block,
  327|      0|                amount,
  328|      0|                is_state_send,
  329|      0|                is_state_epoch,
  330|      0|            );
  331|      0|        }
  332|      0|    }
  333|       |
  334|      3|    fn request_loop2<'a>(
  335|      3|        &self,
  336|      3|        stamp: Instant,
  337|      3|        guard: MutexGuard<'a, ActiveElectionsState>,
  338|      3|    ) -> MutexGuard<'a, ActiveElectionsState> {
  339|      3|        if !guard.stopped {
  340|      3|            let loop_interval = self.network_params.network.aec_loop_interval;
  341|      3|            let min_sleep = loop_interval / 2;
  342|      3|
  343|      3|            let wait_duration = max(
  344|      3|                min_sleep,
  345|      3|                (stamp + loop_interval).saturating_duration_since(Instant::now()),
  346|      3|            );
  347|      3|
  348|      3|            self.condition
  349|      6|                .wait_timeout_while(guard, wait_duration, |data| !data.stopped)
  350|      3|                .unwrap()
  351|      3|                .0
  352|       |        } else {
  353|      0|            guard
  354|       |        }
  355|      3|    }
  356|       |
  357|      0|    pub fn remove_block(&self, election_guard: &mut MutexGuard<ElectionData>, hash: &BlockHash) {
  358|      0|        if election_guard.status.winner.as_ref().unwrap().hash() != *hash {
  359|      0|            if let Some(existing) = election_guard.last_blocks.remove(hash) {
  360|      0|                election_guard.last_votes.retain(|_, v| v.hash != *hash);
  361|      0|                self.clear_publish_filter(&existing);
  362|      0|            }
  363|      0|        }
  364|      0|    }
  365|       |
  366|      0|    fn clear_publish_filter(&self, block: &Block) {
  367|      0|        let mut buf = MemoryStream::new();
  368|      0|        block.serialize_without_block_type(&mut buf);
  369|      0|        self.network_filter.clear_bytes(buf.as_bytes());
  370|      0|    }
  371|       |
  372|       |    /// Maximum number of elections that should be present in this container
  373|       |    /// NOTE: This is only a soft limit, it is possible for this container to exceed this count
  374|     18|    pub fn limit(&self, behavior: ElectionBehavior) -> usize {
  375|     18|        match behavior {
  376|      0|            ElectionBehavior::Manual => usize::MAX,
  377|      0|            ElectionBehavior::Priority => self.config.size,
  378|       |            ElectionBehavior::Hinted => {
  379|     12|                self.config.hinted_limit_percentage * self.config.size / 100
  380|       |            }
  381|       |            ElectionBehavior::Optimistic => {
  382|      6|                self.config.optimistic_limit_percentage * self.config.size / 100
  383|       |            }
  384|       |        }
  385|     18|    }
  386|       |
  387|       |    /// How many election slots are available for specified election type
  388|     12|    pub fn vacancy(&self, behavior: ElectionBehavior) -> i64 {
  389|     12|        let election_vacancy = self.election_vacancy(behavior);
  390|     12|        let winners_vacancy = self.election_winners_vacancy();
  391|     12|        min(election_vacancy, winners_vacancy)
  392|     12|    }
  393|       |
  394|     12|    fn election_vacancy(&self, behavior: ElectionBehavior) -> i64 {
  395|     12|        let guard = self.mutex.lock().unwrap();
  396|     12|        match behavior {
  397|      0|            ElectionBehavior::Manual => i64::MAX,
  398|       |            ElectionBehavior::Priority => {
  399|      0|                self.limit(ElectionBehavior::Priority) as i64 - guard.roots.len() as i64
  400|       |            }
  401|       |            ElectionBehavior::Hinted | ElectionBehavior::Optimistic => {
  402|     12|                self.limit(behavior) as i64 - guard.count_by_behavior(behavior) as i64
  403|       |            }
  404|       |        }
  405|     12|    }
  406|       |
  407|     12|    fn election_winners_vacancy(&self) -> i64 {
  408|     12|        self.config.max_election_winners as i64 - self.confirming_set.len() as i64
  409|     12|    }
  410|       |
  411|      3|    pub fn clear(&self) {
  412|      3|        // TODO: Call erased_callback for each election
  413|      3|        {
  414|      3|            let mut guard = self.mutex.lock().unwrap();
  415|      3|            guard.roots.clear();
  416|      3|        }
  417|      3|
  418|      3|        self.vacancy_updated();
  419|      3|    }
  420|       |
  421|       |    /// Notify election schedulers when AEC frees election slot
  422|      3|    fn vacancy_updated(&self) {
  423|      3|        let guard = self.vacancy_updated_observers.read().unwrap();
  424|      3|        for observer in &*guard {
  425|      3|            observer();
  426|      3|        }
  427|      3|    }
  428|       |
  429|      0|    pub fn active_root(&self, root: &QualifiedRoot) -> bool {
  430|      0|        let guard = self.mutex.lock().unwrap();
  431|      0|        guard.roots.get(root).is_some()
  432|      0|    }
  433|       |
  434|      0|    pub fn active(&self, block: &Block) -> bool {
  435|      0|        self.active_root(&block.qualified_root())
  436|      0|    }
  437|       |
  438|      0|    pub fn replace_by_weight<'a>(
  439|      0|        &self,
  440|      0|        election: &'a Election,
  441|      0|        mut election_guard: MutexGuard<'a, ElectionData>,
  442|      0|        hash: &BlockHash,
  443|      0|    ) -> (bool, MutexGuard<'a, ElectionData>) {
  444|      0|        let mut replaced_block = BlockHash::zero();
  445|      0|        let winner_hash = election_guard.status.winner.as_ref().unwrap().hash();
  446|      0|        // Sort existing blocks tally
  447|      0|        let mut sorted: Vec<_> = election_guard
  448|      0|            .last_tally
  449|      0|            .iter()
  450|      0|            .map(|(hash, amount)| (*hash, *amount))
  451|      0|            .collect();
  452|      0|        drop(election_guard);
  453|      0|
  454|      0|        // Sort in ascending order
  455|      0|        sorted.sort_by(|left, right| right.cmp(left));
  456|      0|
  457|      0|        let votes_tally = |votes: &[Arc<Vote>]| {
  458|      0|            let mut result = Amount::zero();
  459|      0|            for vote in votes {
  460|      0|                result += self.ledger.weight(&vote.voting_account);
  461|      0|            }
  462|      0|            result
  463|      0|        };
  464|       |
  465|       |        // Replace if lowest tally is below inactive cache new block weight
  466|      0|        let inactive_existing = self.vote_cache.lock().unwrap().find(hash);
  467|      0|        let inactive_tally = votes_tally(&inactive_existing);
  468|      0|        if inactive_tally > Amount::zero() && sorted.len() < ELECTION_MAX_BLOCKS {
  469|       |            // If count of tally items is less than 10, remove any block without tally
  470|      0|            let guard = election.mutex.lock().unwrap();
  471|      0|            for (hash, _) in &guard.last_blocks {
  472|      0|                if sorted.iter().all(|(h, _)| h != hash) && *hash != winner_hash {
  473|      0|                    replaced_block = *hash;
  474|      0|                    break;
  475|      0|                }
  476|       |            }
  477|      0|        } else if inactive_tally > Amount::zero() && inactive_tally > sorted.first().unwrap().1 {
  478|      0|            if sorted.first().unwrap().0 != winner_hash {
  479|      0|                replaced_block = sorted[0].0;
  480|      0|            } else if inactive_tally > sorted[1].1 {
  481|      0|                // Avoid removing winner
  482|      0|                replaced_block = sorted[1].0;
  483|      0|            }
  484|      0|        }
  485|       |
  486|      0|        let mut replaced = false;
  487|      0|        if !replaced_block.is_zero() {
  488|      0|            self.vote_router.disconnect(&replaced_block);
  489|      0|            election_guard = election.mutex.lock().unwrap();
  490|      0|            self.remove_block(&mut election_guard, &replaced_block);
  491|      0|            replaced = true;
  492|      0|        } else {
  493|      0|            election_guard = election.mutex.lock().unwrap();
  494|      0|        }
  495|      0|        (replaced, election_guard)
  496|      0|    }
  497|       |
  498|      0|    fn publish(&self, block: &Block, election: &Election) -> bool {
  499|      0|        let mut election_guard = election.mutex.lock().unwrap();
  500|      0|
  501|      0|        // Do not insert new blocks if already confirmed
  502|      0|        let mut result = election_guard.is_confirmed();
  503|      0|        if !result
  504|      0|            && election_guard.last_blocks.len() >= ELECTION_MAX_BLOCKS
  505|      0|            && !election_guard.last_blocks.contains_key(&block.hash())
  506|       |        {
  507|      0|            let (replaced, guard) = self.replace_by_weight(election, election_guard, &block.hash());
  508|      0|            election_guard = guard;
  509|      0|            if !replaced {
  510|      0|                result = true;
  511|      0|                self.clear_publish_filter(block);
  512|      0|            }
  513|      0|        }
  514|      0|        if !result {
  515|      0|            if election_guard.last_blocks.get(&block.hash()).is_some() {
  516|      0|                result = true;
  517|      0|                election_guard
  518|      0|                    .last_blocks
  519|      0|                    .insert(block.hash(), MaybeSavedBlock::Unsaved(block.clone()));
  520|      0|                if election_guard.status.winner.as_ref().unwrap().hash() == block.hash() {
  521|      0|                    election_guard.status.winner = Some(MaybeSavedBlock::Unsaved(block.clone()));
  522|      0|                    let message = Message::Publish(Publish::new_forward(block.clone()));
  523|      0|                    let mut publisher = self.message_flooder.lock().unwrap();
  524|      0|                    publisher.flood(&message, TrafficType::BlockBroadcast, 1.0);
  525|      0|                }
  526|      0|            } else {
  527|      0|                election_guard
  528|      0|                    .last_blocks
  529|      0|                    .insert(block.hash(), MaybeSavedBlock::Unsaved(block.clone()));
  530|      0|            }
  531|      0|        }
  532|       |        /*
  533|       |        Result is true if:
  534|       |        1) election is confirmed or expired
  535|       |        2) given election contains 10 blocks & new block didn't receive enough votes to replace existing blocks
  536|       |        3) given block in already in election & election contains less than 10 blocks (replacing block content with new)
  537|       |        */
  538|      0|        result
  539|      0|    }
  540|       |
  541|       |    /// Broadcasts vote for the current winner of this election
  542|       |    /// Checks if sufficient amount of time (`vote_generation_interval`) passed since the last vote generation
  543|      0|    pub fn broadcast_vote(
  544|      0|        &self,
  545|      0|        election: &Election,
  546|      0|        election_guard: &mut MutexGuard<ElectionData>,
  547|      0|    ) {
  548|      0|        if election_guard.last_vote_elapsed() >= self.network_params.network.vote_broadcast_interval
  549|      0|        {
  550|      0|            self.broadcast_vote_locked(election_guard, election);
  551|      0|            election_guard.set_last_vote();
  552|      0|        }
  553|      0|    }
  554|       |
  555|      0|    pub fn broadcast_block(
  556|      0|        &self,
  557|      0|        solicitor: &mut ConfirmationSolicitor,
  558|      0|        election: &Election,
  559|      0|        election_guard: &mut MutexGuard<ElectionData>,
  560|      0|    ) {
  561|      0|        if self.broadcast_block_predicate(election, election_guard) {
  562|      0|            if solicitor.broadcast(election_guard).is_ok() {
  563|      0|                let last_block_hash = election_guard.last_block_hash;
  564|      0|                election.set_last_block();
  565|      0|                election_guard.last_block_hash =
  566|      0|                    election_guard.status.winner.as_ref().unwrap().hash();
  567|      0|
  568|      0|                self.stats.inc(
  569|      0|                    StatType::Election,
  570|      0|                    if last_block_hash.is_zero() {
  571|      0|                        DetailType::BroadcastBlockInitial
  572|       |                    } else {
  573|      0|                        DetailType::BroadcastBlockRepeat
  574|       |                    },
  575|       |                );
  576|      0|            }
  577|      0|        }
  578|      0|    }
  579|       |
  580|       |    /// Broadcast vote for current election winner. Generates final vote if reached quorum or already confirmed
  581|       |    /// Requires mutex lock
  582|      0|    pub fn broadcast_vote_locked(
  583|      0|        &self,
  584|      0|        election_guard: &mut MutexGuard<ElectionData>,
  585|      0|        election: &Election,
  586|      0|    ) {
  587|      0|        let last_vote_elapsed = election_guard.last_vote_elapsed();
  588|      0|        if last_vote_elapsed < self.network_params.network.vote_broadcast_interval {
  589|      0|            return;
  590|      0|        }
  591|      0|        election_guard.set_last_vote();
  592|      0|        if self.node_config.enable_voting && self.wallets.voting_reps_count() > 0 {
  593|      0|            self.stats
  594|      0|                .inc(StatType::Election, DetailType::BroadcastVote);
  595|      0|            election_guard.status.vote_broadcast_count += 1;
  596|      0|
  597|      0|            if election_guard.is_confirmed()
  598|      0|                || self
  599|      0|                    .vote_applier
  600|      0|                    .have_quorum(&self.vote_applier.tally_impl(election_guard))
  601|       |            {
  602|      0|                self.stats
  603|      0|                    .inc(StatType::Election, DetailType::GenerateVoteFinal);
  604|      0|                let winner = election_guard.status.winner.as_ref().unwrap().hash();
  605|      0|                trace!(qualified_root = ?election.qualified_root, %winner, "type" = "final", "broadcast vote");
  606|      0|                self.vote_generators
  607|      0|                    .generate_final_vote(&election.root, &winner); // Broadcasts vote to the network
  608|       |            } else {
  609|      0|                self.stats
  610|      0|                    .inc(StatType::Election, DetailType::GenerateVoteNormal);
  611|      0|                let winner = election_guard.status.winner.as_ref().unwrap().hash();
  612|      0|                trace!(qualified_root = ?election.qualified_root, %winner, "type" = "normal", "broadcast vote");
  613|      0|                self.vote_generators
  614|      0|                    .generate_non_final_vote(&election.root, &winner); // Broadcasts vote to the network
  615|       |            }
  616|      0|        }
  617|      0|    }
  618|       |
  619|       |    /// Erase all blocks from active and, if not confirmed, clear digests from network filters
  620|      0|    fn cleanup_election<'a>(
  621|      0|        &self,
  622|      0|        mut guard: MutexGuard<'a, ActiveElectionsState>,
  623|      0|        election: &'a Arc<Election>,
  624|      0|    ) {
  625|      0|        // Keep track of election count by election type
  626|      0|        debug_assert!(guard.count_by_behavior(election.behavior()) > 0);
  627|      0|        *guard.count_by_behavior_mut(election.behavior()) -= 1;
  628|      0|
  629|      0|        let election_winner: BlockHash;
  630|      0|        let election_state;
  631|      0|        let blocks;
  632|      0|        {
  633|      0|            let election_guard = election.mutex.lock().unwrap();
  634|      0|            blocks = election_guard.last_blocks.clone();
  635|      0|            election_winner = election_guard.status.winner.as_ref().unwrap().hash();
  636|      0|            election_state = election_guard.state;
  637|      0|        }
  638|      0|
  639|      0|        self.vote_router.disconnect_election(election);
  640|      0|
  641|      0|        // Erase root info
  642|      0|        let entry = guard
  643|      0|            .roots
  644|      0|            .erase(&election.qualified_root)
  645|      0|            .expect("election not found");
  646|      0|
  647|      0|        let state = election.state();
  648|      0|        self.stats
  649|      0|            .inc(StatType::ActiveElections, DetailType::Stopped);
  650|      0|        self.stats.inc(
  651|      0|            StatType::ActiveElections,
  652|      0|            if state.is_confirmed() {
  653|      0|                DetailType::Confirmed
  654|       |            } else {
  655|      0|                DetailType::Unconfirmed
  656|       |            },
  657|       |        );
  658|      0|        self.stats
  659|      0|            .inc(StatType::ActiveElectionsStopped, state.into());
  660|      0|        self.stats.inc(state.into(), election.behavior().into());
  661|      0|
  662|      0|        trace!(election = ?election, "active stopped");
  663|       |
  664|      0|        debug!(
  665|      0|            "Erased election for blocks: {} (behavior: {:?}, state: {:?})",
  666|      0|            blocks
  667|      0|                .keys()
  668|      0|                .map(|k| k.to_string())
  669|      0|                .collect::<Vec<_>>()
  670|      0|                .join(", "),
  671|      0|            election.behavior(),
  672|       |            election_state
  673|       |        );
  674|       |
  675|      0|        drop(guard);
  676|      0|
  677|      0|        // Track election duration
  678|      0|        self.stats.sample(
  679|      0|            Sample::ActiveElectionDuration,
  680|      0|            election.duration().as_millis() as i64,
  681|      0|            (0, 1000 * 60 * 10),
  682|      0|        ); // 0-10 minutes range
  683|       |
  684|       |        // Notify observers without holding the lock
  685|      0|        if let Some(callback) = entry.erased_callback {
  686|      0|            callback(election)
  687|      0|        }
  688|       |
  689|      0|        self.vacancy_updated();
  690|       |
  691|      0|        for (hash, block) in blocks {
  692|       |            // Notify observers about dropped elections & blocks lost confirmed elections
  693|      0|            if !self.confirmed(election) || hash != election_winner {
  694|      0|                let callbacks = self.active_stopped_observer.lock().unwrap();
  695|      0|                for callback in callbacks.iter() {
  696|      0|                    (callback)(hash);
  697|      0|                }
  698|      0|            }
  699|       |
  700|      0|            if !self.confirmed(election) {
  701|      0|                // Clear from publish filter
  702|      0|                self.clear_publish_filter(&block);
  703|      0|            }
  704|       |        }
  705|      0|    }
  706|       |
  707|      0|    pub fn confirmed(&self, election: &Election) -> bool {
  708|      0|        election.mutex.lock().unwrap().is_confirmed()
  709|      0|    }
  710|       |
  711|       |    /// Minimum time between broadcasts of the current winner of an election, as a backup to requesting confirmations
  712|      0|    fn base_latency(&self) -> Duration {
  713|      0|        if self.network_params.network.is_dev_network() {
  714|      0|            Duration::from_millis(25)
  715|       |        } else {
  716|      0|            Duration::from_millis(1000)
  717|       |        }
  718|      0|    }
  719|       |
  720|       |    /// Calculates time delay between broadcasting confirmation requests
  721|      0|    fn confirm_req_time(&self, election_data: &ElectionData) -> Duration {
  722|      0|        match election_data.behavior {
  723|       |            ElectionBehavior::Priority | ElectionBehavior::Manual | ElectionBehavior::Hinted => {
  724|      0|                self.base_latency() * 5
  725|       |            }
  726|      0|            ElectionBehavior::Optimistic => self.base_latency() * 2,
  727|       |        }
  728|      0|    }
  729|       |
  730|      0|    pub fn broadcast_block_predicate(
  731|      0|        &self,
  732|      0|        election: &Election,
  733|      0|        election_guard: &MutexGuard<ElectionData>,
  734|      0|    ) -> bool {
  735|      0|        // Broadcast the block if enough time has passed since the last broadcast (or it's the first broadcast)
  736|      0|        if election.last_block_elapsed() < self.network_params.network.block_broadcast_interval {
  737|      0|            true
  738|       |        }
  739|       |        // Or the current election winner has changed
  740|      0|        else if election_guard.status.winner.as_ref().unwrap().hash()
  741|      0|            != election_guard.last_block_hash
  742|       |        {
  743|      0|            true
  744|       |        } else {
  745|      0|            false
  746|       |        }
  747|      0|    }
  748|       |
  749|      0|    pub fn election(&self, root: &QualifiedRoot) -> Option<Arc<Election>> {
  750|      0|        let guard = self.mutex.lock().unwrap();
  751|      0|        guard.election(root)
  752|      0|    }
  753|       |
  754|      0|    pub fn votes_with_weight(&self, election: &Election) -> Vec<VoteWithWeightInfo> {
  755|      0|        let mut sorted_votes: BTreeMap<TallyKey, Vec<VoteWithWeightInfo>> = BTreeMap::new();
  756|      0|        let guard = election.mutex.lock().unwrap();
  757|      0|        for (&representative, info) in &guard.last_votes {
  758|      0|            if representative == HardenedConstants::get().not_an_account_key {
  759|      0|                continue;
  760|      0|            }
  761|      0|            let weight = self.ledger.weight(&representative);
  762|      0|            let vote_with_weight = VoteWithWeightInfo {
  763|      0|                representative,
  764|      0|                time: info.time,
  765|      0|                timestamp: info.timestamp,
  766|      0|                hash: info.hash,
  767|      0|                weight,
  768|      0|            };
  769|      0|            sorted_votes
  770|      0|                .entry(TallyKey(weight))
  771|      0|                .or_default()
  772|      0|                .push(vote_with_weight);
  773|       |        }
  774|      0|        let result: Vec<_> = sorted_votes
  775|      0|            .values_mut()
  776|      0|            .map(|i| std::mem::take(i))
  777|      0|            .flatten()
  778|      0|            .collect();
  779|      0|        result
  780|      0|    }
  781|       |
  782|      3|    pub fn request_loop(&self) {
  783|      3|        let mut guard = self.mutex.lock().unwrap();
  784|      6|        while !guard.stopped {
  785|      3|            let stamp = Instant::now();
  786|      3|            self.stats.inc(StatType::Active, DetailType::Loop);
  787|      3|            guard = self.request_confirm(guard);
  788|      3|            guard = self.request_loop2(stamp, guard);
  789|      3|        }
  790|      3|    }
  791|       |
  792|      3|    fn request_confirm<'a>(
  793|      3|        &'a self,
  794|      3|        guard: MutexGuard<'a, ActiveElectionsState>,
  795|      3|    ) -> MutexGuard<'a, ActiveElectionsState> {
  796|      3|        let this_loop_target = guard.roots.len();
  797|      3|        let elections = Self::list_active_impl(this_loop_target, &guard);
  798|      3|        drop(guard);
  799|      3|
  800|      3|        let publisher = self.message_flooder.lock().unwrap().clone();
  801|      3|        let mut solicitor =
  802|      3|            ConfirmationSolicitor::new(&self.network_params, &self.network, publisher);
  803|      3|        let peered_prs = self.online_reps.lock().unwrap().peered_principal_reps();
  804|      3|        solicitor.prepare(&peered_prs);
  805|       |
  806|       |        /*
  807|       |         * Loop through active elections in descending order of proof-of-work difficulty, requesting confirmation
  808|       |         *
  809|       |         * Only up to a certain amount of elections are queued for confirmation request and block rebroadcasting. The remaining elections can still be confirmed if votes arrive
  810|       |         * Elections extending the soft config.size limit are flushed after a certain time-to-live cutoff
  811|       |         * Flushed elections are later re-activated via frontier confirmation
  812|       |         */
  813|      3|        for election in elections {
                          ^0
  814|      0|            if self.transition_time(&mut solicitor, &election) {
  815|      0|                self.erase(&election.qualified_root);
  816|      0|            }
  817|       |        }
  818|       |
  819|      3|        solicitor.flush();
  820|      3|        self.mutex.lock().unwrap()
  821|      3|    }
  822|       |
  823|       |    // Returns a list of elections sorted by difficulty
  824|      0|    pub fn list_active(&self, max: usize) -> Vec<Arc<Election>> {
  825|      0|        self.mutex
  826|      0|            .lock()
  827|      0|            .unwrap()
  828|      0|            .roots
  829|      0|            .iter_sequenced()
  830|      0|            .map(|i| i.election.clone())
  831|      0|            .take(max)
  832|      0|            .collect()
  833|      0|    }
  834|       |
  835|       |    /// Returns a list of elections sorted by difficulty, mutex must be locked
  836|      3|    fn list_active_impl(
  837|      3|        max: usize,
  838|      3|        guard: &MutexGuard<ActiveElectionsState>,
  839|      3|    ) -> Vec<Arc<Election>> {
  840|      3|        guard
  841|      3|            .roots
  842|      3|            .iter_sequenced()
  843|      3|            .map(|i| i.election.clone())
                                   ^0
  844|      3|            .take(max)
  845|      3|            .collect()
  846|      3|    }
  847|       |
  848|      0|    pub fn erase(&self, root: &QualifiedRoot) -> bool {
  849|      0|        let guard = self.mutex.lock().unwrap();
  850|      0|        if let Some(entry) = guard.roots.get(root) {
  851|      0|            let election = entry.election.clone();
  852|      0|            self.cleanup_election(guard, &election);
  853|      0|            true
  854|       |        } else {
  855|      0|            false
  856|       |        }
  857|      0|    }
  858|       |
  859|      0|    fn transition_time(
  860|      0|        &self,
  861|      0|        solicitor: &mut ConfirmationSolicitor,
  862|      0|        election: &Arc<Election>,
  863|      0|    ) -> bool {
  864|      0|        let mut guard = election.mutex.lock().unwrap();
  865|      0|        let mut result = false;
  866|      0|        match guard.state {
  867|       |            ElectionState::Passive => {
  868|      0|                if self.base_latency() * Election::PASSIVE_DURATION_FACTOR
  869|      0|                    < election.election_start.elapsed()
  870|      0|                {
  871|      0|                    guard
  872|      0|                        .state_change(ElectionState::Passive, ElectionState::Active)
  873|      0|                        .unwrap();
  874|      0|                }
  875|       |            }
  876|      0|            ElectionState::Active => {
  877|      0|                self.broadcast_vote(election, &mut guard);
  878|      0|                self.broadcast_block(solicitor, election, &mut guard);
  879|      0|                self.send_confirm_req(solicitor, election, &guard);
  880|      0|            }
  881|      0|            ElectionState::Confirmed => {
  882|      0|                result = true; // Return true to indicate this election should be cleaned up
  883|      0|                self.broadcast_block(solicitor, election, &mut guard); // Ensure election winner is broadcasted
  884|      0|                guard
  885|      0|                    .state_change(ElectionState::Confirmed, ElectionState::ExpiredConfirmed)
  886|      0|                    .unwrap();
  887|      0|            }
  888|       |            ElectionState::ExpiredConfirmed | ElectionState::ExpiredUnconfirmed => {
  889|      0|                unreachable!()
  890|       |            }
  891|       |            ElectionState::Cancelled => {
  892|      0|                return true; // Clean up cancelled elections immediately
  893|       |            }
  894|       |        }
  895|       |
  896|      0|        if !guard.is_confirmed() && guard.time_to_live() < election.election_start.elapsed() {
  897|       |            // It is possible the election confirmed while acquiring the mutex
  898|       |            // state_change returning true would indicate it
  899|      0|            let state = guard.state;
  900|      0|            if guard
  901|      0|                .state_change(state, ElectionState::ExpiredUnconfirmed)
  902|      0|                .is_ok()
  903|       |            {
  904|      0|                trace!(qualified_root = ?election.qualified_root, "election expired");
  905|      0|                result = true; // Return true to indicate this election should be cleaned up
  906|      0|                guard.status.election_status_type = ElectionStatusType::Stopped;
  907|      0|            }
  908|      0|        }
  909|       |
  910|      0|        result
  911|      0|    }
  912|       |
  913|      0|    fn send_confirm_req(
  914|      0|        &self,
  915|      0|        solicitor: &mut ConfirmationSolicitor,
  916|      0|        election: &Election,
  917|      0|        election_guard: &MutexGuard<ElectionData>,
  918|      0|    ) {
  919|      0|        if self.confirm_req_time(election_guard) < election.last_req_elapsed() {
  920|      0|            if !solicitor.add(election, election_guard) {
  921|      0|                election.set_last_req();
  922|      0|                election
  923|      0|                    .confirmation_request_count
  924|      0|                    .fetch_add(1, Ordering::SeqCst);
  925|      0|
  926|      0|                self.stats
  927|      0|                    .inc(StatType::Election, DetailType::ConfirmationRequest);
  928|      0|            }
  929|      0|        }
  930|      0|    }
  931|       |
  932|      0|    pub fn container_info(&self) -> ContainerInfo {
  933|      0|        let guard = self.mutex.lock().unwrap();
  934|      0|
  935|      0|        let recently_cemented: ContainerInfo = [(
  936|      0|            "cemented",
  937|      0|            self.recently_cemented.lock().unwrap().len(),
  938|      0|            size_of::<ElectionStatus>(),
  939|      0|        )]
  940|      0|        .into();
  941|      0|
  942|      0|        ContainerInfo::builder()
  943|      0|            .leaf("roots", guard.roots.len(), OrderedRoots::ELEMENT_SIZE)
  944|      0|            .leaf(
  945|      0|                "normal",
  946|      0|                guard.count_by_behavior(ElectionBehavior::Priority),
  947|      0|                0,
  948|      0|            )
  949|      0|            .leaf(
  950|      0|                "hinted".to_string(),
  951|      0|                guard.count_by_behavior(ElectionBehavior::Hinted),
  952|      0|                0,
  953|      0|            )
  954|      0|            .leaf(
  955|      0|                "optimistic".to_string(),
  956|      0|                guard.count_by_behavior(ElectionBehavior::Optimistic),
  957|      0|                0,
  958|      0|            )
  959|      0|            .node(
  960|      0|                "recently_confirmed",
  961|      0|                self.recently_confirmed.container_info(),
  962|      0|            )
  963|      0|            .node("recently_cemented", recently_cemented)
  964|      0|            .finish()
  965|      0|    }
  966|       |}
  967|       |
  968|       |impl Drop for ActiveElections {
  969|      3|    fn drop(&mut self) {
  970|      3|        // Thread must be stopped before destruction
  971|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  972|      3|    }
  973|       |}
  974|       |
  975|       |#[derive(PartialEq, Eq)]
  976|       |pub struct TallyKey(pub Amount);
  977|       |
  978|       |impl TallyKey {
  979|      0|    pub fn amount(&self) -> Amount {
  980|      0|        self.0.clone()
  981|      0|    }
  982|       |}
  983|       |
  984|       |impl Deref for TallyKey {
  985|       |    type Target = Amount;
  986|       |
  987|      0|    fn deref(&self) -> &Self::Target {
  988|      0|        &self.0
  989|      0|    }
  990|       |}
  991|       |
  992|       |impl Ord for TallyKey {
  993|     56|    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
  994|     56|        other.0.cmp(&self.0)
  995|     56|    }
  996|       |}
  997|       |
  998|       |impl PartialOrd for TallyKey {
  999|      0|    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
 1000|      0|        other.0.partial_cmp(&self.0)
 1001|      0|    }
 1002|       |}
 1003|       |
 1004|       |impl From<Amount> for TallyKey {
 1005|     46|    fn from(value: Amount) -> Self {
 1006|     46|        Self(value)
 1007|     46|    }
 1008|       |}
 1009|       |
 1010|       |pub struct ActiveElectionsState {
 1011|       |    roots: OrderedRoots,
 1012|       |    stopped: bool,
 1013|       |    manual_count: usize,
 1014|       |    priority_count: usize,
 1015|       |    hinted_count: usize,
 1016|       |    optimistic_count: usize,
 1017|       |}
 1018|       |
 1019|       |impl ActiveElectionsState {
 1020|     12|    pub fn count_by_behavior(&self, behavior: ElectionBehavior) -> usize {
 1021|     12|        match behavior {
 1022|      0|            ElectionBehavior::Manual => self.manual_count,
 1023|      0|            ElectionBehavior::Priority => self.priority_count,
 1024|      6|            ElectionBehavior::Hinted => self.hinted_count,
 1025|      6|            ElectionBehavior::Optimistic => self.optimistic_count,
 1026|       |        }
 1027|     12|    }
 1028|       |
 1029|      0|    pub fn count_by_behavior_mut(&mut self, behavior: ElectionBehavior) -> &mut usize {
 1030|      0|        match behavior {
 1031|      0|            ElectionBehavior::Manual => &mut self.manual_count,
 1032|      0|            ElectionBehavior::Priority => &mut self.priority_count,
 1033|      0|            ElectionBehavior::Hinted => &mut self.hinted_count,
 1034|      0|            ElectionBehavior::Optimistic => &mut self.optimistic_count,
 1035|       |        }
 1036|      0|    }
 1037|       |
 1038|      0|    pub fn election(&self, root: &QualifiedRoot) -> Option<Arc<Election>> {
 1039|      0|        self.roots.get(root).map(|i| i.election.clone())
 1040|      0|    }
 1041|       |}
 1042|       |
 1043|       |#[derive(Default)]
 1044|       |pub(crate) struct OrderedRoots {
 1045|       |    by_root: HashMap<QualifiedRoot, Entry>,
 1046|       |    sequenced: Vec<QualifiedRoot>,
 1047|       |}
 1048|       |
 1049|       |impl OrderedRoots {
 1050|       |    pub const ELEMENT_SIZE: usize = size_of::<QualifiedRoot>() * 2 + size_of::<Arc<Election>>();
 1051|       |
 1052|      0|    pub fn insert(&mut self, entry: Entry) {
 1053|      0|        let root = entry.root.clone();
 1054|      0|        if self.by_root.insert(root.clone(), entry).is_none() {
 1055|      0|            self.sequenced.push(root);
 1056|      0|        }
 1057|      0|    }
 1058|       |
 1059|      0|    pub fn get(&self, root: &QualifiedRoot) -> Option<&Entry> {
 1060|      0|        self.by_root.get(root)
 1061|      0|    }
 1062|       |
 1063|      0|    pub fn erase(&mut self, root: &QualifiedRoot) -> Option<Entry> {
 1064|      0|        let erased = self.by_root.remove(root);
 1065|      0|        if erased.is_some() {
 1066|      0|            self.sequenced.retain(|x| x != root)
 1067|      0|        }
 1068|      0|        erased
 1069|      0|    }
 1070|       |
 1071|      3|    pub fn clear(&mut self) {
 1072|      3|        self.sequenced.clear();
 1073|      3|        self.by_root.clear();
 1074|      3|    }
 1075|       |
 1076|      3|    pub fn len(&self) -> usize {
 1077|      3|        self.sequenced.len()
 1078|      3|    }
 1079|       |
 1080|      3|    pub fn iter_sequenced(&self) -> impl Iterator<Item = &Entry> {
 1081|      3|        self.sequenced.iter().map(|r| self.by_root.get(r).unwrap())
                                                    ^0
 1082|      3|    }
 1083|       |}
 1084|       |
 1085|       |pub trait ActiveElectionsExt {
 1086|       |    fn initialize(&self);
 1087|       |    fn start(&self);
 1088|       |    fn stop(&self);
 1089|       |    fn force_confirm(&self, election: &Arc<Election>);
 1090|       |    fn try_confirm(&self, election: &Arc<Election>, hash: &BlockHash);
 1091|       |    /// Distinguishes replay votes, cannot be determined if the block is not in any election
 1092|       |    fn block_cemented(
 1093|       |        &self,
 1094|       |        guard: &mut ActiveElectionsState,
 1095|       |        block: &SavedBlock,
 1096|       |        confirmation_root: &BlockHash,
 1097|       |        source_election: &Option<Arc<Election>>,
 1098|       |    ) -> (ElectionStatus, Vec<VoteWithWeightInfo>);
 1099|       |    fn publish_block(&self, block: &Block) -> bool;
 1100|       |    fn insert(
 1101|       |        &self,
 1102|       |        block: SavedBlock,
 1103|       |        election_behavior: ElectionBehavior,
 1104|       |        erased_callback: Option<ErasedCallback>,
 1105|       |    ) -> (bool, Option<Arc<Election>>);
 1106|       |}
 1107|       |
 1108|       |impl ActiveElectionsExt for Arc<ActiveElections> {
 1109|      3|    fn initialize(&self) {
 1110|      3|        let self_w = Arc::downgrade(self);
 1111|      3|        // Cementing blocks might implicitly confirm dependent elections
 1112|      3|        self.confirming_set
 1113|      3|            .on_batch_cemented(Box::new(move |cemented| {
                                                                      ^0
 1114|      0|                if let Some(active) = self_w.upgrade() {
 1115|       |                    {
 1116|      0|                        let mut results = Vec::new();
 1117|      0|                        {
 1118|      0|                            let mut guard = active.mutex.lock().unwrap();
 1119|       |                            // Process all cemented blocks while holding the lock to avoid
 1120|       |                            // races where an election for a block that is already
 1121|       |                            // cemented is inserted
 1122|      0|                            for context in cemented {
 1123|      0|                                let result = active.block_cemented(
 1124|      0|                                    &mut guard,
 1125|      0|                                    &context.block,
 1126|      0|                                    &context.confirmation_root,
 1127|      0|                                    &context.election,
 1128|      0|                                );
 1129|      0|                                results.push(result)
 1130|       |                            }
 1131|       |                        }
 1132|       |
 1133|       |                        // TODO: This could be offloaded to a separate notification worker, profiling is needed
 1134|      0|                        let mut tx = active.ledger.read_txn();
 1135|      0|                        for (status, votes) in results {
 1136|      0|                            tx.refresh_if_needed();
 1137|      0|                            active.notify_observers(&tx, &status, &votes);
 1138|      0|                        }
 1139|       |                    }
 1140|      0|                }
 1141|      3|            }));
                          ^0
 1142|      3|
 1143|      3|        let self_w = Arc::downgrade(self);
 1144|      3|        // Notify elections about alternative (forked) blocks
 1145|      3|        self.notifications
 1146|      3|            .on_blocks_processed(Box::new(move |batch| {
                                                                     ^0
 1147|      0|                if let Some(active) = self_w.upgrade() {
 1148|      0|                    for (status, context) in batch {
 1149|      0|                        if *status == BlockStatus::Fork {
 1150|      0|                            let block = context.block.lock().unwrap().clone();
 1151|      0|                            active.publish_block(&block);
 1152|      0|                        }
 1153|       |                    }
 1154|      0|                }
 1155|      3|            }));
                          ^0
 1156|      3|    }
 1157|       |
 1158|      3|    fn start(&self) {
 1159|      3|        if self.flags.disable_request_loop {
 1160|      0|            return;
 1161|      3|        }
 1162|      3|
 1163|      3|        let mut guard = self.thread.lock().unwrap();
 1164|      3|        let self_l = Arc::clone(self);
 1165|      3|        assert!(guard.is_none());
 1166|      3|        *guard = Some(
 1167|      3|            std::thread::Builder::new()
 1168|      3|                .name("Request loop".to_string())
 1169|      3|                .spawn(Box::new(move || {
 1170|      3|                    self_l.request_loop();
 1171|      3|                }))
 1172|      3|                .unwrap(),
 1173|      3|        );
 1174|      3|    }
 1175|       |
 1176|      3|    fn stop(&self) {
 1177|      3|        self.mutex.lock().unwrap().stopped = true;
 1178|      3|        self.condition.notify_all();
 1179|      3|        let join_handle = self.thread.lock().unwrap().take();
 1180|      3|        if let Some(join_handle) = join_handle {
 1181|      3|            join_handle.join().unwrap();
 1182|      3|        }
                       ^0
 1183|      3|        self.clear();
 1184|      3|    }
 1185|       |
 1186|      0|    fn force_confirm(&self, election: &Arc<Election>) {
 1187|      0|        assert!(self.network_params.network.is_dev_network());
 1188|      0|        let guard = election.mutex.lock().unwrap();
 1189|      0|        self.vote_applier.confirm_once(guard, election);
 1190|      0|    }
 1191|       |
 1192|      0|    fn try_confirm(&self, election: &Arc<Election>, hash: &BlockHash) {
 1193|      0|        let guard = election.mutex.lock().unwrap();
 1194|      0|        if let Some(winner) = &guard.status.winner {
 1195|      0|            if winner.hash() == *hash {
 1196|      0|                if !guard.is_confirmed() {
 1197|      0|                    self.vote_applier.confirm_once(guard, election);
 1198|      0|                }
 1199|      0|            }
 1200|      0|        }
 1201|      0|    }
 1202|       |
 1203|      0|    fn block_cemented(
 1204|      0|        &self,
 1205|      0|        guard: &mut ActiveElectionsState,
 1206|      0|        block: &SavedBlock,
 1207|      0|        confirmation_root: &BlockHash,
 1208|      0|        source_election: &Option<Arc<Election>>,
 1209|      0|    ) -> (ElectionStatus, Vec<VoteWithWeightInfo>) {
 1210|      0|        // Dependent elections are implicitly confirmed when their block is cemented
 1211|      0|        let dependent_election = guard.election(&block.qualified_root());
 1212|      0|        if let Some(dependent_election) = &dependent_election {
 1213|      0|            self.stats
 1214|      0|                .inc(StatType::ActiveElections, DetailType::ConfirmDependent);
 1215|      0|
 1216|      0|            // TODO: This should either confirm or cancel the election
 1217|      0|            self.try_confirm(&dependent_election, &block.hash());
 1218|      0|        }
 1219|       |
 1220|      0|        let mut status = ElectionStatus::default();
 1221|      0|        let mut votes = Vec::new();
 1222|      0|        status.winner = Some(MaybeSavedBlock::Saved(block.clone()));
 1223|      0|
 1224|      0|        // Check if the currently cemented block was part of an election that triggered the confirmation
 1225|      0|        let mut handled = false;
 1226|      0|        if let Some(source_election) = source_election {
 1227|      0|            if source_election.qualified_root == block.qualified_root() {
 1228|      0|                status = source_election.mutex.lock().unwrap().status.clone();
 1229|      0|                debug_assert_eq!(status.winner.as_ref().unwrap().hash(), block.hash());
 1230|      0|                votes = self.votes_with_weight(source_election);
 1231|      0|                status.election_status_type = ElectionStatusType::ActiveConfirmedQuorum;
 1232|      0|                handled = true;
 1233|      0|            }
 1234|      0|        }
 1235|       |
 1236|      0|        if handled {
 1237|      0|            // already handled
 1238|      0|        } else if dependent_election.is_some() {
 1239|      0|            status.election_status_type = ElectionStatusType::ActiveConfirmationHeight;
 1240|      0|        } else {
 1241|      0|            status.election_status_type = ElectionStatusType::InactiveConfirmationHeight;
 1242|      0|        }
 1243|       |
 1244|      0|        self.recently_cemented
 1245|      0|            .lock()
 1246|      0|            .unwrap()
 1247|      0|            .push_back(status.clone());
 1248|      0|
 1249|      0|        self.stats
 1250|      0|            .inc(StatType::ActiveElections, DetailType::Cemented);
 1251|      0|        self.stats.inc(
 1252|      0|            StatType::ActiveElectionsCemented,
 1253|      0|            status.election_status_type.into(),
 1254|      0|        );
 1255|      0|
 1256|      0|        trace!(?block, %confirmation_root, "active cemented");
 1257|       |
 1258|      0|        (status, votes)
 1259|      0|    }
 1260|       |
 1261|      0|    fn publish_block(&self, block: &Block) -> bool {
 1262|      0|        let mut guard = self.mutex.lock().unwrap();
 1263|      0|        let root = block.qualified_root();
 1264|      0|        let mut result = true;
 1265|      0|        if let Some(entry) = guard.roots.get(&root) {
 1266|      0|            let election = entry.election.clone();
 1267|      0|            drop(guard);
 1268|      0|            result = self.publish(block, &election);
 1269|      0|            if !result {
 1270|      0|                guard = self.mutex.lock().unwrap();
 1271|      0|                self.vote_router
 1272|      0|                    .connect(block.hash(), Arc::downgrade(&election));
 1273|      0|                drop(guard);
 1274|      0|
 1275|      0|                self.vote_cache_processor.trigger(block.hash());
 1276|      0|
 1277|      0|                self.stats
 1278|      0|                    .inc(StatType::Active, DetailType::ElectionBlockConflict);
 1279|      0|                debug!("Block was added to an existing election: {}", block.hash());
 1280|      0|            }
 1281|      0|        }
 1282|       |
 1283|      0|        result
 1284|      0|    }
 1285|       |
 1286|      0|    fn insert(
 1287|      0|        &self,
 1288|      0|        block: SavedBlock,
 1289|      0|        election_behavior: ElectionBehavior,
 1290|      0|        erased_callback: Option<ErasedCallback>,
 1291|      0|    ) -> (bool, Option<Arc<Election>>) {
 1292|      0|        let mut election_result = None;
 1293|      0|        let mut inserted = false;
 1294|      0|
 1295|      0|        let mut guard = self.mutex.lock().unwrap();
 1296|      0|
 1297|      0|        if guard.stopped {
 1298|      0|            return (false, None);
 1299|      0|        }
 1300|      0|
 1301|      0|        let root = block.qualified_root();
 1302|      0|        let hash = block.hash();
 1303|      0|        let existing = guard.roots.get(&root);
 1304|       |
 1305|      0|        if let Some(existing) = existing {
 1306|      0|            election_result = Some(existing.election.clone());
 1307|      0|
 1308|      0|            // Upgrade to priority election to enable immediate vote broadcasting.
 1309|      0|            let previous_behavior = existing.election.behavior();
 1310|      0|            if election_behavior == ElectionBehavior::Priority
 1311|      0|                && previous_behavior != ElectionBehavior::Priority
 1312|       |            {
 1313|      0|                let transitioned = existing.election.transition_priority();
 1314|      0|                if transitioned {
 1315|      0|                    *guard.count_by_behavior_mut(previous_behavior) -= 1;
 1316|      0|                    *guard.count_by_behavior_mut(election_behavior) += 1;
 1317|      0|                    self.stats
 1318|      0|                        .inc(StatType::ActiveElections, DetailType::TransitionPriority);
 1319|      0|                } else {
 1320|      0|                    self.stats.inc(
 1321|      0|                        StatType::ActiveElections,
 1322|      0|                        DetailType::TransitionPriorityFailed,
 1323|      0|                    );
 1324|      0|                }
 1325|      0|            }
 1326|       |        } else {
 1327|      0|            if !self.recently_confirmed.root_exists(&root) {
 1328|      0|                inserted = true;
 1329|      0|                let online_reps = self.online_reps.clone();
 1330|      0|                let clock = self.steady_clock.clone();
 1331|      0|                let observer_rep_cb = Box::new(move |rep| {
 1332|      0|                    // TODO: Is this neccessary? Move this outside of the election class
 1333|      0|                    // Representative is defined as online if replying to live votes or rep_crawler queries
 1334|      0|                    online_reps.lock().unwrap().vote_observed(rep, clock.now());
 1335|      0|                });
 1336|      0|
 1337|      0|                let id = NEXT_ELECTION_ID.fetch_add(1, Ordering::Relaxed);
 1338|      0|                let election = Arc::new(Election::new(
 1339|      0|                    id,
 1340|      0|                    block,
 1341|      0|                    election_behavior,
 1342|      0|                    Box::new(|_| {}),
 1343|      0|                    observer_rep_cb,
 1344|      0|                ));
 1345|      0|                guard.roots.insert(Entry {
 1346|      0|                    root,
 1347|      0|                    election: election.clone(),
 1348|      0|                    erased_callback,
 1349|      0|                });
 1350|      0|                self.vote_router.connect(hash, Arc::downgrade(&election));
 1351|      0|
 1352|      0|                // Keep track of election count by election type
 1353|      0|                *guard.count_by_behavior_mut(election.behavior()) += 1;
 1354|      0|
 1355|      0|                // Skip passive phase for blocks without cached votes to avoid bootstrap delays
 1356|      0|                let in_cache = self.vote_cache.lock().unwrap().contains(&hash);
 1357|      0|                let activate_immediately = !in_cache;
 1358|      0|
 1359|      0|                if activate_immediately {
 1360|      0|                    self.stats
 1361|      0|                        .inc(StatType::ActiveElections, DetailType::ActivateImmediately);
 1362|      0|                    election.transition_active();
 1363|      0|                }
 1364|       |
 1365|      0|                self.stats
 1366|      0|                    .inc(StatType::ActiveElections, DetailType::Started);
 1367|      0|                self.stats
 1368|      0|                    .inc(StatType::ActiveElectionsStarted, election_behavior.into());
 1369|      0|
 1370|      0|                debug!(
 1371|       |                    activate_immediately,
 1372|       |                    behavior = ?election_behavior,
 1373|       |                    block = %hash,
 1374|      0|                    "Started new election"
 1375|       |                );
 1376|       |
 1377|      0|                election_result = Some(election);
 1378|      0|            } else {
 1379|      0|                // result is not set
 1380|      0|            }
 1381|       |        }
 1382|      0|        drop(guard);
 1383|      0|
 1384|      0|        if inserted {
 1385|      0|            debug_assert!(election_result.is_some());
 1386|       |
 1387|      0|            self.vote_cache_processor.trigger(hash);
 1388|      0|
 1389|      0|            {
 1390|      0|                let callbacks = self.active_started_observer.lock().unwrap();
 1391|      0|                for callback in callbacks.iter() {
 1392|      0|                    (callback)(hash);
 1393|      0|                }
 1394|       |            }
 1395|      0|            self.vacancy_updated();
 1396|      0|        }
 1397|       |
 1398|       |        // Votes are generated for inserted or ongoing elections
 1399|      0|        if let Some(election) = &election_result {
 1400|      0|            let mut guard = election.mutex.lock().unwrap();
 1401|      0|            self.broadcast_vote(election, &mut guard);
 1402|      0|        }
 1403|       |
 1404|      0|        (inserted, election_result)
 1405|      0|    }
 1406|       |}
 1407|       |
 1408|       |#[derive(Default)]
 1409|       |pub struct ActiveElectionsInfo {
 1410|       |    pub max_queue: usize,
 1411|       |    pub total: usize,
 1412|       |    pub priority: usize,
 1413|       |    pub hinted: usize,
 1414|       |    pub optimistic: usize,
 1415|       |}
 1416|       |
 1417|       |pub(crate) struct Entry {
 1418|       |    root: QualifiedRoot,
 1419|       |    election: Arc<Election>,
 1420|       |    erased_callback: Option<ErasedCallback>,
 1421|       |}
 1422|       |
 1423|       |pub(crate) type ErasedCallback = Box<dyn Fn(&Arc<Election>) + Send + Sync>;

/home/gustav/code/nano/rsnano-node/node/src/consensus/bootstrap_weights.rs:
    1|       |use rsnano_core::{Account, Amount, Networks, PublicKey};
    2|       |use rsnano_ledger::RepWeightCache;
    3|       |use std::collections::HashMap;
    4|       |use tracing::info;
    5|       |
    6|      1|pub(crate) fn get_bootstrap_weights(network: Networks) -> (u64, HashMap<PublicKey, Amount>) {
    7|      1|    let buffer = get_bootstrap_weights_text(network);
    8|      1|    deserialize_bootstrap_weights(buffer)
    9|      1|}
   10|       |
   11|      3|fn get_bootstrap_weights_text(network: Networks) -> &'static str {
   12|      3|    if network == Networks::NanoLiveNetwork {
   13|      2|        include_str!("../../rep_weights_live.txt")
   14|       |    } else {
   15|      1|        include_str!("../../rep_weights_beta.txt")
   16|       |    }
   17|      3|}
   18|       |
   19|      1|fn deserialize_bootstrap_weights(buffer: &str) -> (u64, HashMap<PublicKey, Amount>) {
   20|      1|    let mut weights = HashMap::new();
   21|      1|    let mut first_line = true;
   22|      1|    let mut max_blocks = 0;
   23|    136|    for line in buffer.lines() {
                              ^1
   24|    136|        if first_line {
   25|      1|            max_blocks = line.parse().unwrap();
   26|      1|            first_line = false;
   27|      1|            continue;
   28|    135|        }
   29|    135|
   30|    135|        let mut it = line.split(':');
   31|    135|        let account = Account::decode_account(it.next().unwrap()).unwrap();
   32|    135|        let weight = Amount::decode_dec(it.next().unwrap()).unwrap();
   33|    135|        weights.insert(account.into(), weight);
   34|       |    }
   35|       |
   36|      1|    (max_blocks, weights)
   37|      1|}
   38|       |
   39|      3|pub(crate) fn log_bootstrap_weights(weight_cache: &RepWeightCache) {
   40|      3|    let mut bootstrap_weights = weight_cache.bootstrap_weights();
   41|      3|    if !bootstrap_weights.is_empty() {
   42|      0|        info!(
   43|      0|            "Initial bootstrap height: {}",
   44|      0|            weight_cache.bootstrap_weight_max_blocks()
   45|       |        );
   46|      0|        info!("Current ledger height:    {}", weight_cache.block_count());
   47|       |
   48|       |        // Use bootstrap weights if initial bootstrap is not completed
   49|      0|        if weight_cache.use_bootstrap_weights() {
   50|      0|            info!("Using predefined representative weights, since block count is less than bootstrap threshold");
   51|      0|            info!("************************************ Bootstrap weights ************************************");
   52|       |            // Sort the weights
   53|      0|            let mut sorted_weights = bootstrap_weights.drain().collect::<Vec<_>>();
   54|      0|            sorted_weights.sort_by(|(_, weight_a), (_, weight_b)| weight_b.cmp(weight_a));
   55|       |
   56|      0|            for (rep, weight) in sorted_weights {
   57|      0|                info!(
   58|      0|                    "Using bootstrap rep weight: {} -> {}",
   59|      0|                    Account::from(&rep).encode_account(),
   60|      0|                    weight.format_balance(0)
   61|       |                );
   62|       |            }
   63|      0|            info!("************************************ ================= ************************************");
   64|      0|        }
   65|      3|    }
   66|      3|}
   67|       |
   68|       |#[cfg(test)]
   69|       |mod tests {
   70|       |    use super::*;
   71|       |
   72|       |    #[test]
   73|      1|    fn bootstrap_weights_text() {
   74|      1|        assert_eq!(
   75|      1|            get_bootstrap_weights_text(Networks::NanoLiveNetwork).len(),
   76|       |            13921,
   77|      0|            "expected live weights don't match'"
   78|       |        );
   79|      1|        assert_eq!(
   80|      1|            get_bootstrap_weights_text(Networks::NanoBetaNetwork).len(),
   81|       |            1161,
   82|      0|            "expected beta weights don't match'"
   83|       |        );
   84|      1|    }
   85|       |
   86|       |    #[test]
   87|      1|    fn bootstrap_weights() {
   88|      1|        let (max_blocks, weights) = get_bootstrap_weights(Networks::NanoLiveNetwork);
   89|      1|        assert_eq!(weights.len(), 135);
   90|      1|        assert_eq!(max_blocks, 204_137_485);
   91|      1|    }
   92|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/bucket.rs:
    1|       |use super::{
    2|       |    ordered_blocks::{BlockEntry, OrderedBlocks},
    3|       |    ActiveElections, Election, ElectionBehavior,
    4|       |};
    5|       |use crate::{
    6|       |    consensus::ActiveElectionsExt,
    7|       |    stats::{DetailType, StatType, Stats},
    8|       |};
    9|       |use rsnano_core::{utils::UnixTimestamp, Block, BlockHash, QualifiedRoot, SavedBlock};
   10|       |use std::{
   11|       |    collections::{BTreeMap, HashMap},
   12|       |    sync::{Arc, Mutex},
   13|       |};
   14|       |
   15|       |#[derive(Clone, Debug, PartialEq)]
   16|       |pub struct PriorityBucketConfig {
   17|       |    /// Maximum number of blocks to sort by priority per bucket.
   18|       |    pub max_blocks: usize,
   19|       |
   20|       |    /// Number of guaranteed slots per bucket available for election activation.
   21|       |    pub reserved_elections: usize,
   22|       |
   23|       |    /// Maximum number of slots per bucket available for election activation if the active election count is below the configured limit. (node.active_elections.size)
   24|       |    pub max_elections: usize,
   25|       |}
   26|       |
   27|       |impl Default for PriorityBucketConfig {
   28|     10|    fn default() -> Self {
   29|     10|        Self {
   30|     10|            max_blocks: 1024 * 8,
   31|     10|            reserved_elections: 100,
   32|     10|            max_elections: 150,
   33|     10|        }
   34|     10|    }
   35|       |}
   36|       |
   37|       |/// A struct which holds an ordered set of blocks to be scheduled, ordered by their block arrival time
   38|       |/// TODO: This combines both block ordering and election management, which makes the class harder to test. The functionality should be split.
   39|       |pub struct Bucket {
   40|       |    config: PriorityBucketConfig,
   41|       |    active: Arc<ActiveElections>,
   42|       |    stats: Arc<Stats>,
   43|       |    data: Mutex<BucketData>,
   44|       |}
   45|       |
   46|       |impl Bucket {
   47|    189|    pub fn new(
   48|    189|        config: PriorityBucketConfig,
   49|    189|        active: Arc<ActiveElections>,
   50|    189|        stats: Arc<Stats>,
   51|    189|    ) -> Self {
   52|    189|        Self {
   53|    189|            config,
   54|    189|            active,
   55|    189|            stats: stats.clone(),
   56|    189|            data: Mutex::new(BucketData {
   57|    189|                queue: Default::default(),
   58|    189|                elections: OrderedElections::default(),
   59|    189|            }),
   60|    189|        }
   61|    189|    }
   62|       |
   63|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   64|      0|        self.data.lock().unwrap().queue.contains(hash)
   65|      0|    }
   66|       |
   67|    189|    pub fn available(&self) -> bool {
   68|    189|        let candidate: UnixTimestamp;
   69|    189|        let election_count: usize;
   70|    189|        let lowest: UnixTimestamp;
   71|    189|
   72|    189|        {
   73|    189|            let guard = self.data.lock().unwrap();
   74|    189|            let Some(first) = guard.queue.first() else {
                                   ^0
   75|    189|                return false;
   76|       |            };
   77|       |
   78|      0|            candidate = first.time;
   79|      0|            election_count = guard.elections.len();
   80|      0|            lowest = guard.elections.lowest_priority();
   81|      0|        }
   82|      0|
   83|      0|        if election_count < self.config.reserved_elections
   84|      0|            || election_count < self.config.max_elections
   85|       |        {
   86|      0|            self.active.vacancy(ElectionBehavior::Priority) > 0
   87|      0|        } else if election_count > 0 {
   88|       |            // Compare to equal to drain duplicates
   89|      0|            if candidate <= lowest {
   90|       |                // Bound number of reprioritizations
   91|      0|                election_count < self.config.max_elections * 2
   92|       |            } else {
   93|      0|                false
   94|       |            }
   95|       |        } else {
   96|      0|            false
   97|       |        }
   98|    189|    }
   99|       |
  100|      0|    fn election_overfill(&self, data: &BucketData) -> bool {
  101|      0|        if data.elections.len() < self.config.reserved_elections {
  102|      0|            false
  103|      0|        } else if data.elections.len() < self.config.max_elections {
  104|      0|            self.active.vacancy(ElectionBehavior::Priority) < 0
  105|       |        } else {
  106|      0|            true
  107|       |        }
  108|      0|    }
  109|       |
  110|      0|    pub fn update(&self) {
  111|      0|        let guard = self.data.lock().unwrap();
  112|      0|        if self.election_overfill(&guard) {
  113|      0|            guard.cancel_lowest_election();
  114|      0|            drop(guard);
  115|      0|            self.stats
  116|      0|                .inc(StatType::ElectionBucket, DetailType::CancelLowest);
  117|      0|        }
  118|      0|    }
  119|       |
  120|      0|    pub fn push(&self, time: UnixTimestamp, block: SavedBlock) -> bool {
  121|      0|        let hash = block.hash();
  122|      0|        let mut guard = self.data.lock().unwrap();
  123|      0|        let inserted = guard.queue.insert(BlockEntry { time, block });
  124|      0|        if guard.queue.len() > self.config.max_blocks {
  125|      0|            if let Some(removed) = guard.queue.pop_last() {
  126|      0|                inserted && !(removed.time == time && removed.block.hash() == hash)
  127|       |            } else {
  128|      0|                inserted
  129|       |            }
  130|       |        } else {
  131|      0|            inserted
  132|       |        }
  133|      0|    }
  134|       |
  135|      0|    pub fn len(&self) -> usize {
  136|      0|        self.data.lock().unwrap().queue.len()
  137|      0|    }
  138|       |
  139|      0|    pub fn election_count(&self) -> usize {
  140|      0|        self.data.lock().unwrap().elections.len()
  141|      0|    }
  142|       |
  143|      0|    pub fn blocks(&self) -> Vec<Block> {
  144|      0|        let guard = self.data.lock().unwrap();
  145|      0|        guard.queue.iter().map(|i| i.block.clone().into()).collect()
  146|      0|    }
  147|       |}
  148|       |
  149|       |pub(crate) trait BucketExt {
  150|       |    fn activate(&self) -> bool;
  151|       |}
  152|       |
  153|       |impl BucketExt for Arc<Bucket> {
  154|      0|    fn activate(&self) -> bool {
  155|      0|        let block: SavedBlock;
  156|      0|        let priority: UnixTimestamp;
  157|      0|
  158|      0|        {
  159|      0|            let mut guard = self.data.lock().unwrap();
  160|       |
  161|      0|            let Some(top) = guard.queue.pop_first() else {
  162|      0|                return false; // Not activated;
  163|       |            };
  164|       |
  165|      0|            block = top.block;
  166|      0|            priority = top.time;
  167|      0|        }
  168|      0|
  169|      0|        let self_w = Arc::downgrade(self);
  170|      0|        let erase_callback = Box::new(move |election: &Arc<Election>| {
  171|      0|            let Some(self_l) = self_w.upgrade() else {
  172|      0|                return;
  173|       |            };
  174|      0|            let mut guard = self_l.data.lock().unwrap();
  175|      0|            guard.elections.erase(&election.qualified_root);
  176|      0|        });
  177|      0|
  178|      0|        let (inserted, election) =
  179|      0|            self.active
  180|      0|                .insert(block, ElectionBehavior::Priority, Some(erase_callback));
  181|      0|
  182|      0|        if inserted {
  183|      0|            let election = election.unwrap();
  184|      0|            self.data.lock().unwrap().elections.insert(ElectionEntry {
  185|      0|                root: election.qualified_root.clone(),
  186|      0|                election,
  187|      0|                priority,
  188|      0|            });
  189|      0|            self.stats
  190|      0|                .inc(StatType::ElectionBucket, DetailType::ActivateSuccess);
  191|      0|        } else {
  192|      0|            self.stats
  193|      0|                .inc(StatType::ElectionBucket, DetailType::ActivateFailed);
  194|      0|        }
  195|       |
  196|      0|        inserted
  197|      0|    }
  198|       |}
  199|       |
  200|       |struct BucketData {
  201|       |    queue: OrderedBlocks,
  202|       |    elections: OrderedElections,
  203|       |}
  204|       |
  205|       |impl BucketData {
  206|      0|    fn cancel_lowest_election(&self) {
  207|      0|        if let Some(entry) = self.elections.entry_with_lowest_priority() {
  208|      0|            entry.election.cancel();
  209|      0|        }
  210|      0|    }
  211|       |}
  212|       |
  213|       |struct ElectionEntry {
  214|       |    election: Arc<Election>,
  215|       |    root: QualifiedRoot,
  216|       |    priority: UnixTimestamp,
  217|       |}
  218|       |
  219|       |#[derive(Default)]
  220|       |struct OrderedElections {
  221|       |    by_root: HashMap<QualifiedRoot, ElectionEntry>,
  222|       |    sequenced: Vec<QualifiedRoot>,
  223|       |    by_priority: BTreeMap<UnixTimestamp, Vec<QualifiedRoot>>,
  224|       |}
  225|       |
  226|       |impl OrderedElections {
  227|      0|    fn insert(&mut self, entry: ElectionEntry) {
  228|      0|        let root = entry.root.clone();
  229|      0|        let priority = entry.priority;
  230|      0|        let old = self.by_root.insert(root.clone(), entry);
  231|      0|        if let Some(old) = old {
  232|      0|            self.erase_indices(old);
  233|      0|        }
  234|      0|        self.sequenced.push(root.clone());
  235|      0|        self.by_priority.entry(priority).or_default().push(root);
  236|      0|    }
  237|       |
  238|      0|    fn entry_with_lowest_priority(&self) -> Option<&ElectionEntry> {
  239|      0|        self.by_priority
  240|      0|            .first_key_value()
  241|      0|            .and_then(|(_, roots)| self.by_root.get(&roots[0]))
  242|      0|    }
  243|       |
  244|      0|    fn lowest_priority(&self) -> UnixTimestamp {
  245|      0|        self.by_priority
  246|      0|            .first_key_value()
  247|      0|            .map(|(prio, _)| *prio)
  248|      0|            .unwrap_or_default()
  249|      0|    }
  250|       |
  251|      0|    fn len(&self) -> usize {
  252|      0|        self.sequenced.len()
  253|      0|    }
  254|       |
  255|      0|    fn erase(&mut self, root: &QualifiedRoot) {
  256|      0|        if let Some(entry) = self.by_root.remove(root) {
  257|      0|            self.erase_indices(entry)
  258|      0|        }
  259|      0|    }
  260|       |
  261|      0|    fn erase_indices(&mut self, entry: ElectionEntry) {
  262|      0|        let keys = self.by_priority.get_mut(&entry.priority).unwrap();
  263|      0|        if keys.len() == 1 {
  264|      0|            self.by_priority.remove(&entry.priority);
  265|      0|        } else {
  266|      0|            keys.retain(|i| *i != entry.root);
  267|      0|        }
  268|      0|        self.sequenced.retain(|i| *i != entry.root);
  269|      0|    }
  270|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/bucketing.rs:
    1|       |use rsnano_core::Amount;
    2|       |
    3|       |#[derive(Clone)]
    4|       |pub struct Bucketing {
    5|       |    minimums: Vec<Amount>,
    6|       |}
    7|       |
    8|       |impl Bucketing {
    9|      8|    pub fn new() -> Self {
   10|      8|        Default::default()
   11|      8|    }
   12|       |
   13|      7|    pub fn bucket_index(&self, balance: Amount) -> usize {
   14|      7|        let result = self
   15|      7|            .minimums
   16|      7|            .iter()
   17|      7|            .enumerate()
   18|      7|            .rev()
   19|    315|            .find(|(_, minimum)| balance >= **minimum);
   20|      7|
   21|      7|        match result {
   22|      7|            Some((index, _)) => index,
   23|       |            None => {
   24|       |                // There should always be a bucket with a minimum_balance of 0
   25|      0|                unreachable!()
   26|       |            }
   27|       |        }
   28|      7|    }
   29|       |
   30|     13|    pub fn bucket_count(&self) -> usize {
   31|     13|        self.minimums.len()
   32|     13|    }
   33|       |}
   34|       |
   35|       |impl Default for Bucketing {
   36|     11|    fn default() -> Self {
   37|     11|        let mut minimums = Vec::new();
   38|    121|        let mut build_region = |begin: u128, end: u128, count: usize| {
   39|    121|            let width = (end - begin) / (count as u128);
   40|    693|            for i in 0..count {
                                      ^121
   41|    693|                let minimum_balance = begin + (i as u128 * width);
   42|    693|                minimums.push(minimum_balance.into())
   43|       |            }
   44|    121|        };
   45|       |
   46|     11|        build_region(0, 1 << 79, 1);
   47|     11|        build_region(1 << 79, 1 << 88, 1);
   48|     11|        build_region(1 << 88, 1 << 92, 2);
   49|     11|        build_region(1 << 92, 1 << 96, 4);
   50|     11|        build_region(1 << 96, 1 << 100, 8);
   51|     11|        build_region(1 << 100, 1 << 104, 16);
   52|     11|        build_region(1 << 104, 1 << 108, 16);
   53|     11|        build_region(1 << 108, 1 << 112, 8);
   54|     11|        build_region(1 << 112, 1 << 116, 4);
   55|     11|        build_region(1 << 116, 1 << 120, 2);
   56|     11|        build_region(1 << 120, 1 << 127, 1);
   57|     11|
   58|     11|        Self { minimums }
   59|     11|    }
   60|       |}
   61|       |
   62|       |#[cfg(test)]
   63|       |mod tests {
   64|       |    use super::*;
   65|       |
   66|       |    #[test]
   67|      1|    fn bucket_creation() {
   68|      1|        assert_eq!(Bucketing::new().bucket_count(), 63);
   69|      1|    }
   70|       |
   71|       |    #[test]
   72|      1|    fn bucket_0() {
   73|      1|        assert_eq!(Bucketing::new().bucket_index(0.into()), 0);
   74|      1|        assert_eq!(Bucketing::new().bucket_index(1.into()), 0);
   75|      1|        assert_eq!(Bucketing::new().bucket_index(Amount::raw((1 << 79) - 1)), 0);
   76|      1|    }
   77|       |
   78|       |    #[test]
   79|      1|    fn bucket_1() {
   80|      1|        assert_eq!(Bucketing::new().bucket_index(Amount::raw(1 << 79)), 1);
   81|      1|    }
   82|       |
   83|       |    #[test]
   84|      1|    fn nano_index() {
   85|      1|        assert_eq!(Bucketing::new().bucket_index(Amount::nano(1)), 14);
   86|      1|    }
   87|       |
   88|       |    #[test]
   89|      1|    fn knano_index() {
   90|      1|        assert_eq!(Bucketing::new().bucket_index(Amount::nano(1000)), 49);
   91|      1|    }
   92|       |
   93|       |    #[test]
   94|      1|    fn max_index() {
   95|      1|        assert_eq!(Bucketing::new().bucket_index(Amount::MAX), 62);
   96|      1|    }
   97|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/confirmation_solicitor.rs:
    1|       |use super::{Election, ElectionData};
    2|       |use crate::{representatives::PeeredRep, transport::MessageFlooder, NetworkParams};
    3|       |use rsnano_core::{BlockHash, Root};
    4|       |use rsnano_messages::{ConfirmReq, Message, Publish};
    5|       |use rsnano_network::{ChannelId, Network, TrafficType};
    6|       |use std::{
    7|       |    cmp::max,
    8|       |    collections::HashMap,
    9|       |    sync::{atomic::Ordering, MutexGuard, RwLock},
   10|       |};
   11|       |
   12|       |/// This struct accepts elections that need further votes before they can be confirmed and bundles them in to single confirm_req packets
   13|       |pub struct ConfirmationSolicitor<'a> {
   14|       |    network: &'a RwLock<Network>,
   15|       |    /// Global maximum amount of block broadcasts
   16|       |    max_block_broadcasts: usize,
   17|       |    /// Maximum amount of requests to be sent per election, bypassed if an existing vote is for a different hash
   18|       |    max_election_requests: usize,
   19|       |    /// Maximum amount of directed broadcasts to be sent per election
   20|       |    max_election_broadcasts: usize,
   21|       |    representative_requests: Vec<PeeredRep>,
   22|       |    representative_broadcasts: Vec<PeeredRep>,
   23|       |    requests: HashMap<ChannelId, Vec<(BlockHash, Root)>>,
   24|       |    prepared: bool,
   25|       |    rebroadcasted: usize,
   26|       |    message_flooder: MessageFlooder,
   27|       |}
   28|       |
   29|       |impl<'a> ConfirmationSolicitor<'a> {
   30|      3|    pub fn new(
   31|      3|        network_params: &NetworkParams,
   32|      3|        network: &'a RwLock<Network>,
   33|      3|        message_flooder: MessageFlooder,
   34|      3|    ) -> Self {
   35|      3|        let max_election_broadcasts = max(network.read().unwrap().fanout(1.0) / 2, 1);
   36|      3|        Self {
   37|      3|            network,
   38|      3|            max_block_broadcasts: if network_params.network.is_dev_network() {
   39|      3|                4
   40|       |            } else {
   41|      0|                30
   42|       |            },
   43|       |            max_election_requests: 50,
   44|      3|            max_election_broadcasts,
   45|      3|            prepared: false,
   46|      3|            representative_requests: Vec::new(),
   47|      3|            representative_broadcasts: Vec::new(),
   48|      3|            requests: HashMap::new(),
   49|      3|            rebroadcasted: 0,
   50|      3|            message_flooder,
   51|      3|        }
   52|      3|    }
   53|       |
   54|       |    /// Prepare object for batching election confirmation requests
   55|      3|    pub fn prepare(&mut self, representatives: &[PeeredRep]) {
   56|      3|        debug_assert!(!self.prepared);
   57|      3|        self.requests.clear();
   58|      3|        self.rebroadcasted = 0;
   59|      3|        self.representative_requests = representatives.to_vec();
   60|      3|        self.representative_broadcasts = representatives.to_vec();
   61|      3|        self.prepared = true;
   62|      3|    }
   63|       |
   64|       |    /// Broadcast the winner of an election if the broadcast limit has not been reached. Returns false if the broadcast was performed
   65|      0|    pub fn broadcast(&mut self, guard: &MutexGuard<ElectionData>) -> Result<(), ()> {
   66|      0|        debug_assert!(self.prepared);
   67|      0|        self.rebroadcasted += 1;
   68|      0|        if self.rebroadcasted >= self.max_block_broadcasts {
   69|      0|            return Err(());
   70|      0|        }
   71|      0|
   72|      0|        let winner_block = guard.status.winner.as_ref().unwrap();
   73|      0|        let hash = winner_block.hash();
   74|      0|        let winner = Message::Publish(Publish::new_forward(winner_block.clone().into()));
   75|      0|        let mut count = 0;
   76|       |        // Directed broadcasting to principal representatives
   77|      0|        for i in &self.representative_broadcasts {
   78|      0|            if count >= self.max_election_broadcasts {
   79|      0|                break;
   80|      0|            }
   81|      0|            let should_broadcast = if let Some(existing) = guard.last_votes.get(&i.account) {
   82|      0|                existing.hash != hash
   83|       |            } else {
   84|      0|                count += 1;
   85|      0|                true
   86|       |            };
   87|      0|            if should_broadcast {
   88|      0|                self.message_flooder
   89|      0|                    .try_send(i.channel_id, &winner, TrafficType::BlockBroadcast);
   90|      0|            }
   91|       |        }
   92|       |        // Random flood for block propagation
   93|       |        // TODO: Avoid broadcasting to the same peers that were already broadcasted to
   94|      0|        self.message_flooder
   95|      0|            .flood(&winner, TrafficType::BlockBroadcast, 0.5);
   96|      0|        Ok(())
   97|      0|    }
   98|       |
   99|       |    /// Add an election that needs to be confirmed. Returns false if successfully added
  100|      0|    pub fn add(&mut self, election: &Election, guard: &MutexGuard<ElectionData>) -> bool {
  101|      0|        debug_assert!(self.prepared);
  102|      0|        let mut error = true;
  103|      0|        let mut count = 0;
  104|      0|        let winner = guard.status.winner.as_ref().unwrap();
  105|      0|        let hash = winner.hash();
  106|      0|        let mut to_remove = Vec::new();
  107|      0|        for rep in &self.representative_requests {
  108|      0|            if count >= self.max_election_requests {
  109|      0|                break;
  110|      0|            }
  111|      0|            let mut full_queue = false;
  112|      0|            let existing = guard.last_votes.get(&rep.account);
  113|      0|            let exists = existing.is_some();
  114|      0|            let is_final = if let Some(existing) = existing {
  115|      0|                !election.is_quorum.load(Ordering::SeqCst) || existing.timestamp == u64::MAX
  116|       |            } else {
  117|      0|                false
  118|       |            };
  119|      0|            let different = if let Some(existing) = existing {
  120|      0|                existing.hash != hash
  121|       |            } else {
  122|      0|                false
  123|       |            };
  124|      0|            if !exists || !is_final || different {
  125|      0|                let should_drop = self
  126|      0|                    .network
  127|      0|                    .read()
  128|      0|                    .unwrap()
  129|      0|                    .should_drop(rep.channel_id, TrafficType::ConfirmationRequests);
  130|      0|
  131|      0|                if !should_drop {
  132|      0|                    let request_queue = self.requests.entry(rep.channel_id).or_default();
  133|      0|                    request_queue.push((winner.hash(), winner.root()));
  134|      0|                    if !different {
  135|      0|                        count += 1;
  136|      0|                    }
  137|      0|                    error = false;
  138|      0|                } else {
  139|      0|                    full_queue = true;
  140|      0|                }
  141|      0|            }
  142|      0|            if full_queue {
  143|      0|                to_remove.push(rep.account);
  144|      0|            }
  145|       |        }
  146|       |
  147|      0|        if !to_remove.is_empty() {
  148|      0|            self.representative_requests
  149|      0|                .retain(|i| !to_remove.contains(&i.account));
  150|      0|        }
  151|       |
  152|      0|        error
  153|      0|    }
  154|       |
  155|       |    /// Dispatch bundled requests to each channel
  156|      3|    pub fn flush(&mut self) {
  157|      3|        debug_assert!(self.prepared);
  158|      3|        for (channel_id, requests) in &self.requests {
                           ^0
  159|      0|            let mut roots_hashes = Vec::new();
  160|      0|            for root_hash in requests {
  161|      0|                roots_hashes.push(root_hash.clone());
  162|      0|                if roots_hashes.len() == ConfirmReq::HASHES_MAX {
  163|      0|                    let req = Message::ConfirmReq(ConfirmReq::new(roots_hashes));
  164|      0|                    self.message_flooder.try_send(
  165|      0|                        *channel_id,
  166|      0|                        &req,
  167|      0|                        TrafficType::ConfirmationRequests,
  168|      0|                    );
  169|      0|                    roots_hashes = Vec::new();
  170|      0|                }
  171|       |            }
  172|      0|            if !roots_hashes.is_empty() {
  173|      0|                let req = Message::ConfirmReq(ConfirmReq::new(roots_hashes));
  174|      0|                self.message_flooder
  175|      0|                    .try_send(*channel_id, &req, TrafficType::ConfirmationRequests);
  176|      0|            }
  177|       |        }
  178|      3|        self.prepared = false;
  179|      3|    }
  180|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/election.rs:
    1|       |use super::ElectionStatus;
    2|       |use crate::{
    3|       |    stats::{DetailType, StatType},
    4|       |    utils::HardenedConstants,
    5|       |};
    6|       |use rsnano_core::{
    7|       |    Amount, Block, BlockHash, MaybeSavedBlock, PublicKey, QualifiedRoot, Root, SavedBlock,
    8|       |};
    9|       |use std::{
   10|       |    collections::HashMap,
   11|       |    fmt::Debug,
   12|       |    sync::{
   13|       |        atomic::{AtomicBool, AtomicU32, AtomicUsize, Ordering},
   14|       |        Mutex, RwLock,
   15|       |    },
   16|       |    time::{Duration, Instant, SystemTime},
   17|       |};
   18|       |
   19|       |pub static NEXT_ELECTION_ID: AtomicUsize = AtomicUsize::new(1);
   20|       |
   21|       |//TODO remove the many RwLocks
   22|       |pub struct Election {
   23|       |    pub id: usize,
   24|       |    pub mutex: Mutex<ElectionData>,
   25|       |    pub root: Root,
   26|       |    pub qualified_root: QualifiedRoot,
   27|       |    pub is_quorum: AtomicBool,
   28|       |    pub confirmation_request_count: AtomicU32,
   29|       |    // These are modified while not holding the mutex from transition_time only
   30|       |    last_block: RwLock<Instant>,
   31|       |    pub last_req: RwLock<Option<Instant>>,
   32|       |    pub election_start: Instant,
   33|       |    pub confirmation_action: Box<dyn Fn(Block) + Send + Sync>,
   34|       |    pub live_vote_action: Box<dyn Fn(PublicKey) + Send + Sync>,
   35|       |    height: u64,
   36|       |}
   37|       |
   38|       |impl Election {
   39|       |    pub const PASSIVE_DURATION_FACTOR: u32 = 5;
   40|       |
   41|      0|    pub fn new(
   42|      0|        id: usize,
   43|      0|        block: SavedBlock,
   44|      0|        behavior: ElectionBehavior,
   45|      0|        confirmation_action: Box<dyn Fn(Block) + Send + Sync>,
   46|      0|        live_vote_action: Box<dyn Fn(PublicKey) + Send + Sync>,
   47|      0|    ) -> Self {
   48|      0|        let root = block.root();
   49|      0|        let qualified_root = block.qualified_root();
   50|      0|        let height = block.height();
   51|      0|
   52|      0|        let data = ElectionData {
   53|      0|            status: ElectionStatus {
   54|      0|                winner: Some(rsnano_core::MaybeSavedBlock::Saved(block.clone())),
   55|      0|                election_end: SystemTime::now(),
   56|      0|                block_count: 1,
   57|      0|                election_status_type: super::ElectionStatusType::Ongoing,
   58|      0|                ..Default::default()
   59|      0|            },
   60|      0|            last_votes: HashMap::from([(
   61|      0|                HardenedConstants::get().not_an_account_key,
   62|      0|                VoteInfo::new(0, block.hash()),
   63|      0|            )]),
   64|      0|            last_blocks: HashMap::from([(block.hash(), MaybeSavedBlock::Saved(block))]),
   65|      0|            state: ElectionState::Passive,
   66|      0|            state_start: Instant::now(),
   67|      0|            last_tally: HashMap::new(),
   68|      0|            final_weight: Amount::zero(),
   69|      0|            last_vote: None,
   70|      0|            last_block_hash: BlockHash::zero(),
   71|      0|            behavior,
   72|      0|        };
   73|      0|
   74|      0|        Self {
   75|      0|            id,
   76|      0|            mutex: Mutex::new(data),
   77|      0|            root,
   78|      0|            qualified_root,
   79|      0|            is_quorum: AtomicBool::new(false),
   80|      0|            confirmation_request_count: AtomicU32::new(0),
   81|      0|            last_block: RwLock::new(Instant::now()),
   82|      0|            election_start: Instant::now(),
   83|      0|            last_req: RwLock::new(None),
   84|      0|            confirmation_action,
   85|      0|            live_vote_action,
   86|      0|            height,
   87|      0|        }
   88|      0|    }
   89|       |
   90|      0|    pub fn duration(&self) -> Duration {
   91|      0|        self.election_start.elapsed()
   92|      0|    }
   93|       |
   94|      0|    pub fn state(&self) -> ElectionState {
   95|      0|        self.mutex.lock().unwrap().state
   96|      0|    }
   97|       |
   98|      0|    pub fn transition_active(&self) {
   99|      0|        let _ = self
  100|      0|            .mutex
  101|      0|            .lock()
  102|      0|            .unwrap()
  103|      0|            .state_change(ElectionState::Passive, ElectionState::Active);
  104|      0|    }
  105|       |
  106|      0|    pub fn transition_priority(&self) -> bool {
  107|      0|        let mut guard = self.mutex.lock().unwrap();
  108|      0|        if matches!(
  109|      0|            guard.behavior,
  110|       |            ElectionBehavior::Priority | ElectionBehavior::Manual
  111|       |        ) {
  112|      0|            return false;
  113|      0|        }
  114|      0|
  115|      0|        guard.behavior = ElectionBehavior::Priority;
  116|      0|
  117|      0|        // allow new outgoing votes immediately
  118|      0|        guard.last_vote = None;
  119|      0|        true
  120|      0|    }
  121|       |
  122|      0|    pub fn cancel(&self) {
  123|      0|        let mut guard = self.mutex.lock().unwrap();
  124|      0|        let current = guard.state;
  125|      0|        let _ = guard.state_change(current, ElectionState::Cancelled);
  126|      0|    }
  127|       |
  128|      0|    pub fn set_last_req(&self) {
  129|      0|        *self.last_req.write().unwrap() = Some(Instant::now());
  130|      0|    }
  131|       |
  132|      0|    pub fn last_req_elapsed(&self) -> Duration {
  133|      0|        match self.last_req.read().unwrap().as_ref() {
  134|      0|            Some(i) => i.elapsed(),
  135|      0|            None => Duration::from_secs(60 * 60 * 24 * 365), // Duration::MAX caused problems with C++
  136|       |        }
  137|      0|    }
  138|       |
  139|      0|    pub fn set_last_block(&self) {
  140|      0|        *self.last_block.write().unwrap() = Instant::now();
  141|      0|    }
  142|       |
  143|      0|    pub fn last_block_elapsed(&self) -> Duration {
  144|      0|        self.last_block.read().unwrap().elapsed()
  145|      0|    }
  146|       |
  147|      0|    pub fn age(&self) -> Duration {
  148|      0|        self.mutex.lock().unwrap().state_start.elapsed()
  149|      0|    }
  150|       |
  151|      0|    pub fn failed(&self) -> bool {
  152|      0|        self.mutex.lock().unwrap().state == ElectionState::ExpiredUnconfirmed
  153|      0|    }
  154|       |
  155|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
  156|      0|        self.mutex.lock().unwrap().last_blocks.contains_key(hash)
  157|      0|    }
  158|       |
  159|      0|    pub fn vote_count(&self) -> usize {
  160|      0|        self.mutex.lock().unwrap().last_votes.len()
  161|      0|    }
  162|       |
  163|      0|    pub fn winner_hash(&self) -> Option<BlockHash> {
  164|      0|        self.mutex
  165|      0|            .lock()
  166|      0|            .unwrap()
  167|      0|            .status
  168|      0|            .winner
  169|      0|            .as_ref()
  170|      0|            .map(|w| w.hash())
  171|      0|    }
  172|       |
  173|      0|    pub fn behavior(&self) -> ElectionBehavior {
  174|      0|        self.mutex.lock().unwrap().behavior
  175|      0|    }
  176|       |}
  177|       |
  178|       |impl Debug for Election {
  179|      0|    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
  180|      0|        f.debug_struct("Election")
  181|      0|            .field("id", &self.id)
  182|      0|            .field("qualified_root", &self.qualified_root)
  183|      0|            .field("height", &self.height)
  184|      0|            .finish()
  185|      0|    }
  186|       |}
  187|       |
  188|       |pub struct ElectionData {
  189|       |    pub status: ElectionStatus,
  190|       |    pub state: ElectionState,
  191|       |    pub state_start: Instant,
  192|       |    pub last_blocks: HashMap<BlockHash, MaybeSavedBlock>,
  193|       |    pub last_votes: HashMap<PublicKey, VoteInfo>,
  194|       |    pub final_weight: Amount,
  195|       |    pub last_tally: HashMap<BlockHash, Amount>,
  196|       |    /** The last time vote for this election was generated */
  197|       |    pub last_vote: Option<Instant>,
  198|       |    pub last_block_hash: BlockHash,
  199|       |    pub behavior: ElectionBehavior,
  200|       |}
  201|       |
  202|       |impl ElectionData {
  203|      0|    pub fn is_confirmed(&self) -> bool {
  204|      0|        matches!(
  205|      0|            self.state,
  206|       |            ElectionState::Confirmed | ElectionState::ExpiredConfirmed
  207|       |        )
  208|      0|    }
  209|       |
  210|      0|    pub fn update_status_to_confirmed(&mut self, election: &Election) {
  211|      0|        self.status.election_end = SystemTime::now();
  212|      0|        self.status.election_duration = election.election_start.elapsed();
  213|      0|        self.status.confirmation_request_count =
  214|      0|            election.confirmation_request_count.load(Ordering::SeqCst);
  215|      0|        self.status.block_count = self.last_blocks.len() as u32;
  216|      0|        self.status.voter_count = self.last_votes.len() as u32;
  217|      0|    }
  218|       |
  219|      0|    pub fn state_change(
  220|      0|        &mut self,
  221|      0|        expected: ElectionState,
  222|      0|        desired: ElectionState,
  223|      0|    ) -> Result<(), ()> {
  224|      0|        if Self::valid_change(expected, desired) {
  225|      0|            if self.state == expected {
  226|      0|                self.state = desired;
  227|      0|                self.state_start = Instant::now();
  228|      0|                return Ok(());
  229|      0|            }
  230|      0|        }
  231|       |
  232|      0|        Err(())
  233|      0|    }
  234|       |
  235|      0|    pub fn time_to_live(&self) -> Duration {
  236|      0|        match self.behavior {
  237|      0|            ElectionBehavior::Manual | ElectionBehavior::Priority => Duration::from_secs(60 * 5),
  238|      0|            ElectionBehavior::Hinted | ElectionBehavior::Optimistic => Duration::from_secs(30),
  239|       |        }
  240|      0|    }
  241|       |
  242|      0|    fn valid_change(expected: ElectionState, desired: ElectionState) -> bool {
  243|      0|        match expected {
  244|      0|            ElectionState::Passive => matches!(
  245|      0|                desired,
  246|       |                ElectionState::Active
  247|       |                    | ElectionState::Confirmed
  248|       |                    | ElectionState::ExpiredUnconfirmed
  249|       |                    | ElectionState::Cancelled
  250|       |            ),
  251|      0|            ElectionState::Active => matches!(
  252|      0|                desired,
  253|       |                ElectionState::Confirmed
  254|       |                    | ElectionState::ExpiredUnconfirmed
  255|       |                    | ElectionState::Cancelled
  256|       |            ),
  257|      0|            ElectionState::Confirmed => matches!(desired, ElectionState::ExpiredConfirmed),
  258|       |            ElectionState::Cancelled
  259|       |            | ElectionState::ExpiredConfirmed
  260|      0|            | ElectionState::ExpiredUnconfirmed => false,
  261|       |        }
  262|      0|    }
  263|       |
  264|      0|    pub fn set_last_vote(&mut self) {
  265|      0|        self.last_vote = Some(Instant::now());
  266|      0|    }
  267|       |
  268|      0|    pub fn last_vote_elapsed(&self) -> Duration {
  269|      0|        match &self.last_vote {
  270|      0|            Some(i) => i.elapsed(),
  271|      0|            None => Duration::from_secs(60 * 60 * 24 * 365), // Duration::MAX caused problems with C++
  272|       |        }
  273|      0|    }
  274|       |}
  275|       |
  276|       |#[derive(Clone)]
  277|       |pub struct VoteInfo {
  278|       |    pub time: SystemTime, // TODO use Instant
  279|       |    pub timestamp: u64,
  280|       |    pub hash: BlockHash,
  281|       |}
  282|       |
  283|       |impl VoteInfo {
  284|      0|    pub fn new(timestamp: u64, hash: BlockHash) -> Self {
  285|      0|        Self {
  286|      0|            time: SystemTime::now(),
  287|      0|            timestamp,
  288|      0|            hash,
  289|      0|        }
  290|      0|    }
  291|       |}
  292|       |
  293|       |impl Default for VoteInfo {
  294|      0|    fn default() -> Self {
  295|      0|        Self::new(0, BlockHash::zero())
  296|      0|    }
  297|       |}
  298|       |
  299|      0|#[derive(FromPrimitive, Copy, Clone, Debug, PartialEq, Eq)]
  300|       |#[repr(u8)]
  301|       |pub enum ElectionState {
  302|       |    Passive,   // only listening for incoming votes
  303|       |    Active,    // actively request confirmations
  304|       |    Confirmed, // confirmed but still listening for votes
  305|       |    ExpiredConfirmed,
  306|       |    ExpiredUnconfirmed,
  307|       |    Cancelled,
  308|       |}
  309|       |
  310|       |impl ElectionState {
  311|      0|    pub fn is_confirmed(&self) -> bool {
  312|      0|        matches!(self, Self::Confirmed | Self::ExpiredConfirmed)
  313|      0|    }
  314|       |}
  315|       |
  316|       |impl From<ElectionState> for StatType {
  317|      0|    fn from(value: ElectionState) -> Self {
  318|      0|        match value {
  319|      0|            ElectionState::Passive | ElectionState::Active => StatType::ActiveElectionsDropped,
  320|       |            ElectionState::Confirmed | ElectionState::ExpiredConfirmed => {
  321|      0|                StatType::ActiveElectionsConfirmed
  322|       |            }
  323|      0|            ElectionState::ExpiredUnconfirmed => StatType::ActiveElectionsTimeout,
  324|      0|            ElectionState::Cancelled => StatType::ActiveElectionsCancelled,
  325|       |        }
  326|      0|    }
  327|       |}
  328|       |
  329|       |impl From<ElectionState> for DetailType {
  330|      0|    fn from(value: ElectionState) -> Self {
  331|      0|        match value {
  332|      0|            ElectionState::Passive => DetailType::Passive,
  333|      0|            ElectionState::Active => DetailType::Active,
  334|      0|            ElectionState::Confirmed => DetailType::Confirmed,
  335|      0|            ElectionState::ExpiredConfirmed => DetailType::ExpiredConfirmed,
  336|      0|            ElectionState::ExpiredUnconfirmed => DetailType::ExpiredUnconfirmed,
  337|      0|            ElectionState::Cancelled => DetailType::Cancelled,
  338|       |        }
  339|      0|    }
  340|       |}
  341|       |
  342|      0|#[derive(FromPrimitive, Copy, Clone, Debug, PartialEq, Eq)]
  343|       |#[repr(u8)]
  344|       |pub enum ElectionBehavior {
  345|       |    Manual,
  346|       |    Priority,
  347|       |    /**
  348|       |     * Hinted elections:
  349|       |     * - shorter timespan
  350|       |     * - limited space inside AEC
  351|       |     */
  352|       |    Hinted,
  353|       |    /**
  354|       |     * Optimistic elections:
  355|       |     * - shorter timespan
  356|       |     * - limited space inside AEC
  357|       |     * - more frequent confirmation requests
  358|       |     */
  359|       |    Optimistic,
  360|       |}
  361|       |
  362|       |impl From<ElectionBehavior> for DetailType {
  363|      0|    fn from(value: ElectionBehavior) -> Self {
  364|      0|        match value {
  365|      0|            ElectionBehavior::Manual => DetailType::Manual,
  366|      0|            ElectionBehavior::Priority => DetailType::Priority,
  367|      0|            ElectionBehavior::Hinted => DetailType::Hinted,
  368|      0|            ElectionBehavior::Optimistic => DetailType::Optimistic,
  369|       |        }
  370|      0|    }
  371|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/election_schedulers/mod.rs:
    1|       |use crate::{
    2|       |    cementation::ConfirmingSet,
    3|       |    config::{NetworkConstants, NodeConfig},
    4|       |    representatives::OnlineReps,
    5|       |    stats::Stats,
    6|       |};
    7|       |
    8|       |use super::{
    9|       |    ActiveElections, HintedScheduler, HintedSchedulerExt, ManualScheduler, ManualSchedulerExt,
   10|       |    OptimisticScheduler, OptimisticSchedulerExt, PriorityScheduler, PrioritySchedulerExt,
   11|       |    VoteCache,
   12|       |};
   13|       |use rsnano_core::{
   14|       |    utils::ContainerInfo, Account, AccountInfo, BlockHash, ConfirmationHeightInfo, SavedBlock,
   15|       |};
   16|       |use rsnano_ledger::Ledger;
   17|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   18|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   19|       |use std::sync::{Arc, Mutex};
   20|       |
   21|       |pub struct ElectionSchedulers {
   22|       |    pub priority: Arc<PriorityScheduler>,
   23|       |    optimistic: Arc<OptimisticScheduler>,
   24|       |    hinted: Arc<HintedScheduler>,
   25|       |    pub manual: Arc<ManualScheduler>,
   26|       |    notify_listener: OutputListenerMt<()>,
   27|       |    config: NodeConfig,
   28|       |}
   29|       |
   30|       |impl ElectionSchedulers {
   31|      3|    pub fn new(
   32|      3|        config: NodeConfig,
   33|      3|        network_constants: NetworkConstants,
   34|      3|        active_elections: Arc<ActiveElections>,
   35|      3|        ledger: Arc<Ledger>,
   36|      3|        stats: Arc<Stats>,
   37|      3|        vote_cache: Arc<Mutex<VoteCache>>,
   38|      3|        confirming_set: Arc<ConfirmingSet>,
   39|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   40|      3|    ) -> Self {
   41|      3|        let hinted = Arc::new(HintedScheduler::new(
   42|      3|            config.hinted_scheduler.clone(),
   43|      3|            active_elections.clone(),
   44|      3|            ledger.clone(),
   45|      3|            stats.clone(),
   46|      3|            vote_cache.clone(),
   47|      3|            confirming_set.clone(),
   48|      3|            online_reps.clone(),
   49|      3|        ));
   50|      3|
   51|      3|        let manual = Arc::new(ManualScheduler::new(
   52|      3|            stats.clone(),
   53|      3|            active_elections.clone(),
   54|      3|        ));
   55|      3|
   56|      3|        let optimistic = Arc::new(OptimisticScheduler::new(
   57|      3|            config.optimistic_scheduler.clone(),
   58|      3|            stats.clone(),
   59|      3|            active_elections.clone(),
   60|      3|            network_constants,
   61|      3|            ledger.clone(),
   62|      3|            confirming_set.clone(),
   63|      3|        ));
   64|      3|
   65|      3|        let priority = Arc::new(PriorityScheduler::new(
   66|      3|            config.priority_bucket.clone(),
   67|      3|            ledger.clone(),
   68|      3|            stats.clone(),
   69|      3|            active_elections.clone(),
   70|      3|        ));
   71|      3|
   72|      3|        Self {
   73|      3|            priority,
   74|      3|            optimistic,
   75|      3|            hinted,
   76|      3|            manual,
   77|      3|            notify_listener: OutputListenerMt::new(),
   78|      3|            config,
   79|      3|        }
   80|      3|    }
   81|       |
   82|       |    /// Does the block exist in any of the schedulers
   83|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   84|      0|        self.manual.contains(hash) || self.priority.contains(hash)
   85|      0|    }
   86|       |
   87|      0|    pub fn activate_successors(&self, tx: &LmdbReadTransaction, block: &SavedBlock) {
   88|      0|        self.priority.activate_successors(tx, block);
   89|      0|    }
   90|       |
   91|      0|    pub fn activate_backlog(
   92|      0|        &self,
   93|      0|        txn: &dyn Transaction,
   94|      0|        account: &Account,
   95|      0|        account_info: &AccountInfo,
   96|      0|        conf_info: &ConfirmationHeightInfo,
   97|      0|    ) {
   98|      0|        self.optimistic.activate(account, account_info, conf_info);
   99|      0|        self.priority
  100|      0|            .activate_with_info(txn, account, account_info, conf_info);
  101|      0|    }
  102|       |
  103|      0|    pub fn activate(&self, tx: &dyn Transaction, account: &Account) -> bool {
  104|      0|        self.priority.activate(tx, account)
  105|      0|    }
  106|       |
  107|      3|    pub fn notify(&self) {
  108|      3|        self.notify_listener.emit(());
  109|      3|        self.priority.notify();
  110|      3|        self.hinted.notify();
  111|      3|        self.optimistic.notify();
  112|      3|    }
  113|       |
  114|      0|    pub fn add_manual(&self, block: SavedBlock) {
  115|      0|        self.manual.push(block, None);
  116|      0|    }
  117|       |
  118|      3|    pub fn start(&self) {
  119|      3|        if self.config.enable_hinted_scheduler {
  120|      3|            self.hinted.start();
  121|      3|        }
                       ^0
  122|      3|        self.manual.start();
  123|      3|        if self.config.enable_optimistic_scheduler {
  124|      3|            self.optimistic.start();
  125|      3|        }
                       ^0
  126|      3|        if self.config.enable_priority_scheduler {
  127|      3|            self.priority.start();
  128|      3|        }
                       ^0
  129|      3|    }
  130|       |
  131|      0|    pub fn track_notify(&self) -> Arc<OutputTrackerMt<()>> {
  132|      0|        self.notify_listener.track()
  133|      0|    }
  134|       |
  135|      3|    pub fn stop(&self) {
  136|      3|        self.hinted.stop();
  137|      3|        self.manual.stop();
  138|      3|        self.optimistic.stop();
  139|      3|        self.priority.stop();
  140|      3|    }
  141|       |
  142|      0|    pub fn container_info(&self) -> ContainerInfo {
  143|      0|        ContainerInfo::builder()
  144|      0|            .node("hinted", self.hinted.container_info())
  145|      0|            .node("manual", self.manual.container_info())
  146|      0|            .node("optimistic", self.optimistic.container_info())
  147|      0|            .node("priority", self.priority.container_info())
  148|      0|            .finish()
  149|      0|    }
  150|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/election_status.rs:
    1|       |use crate::stats::DetailType;
    2|       |use rsnano_core::{Amount, MaybeSavedBlock};
    3|       |use std::time::{Duration, SystemTime};
    4|       |
    5|       |/**
    6|       | * Tag for the type of the election status
    7|       | */
    8|       |#[repr(u8)]
    9|      0|#[derive(PartialEq, Eq, Debug, Clone, Copy, FromPrimitive)]
   10|       |pub enum ElectionStatusType {
   11|       |    Ongoing = 0,
   12|       |    ActiveConfirmedQuorum = 1,
   13|       |    ActiveConfirmationHeight = 2,
   14|       |    InactiveConfirmationHeight = 3,
   15|       |    Stopped = 5,
   16|       |}
   17|       |
   18|       |impl ElectionStatusType {
   19|      0|    pub fn as_str(&self) -> &'static str {
   20|      0|        match self {
   21|      0|            Self::Ongoing => "ongoing",
   22|      0|            Self::ActiveConfirmedQuorum => "active_quorum",
   23|      0|            Self::ActiveConfirmationHeight => "active_confirmation_height",
   24|      0|            Self::InactiveConfirmationHeight => "inactive",
   25|      0|            Self::Stopped => "stopped",
   26|       |        }
   27|      0|    }
   28|       |}
   29|       |
   30|       |impl From<ElectionStatusType> for DetailType {
   31|      0|    fn from(value: ElectionStatusType) -> Self {
   32|      0|        match value {
   33|      0|            ElectionStatusType::Ongoing => DetailType::Ongoing,
   34|      0|            ElectionStatusType::ActiveConfirmedQuorum => DetailType::ActiveConfirmedQuorum,
   35|      0|            ElectionStatusType::ActiveConfirmationHeight => DetailType::ActiveConfirmationHeight,
   36|       |            ElectionStatusType::InactiveConfirmationHeight => {
   37|      0|                DetailType::InactiveConfirmationHeight
   38|       |            }
   39|      0|            ElectionStatusType::Stopped => DetailType::Stopped,
   40|       |        }
   41|      0|    }
   42|       |}
   43|       |
   44|       |/// Information on the status of an election
   45|       |#[derive(Clone)]
   46|       |pub struct ElectionStatus {
   47|       |    pub winner: Option<MaybeSavedBlock>,
   48|       |    pub tally: Amount,
   49|       |    pub final_tally: Amount,
   50|       |    pub confirmation_request_count: u32,
   51|       |    pub block_count: u32,
   52|       |    pub voter_count: u32,
   53|       |    pub election_end: SystemTime,
   54|       |    pub election_duration: Duration,
   55|       |    pub election_status_type: ElectionStatusType,
   56|       |    pub vote_broadcast_count: u32,
   57|       |}
   58|       |
   59|       |impl Default for ElectionStatus {
   60|      0|    fn default() -> Self {
   61|      0|        Self {
   62|      0|            winner: None,
   63|      0|            tally: Amount::zero(),
   64|      0|            final_tally: Amount::zero(),
   65|      0|            block_count: 0,
   66|      0|            voter_count: 0,
   67|      0|            confirmation_request_count: 0,
   68|      0|            election_end: SystemTime::now(),
   69|      0|            election_duration: Duration::ZERO,
   70|      0|            election_status_type: ElectionStatusType::InactiveConfirmationHeight,
   71|      0|            vote_broadcast_count: 0,
   72|      0|        }
   73|      0|    }
   74|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/hinted_scheduler.rs:
    1|       |use super::{ActiveElections, ElectionBehavior, VoteCache};
    2|       |use crate::{
    3|       |    cementation::ConfirmingSet,
    4|       |    consensus::ActiveElectionsExt,
    5|       |    representatives::OnlineReps,
    6|       |    stats::{DetailType, StatType, Stats},
    7|       |};
    8|       |use rsnano_core::{utils::ContainerInfo, Amount, BlockHash};
    9|       |use rsnano_ledger::Ledger;
   10|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   11|       |use std::{
   12|       |    collections::{BTreeMap, HashMap, HashSet},
   13|       |    mem::size_of,
   14|       |    sync::{
   15|       |        atomic::{AtomicBool, Ordering},
   16|       |        Arc, Condvar, Mutex,
   17|       |    },
   18|       |    thread::JoinHandle,
   19|       |    time::{Duration, Instant},
   20|       |};
   21|       |
   22|       |#[derive(Clone, Debug, PartialEq)]
   23|       |pub struct HintedSchedulerConfig {
   24|       |    pub check_interval: Duration,
   25|       |    pub block_cooldown: Duration,
   26|       |    pub hinting_threshold_percent: u32,
   27|       |    pub vacancy_threshold_percent: u32,
   28|       |}
   29|       |
   30|       |impl HintedSchedulerConfig {
   31|      5|    pub fn default_for_dev_network() -> Self {
   32|      5|        Self {
   33|      5|            check_interval: Duration::from_millis(100),
   34|      5|            block_cooldown: Duration::from_millis(100),
   35|      5|            ..Default::default()
   36|      5|        }
   37|      5|    }
   38|       |}
   39|       |
   40|       |impl Default for HintedSchedulerConfig {
   41|      9|    fn default() -> Self {
   42|      9|        Self {
   43|      9|            check_interval: Duration::from_millis(1000),
   44|      9|            block_cooldown: Duration::from_millis(5000),
   45|      9|            hinting_threshold_percent: 10,
   46|      9|            vacancy_threshold_percent: 20,
   47|      9|        }
   48|      9|    }
   49|       |}
   50|       |
   51|       |/// Monitors inactive vote cache and schedules elections with the highest observed vote tally.
   52|       |pub struct HintedScheduler {
   53|       |    thread: Mutex<Option<JoinHandle<()>>>,
   54|       |    config: HintedSchedulerConfig,
   55|       |    active: Arc<ActiveElections>,
   56|       |    condition: Condvar,
   57|       |    ledger: Arc<Ledger>,
   58|       |    confirming_set: Arc<ConfirmingSet>,
   59|       |    stats: Arc<Stats>,
   60|       |    vote_cache: Arc<Mutex<VoteCache>>,
   61|       |    online_reps: Arc<Mutex<OnlineReps>>,
   62|       |    stopped: AtomicBool,
   63|       |    stopped_mutex: Mutex<()>,
   64|       |    cooldowns: Mutex<OrderedCooldowns>,
   65|       |}
   66|       |
   67|       |impl HintedScheduler {
   68|      3|    pub fn new(
   69|      3|        config: HintedSchedulerConfig,
   70|      3|        active: Arc<ActiveElections>,
   71|      3|        ledger: Arc<Ledger>,
   72|      3|        stats: Arc<Stats>,
   73|      3|        vote_cache: Arc<Mutex<VoteCache>>,
   74|      3|        confirming_set: Arc<ConfirmingSet>,
   75|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   76|      3|    ) -> Self {
   77|      3|        Self {
   78|      3|            thread: Mutex::new(None),
   79|      3|            config,
   80|      3|            condition: Condvar::new(),
   81|      3|            active,
   82|      3|            ledger,
   83|      3|            stats,
   84|      3|            vote_cache,
   85|      3|            confirming_set,
   86|      3|            online_reps,
   87|      3|            stopped: AtomicBool::new(false),
   88|      3|            stopped_mutex: Mutex::new(()),
   89|      3|            cooldowns: Mutex::new(OrderedCooldowns::new()),
   90|      3|        }
   91|      3|    }
   92|       |
   93|      3|    pub fn stop(&self) {
   94|      3|        self.stopped.store(true, Ordering::SeqCst);
   95|      3|        self.notify();
   96|      3|        let handle = self.thread.lock().unwrap().take();
   97|      3|        if let Some(handle) = handle {
   98|      3|            handle.join().unwrap();
   99|      3|        }
                       ^0
  100|      3|    }
  101|       |
  102|       |    /// Notify about changes in AEC vacancy
  103|      6|    pub fn notify(&self) {
  104|      6|        // Avoid notifying when there is very little space inside AEC
  105|      6|        let limit = self.active.limit(ElectionBehavior::Hinted);
  106|      6|        if self.active.vacancy(ElectionBehavior::Hinted)
  107|      6|            >= (limit * self.config.vacancy_threshold_percent as usize / 100) as i64
  108|      6|        {
  109|      6|            self.condition.notify_all();
  110|      6|        }
                       ^0
  111|      6|    }
  112|       |
  113|      0|    pub fn container_info(&self) -> ContainerInfo {
  114|      0|        let guard = self.cooldowns.lock().unwrap();
  115|      0|        [(
  116|      0|            "cooldowns",
  117|      0|            guard.len(),
  118|      0|            (size_of::<BlockHash>() + size_of::<Instant>()) * 2,
  119|      0|        )]
  120|      0|        .into()
  121|      0|    }
  122|       |
  123|      0|    fn predicate(&self) -> bool {
  124|      0|        // Check if there is space inside AEC for a new hinted election
  125|      0|        self.active.vacancy(ElectionBehavior::Hinted) > 0
  126|      0|    }
  127|       |
  128|      0|    fn activate(&self, tx: &mut LmdbReadTransaction, hash: BlockHash, check_dependents: bool) {
  129|       |        const MAX_ITERATIONS: usize = 64;
  130|      0|        let mut visited = HashSet::new();
  131|      0|        let mut stack = Vec::new();
  132|      0|        stack.push(hash);
  133|      0|        let mut iterations = 0;
  134|      0|        while let Some(current_hash) = stack.pop() {
  135|      0|            if iterations >= MAX_ITERATIONS {
  136|      0|                break;
  137|      0|            }
  138|      0|            iterations += 1;
  139|      0|            tx.refresh_if_needed();
  140|       |
  141|       |            // Check if block exists
  142|      0|            if let Some(block) = self.ledger.any().get_block(tx, &current_hash) {
  143|       |                // Ensure block is not already confirmed
  144|      0|                if self.confirming_set.contains(&current_hash)
  145|      0|                    || self
  146|      0|                        .ledger
  147|      0|                        .confirmed()
  148|      0|                        .block_exists_or_pruned(tx, &current_hash)
  149|       |                {
  150|      0|                    self.stats
  151|      0|                        .inc(StatType::Hinting, DetailType::AlreadyConfirmed);
  152|      0|                    self.vote_cache.lock().unwrap().erase(&current_hash); // Remove from vote cache
  153|      0|                    continue; // Move on to the next item in the stack
  154|      0|                }
  155|      0|
  156|      0|                if check_dependents {
  157|       |                    // Perform a depth-first search of the dependency graph
  158|      0|                    if !self.ledger.dependents_confirmed(tx, &block) {
  159|      0|                        self.stats
  160|      0|                            .inc(StatType::Hinting, DetailType::DependentUnconfirmed);
  161|      0|                        let dependents = self.ledger.dependent_blocks(tx, &block);
  162|      0|                        for dependent_hash in dependents.iter() {
  163|       |                            // Avoid visiting the same block twice
  164|      0|                            if !dependent_hash.is_zero() && visited.insert(*dependent_hash) {
  165|      0|                                stack.push(*dependent_hash); // Add dependent block to the stack
  166|      0|                            }
  167|       |                        }
  168|      0|                        continue; // Move on to the next item in the stack
  169|      0|                    }
  170|      0|                }
  171|       |
  172|       |                // Try to insert it into AEC as hinted election
  173|      0|                let (inserted, _) = self.active.insert(block, ElectionBehavior::Hinted, None);
  174|      0|                self.stats.inc(
  175|      0|                    StatType::Hinting,
  176|      0|                    if inserted {
  177|      0|                        DetailType::Insert
  178|       |                    } else {
  179|      0|                        DetailType::InsertFailed
  180|       |                    },
  181|       |                );
  182|      0|            } else {
  183|      0|                self.stats.inc(StatType::Hinting, DetailType::MissingBlock);
  184|      0|
  185|      0|                // TODO: Block is missing, bootstrap it
  186|      0|            }
  187|       |        }
  188|      0|    }
  189|       |
  190|      0|    fn run_interactive(&self) {
  191|      0|        let minimum_tally = self.tally_threshold();
  192|      0|        let minimum_final_tally = self.final_tally_threshold();
  193|      0|
  194|      0|        // Get the list before db transaction starts to avoid unnecessary slowdowns
  195|      0|        let tops = self.vote_cache.lock().unwrap().top(minimum_tally);
  196|      0|
  197|      0|        let mut tx = self.ledger.read_txn();
  198|       |
  199|      0|        for entry in tops {
  200|      0|            if self.stopped.load(Ordering::SeqCst) {
  201|      0|                return;
  202|      0|            }
  203|      0|
  204|      0|            if !self.predicate() {
  205|      0|                return;
  206|      0|            }
  207|      0|
  208|      0|            if self.cooldown(entry.hash) {
  209|      0|                continue;
  210|      0|            }
  211|      0|
  212|      0|            // Check dependents only if cached tally is lower than quorum
  213|      0|            if entry.final_tally < minimum_final_tally {
  214|      0|                // Ensure all dependent blocks are already confirmed before activating
  215|      0|                self.stats.inc(StatType::Hinting, DetailType::Activate);
  216|      0|                self.activate(&mut tx, entry.hash, /* activate dependents */ true);
  217|      0|            } else {
  218|      0|                // Blocks with a vote tally higher than quorum, can be activated and confirmed immediately
  219|      0|                self.stats
  220|      0|                    .inc(StatType::Hinting, DetailType::ActivateImmediate);
  221|      0|                self.activate(&mut tx, entry.hash, false);
  222|      0|            }
  223|       |        }
  224|      0|    }
  225|       |
  226|      3|    fn run(&self) {
  227|      3|        let mut guard = self.stopped_mutex.lock().unwrap();
  228|      6|        while !self.stopped.load(Ordering::SeqCst) {
  229|      3|            self.stats.inc(StatType::Hinting, DetailType::Loop);
  230|      3|            guard = self
  231|      3|                .condition
  232|      6|                .wait_timeout_while(guard, self.config.check_interval, |_| {
  233|      6|                    !self.stopped.load(Ordering::SeqCst)
  234|      6|                })
  235|      3|                .unwrap()
  236|      3|                .0;
  237|      3|            if !self.stopped.load(Ordering::SeqCst) {
  238|      0|                drop(guard);
  239|      0|                if self.predicate() {
  240|      0|                    self.run_interactive()
  241|      0|                }
  242|      0|                guard = self.stopped_mutex.lock().unwrap();
  243|      3|            }
  244|       |        }
  245|      3|    }
  246|       |
  247|      0|    fn tally_threshold(&self) -> Amount {
  248|      0|        (self.online_reps.lock().unwrap().trended_or_minimum_weight() / 100)
  249|      0|            * self.config.hinting_threshold_percent as u128
  250|      0|    }
  251|       |
  252|      0|    fn final_tally_threshold(&self) -> Amount {
  253|      0|        self.online_reps.lock().unwrap().quorum_delta()
  254|      0|    }
  255|       |
  256|      0|    fn cooldown(&self, hash: BlockHash) -> bool {
  257|      0|        let mut guard = self.cooldowns.lock().unwrap();
  258|      0|        let now = Instant::now();
  259|       |        // Check if the hash is still in the cooldown period using the hashed index
  260|      0|        if let Some(timeout) = guard.get(&hash) {
  261|      0|            if *timeout > now {
  262|      0|                return true; // Needs cooldown
  263|      0|            }
  264|      0|            guard.remove(&hash); // Entry is outdated, so remove it
  265|      0|        }
  266|       |
  267|       |        // Insert the new entry
  268|      0|        guard.insert(hash, now + self.config.block_cooldown);
  269|      0|
  270|      0|        // Trim old entries
  271|      0|        guard.trim(now);
  272|      0|        false // No need to cooldown
  273|      0|    }
  274|       |}
  275|       |
  276|       |impl Drop for HintedScheduler {
  277|      3|    fn drop(&mut self) {
  278|      3|        // Thread must be stopped before destruction
  279|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  280|      3|    }
  281|       |}
  282|       |
  283|       |pub trait HintedSchedulerExt {
  284|       |    fn start(&self);
  285|       |}
  286|       |
  287|       |impl HintedSchedulerExt for Arc<HintedScheduler> {
  288|      3|    fn start(&self) {
  289|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  290|      3|        let self_l = Arc::clone(self);
  291|      3|        *self.thread.lock().unwrap() = Some(
  292|      3|            std::thread::Builder::new()
  293|      3|                .name("Sched Hinted".to_string())
  294|      3|                .spawn(Box::new(move || {
  295|      3|                    self_l.run();
  296|      3|                }))
  297|      3|                .unwrap(),
  298|      3|        );
  299|      3|    }
  300|       |}
  301|       |
  302|       |struct OrderedCooldowns {
  303|       |    by_hash: HashMap<BlockHash, Instant>,
  304|       |    by_time: BTreeMap<Instant, Vec<BlockHash>>,
  305|       |}
  306|       |
  307|       |impl OrderedCooldowns {
  308|      3|    fn new() -> Self {
  309|      3|        Self {
  310|      3|            by_hash: HashMap::new(),
  311|      3|            by_time: BTreeMap::new(),
  312|      3|        }
  313|      3|    }
  314|      0|    fn insert(&mut self, hash: BlockHash, timeout: Instant) {
  315|      0|        if let Some(old_timeout) = self.by_hash.insert(hash, timeout) {
  316|      0|            self.remove_timeout_entry(&hash, old_timeout);
  317|      0|        }
  318|      0|        self.by_time.entry(timeout).or_default().push(hash);
  319|      0|    }
  320|       |
  321|      0|    fn get(&self, hash: &BlockHash) -> Option<&Instant> {
  322|      0|        self.by_hash.get(hash)
  323|      0|    }
  324|       |
  325|      0|    fn remove(&mut self, hash: &BlockHash) {
  326|      0|        if let Some(timeout) = self.by_hash.remove(hash) {
  327|      0|            self.remove_timeout_entry(hash, timeout);
  328|      0|        }
  329|      0|    }
  330|       |
  331|      0|    fn remove_timeout_entry(&mut self, hash: &BlockHash, timeout: Instant) {
  332|      0|        if let Some(hashes) = self.by_time.get_mut(&timeout) {
  333|      0|            if hashes.len() == 1 {
  334|      0|                self.by_time.remove(&timeout);
  335|      0|            } else {
  336|      0|                hashes.retain(|h| h != hash)
  337|       |            }
  338|      0|        }
  339|      0|    }
  340|       |
  341|      0|    fn trim(&mut self, now: Instant) {
  342|      0|        while let Some(entry) = self.by_time.first_entry() {
  343|      0|            if *entry.key() <= now {
  344|      0|                entry.remove();
  345|      0|                // TODO
  346|      0|            } else {
  347|      0|                break;
  348|       |            }
  349|       |        }
  350|      0|    }
  351|       |
  352|      0|    fn len(&self) -> usize {
  353|      0|        self.by_hash.len()
  354|      0|    }
  355|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/manual_scheduler.rs:
    1|       |use super::{ActiveElections, ActiveElectionsExt, ElectionBehavior};
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::{utils::ContainerInfo, Amount, Block, BlockHash, SavedBlock};
    4|       |use std::{
    5|       |    collections::VecDeque,
    6|       |    mem::size_of,
    7|       |    sync::{Arc, Condvar, Mutex},
    8|       |    thread::JoinHandle,
    9|       |};
   10|       |
   11|       |pub struct ManualScheduler {
   12|       |    thread: Mutex<Option<JoinHandle<()>>>,
   13|       |    condition: Condvar,
   14|       |    mutex: Mutex<ManualSchedulerImpl>,
   15|       |    stats: Arc<Stats>,
   16|       |    active: Arc<ActiveElections>,
   17|       |}
   18|       |
   19|       |impl ManualScheduler {
   20|      3|    pub fn new(stats: Arc<Stats>, active: Arc<ActiveElections>) -> Self {
   21|      3|        Self {
   22|      3|            thread: Mutex::new(None),
   23|      3|            condition: Condvar::new(),
   24|      3|            stats,
   25|      3|            active,
   26|      3|            mutex: Mutex::new(ManualSchedulerImpl {
   27|      3|                queue: Default::default(),
   28|      3|                stopped: false,
   29|      3|            }),
   30|      3|        }
   31|      3|    }
   32|       |
   33|      3|    pub fn stop(&self) {
   34|      3|        self.mutex.lock().unwrap().stopped = true;
   35|      3|        self.notify();
   36|      3|        let handle = self.thread.lock().unwrap().take();
   37|      3|        if let Some(handle) = handle {
   38|      3|            handle.join().unwrap();
   39|      3|        }
                       ^0
   40|      3|    }
   41|       |
   42|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   43|      0|        self.mutex
   44|      0|            .lock()
   45|      0|            .unwrap()
   46|      0|            .queue
   47|      0|            .iter()
   48|      0|            .any(|(block, _, _)| block.hash() == *hash)
   49|      0|    }
   50|       |
   51|      3|    pub fn notify(&self) {
   52|      3|        self.condition.notify_all();
   53|      3|    }
   54|       |
   55|      0|    pub fn push(&self, block: SavedBlock, previous_balance: Option<Amount>) {
   56|      0|        let mut guard = self.mutex.lock().unwrap();
   57|      0|        guard
   58|      0|            .queue
   59|      0|            .push_back((block, previous_balance, ElectionBehavior::Manual));
   60|      0|        self.notify();
   61|      0|    }
   62|       |
   63|      3|    fn run(&self) {
   64|      3|        let mut guard = self.mutex.lock().unwrap();
   65|      6|        while !guard.stopped {
   66|      3|            guard = self
   67|      3|                .condition
   68|      6|                .wait_while(guard, |g| !g.stopped && !g.predicate())
                                                                   ^3
   69|      3|                .unwrap();
   70|      3|
   71|      3|            if !guard.stopped {
   72|      0|                self.stats
   73|      0|                    .inc(StatType::ElectionScheduler, DetailType::Loop);
   74|      0|
   75|      0|                if guard.predicate() {
   76|      0|                    let (block, _previous_balance, election_behavior) =
   77|      0|                        guard.queue.pop_front().unwrap();
   78|      0|
   79|      0|                    drop(guard);
   80|      0|
   81|      0|                    self.stats
   82|      0|                        .inc(StatType::ElectionScheduler, DetailType::InsertManual);
   83|      0|
   84|      0|                    let (_inserted, election) = self.active.insert(block, election_behavior, None);
   85|      0|                    if let Some(election) = election {
   86|      0|                        election.transition_active();
   87|      0|                    }
   88|      0|                } else {
   89|      0|                    drop(guard);
   90|      0|                }
   91|      0|                self.notify();
   92|      0|                guard = self.mutex.lock().unwrap();
   93|      3|            }
   94|       |        }
   95|      3|    }
   96|       |
   97|      0|    pub fn container_info(&self) -> ContainerInfo {
   98|      0|        let guard = self.mutex.lock().unwrap();
   99|      0|        [(
  100|      0|            "queue",
  101|      0|            guard.queue.len(),
  102|      0|            size_of::<Arc<Block>>() + size_of::<Option<Amount>>() + size_of::<ElectionBehavior>(),
  103|      0|        )]
  104|      0|        .into()
  105|      0|    }
  106|       |}
  107|       |
  108|       |impl Drop for ManualScheduler {
  109|      3|    fn drop(&mut self) {
  110|      3|        // Thread must be stopped before destruction
  111|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  112|      3|    }
  113|       |}
  114|       |
  115|       |pub trait ManualSchedulerExt {
  116|       |    fn start(&self);
  117|       |}
  118|       |
  119|       |impl ManualSchedulerExt for Arc<ManualScheduler> {
  120|      3|    fn start(&self) {
  121|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  122|      3|        let self_l = Arc::clone(self);
  123|      3|        *self.thread.lock().unwrap() = Some(
  124|      3|            std::thread::Builder::new()
  125|      3|                .name("Sched Manual".to_string())
  126|      3|                .spawn(Box::new(move || {
  127|      3|                    self_l.run();
  128|      3|                }))
  129|      3|                .unwrap(),
  130|      3|        )
  131|      3|    }
  132|       |}
  133|       |
  134|       |struct ManualSchedulerImpl {
  135|       |    queue: VecDeque<(SavedBlock, Option<Amount>, ElectionBehavior)>,
  136|       |    stopped: bool,
  137|       |}
  138|       |
  139|       |impl ManualSchedulerImpl {
  140|      3|    fn predicate(&self) -> bool {
  141|      3|        !self.queue.is_empty()
  142|      3|    }
  143|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/optimistic_scheduler.rs:
    1|       |use super::{ActiveElections, ActiveElectionsExt, ElectionBehavior};
    2|       |use crate::{
    3|       |    cementation::ConfirmingSet,
    4|       |    config::NetworkConstants,
    5|       |    stats::{DetailType, StatType, Stats},
    6|       |};
    7|       |use rsnano_core::{utils::ContainerInfo, Account, AccountInfo, ConfirmationHeightInfo};
    8|       |use rsnano_ledger::Ledger;
    9|       |use rsnano_store_lmdb::LmdbReadTransaction;
   10|       |use std::{
   11|       |    collections::{HashMap, VecDeque},
   12|       |    mem::size_of,
   13|       |    sync::{
   14|       |        atomic::{AtomicBool, Ordering},
   15|       |        Arc, Condvar, Mutex,
   16|       |    },
   17|       |    thread::JoinHandle,
   18|       |    time::Instant,
   19|       |};
   20|       |
   21|       |#[derive(Clone, Debug, PartialEq)]
   22|       |pub struct OptimisticSchedulerConfig {
   23|       |    /// Minimum difference between confirmation frontier and account frontier to become a candidate for optimistic confirmation
   24|       |    pub gap_threshold: u64,
   25|       |
   26|       |    /// Maximum number of candidates stored in memory
   27|       |    pub max_size: usize,
   28|       |}
   29|       |
   30|       |impl OptimisticSchedulerConfig {
   31|      9|    pub fn new() -> Self {
   32|      9|        Self {
   33|      9|            gap_threshold: 32,
   34|      9|            max_size: 1024 * 64,
   35|      9|        }
   36|      9|    }
   37|       |}
   38|       |
   39|       |impl Default for OptimisticSchedulerConfig {
   40|      0|    fn default() -> Self {
   41|      0|        Self::new()
   42|      0|    }
   43|       |}
   44|       |
   45|       |pub struct OptimisticScheduler {
   46|       |    thread: Mutex<Option<JoinHandle<()>>>,
   47|       |    config: OptimisticSchedulerConfig,
   48|       |    stopped: AtomicBool,
   49|       |    condition: Condvar,
   50|       |    candidates: Mutex<OrderedCandidates>,
   51|       |    stats: Arc<Stats>,
   52|       |    active: Arc<ActiveElections>,
   53|       |    network_constants: NetworkConstants,
   54|       |    ledger: Arc<Ledger>,
   55|       |    confirming_set: Arc<ConfirmingSet>,
   56|       |}
   57|       |
   58|       |impl OptimisticScheduler {
   59|      3|    pub fn new(
   60|      3|        config: OptimisticSchedulerConfig,
   61|      3|        stats: Arc<Stats>,
   62|      3|        active: Arc<ActiveElections>,
   63|      3|        network_constants: NetworkConstants,
   64|      3|        ledger: Arc<Ledger>,
   65|      3|        confirming_set: Arc<ConfirmingSet>,
   66|      3|    ) -> Self {
   67|      3|        Self {
   68|      3|            thread: Mutex::new(None),
   69|      3|            config,
   70|      3|            stopped: AtomicBool::new(true),
   71|      3|            condition: Condvar::new(),
   72|      3|            candidates: Mutex::new(OrderedCandidates::default()),
   73|      3|            stats,
   74|      3|            active,
   75|      3|            network_constants,
   76|      3|            ledger,
   77|      3|            confirming_set,
   78|      3|        }
   79|      3|    }
   80|       |
   81|      3|    pub fn stop(&self) {
   82|      3|        self.stopped.store(true, Ordering::SeqCst);
   83|      3|        self.notify();
   84|      3|        let handle = self.thread.lock().unwrap().take();
   85|      3|        if let Some(handle) = handle {
   86|      3|            handle.join().unwrap();
   87|      3|        }
                       ^0
   88|      3|    }
   89|       |
   90|       |    /// Notify about changes in AEC vacancy
   91|      6|    pub fn notify(&self) {
   92|      6|        self.condition.notify_all();
   93|      6|    }
   94|       |
   95|      0|    fn activate_predicate(
   96|      0|        &self,
   97|      0|        account_info: &AccountInfo,
   98|      0|        conf_info: &ConfirmationHeightInfo,
   99|      0|    ) -> bool {
  100|      0|        let big_enough_gap =
  101|      0|            account_info.block_count - conf_info.height > self.config.gap_threshold;
  102|      0|
  103|      0|        let nothing_confirmed_yet = conf_info.height == 0;
  104|      0|
  105|      0|        big_enough_gap | nothing_confirmed_yet
  106|      0|    }
  107|       |
  108|       |    /// Called from backlog population to process accounts with unconfirmed blocks
  109|      0|    pub fn activate(
  110|      0|        &self,
  111|      0|        account: &Account,
  112|      0|        account_info: &AccountInfo,
  113|      0|        conf_info: &ConfirmationHeightInfo,
  114|      0|    ) -> bool {
  115|      0|        if self.stopped.load(Ordering::Relaxed) {
  116|      0|            return false;
  117|      0|        }
  118|      0|
  119|      0|        if self.activate_predicate(account_info, conf_info) {
  120|       |            {
  121|      0|                let mut candidates = self.candidates.lock().unwrap();
  122|      0|                // Prevent duplicate candidate accounts
  123|      0|                if candidates.contains(&account) {
  124|      0|                    return false; // Not activated
  125|      0|                }
  126|      0|                // Limit candidates container size
  127|      0|                if candidates.len() >= self.config.max_size {
  128|      0|                    return false; // Not activated
  129|      0|                }
  130|      0|
  131|      0|                self.stats
  132|      0|                    .inc(StatType::OptimisticScheduler, DetailType::Activated);
  133|      0|                candidates.insert(*account, Instant::now());
  134|      0|            }
  135|      0|            true // Activated
  136|       |        } else {
  137|      0|            false // Not activated
  138|       |        }
  139|      0|    }
  140|       |
  141|      0|    pub fn container_info(&self) -> ContainerInfo {
  142|      0|        let guard = self.candidates.lock().unwrap();
  143|      0|        [(
  144|      0|            "candidates",
  145|      0|            guard.len(),
  146|      0|            size_of::<Account>() * 2 + size_of::<Instant>(),
  147|      0|        )]
  148|      0|        .into()
  149|      0|    }
  150|       |
  151|      6|    fn predicate(&self, candidates: &OrderedCandidates) -> bool {
  152|      6|        if self.active.vacancy(ElectionBehavior::Optimistic) <= 0 {
  153|      0|            return false;
  154|      6|        }
  155|      6|        if let Some((_account, time)) = candidates.front() {
                                   ^0
  156|      0|            time.elapsed() >= self.network_constants.optimistic_activation_delay
  157|       |        } else {
  158|      6|            false
  159|       |        }
  160|      6|    }
  161|       |
  162|      3|    fn run(&self) {
  163|      3|        let mut guard = self.candidates.lock().unwrap();
  164|      6|        while !self.stopped.load(Ordering::SeqCst) {
  165|      3|            self.stats
  166|      3|                .inc(StatType::OptimisticScheduler, DetailType::Loop);
  167|      3|
  168|      3|            if self.predicate(&guard) {
  169|      0|                let tx = self.ledger.read_txn();
  170|       |
  171|      0|                while self.predicate(&guard) {
  172|      0|                    let (account, time) = guard.pop_front().unwrap();
  173|      0|                    drop(guard);
  174|      0|                    self.run_one(&tx, account, time);
  175|      0|                    guard = self.candidates.lock().unwrap();
  176|      0|                }
  177|      3|            }
  178|       |
  179|      3|            guard = self
  180|      3|                .condition
  181|      3|                .wait_timeout_while(
  182|      3|                    guard,
  183|      3|                    self.network_constants.optimistic_activation_delay / 2,
  184|      6|                    |g| !self.stopped.load(Ordering::SeqCst) && !self.predicate(g),
                                                                              ^3
  185|      3|                )
  186|      3|                .unwrap()
  187|      3|                .0;
  188|       |        }
  189|      3|    }
  190|       |
  191|      0|    fn run_one(&self, tx: &LmdbReadTransaction, account: Account, _time: Instant) {
  192|      0|        let any = self.ledger.any();
  193|      0|        let Some(head) = any.account_head(tx, &account) else {
  194|      0|            return;
  195|       |        };
  196|      0|        if let Some(block) = any.get_block(tx, &head) {
  197|       |            // Ensure block is not already confirmed
  198|      0|            if !self.confirming_set.contains(&block.hash())
  199|      0|                || self
  200|      0|                    .ledger
  201|      0|                    .confirmed()
  202|      0|                    .block_exists_or_pruned(tx, &block.hash())
  203|       |            {
  204|       |                // Try to insert it into AEC
  205|       |                // We check for AEC vacancy inside our predicate
  206|      0|                let (inserted, _) = self
  207|      0|                    .active
  208|      0|                    .insert(block, ElectionBehavior::Optimistic, None);
  209|      0|                self.stats.inc(
  210|      0|                    StatType::OptimisticScheduler,
  211|      0|                    if inserted {
  212|      0|                        DetailType::Insert
  213|       |                    } else {
  214|      0|                        DetailType::InsertFailed
  215|       |                    },
  216|       |                );
  217|      0|            }
  218|      0|        }
  219|      0|    }
  220|       |}
  221|       |
  222|       |impl Drop for OptimisticScheduler {
  223|      3|    fn drop(&mut self) {
  224|      3|        // Thread must be stopped before destruction
  225|      3|        debug_assert!(self.thread.lock().unwrap().is_none())
  226|      3|    }
  227|       |}
  228|       |
  229|       |pub trait OptimisticSchedulerExt {
  230|       |    fn start(&self);
  231|       |}
  232|       |
  233|       |impl OptimisticSchedulerExt for Arc<OptimisticScheduler> {
  234|      3|    fn start(&self) {
  235|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  236|      3|        self.stopped.store(false, Ordering::SeqCst);
  237|      3|        let self_l = Arc::clone(self);
  238|      3|        *self.thread.lock().unwrap() = Some(
  239|      3|            std::thread::Builder::new()
  240|      3|                .name("Sched Opt".to_string())
  241|      3|                .spawn(Box::new(move || {
  242|      3|                    self_l.run();
  243|      3|                }))
  244|      3|                .unwrap(),
  245|      3|        );
  246|      3|    }
  247|       |}
  248|       |
  249|       |#[derive(Default)]
  250|       |struct OrderedCandidates {
  251|       |    by_account: HashMap<Account, Instant>,
  252|       |    sequenced: VecDeque<Account>,
  253|       |}
  254|       |
  255|       |impl OrderedCandidates {
  256|      0|    fn insert(&mut self, account: Account, time: Instant) {
  257|      0|        if let Some(_) = self.by_account.insert(account, time) {
  258|      0|            self.sequenced.retain(|i| *i != account);
  259|      0|        }
  260|      0|        self.sequenced.push_back(account);
  261|      0|    }
  262|       |
  263|      0|    fn len(&self) -> usize {
  264|      0|        self.sequenced.len()
  265|      0|    }
  266|       |
  267|      0|    fn contains(&self, account: &Account) -> bool {
  268|      0|        self.by_account.contains_key(account)
  269|      0|    }
  270|       |
  271|      6|    fn front(&self) -> Option<(Account, Instant)> {
  272|      6|        self.sequenced
  273|      6|            .front()
  274|      6|            .and_then(|account| self.by_account.get(account).map(|time| (*account, *time)))
                                              ^0                                      ^0               ^0
  275|      6|    }
  276|       |
  277|      0|    fn pop_front(&mut self) -> Option<(Account, Instant)> {
  278|      0|        self.sequenced.pop_front().map(|account| {
  279|      0|            let time = self.by_account.remove(&account).unwrap();
  280|      0|            (account, time)
  281|      0|        })
  282|      0|    }
  283|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/ordered_blocks.rs:
    1|       |use rsnano_core::{utils::UnixTimestamp, BlockHash, SavedBlock};
    2|       |use std::{
    3|       |    cmp::Ordering,
    4|       |    collections::{BTreeSet, HashSet},
    5|       |};
    6|       |
    7|       |pub(super) struct BlockEntry {
    8|       |    pub time: UnixTimestamp,
    9|       |    pub block: SavedBlock,
   10|       |}
   11|       |
   12|       |impl BlockEntry {
   13|      0|    pub fn hash(&self) -> BlockHash {
   14|      0|        self.block.hash()
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl Ord for BlockEntry {
   19|      0|    fn cmp(&self, other: &Self) -> Ordering {
   20|      0|        let time_order = self.time.cmp(&other.time);
   21|      0|        match time_order {
   22|      0|            Ordering::Equal => self.block.hash().cmp(&other.block.hash()),
   23|      0|            _ => time_order,
   24|       |        }
   25|      0|    }
   26|       |}
   27|       |
   28|       |impl PartialOrd for BlockEntry {
   29|      0|    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
   30|      0|        Some(self.cmp(other))
   31|      0|    }
   32|       |}
   33|       |
   34|       |impl PartialEq for BlockEntry {
   35|      0|    fn eq(&self, other: &Self) -> bool {
   36|      0|        self.time == other.time && self.block.hash() == other.block.hash()
   37|      0|    }
   38|       |}
   39|       |
   40|       |impl Eq for BlockEntry {}
   41|       |
   42|       |#[derive(Default)]
   43|       |pub(super) struct OrderedBlocks {
   44|       |    hashes: HashSet<BlockHash>,
   45|       |    by_priority: BTreeSet<BlockEntry>,
   46|       |}
   47|       |
   48|       |impl OrderedBlocks {
   49|      1|    pub fn len(&self) -> usize {
   50|      1|        self.hashes.len()
   51|      1|    }
   52|       |
   53|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   54|      0|        self.hashes.contains(hash)
   55|      0|    }
   56|       |
   57|      0|    pub fn insert(&mut self, entry: BlockEntry) -> bool {
   58|      0|        if self.hashes.contains(&entry.hash()) {
   59|      0|            return false;
   60|      0|        }
   61|      0|
   62|      0|        self.hashes.insert(entry.hash());
   63|      0|        self.by_priority.insert(entry);
   64|      0|        true
   65|      0|    }
   66|       |
   67|    189|    pub fn first(&self) -> Option<&BlockEntry> {
   68|    189|        self.by_priority.first()
   69|    189|    }
   70|       |
   71|      0|    pub fn pop_first(&mut self) -> Option<BlockEntry> {
   72|      0|        let first = self.by_priority.pop_first()?;
   73|      0|        self.hashes.remove(&first.hash());
   74|      0|        Some(first)
   75|      0|    }
   76|       |
   77|      0|    pub fn pop_last(&mut self) -> Option<BlockEntry> {
   78|      0|        let last = self.by_priority.pop_last()?;
   79|      0|        self.hashes.remove(&last.hash());
   80|      0|        Some(last)
   81|      0|    }
   82|       |
   83|      0|    pub fn iter(&self) -> impl Iterator<Item = &BlockEntry> {
   84|      0|        self.by_priority.iter()
   85|      0|    }
   86|       |}
   87|       |
   88|       |#[cfg(test)]
   89|       |mod tests {
   90|       |    use super::*;
   91|       |
   92|       |    #[test]
   93|      1|    fn empty() {
   94|      1|        let blocks = OrderedBlocks::default();
   95|      1|        assert_eq!(blocks.len(), 0);
   96|      1|    }
   97|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/priority_scheduler.rs:
    1|       |use super::{bucketing::Bucketing, ActiveElections, Bucket, BucketExt, PriorityBucketConfig};
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::{
    4|       |    utils::ContainerInfo, Account, AccountInfo, Amount, BlockHash, ConfirmationHeightInfo,
    5|       |    SavedBlock,
    6|       |};
    7|       |use rsnano_ledger::Ledger;
    8|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
    9|       |use std::{
   10|       |    sync::{Arc, Condvar, Mutex},
   11|       |    thread::JoinHandle,
   12|       |    time::Duration,
   13|       |};
   14|       |use tracing::trace;
   15|       |
   16|       |pub struct PriorityScheduler {
   17|       |    mutex: Mutex<PrioritySchedulerImpl>,
   18|       |    condition: Condvar,
   19|       |    ledger: Arc<Ledger>,
   20|       |    stats: Arc<Stats>,
   21|       |    bucketing: Bucketing,
   22|       |    buckets: Vec<Arc<Bucket>>,
   23|       |    thread: Mutex<Option<JoinHandle<()>>>,
   24|       |    cleanup_thread: Mutex<Option<JoinHandle<()>>>,
   25|       |}
   26|       |
   27|       |impl PriorityScheduler {
   28|      3|    pub(crate) fn new(
   29|      3|        config: PriorityBucketConfig,
   30|      3|        ledger: Arc<Ledger>,
   31|      3|        stats: Arc<Stats>,
   32|      3|        active: Arc<ActiveElections>,
   33|      3|    ) -> Self {
   34|      3|        let bucketing = Bucketing::default();
   35|      3|        let mut buckets = Vec::with_capacity(bucketing.bucket_count());
   36|      3|        for _ in 0..bucketing.bucket_count() {
   37|    189|            buckets.push(Arc::new(Bucket::new(
   38|    189|                config.clone(),
   39|    189|                active.clone(),
   40|    189|                stats.clone(),
   41|    189|            )))
   42|       |        }
   43|       |
   44|      3|        Self {
   45|      3|            thread: Mutex::new(None),
   46|      3|            cleanup_thread: Mutex::new(None),
   47|      3|            mutex: Mutex::new(PrioritySchedulerImpl { stopped: false }),
   48|      3|            condition: Condvar::new(),
   49|      3|            buckets,
   50|      3|            bucketing,
   51|      3|            ledger,
   52|      3|            stats,
   53|      3|        }
   54|      3|    }
   55|       |
   56|      3|    pub fn bucketing(&self) -> &Bucketing {
   57|      3|        &self.bucketing
   58|      3|    }
   59|       |
   60|      3|    pub fn stop(&self) {
   61|      3|        self.mutex.lock().unwrap().stopped = true;
   62|      3|        self.condition.notify_all();
   63|      3|        let handle = self.thread.lock().unwrap().take();
   64|      3|        if let Some(handle) = handle {
   65|      3|            handle.join().unwrap();
   66|      3|        }
                       ^0
   67|      3|        let handle = self.cleanup_thread.lock().unwrap().take();
   68|      3|        if let Some(handle) = handle {
   69|      3|            handle.join().unwrap();
   70|      3|        }
                       ^0
   71|      3|    }
   72|       |
   73|      3|    pub fn notify(&self) {
   74|      3|        self.condition.notify_all();
   75|      3|    }
   76|       |
   77|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   78|      0|        self.buckets.iter().any(|b| b.contains(hash))
   79|      0|    }
   80|       |
   81|      0|    pub fn activate(&self, tx: &dyn Transaction, account: &Account) -> bool {
   82|      0|        debug_assert!(!account.is_zero());
   83|      0|        if let Some(account_info) = self.ledger.any().get_account(tx, account) {
   84|      0|            let conf_info = self
   85|      0|                .ledger
   86|      0|                .store
   87|      0|                .confirmation_height
   88|      0|                .get(tx, account)
   89|      0|                .unwrap_or_default();
   90|      0|            if conf_info.height < account_info.block_count {
   91|      0|                return self.activate_with_info(tx, account, &account_info, &conf_info);
   92|      0|            }
   93|      0|        };
   94|       |
   95|      0|        self.stats
   96|      0|            .inc(StatType::ElectionScheduler, DetailType::ActivateSkip);
   97|      0|        false // Not activated
   98|      0|    }
   99|       |
  100|      0|    pub fn activate_with_info(
  101|      0|        &self,
  102|      0|        tx: &dyn Transaction,
  103|      0|        account: &Account,
  104|      0|        account_info: &AccountInfo,
  105|      0|        conf_info: &ConfirmationHeightInfo,
  106|      0|    ) -> bool {
  107|      0|        debug_assert!(conf_info.frontier != account_info.head);
  108|       |
  109|      0|        let hash = match conf_info.height {
  110|      0|            0 => account_info.open_block,
  111|      0|            _ => self
  112|      0|                .ledger
  113|      0|                .any()
  114|      0|                .block_successor(tx, &conf_info.frontier)
  115|      0|                .unwrap(),
  116|       |        };
  117|       |
  118|      0|        let Some(block) = self.ledger.any().get_block(tx, &hash) else {
  119|       |            // Not activated
  120|      0|            return false;
  121|       |        };
  122|       |
  123|      0|        if !self.ledger.dependents_confirmed(tx, &block) {
  124|      0|            self.stats
  125|      0|                .inc(StatType::ElectionScheduler, DetailType::ActivateFailed);
  126|      0|            return false; // Not activated
  127|      0|        }
  128|      0|
  129|      0|        let (priority_balance, priority_timestamp) = self.ledger.block_priority(tx, &block);
  130|      0|
  131|      0|        let added = self
  132|      0|            .find_bucket(priority_balance)
  133|      0|            .push(priority_timestamp, block.into());
  134|      0|
  135|      0|        if added {
  136|      0|            self.stats
  137|      0|                .inc(StatType::ElectionScheduler, DetailType::Activated);
  138|      0|            trace!(
  139|      0|                account = account.encode_account(),
  140|      0|                time = %account_info.modified,
  141|      0|                priority_balance = ?priority_balance,
  142|      0|                priority_timestamp = ?priority_timestamp,
  143|      0|                "block activated"
  144|       |            );
  145|      0|            self.condition.notify_all();
  146|      0|        } else {
  147|      0|            self.stats
  148|      0|                .inc(StatType::ElectionScheduler, DetailType::ActivateFull);
  149|      0|        }
  150|       |
  151|      0|        true // Activated
  152|      0|    }
  153|       |
  154|      0|    fn find_bucket(&self, priority: Amount) -> &Bucket {
  155|      0|        let index = self.bucketing.bucket_index(priority);
  156|      0|        &self.buckets[index]
  157|      0|    }
  158|       |
  159|      0|    pub fn len(&self) -> usize {
  160|      0|        self.buckets.iter().map(|b| b.len()).sum()
  161|      0|    }
  162|       |
  163|      0|    pub fn is_empty(&self) -> bool {
  164|      0|        self.len() == 0
  165|      0|    }
  166|       |
  167|      3|    fn predicate(&self) -> bool {
  168|    189|        self.buckets.iter().any(|b| b.available())
  169|      3|    }
  170|       |
  171|      3|    fn run(&self) {
  172|      3|        let mut guard = self.mutex.lock().unwrap();
  173|      6|        while !guard.stopped {
  174|      3|            guard = self
  175|      3|                .condition
  176|      6|                .wait_while(guard, |i| !i.stopped && !self.predicate())
                                                                   ^3
  177|      3|                .unwrap();
  178|      3|            if !guard.stopped {
  179|      0|                drop(guard);
  180|      0|                self.stats
  181|      0|                    .inc(StatType::ElectionScheduler, DetailType::Loop);
  182|       |
  183|      0|                for bucket in &self.buckets {
  184|      0|                    if bucket.available() {
  185|      0|                        bucket.activate();
  186|      0|                    }
  187|       |                }
  188|       |
  189|      0|                guard = self.mutex.lock().unwrap();
  190|      3|            }
  191|       |        }
  192|      3|    }
  193|       |
  194|      3|    fn run_cleanup(&self) {
  195|      3|        let mut guard = self.mutex.lock().unwrap();
  196|      6|        while !guard.stopped {
  197|      3|            guard = self
  198|      3|                .condition
  199|      6|                .wait_timeout_while(guard, Duration::from_secs(1), |i| !i.stopped)
  200|      3|                .unwrap()
  201|      3|                .0;
  202|      3|
  203|      3|            if !guard.stopped {
  204|      0|                drop(guard);
  205|      0|                self.stats
  206|      0|                    .inc(StatType::ElectionScheduler, DetailType::Cleanup);
  207|      0|                for bucket in &self.buckets {
  208|      0|                    bucket.update();
  209|      0|                }
  210|       |
  211|      0|                guard = self.mutex.lock().unwrap();
  212|      3|            }
  213|       |        }
  214|      3|    }
  215|       |
  216|      0|    pub fn activate_successors(&self, tx: &LmdbReadTransaction, block: &SavedBlock) -> bool {
  217|      0|        let mut result = self.activate(tx, &block.account());
  218|       |
  219|       |        // Start or vote for the next unconfirmed block in the destination account
  220|      0|        if let Some(destination) = block.destination() {
  221|      0|            if block.is_send() && !destination.is_zero() && destination != block.account() {
  222|      0|                result |= self.activate(tx, &destination);
  223|      0|            }
  224|      0|        }
  225|      0|        result
  226|      0|    }
  227|       |
  228|      0|    pub fn container_info(&self) -> ContainerInfo {
  229|      0|        let mut bucket_infos = ContainerInfo::builder();
  230|      0|        let mut election_infos = ContainerInfo::builder();
  231|       |
  232|      0|        for (id, bucket) in self.buckets.iter().enumerate() {
  233|      0|            bucket_infos = bucket_infos.leaf(id.to_string(), bucket.len(), 0);
  234|      0|            election_infos = election_infos.leaf(id.to_string(), bucket.election_count(), 0);
  235|      0|        }
  236|       |
  237|      0|        ContainerInfo::builder()
  238|      0|            .node("blocks", bucket_infos.finish())
  239|      0|            .node("elections", election_infos.finish())
  240|      0|            .finish()
  241|      0|    }
  242|       |}
  243|       |
  244|       |impl Drop for PriorityScheduler {
  245|      3|    fn drop(&mut self) {
  246|      3|        // Thread must be stopped before destruction
  247|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  248|      3|        debug_assert!(self.cleanup_thread.lock().unwrap().is_none());
  249|      3|    }
  250|       |}
  251|       |
  252|       |pub trait PrioritySchedulerExt {
  253|       |    fn start(&self);
  254|       |}
  255|       |
  256|       |impl PrioritySchedulerExt for Arc<PriorityScheduler> {
  257|      3|    fn start(&self) {
  258|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  259|      3|        debug_assert!(self.cleanup_thread.lock().unwrap().is_none());
  260|       |
  261|      3|        let self_l = Arc::clone(&self);
  262|      3|        *self.thread.lock().unwrap() = Some(
  263|      3|            std::thread::Builder::new()
  264|      3|                .name("Sched Priority".to_string())
  265|      3|                .spawn(Box::new(move || {
  266|      3|                    self_l.run();
  267|      3|                }))
  268|      3|                .unwrap(),
  269|      3|        );
  270|      3|
  271|      3|        let self_l = Arc::clone(&self);
  272|      3|        *self.cleanup_thread.lock().unwrap() = Some(
  273|      3|            std::thread::Builder::new()
  274|      3|                .name("Sched Priority".to_string())
  275|      3|                .spawn(Box::new(move || {
  276|      3|                    self_l.run_cleanup();
  277|      3|                }))
  278|      3|                .unwrap(),
  279|      3|        );
  280|      3|    }
  281|       |}
  282|       |
  283|       |struct PrioritySchedulerImpl {
  284|       |    stopped: bool,
  285|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/recently_confirmed_cache.rs:
    1|       |use std::{
    2|       |    collections::{HashMap, VecDeque},
    3|       |    sync::Mutex,
    4|       |};
    5|       |
    6|       |use rsnano_core::{utils::ContainerInfo, BlockHash, QualifiedRoot};
    7|       |
    8|       |pub struct RecentlyConfirmedCache {
    9|       |    mutex: Mutex<RecentlyConfirmedCacheImpl>,
   10|       |    max_len: usize,
   11|       |}
   12|       |
   13|       |impl RecentlyConfirmedCache {
   14|      3|    pub fn new(max_len: usize) -> Self {
   15|      3|        Self {
   16|      3|            mutex: Mutex::new(RecentlyConfirmedCacheImpl {
   17|      3|                sequential: VecDeque::new(),
   18|      3|                by_root: HashMap::new(),
   19|      3|                by_hash: HashMap::new(),
   20|      3|            }),
   21|      3|            max_len,
   22|      3|        }
   23|      3|    }
   24|       |
   25|      0|    pub fn put(&self, root: QualifiedRoot, hash: BlockHash) -> bool {
   26|      0|        let mut guard = self.mutex.lock().unwrap();
   27|      0|        if guard.by_hash.contains_key(&hash) || guard.by_root.contains_key(&root) {
   28|      0|            return false;
   29|      0|        }
   30|      0|        guard.sequential.push_back(hash);
   31|      0|        guard.by_root.insert(root.clone(), hash);
   32|      0|        guard.by_hash.insert(hash, root);
   33|      0|        if guard.sequential.len() > self.max_len {
   34|      0|            if let Some(old_hash) = guard.sequential.pop_front() {
   35|      0|                if let Some(old_root) = guard.by_hash.remove(&old_hash) {
   36|      0|                    guard.by_root.remove(&old_root);
   37|      0|                }
   38|      0|            }
   39|      0|        }
   40|      0|        true
   41|      0|    }
   42|       |
   43|      0|    pub fn erase(&self, hash: &BlockHash) {
   44|      0|        let mut guard = self.mutex.lock().unwrap();
   45|      0|        if let Some(root) = guard.by_hash.remove(hash) {
   46|      0|            guard.by_root.remove(&root);
   47|      0|            guard.sequential.retain(|i| i != hash);
   48|      0|        }
   49|      0|    }
   50|       |
   51|      0|    pub fn root_exists(&self, root: &QualifiedRoot) -> bool {
   52|      0|        self.mutex.lock().unwrap().by_root.contains_key(root)
   53|      0|    }
   54|       |
   55|      3|    pub fn hash_exists(&self, hash: &BlockHash) -> bool {
   56|      3|        self.mutex.lock().unwrap().by_hash.contains_key(hash)
   57|      3|    }
   58|       |
   59|      0|    pub fn clear(&self) {
   60|      0|        let mut guard = self.mutex.lock().unwrap();
   61|      0|        guard.sequential.clear();
   62|      0|        guard.by_root.clear();
   63|      0|        guard.by_hash.clear();
   64|      0|    }
   65|       |
   66|      0|    pub fn len(&self) -> usize {
   67|      0|        self.mutex.lock().unwrap().sequential.len()
   68|      0|    }
   69|       |
   70|      0|    pub fn back(&self) -> Option<(QualifiedRoot, BlockHash)> {
   71|      0|        let guard = self.mutex.lock().unwrap();
   72|      0|        guard
   73|      0|            .sequential
   74|      0|            .back()
   75|      0|            .map(|hash| (guard.by_hash.get(hash).unwrap().clone(), *hash))
   76|      0|    }
   77|       |
   78|      0|    pub fn container_info(&self) -> ContainerInfo {
   79|      0|        [(
   80|      0|            "confirmed",
   81|      0|            self.len(),
   82|      0|            std::mem::size_of::<BlockHash>() * 3 + std::mem::size_of::<QualifiedRoot>(),
   83|      0|        )]
   84|      0|        .into()
   85|      0|    }
   86|       |}
   87|       |
   88|       |struct RecentlyConfirmedCacheImpl {
   89|       |    by_root: HashMap<QualifiedRoot, BlockHash>,
   90|       |    by_hash: HashMap<BlockHash, QualifiedRoot>,
   91|       |    sequential: VecDeque<BlockHash>,
   92|       |}
   93|       |
   94|       |impl RecentlyConfirmedCacheImpl {}

/home/gustav/code/nano/rsnano-node/node/src/consensus/rep_tiers.rs:
    1|       |use crate::{
    2|       |    representatives::OnlineReps,
    3|       |    stats::{DetailType, Direction, StatType, Stats},
    4|       |    NetworkParams,
    5|       |};
    6|       |use rsnano_core::{utils::ContainerInfo, Account, PublicKey};
    7|       |use rsnano_ledger::RepWeightCache;
    8|       |use std::{
    9|       |    collections::HashSet,
   10|       |    mem::size_of,
   11|       |    sync::{Arc, Condvar, Mutex},
   12|       |    thread::JoinHandle,
   13|       |    time::Duration,
   14|       |};
   15|       |use strum_macros::EnumIter;
   16|       |use tracing::debug;
   17|       |
   18|       |// Higher number means higher priority
   19|      0|#[derive(FromPrimitive, Copy, Clone, PartialOrd, Ord, PartialEq, Eq, EnumIter, Hash, Debug)]
   20|       |pub enum RepTier {
   21|       |    None,  // Not a principal representatives
   22|       |    Tier1, // (0.1-1%) of online stake
   23|       |    Tier2, // (1-5%) of online stake
   24|       |    Tier3, // (> 5%) of online stake
   25|       |}
   26|       |
   27|       |impl From<RepTier> for DetailType {
   28|      0|    fn from(value: RepTier) -> Self {
   29|      0|        match value {
   30|      0|            RepTier::None => DetailType::None,
   31|      0|            RepTier::Tier1 => DetailType::Tier1,
   32|      0|            RepTier::Tier2 => DetailType::Tier2,
   33|      0|            RepTier::Tier3 => DetailType::Tier3,
   34|       |        }
   35|      0|    }
   36|       |}
   37|       |
   38|       |pub struct RepTiers {
   39|       |    network_params: NetworkParams,
   40|       |    thread: Mutex<Option<JoinHandle<()>>>,
   41|       |    stopped: Arc<Mutex<bool>>,
   42|       |    condition: Arc<Condvar>,
   43|       |    rep_tiers_impl: Arc<RepTiersImpl>,
   44|       |}
   45|       |
   46|       |impl RepTiers {
   47|      3|    pub fn new(
   48|      3|        rep_weights: Arc<RepWeightCache>,
   49|      3|        network_params: NetworkParams,
   50|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   51|      3|        stats: Arc<Stats>,
   52|      3|    ) -> Self {
   53|      3|        Self {
   54|      3|            network_params,
   55|      3|            thread: Mutex::new(None),
   56|      3|            stopped: Arc::new(Mutex::new(false)),
   57|      3|            condition: Arc::new(Condvar::new()),
   58|      3|            rep_tiers_impl: Arc::new(RepTiersImpl::new(stats, online_reps, rep_weights)),
   59|      3|        }
   60|      3|    }
   61|       |
   62|      3|    pub fn start(&self) {
   63|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
   64|      3|        let stopped_mutex = Arc::clone(&self.stopped);
   65|      3|        let condition = Arc::clone(&self.condition);
   66|      3|        let rep_tiers_impl = Arc::clone(&self.rep_tiers_impl);
   67|      3|        let interval = if self.network_params.network.is_dev_network() {
   68|      3|            Duration::from_millis(500)
   69|       |        } else {
   70|      0|            Duration::from_secs(10 * 60)
   71|       |        };
   72|       |
   73|      3|        let join_handle = std::thread::Builder::new()
   74|      3|            .name("Rep tiers".to_string())
   75|      3|            .spawn(move || {
   76|      3|                let mut stopped = stopped_mutex.lock().unwrap();
   77|      6|                while !*stopped {
   78|      3|                    drop(stopped);
   79|      3|
   80|      3|                    rep_tiers_impl.calculate_tiers();
   81|      3|
   82|      3|                    stopped = stopped_mutex.lock().unwrap();
   83|      3|                    stopped = condition
   84|      6|                        .wait_timeout_while(stopped, interval, |stop| !*stop)
   85|      3|                        .unwrap()
   86|      3|                        .0;
   87|       |                }
   88|      3|            })
   89|      3|            .unwrap();
   90|      3|        *self.thread.lock().unwrap() = Some(join_handle);
   91|      3|    }
   92|       |
   93|      3|    pub fn stop(&self) {
   94|      3|        *self.stopped.lock().unwrap() = true;
   95|      3|        self.condition.notify_all();
   96|      3|        let join_handle = self.thread.lock().unwrap().take();
   97|      3|        if let Some(join_handle) = join_handle {
   98|      3|            join_handle.join().unwrap();
   99|      3|        }
                       ^0
  100|      3|    }
  101|       |
  102|      0|    pub fn tier(&self, representative: &PublicKey) -> RepTier {
  103|      0|        let tiers = self.rep_tiers_impl.tiers.lock().unwrap();
  104|      0|        if tiers.representatives_3.contains(representative) {
  105|      0|            RepTier::Tier3
  106|      0|        } else if tiers.representatives_2.contains(representative) {
  107|      0|            RepTier::Tier2
  108|      0|        } else if tiers.representatives_1.contains(representative) {
  109|      0|            RepTier::Tier1
  110|       |        } else {
  111|      0|            RepTier::None
  112|       |        }
  113|      0|    }
  114|       |
  115|      0|    pub fn container_info(&self) -> ContainerInfo {
  116|      0|        let tiers = self.rep_tiers_impl.tiers.lock().unwrap();
  117|      0|        [
  118|      0|            (
  119|      0|                "representatives_1",
  120|      0|                tiers.representatives_1.len(),
  121|      0|                size_of::<Account>(),
  122|      0|            ),
  123|      0|            (
  124|      0|                "representatives_2",
  125|      0|                tiers.representatives_2.len(),
  126|      0|                size_of::<Account>(),
  127|      0|            ),
  128|      0|            (
  129|      0|                "representatives_3",
  130|      0|                tiers.representatives_3.len(),
  131|      0|                size_of::<Account>(),
  132|      0|            ),
  133|      0|        ]
  134|      0|        .into()
  135|      0|    }
  136|       |}
  137|       |
  138|       |impl Drop for RepTiers {
  139|      3|    fn drop(&mut self) {
  140|      3|        // Thread must be stopped before destruction
  141|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  142|      3|    }
  143|       |}
  144|       |
  145|       |#[derive(Default)]
  146|       |struct Tiers {
  147|       |    /// 0.1% or above
  148|       |    representatives_1: HashSet<PublicKey>,
  149|       |    /// 1% or above
  150|       |    representatives_2: HashSet<PublicKey>,
  151|       |    /// 5% or above
  152|       |    representatives_3: HashSet<PublicKey>,
  153|       |}
  154|       |
  155|       |struct RepTiersImpl {
  156|       |    stats: Arc<Stats>,
  157|       |    online_reps: Arc<Mutex<OnlineReps>>,
  158|       |    rep_weights: Arc<RepWeightCache>,
  159|       |    tiers: Mutex<Tiers>,
  160|       |}
  161|       |
  162|       |impl RepTiersImpl {
  163|      3|    fn new(
  164|      3|        stats: Arc<Stats>,
  165|      3|        online_reps: Arc<Mutex<OnlineReps>>,
  166|      3|        rep_weights: Arc<RepWeightCache>,
  167|      3|    ) -> Self {
  168|      3|        Self {
  169|      3|            stats,
  170|      3|            online_reps,
  171|      3|            rep_weights,
  172|      3|            tiers: Mutex::new(Tiers::default()),
  173|      3|        }
  174|      3|    }
  175|       |
  176|      3|    fn calculate_tiers(&self) {
  177|      3|        self.stats.inc(StatType::RepTiers, DetailType::Loop);
  178|      3|        let trended = self.online_reps.lock().unwrap().trended_or_minimum_weight();
  179|      3|        let mut representatives_1_l = HashSet::new();
  180|      3|        let mut representatives_2_l = HashSet::new();
  181|      3|        let mut representatives_3_l = HashSet::new();
  182|      3|        let mut ignored = 0;
  183|      3|        let reps_count;
  184|      3|        {
  185|      3|            let rep_weights = self.rep_weights.read();
  186|      3|            reps_count = rep_weights.len();
  187|      3|            for (&representative, &weight) in rep_weights.iter() {
  188|      3|                if weight > trended / 1000 {
  189|       |                    // 0.1% or above (level 1)
  190|      3|                    representatives_1_l.insert(representative);
  191|      3|                    if weight > trended / 100 {
  192|       |                        // 1% or above (level 2)
  193|      3|                        representatives_2_l.insert(representative);
  194|      3|                        if weight > trended / 20 {
  195|      3|                            // 5% or above (level 3)
  196|      3|                            representatives_3_l.insert(representative);
  197|      3|                        }
                                       ^0
  198|      0|                    }
  199|      0|                } else {
  200|      0|                    ignored += 1;
  201|      0|                }
  202|       |            }
  203|       |        }
  204|       |
  205|      3|        self.stats.add_dir(
  206|      3|            StatType::RepTiers,
  207|      3|            DetailType::Processed,
  208|      3|            Direction::In,
  209|      3|            reps_count as u64,
  210|      3|        );
  211|      3|
  212|      3|        self.stats.add_dir(
  213|      3|            StatType::RepTiers,
  214|      3|            DetailType::Ignored,
  215|      3|            Direction::In,
  216|      3|            ignored,
  217|      3|        );
  218|      3|
  219|      3|        debug!(
  220|      0|            "Representative tiers updated, tier 1: {}, tier 2: {}, tier 3: {} ({} ignored)",
  221|      0|            representatives_1_l.len(),
  222|      0|            representatives_2_l.len(),
  223|      0|            representatives_3_l.len(),
  224|       |            ignored
  225|       |        );
  226|       |
  227|      3|        {
  228|      3|            let mut guard = self.tiers.lock().unwrap();
  229|      3|            guard.representatives_1 = representatives_1_l;
  230|      3|            guard.representatives_2 = representatives_2_l;
  231|      3|            guard.representatives_3 = representatives_3_l;
  232|      3|        }
  233|      3|
  234|      3|        self.stats.inc(StatType::RepTiers, DetailType::Updated);
  235|      3|    }
  236|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_applier.rs:
    1|       |use crate::{
    2|       |    block_processing::{BlockProcessor, BlockSource},
    3|       |    cementation::ConfirmingSet,
    4|       |    config::NodeConfig,
    5|       |    consensus::{ElectionState, VoteInfo},
    6|       |    representatives::OnlineReps,
    7|       |    stats::{DetailType, StatType, Stats},
    8|       |    utils::ThreadPool,
    9|       |    wallets::Wallets,
   10|       |    NetworkParams,
   11|       |};
   12|       |
   13|       |use super::{
   14|       |    election_schedulers::ElectionSchedulers, Election, ElectionData, LocalVoteHistory,
   15|       |    RecentlyConfirmedCache, TallyKey, VoteGenerators,
   16|       |};
   17|       |use rsnano_core::{Amount, BlockHash, MaybeSavedBlock, PublicKey, VoteCode, VoteSource};
   18|       |use rsnano_ledger::Ledger;
   19|       |use rsnano_network::ChannelId;
   20|       |use std::{
   21|       |    collections::{BTreeMap, HashMap},
   22|       |    sync::{atomic::Ordering, Arc, Mutex, MutexGuard, RwLock, Weak},
   23|       |    time::{Duration, SystemTime},
   24|       |};
   25|       |use tracing::trace;
   26|       |
   27|       |pub struct VoteApplier {
   28|       |    ledger: Arc<Ledger>,
   29|       |    network_params: NetworkParams,
   30|       |    online_reps: Arc<Mutex<OnlineReps>>,
   31|       |    stats: Arc<Stats>,
   32|       |    vote_generators: Arc<VoteGenerators>,
   33|       |    block_processor: Arc<BlockProcessor>,
   34|       |    node_config: NodeConfig,
   35|       |    history: Arc<LocalVoteHistory>,
   36|       |    wallets: Arc<Wallets>,
   37|       |    recently_confirmed: Arc<RecentlyConfirmedCache>,
   38|       |    confirming_set: Arc<ConfirmingSet>,
   39|       |    workers: Arc<dyn ThreadPool>,
   40|       |    election_schedulers: RwLock<Option<Weak<ElectionSchedulers>>>,
   41|       |}
   42|       |
   43|       |impl VoteApplier {
   44|      3|    pub(crate) fn new(
   45|      3|        ledger: Arc<Ledger>,
   46|      3|        network_params: NetworkParams,
   47|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   48|      3|        stats: Arc<Stats>,
   49|      3|        vote_generators: Arc<VoteGenerators>,
   50|      3|        block_processor: Arc<BlockProcessor>,
   51|      3|        node_config: NodeConfig,
   52|      3|        history: Arc<LocalVoteHistory>,
   53|      3|        wallets: Arc<Wallets>,
   54|      3|        recently_confirmed: Arc<RecentlyConfirmedCache>,
   55|      3|        confirming_set: Arc<ConfirmingSet>,
   56|      3|        workers: Arc<dyn ThreadPool>,
   57|      3|    ) -> Self {
   58|      3|        Self {
   59|      3|            ledger,
   60|      3|            network_params,
   61|      3|            online_reps,
   62|      3|            stats,
   63|      3|            vote_generators,
   64|      3|            block_processor,
   65|      3|            node_config,
   66|      3|            history,
   67|      3|            wallets,
   68|      3|            recently_confirmed,
   69|      3|            confirming_set,
   70|      3|            workers,
   71|      3|            election_schedulers: RwLock::new(None),
   72|      3|        }
   73|      3|    }
   74|       |
   75|      3|    pub(crate) fn set_election_schedulers(&self, schedulers: &Arc<ElectionSchedulers>) {
   76|      3|        *self.election_schedulers.write().unwrap() = Some(Arc::downgrade(&schedulers));
   77|      3|    }
   78|       |
   79|       |    /// Calculates minimum time delay between subsequent votes when processing non-final votes
   80|      0|    pub fn cooldown_time(&self, weight: Amount) -> Duration {
   81|      0|        let online_stake = { self.online_reps.lock().unwrap().trended_or_minimum_weight() };
   82|      0|        if weight > online_stake / 20 {
   83|       |            // Reps with more than 5% weight
   84|      0|            Duration::from_secs(1)
   85|      0|        } else if weight > online_stake / 100 {
   86|       |            // Reps with more than 1% weight
   87|      0|            Duration::from_secs(5)
   88|       |        } else {
   89|       |            // The rest of smaller reps
   90|      0|            Duration::from_secs(15)
   91|       |        }
   92|      0|    }
   93|       |
   94|      0|    pub fn tally_impl(
   95|      0|        &self,
   96|      0|        guard: &mut MutexGuard<ElectionData>,
   97|      0|    ) -> BTreeMap<TallyKey, MaybeSavedBlock> {
   98|      0|        let mut block_weights: HashMap<BlockHash, Amount> = HashMap::new();
   99|      0|        let mut final_weights: HashMap<BlockHash, Amount> = HashMap::new();
  100|      0|        for (account, info) in &guard.last_votes {
  101|      0|            let rep_weight = self.ledger.weight(account);
  102|      0|            *block_weights.entry(info.hash).or_default() += rep_weight;
  103|      0|            if info.timestamp == u64::MAX {
  104|      0|                *final_weights.entry(info.hash).or_default() += rep_weight;
  105|      0|            }
  106|       |        }
  107|      0|        guard.last_tally.clear();
  108|      0|        for (&hash, &weight) in &block_weights {
  109|      0|            guard.last_tally.insert(hash, weight);
  110|      0|        }
  111|      0|        let mut result = BTreeMap::new();
  112|      0|        for (hash, weight) in &block_weights {
  113|      0|            if let Some(block) = guard.last_blocks.get(hash) {
  114|      0|                result.insert(TallyKey(*weight), block.clone());
  115|      0|            }
  116|       |        }
  117|       |        // Calculate final votes sum for winner
  118|      0|        if !final_weights.is_empty() && !result.is_empty() {
  119|      0|            let winner_hash = result.first_key_value().unwrap().1.hash();
  120|      0|            if let Some(final_weight) = final_weights.get(&winner_hash) {
  121|      0|                guard.final_weight = *final_weight;
  122|      0|            }
  123|      0|        }
  124|      0|        result
  125|      0|    }
  126|       |
  127|      0|    pub fn remove_votes(
  128|      0|        &self,
  129|      0|        election: &Election,
  130|      0|        guard: &mut MutexGuard<ElectionData>,
  131|      0|        hash: &BlockHash,
  132|      0|    ) {
  133|      0|        if self.node_config.enable_voting && self.wallets.voting_reps_count() > 0 {
  134|       |            // Remove votes from election
  135|      0|            let list_generated_votes = self.history.votes(&election.root, hash, false);
  136|      0|            for vote in list_generated_votes {
  137|      0|                guard.last_votes.remove(&vote.voting_account);
  138|      0|            }
  139|       |            // Clear votes cache
  140|      0|            self.history.erase(&election.root);
  141|      0|        }
  142|      0|    }
  143|       |
  144|      0|    pub fn have_quorum(&self, tally: &BTreeMap<TallyKey, MaybeSavedBlock>) -> bool {
  145|      0|        let mut it = tally.keys();
  146|      0|        let first = it.next().map(|i| i.amount()).unwrap_or_default();
  147|      0|        let second = it.next().map(|i| i.amount()).unwrap_or_default();
  148|      0|        let delta = self.online_reps.lock().unwrap().quorum_delta();
  149|      0|        first - second >= delta
  150|      0|    }
  151|       |}
  152|       |
  153|       |pub trait VoteApplierExt {
  154|       |    fn vote(
  155|       |        &self,
  156|       |        election: &Arc<Election>,
  157|       |        rep: &PublicKey,
  158|       |        timestamp: u64,
  159|       |        block_hash: &BlockHash,
  160|       |        vote_source: VoteSource,
  161|       |    ) -> VoteCode;
  162|       |    fn confirm_if_quorum(&self, election_lock: MutexGuard<ElectionData>, election: &Arc<Election>);
  163|       |    fn confirm_once(&self, election_lock: MutexGuard<ElectionData>, election: &Arc<Election>);
  164|       |}
  165|       |
  166|       |impl VoteApplierExt for Arc<VoteApplier> {
  167|      0|    fn vote(
  168|      0|        &self,
  169|      0|        election: &Arc<Election>,
  170|      0|        rep: &PublicKey,
  171|      0|        timestamp: u64,
  172|      0|        block_hash: &BlockHash,
  173|      0|        vote_source: VoteSource,
  174|      0|    ) -> VoteCode {
  175|      0|        let weight = self.ledger.weight(rep);
  176|      0|        if !self.network_params.network.is_dev_network()
  177|      0|            && weight <= self.online_reps.lock().unwrap().minimum_principal_weight()
  178|       |        {
  179|      0|            return VoteCode::Indeterminate;
  180|      0|        }
  181|      0|
  182|      0|        let mut guard = election.mutex.lock().unwrap();
  183|       |
  184|      0|        if let Some(last_vote) = guard.last_votes.get(rep) {
  185|      0|            if last_vote.timestamp > timestamp {
  186|      0|                return VoteCode::Replay;
  187|      0|            }
  188|      0|            if last_vote.timestamp == timestamp && !(last_vote.hash < *block_hash) {
  189|      0|                return VoteCode::Replay;
  190|      0|            }
  191|       |
  192|      0|            let max_vote = timestamp == u64::MAX && last_vote.timestamp < timestamp;
  193|       |
  194|      0|            let mut past_cooldown = true;
  195|      0|            // Only cooldown live votes
  196|      0|            if vote_source != VoteSource::Cache {
  197|      0|                let cooldown = self.cooldown_time(weight);
  198|      0|                past_cooldown = last_vote.time <= SystemTime::now() - cooldown;
  199|      0|            }
  200|       |
  201|      0|            if !max_vote && !past_cooldown {
  202|      0|                return VoteCode::Ignored;
  203|      0|            }
  204|      0|        }
  205|      0|        guard
  206|      0|            .last_votes
  207|      0|            .insert(*rep, VoteInfo::new(timestamp, *block_hash));
  208|      0|
  209|      0|        if vote_source != VoteSource::Cache {
  210|      0|            (election.live_vote_action)(*rep);
  211|      0|        }
  212|       |
  213|      0|        self.stats.inc(StatType::Election, DetailType::Vote);
  214|      0|        self.stats.inc(StatType::ElectionVote, vote_source.into());
  215|      0|        tracing::trace!(
  216|      0|            qualified_root = ?election.qualified_root,
  217|      0|            account = %rep,
  218|      0|            hash = %block_hash,
  219|      0|            timestamp,
  220|      0|            ?vote_source,
  221|      0|            ?weight,
  222|      0|            "vote processed");
  223|       |
  224|      0|        if !guard.is_confirmed() {
  225|      0|            self.confirm_if_quorum(guard, election);
  226|      0|        }
  227|      0|        VoteCode::Vote
  228|      0|    }
  229|       |
  230|      0|    fn confirm_if_quorum(
  231|      0|        &self,
  232|      0|        mut election_lock: MutexGuard<ElectionData>,
  233|      0|        election: &Arc<Election>,
  234|      0|    ) {
  235|      0|        let tally = self.tally_impl(&mut election_lock);
  236|      0|        assert!(!tally.is_empty());
  237|      0|        let (amount, block) = tally.first_key_value().unwrap();
  238|      0|        let winner_hash = block.hash();
  239|      0|        election_lock.status.tally = amount.amount();
  240|      0|        election_lock.status.final_tally = election_lock.final_weight;
  241|      0|        let status_winner_hash = election_lock.status.winner.as_ref().unwrap().hash();
  242|      0|        let mut sum = Amount::zero();
  243|      0|        for k in tally.keys() {
  244|      0|            sum += k.amount();
  245|      0|        }
  246|      0|        if sum >= self.online_reps.lock().unwrap().quorum_delta()
  247|      0|            && winner_hash != status_winner_hash
  248|      0|        {
  249|      0|            election_lock.status.winner = Some(block.clone());
  250|      0|            self.remove_votes(election, &mut election_lock, &status_winner_hash);
  251|      0|            self.block_processor.force(block.clone().into());
  252|      0|        }
  253|       |
  254|      0|        if self.have_quorum(&tally) {
  255|      0|            if !election.is_quorum.swap(true, Ordering::SeqCst)
  256|      0|                && self.node_config.enable_voting
  257|      0|                && self.wallets.voting_reps_count() > 0
  258|      0|            {
  259|      0|                election_lock.status.vote_broadcast_count += 1;
  260|      0|                self.vote_generators
  261|      0|                    .generate_final_vote(&election.root, &status_winner_hash);
  262|      0|            }
  263|      0|            let quorum_delta = self.online_reps.lock().unwrap().quorum_delta();
  264|      0|            if election_lock.final_weight >= quorum_delta {
  265|      0|                // In some edge cases block might get rolled back while the election
  266|      0|                // is confirming, reprocess it to ensure it's present in the ledger
  267|      0|                self.block_processor.add(
  268|      0|                    (**block).clone(),
  269|      0|                    BlockSource::Election,
  270|      0|                    ChannelId::LOOPBACK,
  271|      0|                );
  272|      0|                self.confirm_once(election_lock, election);
  273|      0|            }
  274|      0|        }
  275|      0|    }
  276|       |
  277|      0|    fn confirm_once(&self, mut election_lock: MutexGuard<ElectionData>, election: &Arc<Election>) {
  278|      0|        let just_confirmed = election_lock.state != ElectionState::Confirmed;
  279|      0|        election_lock.state = ElectionState::Confirmed;
  280|      0|
  281|      0|        if just_confirmed {
  282|      0|            election_lock.update_status_to_confirmed(election);
  283|      0|            let status = election_lock.status.clone();
  284|      0|
  285|      0|            self.recently_confirmed.put(
  286|      0|                election.qualified_root.clone(),
  287|      0|                status.winner.as_ref().unwrap().hash(),
  288|      0|            );
  289|      0|
  290|      0|            self.stats.inc(StatType::Election, DetailType::ConfirmOnce);
  291|      0|            trace!(
  292|      0|                qualified_root = ?election.qualified_root,
  293|      0|                "election confirmed"
  294|       |            );
  295|       |
  296|      0|            self.confirming_set.add_with_election(
  297|      0|                status.winner.as_ref().unwrap().hash(),
  298|      0|                Some(election.clone()),
  299|      0|            );
  300|      0|
  301|      0|            drop(election_lock);
  302|      0|
  303|      0|            let election = Arc::clone(election);
  304|      0|            self.workers.post(Box::new(move || {
  305|      0|                let block = status.winner.as_ref().unwrap().clone();
  306|      0|                (election.confirmation_action)(block.into());
  307|      0|            }));
  308|      0|        } else {
  309|      0|            self.stats
  310|      0|                .inc(StatType::Election, DetailType::ConfirmOnceFailed);
  311|      0|        }
  312|      0|    }
  313|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_broadcaster.rs:
    1|       |use super::VoteProcessorQueue;
    2|       |use crate::transport::MessageFlooder;
    3|       |use rsnano_core::{Vote, VoteSource};
    4|       |use rsnano_messages::{ConfirmAck, Message};
    5|       |use rsnano_network::{ChannelId, TrafficType};
    6|       |use std::{
    7|       |    ops::Deref,
    8|       |    sync::{Arc, Mutex},
    9|       |};
   10|       |
   11|       |/// Broadcast a vote to PRs and some non-PRs
   12|       |pub struct VoteBroadcaster {
   13|       |    vote_processor_queue: Arc<VoteProcessorQueue>,
   14|       |    message_flooder: Mutex<MessageFlooder>,
   15|       |}
   16|       |
   17|       |impl VoteBroadcaster {
   18|      3|    pub fn new(
   19|      3|        vote_processor_queue: Arc<VoteProcessorQueue>,
   20|      3|        message_flooder: MessageFlooder,
   21|      3|    ) -> Self {
   22|      3|        Self {
   23|      3|            vote_processor_queue,
   24|      3|            message_flooder: Mutex::new(message_flooder),
   25|      3|        }
   26|      3|    }
   27|       |
   28|       |    /// Broadcast vote to PRs and some non-PRs
   29|      0|    pub fn broadcast(&self, vote: Arc<Vote>) {
   30|      0|        let ack = Message::ConfirmAck(ConfirmAck::new_with_own_vote(vote.deref().clone()));
   31|      0|
   32|      0|        self.message_flooder
   33|      0|            .lock()
   34|      0|            .unwrap()
   35|      0|            .flood_prs_and_some_non_prs(&ack, TrafficType::Vote, 2.0);
   36|      0|
   37|      0|        self.vote_processor_queue
   38|      0|            .vote(vote, ChannelId::LOOPBACK, VoteSource::Live);
   39|      0|    }
   40|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_cache.rs:
    1|       |use super::TallyKey;
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |#[cfg(test)]
    4|       |use mock_instant::thread_local::Instant;
    5|       |use rsnano_core::{utils::ContainerInfo, Amount, BlockHash, PublicKey, Vote, VoteCode};
    6|       |#[cfg(not(test))]
    7|       |use std::time::Instant;
    8|       |use std::{
    9|       |    cmp::Ordering,
   10|       |    collections::{BTreeMap, HashMap},
   11|       |    fmt::Debug,
   12|       |    mem::size_of,
   13|       |    sync::Arc,
   14|       |    time::Duration,
   15|       |};
   16|       |
   17|       |#[derive(Clone, Debug, PartialEq)]
   18|       |pub struct VoteCacheConfig {
   19|       |    pub max_size: usize,
   20|       |    pub max_voters: usize,
   21|       |    pub age_cutoff: Duration,
   22|       |}
   23|       |
   24|       |impl Default for VoteCacheConfig {
   25|     10|    fn default() -> Self {
   26|     10|        Self {
   27|     10|            max_size: 1024 * 64,
   28|     10|            max_voters: 64,
   29|     10|            age_cutoff: Duration::from_secs(15 * 60),
   30|     10|        }
   31|     10|    }
   32|       |}
   33|       |
   34|       |///	A container holding votes that do not match any active or recently finished elections.
   35|       |///	It keeps track of votes in two internal structures: cache and queue
   36|       |///
   37|       |///	Cache: Stores votes associated with a particular block hash with a bounded maximum number of votes per hash.
   38|       |///			When cache size exceeds `max_size` oldest entries are evicted first.
   39|       |pub struct VoteCache {
   40|       |    config: VoteCacheConfig,
   41|       |    cache: CacheEntryCollection,
   42|       |    next_id: usize,
   43|       |    last_cleanup: Instant,
   44|       |    stats: Arc<Stats>,
   45|       |}
   46|       |
   47|       |impl VoteCache {
   48|     21|    pub fn new(config: VoteCacheConfig, stats: Arc<Stats>) -> Self {
   49|     21|        VoteCache {
   50|     21|            last_cleanup: Instant::now(),
   51|     21|            config,
   52|     21|            cache: CacheEntryCollection::default(),
   53|     21|            next_id: 0,
   54|     21|            stats,
   55|     21|        }
   56|     21|    }
   57|       |
   58|      3|    pub fn contains(&self, hash: &BlockHash) -> bool {
   59|      3|        self.cache.contains(hash)
   60|      3|    }
   61|       |
   62|       |    /// Adds a new vote to cache
   63|     38|    pub fn insert(
   64|     38|        &mut self,
   65|     38|        vote: &Arc<Vote>,
   66|     38|        rep_weight: Amount,
   67|     38|        results: &HashMap<BlockHash, VoteCode>,
   68|     38|    ) {
   69|     38|        // Results map should be empty or have the same hashes as the vote
   70|     38|        debug_assert!(results.is_empty() || vote.hashes.iter().all(|h| results.contains_key(h)));
                                                          ^0                         ^0                     ^0
   71|       |
   72|       |        // If results map is empty, insert all hashes (meant for testing)
   73|     38|        if results.is_empty() {
   74|     38|            for hash in &vote.hashes {
   75|     38|                self.insert_impl(vote, hash, rep_weight);
   76|     38|            }
   77|       |        } else {
   78|      0|            for (hash, code) in results {
   79|       |                // Cache votes with a corresponding active election (indicated by `vote_code::vote`) in case that election gets dropped
   80|      0|                if matches!(code, VoteCode::Vote | VoteCode::Indeterminate) {
   81|      0|                    self.insert_impl(vote, hash, rep_weight)
   82|      0|                }
   83|       |            }
   84|       |        }
   85|     38|    }
   86|       |
   87|     38|    fn insert_impl(&mut self, vote: &Arc<Vote>, hash: &BlockHash, rep_weight: Amount) {
   88|     38|        let cache_entry_exists = self.cache.modify_by_hash(hash, |existing| {
   89|     11|            self.stats.inc(StatType::VoteCache, DetailType::Update);
   90|     11|            existing.vote(vote, rep_weight, self.config.max_voters);
   91|     38|        });
   92|     38|
   93|     38|        if !cache_entry_exists {
   94|     27|            self.stats.inc(StatType::VoteCache, DetailType::Insert);
   95|     27|            let id = self.next_id;
   96|     27|            self.next_id += 1;
   97|     27|            let mut cache_entry = CacheEntry::new(id, *hash);
   98|     27|            cache_entry.vote(vote, rep_weight, self.config.max_voters);
   99|     27|            self.cache.insert(cache_entry);
  100|     27|
  101|     27|            // Remove the oldest entry if we have reached the capacity limit
  102|     27|            if self.cache.len() > self.config.max_size {
  103|      1|                self.cache.pop_front();
  104|     26|            }
  105|     11|        }
  106|     38|    }
  107|       |
  108|      2|    pub fn empty(&self) -> bool {
  109|      2|        self.cache.is_empty()
  110|      2|    }
  111|       |
  112|     10|    pub fn size(&self) -> usize {
  113|     10|        self.cache.len()
  114|     10|    }
  115|       |
  116|       |    /// Tries to find an entry associated with block hash
  117|     23|    pub fn find(&self, hash: &BlockHash) -> Vec<Arc<Vote>> {
  118|     23|        self.cache
  119|     23|            .get_by_hash(hash)
  120|     23|            .map(|entry| entry.votes())
                                       ^20
  121|     23|            .unwrap_or_default()
  122|     23|    }
  123|       |
  124|       |    /// Removes an entry associated with block hash, does nothing if entry does not exist
  125|       |    /// return true if hash existed and was erased, false otherwise
  126|      3|    pub fn erase(&mut self, hash: &BlockHash) -> bool {
  127|      3|        self.cache.remove_by_hash(hash).is_some()
  128|      3|    }
  129|       |
  130|      0|    pub fn clear(&mut self) {
  131|      0|        self.cache.clear()
  132|      0|    }
  133|       |
  134|       |    /// Returns blocks with highest observed tally, greater than `min_tally`
  135|       |    /// The blocks are sorted in descending order by final tally, then by tally
  136|       |    /// @param min_tally minimum tally threshold, entries below with their voting weight
  137|       |    /// below this will be ignore
  138|      6|    pub fn top(&mut self, min_tally: impl Into<Amount>) -> Vec<TopEntry> {
  139|      6|        let min_tally = min_tally.into();
  140|      6|        self.stats.inc(StatType::VoteCache, DetailType::Top);
  141|      6|        if self.last_cleanup.elapsed() >= self.config.age_cutoff / 2 {
  142|      2|            self.cleanup();
  143|      2|            self.last_cleanup = Instant::now();
  144|      4|        }
  145|       |
  146|      6|        let mut results = Vec::new();
  147|      8|        for entry in self.cache.iter_by_tally_desc() {
                                   ^6
  148|      8|            let tally = entry.tally();
  149|      8|            if tally < min_tally {
  150|      1|                break;
  151|      7|            }
  152|      7|            results.push(TopEntry {
  153|      7|                hash: entry.hash,
  154|      7|                tally,
  155|      7|                final_tally: entry.final_tally(),
  156|      7|            })
  157|       |        }
  158|       |
  159|       |        // Sort by final tally then by normal tally, descending
  160|      6|        results.sort_by(|a, b| {
  161|      3|            let res = b.final_tally.cmp(&b.final_tally);
  162|      3|            if res == Ordering::Equal {
  163|      3|                b.tally.cmp(&a.tally)
  164|       |            } else {
  165|      0|                res
  166|       |            }
  167|      6|        });
                      ^3
  168|      6|
  169|      6|        results
  170|      6|    }
  171|       |
  172|      2|    fn cleanup(&mut self) {
  173|      2|        self.stats.inc(StatType::VoteCache, DetailType::Cleanup);
  174|      2|        let to_delete: Vec<_> = self
  175|      2|            .cache
  176|      2|            .iter()
  177|      2|            .filter(|i| i.last_vote.elapsed() >= self.config.age_cutoff)
  178|      2|            .map(|i| i.hash)
                                   ^1
  179|      2|            .collect();
  180|      3|        for hash in to_delete {
                          ^1
  181|      1|            self.cache.remove_by_hash(&hash);
  182|      1|        }
  183|      2|    }
  184|       |
  185|      0|    pub fn container_info(&self) -> ContainerInfo {
  186|      0|        [("cache", self.size(), size_of::<CacheEntry>())].into()
  187|      0|    }
  188|       |}
  189|       |
  190|       |#[derive(PartialEq, Eq, Debug)]
  191|       |pub struct TopEntry {
  192|       |    pub hash: BlockHash,
  193|       |    pub tally: Amount,
  194|       |    pub final_tally: Amount,
  195|       |}
  196|       |
  197|       |/// Stores votes associated with a single block hash
  198|       |#[derive(Clone)]
  199|       |pub struct CacheEntry {
  200|       |    id: usize,
  201|       |    pub hash: BlockHash,
  202|       |    pub voters: OrderedVoters,
  203|       |    pub last_vote: Instant,
  204|       |    tally: Amount,
  205|       |    final_tally: Amount,
  206|       |}
  207|       |
  208|       |#[derive(Clone, Debug, PartialEq, Eq)]
  209|       |pub struct VoterEntry {
  210|       |    pub representative: PublicKey,
  211|       |    pub weight: Amount,
  212|       |    pub vote: Arc<Vote>,
  213|       |}
  214|       |
  215|       |impl VoterEntry {
  216|     34|    pub fn new(representative: PublicKey, weight: Amount, vote: Arc<Vote>) -> Self {
  217|     34|        Self {
  218|     34|            representative,
  219|     34|            weight,
  220|     34|            vote,
  221|     34|        }
  222|     34|    }
  223|       |
  224|      0|    pub fn final_weight(&self) -> Amount {
  225|      0|        if self.vote.is_final() {
  226|      0|            self.weight
  227|       |        } else {
  228|      0|            Amount::zero()
  229|       |        }
  230|      0|    }
  231|       |}
  232|       |
  233|       |impl CacheEntry {
  234|     27|    pub fn new(id: usize, hash: BlockHash) -> Self {
  235|     27|        CacheEntry {
  236|     27|            id,
  237|     27|            hash,
  238|     27|            voters: OrderedVoters::default(),
  239|     27|            last_vote: Instant::now(),
  240|     27|            tally: Amount::zero(),
  241|     27|            final_tally: Amount::zero(),
  242|     27|        }
  243|     27|    }
  244|       |
  245|     36|    fn calculate_tally(&mut self) -> (Amount, Amount) {
  246|     36|        let mut tally = Amount::zero();
  247|     36|        let mut final_tally = Amount::zero();
  248|     45|        for voter in self.voters.iter_unordered() {
                                   ^36
  249|     45|            tally = tally.wrapping_add(voter.weight);
  250|     45|            if voter.vote.is_final() {
  251|      5|                final_tally = final_tally.wrapping_add(voter.weight);
  252|     40|            }
  253|       |        }
  254|     36|        (tally, final_tally)
  255|     36|    }
  256|       |
  257|     62|    pub fn tally(&self) -> Amount {
  258|     62|        self.tally
  259|     62|    }
  260|       |
  261|      7|    pub fn final_tally(&self) -> Amount {
  262|      7|        self.final_tally
  263|      7|    }
  264|       |
  265|     20|    pub fn votes(&self) -> Vec<Arc<Vote>> {
  266|     20|        self.voters
  267|     20|            .iter_unordered()
  268|     23|            .map(|i| Arc::clone(&i.vote))
  269|     20|            .collect()
  270|     20|    }
  271|       |
  272|       |    /// Adds a vote into a list, checks for duplicates and updates timestamp if new one is greater
  273|       |    /// returns true if current tally changed, false otherwise
  274|     38|    pub fn vote(&mut self, vote: &Arc<Vote>, rep_weight: Amount, max_voters: usize) -> bool {
  275|     38|        let updated = self.vote_impl(vote, rep_weight, max_voters);
  276|     38|        if updated {
  277|     36|            (self.tally, self.final_tally) = self.calculate_tally();
  278|     36|            self.last_vote = Instant::now();
  279|     36|        }
                       ^2
  280|     38|        updated
  281|     38|    }
  282|       |
  283|     38|    fn vote_impl(&mut self, vote: &Arc<Vote>, rep_weight: Amount, max_voters: usize) -> bool {
  284|     38|        let representative = vote.voting_account;
  285|       |
  286|     38|        if let Some(existing) = self.voters.find(&representative) {
                                  ^4
  287|       |            // We already have a vote from this rep
  288|       |            // Update timestamp if newer but tally remains unchanged as we already counted this rep weight
  289|       |            // It is not essential to keep tally up to date if rep voting weight changes, elections do tally calculations independently, so in the worst case scenario only our queue ordering will be a bit off
  290|      4|            if vote.timestamp() > existing.vote.timestamp() {
  291|      2|                let was_final = existing.vote.is_final();
  292|      2|                self.voters
  293|      2|                    .modify(&representative, Arc::clone(vote), rep_weight);
  294|      2|                return !was_final && vote.is_final(); // Tally changed only if the vote became final
  295|       |            } else {
  296|      2|                return false;
  297|       |            }
  298|     34|        }
  299|       |
  300|     34|        let should_add = if self.voters.len() < max_voters {
  301|     34|            true
  302|       |        } else {
  303|      0|            let min_weight = self.voters.min_weight().expect("voters must not be empty");
  304|      0|            rep_weight > min_weight
  305|       |        };
  306|       |
  307|       |        // Vote from a new representative, add it to the list and update tally
  308|     34|        if should_add {
  309|     34|            self.voters.insert(VoterEntry::new(
  310|     34|                representative,
  311|     34|                rep_weight,
  312|     34|                Arc::clone(&vote),
  313|     34|            ));
  314|     34|
  315|     34|            // If we have reached the maximum number of voters, remove the lowest weight voter
  316|     34|            if self.voters.len() >= max_voters {
  317|      0|                self.voters.remove_lowest_weight();
  318|     34|            }
  319|     34|            return true;
  320|      0|        }
  321|      0|        false
  322|     38|    }
  323|       |
  324|      0|    pub fn size(&self) -> usize {
  325|      0|        self.voters.len()
  326|      0|    }
  327|       |}
  328|       |
  329|       |#[derive(Default)]
  330|       |pub struct CacheEntryCollection {
  331|       |    sequential: BTreeMap<usize, BlockHash>,
  332|       |    by_hash: HashMap<BlockHash, CacheEntry>,
  333|       |    by_tally: BTreeMap<TallyKey, Vec<BlockHash>>,
  334|       |}
  335|       |
  336|       |impl CacheEntryCollection {
  337|      3|    pub fn contains(&self, hash: &BlockHash) -> bool {
  338|      3|        self.by_hash.contains_key(hash)
  339|      3|    }
  340|       |
  341|     27|    pub fn insert(&mut self, entry: CacheEntry) {
  342|     27|        let old = self.sequential.insert(entry.id, entry.hash);
  343|     27|        debug_assert!(old.is_none());
  344|       |
  345|     27|        let tally = entry.tally().into();
  346|     27|        self.by_tally.entry(tally).or_default().push(entry.hash);
  347|     27|
  348|     27|        let old = self.by_hash.insert(entry.hash, entry);
  349|     27|        debug_assert!(old.is_none());
  350|     27|    }
  351|       |
  352|     38|    pub fn modify_by_hash<F>(&mut self, hash: &BlockHash, f: F) -> bool
  353|     38|    where
  354|     38|        F: FnOnce(&mut CacheEntry),
  355|     38|    {
  356|     38|        if let Some(entry) = self.by_hash.get_mut(hash) {
                                  ^11
  357|     11|            let old_tally = entry.tally();
  358|     11|            f(entry);
  359|     11|            let new_tally = entry.tally();
  360|     11|            let hash = entry.hash;
  361|     11|            self.update_tally(hash, old_tally, new_tally);
  362|     11|            true
  363|       |        } else {
  364|     27|            false
  365|       |        }
  366|     38|    }
  367|       |
  368|     11|    fn update_tally(&mut self, hash: BlockHash, old_tally: Amount, new_tally: Amount) {
  369|     11|        if old_tally == new_tally {
  370|      4|            return;
  371|      7|        }
  372|      7|        self.remove_by_tally(hash, old_tally);
  373|      7|        self.by_tally
  374|      7|            .entry(new_tally.into())
  375|      7|            .or_default()
  376|      7|            .push(hash);
  377|     11|    }
  378|       |
  379|     12|    fn remove_by_tally(&mut self, hash: BlockHash, tally: Amount) {
  380|     12|        let key = TallyKey::from(tally);
  381|     12|        let hashes = self.by_tally.get_mut(&key).unwrap();
  382|     12|        if hashes.len() == 1 {
  383|     12|            self.by_tally.remove(&key);
  384|     12|        } else {
  385|      0|            hashes.retain(|h| *h != hash)
  386|       |        }
  387|     12|    }
  388|       |
  389|      1|    pub fn pop_front(&mut self) -> Option<CacheEntry> {
  390|      1|        match self.sequential.pop_first() {
  391|      1|            Some((_, front_hash)) => {
  392|      1|                let entry = self.by_hash.remove(&front_hash).unwrap();
  393|      1|                self.remove_by_tally(front_hash, entry.tally());
  394|      1|                Some(entry)
  395|       |            }
  396|      0|            None => None,
  397|       |        }
  398|      1|    }
  399|       |
  400|     23|    pub fn get_by_hash(&self, hash: &BlockHash) -> Option<&CacheEntry> {
  401|     23|        self.by_hash.get(hash)
  402|     23|    }
  403|       |
  404|      4|    pub fn remove_by_hash(&mut self, hash: &BlockHash) -> Option<CacheEntry> {
  405|      4|        match self.by_hash.remove(hash) {
  406|      4|            Some(entry) => {
  407|      4|                self.sequential.remove(&entry.id);
  408|      4|                self.remove_by_tally(*hash, entry.tally());
  409|      4|                Some(entry)
  410|       |            }
  411|      0|            None => None,
  412|       |        }
  413|      4|    }
  414|       |
  415|      2|    pub fn iter(&self) -> impl Iterator<Item = &CacheEntry> {
  416|      2|        self.by_hash.values()
  417|      2|    }
  418|       |
  419|      6|    pub fn iter_by_tally_desc(&self) -> impl Iterator<Item = &CacheEntry> {
  420|      6|        self.by_tally
  421|      6|            .values()
  422|      8|            .flat_map(|hashes| hashes.iter().map(|hash| self.by_hash.get(hash).unwrap()))
  423|      6|    }
  424|       |
  425|     37|    pub fn len(&self) -> usize {
  426|     37|        self.sequential.len()
  427|     37|    }
  428|       |
  429|      2|    pub fn is_empty(&self) -> bool {
  430|      2|        self.sequential.is_empty()
  431|      2|    }
  432|       |
  433|      0|    pub fn clear(&mut self) {
  434|      0|        self.sequential.clear();
  435|      0|        self.by_hash.clear();
  436|      0|        self.by_tally.clear();
  437|      0|    }
  438|       |}
  439|       |
  440|       |#[derive(Default, Clone)]
  441|       |pub struct OrderedVoters {
  442|       |    by_representative: HashMap<PublicKey, VoterEntry>,
  443|       |    by_weight: BTreeMap<Amount, Vec<PublicKey>>,
  444|       |}
  445|       |
  446|       |impl OrderedVoters {
  447|     34|    pub fn insert(&mut self, entry: VoterEntry) {
  448|     34|        let weight = entry.weight;
  449|     34|        let rep = entry.representative;
  450|     34|        if let Some(existing) = self.by_representative.get_mut(&rep) {
                                  ^0
  451|      0|            let old_weight = existing.weight;
  452|      0|            *existing = entry;
  453|      0|            self.remove_by_weight(&old_weight, &rep);
  454|     34|        } else {
  455|     34|            self.by_representative.insert(rep, entry);
  456|     34|        }
  457|     34|        self.add_by_weight(weight, rep);
  458|     34|    }
  459|       |
  460|     56|    pub fn iter_unordered(&self) -> impl Iterator<Item = &VoterEntry> {
  461|     56|        self.by_representative.values()
  462|     56|    }
  463|       |
  464|     38|    pub fn find(&self, representative: &PublicKey) -> Option<&VoterEntry> {
  465|     38|        self.by_representative.get(representative)
  466|     38|    }
  467|       |
  468|      0|    pub fn first(&self) -> Option<&VoterEntry> {
  469|      0|        self.by_weight
  470|      0|            .first_key_value()
  471|      0|            .and_then(|(_, reps)| reps.first())
  472|      0|            .and_then(|rep| self.by_representative.get(rep))
  473|      0|    }
  474|       |
  475|      2|    pub fn modify(&mut self, representative: &PublicKey, vote: Arc<Vote>, new_weight: Amount) {
  476|      2|        if let Some(entry) = self.by_representative.get_mut(representative) {
  477|      2|            let old_weight = entry.weight;
  478|      2|            entry.vote = vote;
  479|      2|            entry.weight = new_weight;
  480|      2|            if old_weight != new_weight {
  481|      0|                self.remove_by_weight(&old_weight, representative);
  482|      0|                self.add_by_weight(new_weight, *representative);
  483|      2|            }
  484|      0|        }
  485|      2|    }
  486|       |
  487|      0|    pub fn min_weight(&self) -> Option<Amount> {
  488|      0|        self.by_weight
  489|      0|            .first_key_value()
  490|      0|            .map(|(weight, _reps)| *weight)
  491|      0|    }
  492|       |
  493|      0|    pub fn remove_lowest_weight(&mut self) {
  494|      0|        if let Some((_, reps)) = self.by_weight.pop_first() {
  495|      0|            for rep in reps {
  496|      0|                self.by_representative.remove(&rep);
  497|      0|            }
  498|      0|        }
  499|      0|    }
  500|       |
  501|     68|    pub fn len(&self) -> usize {
  502|     68|        self.by_representative.len()
  503|     68|    }
  504|       |
  505|      0|    pub fn is_empty(&self) -> bool {
  506|      0|        self.by_representative.is_empty()
  507|      0|    }
  508|       |
  509|      0|    fn remove_by_weight(&mut self, weight: &Amount, representative: &PublicKey) {
  510|      0|        if let Some(mut accounts) = self.by_weight.remove(weight) {
  511|      0|            if accounts.len() > 1 {
  512|      0|                accounts.retain(|a| a != representative);
  513|      0|                self.by_weight.insert(*weight, accounts);
  514|      0|            }
  515|      0|        }
  516|      0|    }
  517|       |
  518|     34|    fn add_by_weight(&mut self, weight: Amount, representative: PublicKey) {
  519|     34|        self.by_weight
  520|     34|            .entry(weight)
  521|     34|            .or_default()
  522|     34|            .push(representative);
  523|     34|    }
  524|       |}
  525|       |
  526|       |#[cfg(test)]
  527|       |mod tests {
  528|       |    use super::*;
  529|       |    use crate::stats::Direction;
  530|       |    use mock_instant::thread_local::MockClock;
  531|       |    use rsnano_core::PrivateKey;
  532|       |
  533|     33|    fn create_vote(rep: &PrivateKey, hash: &BlockHash, timestamp_offset: u64) -> Arc<Vote> {
  534|     33|        Arc::new(Vote::new(
  535|     33|            &rep,
  536|     33|            timestamp_offset * 1024 * 1024,
  537|     33|            0,
  538|     33|            vec![*hash],
  539|     33|        ))
  540|     33|    }
  541|       |
  542|      4|    fn create_final_vote(rep: &PrivateKey, hash: &BlockHash) -> Arc<Vote> {
  543|      4|        Arc::new(Vote::new_final(rep, vec![*hash]))
  544|      4|    }
  545|       |
  546|     18|    fn test_config() -> VoteCacheConfig {
  547|     18|        VoteCacheConfig {
  548|     18|            max_size: 3,
  549|     18|            max_voters: 80,
  550|     18|            age_cutoff: Duration::from_secs(5 * 60),
  551|     18|        }
  552|     18|    }
  553|       |
  554|     17|    fn create_vote_cache() -> VoteCache {
  555|     17|        VoteCache::new(test_config(), Arc::new(Stats::new(Default::default())))
  556|     17|    }
  557|       |
  558|       |    #[test]
  559|      1|    fn construction() {
  560|      1|        let cache = create_vote_cache();
  561|      1|        assert_eq!(cache.size(), 0);
  562|      1|        assert!(cache.empty());
  563|      1|        let hash = BlockHash::random();
  564|      1|        assert!(cache.find(&hash).is_empty());
  565|      1|    }
  566|       |
  567|       |    #[test]
  568|      1|    fn insert_one_hash() {
  569|      1|        let mut cache = create_vote_cache();
  570|      1|        let rep = PrivateKey::new();
  571|      1|        let hash = BlockHash::from(1);
  572|      1|        let vote = create_vote(&rep, &hash, 1);
  573|      1|
  574|      1|        cache.insert(&vote, Amount::raw(7), &HashMap::new());
  575|      1|
  576|      1|        assert_eq!(cache.size(), 1);
  577|      1|        let peek = cache.find(&hash);
  578|      1|        assert_eq!(peek.len(), 1);
  579|      1|        assert_eq!(peek.first(), Some(&vote));
  580|      1|    }
  581|       |
  582|       |    #[test]
  583|      1|    fn contains() {
  584|      1|        let mut cache = create_vote_cache();
  585|      1|        let rep = PrivateKey::new();
  586|      1|        let hash = BlockHash::from(1);
  587|      1|        let vote = create_vote(&rep, &hash, 1);
  588|      1|
  589|      1|        assert_eq!(cache.contains(&hash), false);
  590|       |
  591|      1|        cache.insert(&vote, Amount::raw(7), &HashMap::new());
  592|      1|
  593|      1|        assert_eq!(cache.contains(&hash), true);
  594|      1|    }
  595|       |
  596|       |    /*
  597|       |     * Inserts multiple votes for single hash
  598|       |     * Ensures all of them can be retrieved and that tally is properly accumulated
  599|       |     */
  600|       |    #[test]
  601|      1|    fn insert_one_hash_many_votes() {
  602|      1|        let mut cache = create_vote_cache();
  603|      1|
  604|      1|        let hash = BlockHash::random();
  605|      1|        let rep1 = PrivateKey::new();
  606|      1|        let rep2 = PrivateKey::new();
  607|      1|        let rep3 = PrivateKey::new();
  608|      1|
  609|      1|        let vote1 = create_vote(&rep1, &hash, 1);
  610|      1|        let vote2 = create_vote(&rep2, &hash, 2);
  611|      1|        let vote3 = create_vote(&rep3, &hash, 3);
  612|      1|
  613|      1|        cache.insert(&vote1, Amount::raw(7), &HashMap::new());
  614|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  615|      1|        cache.insert(&vote3, Amount::raw(11), &HashMap::new());
  616|      1|        // We have 3 votes but for a single hash, so just one entry in vote cache
  617|      1|        assert_eq!(cache.size(), 1);
  618|      1|        let votes = cache.find(&hash);
  619|      1|        assert_eq!(votes.len(), 3);
  620|      1|    }
  621|       |
  622|       |    #[test]
  623|      1|    fn insert_many_hashes_many_votes() {
  624|      1|        let mut cache = create_vote_cache();
  625|      1|
  626|      1|        // There will be 3 hashes to vote for
  627|      1|        let hash1 = BlockHash::from(1);
  628|      1|        let hash2 = BlockHash::from(2);
  629|      1|        let hash3 = BlockHash::from(3);
  630|      1|
  631|      1|        // There will be 4 reps with different weights
  632|      1|        let rep1 = PrivateKey::new();
  633|      1|        let rep2 = PrivateKey::new();
  634|      1|        let rep3 = PrivateKey::new();
  635|      1|        let rep4 = PrivateKey::new();
  636|      1|
  637|      1|        // Votes: rep1 > hash1, rep2 > hash2, rep3 > hash3, rep4 > hash1 (the same as rep1)
  638|      1|        let vote1 = create_vote(&rep1, &hash1, 1);
  639|      1|        let vote2 = create_vote(&rep2, &hash2, 1);
  640|      1|        let vote3 = create_vote(&rep3, &hash3, 1);
  641|      1|        let vote4 = create_vote(&rep4, &hash1, 1);
  642|      1|
  643|      1|        // Insert first 3 votes in cache
  644|      1|        cache.insert(&vote1, Amount::raw(7), &HashMap::new());
  645|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  646|      1|        cache.insert(&vote3, Amount::raw(11), &HashMap::new());
  647|      1|
  648|      1|        // Ensure all of those are properly inserted
  649|      1|        assert_eq!(cache.size(), 3);
  650|      1|        assert_eq!(cache.find(&hash1).len(), 1);
  651|      1|        assert_eq!(cache.find(&hash2).len(), 1);
  652|      1|        assert_eq!(cache.find(&hash3).len(), 1);
  653|       |
  654|       |        // Now add a vote from rep4 with the highest voting weight
  655|      1|        cache.insert(&vote4, Amount::raw(13), &HashMap::new());
  656|      1|
  657|      1|        let pop1 = cache.find(&hash1);
  658|      1|        assert_eq!(pop1.len(), 2);
  659|       |
  660|      1|        let pop2 = cache.find(&hash3);
  661|      1|        assert_eq!(pop2.len(), 1);
  662|      1|    }
  663|       |
  664|       |    /*
  665|       |     * Ensure that duplicate votes are ignored
  666|       |     */
  667|       |    #[test]
  668|      1|    fn insert_duplicate() {
  669|      1|        let mut cache = create_vote_cache();
  670|      1|
  671|      1|        let hash = BlockHash::from(1);
  672|      1|        let rep = PrivateKey::new();
  673|      1|        let vote1 = create_vote(&rep, &hash, 1);
  674|      1|        let vote2 = create_vote(&rep, &hash, 1);
  675|      1|
  676|      1|        cache.insert(&vote1, Amount::raw(9), &HashMap::new());
  677|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  678|      1|
  679|      1|        assert_eq!(cache.size(), 1)
  680|      1|    }
  681|       |
  682|       |    /*
  683|       |     * Ensure that when processing vote from a representative that is already cached, we always update to the vote with the highest timestamp
  684|       |     */
  685|       |    #[test]
  686|      1|    fn insert_newer() {
  687|      1|        let mut cache = create_vote_cache();
  688|      1|
  689|      1|        let hash = BlockHash::from(1);
  690|      1|        let rep = PrivateKey::new();
  691|      1|        let vote1 = create_vote(&rep, &hash, 1);
  692|      1|        cache.insert(&vote1, Amount::raw(9), &HashMap::new());
  693|      1|
  694|      1|        let vote2 = Arc::new(Vote::new(
  695|      1|            &rep,
  696|      1|            Vote::TIMESTAMP_MAX,
  697|      1|            Vote::DURATION_MAX,
  698|      1|            vec![hash],
  699|      1|        ));
  700|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  701|      1|
  702|      1|        let peek2 = cache.find(&hash);
  703|      1|        assert_eq!(peek2.len(), 1);
  704|      1|        assert_eq!(peek2.first().unwrap().timestamp(), Vote::FINAL_TIMESTAMP); // final timestamp
  705|      1|    }
  706|       |
  707|       |    /*
  708|       |     * Ensure that when processing vote from a representative that is already cached, votes with older timestamp are ignored
  709|       |     */
  710|       |    #[test]
  711|      1|    fn insert_older() {
  712|      1|        let mut cache = create_vote_cache();
  713|      1|        let hash = BlockHash::from(1);
  714|      1|        let rep = PrivateKey::new();
  715|      1|        let vote1 = create_vote(&rep, &hash, 2);
  716|      1|        cache.insert(&vote1, Amount::raw(9), &HashMap::new());
  717|      1|        let peek1 = cache.find(&hash);
  718|      1|
  719|      1|        let vote2 = create_vote(&rep, &hash, 1);
  720|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  721|      1|        let peek2 = cache.find(&hash);
  722|      1|
  723|      1|        assert_eq!(cache.size(), 1);
  724|      1|        assert_eq!(peek2.len(), 1);
  725|      1|        assert_eq!(
  726|      1|            peek2.first().unwrap().timestamp(),
  727|      1|            peek1.first().unwrap().timestamp()
  728|      1|        ); // timestamp2 == timestamp1
  729|      1|    }
  730|       |
  731|       |    /*
  732|       |     * Ensure that erase functionality works
  733|       |     */
  734|       |    #[test]
  735|      1|    fn erase() {
  736|      1|        let mut cache = create_vote_cache();
  737|      1|        let hash1 = BlockHash::from(1);
  738|      1|        let hash2 = BlockHash::from(2);
  739|      1|        let hash3 = BlockHash::from(3);
  740|      1|
  741|      1|        let rep1 = PrivateKey::new();
  742|      1|        let rep2 = PrivateKey::new();
  743|      1|        let rep3 = PrivateKey::new();
  744|      1|
  745|      1|        let vote1 = create_vote(&rep1, &hash1, 1);
  746|      1|        let vote2 = create_vote(&rep2, &hash2, 1);
  747|      1|        let vote3 = create_vote(&rep3, &hash3, 1);
  748|      1|
  749|      1|        cache.insert(&vote1, Amount::raw(7), &HashMap::new());
  750|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  751|      1|        cache.insert(&vote3, Amount::raw(11), &HashMap::new());
  752|      1|
  753|      1|        assert_eq!(cache.size(), 3);
  754|      1|        assert_eq!(cache.find(&hash1).len(), 1);
  755|      1|        assert_eq!(cache.find(&hash2).len(), 1);
  756|      1|        assert_eq!(cache.find(&hash3).len(), 1);
  757|       |
  758|      1|        cache.erase(&hash2);
  759|      1|
  760|      1|        assert_eq!(cache.size(), 2);
  761|      1|        assert_eq!(cache.contains(&hash2), false);
  762|      1|        assert_eq!(cache.find(&hash1).len(), 1);
  763|      1|        assert_eq!(cache.find(&hash2).len(), 0);
  764|      1|        assert_eq!(cache.find(&hash3).len(), 1);
  765|      1|        cache.erase(&hash1);
  766|      1|        cache.erase(&hash3);
  767|      1|
  768|      1|        assert!(cache.empty());
  769|      1|    }
  770|       |
  771|       |    /*
  772|       |     * Ensure that when cache is overfilled, we remove the oldest entries first
  773|       |     */
  774|       |    #[test]
  775|      1|    fn overfill() {
  776|      1|        let mut cache = create_vote_cache();
  777|      1|
  778|      1|        let hash1 = BlockHash::from(1);
  779|      1|        let hash2 = BlockHash::from(2);
  780|      1|        let hash3 = BlockHash::from(3);
  781|      1|        let hash4 = BlockHash::from(4);
  782|      1|
  783|      1|        let rep1 = PrivateKey::new();
  784|      1|        let rep2 = PrivateKey::new();
  785|      1|        let rep3 = PrivateKey::new();
  786|      1|        let rep4 = PrivateKey::new();
  787|      1|
  788|      1|        let vote1 = create_vote(&rep1, &hash1, 1);
  789|      1|        cache.insert(&vote1, Amount::raw(1), &HashMap::new());
  790|      1|
  791|      1|        let vote2 = create_vote(&rep2, &hash2, 1);
  792|      1|        cache.insert(&vote2, Amount::raw(2), &HashMap::new());
  793|      1|
  794|      1|        let vote3 = create_vote(&rep3, &hash3, 1);
  795|      1|        cache.insert(&vote3, Amount::raw(3), &HashMap::new());
  796|      1|
  797|      1|        let vote4 = create_vote(&rep4, &hash4, 1);
  798|      1|        cache.insert(&vote4, Amount::raw(4), &HashMap::new());
  799|      1|
  800|      1|        assert_eq!(cache.size(), 3);
  801|       |
  802|       |        // Check that oldest votes are dropped first
  803|      1|        assert_eq!(cache.find(&hash4).len(), 1);
  804|      1|        assert_eq!(cache.find(&hash3).len(), 1);
  805|      1|        assert_eq!(cache.find(&hash2).len(), 1);
  806|      1|        assert_eq!(cache.find(&hash1).len(), 0);
  807|      1|    }
  808|       |
  809|       |    /*
  810|       |     * Check that when a single vote cache entry is overfilled, it ignores any new votes
  811|       |     */
  812|       |    #[test]
  813|      1|    fn overfill_entry() {
  814|      1|        let mut cache = create_vote_cache();
  815|      1|        let hash = BlockHash::from(1);
  816|      1|
  817|      1|        let rep1 = PrivateKey::new();
  818|      1|        let vote1 = create_vote(&rep1, &hash, 1);
  819|      1|        cache.insert(&vote1, Amount::raw(9), &HashMap::new());
  820|      1|
  821|      1|        let rep2 = PrivateKey::new();
  822|      1|        let vote2 = create_vote(&rep2, &hash, 1);
  823|      1|        cache.insert(&vote2, Amount::raw(9), &HashMap::new());
  824|      1|
  825|      1|        let rep3 = PrivateKey::new();
  826|      1|        let vote3 = create_vote(&rep3, &hash, 1);
  827|      1|        cache.insert(&vote3, Amount::raw(9), &HashMap::new());
  828|      1|
  829|      1|        assert_eq!(cache.size(), 1);
  830|      1|    }
  831|       |
  832|       |    #[test]
  833|      1|    fn change_vote_to_final_vote() {
  834|      1|        let mut cache = create_vote_cache();
  835|      1|        let hash = BlockHash::from(1);
  836|      1|
  837|      1|        let rep = PrivateKey::new();
  838|      1|        let vote = create_vote(&rep, &hash, 1);
  839|      1|        let final_vote = create_final_vote(&rep, &hash);
  840|      1|        cache.insert(&vote, Amount::raw(9), &HashMap::new());
  841|      1|        cache.insert(&final_vote, Amount::raw(9), &HashMap::new());
  842|      1|
  843|      1|        let votes = cache.find(&hash);
  844|      1|        let vote = votes.first().unwrap();
  845|      1|        assert!(vote.is_final());
  846|      1|    }
  847|       |
  848|       |    #[test]
  849|      1|    fn add_final_vote() {
  850|      1|        let mut cache = create_vote_cache();
  851|      1|        let hash = BlockHash::from(1);
  852|      1|
  853|      1|        let rep = PrivateKey::new();
  854|      1|        let vote = create_final_vote(&rep, &hash);
  855|      1|        cache.insert(&vote, Amount::raw(9), &HashMap::new());
  856|      1|
  857|      1|        let votes = cache.find(&hash);
  858|      1|        let vote = votes.first().unwrap();
  859|      1|        assert!(vote.is_final());
  860|      1|    }
  861|       |
  862|       |    #[test]
  863|      1|    fn top_empty() {
  864|      1|        let mut cache = create_vote_cache();
  865|      1|        assert_eq!(cache.top(0), Vec::new());
  866|      1|    }
  867|       |
  868|       |    #[test]
  869|      1|    fn top_one_entry() {
  870|      1|        let mut cache = create_vote_cache();
  871|      1|        let hash = BlockHash::from(1);
  872|      1|        add_test_vote(&mut cache, &hash, Amount::raw(1));
  873|      1|
  874|      1|        assert_eq!(
  875|      1|            cache.top(0),
  876|      1|            vec![TopEntry {
  877|      1|                hash,
  878|      1|                tally: Amount::raw(1),
  879|      1|                final_tally: Amount::zero()
  880|      1|            }]
  881|      1|        );
  882|      1|    }
  883|       |
  884|       |    #[test]
  885|      1|    fn top_multiple_entries_sorted_by_tally() {
  886|      1|        let mut cache = create_vote_cache();
  887|      1|        let hash1 = BlockHash::from(1);
  888|      1|        let hash2 = BlockHash::from(2);
  889|      1|        let hash3 = BlockHash::from(3);
  890|      1|        add_test_vote(&mut cache, &hash1, Amount::raw(1));
  891|      1|        add_test_vote(&mut cache, &hash2, Amount::raw(4));
  892|      1|        add_test_vote(&mut cache, &hash3, Amount::raw(3));
  893|      1|        add_test_final_vote(&mut cache, &hash2, Amount::raw(5));
  894|      1|        add_test_final_vote(&mut cache, &hash3, Amount::raw(5));
  895|      1|
  896|      1|        let top = cache.top(0);
  897|      1|
  898|      1|        assert_eq!(top.len(), 3);
  899|      1|        assert_eq!(top[0].hash, hash2);
  900|      1|        assert_eq!(top[1].hash, hash3);
  901|      1|        assert_eq!(top[2].hash, hash1);
  902|      1|    }
  903|       |
  904|       |    #[test]
  905|      1|    fn top_min_tally() {
  906|      1|        let mut cache = create_vote_cache();
  907|      1|        let hash1 = BlockHash::from(1);
  908|      1|        let hash2 = BlockHash::from(2);
  909|      1|        let hash3 = BlockHash::from(3);
  910|      1|        add_test_vote(&mut cache, &hash1, Amount::raw(1));
  911|      1|        add_test_vote(&mut cache, &hash2, Amount::raw(2));
  912|      1|        add_test_vote(&mut cache, &hash3, Amount::raw(3));
  913|      1|
  914|      1|        let top = cache.top(2);
  915|      1|        assert_eq!(top.len(), 2);
  916|      1|        assert_eq!(top[0].hash, hash3);
  917|      1|        assert_eq!(top[1].hash, hash2);
  918|      1|    }
  919|       |
  920|       |    #[test]
  921|      1|    fn top_age_cutoff() {
  922|      1|        let stats = Arc::new(Stats::new(Default::default()));
  923|      1|        let mut cache = VoteCache::new(test_config(), Arc::clone(&stats));
  924|      1|        let hash = BlockHash::from(1);
  925|      1|        add_test_vote(&mut cache, &hash, Amount::raw(1));
  926|      1|        assert_eq!(
  927|      1|            stats.count(StatType::VoteCache, DetailType::Cleanup, Direction::In),
  928|      1|            0
  929|      1|        );
  930|      1|        MockClock::advance(Duration::from_secs(150));
  931|      1|        assert_eq!(cache.top(0).len(), 1);
  932|      1|        assert_eq!(
  933|      1|            stats.count(StatType::VoteCache, DetailType::Cleanup, Direction::In),
  934|      1|            1
  935|      1|        );
  936|      1|        MockClock::advance(Duration::from_secs(150));
  937|      1|        assert_eq!(cache.top(0).len(), 0);
  938|      1|        assert_eq!(
  939|      1|            stats.count(StatType::VoteCache, DetailType::Cleanup, Direction::In),
  940|      1|            2
  941|      1|        );
  942|      1|    }
  943|       |
  944|      8|    fn add_test_vote(cache: &mut VoteCache, hash: &BlockHash, rep_weight: Amount) {
  945|      8|        let vote = create_vote(&PrivateKey::new(), &hash, 0);
  946|      8|        cache.insert(&vote, rep_weight, &HashMap::new());
  947|      8|    }
  948|       |
  949|      2|    fn add_test_final_vote(cache: &mut VoteCache, hash: &BlockHash, rep_weight: Amount) {
  950|      2|        let vote = create_final_vote(&PrivateKey::new(), &hash);
  951|      2|        cache.insert(&vote, rep_weight, &HashMap::new());
  952|      2|    }
  953|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_cache_processor.rs:
    1|       |use super::{VoteCache, VoteProcessorConfig, VoteRouter};
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::{utils::ContainerInfo, BlockHash, VoteSource};
    4|       |use std::{
    5|       |    collections::{HashSet, VecDeque},
    6|       |    sync::{Arc, Condvar, Mutex, MutexGuard},
    7|       |    thread::JoinHandle,
    8|       |};
    9|       |
   10|       |pub(crate) struct VoteCacheProcessor {
   11|       |    state: Arc<Mutex<State>>,
   12|       |    condition: Arc<Condvar>,
   13|       |    stats: Arc<Stats>,
   14|       |    vote_cache: Arc<Mutex<VoteCache>>,
   15|       |    vote_router: Arc<VoteRouter>,
   16|       |    config: VoteProcessorConfig,
   17|       |}
   18|       |
   19|       |impl VoteCacheProcessor {
   20|      3|    pub(crate) fn new(
   21|      3|        stats: Arc<Stats>,
   22|      3|        vote_cache: Arc<Mutex<VoteCache>>,
   23|      3|        vote_router: Arc<VoteRouter>,
   24|      3|        config: VoteProcessorConfig,
   25|      3|    ) -> Self {
   26|      3|        Self {
   27|      3|            state: Arc::new(Mutex::new(State {
   28|      3|                thread: None,
   29|      3|                stopped: false,
   30|      3|                triggered: VecDeque::new(),
   31|      3|            })),
   32|      3|            condition: Arc::new(Condvar::new()),
   33|      3|            stats,
   34|      3|            vote_router,
   35|      3|            vote_cache,
   36|      3|            config,
   37|      3|        }
   38|      3|    }
   39|       |}
   40|       |
   41|       |impl VoteCacheProcessor {
   42|      3|    pub fn start(&self) {
   43|      3|        debug_assert!(self.state.lock().unwrap().thread.is_none());
   44|      3|        let cache_loop = VoteCacheLoop {
   45|      3|            state: self.state.clone(),
   46|      3|            condition: self.condition.clone(),
   47|      3|            stats: self.stats.clone(),
   48|      3|            vote_cache: self.vote_cache.clone(),
   49|      3|            vote_router: self.vote_router.clone(),
   50|      3|        };
   51|      3|
   52|      3|        self.state.lock().unwrap().thread = Some(
   53|      3|            std::thread::Builder::new()
   54|      3|                .name("Vote cache proc".to_owned())
   55|      3|                .spawn(move || cache_loop.run())
   56|      3|                .unwrap(),
   57|      3|        );
   58|      3|    }
   59|       |
   60|      3|    pub fn stop(&self) {
   61|      3|        let thread = {
   62|      3|            let mut state = self.state.lock().unwrap();
   63|      3|            state.stopped = true;
   64|      3|            state.thread.take()
   65|      3|        };
   66|      3|
   67|      3|        self.condition.notify_all();
   68|       |
   69|      3|        if let Some(handle) = thread {
   70|      3|            handle.join().unwrap();
   71|      3|        }
                       ^0
   72|      3|    }
   73|       |
   74|      0|    pub fn trigger(&self, hash: BlockHash) {
   75|      0|        {
   76|      0|            let mut state = self.state.lock().unwrap();
   77|      0|            if state.triggered.len() > self.config.max_triggered {
   78|      0|                state.triggered.pop_front();
   79|      0|                self.stats
   80|      0|                    .inc(StatType::VoteCacheProcessor, DetailType::Overfill);
   81|      0|            }
   82|      0|            state.triggered.push_back(hash);
   83|      0|        }
   84|      0|        self.condition.notify_all();
   85|      0|        self.stats
   86|      0|            .inc(StatType::VoteCacheProcessor, DetailType::Triggered);
   87|      0|    }
   88|       |
   89|      0|    pub fn len(&self) -> usize {
   90|      0|        self.state.lock().unwrap().triggered.len()
   91|      0|    }
   92|       |
   93|      0|    pub fn container_info(&self) -> ContainerInfo {
   94|      0|        [("triggered", self.len(), std::mem::size_of::<BlockHash>())].into()
   95|      0|    }
   96|       |}
   97|       |
   98|       |impl Drop for VoteCacheProcessor {
   99|      3|    fn drop(&mut self) {
  100|      3|        debug_assert!(self.state.lock().unwrap().thread.is_none())
  101|      3|    }
  102|       |}
  103|       |
  104|       |struct State {
  105|       |    thread: Option<JoinHandle<()>>,
  106|       |    stopped: bool,
  107|       |    triggered: VecDeque<BlockHash>,
  108|       |}
  109|       |
  110|       |struct VoteCacheLoop {
  111|       |    state: Arc<Mutex<State>>,
  112|       |    condition: Arc<Condvar>,
  113|       |    stats: Arc<Stats>,
  114|       |    vote_cache: Arc<Mutex<VoteCache>>,
  115|       |    vote_router: Arc<VoteRouter>,
  116|       |}
  117|       |
  118|       |impl VoteCacheLoop {
  119|      3|    fn run(&self) {
  120|      3|        let mut guard = self.state.lock().unwrap();
  121|      6|        while !guard.stopped {
  122|      3|            if !guard.triggered.is_empty() {
  123|      0|                self.run_batch(guard);
  124|      0|                guard = self.state.lock().unwrap();
  125|      3|            } else {
  126|      3|                guard = self
  127|      3|                    .condition
  128|      6|                    .wait_while(guard, |i| !i.stopped && i.triggered.is_empty())
                                                                       ^3
  129|      3|                    .unwrap();
  130|      3|            }
  131|       |        }
  132|      3|    }
  133|       |
  134|      0|    fn run_batch(&self, mut state: MutexGuard<'_, State>) {
  135|      0|        let mut triggered = VecDeque::new();
  136|      0|        std::mem::swap(&mut triggered, &mut state.triggered);
  137|      0|        drop(state);
  138|      0|
  139|      0|        //deduplicate
  140|      0|        let hashes: HashSet<BlockHash> = triggered.drain(..).collect();
  141|      0|
  142|      0|        self.stats.add(
  143|      0|            StatType::VoteCacheProcessor,
  144|      0|            DetailType::Processed,
  145|      0|            hashes.len() as u64,
  146|      0|        );
  147|       |
  148|      0|        for hash in hashes {
  149|      0|            let cached = self.vote_cache.lock().unwrap().find(&hash);
  150|      0|            for cached_vote in cached {
  151|      0|                self.vote_router
  152|      0|                    .vote_filter(&cached_vote, VoteSource::Cache, &hash);
  153|      0|            }
  154|       |        }
  155|      0|    }
  156|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/local_vote_history.rs:
    1|       |use rsnano_core::{utils::ContainerInfo, BlockHash, Root, Vote};
    2|       |use std::{
    3|       |    collections::{BTreeMap, HashMap, HashSet},
    4|       |    mem::size_of,
    5|       |    sync::{Arc, Mutex},
    6|       |};
    7|       |
    8|       |pub struct LocalVoteHistory {
    9|       |    data: Mutex<LocalVoteHistoryData>,
   10|       |    max_cache: usize,
   11|       |}
   12|       |
   13|       |#[derive(Default)]
   14|       |struct LocalVoteHistoryData {
   15|       |    history: BTreeMap<usize, LocalVote>,
   16|       |    history_by_root: HashMap<Root, HashSet<usize>>,
   17|       |}
   18|       |
   19|       |impl LocalVoteHistoryData {
   20|      8|    fn new() -> Self {
   21|      8|        Default::default()
   22|      8|    }
   23|       |}
   24|       |
   25|       |struct LocalVote {
   26|       |    root: Root,
   27|       |    hash: BlockHash,
   28|       |    vote: Arc<Vote>,
   29|       |}
   30|       |
   31|       |impl LocalVoteHistory {
   32|      8|    pub fn new(max_cache: usize) -> Self {
   33|      8|        Self {
   34|      8|            data: Mutex::new(LocalVoteHistoryData::new()),
   35|      8|            max_cache,
   36|      8|        }
   37|      8|    }
   38|       |
   39|     10|    pub fn add(&self, root: &Root, hash: &BlockHash, vote: &Arc<Vote>) {
   40|     10|        let mut data_lk = self.data.lock().unwrap();
   41|     10|        let data: &mut LocalVoteHistoryData = &mut data_lk;
   42|     10|        clean(data, self.max_cache);
   43|     10|
   44|     10|        let mut add_vote = true;
   45|     10|        let mut remove_root = false;
   46|     10|        let mut ids_to_delete = Vec::new();
   47|       |        // Erase any vote that is not for this hash, or duplicate by account, and if new timestamp is higher
   48|     10|        if let Some(ids) = data.history_by_root.get_mut(root) {
                                  ^6
   49|      7|            for &i in ids.iter() {
                                    ^6
   50|      7|                let current = &data.history[&i];
   51|      7|                if &current.hash != hash
   52|      5|                    || (vote.voting_account == current.vote.voting_account
   53|      3|                        && current.vote.timestamp() <= vote.timestamp())
   54|      5|                {
   55|      5|                    ids_to_delete.push(i);
   56|      5|                } else if vote.voting_account == current.vote.voting_account
                                        ^2
   57|      0|                    && current.vote.timestamp() > vote.timestamp()
   58|      0|                {
   59|      0|                    add_vote = false;
   60|      2|                }
   61|       |            }
   62|       |
   63|     11|            for &i in &ids_to_delete {
                               ^5
   64|      5|                ids.remove(&i);
   65|      5|                data.history.remove(&i);
   66|      5|                remove_root = ids.is_empty();
   67|      5|            }
   68|      4|        }
   69|       |
   70|     10|        if remove_root && !add_vote {
                                        ^4
   71|      0|            data.history_by_root.remove(root);
   72|     10|        }
   73|       |
   74|       |        // Do not add new vote to cache if representative account is same and timestamp is lower
   75|     10|        if add_vote {
   76|     10|            let id = data
   77|     10|                .history
   78|     10|                .iter()
   79|     10|                .next_back()
   80|     10|                .map(|(k, _)| k + 1)
                                            ^2
   81|     10|                .unwrap_or_default();
   82|     10|            data.history.insert(
   83|     10|                id,
   84|     10|                LocalVote {
   85|     10|                    root: root.to_owned(),
   86|     10|                    hash: hash.to_owned(),
   87|     10|                    vote: vote.clone(),
   88|     10|                },
   89|     10|            );
   90|     10|            data.history_by_root
   91|     10|                .entry(root.to_owned())
   92|     10|                .or_default()
   93|     10|                .insert(id);
   94|     10|        }
                       ^0
   95|     10|    }
   96|       |
   97|      0|    pub fn erase(&self, root: &Root) {
   98|      0|        let mut data_lk = self.data.lock().unwrap();
   99|      0|        if let Some(removed) = data_lk.history_by_root.remove(root) {
  100|      0|            for &id in &removed {
  101|      0|                data_lk.history.remove(&id);
  102|      0|            }
  103|      0|        }
  104|      0|    }
  105|       |
  106|      7|    pub fn votes(&self, root: &Root, hash: &BlockHash, is_final: bool) -> Vec<Arc<Vote>> {
  107|      7|        let data_lk = self.data.lock().unwrap();
  108|      7|        let mut result = Vec::new();
  109|      7|        if let Some(ids) = data_lk.history_by_root.get(root) {
                                  ^5
  110|      6|            for &id in ids.iter() {
                                     ^5
  111|      6|                let entry = &data_lk.history[&id];
  112|      6|                if &entry.hash == hash && (!is_final || entry.vote.timestamp() == u64::MAX) {
                                                         ^5           ^0
  113|      5|                    result.push(entry.vote.clone())
  114|      1|                }
  115|       |            }
  116|      2|        }
  117|      7|        result
  118|      7|    }
  119|       |
  120|      3|    pub fn exists(&self, root: &Root) -> bool {
  121|      3|        let data_lk = self.data.lock().unwrap();
  122|      3|        data_lk.history_by_root.contains_key(root)
  123|      3|    }
  124|       |
  125|      4|    pub fn size(&self) -> usize {
  126|      4|        self.data.lock().unwrap().history.len()
  127|      4|    }
  128|       |
  129|      0|    pub fn container_info(&self) -> ContainerInfo {
  130|      0|        [(
  131|      0|            "history",
  132|      0|            self.data.lock().unwrap().history.len(),
  133|      0|            size_of::<LocalVote>(),
  134|      0|        )]
  135|      0|        .into()
  136|      0|    }
  137|       |}
  138|       |
  139|     10|fn clean(data: &mut LocalVoteHistoryData, max_cache: usize) {
  140|     10|    debug_assert!(max_cache > 0);
  141|     10|    while data.history.len() > max_cache {
  142|      0|        let (id, root) = {
  143|      0|            let (id, vote) = data.history.iter().next().unwrap();
  144|      0|            (*id, vote.root)
  145|      0|        };
  146|      0|        data.history.remove(&id);
  147|      0|        let mut root_empty = false;
  148|      0|        if let Some(root) = data.history_by_root.get_mut(&root) {
  149|      0|            root.remove(&id);
  150|      0|            root_empty = root.is_empty();
  151|      0|        }
  152|       |
  153|      0|        if root_empty {
  154|      0|            data.history_by_root.remove(&root);
  155|      0|        }
  156|       |    }
  157|     10|}
  158|       |
  159|       |#[cfg(test)]
  160|       |mod tests {
  161|       |    use super::*;
  162|       |    use rsnano_core::PrivateKey;
  163|       |
  164|       |    #[test]
  165|      1|    fn empty_history() {
  166|      1|        let history = LocalVoteHistory::new(256);
  167|      1|        assert!(!history.exists(&Root::from(1)));
  168|      1|        assert_eq!(
  169|      1|            history
  170|      1|                .votes(&Root::from(1), &BlockHash::from(2), false)
  171|      1|                .len(),
  172|      1|            0
  173|      1|        );
  174|      1|        assert_eq!(history.size(), 0);
  175|      1|    }
  176|       |
  177|       |    #[test]
  178|      1|    fn add_one_vote() {
  179|      1|        let history = LocalVoteHistory::new(256);
  180|      1|        let vote = Arc::new(Vote::null());
  181|      1|        let root = Root::from(1);
  182|      1|        let hash = BlockHash::from(2);
  183|      1|        history.add(&root, &hash, &vote);
  184|      1|        assert_eq!(history.size(), 1);
  185|      1|        assert_eq!(history.exists(&root), true);
  186|      1|        assert_eq!(history.exists(&Root::from(2)), false);
  187|      1|        let votes = history.votes(&root, &hash, false);
  188|      1|        assert_eq!(votes.len(), 1);
  189|      1|        assert_eq!(Arc::ptr_eq(&votes[0], &vote), true);
  190|      1|        assert_eq!(history.votes(&root, &BlockHash::from(3), false).len(), 0);
  191|      1|        assert_eq!(
  192|      1|            history
  193|      1|                .votes(&Root::from(2), &BlockHash::from(2), false)
  194|      1|                .len(),
  195|      1|            0
  196|      1|        );
  197|      1|    }
  198|       |
  199|       |    #[test]
  200|      1|    fn add_two_votes() {
  201|      1|        let history = LocalVoteHistory::new(256);
  202|      1|        let vote1a = Arc::new(Vote::null());
  203|      1|        let vote1b = Arc::new(Vote::null());
  204|      1|        let root = Root::from(1);
  205|      1|        let hash = BlockHash::from(2);
  206|      1|        history.add(&root, &hash, &vote1a);
  207|      1|        history.add(&root, &hash, &vote1b);
  208|      1|        let votes = history.votes(&root, &hash, false);
  209|      1|        assert_eq!(votes.len(), 1);
  210|      1|        assert_eq!(Arc::ptr_eq(&votes[0], &vote1b), true);
  211|      1|        assert_eq!(Arc::ptr_eq(&votes[0], &vote1a), false);
  212|      1|    }
  213|       |
  214|       |    #[test]
  215|      1|    fn basic() {
  216|      1|        let history = LocalVoteHistory::new(256);
  217|      1|        let root = Root::from(1);
  218|      1|        let hash = BlockHash::from(2);
  219|      1|        let vote1a = Arc::new(Vote::null());
  220|      1|        let vote1b = Arc::new(Vote::null());
  221|      1|        let keys = PrivateKey::new();
  222|      1|        let vote2 = Arc::new(Vote::new(&keys, 0, 0, Vec::new()));
  223|      1|        history.add(&root, &hash, &vote1a);
  224|      1|        history.add(&root, &hash, &vote1b);
  225|      1|        history.add(&root, &hash, &vote2);
  226|      1|        assert_eq!(history.size(), 2);
  227|       |
  228|      1|        let votes = history.votes(&root, &hash, false);
  229|      1|        assert_eq!(votes.len(), 2);
  230|      1|        assert!(Arc::ptr_eq(&votes[0], &vote1b) || Arc::ptr_eq(&votes[1], &vote1b));
                                                                 ^0
  231|      1|        assert!(Arc::ptr_eq(&votes[0], &vote2) || Arc::ptr_eq(&votes[1], &vote2));
  232|      1|    }
  233|       |
  234|       |    #[test]
  235|      1|    fn basic2() {
  236|      1|        let history = LocalVoteHistory::new(256);
  237|      1|        let root = Root::from(1);
  238|      1|        let hash = BlockHash::from(2);
  239|      1|        let vote1a = Arc::new(Vote::null());
  240|      1|        let vote1b = Arc::new(Vote::null());
  241|      1|        let keys1 = PrivateKey::new();
  242|      1|        let vote2 = Arc::new(Vote::new(&keys1, 0, 0, Vec::new()));
  243|      1|        let keys2 = PrivateKey::new();
  244|      1|        let vote3 = Arc::new(Vote::new(&keys2, 0, 0, Vec::new()));
  245|      1|        history.add(&root, &hash, &vote1a);
  246|      1|        history.add(&root, &hash, &vote1b);
  247|      1|        history.add(&root, &hash, &vote2);
  248|      1|        history.add(&root, &BlockHash::from(3), &vote3);
  249|      1|        assert_eq!(history.size(), 1);
  250|      1|        let votes = history.votes(&root, &BlockHash::from(3), false);
  251|      1|        assert_eq!(votes.len(), 1);
  252|      1|        assert!(Arc::ptr_eq(&votes[0], &vote3));
  253|      1|    }
  254|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/request_aggregator.rs:
    1|       |use super::{
    2|       |    request_aggregator_impl::{AggregateResult, RequestAggregatorImpl},
    3|       |    VoteGenerators,
    4|       |};
    5|       |use crate::stats::{DetailType, Direction, StatType, Stats};
    6|       |use rsnano_core::{
    7|       |    utils::{ContainerInfo, FairQueue},
    8|       |    BlockHash, Root,
    9|       |};
   10|       |use rsnano_ledger::Ledger;
   11|       |use rsnano_network::{ChannelId, DeadChannelCleanupStep, Network, TrafficType};
   12|       |use rsnano_store_lmdb::{LmdbReadTransaction, Transaction};
   13|       |use std::{
   14|       |    cmp::{max, min},
   15|       |    sync::{Arc, Condvar, Mutex, MutexGuard, RwLock},
   16|       |    thread::JoinHandle,
   17|       |};
   18|       |
   19|       |#[derive(Clone, Debug, PartialEq)]
   20|       |pub struct RequestAggregatorConfig {
   21|       |    pub threads: usize,
   22|       |    pub max_queue: usize,
   23|       |    pub batch_size: usize,
   24|       |}
   25|       |
   26|       |impl RequestAggregatorConfig {
   27|      9|    pub fn new(parallelism: usize) -> Self {
   28|      9|        Self {
   29|      9|            threads: max(1, min(parallelism / 2, 4)),
   30|      9|            max_queue: 128,
   31|      9|            batch_size: 16,
   32|      9|        }
   33|      9|    }
   34|       |}
   35|       |
   36|       |/**
   37|       | * Pools together confirmation requests, separately for each endpoint.
   38|       | * Requests are added from network messages, and aggregated to minimize bandwidth and vote generation. Example:
   39|       | * * Two votes are cached, one for hashes {1,2,3} and another for hashes {4,5,6}
   40|       | * * A request arrives for hashes {1,4,5}. Another request arrives soon afterwards for hashes {2,3,6}
   41|       | * * The aggregator will reply with the two cached votes
   42|       | * Votes are generated for uncached hashes.
   43|       | */
   44|       |pub struct RequestAggregator {
   45|       |    config: RequestAggregatorConfig,
   46|       |    stats: Arc<Stats>,
   47|       |    vote_generators: Arc<VoteGenerators>,
   48|       |    ledger: Arc<Ledger>,
   49|       |    pub(crate) state: Arc<Mutex<RequestAggregatorState>>,
   50|       |    condition: Arc<Condvar>,
   51|       |    threads: Mutex<Vec<JoinHandle<()>>>,
   52|       |    network: Arc<RwLock<Network>>,
   53|       |}
   54|       |
   55|       |impl RequestAggregator {
   56|      3|    pub fn new(
   57|      3|        config: RequestAggregatorConfig,
   58|      3|        stats: Arc<Stats>,
   59|      3|        vote_generators: Arc<VoteGenerators>,
   60|      3|        ledger: Arc<Ledger>,
   61|      3|        network: Arc<RwLock<Network>>,
   62|      3|    ) -> Self {
   63|      3|        let max_queue = config.max_queue;
   64|      3|        Self {
   65|      3|            stats,
   66|      3|            vote_generators,
   67|      3|            ledger,
   68|      3|            config,
   69|      3|            condition: Arc::new(Condvar::new()),
   70|      3|            state: Arc::new(Mutex::new(RequestAggregatorState {
   71|      3|                queue: FairQueue::new(move |_| max_queue, |_| 1),
                                                             ^0             ^0
   72|      3|                stopped: false,
   73|      3|            })),
   74|      3|            threads: Mutex::new(Vec::new()),
   75|      3|            network,
   76|      3|        }
   77|      3|    }
   78|       |
   79|      3|    pub fn start(&self) {
   80|      3|        let mut guard = self.threads.lock().unwrap();
   81|      3|        for _ in 0..self.config.threads {
   82|      3|            let aggregator_loop = RequestAggregatorLoop {
   83|      3|                mutex: self.state.clone(),
   84|      3|                condition: self.condition.clone(),
   85|      3|                stats: self.stats.clone(),
   86|      3|                config: self.config.clone(),
   87|      3|                ledger: self.ledger.clone(),
   88|      3|                vote_generators: self.vote_generators.clone(),
   89|      3|                network: self.network.clone(),
   90|      3|            };
   91|      3|
   92|      3|            guard.push(
   93|      3|                std::thread::Builder::new()
   94|      3|                    .name("Req aggregator".to_string())
   95|      3|                    .spawn(move || aggregator_loop.run())
   96|      3|                    .unwrap(),
   97|      3|            );
   98|      3|        }
   99|      3|    }
  100|       |
  101|      0|    pub fn request(&self, request: RequestType, channel_id: ChannelId) -> bool {
  102|      0|        if request.is_empty() {
  103|      0|            return false;
  104|      0|        }
  105|      0|
  106|      0|        let request_len = request.len();
  107|      0|
  108|      0|        let added = { self.state.lock().unwrap().queue.push(channel_id, request) };
  109|      0|
  110|      0|        if added {
  111|      0|            self.stats
  112|      0|                .inc(StatType::RequestAggregator, DetailType::Request);
  113|      0|            self.stats.add(
  114|      0|                StatType::RequestAggregator,
  115|      0|                DetailType::RequestHashes,
  116|      0|                request_len as u64,
  117|      0|            );
  118|      0|            self.condition.notify_one();
  119|      0|        } else {
  120|      0|            self.stats
  121|      0|                .inc(StatType::RequestAggregator, DetailType::Overfill);
  122|      0|            self.stats.add(
  123|      0|                StatType::RequestAggregator,
  124|      0|                DetailType::OverfillHashes,
  125|      0|                request_len as u64,
  126|      0|            );
  127|      0|        }
  128|       |
  129|       |        // TODO: This stat is for compatibility with existing tests and is in principle unnecessary
  130|      0|        self.stats.inc(
  131|      0|            StatType::Aggregator,
  132|      0|            if added {
  133|      0|                DetailType::AggregatorAccepted
  134|       |            } else {
  135|      0|                DetailType::AggregatorDropped
  136|       |            },
  137|       |        );
  138|       |
  139|      0|        added
  140|      0|    }
  141|       |
  142|      3|    pub fn stop(&self) {
  143|      3|        self.state.lock().unwrap().stopped = true;
  144|      3|        self.condition.notify_all();
  145|      3|        let mut threads = Vec::new();
  146|      3|        {
  147|      3|            let mut guard = self.threads.lock().unwrap();
  148|      3|            std::mem::swap(&mut threads, &mut *guard);
  149|      3|        }
  150|      6|        for thread in threads {
                          ^3
  151|      3|            thread.join().unwrap();
  152|      3|        }
  153|      3|    }
  154|       |
  155|       |    /// Returns the number of currently queued request pools
  156|      0|    pub fn len(&self) -> usize {
  157|      0|        self.state.lock().unwrap().queue.len()
  158|      0|    }
  159|       |
  160|      0|    pub fn is_empty(&self) -> bool {
  161|      0|        self.len() == 0
  162|      0|    }
  163|       |
  164|      0|    pub fn container_info(&self) -> ContainerInfo {
  165|      0|        let guard = self.state.lock().unwrap();
  166|      0|        ContainerInfo::builder()
  167|      0|            .node("queue", guard.queue.container_info())
  168|      0|            .finish()
  169|      0|    }
  170|       |}
  171|       |
  172|       |impl Drop for RequestAggregator {
  173|      3|    fn drop(&mut self) {
  174|      3|        debug_assert!(self.threads.lock().unwrap().is_empty())
  175|      3|    }
  176|       |}
  177|       |
  178|       |type RequestType = Vec<(BlockHash, Root)>;
  179|       |
  180|       |pub(crate) struct RequestAggregatorState {
  181|       |    queue: FairQueue<ChannelId, RequestType>,
  182|       |    stopped: bool,
  183|       |}
  184|       |
  185|       |struct RequestAggregatorLoop {
  186|       |    mutex: Arc<Mutex<RequestAggregatorState>>,
  187|       |    condition: Arc<Condvar>,
  188|       |    stats: Arc<Stats>,
  189|       |    config: RequestAggregatorConfig,
  190|       |    ledger: Arc<Ledger>,
  191|       |    vote_generators: Arc<VoteGenerators>,
  192|       |    network: Arc<RwLock<Network>>,
  193|       |}
  194|       |
  195|       |impl RequestAggregatorLoop {
  196|      3|    fn run(&self) {
  197|      3|        let mut guard = self.mutex.lock().unwrap();
  198|      6|        while !guard.stopped {
  199|      3|            if !guard.queue.is_empty() {
  200|      0|                guard = self.run_batch(guard);
  201|      3|            } else {
  202|      3|                guard = self
  203|      3|                    .condition
  204|      6|                    .wait_while(guard, |g| !g.stopped && g.queue.is_empty())
                                                                       ^3
  205|      3|                    .unwrap();
  206|      3|            }
  207|       |        }
  208|      3|    }
  209|       |
  210|      0|    fn run_batch<'a>(
  211|      0|        &'a self,
  212|      0|        mut state: MutexGuard<'a, RequestAggregatorState>,
  213|      0|    ) -> MutexGuard<'a, RequestAggregatorState> {
  214|      0|        let batch = state.queue.next_batch(self.config.batch_size);
  215|      0|        drop(state);
  216|      0|
  217|      0|        let mut tx = self.ledger.read_txn();
  218|       |
  219|      0|        for (channel_id, request) in &batch {
  220|      0|            tx.refresh_if_needed();
  221|      0|
  222|      0|            let should_drop = self
  223|      0|                .network
  224|      0|                .read()
  225|      0|                .unwrap()
  226|      0|                .should_drop(*channel_id, TrafficType::VoteReply);
  227|      0|
  228|      0|            if !should_drop {
  229|      0|                self.process(&tx, request, *channel_id);
  230|      0|            } else {
  231|      0|                self.stats.inc_dir(
  232|      0|                    StatType::RequestAggregator,
  233|      0|                    DetailType::ChannelFull,
  234|      0|                    Direction::Out,
  235|      0|                );
  236|      0|            }
  237|       |        }
  238|       |
  239|      0|        self.mutex.lock().unwrap()
  240|      0|    }
  241|       |
  242|      0|    fn process(&self, tx: &LmdbReadTransaction, request: &RequestType, channel_id: ChannelId) {
  243|      0|        let remaining = self.aggregate(tx, request);
  244|      0|
  245|      0|        if !remaining.remaining_normal.is_empty() {
  246|      0|            self.stats
  247|      0|                .inc(StatType::RequestAggregatorReplies, DetailType::NormalVote);
  248|      0|
  249|      0|            // Generate votes for the remaining hashes
  250|      0|            let generated = self
  251|      0|                .vote_generators
  252|      0|                .generate_non_final_votes(&remaining.remaining_normal, channel_id);
  253|      0|            self.stats.add_dir(
  254|      0|                StatType::Requests,
  255|      0|                DetailType::RequestsCannotVote,
  256|      0|                Direction::In,
  257|      0|                (remaining.remaining_normal.len() - generated) as u64,
  258|      0|            );
  259|      0|        }
  260|       |
  261|      0|        if !remaining.remaining_final.is_empty() {
  262|      0|            self.stats
  263|      0|                .inc(StatType::RequestAggregatorReplies, DetailType::FinalVote);
  264|      0|
  265|      0|            // Generate final votes for the remaining hashes
  266|      0|            let generated = self
  267|      0|                .vote_generators
  268|      0|                .generate_final_votes(&remaining.remaining_final, channel_id);
  269|      0|            self.stats.add_dir(
  270|      0|                StatType::Requests,
  271|      0|                DetailType::RequestsCannotVote,
  272|      0|                Direction::In,
  273|      0|                (remaining.remaining_final.len() - generated) as u64,
  274|      0|            );
  275|      0|        }
  276|      0|    }
  277|       |
  278|       |    /// Aggregate requests and send cached votes to channel.
  279|       |    /// Return the remaining hashes that need vote generation for each block for regular & final vote generators
  280|      0|    fn aggregate(&self, tx: &LmdbReadTransaction, requests: &RequestType) -> AggregateResult {
  281|      0|        let mut aggregator = RequestAggregatorImpl::new(&self.ledger, &self.stats, tx);
  282|      0|        aggregator.add_votes(requests);
  283|      0|        aggregator.get_result()
  284|      0|    }
  285|       |}
  286|       |
  287|       |pub(crate) struct RequestAggregatorCleanup {
  288|       |    state: Arc<Mutex<RequestAggregatorState>>,
  289|       |}
  290|       |
  291|       |impl RequestAggregatorCleanup {
  292|      3|    pub(crate) fn new(state: Arc<Mutex<RequestAggregatorState>>) -> Self {
  293|      3|        Self { state }
  294|      3|    }
  295|       |}
  296|       |
  297|       |impl DeadChannelCleanupStep for RequestAggregatorCleanup {
  298|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  299|      0|        let mut guard = self.state.lock().unwrap();
  300|      0|        for channel_id in dead_channel_ids {
  301|      0|            guard.queue.remove(channel_id);
  302|      0|        }
  303|      0|    }
  304|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/request_aggregator_impl.rs:
    1|       |use crate::stats::{DetailType, StatType, Stats};
    2|       |use rsnano_core::{Account, Block, BlockHash, Root, SavedBlock};
    3|       |use rsnano_ledger::Ledger;
    4|       |use rsnano_store_lmdb::LmdbReadTransaction;
    5|       |
    6|       |pub(super) struct RequestAggregatorImpl<'a> {
    7|       |    ledger: &'a Ledger,
    8|       |    stats: &'a Stats,
    9|       |    tx: &'a LmdbReadTransaction,
   10|       |
   11|       |    pub to_generate: Vec<SavedBlock>,
   12|       |    pub to_generate_final: Vec<SavedBlock>,
   13|       |}
   14|       |
   15|       |impl<'a> RequestAggregatorImpl<'a> {
   16|      0|    pub fn new(ledger: &'a Ledger, stats: &'a Stats, tx: &'a LmdbReadTransaction) -> Self {
   17|      0|        Self {
   18|      0|            ledger,
   19|      0|            stats,
   20|      0|            tx,
   21|      0|            to_generate: Vec::new(),
   22|      0|            to_generate_final: Vec::new(),
   23|      0|        }
   24|      0|    }
   25|       |
   26|      0|    fn search_for_block(&self, hash: &BlockHash, root: &Root) -> Option<SavedBlock> {
   27|      0|        // Ledger by hash
   28|      0|        let block = self.ledger.any().get_block(self.tx, hash);
   29|      0|        if block.is_some() {
   30|      0|            return block;
   31|      0|        }
   32|      0|
   33|      0|        if !root.is_zero() {
   34|       |            // Search for successor of root
   35|      0|            if let Some(successor) = self.ledger.any().block_successor(self.tx, &(*root).into()) {
   36|      0|                return self.ledger.any().get_block(self.tx, &successor);
   37|      0|            }
   38|       |
   39|       |            // If that fails treat root as account
   40|      0|            if let Some(info) = self
   41|      0|                .ledger
   42|      0|                .any()
   43|      0|                .get_account(self.tx, &Account::from(*root))
   44|       |            {
   45|      0|                return self.ledger.any().get_block(self.tx, &info.open_block);
   46|      0|            }
   47|      0|        }
   48|       |
   49|      0|        None
   50|      0|    }
   51|       |
   52|      0|    pub fn add_votes(&mut self, requests: &[(BlockHash, Root)]) {
   53|      0|        for (hash, root) in requests {
   54|      0|            let block = self.search_for_block(hash, root);
   55|      0|
   56|      0|            let should_generate_final_vote = |block: &Block| {
   57|       |                // Check if final vote is set for this block
   58|      0|                if let Some(final_hash) = self
   59|      0|                    .ledger
   60|      0|                    .store
   61|      0|                    .final_vote
   62|      0|                    .get(self.tx, &block.qualified_root())
   63|       |                {
   64|      0|                    final_hash == block.hash()
   65|       |                } else {
   66|       |                    // If the final vote is not set, generate vote if the block is confirmed
   67|      0|                    self.ledger.confirmed().block_exists(self.tx, &block.hash())
   68|       |                }
   69|      0|            };
   70|       |
   71|      0|            if let Some(block) = block {
   72|      0|                if should_generate_final_vote(&block) {
   73|      0|                    self.to_generate_final.push(block);
   74|      0|                    self.stats
   75|      0|                        .inc(StatType::Requests, DetailType::RequestsFinal);
   76|      0|                } else {
   77|      0|                    self.stats
   78|      0|                        .inc(StatType::Requests, DetailType::RequestsNonFinal);
   79|      0|                }
   80|      0|            } else {
   81|      0|                self.stats
   82|      0|                    .inc(StatType::Requests, DetailType::RequestsUnknown);
   83|      0|            }
   84|       |        }
   85|      0|    }
   86|       |
   87|      0|    pub fn get_result(self) -> AggregateResult {
   88|      0|        AggregateResult {
   89|      0|            remaining_normal: self.to_generate,
   90|      0|            remaining_final: self.to_generate_final,
   91|      0|        }
   92|      0|    }
   93|       |}
   94|       |
   95|       |pub(super) struct AggregateResult {
   96|       |    pub remaining_normal: Vec<SavedBlock>,
   97|       |    pub remaining_final: Vec<SavedBlock>,
   98|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/vote_generator.rs:
    1|       |use super::{LocalVoteHistory, VoteSpacing};
    2|       |use crate::{
    3|       |    consensus::VoteBroadcaster,
    4|       |    stats::{DetailType, Direction, Sample, StatType, Stats},
    5|       |    transport::MessageSender,
    6|       |    utils::ProcessingQueue,
    7|       |    wallets::Wallets,
    8|       |};
    9|       |use rsnano_core::{
   10|       |    utils::{milliseconds_since_epoch, ContainerInfo},
   11|       |    BlockHash, Root, SavedBlock, Vote,
   12|       |};
   13|       |use rsnano_ledger::{Ledger, Writer};
   14|       |use rsnano_messages::{ConfirmAck, Message};
   15|       |use rsnano_network::{ChannelId, TrafficType};
   16|       |use rsnano_nullable_clock::SteadyClock;
   17|       |use rsnano_store_lmdb::{LmdbReadTransaction, LmdbWriteTransaction, Transaction};
   18|       |use std::{
   19|       |    collections::VecDeque,
   20|       |    mem::size_of,
   21|       |    sync::{
   22|       |        atomic::{AtomicBool, Ordering},
   23|       |        Arc, Condvar, Mutex, MutexGuard,
   24|       |    },
   25|       |    thread::{self, JoinHandle},
   26|       |    time::{Duration, Instant},
   27|       |};
   28|       |
   29|       |pub(crate) struct VoteGenerator {
   30|       |    ledger: Arc<Ledger>,
   31|       |    vote_generation_queue: ProcessingQueue<(Root, BlockHash)>,
   32|       |    shared_state: Arc<SharedState>,
   33|       |    thread: Mutex<Option<JoinHandle<()>>>,
   34|       |    stats: Arc<Stats>,
   35|       |}
   36|       |
   37|       |impl VoteGenerator {
   38|       |    const MAX_REQUESTS: usize = 2048;
   39|       |    const MAX_HASHES: usize = 255;
   40|       |
   41|      6|    pub(crate) fn new(
   42|      6|        ledger: Arc<Ledger>,
   43|      6|        wallets: Arc<Wallets>,
   44|      6|        history: Arc<LocalVoteHistory>,
   45|      6|        is_final: bool,
   46|      6|        stats: Arc<Stats>,
   47|      6|        message_sender: MessageSender,
   48|      6|        voting_delay: Duration,
   49|      6|        vote_generator_delay: Duration,
   50|      6|        vote_broadcaster: Arc<VoteBroadcaster>,
   51|      6|        clock: Arc<SteadyClock>,
   52|      6|    ) -> Self {
   53|      6|        let shared_state = Arc::new(SharedState {
   54|      6|            ledger: Arc::clone(&ledger),
   55|      6|            message_sender: Mutex::new(message_sender),
   56|      6|            history,
   57|      6|            wallets,
   58|      6|            condition: Condvar::new(),
   59|      6|            queues: Mutex::new(Queues {
   60|      6|                requests: Default::default(),
   61|      6|                candidates: Default::default(),
   62|      6|                next_broadcast: Instant::now(),
   63|      6|            }),
   64|      6|            is_final,
   65|      6|            stopped: AtomicBool::new(false),
   66|      6|            stats: Arc::clone(&stats),
   67|      6|            vote_broadcaster,
   68|      6|            spacing: Mutex::new(VoteSpacing::new(voting_delay)),
   69|      6|            vote_generator_delay,
   70|      6|            clock,
   71|      6|        });
   72|      6|
   73|      6|        let shared_state_clone = Arc::clone(&shared_state);
   74|      6|        Self {
   75|      6|            ledger,
   76|      6|            shared_state,
   77|      6|            thread: Mutex::new(None),
   78|      6|            vote_generation_queue: ProcessingQueue::new(
   79|      6|                Arc::clone(&stats),
   80|      6|                StatType::VoteGenerator,
   81|      6|                "Voting que".to_string(),
   82|      6|                1,         // single threaded
   83|      6|                1024 * 32, // max queue size
   84|      6|                256,       // max batch size,
   85|      6|                Box::new(move |batch| {
   86|      0|                    shared_state_clone.process_batch(batch);
   87|      6|                }),
   88|      6|            ),
   89|      6|            stats,
   90|      6|        }
   91|      6|    }
   92|       |
   93|      6|    pub(crate) fn start(&self) {
   94|      6|        let shared_state_clone = Arc::clone(&self.shared_state);
   95|      6|        *self.thread.lock().unwrap() = Some(
   96|      6|            thread::Builder::new()
   97|      6|                .name("voting".to_owned())
   98|      6|                .spawn(move || shared_state_clone.run())
   99|      6|                .unwrap(),
  100|      6|        );
  101|      6|        self.vote_generation_queue.start();
  102|      6|    }
  103|       |
  104|      6|    pub(crate) fn stop(&self) {
  105|      6|        self.vote_generation_queue.stop();
  106|      6|        {
  107|      6|            let _guard = self.shared_state.queues.lock().unwrap();
  108|      6|            self.shared_state.stopped.store(true, Ordering::SeqCst);
  109|      6|        }
  110|      6|        self.shared_state.condition.notify_all();
  111|      6|        let thread = self.thread.lock().unwrap().take();
  112|      6|        if let Some(thread) = thread {
  113|      6|            thread.join().unwrap();
  114|      6|        }
                       ^0
  115|      6|    }
  116|       |
  117|       |    /// Queue items for vote generation, or broadcast votes already in cache
  118|      0|    pub(crate) fn add(&self, root: &Root, hash: &BlockHash) {
  119|      0|        self.vote_generation_queue.add((*root, *hash));
  120|      0|    }
  121|       |
  122|       |    /// Queue blocks for vote generation, returning the number of successful candidates.
  123|      0|    pub(crate) fn generate(&self, blocks: &[SavedBlock], channel_id: ChannelId) -> usize {
  124|      0|        let req_candidates = {
  125|      0|            let txn = self.ledger.read_txn();
  126|      0|            blocks
  127|      0|                .iter()
  128|      0|                .filter_map(|i| {
  129|      0|                    if self.ledger.dependents_confirmed(&txn, i) {
  130|      0|                        Some((i.root(), i.hash()))
  131|       |                    } else {
  132|      0|                        None
  133|       |                    }
  134|      0|                })
  135|      0|                .collect::<Vec<_>>()
  136|      0|        };
  137|      0|
  138|      0|        let result = req_candidates.len();
  139|      0|        let mut guard = self.shared_state.queues.lock().unwrap();
  140|      0|        guard.requests.push_back((req_candidates, channel_id));
  141|      0|        while guard.requests.len() > Self::MAX_REQUESTS {
  142|      0|            // On a large queue of requests, erase the oldest one
  143|      0|            guard.requests.pop_front();
  144|      0|            self.stats.inc(
  145|      0|                StatType::VoteGenerator,
  146|      0|                DetailType::GeneratorRepliesDiscarded,
  147|      0|            );
  148|      0|        }
  149|       |
  150|      0|        result
  151|      0|    }
  152|       |
  153|      0|    pub(crate) fn container_info(&self) -> ContainerInfo {
  154|      0|        let candidates_count;
  155|      0|        let requests_count;
  156|      0|        {
  157|      0|            let guard = self.shared_state.queues.lock().unwrap();
  158|      0|            candidates_count = guard.candidates.len();
  159|      0|            requests_count = guard.requests.len();
  160|      0|        }
  161|      0|
  162|      0|        [
  163|      0|            (
  164|      0|                "candidates",
  165|      0|                candidates_count,
  166|      0|                size_of::<Root>() + size_of::<BlockHash>(),
  167|      0|            ),
  168|      0|            (
  169|      0|                "requests",
  170|      0|                requests_count,
  171|      0|                size_of::<ChannelId>() + size_of::<Vec<(Root, BlockHash)>>(),
  172|      0|            ),
  173|      0|        ]
  174|      0|        .into()
  175|      0|    }
  176|       |}
  177|       |
  178|       |impl Drop for VoteGenerator {
  179|      6|    fn drop(&mut self) {
  180|      6|        debug_assert!(self.thread.lock().unwrap().is_none())
  181|      6|    }
  182|       |}
  183|       |
  184|       |struct SharedState {
  185|       |    ledger: Arc<Ledger>,
  186|       |    wallets: Arc<Wallets>,
  187|       |    history: Arc<LocalVoteHistory>,
  188|       |    message_sender: Mutex<MessageSender>,
  189|       |    is_final: bool,
  190|       |    condition: Condvar,
  191|       |    stopped: AtomicBool,
  192|       |    queues: Mutex<Queues>,
  193|       |    stats: Arc<Stats>,
  194|       |    vote_broadcaster: Arc<VoteBroadcaster>,
  195|       |    spacing: Mutex<VoteSpacing>,
  196|       |    vote_generator_delay: Duration,
  197|       |    clock: Arc<SteadyClock>,
  198|       |}
  199|       |
  200|       |impl SharedState {
  201|      6|    fn run(&self) {
  202|      6|        let mut queues = self.queues.lock().unwrap();
  203|      6|        while !self.stopped.load(Ordering::SeqCst) {
  204|      6|            queues = self
  205|      6|                .condition
  206|     12|                .wait_timeout_while(queues, self.vote_generator_delay, |i| {
  207|     12|                    !self.stopped.load(Ordering::SeqCst)
  208|      6|                        && i.requests.is_empty()
  209|      6|                        && !i.should_broadcast()
  210|     12|                })
  211|      6|                .unwrap()
  212|      6|                .0;
  213|      6|
  214|      6|            if self.stopped.load(Ordering::SeqCst) {
  215|      6|                return;
  216|      0|            }
  217|      0|
  218|      0|            if queues.should_broadcast() {
  219|      0|                queues = self.broadcast(queues);
  220|      0|                queues.next_broadcast = Instant::now() + self.vote_generator_delay;
  221|      0|            }
  222|       |
  223|      0|            if let Some(request) = queues.requests.pop_front() {
  224|      0|                drop(queues);
  225|      0|                self.reply(request);
  226|      0|                queues = self.queues.lock().unwrap();
  227|      0|            }
  228|       |        }
  229|      6|    }
  230|       |
  231|      0|    fn broadcast<'a>(&'a self, mut queues: MutexGuard<'a, Queues>) -> MutexGuard<'a, Queues> {
  232|      0|        let mut hashes = Vec::with_capacity(VoteGenerator::MAX_HASHES);
  233|      0|        let mut roots = Vec::with_capacity(VoteGenerator::MAX_HASHES);
  234|      0|        {
  235|      0|            let spacing = self.spacing.lock().unwrap();
  236|      0|            while let Some((root, hash)) = queues.candidates.pop_front() {
  237|      0|                if !roots.contains(&root) {
  238|      0|                    if spacing.votable(&root, &hash, self.clock.now()) {
  239|      0|                        roots.push(root);
  240|      0|                        hashes.push(hash);
  241|      0|                    } else {
  242|      0|                        self.stats
  243|      0|                            .inc(StatType::VoteGenerator, DetailType::GeneratorSpacing);
  244|      0|                    }
  245|      0|                }
  246|      0|                if hashes.len() == VoteGenerator::MAX_HASHES {
  247|      0|                    break;
  248|      0|                }
  249|       |            }
  250|       |        }
  251|       |
  252|      0|        if !hashes.is_empty() {
  253|      0|            drop(queues);
  254|      0|            self.vote(&hashes, &roots, |generated_vote| {
  255|      0|                self.stats
  256|      0|                    .inc(StatType::VoteGenerator, DetailType::GeneratorBroadcasts);
  257|      0|                let sample = if self.is_final {
  258|      0|                    Sample::VoteGeneratorFinalHashes
  259|       |                } else {
  260|      0|                    Sample::VoteGeneratorHashes
  261|       |                };
  262|      0|                self.stats.sample(
  263|      0|                    sample,
  264|      0|                    generated_vote.hashes.len() as i64,
  265|      0|                    (0, ConfirmAck::HASHES_MAX as i64),
  266|      0|                );
  267|      0|                self.vote_broadcaster.broadcast(generated_vote);
  268|      0|            });
  269|      0|            queues = self.queues.lock().unwrap();
  270|      0|        }
  271|       |
  272|      0|        queues
  273|      0|    }
  274|       |
  275|      0|    fn vote<F>(&self, hashes: &Vec<BlockHash>, roots: &Vec<Root>, action: F)
  276|      0|    where
  277|      0|        F: Fn(Arc<Vote>),
  278|      0|    {
  279|      0|        debug_assert_eq!(hashes.len(), roots.len());
  280|      0|        let mut votes = Vec::new();
  281|      0|        self.wallets.foreach_representative(|keys| {
  282|      0|            let timestamp = if self.is_final {
  283|      0|                Vote::TIMESTAMP_MAX
  284|       |            } else {
  285|      0|                milliseconds_since_epoch()
  286|       |            };
  287|      0|            let duration = if self.is_final {
  288|      0|                Vote::DURATION_MAX
  289|       |            } else {
  290|      0|                0x9 /*8192ms*/
  291|       |            };
  292|      0|            votes.push(Arc::new(Vote::new(
  293|      0|                keys,
  294|      0|                timestamp,
  295|      0|                duration,
  296|      0|                hashes.clone(),
  297|      0|            )));
  298|      0|        });
  299|       |
  300|      0|        for vote in votes {
  301|       |            {
  302|      0|                let mut spacing = self.spacing.lock().unwrap();
  303|      0|                let now = self.clock.now();
  304|      0|                for i in 0..hashes.len() {
  305|      0|                    self.history.add(&roots[i], &hashes[i], &vote);
  306|      0|                    spacing.flag(&roots[i], &hashes[i], now);
  307|      0|                }
  308|       |            }
  309|      0|            action(vote);
  310|       |        }
  311|      0|    }
  312|       |
  313|      0|    fn reply(&self, request: (Vec<(Root, BlockHash)>, ChannelId)) {
  314|      0|        let mut i = request.0.iter().peekable();
  315|      0|        while i.peek().is_some() && !self.stopped.load(Ordering::SeqCst) {
  316|      0|            let mut hashes = Vec::with_capacity(VoteGenerator::MAX_HASHES);
  317|      0|            let mut roots = Vec::with_capacity(VoteGenerator::MAX_HASHES);
  318|      0|            {
  319|      0|                let spacing = self.spacing.lock().unwrap();
  320|      0|                while hashes.len() < VoteGenerator::MAX_HASHES {
  321|      0|                    let Some((root, hash)) = i.next() else {
  322|      0|                        break;
  323|       |                    };
  324|      0|                    if !roots.contains(root) {
  325|      0|                        if spacing.votable(root, hash, self.clock.now()) {
  326|      0|                            roots.push(*root);
  327|      0|                            hashes.push(*hash);
  328|      0|                        } else {
  329|      0|                            self.stats
  330|      0|                                .inc(StatType::VoteGenerator, DetailType::GeneratorSpacing);
  331|      0|                        }
  332|      0|                    }
  333|       |                }
  334|       |            }
  335|      0|            if !hashes.is_empty() {
  336|      0|                self.stats.add_dir(
  337|      0|                    StatType::Requests,
  338|      0|                    DetailType::RequestsGeneratedHashes,
  339|      0|                    Direction::In,
  340|      0|                    hashes.len() as u64,
  341|      0|                );
  342|      0|                self.vote(&hashes, &roots, |vote| {
  343|      0|                    let channel_id = &request.1;
  344|      0|                    let confirm =
  345|      0|                        Message::ConfirmAck(ConfirmAck::new_with_own_vote((*vote).clone()));
  346|      0|                    self.message_sender.lock().unwrap().try_send(
  347|      0|                        *channel_id,
  348|      0|                        &confirm,
  349|      0|                        TrafficType::Vote,
  350|      0|                    );
  351|      0|                    self.stats.inc_dir(
  352|      0|                        StatType::Requests,
  353|      0|                        DetailType::RequestsGeneratedVotes,
  354|      0|                        Direction::In,
  355|      0|                    );
  356|      0|                });
  357|      0|            }
  358|       |        }
  359|      0|        self.stats
  360|      0|            .inc(StatType::VoteGenerator, DetailType::GeneratorReplies);
  361|      0|    }
  362|       |
  363|      0|    fn process_batch(&self, batch: VecDeque<(Root, BlockHash)>) {
  364|      0|        let mut verified = VecDeque::new();
  365|      0|
  366|      0|        if self.is_final {
  367|      0|            let mut write_guard = self.ledger.write_queue.wait(Writer::VotingFinal);
  368|      0|            let mut tx = self.ledger.rw_txn();
  369|      0|            for (root, hash) in &batch {
  370|      0|                (write_guard, tx) = self.ledger.refresh_if_needed(write_guard, tx);
  371|      0|                if self.should_vote_final(&mut tx, root, hash) {
  372|      0|                    verified.push_back((*root, *hash));
  373|      0|                }
  374|       |            }
  375|       |        } else {
  376|      0|            let mut tx = self.ledger.read_txn();
  377|      0|            for (root, hash) in &batch {
  378|      0|                tx.refresh_if_needed();
  379|      0|                if self.should_vote_non_final(&tx, root, hash) {
  380|      0|                    verified.push_back((*root, *hash));
  381|      0|                }
  382|       |            }
  383|       |        };
  384|       |
  385|       |        // Submit verified candidates to the main processing thread
  386|      0|        if !verified.is_empty() {
  387|      0|            let should_notify = {
  388|      0|                let mut queues = self.queues.lock().unwrap();
  389|      0|                queues.candidates.extend(verified);
  390|      0|                queues.candidates.len() >= VoteGenerator::MAX_HASHES
  391|      0|            };
  392|      0|
  393|      0|            if should_notify {
  394|      0|                self.condition.notify_all();
  395|      0|            }
  396|      0|        }
  397|      0|    }
  398|       |
  399|      0|    fn should_vote_non_final(
  400|      0|        &self,
  401|      0|        txn: &LmdbReadTransaction,
  402|      0|        root: &Root,
  403|      0|        hash: &BlockHash,
  404|      0|    ) -> bool {
  405|      0|        let Some(block) = self.ledger.any().get_block(txn, hash) else {
  406|      0|            return false;
  407|       |        };
  408|      0|        debug_assert!(block.root() == *root);
  409|      0|        self.ledger.dependents_confirmed(txn, &block)
  410|      0|    }
  411|       |
  412|      0|    fn should_vote_final(
  413|      0|        &self,
  414|      0|        txn: &mut LmdbWriteTransaction,
  415|      0|        root: &Root,
  416|      0|        hash: &BlockHash,
  417|      0|    ) -> bool {
  418|      0|        let Some(block) = self.ledger.any().get_block(txn, hash) else {
  419|      0|            return false;
  420|       |        };
  421|      0|        debug_assert!(block.root() == *root);
  422|      0|        self.ledger.dependents_confirmed(txn, &block)
  423|      0|            && self
  424|      0|                .ledger
  425|      0|                .store
  426|      0|                .final_vote
  427|      0|                .put(txn, &block.qualified_root(), hash)
  428|      0|    }
  429|       |}
  430|       |
  431|       |struct Queues {
  432|       |    candidates: VecDeque<(Root, BlockHash)>,
  433|       |    requests: VecDeque<(Vec<(Root, BlockHash)>, ChannelId)>,
  434|       |    next_broadcast: Instant,
  435|       |}
  436|       |
  437|       |impl Queues {
  438|      6|    fn should_broadcast(&self) -> bool {
  439|      6|        if self.candidates.len() >= ConfirmAck::HASHES_MAX {
  440|      0|            return true;
  441|      6|        }
  442|      6|
  443|      6|        !self.candidates.is_empty() && Instant::now() >= self.next_broadcast
                                                     ^0
  444|      6|    }
  445|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/vote_generators.rs:
    1|       |use super::{vote_generator::VoteGenerator, LocalVoteHistory};
    2|       |use crate::{
    3|       |    config::NodeConfig, consensus::VoteBroadcaster, stats::Stats, transport::MessageSender,
    4|       |    wallets::Wallets, NetworkParams,
    5|       |};
    6|       |use rsnano_core::{utils::ContainerInfo, BlockHash, Root, SavedBlock};
    7|       |use rsnano_ledger::Ledger;
    8|       |use rsnano_network::ChannelId;
    9|       |use rsnano_nullable_clock::SteadyClock;
   10|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   11|       |use std::sync::Arc;
   12|       |
   13|       |#[derive(Clone)]
   14|       |pub struct VoteGenerationEvent {
   15|       |    pub channel_id: ChannelId,
   16|       |    pub blocks: Vec<SavedBlock>,
   17|       |    pub final_vote: bool,
   18|       |}
   19|       |
   20|       |pub struct VoteGenerators {
   21|       |    non_final_vote_generator: VoteGenerator,
   22|       |    final_vote_generator: VoteGenerator,
   23|       |    vote_listener: OutputListenerMt<VoteGenerationEvent>,
   24|       |}
   25|       |
   26|       |impl VoteGenerators {
   27|      3|    pub(crate) fn new(
   28|      3|        ledger: Arc<Ledger>,
   29|      3|        wallets: Arc<Wallets>,
   30|      3|        history: Arc<LocalVoteHistory>,
   31|      3|        stats: Arc<Stats>,
   32|      3|        config: &NodeConfig,
   33|      3|        network_params: &NetworkParams,
   34|      3|        vote_broadcaster: Arc<VoteBroadcaster>,
   35|      3|        message_sender: MessageSender,
   36|      3|        clock: Arc<SteadyClock>,
   37|      3|    ) -> Self {
   38|      3|        let non_final_vote_generator = VoteGenerator::new(
   39|      3|            ledger.clone(),
   40|      3|            wallets.clone(),
   41|      3|            history.clone(),
   42|      3|            false, //none-final
   43|      3|            stats.clone(),
   44|      3|            message_sender.clone(),
   45|      3|            network_params.voting.delay,
   46|      3|            config.vote_generator_delay,
   47|      3|            vote_broadcaster.clone(),
   48|      3|            clock.clone(),
   49|      3|        );
   50|      3|
   51|      3|        let final_vote_generator = VoteGenerator::new(
   52|      3|            ledger,
   53|      3|            wallets,
   54|      3|            history,
   55|      3|            true, //final
   56|      3|            stats,
   57|      3|            message_sender.clone(),
   58|      3|            network_params.voting.delay,
   59|      3|            config.vote_generator_delay,
   60|      3|            vote_broadcaster,
   61|      3|            clock,
   62|      3|        );
   63|      3|
   64|      3|        Self {
   65|      3|            non_final_vote_generator,
   66|      3|            final_vote_generator,
   67|      3|            vote_listener: OutputListenerMt::new(),
   68|      3|        }
   69|      3|    }
   70|       |
   71|      3|    pub fn start(&self) {
   72|      3|        self.non_final_vote_generator.start();
   73|      3|        self.final_vote_generator.start();
   74|      3|    }
   75|       |
   76|      3|    pub fn stop(&self) {
   77|      3|        self.non_final_vote_generator.stop();
   78|      3|        self.final_vote_generator.stop();
   79|      3|    }
   80|       |
   81|      0|    pub fn track(&self) -> Arc<OutputTrackerMt<VoteGenerationEvent>> {
   82|      0|        self.vote_listener.track()
   83|      0|    }
   84|       |
   85|      0|    pub(crate) fn generate_final_vote(&self, root: &Root, hash: &BlockHash) {
   86|      0|        self.final_vote_generator.add(root, hash);
   87|      0|    }
   88|       |
   89|      0|    pub(crate) fn generate_final_votes(
   90|      0|        &self,
   91|      0|        blocks: &[SavedBlock],
   92|      0|        channel_id: ChannelId,
   93|      0|    ) -> usize {
   94|      0|        if self.vote_listener.is_tracked() {
   95|      0|            self.vote_listener.emit(VoteGenerationEvent {
   96|      0|                channel_id,
   97|      0|                blocks: blocks.to_vec(),
   98|      0|                final_vote: true,
   99|      0|            });
  100|      0|        }
  101|      0|        self.final_vote_generator.generate(blocks, channel_id)
  102|      0|    }
  103|       |
  104|      0|    pub fn generate_non_final_vote(&self, root: &Root, hash: &BlockHash) {
  105|      0|        self.non_final_vote_generator.add(root, hash);
  106|      0|    }
  107|       |
  108|      0|    pub fn generate_non_final_votes(&self, blocks: &[SavedBlock], channel_id: ChannelId) -> usize {
  109|      0|        if self.vote_listener.is_tracked() {
  110|      0|            self.vote_listener.emit(VoteGenerationEvent {
  111|      0|                channel_id,
  112|      0|                blocks: blocks.to_vec(),
  113|      0|                final_vote: false,
  114|      0|            });
  115|      0|        }
  116|      0|        self.non_final_vote_generator.generate(blocks, channel_id)
  117|      0|    }
  118|       |
  119|      0|    pub(crate) fn container_info(&self) -> ContainerInfo {
  120|      0|        ContainerInfo::builder()
  121|      0|            .node("non_final", self.non_final_vote_generator.container_info())
  122|      0|            .node("final", self.final_vote_generator.container_info())
  123|      0|            .finish()
  124|      0|    }
  125|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_generation/vote_spacing.rs:
    1|       |use rsnano_core::{BlockHash, Root};
    2|       |use rsnano_nullable_clock::Timestamp;
    3|       |use std::{
    4|       |    collections::{BTreeMap, HashMap, HashSet},
    5|       |    time::Duration,
    6|       |};
    7|       |
    8|       |pub struct VoteSpacing {
    9|       |    delay: Duration,
   10|       |    recent: EntryContainer,
   11|       |}
   12|       |
   13|       |impl VoteSpacing {
   14|      9|    pub fn new(delay: Duration) -> Self {
   15|      9|        Self {
   16|      9|            recent: EntryContainer::new(),
   17|      9|            delay,
   18|      9|        }
   19|      9|    }
   20|       |
   21|      3|    pub fn votable(&self, root: &Root, hash: &BlockHash, now: Timestamp) -> bool {
   22|      3|        self.recent
   23|      3|            .by_root(root)
   24|      3|            .all(|item| *hash == item.hash || item.timestamp.elapsed(now) >= self.delay)
                                      ^2                    ^1                                      ^2
   25|      3|    }
   26|       |
   27|      4|    pub fn flag(&mut self, root: &Root, hash: &BlockHash, now: Timestamp) {
   28|      4|        self.trim(now);
   29|      4|        if !self.recent.change_time_for_root(root, now) {
   30|      4|            self.recent.insert(Entry {
   31|      4|                root: *root,
   32|      4|                hash: *hash,
   33|      4|                timestamp: now,
   34|      4|            });
   35|      4|        }
                       ^0
   36|      4|    }
   37|       |
   38|      5|    pub fn len(&self) -> usize {
   39|      5|        self.recent.len()
   40|      5|    }
   41|       |
   42|      0|    pub fn is_empty(&self) -> bool {
   43|      0|        self.recent.is_empty()
   44|      0|    }
   45|       |
   46|      4|    fn trim(&mut self, now: Timestamp) {
   47|      4|        self.recent.trim(now - self.delay);
   48|      4|    }
   49|       |}
   50|       |
   51|       |struct Entry {
   52|       |    root: Root,
   53|       |    hash: BlockHash,
   54|       |    timestamp: Timestamp,
   55|       |}
   56|       |
   57|       |#[derive(Default)]
   58|       |struct EntryContainer {
   59|       |    entries: HashMap<usize, Entry>,
   60|       |    by_root: HashMap<Root, HashSet<usize>>,
   61|       |    by_time: BTreeMap<Timestamp, Vec<usize>>,
   62|       |    next_id: usize,
   63|       |    empty_id_set: HashSet<usize>,
   64|       |}
   65|       |
   66|       |impl EntryContainer {
   67|     10|    pub fn new() -> Self {
   68|     10|        Default::default()
   69|     10|    }
   70|       |
   71|      5|    pub fn insert(&mut self, entry: Entry) {
   72|      5|        let id = self.create_id();
   73|      5|
   74|      5|        let by_root = self.by_root.entry(entry.root).or_default();
   75|      5|        by_root.insert(id);
   76|      5|
   77|      5|        let by_time = self.by_time.entry(entry.timestamp).or_default();
   78|      5|        by_time.push(id);
   79|      5|
   80|      5|        self.entries.insert(id, entry);
   81|      5|    }
   82|       |
   83|      5|    fn create_id(&mut self) -> usize {
   84|      5|        let id = self.next_id;
   85|      5|        self.next_id = self.next_id.wrapping_add(1);
   86|      5|        id
   87|      5|    }
   88|       |
   89|      3|    pub fn by_root(&self, root: &Root) -> impl Iterator<Item = &Entry> + '_ {
   90|      3|        match self.by_root.get(root) {
   91|      2|            Some(ids) => self.iter_entries(ids),
   92|      1|            None => self.iter_entries(&self.empty_id_set),
   93|       |        }
   94|      3|    }
   95|       |
   96|      3|    fn iter_entries<'a>(&'a self, ids: &'a HashSet<usize>) -> impl Iterator<Item = &'a Entry> + 'a {
   97|      3|        ids.iter().map(|&id| &self.entries[&id])
                                           ^2
   98|      3|    }
   99|       |
  100|      5|    fn trim(&mut self, cutoff: Timestamp) {
  101|      5|        let mut to_remove = Vec::new();
  102|      5|        for (&timestamp, ids) in self.by_time.iter() {
                            ^3
  103|      3|            if timestamp > cutoff {
  104|      1|                break;
  105|      2|            }
  106|      2|
  107|      2|            to_remove.push(timestamp);
  108|       |
  109|      4|            for id in ids {
                              ^2
  110|      2|                let entry = self.entries.remove(id).unwrap();
  111|      2|
  112|      2|                let by_root = self.by_root.get_mut(&entry.root).unwrap();
  113|      2|                by_root.remove(id);
  114|      2|                if by_root.is_empty() {
  115|      2|                    self.by_root.remove(&entry.root);
  116|      2|                }
                               ^0
  117|       |            }
  118|       |        }
  119|       |
  120|      7|        for timestamp in to_remove {
                          ^2
  121|      2|            self.by_time.remove(&timestamp);
  122|      2|        }
  123|      5|    }
  124|       |
  125|      4|    fn change_time_for_root(&mut self, root: &Root, time: Timestamp) -> bool {
  126|      4|        match self.by_root.get(root) {
  127|      0|            Some(ids) => {
  128|      0|                change_time_for_entries(ids, time, &mut self.entries, &mut self.by_time);
  129|      0|                true
  130|       |            }
  131|      4|            None => false,
  132|       |        }
  133|      4|    }
  134|       |
  135|      6|    fn len(&self) -> usize {
  136|      6|        self.entries.len()
  137|      6|    }
  138|       |
  139|      0|    fn is_empty(&self) -> bool {
  140|      0|        self.entries.is_empty()
  141|      0|    }
  142|       |}
  143|       |
  144|      0|fn change_time_for_entries(
  145|      0|    ids: &HashSet<usize>,
  146|      0|    time: Timestamp,
  147|      0|    entries: &mut HashMap<usize, Entry>,
  148|      0|    by_time: &mut BTreeMap<Timestamp, Vec<usize>>,
  149|      0|) {
  150|      0|    for id in ids {
  151|      0|        change_time_for_entry(id, time, entries, by_time);
  152|      0|    }
  153|      0|}
  154|       |
  155|      0|fn change_time_for_entry(
  156|      0|    id: &usize,
  157|      0|    time: Timestamp,
  158|      0|    entries: &mut HashMap<usize, Entry>,
  159|      0|    by_time: &mut BTreeMap<Timestamp, Vec<usize>>,
  160|      0|) {
  161|      0|    if let Some(entry) = entries.get_mut(id) {
  162|      0|        let old_time = entry.timestamp;
  163|      0|        entry.timestamp = time;
  164|      0|        remove_from_time_index(old_time, id, by_time);
  165|      0|        by_time.entry(time).or_default().push(*id);
  166|      0|    }
  167|      0|}
  168|       |
  169|      0|fn remove_from_time_index(
  170|      0|    time: Timestamp,
  171|      0|    id: &usize,
  172|      0|    ids_by_time: &mut BTreeMap<Timestamp, Vec<usize>>,
  173|      0|) {
  174|      0|    if let Some(ids) = ids_by_time.get_mut(&time) {
  175|      0|        if ids.len() == 1 {
  176|      0|            ids_by_time.remove(&time);
  177|      0|        } else {
  178|      0|            ids.retain(|x| x != id);
  179|      0|        }
  180|      0|    }
  181|      0|}
  182|       |
  183|       |#[cfg(test)]
  184|       |mod tests {
  185|       |    use super::*;
  186|       |
  187|       |    #[test]
  188|      1|    fn empty() {
  189|      1|        let now = Timestamp::new_test_instance();
  190|      1|        let spacing = VoteSpacing::new(Duration::from_millis(100));
  191|      1|        assert_eq!(spacing.len(), 0);
  192|      1|        assert!(spacing.votable(&Root::from(1), &BlockHash::from(2), now));
  193|      1|    }
  194|       |
  195|       |    #[test]
  196|      1|    fn flag() {
  197|      1|        let now = Timestamp::new_test_instance();
  198|      1|        let mut spacing = VoteSpacing::new(Duration::from_millis(100));
  199|      1|        let root1 = Root::from(1);
  200|      1|        let root2 = Root::from(2);
  201|      1|        let hash1 = BlockHash::from(3);
  202|      1|        let hash2 = BlockHash::from(4);
  203|      1|        let hash3 = BlockHash::from(5);
  204|      1|
  205|      1|        spacing.flag(&root1, &hash1, now);
  206|      1|        assert_eq!(spacing.len(), 1);
  207|      1|        assert!(spacing.votable(&root1, &hash1, now));
  208|      1|        assert!(!spacing.votable(&root1, &hash2, now));
  209|       |
  210|      1|        spacing.flag(&root2, &hash3, now);
  211|      1|        assert_eq!(spacing.len(), 2);
  212|      1|    }
  213|       |
  214|       |    #[test]
  215|      1|    fn prune() {
  216|      1|        let length = Duration::from_millis(100);
  217|      1|        let now = Timestamp::new_test_instance();
  218|      1|        let mut spacing = VoteSpacing::new(length);
  219|      1|        spacing.flag(&Root::from(1), &BlockHash::from(3), now);
  220|      1|        assert_eq!(spacing.len(), 1);
  221|       |
  222|      1|        spacing.flag(&Root::from(2), &BlockHash::from(4), now + length);
  223|      1|        assert_eq!(spacing.len(), 1);
  224|      1|    }
  225|       |
  226|       |    mod entry_container_tests {
  227|       |        use super::*;
  228|       |
  229|       |        #[test]
  230|      1|        fn trim() {
  231|      1|            let mut container = EntryContainer::new();
  232|      1|            let now = Timestamp::new_test_instance();
  233|      1|            container.insert(Entry {
  234|      1|                root: Root::from(1),
  235|      1|                hash: BlockHash::from(2),
  236|      1|                timestamp: now,
  237|      1|            });
  238|      1|            container.trim(now + Duration::from_secs(5));
  239|      1|            assert_eq!(container.len(), 0);
  240|      1|            assert_eq!(container.by_time.len(), 0);
  241|      1|            assert_eq!(container.entries.len(), 0);
  242|      1|            assert_eq!(container.by_root.len(), 0);
  243|      1|        }
  244|       |    }
  245|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_processor.rs:
    1|       |use super::{VoteProcessorQueue, VoteRouter};
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::{Vote, VoteCode, VoteSource};
    4|       |use rsnano_network::ChannelId;
    5|       |use std::{
    6|       |    cmp::{max, min},
    7|       |    sync::{
    8|       |        atomic::{AtomicU64, Ordering},
    9|       |        Arc, Mutex,
   10|       |    },
   11|       |    thread::JoinHandle,
   12|       |    time::Instant,
   13|       |};
   14|       |use tracing::{debug, trace};
   15|       |
   16|       |#[derive(Clone, Debug, PartialEq)]
   17|       |pub struct VoteProcessorConfig {
   18|       |    pub max_pr_queue: usize,
   19|       |    pub max_non_pr_queue: usize,
   20|       |    pub pr_priority: usize,
   21|       |    pub threads: usize,
   22|       |    pub batch_size: usize,
   23|       |    pub max_triggered: usize,
   24|       |}
   25|       |
   26|       |impl VoteProcessorConfig {
   27|      9|    pub fn new(parallelism: usize) -> Self {
   28|      9|        Self {
   29|      9|            max_pr_queue: 256,
   30|      9|            max_non_pr_queue: 32,
   31|      9|            pr_priority: 3,
   32|      9|            threads: max(1, min(4, parallelism / 2)),
   33|      9|            batch_size: 1024,
   34|      9|            max_triggered: 16384,
   35|      9|        }
   36|      9|    }
   37|       |}
   38|       |
   39|       |pub type VoteProcessedCallback2 =
   40|       |    Box<dyn Fn(&Arc<Vote>, ChannelId, VoteSource, VoteCode) + Send + Sync>;
   41|       |
   42|       |pub struct VoteProcessor {
   43|       |    threads: Mutex<Vec<JoinHandle<()>>>,
   44|       |    queue: Arc<VoteProcessorQueue>,
   45|       |    vote_router: Arc<VoteRouter>,
   46|       |    stats: Arc<Stats>,
   47|       |    vote_processed: Mutex<Vec<VoteProcessedCallback2>>,
   48|       |    pub total_processed: AtomicU64,
   49|       |}
   50|       |
   51|       |impl VoteProcessor {
   52|      3|    pub fn new(
   53|      3|        queue: Arc<VoteProcessorQueue>,
   54|      3|        vote_router: Arc<VoteRouter>,
   55|      3|        stats: Arc<Stats>,
   56|      3|        on_vote: VoteProcessedCallback2,
   57|      3|    ) -> Self {
   58|      3|        Self {
   59|      3|            queue,
   60|      3|            vote_router,
   61|      3|            stats,
   62|      3|            vote_processed: Mutex::new(vec![on_vote]),
   63|      3|            threads: Mutex::new(Vec::new()),
   64|      3|            total_processed: AtomicU64::new(0),
   65|      3|        }
   66|      3|    }
   67|       |
   68|      3|    pub fn stop(&self) {
   69|      3|        self.queue.stop();
   70|      3|
   71|      3|        let mut handles = Vec::new();
   72|      3|        {
   73|      3|            let mut guard = self.threads.lock().unwrap();
   74|      3|            std::mem::swap(&mut handles, &mut guard);
   75|      3|        }
   76|      6|        for handle in handles {
                          ^3
   77|      3|            handle.join().unwrap()
   78|       |        }
   79|      3|    }
   80|       |
   81|      3|    pub fn run(&self) {
   82|       |        loop {
   83|      3|            self.stats.inc(StatType::VoteProcessor, DetailType::Loop);
   84|      3|
   85|      3|            let batch = self.queue.wait_for_votes(self.queue.config.batch_size);
   86|      3|            if batch.is_empty() {
   87|      3|                break; //stopped
   88|      0|            }
   89|      0|
   90|      0|            let start = Instant::now();
   91|       |
   92|      0|            for ((_, channel_id), (vote, source)) in &batch {
   93|      0|                self.vote_blocking(vote, *channel_id, *source);
   94|      0|            }
   95|       |
   96|      0|            self.total_processed
   97|      0|                .fetch_add(batch.len() as u64, Ordering::SeqCst);
   98|      0|
   99|      0|            let elapsed_millis = start.elapsed().as_millis();
  100|      0|            if batch.len() == self.queue.config.batch_size && elapsed_millis > 100 {
  101|      0|                debug!(
  102|      0|                    "Processed {} votes in {} milliseconds (rate of {} votes per second)",
  103|      0|                    batch.len(),
  104|      0|                    elapsed_millis,
  105|      0|                    (batch.len() * 1000) / elapsed_millis as usize
  106|       |                );
  107|      0|            }
  108|       |        }
  109|      3|    }
  110|       |
  111|      0|    pub fn vote_blocking(
  112|      0|        &self,
  113|      0|        vote: &Arc<Vote>,
  114|      0|        channel_id: ChannelId,
  115|      0|        source: VoteSource,
  116|      0|    ) -> VoteCode {
  117|      0|        let mut result = VoteCode::Invalid;
  118|      0|        if vote.validate().is_ok() {
  119|      0|            let vote_results = self.vote_router.vote(vote, source);
  120|      0|
  121|      0|            // Aggregate results for individual hashes
  122|      0|            let mut replay = false;
  123|      0|            let mut processed = false;
  124|      0|            for (_, hash_result) in vote_results {
  125|      0|                replay |= hash_result == VoteCode::Replay;
  126|      0|                processed |= hash_result == VoteCode::Vote;
  127|      0|            }
  128|      0|            result = if replay {
  129|      0|                VoteCode::Replay
  130|      0|            } else if processed {
  131|      0|                VoteCode::Vote
  132|       |            } else {
  133|      0|                VoteCode::Indeterminate
  134|       |            };
  135|       |
  136|      0|            let callbacks = self.vote_processed.lock().unwrap();
  137|      0|            for callback in callbacks.iter() {
  138|      0|                (callback)(vote, channel_id, source, result);
  139|      0|            }
  140|      0|        }
  141|       |
  142|      0|        self.stats.inc(StatType::Vote, DetailType::VoteProcessed);
  143|      0|        trace!(?vote, ?result, ?source, "vote processed");
  144|       |
  145|      0|        result
  146|      0|    }
  147|       |
  148|      3|    pub fn on_vote_processed(
  149|      3|        &self,
  150|      3|        callback: Box<dyn Fn(&Arc<Vote>, ChannelId, VoteSource, VoteCode) + Send + Sync>,
  151|      3|    ) {
  152|      3|        self.vote_processed.lock().unwrap().push(callback);
  153|      3|    }
  154|       |}
  155|       |
  156|       |impl Drop for VoteProcessor {
  157|      3|    fn drop(&mut self) {
  158|      3|        // Thread must be stopped before destruction
  159|      3|        debug_assert!(self.threads.lock().unwrap().is_empty());
  160|      3|    }
  161|       |}
  162|       |
  163|       |pub trait VoteProcessorExt {
  164|       |    fn start(&self);
  165|       |}
  166|       |
  167|       |impl VoteProcessorExt for Arc<VoteProcessor> {
  168|      3|    fn start(&self) {
  169|      3|        let mut threads = self.threads.lock().unwrap();
  170|      3|        debug_assert!(threads.is_empty());
  171|      3|        for _ in 0..self.queue.config.threads {
  172|      3|            let self_l = Arc::clone(self);
  173|      3|            threads.push(
  174|      3|                std::thread::Builder::new()
  175|      3|                    .name("Vote processing".to_string())
  176|      3|                    .spawn(Box::new(move || {
  177|      3|                        self_l.run();
  178|      3|                    }))
  179|      3|                    .unwrap(),
  180|      3|            )
  181|       |        }
  182|      3|    }
  183|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_processor_queue.rs:
    1|       |use super::{RepTier, RepTiers, VoteProcessorConfig};
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::{
    4|       |    utils::{ContainerInfo, FairQueue, FairQueueInfo},
    5|       |    Vote, VoteSource,
    6|       |};
    7|       |use rsnano_network::{ChannelId, DeadChannelCleanupStep};
    8|       |use std::{
    9|       |    collections::VecDeque,
   10|       |    mem::size_of,
   11|       |    sync::{Arc, Condvar, Mutex},
   12|       |};
   13|       |use strum::IntoEnumIterator;
   14|       |
   15|       |pub struct VoteProcessorQueue {
   16|       |    data: Mutex<VoteProcessorQueueData>,
   17|       |    condition: Condvar,
   18|       |    pub config: VoteProcessorConfig,
   19|       |    stats: Arc<Stats>,
   20|       |    rep_tiers: Arc<RepTiers>,
   21|       |}
   22|       |
   23|       |impl VoteProcessorQueue {
   24|      3|    pub fn new(config: VoteProcessorConfig, stats: Arc<Stats>, rep_tiers: Arc<RepTiers>) -> Self {
   25|      3|        let conf = config.clone();
   26|      3|        Self {
   27|      3|            data: Mutex::new(VoteProcessorQueueData {
   28|      3|                stopped: false,
   29|      3|                queue: FairQueue::new(
   30|      3|                    move |(tier, _)| match tier {
                                                   ^0
   31|      0|                        RepTier::Tier1 | RepTier::Tier2 | RepTier::Tier3 => conf.max_pr_queue,
   32|      0|                        RepTier::None => conf.max_non_pr_queue,
   33|      3|                    },
                                  ^0
   34|      3|                    move |(tier, _)| match tier {
                                                   ^0
   35|      0|                        RepTier::Tier3 => conf.pr_priority * conf.pr_priority * conf.pr_priority,
   36|      0|                        RepTier::Tier2 => conf.pr_priority * conf.pr_priority,
   37|      0|                        RepTier::Tier1 => conf.pr_priority,
   38|      0|                        RepTier::None => 1,
   39|      3|                    },
                                  ^0
   40|      3|                ),
   41|      3|            }),
   42|      3|            condition: Condvar::new(),
   43|      3|            config,
   44|      3|            stats,
   45|      3|            rep_tiers,
   46|      3|        }
   47|      3|    }
   48|       |
   49|      0|    pub fn len(&self) -> usize {
   50|      0|        self.data.lock().unwrap().queue.len()
   51|      0|    }
   52|       |
   53|      0|    pub fn is_empty(&self) -> bool {
   54|      0|        self.data.lock().unwrap().queue.is_empty()
   55|      0|    }
   56|       |
   57|       |    /// Queue vote for processing. @returns true if the vote was queued
   58|      0|    pub fn vote(&self, vote: Arc<Vote>, channel_id: ChannelId, source: VoteSource) -> bool {
   59|      0|        let tier = self.rep_tiers.tier(&vote.voting_account);
   60|      0|
   61|      0|        let added = {
   62|      0|            let mut guard = self.data.lock().unwrap();
   63|      0|            guard.queue.push((tier, channel_id), (vote, source))
   64|      0|        };
   65|      0|
   66|      0|        if added {
   67|      0|            self.stats.inc(StatType::VoteProcessor, DetailType::Process);
   68|      0|            self.stats.inc(StatType::VoteProcessorTier, tier.into());
   69|      0|            self.condition.notify_one();
   70|      0|        } else {
   71|      0|            self.stats
   72|      0|                .inc(StatType::VoteProcessor, DetailType::Overfill);
   73|      0|            self.stats.inc(StatType::VoteProcessorOverfill, tier.into());
   74|      0|        }
   75|       |
   76|      0|        added
   77|      0|    }
   78|       |
   79|      3|    pub(crate) fn wait_for_votes(
   80|      3|        &self,
   81|      3|        max_batch_size: usize,
   82|      3|    ) -> VecDeque<((RepTier, ChannelId), (Arc<Vote>, VoteSource))> {
   83|      3|        let mut guard = self.data.lock().unwrap();
   84|       |        loop {
   85|      6|            if guard.stopped {
   86|      3|                return VecDeque::new();
   87|      3|            }
   88|      3|
   89|      3|            if !guard.queue.is_empty() {
   90|      0|                return guard.queue.next_batch(max_batch_size);
   91|      3|            } else {
   92|      3|                guard = self.condition.wait(guard).unwrap();
   93|      3|            }
   94|       |        }
   95|      3|    }
   96|       |
   97|      0|    pub fn clear(&self) {
   98|      0|        {
   99|      0|            let mut guard = self.data.lock().unwrap();
  100|      0|            guard.queue.clear();
  101|      0|        }
  102|      0|        self.condition.notify_all();
  103|      0|    }
  104|       |
  105|      3|    pub fn stop(&self) {
  106|      3|        {
  107|      3|            let mut guard = self.data.lock().unwrap();
  108|      3|            guard.stopped = true;
  109|      3|        }
  110|      3|        self.condition.notify_all();
  111|      3|    }
  112|       |
  113|      0|    pub fn info(&self) -> FairQueueInfo<RepTier> {
  114|      0|        self.data
  115|      0|            .lock()
  116|      0|            .unwrap()
  117|      0|            .queue
  118|      0|            .compacted_info(|(tier, _)| *tier)
  119|      0|    }
  120|       |
  121|      0|    pub fn container_info(&self) -> ContainerInfo {
  122|      0|        let guard = self.data.lock().unwrap();
  123|      0|        ContainerInfo::builder()
  124|      0|            .leaf(
  125|      0|                "votes",
  126|      0|                guard.queue.len(),
  127|      0|                size_of::<(Arc<Vote>, VoteSource)>(),
  128|      0|            )
  129|      0|            .node("queue", guard.queue.container_info())
  130|      0|            .finish()
  131|      0|    }
  132|       |}
  133|       |
  134|       |pub struct VoteProcessorQueueCleanup(Arc<VoteProcessorQueue>);
  135|       |
  136|       |impl VoteProcessorQueueCleanup {
  137|      3|    pub fn new(queue: Arc<VoteProcessorQueue>) -> Self {
  138|      3|        Self(queue)
  139|      3|    }
  140|       |}
  141|       |
  142|       |impl DeadChannelCleanupStep for VoteProcessorQueueCleanup {
  143|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  144|      0|        let mut guard = self.0.data.lock().unwrap();
  145|      0|        for channel_id in dead_channel_ids {
  146|      0|            for tier in RepTier::iter() {
  147|      0|                guard.queue.remove(&(tier, *channel_id));
  148|      0|            }
  149|       |        }
  150|      0|    }
  151|       |}
  152|       |
  153|       |struct VoteProcessorQueueData {
  154|       |    stopped: bool,
  155|       |    queue: FairQueue<(RepTier, ChannelId), (Arc<Vote>, VoteSource)>,
  156|       |}

/home/gustav/code/nano/rsnano-node/node/src/consensus/vote_router.rs:
    1|       |use super::{Election, RecentlyConfirmedCache, VoteApplier, VoteCache};
    2|       |use crate::consensus::VoteApplierExt;
    3|       |use rsnano_core::{utils::ContainerInfo, BlockHash, Vote, VoteCode, VoteSource};
    4|       |use rsnano_ledger::RepWeightCache;
    5|       |use std::{
    6|       |    collections::HashMap,
    7|       |    mem::size_of,
    8|       |    sync::{Arc, Condvar, Mutex, Weak},
    9|       |    thread::JoinHandle,
   10|       |    time::Duration,
   11|       |};
   12|       |
   13|       |/// This class routes votes to their associated election
   14|       |/// This class holds a weak_ptr as this container does not own the elections
   15|       |/// Routing entries are removed periodically if the weak_ptr has expired
   16|       |pub struct VoteRouter {
   17|       |    thread: Mutex<Option<JoinHandle<()>>>,
   18|       |    shared: Arc<(Condvar, Mutex<State>)>,
   19|       |    vote_processed_observers: Mutex<Vec<VoteProcessedCallback>>,
   20|       |    recently_confirmed: Arc<RecentlyConfirmedCache>,
   21|       |    vote_applier: Arc<VoteApplier>,
   22|       |    vote_cache: Arc<Mutex<VoteCache>>,
   23|       |    rep_weights: Arc<RepWeightCache>,
   24|       |}
   25|       |
   26|       |impl VoteRouter {
   27|      3|    pub fn new(
   28|      3|        vote_cache: Arc<Mutex<VoteCache>>,
   29|      3|        recently_confirmed: Arc<RecentlyConfirmedCache>,
   30|      3|        vote_applier: Arc<VoteApplier>,
   31|      3|        rep_weights: Arc<RepWeightCache>,
   32|      3|    ) -> Self {
   33|      3|        Self {
   34|      3|            thread: Mutex::new(None),
   35|      3|            shared: Arc::new((
   36|      3|                Condvar::new(),
   37|      3|                Mutex::new(State {
   38|      3|                    stopped: false,
   39|      3|                    elections: HashMap::new(),
   40|      3|                }),
   41|      3|            )),
   42|      3|            vote_processed_observers: Mutex::new(Vec::new()),
   43|      3|            recently_confirmed,
   44|      3|            vote_applier,
   45|      3|            vote_cache,
   46|      3|            rep_weights,
   47|      3|        }
   48|      3|    }
   49|       |
   50|      3|    pub fn start(&self) {
   51|      3|        let shared = self.shared.clone();
   52|      3|        *self.thread.lock().unwrap() = Some(
   53|      3|            std::thread::Builder::new()
   54|      3|                .name("Voute router".to_owned())
   55|      3|                .spawn(move || {
   56|      3|                    let (condition, state) = &*shared;
   57|      3|                    let mut guard = state.lock().unwrap();
   58|      6|                    while !guard.stopped {
   59|      3|                        guard.clean_up();
   60|      3|                        guard = condition
   61|      6|                            .wait_timeout_while(guard, Duration::from_secs(15), |g| !g.stopped)
   62|      3|                            .unwrap()
   63|      3|                            .0;
   64|       |                    }
   65|      3|                })
   66|      3|                .unwrap(),
   67|      3|        )
   68|      3|    }
   69|       |
   70|      3|    pub fn stop(&self) {
   71|      3|        self.shared.1.lock().unwrap().stopped = true;
   72|      3|        self.shared.0.notify_all();
   73|      3|        let thread = self.thread.lock().unwrap().take();
   74|      3|        if let Some(thread) = thread {
   75|      3|            thread.join().unwrap();
   76|      3|        }
                       ^0
   77|      3|    }
   78|       |
   79|      3|    pub fn on_vote_processed(&self, observer: VoteProcessedCallback) {
   80|      3|        self.vote_processed_observers.lock().unwrap().push(observer);
   81|      3|    }
   82|       |    /// This is meant to be a fast check and may return false positives
   83|       |    /// if weak pointers have expired, but we don't care about that here
   84|      0|    pub fn contains(&self, hash: &BlockHash) -> bool {
   85|      0|        self.shared.1.lock().unwrap().elections.contains_key(hash)
   86|      0|    }
   87|       |
   88|       |    /// Add a route for 'hash' to 'election'
   89|       |    /// Existing routes will be replaced
   90|       |    /// Election must hold the block for the hash being passed in
   91|      0|    pub fn connect(&self, hash: BlockHash, election: Weak<Election>) {
   92|      0|        self.shared
   93|      0|            .1
   94|      0|            .lock()
   95|      0|            .unwrap()
   96|      0|            .elections
   97|      0|            .insert(hash, election);
   98|      0|    }
   99|       |
  100|       |    /// Remove all routes to this election
  101|      0|    pub fn disconnect_election(&self, election: &Election) {
  102|      0|        let mut state = self.shared.1.lock().unwrap();
  103|      0|        let election_guard = election.mutex.lock().unwrap();
  104|      0|        for hash in election_guard.last_blocks.keys() {
  105|      0|            state.elections.remove(hash);
  106|      0|        }
  107|      0|    }
  108|       |
  109|       |    /// Remove all routes to this election
  110|      0|    pub fn disconnect(&self, hash: &BlockHash) {
  111|      0|        let mut state = self.shared.1.lock().unwrap();
  112|      0|        state.elections.remove(hash);
  113|      0|    }
  114|       |
  115|      0|    pub fn election(&self, hash: &BlockHash) -> Option<Arc<Election>> {
  116|      0|        let state = self.shared.1.lock().unwrap();
  117|      0|        state.elections.get(hash)?.upgrade()
  118|      0|    }
  119|       |
  120|       |    /// Route vote to associated elections
  121|       |    /// Distinguishes replay votes, cannot be determined if the block is not in any election
  122|       |    /// If 'filter' parameter is non-zero, only elections for the specified hash are notified.
  123|       |    /// This eliminates duplicate processing when triggering votes from the vote_cache as the result of a specific election being created.
  124|      0|    pub fn vote_filter(
  125|      0|        &self,
  126|      0|        vote: &Arc<Vote>,
  127|      0|        source: VoteSource,
  128|      0|        filter: &BlockHash,
  129|      0|    ) -> HashMap<BlockHash, VoteCode> {
  130|      0|        debug_assert!(vote.validate().is_ok());
  131|       |        // If present, filter should be set to one of the hashes in the vote
  132|      0|        debug_assert!(filter.is_zero() || vote.hashes.iter().any(|h| h == filter));
  133|       |
  134|      0|        let mut results = HashMap::new();
  135|      0|        let mut process = HashMap::new();
  136|      0|        {
  137|      0|            let guard = self.shared.1.lock().unwrap();
  138|      0|            for hash in &vote.hashes {
  139|       |                // Ignore votes for other hashes if a filter is set
  140|      0|                if !filter.is_zero() && hash != filter {
  141|      0|                    continue;
  142|      0|                }
  143|      0|
  144|      0|                // Ignore duplicate hashes (should not happen with a well-behaved voting node)
  145|      0|                if results.contains_key(hash) {
  146|      0|                    continue;
  147|      0|                }
  148|      0|
  149|      0|                let election = guard.elections.get(hash).and_then(|e| e.upgrade());
  150|      0|                if let Some(election) = election {
  151|      0|                    process.insert(*hash, election.clone());
  152|      0|                } else {
  153|      0|                    if !self.recently_confirmed.hash_exists(hash) {
  154|      0|                        results.insert(*hash, VoteCode::Indeterminate);
  155|      0|                    } else {
  156|      0|                        results.insert(*hash, VoteCode::Replay);
  157|      0|                    }
  158|       |                }
  159|       |            }
  160|       |        }
  161|       |
  162|      0|        for (block_hash, election) in process {
  163|      0|            let vote_result = self.vote_applier.vote(
  164|      0|                &election,
  165|      0|                &vote.voting_account,
  166|      0|                vote.timestamp(),
  167|      0|                &block_hash,
  168|      0|                source,
  169|      0|            );
  170|      0|            results.insert(block_hash, vote_result);
  171|      0|        }
  172|       |
  173|       |        // Cache the votes that didn't match any election
  174|      0|        if source != VoteSource::Cache {
  175|      0|            let rep_weight = self.rep_weights.weight(&vote.voting_account);
  176|      0|            self.vote_cache
  177|      0|                .lock()
  178|      0|                .unwrap()
  179|      0|                .insert(vote, rep_weight, &results);
  180|      0|        }
  181|       |
  182|      0|        self.notify_vote_processed(vote, source, &results);
  183|      0|
  184|      0|        results
  185|      0|    }
  186|       |
  187|       |    /// Route vote to associated elections
  188|       |    /// Distinguishes replay votes, cannot be determined if the block is not in any election
  189|      0|    pub fn vote(&self, vote: &Arc<Vote>, source: VoteSource) -> HashMap<BlockHash, VoteCode> {
  190|      0|        self.vote_filter(vote, source, &BlockHash::zero())
  191|      0|    }
  192|       |
  193|      0|    pub fn active(&self, hash: &BlockHash) -> bool {
  194|      0|        let state = self.shared.1.lock().unwrap();
  195|      0|        if let Some(existing) = state.elections.get(hash) {
  196|      0|            existing.strong_count() > 0
  197|       |        } else {
  198|      0|            false
  199|       |        }
  200|      0|    }
  201|       |
  202|      0|    fn notify_vote_processed(
  203|      0|        &self,
  204|      0|        vote: &Arc<Vote>,
  205|      0|        source: VoteSource,
  206|      0|        results: &HashMap<BlockHash, VoteCode>,
  207|      0|    ) {
  208|      0|        let observers = self.vote_processed_observers.lock().unwrap();
  209|      0|        for o in observers.iter() {
  210|      0|            o(vote, source, results);
  211|      0|        }
  212|      0|    }
  213|       |
  214|      0|    pub fn container_info(&self) -> ContainerInfo {
  215|      0|        let guard = self.shared.1.lock().unwrap();
  216|      0|        [(
  217|      0|            "elections",
  218|      0|            guard.elections.len(),
  219|      0|            size_of::<BlockHash>() + size_of::<Weak<Election>>(),
  220|      0|        )]
  221|      0|        .into()
  222|      0|    }
  223|       |}
  224|       |
  225|       |impl Drop for VoteRouter {
  226|      3|    fn drop(&mut self) {
  227|      3|        // Thread must be stopped before destruction
  228|      3|        debug_assert!(self.thread.lock().unwrap().is_none())
  229|      3|    }
  230|       |}
  231|       |
  232|       |struct State {
  233|       |    stopped: bool,
  234|       |    // Mapping of block hashes to elections.
  235|       |    // Election already contains the associated block
  236|       |    elections: HashMap<BlockHash, Weak<Election>>,
  237|       |}
  238|       |
  239|       |impl State {
  240|      3|    fn clean_up(&mut self) {
  241|      3|        self.elections
  242|      3|            .retain(|_, election| election.strong_count() > 0);
                                                ^0
  243|      3|    }
  244|       |}
  245|       |
  246|       |pub type VoteProcessedCallback =
  247|       |    Box<dyn Fn(&Arc<Vote>, VoteSource, &HashMap<BlockHash, VoteCode>) + Send + Sync>;

/home/gustav/code/nano/rsnano-node/node/src/http_callbacks.rs:
    1|       |use crate::{
    2|       |    consensus::{ElectionStatus, ElectionStatusType},
    3|       |    stats::{DetailType, Direction, StatType, Stats},
    4|       |};
    5|       |use rsnano_core::{Account, Amount, BlockType, SavedBlock};
    6|       |use rsnano_nullable_http_client::{HttpClient, Url};
    7|       |use serde::Serialize;
    8|       |use std::sync::Arc;
    9|       |use tracing::error;
   10|       |
   11|       |/// Performs an HTTP callback to a configured endpoint
   12|       |/// if a block is confirmed
   13|       |pub(crate) struct HttpCallbacks {
   14|       |    pub runtime: tokio::runtime::Handle,
   15|       |    pub stats: Arc<Stats>,
   16|       |    pub callback_url: Url,
   17|       |}
   18|       |
   19|       |impl HttpCallbacks {
   20|      0|    pub fn execute(
   21|      0|        &self,
   22|      0|        status: &ElectionStatus,
   23|      0|        account: Account,
   24|      0|        block: &SavedBlock,
   25|      0|        amount: Amount,
   26|      0|        is_state_send: bool,
   27|      0|        is_state_epoch: bool,
   28|      0|    ) {
   29|      0|        let block = block.clone();
   30|      0|        if status.election_status_type == ElectionStatusType::ActiveConfirmedQuorum
   31|      0|            || status.election_status_type == ElectionStatusType::ActiveConfirmationHeight
   32|      0|        {
   33|      0|            let url = self.callback_url.clone();
   34|      0|            let stats = self.stats.clone();
   35|      0|
   36|      0|            // TODO use a mpsc queue and a single async task for processing the queue
   37|      0|            // to avoid overload and out of order delivery
   38|      0|            // TODO warn if backlog is large (see nano_node)
   39|      0|            self.runtime.spawn(async move {
   40|      0|                let message = RpcCallbackMessage {
   41|      0|                    account: account.encode_account(),
   42|      0|                    hash: block.hash().encode_hex(),
   43|      0|                    block: (*block).clone().into(),
   44|      0|                    amount: amount.to_string_dec(),
   45|      0|                    sub_type: if is_state_send {
   46|      0|                        Some("send")
   47|      0|                    } else if block.block_type() == BlockType::State {
   48|      0|                        if block.is_change() {
   49|      0|                            Some("change")
   50|      0|                        } else if is_state_epoch {
   51|      0|                            Some("epoch")
   52|       |                        } else {
   53|      0|                            Some("receive")
   54|       |                        }
   55|       |                    } else {
   56|      0|                        None
   57|       |                    },
   58|      0|                    is_send: if is_state_send { Some("true") } else { None },
   59|       |                };
   60|       |
   61|      0|                let http_client = HttpClient::new();
   62|      0|                match http_client.post_json(url.clone(), &message).await {
   63|      0|                    Ok(response) => {
   64|      0|                        if response.status().is_success() {
   65|      0|                            stats.inc_dir(
   66|      0|                                StatType::HttpCallbacks,
   67|      0|                                DetailType::Initiate,
   68|      0|                                Direction::Out,
   69|      0|                            );
   70|      0|                        } else {
   71|      0|                            error!(
   72|      0|                                "Callback to {} failed [status: {:?}]",
   73|      0|                                url,
   74|      0|                                response.status()
   75|       |                            );
   76|      0|                            stats.inc_dir(
   77|      0|                                StatType::Error,
   78|      0|                                DetailType::HttpCallback,
   79|      0|                                Direction::Out,
   80|      0|                            );
   81|       |                        }
   82|       |                    }
   83|      0|                    Err(e) => {
   84|      0|                        error!("Unable to send callback: {} ({})", url, e);
   85|      0|                        stats.inc_dir(StatType::Error, DetailType::HttpCallback, Direction::Out);
   86|       |                    }
   87|       |                }
   88|      0|            });
   89|      0|        }
   90|      0|    }
   91|       |}
   92|       |
   93|       |#[derive(Serialize)]
   94|       |struct RpcCallbackMessage {
   95|       |    account: String,
   96|       |    hash: String,
   97|       |    block: serde_json::Value,
   98|       |    amount: String,
   99|       |    #[serde(skip_serializing_if = "Option::is_none")]
  100|       |    sub_type: Option<&'static str>,
  101|       |    #[serde(skip_serializing_if = "Option::is_none")]
  102|       |    is_send: Option<&'static str>,
  103|       |}

/home/gustav/code/nano/rsnano-node/node/src/monitor.rs:
    1|       |use crate::{
    2|       |    consensus::ActiveElections,
    3|       |    representatives::OnlineReps,
    4|       |    utils::{CancellationToken, Runnable},
    5|       |};
    6|       |use rsnano_ledger::Ledger;
    7|       |use rsnano_network::Network;
    8|       |use std::{
    9|       |    sync::{Arc, Mutex, RwLock},
   10|       |    time::Instant,
   11|       |};
   12|       |use tracing::info;
   13|       |
   14|       |pub struct Monitor {
   15|       |    ledger: Arc<Ledger>,
   16|       |    network: Arc<RwLock<Network>>,
   17|       |    online_reps: Arc<Mutex<OnlineReps>>,
   18|       |    active: Arc<ActiveElections>,
   19|       |    last_time: Option<Instant>,
   20|       |    last_blocks_cemented: u64,
   21|       |    last_blocks_total: u64,
   22|       |}
   23|       |
   24|       |impl Monitor {
   25|      3|    pub fn new(
   26|      3|        ledger: Arc<Ledger>,
   27|      3|        network: Arc<RwLock<Network>>,
   28|      3|        online_peers: Arc<Mutex<OnlineReps>>,
   29|      3|        active: Arc<ActiveElections>,
   30|      3|    ) -> Self {
   31|      3|        Self {
   32|      3|            ledger,
   33|      3|            network,
   34|      3|            online_reps: online_peers,
   35|      3|            active,
   36|      3|            last_time: None,
   37|      3|            last_blocks_total: 0,
   38|      3|            last_blocks_cemented: 0,
   39|      3|        }
   40|      3|    }
   41|       |
   42|      0|    fn log(&self, last: Instant, blocks_cemented: u64, blocks_total: u64) {
   43|      0|        // TODO: Maybe emphasize somehow that confirmed doesn't need to be equal to total; backlog is OK
   44|      0|        info!(
   45|      0|            "Blocks confirmed: {} | total: {}",
   46|       |            blocks_cemented, blocks_total
   47|       |        );
   48|       |
   49|       |        // Calculate the rates
   50|      0|        let elapsed_secs = last.elapsed().as_secs() as f64;
   51|      0|        let blocks_confirmed_rate =
   52|      0|            (blocks_cemented - self.last_blocks_cemented) as f64 / elapsed_secs;
   53|       |
   54|       |        // Block rollback can cause the block count to go down!
   55|      0|        let blocks_checked_rate =
   56|      0|            if let Some(diff) = blocks_total.checked_sub(self.last_blocks_total) {
   57|      0|                diff as f64 / elapsed_secs
   58|       |            } else {
   59|      0|                0.0
   60|       |            };
   61|       |
   62|      0|        info!(
   63|      0|            "Blocks rate (average over last {}s: confirmed: {:.2}/s | total {:.2}/s)",
   64|       |            elapsed_secs, blocks_confirmed_rate, blocks_checked_rate
   65|       |        );
   66|       |
   67|      0|        let channels = self.network.read().unwrap().channels_info();
   68|      0|        info!(
   69|      0|            "Peers: {} (realtime: {} | inbound connections: {} | outbound connections: {})",
   70|       |            channels.total, channels.realtime, channels.inbound, channels.outbound
   71|       |        );
   72|       |
   73|       |        {
   74|      0|            let (delta, online, peered) = {
   75|      0|                let online_reps = self.online_reps.lock().unwrap();
   76|      0|                (
   77|      0|                    online_reps.quorum_delta(),
   78|      0|                    online_reps.online_weight(),
   79|      0|                    online_reps.peered_weight(),
   80|      0|                )
   81|      0|            };
   82|      0|            info!(
   83|      0|                "Quorum: {} (stake peered: {} | online stake: {})",
   84|      0|                delta.format_balance(0),
   85|      0|                online.format_balance(0),
   86|      0|                peered.format_balance(0)
   87|       |            );
   88|       |        }
   89|       |
   90|      0|        let elections = self.active.info();
   91|      0|        info!(
   92|      0|            "Elections active: {} (priority: {} | hinted: {} | optimistic: {})",
   93|       |            elections.total, elections.priority, elections.hinted, elections.optimistic
   94|       |        );
   95|      0|    }
   96|       |}
   97|       |
   98|       |impl Runnable for Monitor {
   99|      0|    fn run(&mut self, _cancel_token: &CancellationToken) {
  100|      0|        let blocks_cemented = self.ledger.cemented_count();
  101|      0|        let blocks_total = self.ledger.block_count();
  102|       |
  103|      0|        if let Some(last) = self.last_time {
  104|      0|            self.log(last, blocks_cemented, blocks_total);
  105|      0|        } else {
  106|      0|            // Wait for node to warm up before logging
  107|      0|        }
  108|      0|        self.last_time = Some(Instant::now());
  109|      0|        self.last_blocks_cemented = blocks_cemented;
  110|      0|        self.last_blocks_total = blocks_total;
  111|      0|    }
  112|       |}

/home/gustav/code/nano/rsnano-node/node/src/node.rs:
    1|       |use crate::{
    2|       |    block_processing::{
    3|       |        BacklogScan, BlockProcessor, BlockProcessorCleanup, BlockSource, BoundedBacklog,
    4|       |        LedgerNotificationThread, LedgerNotifications, LocalBlockBroadcaster,
    5|       |        LocalBlockBroadcasterExt, UncheckedMap,
    6|       |    },
    7|       |    bootstrap::{BootstrapExt, BootstrapResponder, BootstrapResponderCleanup, Bootstrapper},
    8|       |    cementation::ConfirmingSet,
    9|       |    config::{GlobalConfig, NodeConfig, NodeFlags},
   10|       |    consensus::{
   11|       |        election_schedulers::ElectionSchedulers, get_bootstrap_weights, log_bootstrap_weights,
   12|       |        ActiveElections, ActiveElectionsExt, LocalVoteHistory, RecentlyConfirmedCache, RepTiers,
   13|       |        RequestAggregator, RequestAggregatorCleanup, VoteApplier, VoteBroadcaster, VoteCache,
   14|       |        VoteCacheProcessor, VoteGenerators, VoteProcessor, VoteProcessorExt, VoteProcessorQueue,
   15|       |        VoteProcessorQueueCleanup, VoteRouter,
   16|       |    },
   17|       |    http_callbacks::HttpCallbacks,
   18|       |    monitor::Monitor,
   19|       |    node_id_key_file::NodeIdKeyFile,
   20|       |    pruning::{LedgerPruning, LedgerPruningExt},
   21|       |    representatives::{
   22|       |        OnlineReps, OnlineRepsCleanup, OnlineWeightCalculation, RepCrawler, RepCrawlerExt,
   23|       |    },
   24|       |    stats::{
   25|       |        adapters::{LedgerStats, NetworkStats},
   26|       |        Stats,
   27|       |    },
   28|       |    transport::{
   29|       |        keepalive::{KeepaliveMessageFactory, KeepalivePublisher},
   30|       |        BlockFlooder, InboundMessageQueue, InboundMessageQueueCleanup, LatestKeepalives,
   31|       |        LatestKeepalivesCleanup, MessageFlooder, MessageProcessor, MessageSender,
   32|       |        NanoDataReceiverFactory, NetworkThreads, PeerCacheConnector, PeerCacheUpdater,
   33|       |        RealtimeMessageHandler, SynCookies,
   34|       |    },
   35|       |    utils::{
   36|       |        LongRunningTransactionLogger, ThreadPool, ThreadPoolImpl, TimerThread, TxnTrackingConfig,
   37|       |    },
   38|       |    wallets::{ReceivableSearch, WalletBackup, Wallets, WalletsExt},
   39|       |    work::DistributedWorkFactory,
   40|       |    NetworkParams, NodeCallbacks, OnlineWeightSampler, TelementryConfig, TelementryExt, Telemetry,
   41|       |    BUILD_INFO, VERSION_STRING,
   42|       |};
   43|       |use rsnano_core::{
   44|       |    utils::{ContainerInfo, Peer},
   45|       |    work::{WorkPool, WorkPoolImpl},
   46|       |    Account, Amount, Block, BlockHash, Networks, NodeId, PrivateKey, Root, SavedBlock, VoteCode,
   47|       |    VoteSource,
   48|       |};
   49|       |use rsnano_ledger::{BlockStatus, Ledger, RepWeightCache, Writer};
   50|       |use rsnano_messages::{ConfirmAck, Message, NetworkFilter};
   51|       |use rsnano_network::{
   52|       |    ChannelId, DeadChannelCleanup, Network, NetworkCleanup, PeerConnector, TcpListener,
   53|       |    TcpListenerExt, TcpNetworkAdapter, TrafficType,
   54|       |};
   55|       |use rsnano_nullable_clock::{SteadyClock, SystemTimeFactory};
   56|       |use rsnano_output_tracker::OutputListenerMt;
   57|       |use rsnano_store_lmdb::{
   58|       |    EnvOptions, LmdbConfig, LmdbEnv, LmdbStore, NullTransactionTracker, SyncStrategy,
   59|       |    TransactionTracker,
   60|       |};
   61|       |use std::{
   62|       |    collections::{HashMap, VecDeque},
   63|       |    path::{Path, PathBuf},
   64|       |    sync::{
   65|       |        atomic::{AtomicBool, Ordering},
   66|       |        Arc, Mutex, RwLock,
   67|       |    },
   68|       |    time::Duration,
   69|       |};
   70|       |use tracing::{debug, error, info, warn};
   71|       |
   72|       |pub struct Node {
   73|       |    is_nulled: bool,
   74|       |    pub runtime: tokio::runtime::Handle,
   75|       |    pub data_path: PathBuf,
   76|       |    pub steady_clock: Arc<SteadyClock>,
   77|       |    pub node_id: PrivateKey,
   78|       |    pub config: NodeConfig,
   79|       |    pub network_params: NetworkParams,
   80|       |    pub stats: Arc<Stats>,
   81|       |    pub workers: Arc<dyn ThreadPool>,
   82|       |    wallet_workers: Arc<dyn ThreadPool>,
   83|       |    election_workers: Arc<dyn ThreadPool>,
   84|       |    pub flags: NodeFlags,
   85|       |    pub work: Arc<WorkPoolImpl>,
   86|       |    pub distributed_work: Arc<DistributedWorkFactory>,
   87|       |    pub store: Arc<LmdbStore>,
   88|       |    pub unchecked: Arc<UncheckedMap>,
   89|       |    pub ledger: Arc<Ledger>,
   90|       |    pub syn_cookies: Arc<SynCookies>,
   91|       |    pub network: Arc<RwLock<Network>>,
   92|       |    pub telemetry: Arc<Telemetry>,
   93|       |    pub bootstrap_responder: Arc<BootstrapResponder>,
   94|       |    online_weight_calculation: TimerThread<OnlineWeightCalculation>,
   95|       |    pub online_reps: Arc<Mutex<OnlineReps>>,
   96|       |    pub rep_tiers: Arc<RepTiers>,
   97|       |    pub vote_processor_queue: Arc<VoteProcessorQueue>,
   98|       |    pub history: Arc<LocalVoteHistory>,
   99|       |    pub confirming_set: Arc<ConfirmingSet>,
  100|       |    pub vote_cache: Arc<Mutex<VoteCache>>,
  101|       |    pub block_processor: Arc<BlockProcessor>,
  102|       |    pub wallets: Arc<Wallets>,
  103|       |    pub vote_generators: Arc<VoteGenerators>,
  104|       |    pub active: Arc<ActiveElections>,
  105|       |    pub vote_router: Arc<VoteRouter>,
  106|       |    pub vote_processor: Arc<VoteProcessor>,
  107|       |    vote_cache_processor: Arc<VoteCacheProcessor>,
  108|       |    pub rep_crawler: Arc<RepCrawler>,
  109|       |    pub tcp_listener: Arc<TcpListener>,
  110|       |    pub election_schedulers: Arc<ElectionSchedulers>,
  111|       |    pub request_aggregator: Arc<RequestAggregator>,
  112|       |    pub backlog_scan: Arc<BacklogScan>,
  113|       |    bounded_backlog: Arc<BoundedBacklog>,
  114|       |    pub bootstrapper: Arc<Bootstrapper>,
  115|       |    pub local_block_broadcaster: Arc<LocalBlockBroadcaster>,
  116|       |    message_processor: Mutex<MessageProcessor>,
  117|       |    network_threads: Arc<Mutex<NetworkThreads>>,
  118|       |    ledger_pruning: Arc<LedgerPruning>,
  119|       |    pub peer_connector: Arc<PeerConnector>,
  120|       |    peer_cache_updater: TimerThread<PeerCacheUpdater>,
  121|       |    peer_cache_connector: TimerThread<PeerCacheConnector>,
  122|       |    pub inbound_message_queue: Arc<InboundMessageQueue>,
  123|       |    monitor: TimerThread<Monitor>,
  124|       |    stopped: AtomicBool,
  125|       |    pub network_filter: Arc<NetworkFilter>,
  126|       |    pub message_sender: Arc<Mutex<MessageSender>>, // TODO remove this. It is needed right now
  127|       |    pub message_flooder: Arc<Mutex<MessageFlooder>>, // TODO remove this. It is needed right now
  128|       |    pub keepalive_publisher: Arc<KeepalivePublisher>,
  129|       |    // to keep the weak pointer alive
  130|       |    start_stop_listener: OutputListenerMt<&'static str>,
  131|       |    wallet_backup: WalletBackup,
  132|       |    receivable_search: ReceivableSearch,
  133|       |    block_flooder: BlockFlooder,
  134|       |    ledger_notification_thread: LedgerNotificationThread,
  135|       |    pub ledger_notifications: LedgerNotifications,
  136|       |}
  137|       |
  138|       |pub(crate) struct NodeArgs {
  139|       |    pub runtime: tokio::runtime::Handle,
  140|       |    pub data_path: PathBuf,
  141|       |    pub config: NodeConfig,
  142|       |    pub network_params: NetworkParams,
  143|       |    pub flags: NodeFlags,
  144|       |    pub work: Arc<WorkPoolImpl>,
  145|       |    pub callbacks: NodeCallbacks,
  146|       |}
  147|       |
  148|       |impl NodeArgs {
  149|      0|    pub fn create_test_instance() -> Self {
  150|      0|        let network_params = NetworkParams::new(Networks::NanoDevNetwork);
  151|      0|        let config = NodeConfig::new(None, &network_params, 2);
  152|      0|        Self {
  153|      0|            runtime: tokio::runtime::Handle::current(),
  154|      0|            data_path: "/home/nulled-node".into(),
  155|      0|            network_params,
  156|      0|            config,
  157|      0|            flags: Default::default(),
  158|      0|            callbacks: Default::default(),
  159|      0|            work: Arc::new(WorkPoolImpl::new_null(123)),
  160|      0|        }
  161|      0|    }
  162|       |}
  163|       |
  164|       |impl Node {
  165|      0|    pub fn new_null() -> Self {
  166|      0|        Self::new_null_with_callbacks(Default::default())
  167|      0|    }
  168|       |
  169|      0|    pub fn new_null_with_callbacks(callbacks: NodeCallbacks) -> Self {
  170|      0|        let args = NodeArgs {
  171|      0|            callbacks,
  172|      0|            ..NodeArgs::create_test_instance()
  173|      0|        };
  174|      0|        Self::new(args, true, NodeIdKeyFile::new_null())
  175|      0|    }
  176|       |
  177|      3|    pub(crate) fn new_with_args(args: NodeArgs) -> Self {
  178|      3|        Self::new(args, false, NodeIdKeyFile::default())
  179|      3|    }
  180|       |
  181|      0|    pub fn node_id(&self) -> NodeId {
  182|      0|        self.node_id.public_key().into()
  183|      0|    }
  184|       |
  185|      3|    fn new(args: NodeArgs, is_nulled: bool, mut node_id_key_file: NodeIdKeyFile) -> Self {
  186|      3|        let network_params = args.network_params;
  187|      3|        let config = args.config;
  188|      3|        let flags = args.flags;
  189|      3|        let runtime = args.runtime;
  190|      3|        let work = args.work;
  191|      3|        // Time relative to the start of the node. This makes time exlicit and enables us to
  192|      3|        // write time relevant unit tests with ease.
  193|      3|        let steady_clock = Arc::new(SteadyClock::default());
  194|      3|
  195|      3|        let network_label = network_params.network.get_current_network_as_string();
  196|      3|        let global_config = GlobalConfig {
  197|      3|            node_config: config.clone(),
  198|      3|            flags: flags.clone(),
  199|      3|            network_params: network_params.clone(),
  200|      3|        };
  201|      3|        let global_config = &global_config;
  202|      3|        let application_path = args.data_path;
  203|      3|        let node_id = node_id_key_file.initialize(&application_path).unwrap();
  204|      3|
  205|      3|        let stats = Arc::new(Stats::new(config.stat_config.clone()));
  206|       |
  207|      3|        let store = if is_nulled {
  208|      0|            Arc::new(LmdbStore::new_null())
  209|       |        } else {
  210|      3|            make_store(
  211|      3|                &application_path,
  212|      3|                true,
  213|      3|                &config.diagnostics_config.txn_tracking,
  214|      3|                Duration::from_millis(config.block_processor_batch_max_time_ms as u64),
  215|      3|                config.lmdb_config.clone(),
  216|      3|                config.backup_before_upgrade,
  217|      3|            )
  218|      3|            .expect("Could not create LMDB store")
  219|       |        };
  220|       |
  221|      3|        info!("Version: {}", VERSION_STRING);
                            ^0
  222|      3|        info!("Build information: {}", BUILD_INFO);
                            ^0
  223|      3|        info!("Active network: {}", network_label);
                            ^0
  224|      3|        info!("Database backend: {}", store.vendor());
                            ^0
  225|      3|        info!("Data path: {:?}", application_path);
                            ^0
  226|      3|        info!(
  227|      0|            "Work pool threads: {} ({})",
  228|      0|            work.thread_count(),
  229|      0|            if work.has_opencl() { "OpenCL" } else { "CPU" }
  230|       |        );
  231|      3|        info!("Work peers: {}", config.work_peers.len());
                            ^0
  232|      3|        info!("Node ID: {}", NodeId::from(&node_id));
                            ^0
  233|       |
  234|      3|        let (max_blocks, bootstrap_weights) = if (network_params.network.is_live_network()
  235|      3|            || network_params.network.is_beta_network())
  236|      0|            && !flags.inactive_node
  237|       |        {
  238|      0|            get_bootstrap_weights(network_params.network.current_network)
  239|       |        } else {
  240|      3|            (0, HashMap::new())
  241|       |        };
  242|       |
  243|      3|        let rep_weights = Arc::new(RepWeightCache::with_bootstrap_weights(
  244|      3|            bootstrap_weights,
  245|      3|            max_blocks,
  246|      3|            store.cache.clone(),
  247|      3|        ));
  248|      3|
  249|      3|        let mut ledger = Ledger::new(
  250|      3|            store.clone(),
  251|      3|            network_params.ledger.clone(),
  252|      3|            config.representative_vote_weight_minimum,
  253|      3|            rep_weights.clone(),
  254|      3|        )
  255|      3|        .expect("Could not initialize ledger");
  256|      3|        ledger.set_observer(Arc::new(LedgerStats::new(stats.clone())));
  257|      3|        let ledger = Arc::new(ledger);
  258|      3|
  259|      3|        log_bootstrap_weights(&ledger.rep_weights);
  260|      3|
  261|      3|        let syn_cookies = Arc::new(SynCookies::new(network_params.network.max_peers_per_ip));
  262|      3|
  263|      3|        let workers: Arc<dyn ThreadPool> = Arc::new(ThreadPoolImpl::create(
  264|      3|            config.background_threads as usize,
  265|      3|            "Worker".to_string(),
  266|      3|        ));
  267|      3|        let wallet_workers: Arc<dyn ThreadPool> =
  268|      3|            Arc::new(ThreadPoolImpl::create(1, "Wallet work"));
  269|      3|        let election_workers: Arc<dyn ThreadPool> =
  270|      3|            Arc::new(ThreadPoolImpl::create(1, "Election work"));
  271|      3|
  272|      3|        let network_observer = Arc::new(NetworkStats::new(stats.clone()));
  273|      3|        let mut network = Network::new(global_config.into());
  274|      3|        network.set_observer(network_observer.clone());
  275|      3|        let network = Arc::new(RwLock::new(network));
  276|      3|
  277|      3|        let mut dead_channel_cleanup = DeadChannelCleanup::new(
  278|      3|            steady_clock.clone(),
  279|      3|            network.clone(),
  280|      3|            network_params.network.cleanup_cutoff(),
  281|      3|        );
  282|      3|
  283|      3|        let mut network_filter = NetworkFilter::new(1024 * 1024);
  284|      3|        network_filter.age_cutoff = config.network_duplicate_filter_cutoff;
  285|      3|        let network_filter = Arc::new(network_filter);
  286|      3|
  287|      3|        let mut inbound_message_queue =
  288|      3|            InboundMessageQueue::new(config.message_processor.max_queue, stats.clone());
  289|      3|        if let Some(cb) = args.callbacks.on_inbound {
                                  ^0
  290|      0|            inbound_message_queue.set_inbound_callback(cb);
  291|      3|        }
  292|      3|        if let Some(cb) = args.callbacks.on_inbound_dropped {
                                  ^0
  293|      0|            inbound_message_queue.set_inbound_dropped_callback(cb);
  294|      3|        }
  295|      3|        let inbound_message_queue = Arc::new(inbound_message_queue);
  296|      3|
  297|      3|        dead_channel_cleanup.add_step(InboundMessageQueueCleanup::new(
  298|      3|            inbound_message_queue.clone(),
  299|      3|        ));
  300|      3|
  301|      3|        let telemetry_config = TelementryConfig {
  302|      3|            enable_ongoing_requests: false,
  303|      3|            enable_ongoing_broadcasts: !flags.disable_providing_telemetry_metrics,
  304|      3|        };
  305|      3|
  306|      3|        let unchecked = Arc::new(UncheckedMap::new(
  307|      3|            config.max_unchecked_blocks as usize,
  308|      3|            stats.clone(),
  309|      3|            flags.disable_block_processor_unchecked_deletion,
  310|      3|        ));
  311|      3|
  312|      3|        let online_reps = Arc::new(Mutex::new(
  313|      3|            OnlineReps::builder()
  314|      3|                .rep_weights(rep_weights.clone())
  315|      3|                .online_weight_minimum(config.online_weight_minimum)
  316|      3|                .representative_weight_minimum(config.representative_vote_weight_minimum)
  317|      3|                .weight_interval(OnlineReps::default_interval_for(
  318|      3|                    network_params.network.current_network,
  319|      3|                ))
  320|      3|                .finish(),
  321|      3|        ));
  322|      3|
  323|      3|        let online_weight_sampler =
  324|      3|            OnlineWeightSampler::new(ledger.clone(), network_params.network.current_network);
  325|      3|
  326|      3|        let online_weight_calculation =
  327|      3|            OnlineWeightCalculation::new(online_weight_sampler, online_reps.clone());
  328|      3|        dead_channel_cleanup.add_step(OnlineRepsCleanup::new(online_reps.clone()));
  329|      3|
  330|      3|        let mut message_sender = MessageSender::new(
  331|      3|            network.clone(),
  332|      3|            stats.clone(),
  333|      3|            network_params.network.protocol_info(),
  334|      3|        );
  335|       |
  336|      3|        if let Some(callback) = &args.callbacks.on_publish {
                                  ^0
  337|      0|            message_sender.set_published_callback(callback.clone());
  338|      3|        }
  339|       |
  340|      3|        let message_flooder = MessageFlooder::new(
  341|      3|            online_reps.clone(),
  342|      3|            network.clone(),
  343|      3|            stats.clone(),
  344|      3|            message_sender.clone(),
  345|      3|        );
  346|      3|
  347|      3|        let telemetry = Arc::new(Telemetry::new(
  348|      3|            telemetry_config,
  349|      3|            config.clone(),
  350|      3|            stats.clone(),
  351|      3|            ledger.clone(),
  352|      3|            unchecked.clone(),
  353|      3|            network_params.clone(),
  354|      3|            network.clone(),
  355|      3|            message_sender.clone(),
  356|      3|            node_id.clone(),
  357|      3|            steady_clock.clone(),
  358|      3|        ));
  359|      3|
  360|      3|        let bootstrap_responder = Arc::new(BootstrapResponder::new(
  361|      3|            config.bootstrap_responder.clone(),
  362|      3|            stats.clone(),
  363|      3|            ledger.clone(),
  364|      3|            message_sender.clone(),
  365|      3|        ));
  366|      3|        dead_channel_cleanup.add_step(BootstrapResponderCleanup::new(
  367|      3|            bootstrap_responder.server_impl.clone(),
  368|      3|        ));
  369|      3|
  370|      3|        let rep_tiers = Arc::new(RepTiers::new(
  371|      3|            rep_weights.clone(),
  372|      3|            network_params.clone(),
  373|      3|            online_reps.clone(),
  374|      3|            stats.clone(),
  375|      3|        ));
  376|      3|
  377|      3|        let vote_processor_queue = Arc::new(VoteProcessorQueue::new(
  378|      3|            config.vote_processor.clone(),
  379|      3|            stats.clone(),
  380|      3|            rep_tiers.clone(),
  381|      3|        ));
  382|      3|        dead_channel_cleanup.add_step(VoteProcessorQueueCleanup::new(vote_processor_queue.clone()));
  383|      3|
  384|      3|        let history = Arc::new(LocalVoteHistory::new(network_params.voting.max_cache));
  385|      3|
  386|      3|        let confirming_set = Arc::new(ConfirmingSet::new(
  387|      3|            config.confirming_set.clone(),
  388|      3|            ledger.clone(),
  389|      3|            stats.clone(),
  390|      3|        ));
  391|      3|
  392|      3|        let vote_cache = Arc::new(Mutex::new(VoteCache::new(
  393|      3|            config.vote_cache.clone(),
  394|      3|            stats.clone(),
  395|      3|        )));
  396|      3|
  397|      3|        let recently_confirmed = Arc::new(RecentlyConfirmedCache::new(
  398|      3|            config.active_elections.confirmation_cache,
  399|      3|        ));
  400|      3|
  401|      3|        let (ledger_notification_thread, ledger_notification_queue, ledger_notifications) =
  402|      3|            LedgerNotificationThread::new(config.max_ledger_notifications);
  403|      3|
  404|      3|        let block_processor = Arc::new(BlockProcessor::new(
  405|      3|            global_config.into(),
  406|      3|            ledger.clone(),
  407|      3|            unchecked.clone(),
  408|      3|            stats.clone(),
  409|      3|            ledger_notification_queue,
  410|      3|        ));
  411|      3|        dead_channel_cleanup.add_step(BlockProcessorCleanup::new(
  412|      3|            block_processor.processor_loop.clone(),
  413|      3|        ));
  414|      3|
  415|      3|        let confirming_set_w = Arc::downgrade(&confirming_set);
  416|      3|        ledger_notifications.on_blocks_processed(Box::new(move |batch| {
                                                                                     ^0
  417|      0|            if let Some(confirming) = confirming_set_w.upgrade() {
  418|      0|                confirming.requeue_blocks(batch)
  419|      0|            }
  420|      3|        }));
                      ^0
  421|      3|
  422|      3|        let distributed_work = Arc::new(DistributedWorkFactory::new(work.clone(), runtime.clone()));
  423|      3|
  424|      3|        let mut wallets_path = application_path.clone();
  425|      3|        wallets_path.push("wallets.ldb");
  426|      3|
  427|      3|        let mut wallets_lmdb_config = config.lmdb_config.clone();
  428|      3|        wallets_lmdb_config.sync = SyncStrategy::Always;
  429|      3|        wallets_lmdb_config.map_size = 1024 * 1024 * 1024;
  430|      3|        let wallets_options = EnvOptions {
  431|      3|            config: wallets_lmdb_config,
  432|      3|            use_no_mem_init: false,
  433|      3|        };
  434|      3|        let wallets_env = if is_nulled {
  435|      0|            Arc::new(LmdbEnv::new_null())
  436|       |        } else {
  437|      3|            Arc::new(LmdbEnv::new_with_options(wallets_path, &wallets_options).unwrap())
  438|       |        };
  439|       |
  440|      3|        let mut wallets = Wallets::new(
  441|      3|            wallets_env,
  442|      3|            ledger.clone(),
  443|      3|            &config,
  444|      3|            network_params.kdf_work,
  445|      3|            network_params.work.clone(),
  446|      3|            distributed_work.clone(),
  447|      3|            network_params.clone(),
  448|      3|            workers.clone(),
  449|      3|            block_processor.clone(),
  450|      3|            online_reps.clone(),
  451|      3|            confirming_set.clone(),
  452|      3|            message_flooder.clone(),
  453|      3|        );
  454|      3|        if !is_nulled {
  455|      3|            wallets.initialize().expect("Could not create wallet");
  456|      3|        }
                       ^0
  457|      3|        let wallets = Arc::new(wallets);
  458|      3|        if !is_nulled {
  459|      3|            wallets.initialize2();
  460|      3|        }
                       ^0
  461|       |
  462|      3|        let vote_broadcaster = Arc::new(VoteBroadcaster::new(
  463|      3|            vote_processor_queue.clone(),
  464|      3|            message_flooder.clone(),
  465|      3|        ));
  466|      3|
  467|      3|        let vote_generators = Arc::new(VoteGenerators::new(
  468|      3|            ledger.clone(),
  469|      3|            wallets.clone(),
  470|      3|            history.clone(),
  471|      3|            stats.clone(),
  472|      3|            &config,
  473|      3|            &network_params,
  474|      3|            vote_broadcaster,
  475|      3|            message_sender.clone(),
  476|      3|            steady_clock.clone(),
  477|      3|        ));
  478|      3|
  479|      3|        let vote_applier = Arc::new(VoteApplier::new(
  480|      3|            ledger.clone(),
  481|      3|            network_params.clone(),
  482|      3|            online_reps.clone(),
  483|      3|            stats.clone(),
  484|      3|            vote_generators.clone(),
  485|      3|            block_processor.clone(),
  486|      3|            config.clone(),
  487|      3|            history.clone(),
  488|      3|            wallets.clone(),
  489|      3|            recently_confirmed.clone(),
  490|      3|            confirming_set.clone(),
  491|      3|            election_workers.clone(),
  492|      3|        ));
  493|      3|
  494|      3|        let vote_router = Arc::new(VoteRouter::new(
  495|      3|            vote_cache.clone(),
  496|      3|            recently_confirmed.clone(),
  497|      3|            vote_applier.clone(),
  498|      3|            rep_weights.clone(),
  499|      3|        ));
  500|      3|
  501|      3|        let on_vote = args
  502|      3|            .callbacks
  503|      3|            .on_vote
  504|      3|            .unwrap_or_else(|| Box::new(|_, _, _, _| {}));
                                                                   ^0
  505|      3|
  506|      3|        let vote_processor = Arc::new(VoteProcessor::new(
  507|      3|            vote_processor_queue.clone(),
  508|      3|            vote_router.clone(),
  509|      3|            stats.clone(),
  510|      3|            on_vote,
  511|      3|        ));
  512|      3|
  513|      3|        let vote_cache_processor = Arc::new(VoteCacheProcessor::new(
  514|      3|            stats.clone(),
  515|      3|            vote_cache.clone(),
  516|      3|            vote_router.clone(),
  517|      3|            config.vote_processor.clone(),
  518|      3|        ));
  519|      3|
  520|      3|        let active_elections = Arc::new(ActiveElections::new(
  521|      3|            network_params.clone(),
  522|      3|            wallets.clone(),
  523|      3|            config.clone(),
  524|      3|            ledger.clone(),
  525|      3|            confirming_set.clone(),
  526|      3|            ledger_notifications.clone(),
  527|      3|            vote_generators.clone(),
  528|      3|            network_filter.clone(),
  529|      3|            network.clone(),
  530|      3|            vote_cache.clone(),
  531|      3|            stats.clone(),
  532|      3|            online_reps.clone(),
  533|      3|            flags.clone(),
  534|      3|            recently_confirmed.clone(),
  535|      3|            vote_applier.clone(),
  536|      3|            vote_router.clone(),
  537|      3|            vote_cache_processor.clone(),
  538|      3|            steady_clock.clone(),
  539|      3|            message_flooder.clone(),
  540|      3|        ));
  541|      3|
  542|      3|        active_elections.initialize();
  543|      3|
  544|      3|        let election_schedulers = Arc::new(ElectionSchedulers::new(
  545|      3|            config.clone(),
  546|      3|            network_params.network.clone(),
  547|      3|            active_elections.clone(),
  548|      3|            ledger.clone(),
  549|      3|            stats.clone(),
  550|      3|            vote_cache.clone(),
  551|      3|            confirming_set.clone(),
  552|      3|            online_reps.clone(),
  553|      3|        ));
  554|      3|
  555|      3|        let schedulers_w = Arc::downgrade(&election_schedulers);
  556|      3|        let ledger_l = ledger.clone();
  557|      3|        // Activate accounts with fresh blocks
  558|      3|        ledger_notifications.on_blocks_processed(Box::new(move |batch| {
                                                                                     ^0
  559|      0|            let Some(schedulers) = schedulers_w.upgrade() else {
  560|      0|                return;
  561|       |            };
  562|       |
  563|      0|            let tx = ledger_l.read_txn();
  564|      0|            for (status, context) in batch {
  565|      0|                if *status == BlockStatus::Progress {
  566|      0|                    let account = context
  567|      0|                        .saved_block
  568|      0|                        .lock()
  569|      0|                        .unwrap()
  570|      0|                        .as_ref()
  571|      0|                        .unwrap()
  572|      0|                        .account();
  573|      0|                    schedulers.activate(&tx, &account);
  574|      0|                }
  575|       |            }
  576|      3|        }));
                      ^0
  577|      3|
  578|      3|        let schedulers_w = Arc::downgrade(&election_schedulers);
  579|      3|        active_elections.on_vacancy_updated(Box::new(move || {
  580|      3|            if let Some(schedulers) = schedulers_w.upgrade() {
  581|      3|                schedulers.notify();
  582|      3|            }
                           ^0
  583|      3|        }));
  584|      3|
  585|      3|        if !flags.disable_activate_successors {
  586|      3|            let ledger_l = ledger.clone();
  587|      3|            let schedulers_w = Arc::downgrade(&election_schedulers);
  588|      3|            // Activate successors of cemented blocks
  589|      3|            confirming_set.on_batch_cemented(Box::new(move |batch| {
                                                                                 ^0
  590|      0|                let Some(schedulers) = schedulers_w.upgrade() else {
  591|      0|                    return;
  592|       |                };
  593|      0|                let tx = ledger_l.read_txn();
  594|      0|                for context in batch {
  595|      0|                    schedulers.activate_successors(&tx, &context.block);
  596|      0|                }
  597|      3|            }));
                          ^0
  598|      3|        }
                       ^0
  599|       |
  600|      3|        vote_applier.set_election_schedulers(&election_schedulers);
  601|      3|
  602|      3|        let mut bootstrap_sender = MessageSender::new_with_buffer_size(
  603|      3|            network.clone(),
  604|      3|            stats.clone(),
  605|      3|            network_params.network.protocol_info(),
  606|      3|            512,
  607|      3|        );
  608|       |
  609|      3|        if let Some(callback) = &args.callbacks.on_publish {
                                  ^0
  610|      0|            bootstrap_sender.set_published_callback(callback.clone());
  611|      3|        }
  612|       |
  613|      3|        let latest_keepalives = Arc::new(Mutex::new(LatestKeepalives::default()));
  614|      3|        dead_channel_cleanup.add_step(LatestKeepalivesCleanup::new(latest_keepalives.clone()));
  615|      3|
  616|      3|        let data_receiver_factory = Box::new(NanoDataReceiverFactory::new(
  617|      3|            &network,
  618|      3|            inbound_message_queue.clone(),
  619|      3|            network_filter.clone(),
  620|      3|            Arc::new(network_params.clone()),
  621|      3|            stats.clone(),
  622|      3|            syn_cookies.clone(),
  623|      3|            node_id.clone(),
  624|      3|            latest_keepalives.clone(),
  625|      3|        ));
  626|      3|
  627|      3|        network
  628|      3|            .write()
  629|      3|            .unwrap()
  630|      3|            .set_data_receiver_factory(data_receiver_factory);
  631|      3|
  632|      3|        let network_adapter = Arc::new(TcpNetworkAdapter::new(
  633|      3|            network.clone(),
  634|      3|            steady_clock.clone(),
  635|      3|            runtime.clone(),
  636|      3|        ));
  637|      3|
  638|      3|        dead_channel_cleanup.add_step(NetworkCleanup::new(network_adapter.clone()));
  639|      3|
  640|      3|        let peer_connector = Arc::new(PeerConnector::new(
  641|      3|            config.tcp.connect_timeout,
  642|      3|            network_adapter.clone(),
  643|      3|            network_observer.clone(),
  644|      3|            runtime.clone(),
  645|      3|        ));
  646|      3|
  647|      3|        let keepalive_factory = Arc::new(KeepaliveMessageFactory::new(
  648|      3|            network.clone(),
  649|      3|            Peer::new(config.external_address.clone(), config.external_port),
  650|      3|        ));
  651|      3|
  652|      3|        let keepalive_publisher = Arc::new(KeepalivePublisher::new(
  653|      3|            network.clone(),
  654|      3|            peer_connector.clone(),
  655|      3|            message_sender.clone(),
  656|      3|            keepalive_factory.clone(),
  657|      3|        ));
  658|      3|
  659|      3|        let rep_crawler = Arc::new(RepCrawler::new(
  660|      3|            online_reps.clone(),
  661|      3|            stats.clone(),
  662|      3|            config.rep_crawler_query_timeout,
  663|      3|            config.clone(),
  664|      3|            network_params.clone(),
  665|      3|            network.clone(),
  666|      3|            ledger.clone(),
  667|      3|            active_elections.clone(),
  668|      3|            steady_clock.clone(),
  669|      3|            message_sender.clone(),
  670|      3|            keepalive_publisher.clone(),
  671|      3|            runtime.clone(),
  672|      3|        ));
  673|      3|
  674|      3|        // BEWARE: `bootstrap` takes `network.port` instead of `config.peering_port` because when the user doesn't specify
  675|      3|        //         a peering port and wants the OS to pick one, the picking happens when `network` gets initialized
  676|      3|        //         (if UDP is active, otherwise it happens when `bootstrap` gets initialized), so then for TCP traffic
  677|      3|        //         we want to tell `bootstrap` to use the already picked port instead of itself picking a different one.
  678|      3|        //         Thus, be very careful if you change the order: if `bootstrap` gets constructed before `network`,
  679|      3|        //         the latter would inherit the port from the former (if TCP is active, otherwise `network` picks first)
  680|      3|        //
  681|      3|        let tcp_listener = Arc::new(TcpListener::new(
  682|      3|            network.read().unwrap().listening_port(),
  683|      3|            network_adapter.clone(),
  684|      3|            network_observer.clone(),
  685|      3|            runtime.clone(),
  686|      3|        ));
  687|      3|
  688|      3|        let request_aggregator = Arc::new(RequestAggregator::new(
  689|      3|            config.request_aggregator.clone(),
  690|      3|            stats.clone(),
  691|      3|            vote_generators.clone(),
  692|      3|            ledger.clone(),
  693|      3|            network.clone(),
  694|      3|        ));
  695|      3|        dead_channel_cleanup.add_step(RequestAggregatorCleanup::new(
  696|      3|            request_aggregator.state.clone(),
  697|      3|        ));
  698|      3|
  699|      3|        let backlog_scan = Arc::new(BacklogScan::new(
  700|      3|            global_config.into(),
  701|      3|            ledger.clone(),
  702|      3|            stats.clone(),
  703|      3|        ));
  704|      3|
  705|      3|        //  TODO: Hook this direclty in the schedulers
  706|      3|        let schedulers_w = Arc::downgrade(&election_schedulers);
  707|      3|        let ledger_l = ledger.clone();
  708|     30|        backlog_scan.on_batch_activated(move |batch| {
  709|     30|            if let Some(schedulers) = schedulers_w.upgrade() {
  710|     30|                let tx = ledger_l.read_txn();
  711|     30|                for info in batch {
                                  ^0
  712|      0|                    schedulers.activate_backlog(
  713|      0|                        &tx,
  714|      0|                        &info.account,
  715|      0|                        &info.account_info,
  716|      0|                        &info.conf_info,
  717|      0|                    );
  718|      0|                }
  719|      0|            }
  720|     30|        });
  721|      3|
  722|      3|        let bounded_backlog = Arc::new(BoundedBacklog::new(
  723|      3|            election_schedulers.priority.bucketing().clone(),
  724|      3|            config.bounded_backlog.clone(),
  725|      3|            ledger.clone(),
  726|      3|            block_processor.clone(),
  727|      3|            stats.clone(),
  728|      3|        ));
  729|      3|
  730|      3|        // Activate accounts with unconfirmed blocks
  731|      3|        let backlog_w = Arc::downgrade(&bounded_backlog);
  732|     30|        backlog_scan.on_batch_activated(move |batch| {
  733|     30|            if let Some(backlog) = backlog_w.upgrade() {
  734|     30|                backlog.activate_batch(batch);
  735|     30|            }
                           ^0
  736|     30|        });
  737|      3|
  738|      3|        // Erase accounts with all confirmed blocks
  739|      3|        let backlog_w = Arc::downgrade(&bounded_backlog);
  740|     30|        backlog_scan.on_batch_scanned(move |batch| {
  741|     30|            if let Some(backlog) = backlog_w.upgrade() {
  742|     30|                backlog.erase_accounts(batch.iter().map(|i| i.account));
  743|     30|            }
                           ^0
  744|     30|        });
  745|      3|
  746|      3|        // Track unconfirmed blocks
  747|      3|        let backlog_w = Arc::downgrade(&bounded_backlog);
  748|      3|        ledger_notifications.on_blocks_processed(Box::new(move |batch| {
                                                                                     ^0
  749|      0|            if let Some(backlog) = backlog_w.upgrade() {
  750|      0|                backlog.insert_batch(batch);
  751|      0|            }
  752|      3|        }));
                      ^0
  753|      3|
  754|      3|        // Remove rolled back blocks from the backlog
  755|      3|        let backlog_w = Arc::downgrade(&bounded_backlog);
  756|      3|        ledger_notifications.on_blocks_rolled_back(move |blocks, _rollback_root| {
                                                                                               ^0
  757|      0|            if let Some(backlog) = backlog_w.upgrade() {
  758|      0|                backlog.erase_hashes(blocks.iter().map(|b| b.hash()));
  759|      0|            }
  760|      3|        });
                      ^0
  761|      3|
  762|      3|        // Remove cemented blocks from the backlog
  763|      3|        let backlog_w = Arc::downgrade(&bounded_backlog);
  764|      3|        confirming_set.on_batch_cemented(Box::new(move |batch| {
                                                                             ^0
  765|      0|            if let Some(backlog) = backlog_w.upgrade() {
  766|      0|                backlog.erase_hashes(batch.iter().map(|i| i.block.hash()));
  767|      0|            }
  768|      3|        }));
                      ^0
  769|      3|
  770|      3|        let bootstrapper = Arc::new(Bootstrapper::new(
  771|      3|            block_processor.clone(),
  772|      3|            ledger_notifications.clone(),
  773|      3|            ledger.clone(),
  774|      3|            stats.clone(),
  775|      3|            network.clone(),
  776|      3|            message_sender.clone(),
  777|      3|            global_config.node_config.bootstrap.clone(),
  778|      3|            steady_clock.clone(),
  779|      3|        ));
  780|      3|
  781|      3|        let local_block_broadcaster = Arc::new(LocalBlockBroadcaster::new(
  782|      3|            config.local_block_broadcaster.clone(),
  783|      3|            ledger_notifications.clone(),
  784|      3|            stats.clone(),
  785|      3|            ledger.clone(),
  786|      3|            confirming_set.clone(),
  787|      3|            message_flooder.clone(),
  788|      3|            !flags.disable_block_processor_republishing,
  789|      3|        ));
  790|      3|        local_block_broadcaster.initialize();
  791|      3|
  792|      3|        let vote_cache_w = Arc::downgrade(&vote_cache);
  793|      3|        let vote_router_w = Arc::downgrade(&vote_router);
  794|      3|        let recently_confirmed_w = Arc::downgrade(&recently_confirmed);
  795|      3|        let scheduler_w = Arc::downgrade(&election_schedulers);
  796|      3|        let confirming_set_w = Arc::downgrade(&confirming_set);
  797|      3|        let local_block_broadcaster_w = Arc::downgrade(&local_block_broadcaster);
  798|      3|
  799|      3|        // TODO: remove the duplication of the on_rolling_back event
  800|      3|        bounded_backlog.on_rolling_back(move |hash| {
                                                                  ^0
  801|      0|            if let Some(i) = vote_cache_w.upgrade() {
  802|      0|                if i.lock().unwrap().contains(hash) {
  803|      0|                    return false;
  804|      0|                }
  805|      0|            }
  806|       |
  807|      0|            if let Some(i) = vote_router_w.upgrade() {
  808|      0|                if i.contains(hash) {
  809|      0|                    return false;
  810|      0|                }
  811|      0|            }
  812|       |
  813|      0|            if let Some(i) = recently_confirmed_w.upgrade() {
  814|      0|                if i.hash_exists(hash) {
  815|      0|                    return false;
  816|      0|                }
  817|      0|            }
  818|       |
  819|      0|            if let Some(i) = scheduler_w.upgrade() {
  820|      0|                if i.contains(hash) {
  821|      0|                    return false;
  822|      0|                }
  823|      0|            }
  824|       |
  825|      0|            if let Some(i) = confirming_set_w.upgrade() {
  826|      0|                if i.contains(hash) {
  827|      0|                    return false;
  828|      0|                }
  829|      0|            }
  830|       |
  831|      0|            if let Some(i) = local_block_broadcaster_w.upgrade() {
  832|      0|                if i.contains(hash) {
  833|      0|                    return false;
  834|      0|                }
  835|      0|            }
  836|      0|            true
  837|      3|        });
                      ^0
  838|      3|
  839|      3|        let vote_cache_w = Arc::downgrade(&vote_cache);
  840|      3|        let vote_router_w = Arc::downgrade(&vote_router);
  841|      3|        let recently_confirmed_w = Arc::downgrade(&recently_confirmed);
  842|      3|        let scheduler_w = Arc::downgrade(&election_schedulers);
  843|      3|        let confirming_set_w = Arc::downgrade(&confirming_set);
  844|      3|        let local_block_broadcaster_w = Arc::downgrade(&local_block_broadcaster);
  845|      3|        block_processor.on_rolling_back(move |hash| {
                                                                  ^0
  846|      0|            if let Some(i) = vote_cache_w.upgrade() {
  847|      0|                if i.lock().unwrap().contains(hash) {
  848|      0|                    return false;
  849|      0|                }
  850|      0|            }
  851|       |
  852|      0|            if let Some(i) = vote_router_w.upgrade() {
  853|      0|                if i.contains(hash) {
  854|      0|                    return false;
  855|      0|                }
  856|      0|            }
  857|       |
  858|      0|            if let Some(i) = recently_confirmed_w.upgrade() {
  859|      0|                if i.hash_exists(hash) {
  860|      0|                    return false;
  861|      0|                }
  862|      0|            }
  863|       |
  864|      0|            if let Some(i) = scheduler_w.upgrade() {
  865|      0|                if i.contains(hash) {
  866|      0|                    return false;
  867|      0|                }
  868|      0|            }
  869|       |
  870|      0|            if let Some(i) = confirming_set_w.upgrade() {
  871|      0|                if i.contains(hash) {
  872|      0|                    return false;
  873|      0|                }
  874|      0|            }
  875|       |
  876|      0|            if let Some(i) = local_block_broadcaster_w.upgrade() {
  877|      0|                if i.contains(hash) {
  878|      0|                    return false;
  879|      0|                }
  880|      0|            }
  881|      0|            true
  882|      3|        });
                      ^0
  883|      3|
  884|      3|        let realtime_message_handler = Arc::new(RealtimeMessageHandler::new(
  885|      3|            stats.clone(),
  886|      3|            network.clone(),
  887|      3|            network_filter.clone(),
  888|      3|            block_processor.clone(),
  889|      3|            config.clone(),
  890|      3|            wallets.clone(),
  891|      3|            request_aggregator.clone(),
  892|      3|            vote_processor_queue.clone(),
  893|      3|            telemetry.clone(),
  894|      3|            bootstrap_responder.clone(),
  895|      3|            bootstrapper.clone(),
  896|      3|        ));
  897|      3|
  898|      3|        let network_threads = Arc::new(Mutex::new(NetworkThreads::new(
  899|      3|            network.clone(),
  900|      3|            peer_connector.clone(),
  901|      3|            flags.clone(),
  902|      3|            network_params.clone(),
  903|      3|            stats.clone(),
  904|      3|            syn_cookies.clone(),
  905|      3|            network_filter.clone(),
  906|      3|            keepalive_factory.clone(),
  907|      3|            latest_keepalives.clone(),
  908|      3|            dead_channel_cleanup,
  909|      3|            message_flooder.clone(),
  910|      3|            steady_clock.clone(),
  911|      3|        )));
  912|      3|
  913|      3|        let message_processor = Mutex::new(MessageProcessor::new(
  914|      3|            flags.clone(),
  915|      3|            config.clone(),
  916|      3|            inbound_message_queue.clone(),
  917|      3|            realtime_message_handler.clone(),
  918|      3|        ));
  919|      3|
  920|      3|        debug!("Constructing node...");
                             ^0
  921|       |
  922|      3|        let schedulers_weak = Arc::downgrade(&election_schedulers);
  923|      3|        wallets.set_start_election_callback(Box::new(move |block| {
                                                                                ^0
  924|      0|            if let Some(schedulers) = schedulers_weak.upgrade() {
  925|      0|                schedulers.add_manual(block);
  926|      0|            }
  927|      3|        }));
                      ^0
  928|      3|
  929|      3|        let rep_crawler_w = Arc::downgrade(&rep_crawler);
  930|      3|        if !flags.disable_rep_crawler {
  931|      3|            network
  932|      3|                .write()
  933|      3|                .unwrap()
  934|      3|                .on_new_realtime_channel(Arc::new(move |channel| {
                                                                               ^0
  935|      0|                    if let Some(crawler) = rep_crawler_w.upgrade() {
  936|      0|                        crawler.query_with_priority(channel);
  937|      0|                    }
  938|      3|                }));
                              ^0
  939|      3|        }
                       ^0
  940|       |
  941|      3|        let history_w = Arc::downgrade(&history);
  942|      3|        let active_w = Arc::downgrade(&active_elections);
  943|      3|        ledger_notifications.on_blocks_rolled_back(move |blocks, rollback_root| {
                                                                                              ^0
  944|      0|            let Some(history) = history_w.upgrade() else {
  945|      0|                return;
  946|       |            };
  947|      0|            let Some(active) = active_w.upgrade() else {
  948|      0|                return;
  949|       |            };
  950|       |
  951|      0|            for block in blocks {
  952|       |                // Do some cleanup of rolled back blocks
  953|      0|                history.erase(&block.root());
  954|      0|
  955|      0|                // Stop all rolled back active transactions except initial
  956|      0|                if block.qualified_root() != rollback_root {
  957|      0|                    active.erase(&block.qualified_root());
  958|      0|                }
  959|       |            }
  960|      3|        });
                      ^0
  961|      3|
  962|      3|        // Do some cleanup due to this block never being processed by confirmation height processor
  963|      3|        let recently_confirmed_w = Arc::downgrade(&recently_confirmed);
  964|      3|        confirming_set.on_cementing_failed(move |hash| {
                                                                     ^0
  965|      0|            if let Some(recent) = recently_confirmed_w.upgrade() {
  966|      0|                recent.erase(hash);
  967|      0|            }
  968|      3|        });
                      ^0
  969|      3|
  970|      3|        // Requeue blocks that could not be immediately processed
  971|      3|        let block_processor_w = Arc::downgrade(&block_processor);
  972|      3|        unchecked.set_satisfied_observer(Box::new(move |info| {
                                                                            ^0
  973|      0|            if let Some(processor) = block_processor_w.upgrade() {
  974|      0|                processor.add(
  975|      0|                    info.block.clone().into(),
  976|      0|                    BlockSource::Unchecked,
  977|      0|                    ChannelId::LOOPBACK,
  978|      0|                );
  979|      0|            }
  980|      3|        }));
                      ^0
  981|      3|
  982|      3|        let wallets_w = Arc::downgrade(&wallets);
  983|      3|        let flooder_l = Mutex::new(message_flooder.clone());
  984|      3|        vote_router.on_vote_processed(Box::new(move |vote, _source, results| {
                                                                                           ^0
  985|      0|            let Some(wallets) = wallets_w.upgrade() else {
  986|      0|                return;
  987|       |            };
  988|       |
  989|       |            // Republish vote if it is new and the node does not host a principal representative (or close to)
  990|      0|            let processed = results.iter().any(|(_, code)| *code == VoteCode::Vote);
  991|      0|            if processed {
  992|      0|                if wallets.should_republish_vote(vote.voting_account.into()) {
  993|      0|                    let ack = Message::ConfirmAck(ConfirmAck::new_with_rebroadcasted_vote(
  994|      0|                        vote.as_ref().clone(),
  995|      0|                    ));
  996|      0|                    flooder_l
  997|      0|                        .lock()
  998|      0|                        .unwrap()
  999|      0|                        .flood(&ack, TrafficType::VoteRebroadcast, 0.5);
 1000|      0|                }
 1001|      0|            }
 1002|      3|        }));
                      ^0
 1003|      3|
 1004|      3|        let keepalive_factory_w = Arc::downgrade(&keepalive_factory);
 1005|      3|        let message_publisher_l = Arc::new(Mutex::new(message_sender.clone()));
 1006|      3|        let message_publisher_w = Arc::downgrade(&message_publisher_l);
 1007|      3|        network
 1008|      3|            .write()
 1009|      3|            .unwrap()
 1010|      3|            .on_new_realtime_channel(Arc::new(move |channel| {
                                                                           ^0
 1011|       |                // Send a keepalive message to the new channel
 1012|      0|                let Some(factory) = keepalive_factory_w.upgrade() else {
 1013|      0|                    return;
 1014|       |                };
 1015|      0|                let Some(publisher) = message_publisher_w.upgrade() else {
 1016|      0|                    return;
 1017|       |                };
 1018|      0|                let keepalive = factory.create_keepalive_self();
 1019|      0|                publisher.lock().unwrap().try_send(
 1020|      0|                    channel.channel_id(),
 1021|      0|                    &keepalive,
 1022|      0|                    TrafficType::Keepalive,
 1023|      0|                );
 1024|      3|            }));
                          ^0
 1025|      3|
 1026|      3|        let rep_crawler_w = Arc::downgrade(&rep_crawler);
 1027|      3|        let reps_w = Arc::downgrade(&online_reps);
 1028|      3|        let clock = steady_clock.clone();
 1029|      3|        vote_processor.on_vote_processed(Box::new(move |vote, channel_id, source, code| {
 1030|      0|            debug_assert!(code != VoteCode::Invalid);
 1031|      0|            let Some(rep_crawler) = rep_crawler_w.upgrade() else {
 1032|      0|                return;
 1033|       |            };
 1034|      0|            let Some(reps) = reps_w.upgrade() else {
 1035|      0|                return;
 1036|       |            };
 1037|       |            // Ignore republished votes
 1038|      0|            if source != VoteSource::Live {
 1039|      0|                return;
 1040|      0|            }
 1041|      0|
 1042|      0|            let active_in_rep_crawler = rep_crawler.process(vote.clone(), channel_id);
 1043|      0|            if active_in_rep_crawler {
 1044|      0|                // Representative is defined as online if replying to live votes or rep_crawler queries
 1045|      0|                reps.lock()
 1046|      0|                    .unwrap()
 1047|      0|                    .vote_observed(vote.voting_account, clock.now());
 1048|      0|            }
 1049|      3|        }));
                      ^0
 1050|      3|
 1051|      3|        if !distributed_work.work_generation_enabled() {
 1052|      0|            info!("Work generation is disabled");
 1053|      3|        }
 1054|       |
 1055|      3|        info!(
 1056|      0|            "Outbound bandwidth limit: {} bytes/s, burst ratio: {}",
 1057|       |            config.bandwidth_limit, config.bandwidth_limit_burst_ratio
 1058|       |        );
 1059|       |
 1060|      3|        if config.enable_voting {
 1061|      3|            info!(
 1062|      0|                "Voting is enabled, more system resources will be used, local representatives: {}",
 1063|      0|                wallets.voting_reps_count()
 1064|       |            );
 1065|      3|            if wallets.voting_reps_count() > 1 {
 1066|      0|                warn!("Voting with more than one representative can limit performance");
 1067|      3|            }
 1068|      0|        }
 1069|       |
 1070|       |        {
 1071|      3|            let tx = ledger.read_txn();
 1072|      3|            if flags.enable_pruning || ledger.store.pruned.count(&tx) > 0 {
 1073|      0|                ledger.enable_pruning();
 1074|      3|            }
 1075|       |        }
 1076|       |
 1077|      3|        if ledger.pruning_enabled() {
 1078|      0|            if config.enable_voting && !flags.inactive_node {
 1079|      0|                let msg = "Incompatibility detected between config node.enable_voting and existing pruned blocks";
 1080|      0|                error!(msg);
 1081|      0|                panic!("{}", msg);
 1082|      0|            } else if !flags.enable_pruning && !flags.inactive_node {
 1083|      0|                let msg =
 1084|      0|                    "To start node with existing pruned blocks use launch flag --enable_pruning";
 1085|      0|                error!(msg);
 1086|      0|                panic!("{}", msg);
 1087|      0|            }
 1088|      3|        }
 1089|       |
 1090|      3|        let workers_w = Arc::downgrade(&wallet_workers);
 1091|      3|        let wallets_w = Arc::downgrade(&wallets);
 1092|      3|        confirming_set.on_cemented(Box::new(move |block| {
                                                                       ^0
 1093|      0|            let Some(workers) = workers_w.upgrade() else {
 1094|      0|                return;
 1095|       |            };
 1096|      0|            let Some(wallets) = wallets_w.upgrade() else {
 1097|      0|                return;
 1098|       |            };
 1099|       |
 1100|       |            // TODO: Is it neccessary to call this for all blocks?
 1101|      0|            if block.is_send() {
 1102|      0|                let block = block.clone();
 1103|      0|                workers.post(Box::new(move || {
 1104|      0|                    wallets.receive_confirmed(block.hash(), block.destination().unwrap())
 1105|      0|                }));
 1106|      0|            }
 1107|      3|        }));
                      ^0
 1108|       |
 1109|      3|        if let Some(callback_url) = config.rpc_callback_url() {
                                  ^0
 1110|      0|            info!("HTTP callbacks enabled on {:?}", callback_url);
 1111|      0|            let http_callbacks = HttpCallbacks {
 1112|      0|                runtime: runtime.clone(),
 1113|      0|                stats: stats.clone(),
 1114|      0|                callback_url,
 1115|      0|            };
 1116|      0|            active_elections.on_election_ended(Box::new(
 1117|      0|                move |status, _weights, account, block, amount, is_state_send, is_state_epoch| {
 1118|      0|                    http_callbacks.execute(
 1119|      0|                        status,
 1120|      0|                        account,
 1121|      0|                        block,
 1122|      0|                        amount,
 1123|      0|                        is_state_send,
 1124|      0|                        is_state_epoch,
 1125|      0|                    );
 1126|      0|                },
 1127|      0|            ))
 1128|      3|        }
 1129|       |
 1130|      3|        let time_factory = SystemTimeFactory::default();
 1131|       |
 1132|      3|        let peer_cache_updater = PeerCacheUpdater::new(
 1133|      3|            network.clone(),
 1134|      3|            ledger.clone(),
 1135|      3|            time_factory,
 1136|      3|            stats.clone(),
 1137|      3|            if network_params.network.is_dev_network() {
 1138|      3|                Duration::from_secs(10)
 1139|       |            } else {
 1140|      0|                Duration::from_secs(60 * 60)
 1141|       |            },
 1142|       |        );
 1143|       |
 1144|      3|        let peer_cache_connector = PeerCacheConnector::new(
 1145|      3|            ledger.clone(),
 1146|      3|            peer_connector.clone(),
 1147|      3|            stats.clone(),
 1148|      3|            network_params.network.merge_period,
 1149|      3|        );
 1150|      3|
 1151|      3|        let ledger_pruning = Arc::new(LedgerPruning::new(
 1152|      3|            config.clone(),
 1153|      3|            flags.clone(),
 1154|      3|            ledger.clone(),
 1155|      3|            stats.clone(),
 1156|      3|        ));
 1157|      3|
 1158|      3|        let monitor = TimerThread::new(
 1159|      3|            "Monitor",
 1160|      3|            Monitor::new(
 1161|      3|                ledger.clone(),
 1162|      3|                network.clone(),
 1163|      3|                online_reps.clone(),
 1164|      3|                active_elections.clone(),
 1165|      3|            ),
 1166|      3|        );
 1167|      3|
 1168|      3|        let wallet_backup = WalletBackup {
 1169|      3|            data_path: application_path.clone(),
 1170|      3|            backup_interval: Duration::from_secs(network_params.node.backup_interval_m as u64 * 60),
 1171|      3|            workers: workers.clone(),
 1172|      3|            wallets: wallets.clone(),
 1173|      3|        };
 1174|      3|
 1175|      3|        let receivable_search = ReceivableSearch {
 1176|      3|            wallets: wallets.clone(),
 1177|      3|            workers: workers.clone(),
 1178|      3|            interval: Duration::from_secs(network_params.node.search_pending_interval_s as u64),
 1179|      3|        };
 1180|      3|
 1181|      3|        let message_flooder = Arc::new(Mutex::new(message_flooder.clone()));
 1182|      3|
 1183|      3|        let block_flooder = BlockFlooder {
 1184|      3|            message_flooder: message_flooder.clone(),
 1185|      3|            workers: workers.clone(),
 1186|      3|        };
 1187|      3|
 1188|      3|        Self {
 1189|      3|            is_nulled,
 1190|      3|            steady_clock,
 1191|      3|            peer_cache_updater: TimerThread::new("Peer history", peer_cache_updater),
 1192|      3|            peer_cache_connector: TimerThread::new("Net reachout", peer_cache_connector),
 1193|      3|            peer_connector,
 1194|      3|            node_id,
 1195|      3|            workers,
 1196|      3|            wallet_workers,
 1197|      3|            election_workers,
 1198|      3|            distributed_work,
 1199|      3|            unchecked,
 1200|      3|            telemetry,
 1201|      3|            syn_cookies,
 1202|      3|            network,
 1203|      3|            ledger,
 1204|      3|            store,
 1205|      3|            stats,
 1206|      3|            data_path: application_path,
 1207|      3|            network_params,
 1208|      3|            config,
 1209|      3|            flags,
 1210|      3|            work,
 1211|      3|            runtime,
 1212|      3|            bootstrap_responder,
 1213|      3|            online_weight_calculation: TimerThread::new("Online reps", online_weight_calculation),
 1214|      3|            online_reps,
 1215|      3|            rep_tiers,
 1216|      3|            vote_router,
 1217|      3|            vote_processor_queue,
 1218|      3|            history,
 1219|      3|            confirming_set,
 1220|      3|            vote_cache,
 1221|      3|            block_processor,
 1222|      3|            wallets,
 1223|      3|            vote_generators,
 1224|      3|            active: active_elections,
 1225|      3|            vote_processor,
 1226|      3|            vote_cache_processor,
 1227|      3|            rep_crawler,
 1228|      3|            tcp_listener,
 1229|      3|            election_schedulers,
 1230|      3|            request_aggregator,
 1231|      3|            backlog_scan,
 1232|      3|            bounded_backlog,
 1233|      3|            bootstrapper,
 1234|      3|            local_block_broadcaster,
 1235|      3|            ledger_pruning,
 1236|      3|            network_threads,
 1237|      3|            message_processor,
 1238|      3|            inbound_message_queue,
 1239|      3|            monitor,
 1240|      3|            message_sender: message_publisher_l,
 1241|      3|            message_flooder,
 1242|      3|            network_filter,
 1243|      3|            keepalive_publisher,
 1244|      3|            stopped: AtomicBool::new(false),
 1245|      3|            start_stop_listener: OutputListenerMt::new(),
 1246|      3|            wallet_backup,
 1247|      3|            receivable_search,
 1248|      3|            block_flooder,
 1249|      3|            ledger_notification_thread,
 1250|      3|            ledger_notifications,
 1251|      3|        }
 1252|      3|    }
 1253|       |
 1254|      0|    pub fn container_info(&self) -> ContainerInfo {
 1255|      0|        let tcp_channels = self.network.read().unwrap().container_info();
 1256|      0|        let online_reps = self.online_reps.lock().unwrap().container_info();
 1257|      0|        let vote_cache = self.vote_cache.lock().unwrap().container_info();
 1258|      0|
 1259|      0|        let network = ContainerInfo::builder()
 1260|      0|            .node("tcp_channels", tcp_channels)
 1261|      0|            .node("syn_cookies", self.syn_cookies.container_info())
 1262|      0|            .finish();
 1263|      0|
 1264|      0|        ContainerInfo::builder()
 1265|      0|            .node("work", self.work.container_info())
 1266|      0|            .node("ledger", self.ledger.container_info())
 1267|      0|            .node("active", self.active.container_info())
 1268|      0|            .node("network", network)
 1269|      0|            .node("telemetry", self.telemetry.container_info())
 1270|      0|            .node("wallets", self.wallets.container_info())
 1271|      0|            .node("vote_processor", self.vote_processor_queue.container_info())
 1272|      0|            .node(
 1273|      0|                "vote_cache_processor",
 1274|      0|                self.vote_cache_processor.container_info(),
 1275|      0|            )
 1276|      0|            .node("rep_crawler", self.rep_crawler.container_info())
 1277|      0|            .node("block_processor", self.block_processor.container_info())
 1278|      0|            .node("online_reps", online_reps)
 1279|      0|            .node("history", self.history.container_info())
 1280|      0|            .node("confirming_set", self.confirming_set.container_info())
 1281|      0|            .node(
 1282|      0|                "request_aggregator",
 1283|      0|                self.request_aggregator.container_info(),
 1284|      0|            )
 1285|      0|            .node(
 1286|      0|                "election_scheduler",
 1287|      0|                self.election_schedulers.container_info(),
 1288|      0|            )
 1289|      0|            .node("vote_cache", vote_cache)
 1290|      0|            .node("vote_router", self.vote_router.container_info())
 1291|      0|            .node("vote_generators", self.vote_generators.container_info())
 1292|      0|            .node("bootstrap_ascending", self.bootstrapper.container_info())
 1293|      0|            .node("unchecked", self.unchecked.container_info())
 1294|      0|            .node(
 1295|      0|                "local_block_broadcaster",
 1296|      0|                self.local_block_broadcaster.container_info(),
 1297|      0|            )
 1298|      0|            .node("rep_tiers", self.rep_tiers.container_info())
 1299|      0|            .node(
 1300|      0|                "message_processor",
 1301|      0|                self.inbound_message_queue.container_info(),
 1302|      0|            )
 1303|      0|            .node("bounded_backlog", self.bounded_backlog.container_info())
 1304|      0|            .finish()
 1305|      0|    }
 1306|       |
 1307|      0|    pub fn is_stopped(&self) -> bool {
 1308|      0|        self.stopped.load(Ordering::SeqCst)
 1309|      0|    }
 1310|       |
 1311|      0|    pub fn ledger_pruning(&self, batch_size: u64, bootstrap_weight_reached: bool) {
 1312|      0|        self.ledger_pruning
 1313|      0|            .ledger_pruning(batch_size, bootstrap_weight_reached)
 1314|      0|    }
 1315|       |
 1316|      0|    pub fn process_local(&self, block: Block) -> Option<BlockStatus> {
 1317|      0|        let result = self
 1318|      0|            .block_processor
 1319|      0|            .add_blocking(Arc::new(block), BlockSource::Local)
 1320|      0|            .ok()?;
 1321|      0|        match result {
 1322|      0|            Ok(_) => Some(BlockStatus::Progress),
 1323|      0|            Err(status) => Some(status),
 1324|       |        }
 1325|      0|    }
 1326|       |
 1327|      0|    pub fn process(&self, block: Block) -> Result<SavedBlock, BlockStatus> {
 1328|      0|        let _guard = self.ledger.write_queue.wait(Writer::Testing);
 1329|      0|        let mut tx = self.ledger.rw_txn();
 1330|      0|        self.ledger.process(&mut tx, &block)
 1331|      0|    }
 1332|       |
 1333|      0|    pub fn process_multi(&self, blocks: &[Block]) {
 1334|      0|        let _guard = self.ledger.write_queue.wait(Writer::Testing);
 1335|      0|        let mut tx = self.ledger.rw_txn();
 1336|      0|        for (i, block) in blocks.iter().enumerate() {
 1337|      0|            match self.ledger.process(&mut tx, &mut block.clone()) {
 1338|      0|                Ok(_) | Err(BlockStatus::Old) => {}
 1339|      0|                Err(e) => {
 1340|      0|                    panic!("Could not multi-process block index {}: {:?}", i, e);
 1341|       |                }
 1342|       |            }
 1343|       |        }
 1344|      0|    }
 1345|       |
 1346|      0|    pub fn process_and_confirm_multi(&self, blocks: &[Block]) {
 1347|      0|        self.process_multi(blocks);
 1348|      0|        self.confirm_multi(blocks);
 1349|      0|    }
 1350|       |
 1351|      0|    pub fn insert_into_wallet(&self, keys: &PrivateKey) {
 1352|      0|        let wallet_id = self.wallets.wallet_ids()[0];
 1353|      0|        self.wallets
 1354|      0|            .insert_adhoc2(&wallet_id, &keys.raw_key(), true)
 1355|      0|            .unwrap();
 1356|      0|    }
 1357|       |
 1358|      0|    pub fn process_active(&self, block: Block) {
 1359|      0|        self.block_processor.process_active(block);
 1360|      0|    }
 1361|       |
 1362|      0|    pub fn process_local_multi(&self, blocks: &[Block]) {
 1363|      0|        for block in blocks {
 1364|      0|            let status = self.process_local(block.clone()).unwrap();
 1365|      0|            if !matches!(status, BlockStatus::Progress | BlockStatus::Old) {
 1366|      0|                panic!("could not process block!");
 1367|      0|            }
 1368|       |        }
 1369|      0|    }
 1370|       |
 1371|      0|    pub fn block(&self, hash: &BlockHash) -> Option<SavedBlock> {
 1372|      0|        let tx = self.ledger.read_txn();
 1373|      0|        self.ledger.any().get_block(&tx, hash)
 1374|      0|    }
 1375|       |
 1376|      0|    pub fn latest(&self, account: &Account) -> BlockHash {
 1377|      0|        let tx = self.ledger.read_txn();
 1378|      0|        self.ledger
 1379|      0|            .any()
 1380|      0|            .account_head(&tx, account)
 1381|      0|            .unwrap_or_default()
 1382|      0|    }
 1383|       |
 1384|      0|    pub fn get_node_id(&self) -> NodeId {
 1385|      0|        self.node_id.public_key().into()
 1386|      0|    }
 1387|       |
 1388|      0|    pub fn work_generate_dev(&self, root: impl Into<Root>) -> u64 {
 1389|      0|        self.work.generate_dev2(root.into()).unwrap()
 1390|      0|    }
 1391|       |
 1392|      0|    pub fn block_exists(&self, hash: &BlockHash) -> bool {
 1393|      0|        let tx = self.ledger.read_txn();
 1394|      0|        self.ledger.any().block_exists(&tx, hash)
 1395|      0|    }
 1396|       |
 1397|      0|    pub fn blocks_exist(&self, hashes: &[Block]) -> bool {
 1398|      0|        self.block_hashes_exist(hashes.iter().map(|b| b.hash()))
 1399|      0|    }
 1400|       |
 1401|      0|    pub fn block_hashes_exist(&self, hashes: impl IntoIterator<Item = BlockHash>) -> bool {
 1402|      0|        let tx = self.ledger.read_txn();
 1403|      0|        hashes
 1404|      0|            .into_iter()
 1405|      0|            .all(|h| self.ledger.any().block_exists(&tx, &h))
 1406|      0|    }
 1407|       |
 1408|      0|    pub fn balance(&self, account: &Account) -> Amount {
 1409|      0|        let tx = self.ledger.read_txn();
 1410|      0|        self.ledger
 1411|      0|            .any()
 1412|      0|            .account_balance(&tx, account)
 1413|      0|            .unwrap_or_default()
 1414|      0|    }
 1415|       |
 1416|      0|    pub fn confirm_multi(&self, blocks: &[Block]) {
 1417|      0|        for block in blocks {
 1418|      0|            self.confirm(block.hash());
 1419|      0|        }
 1420|      0|    }
 1421|       |
 1422|      0|    pub fn confirm(&self, hash: BlockHash) {
 1423|      0|        let _guard = self.ledger.write_queue.wait(Writer::Testing);
 1424|      0|        let mut tx = self.ledger.rw_txn();
 1425|      0|        self.ledger.confirm(&mut tx, hash);
 1426|      0|    }
 1427|       |
 1428|      0|    pub fn block_confirmed(&self, hash: &BlockHash) -> bool {
 1429|      0|        let tx = self.ledger.read_txn();
 1430|      0|        self.ledger.confirmed().block_exists(&tx, hash)
 1431|      0|    }
 1432|       |
 1433|      0|    pub fn block_hashes_confirmed(&self, blocks: &[BlockHash]) -> bool {
 1434|      0|        let tx = self.ledger.read_txn();
 1435|      0|        blocks
 1436|      0|            .iter()
 1437|      0|            .all(|b| self.ledger.confirmed().block_exists(&tx, b))
 1438|      0|    }
 1439|       |
 1440|      0|    pub fn blocks_confirmed(&self, blocks: &[Block]) -> bool {
 1441|      0|        let tx = self.ledger.read_txn();
 1442|      0|        blocks
 1443|      0|            .iter()
 1444|      0|            .all(|b| self.ledger.confirmed().block_exists(&tx, &b.hash()))
 1445|      0|    }
 1446|       |
 1447|      0|    pub fn flood_block_many(
 1448|      0|        &self,
 1449|      0|        blocks: VecDeque<Block>,
 1450|      0|        callback: Box<dyn FnOnce() + Send + Sync>,
 1451|      0|        delay: Duration,
 1452|      0|    ) {
 1453|      0|        self.block_flooder.flood_block_many(blocks, callback, delay);
 1454|      0|    }
 1455|       |
 1456|      3|    pub fn start(&mut self) {
 1457|      3|        self.start_stop_listener.emit("start");
 1458|      3|        if self.is_nulled {
 1459|      0|            return; // TODO better nullability implementation
 1460|      3|        }
 1461|      3|
 1462|      3|        if !self.ledger.any().block_exists_or_pruned(
 1463|      3|            &self.ledger.read_txn(),
 1464|      3|            &self.network_params.ledger.genesis_block.hash(),
 1465|      3|        ) {
 1466|      0|            error!("Genesis block not found. This commonly indicates a configuration issue, check that the --network or --data_path command line arguments are correct, and also the ledger backend node config option. If using a read-only CLI command a ledger must already exist, start the node with --daemon first.");
 1467|       |
 1468|      0|            if self.network_params.network.is_beta_network() {
 1469|      0|                error!("Beta network may have reset, try clearing database files");
 1470|      0|            }
 1471|       |
 1472|      0|            panic!("Genesis block not found!");
 1473|      3|        }
 1474|      3|
 1475|      3|        self.online_weight_calculation
 1476|      3|            .run_once_then_start(OnlineReps::default_interval_for(
 1477|      3|                self.network_params.network.current_network,
 1478|      3|            ));
 1479|      3|
 1480|      3|        self.network_threads.lock().unwrap().start();
 1481|      3|        self.message_processor.lock().unwrap().start();
 1482|      3|
 1483|      3|        if self.flags.enable_pruning {
 1484|      0|            self.ledger_pruning.start();
 1485|      3|        }
 1486|       |
 1487|      3|        if !self.flags.disable_rep_crawler {
 1488|      3|            self.rep_crawler.start();
 1489|      3|        }
                       ^0
 1490|       |
 1491|      3|        if self.config.tcp.max_inbound_connections > 0
 1492|      3|            && !(self.flags.disable_bootstrap_listener && self.flags.disable_tcp_realtime)
                                                                        ^0
 1493|      3|        {
 1494|      3|            self.tcp_listener.start();
 1495|      3|        } else {
 1496|      0|            warn!("Peering is disabled");
 1497|       |        }
 1498|       |
 1499|      3|        if !self.flags.disable_backup {
 1500|      3|            self.wallet_backup.start();
 1501|      3|        }
                       ^0
 1502|       |
 1503|      3|        if !self.flags.disable_search_pending {
 1504|      3|            self.receivable_search.start();
 1505|      3|        }
                       ^0
 1506|       |
 1507|      3|        self.unchecked.start();
 1508|      3|        self.wallets.start();
 1509|      3|        self.rep_tiers.start();
 1510|      3|        if self.config.enable_vote_processor {
 1511|      3|            self.vote_processor.start();
 1512|      3|        }
                       ^0
 1513|      3|        self.vote_cache_processor.start();
 1514|      3|        self.block_processor.start();
 1515|      3|        self.active.start();
 1516|      3|        self.vote_generators.start();
 1517|      3|        self.request_aggregator.start();
 1518|      3|        self.confirming_set.start();
 1519|      3|        self.election_schedulers.start();
 1520|      3|        self.backlog_scan.start();
 1521|      3|        if self.config.enable_bounded_backlog {
 1522|      3|            self.bounded_backlog.start();
 1523|      3|        }
                       ^0
 1524|      3|        self.bootstrap_responder.start();
 1525|      3|        self.bootstrapper
 1526|      3|            .initialize(&self.network_params.ledger.genesis_account);
 1527|      3|        self.bootstrapper.start();
 1528|      3|        self.telemetry.start();
 1529|      3|        self.stats.start();
 1530|      3|        self.local_block_broadcaster.start();
 1531|       |
 1532|      3|        let peer_cache_update_interval = if self.network_params.network.is_dev_network() {
 1533|      3|            Duration::from_secs(1)
 1534|       |        } else {
 1535|      0|            Duration::from_secs(15)
 1536|       |        };
 1537|      3|        self.peer_cache_updater
 1538|      3|            .start_delayed(peer_cache_update_interval);
 1539|      3|        self.ledger_notification_thread.start();
 1540|      3|
 1541|      3|        if !self.network_params.network.merge_period.is_zero() {
 1542|      3|            self.peer_cache_connector
 1543|      3|                .start(self.network_params.network.merge_period);
 1544|      3|        }
                       ^0
 1545|      3|        self.vote_router.start();
 1546|      3|
 1547|      3|        if self.config.enable_monitor {
 1548|      3|            self.monitor.start_delayed(self.config.monitor.interval);
 1549|      3|        }
                       ^0
 1550|      3|    }
 1551|       |
 1552|      4|    pub fn stop(&mut self) {
 1553|      4|        self.start_stop_listener.emit("stop");
 1554|      4|        if self.is_nulled {
 1555|      0|            return; // TODO better nullability implementation
 1556|      4|        }
 1557|      4|
 1558|      4|        // Ensure stop can only be called once
 1559|      4|        if self.stopped.swap(true, Ordering::SeqCst) {
 1560|      1|            return;
 1561|      3|        }
 1562|      3|        info!("Node stopping...");
                            ^0
 1563|       |
 1564|      3|        self.tcp_listener.stop();
 1565|      3|        self.ledger_notification_thread.stop();
 1566|      3|        self.online_weight_calculation.stop();
 1567|      3|        self.vote_router.stop();
 1568|      3|        self.peer_connector.stop();
 1569|      3|        self.ledger_pruning.stop();
 1570|      3|        self.peer_cache_connector.stop();
 1571|      3|        self.peer_cache_updater.stop();
 1572|      3|        // Cancels ongoing work generation tasks, which may be blocking other threads
 1573|      3|        // No tasks may wait for work generation in I/O threads, or termination signal capturing will be unable to call node::stop()
 1574|      3|        self.distributed_work.stop();
 1575|      3|        self.backlog_scan.stop();
 1576|      3|        self.bootstrapper.stop();
 1577|      3|        self.bounded_backlog.stop();
 1578|      3|        self.rep_crawler.stop();
 1579|      3|        self.unchecked.stop();
 1580|      3|        self.block_processor.stop();
 1581|      3|        self.request_aggregator.stop();
 1582|      3|        self.vote_cache_processor.stop();
 1583|      3|        self.vote_processor.stop();
 1584|      3|        self.rep_tiers.stop();
 1585|      3|        self.election_schedulers.stop();
 1586|      3|        self.active.stop();
 1587|      3|        self.vote_generators.stop();
 1588|      3|        self.confirming_set.stop();
 1589|      3|        self.telemetry.stop();
 1590|      3|        self.bootstrap_responder.stop();
 1591|      3|        self.wallets.stop();
 1592|      3|        self.stats.stop();
 1593|      3|        self.local_block_broadcaster.stop();
 1594|      3|        self.message_processor.lock().unwrap().stop();
 1595|      3|        self.network_threads.lock().unwrap().stop(); // Stop network last to avoid killing in-use sockets
 1596|      3|        self.monitor.stop();
 1597|      3|
 1598|      3|        self.wallet_workers.stop();
 1599|      3|        self.election_workers.stop();
 1600|      3|        self.workers.stop();
 1601|       |
 1602|       |        // work pool is not stopped on purpose due to testing setup
 1603|      4|    }
 1604|       |}
 1605|       |
 1606|      3|fn make_store(
 1607|      3|    path: &Path,
 1608|      3|    add_db_postfix: bool,
 1609|      3|    txn_tracking_config: &TxnTrackingConfig,
 1610|      3|    block_processor_batch_max_time: Duration,
 1611|      3|    lmdb_config: LmdbConfig,
 1612|      3|    backup_before_upgrade: bool,
 1613|      3|) -> anyhow::Result<Arc<LmdbStore>> {
 1614|      3|    let mut path = PathBuf::from(path);
 1615|      3|    if add_db_postfix {
 1616|      3|        path.push("data.ldb");
 1617|      3|    }
                   ^0
 1618|       |
 1619|      3|    let txn_tracker: Arc<dyn TransactionTracker> = if txn_tracking_config.enable {
 1620|      0|        Arc::new(LongRunningTransactionLogger::new(
 1621|      0|            txn_tracking_config.clone(),
 1622|      0|            block_processor_batch_max_time,
 1623|      0|        ))
 1624|       |    } else {
 1625|      3|        Arc::new(NullTransactionTracker::new())
 1626|       |    };
 1627|       |
 1628|      3|    let options = EnvOptions {
 1629|      3|        config: lmdb_config,
 1630|      3|        use_no_mem_init: true,
 1631|      3|    };
 1632|       |
 1633|      3|    let store = LmdbStore::open(&path)
 1634|      3|        .options(&options)
 1635|      3|        .backup_before_upgrade(backup_before_upgrade)
 1636|      3|        .txn_tracker(txn_tracker)
 1637|      3|        .build()?;
                              ^0
 1638|      3|    Ok(Arc::new(store))
 1639|      3|}
 1640|       |
 1641|       |#[cfg(test)]
 1642|       |mod tests {
 1643|       |    use super::*;
 1644|       |    use crate::{
 1645|       |        utils::{TimerStartEvent, TimerStartType},
 1646|       |        NodeBuilder,
 1647|       |    };
 1648|       |    use rsnano_core::Networks;
 1649|       |    use std::ops::{Deref, DerefMut};
 1650|       |    use uuid::Uuid;
 1651|       |
 1652|       |    #[tokio::test]
 1653|      1|    async fn start_peer_cache_updater() {
 1654|      1|        let mut node = TestNode::new().await;
 1655|      1|        let start_tracker = node.peer_cache_updater.track_start();
 1656|      1|
 1657|      1|        node.start();
 1658|      1|
 1659|      1|        assert_eq!(
 1660|      1|            start_tracker.output(),
 1661|      1|            vec![TimerStartEvent {
 1662|      1|                thread_name: "Peer history".to_string(),
 1663|      1|                interval: Duration::from_secs(1),
 1664|      1|                start_type: TimerStartType::StartDelayed
 1665|      1|            }]
 1666|      1|        );
 1667|      1|    }
 1668|       |
 1669|       |    #[tokio::test]
 1670|      1|    async fn start_peer_cache_connector() {
 1671|      1|        let mut node = TestNode::new().await;
 1672|      1|        let start_tracker = node.peer_cache_connector.track_start();
 1673|      1|
 1674|      1|        node.start();
 1675|      1|
 1676|      1|        assert_eq!(
 1677|      1|            start_tracker.output(),
 1678|      1|            vec![TimerStartEvent {
 1679|      1|                thread_name: "Net reachout".to_string(),
 1680|      1|                interval: node.network_params.network.merge_period,
 1681|      1|                start_type: TimerStartType::Start
 1682|      1|            }]
 1683|      1|        );
 1684|      1|    }
 1685|       |
 1686|       |    #[tokio::test]
 1687|      1|    async fn stop_node() {
 1688|      1|        let mut node = TestNode::new().await;
 1689|      1|        node.start();
 1690|      1|
 1691|      1|        node.stop();
 1692|      1|
 1693|      1|        assert_eq!(
 1694|      1|            node.peer_cache_updater.is_running(),
 1695|      1|            false,
 1696|      1|            "peer_cache_updater running"
                          ^0
 1697|      1|        );
 1698|      1|        assert_eq!(
 1699|      1|            node.peer_cache_connector.is_running(),
 1700|      1|            false,
 1701|      1|            "peer_cache_connector running"
                          ^0
 1702|      1|        );
 1703|      1|    }
 1704|       |
 1705|       |    struct TestNode {
 1706|       |        app_path: PathBuf,
 1707|       |        node: Node,
 1708|       |    }
 1709|       |
 1710|       |    impl TestNode {
 1711|      3|        pub async fn new() -> Self {
 1712|      3|            let mut app_path = std::env::temp_dir();
 1713|      3|            app_path.push(format!("rsnano-test-{}", Uuid::new_v4().simple()));
 1714|      3|            let config = NodeConfig::new_test_instance();
 1715|      3|            let network_params = NetworkParams::new(Networks::NanoDevNetwork);
 1716|      3|            let work = Arc::new(WorkPoolImpl::new(
 1717|      3|                network_params.work.clone(),
 1718|      3|                1,
 1719|      3|                Duration::ZERO,
 1720|      3|            ));
 1721|      3|
 1722|      3|            let node = NodeBuilder::new(Networks::NanoDevNetwork)
 1723|      3|                .data_path(app_path.clone())
 1724|      3|                .config(config)
 1725|      3|                .network_params(network_params)
 1726|      3|                .work(work)
 1727|      3|                .finish()
 1728|      3|                .unwrap();
 1729|      3|
 1730|      3|            Self { node, app_path }
 1731|      3|        }
 1732|       |    }
 1733|       |
 1734|       |    impl Drop for TestNode {
 1735|      3|        fn drop(&mut self) {
 1736|      3|            self.node.stop();
 1737|      3|            std::fs::remove_dir_all(&self.app_path).unwrap();
 1738|      3|        }
 1739|       |    }
 1740|       |
 1741|       |    impl Deref for TestNode {
 1742|       |        type Target = Node;
 1743|       |
 1744|      5|        fn deref(&self) -> &Self::Target {
 1745|      5|            &self.node
 1746|      5|        }
 1747|       |    }
 1748|       |
 1749|       |    impl DerefMut for TestNode {
 1750|      4|        fn deref_mut(&mut self) -> &mut Self::Target {
 1751|      4|            &mut self.node
 1752|      4|        }
 1753|       |    }
 1754|       |}

/home/gustav/code/nano/rsnano-node/node/src/node_builder.rs:
    1|       |use crate::{
    2|       |    config::{get_node_toml_config_path, DaemonConfig, DaemonToml, NodeConfig, NodeFlags},
    3|       |    consensus::{ElectionEndCallback, ElectionStatus, VoteProcessedCallback2},
    4|       |    transport::MessageCallback,
    5|       |    working_path_for, NetworkParams, Node, NodeArgs,
    6|       |};
    7|       |use rsnano_core::{
    8|       |    utils::get_cpu_count, work::WorkPoolImpl, Account, Amount, Networks, SavedBlock, Vote,
    9|       |    VoteCode, VoteSource, VoteWithWeightInfo,
   10|       |};
   11|       |use rsnano_messages::Message;
   12|       |use rsnano_network::ChannelId;
   13|       |use std::{path::PathBuf, sync::Arc, time::Duration};
   14|       |
   15|       |#[derive(Default)]
   16|       |pub struct NodeCallbacks {
   17|       |    pub on_election_end: Option<ElectionEndCallback>,
   18|       |    pub on_vote: Option<VoteProcessedCallback2>,
   19|       |    pub on_publish: Option<MessageCallback>,
   20|       |    pub on_inbound: Option<MessageCallback>,
   21|       |    pub on_inbound_dropped: Option<MessageCallback>,
   22|       |}
   23|       |
   24|       |impl NodeCallbacks {
   25|      0|    pub fn builder() -> NodeCallbacksBuilder {
   26|      0|        NodeCallbacksBuilder::new()
   27|      0|    }
   28|       |}
   29|       |
   30|       |pub struct NodeCallbacksBuilder(NodeCallbacks);
   31|       |
   32|       |impl NodeCallbacksBuilder {
   33|      0|    fn new() -> Self {
   34|      0|        Self(NodeCallbacks::default())
   35|      0|    }
   36|       |
   37|      0|    pub fn on_election_end(
   38|      0|        mut self,
   39|      0|        callback: impl Fn(&ElectionStatus, &Vec<VoteWithWeightInfo>, Account, &SavedBlock, Amount, bool, bool)
   40|      0|            + Send
   41|      0|            + Sync
   42|      0|            + 'static,
   43|      0|    ) -> Self {
   44|      0|        self.0.on_election_end = Some(Box::new(callback));
   45|      0|        self
   46|      0|    }
   47|       |
   48|      0|    pub fn on_vote(
   49|      0|        mut self,
   50|      0|        callback: impl Fn(&Arc<Vote>, ChannelId, VoteSource, VoteCode) + Send + Sync + 'static,
   51|      0|    ) -> Self {
   52|      0|        self.0.on_vote = Some(Box::new(callback));
   53|      0|        self
   54|      0|    }
   55|       |
   56|      0|    pub fn on_publish(
   57|      0|        mut self,
   58|      0|        callback: impl Fn(ChannelId, &Message) + Send + Sync + 'static,
   59|      0|    ) -> Self {
   60|      0|        self.0.on_publish = Some(Arc::new(callback));
   61|      0|        self
   62|      0|    }
   63|       |
   64|      0|    pub fn on_inbound(
   65|      0|        mut self,
   66|      0|        callback: impl Fn(ChannelId, &Message) + Send + Sync + 'static,
   67|      0|    ) -> Self {
   68|      0|        self.0.on_inbound = Some(Arc::new(callback));
   69|      0|        self
   70|      0|    }
   71|       |
   72|      0|    pub fn on_inbound_dropped(
   73|      0|        mut self,
   74|      0|        callback: impl Fn(ChannelId, &Message) + Send + Sync + 'static,
   75|      0|    ) -> Self {
   76|      0|        self.0.on_inbound_dropped = Some(Arc::new(callback));
   77|      0|        self
   78|      0|    }
   79|       |
   80|      0|    pub fn finish(self) -> NodeCallbacks {
   81|      0|        self.0
   82|      0|    }
   83|       |}
   84|       |
   85|       |pub struct NodeBuilder {
   86|       |    network: Networks,
   87|       |    runtime: Option<tokio::runtime::Handle>,
   88|       |    data_path: Option<PathBuf>,
   89|       |    config: Option<NodeConfig>,
   90|       |    network_params: Option<NetworkParams>,
   91|       |    flags: Option<NodeFlags>,
   92|       |    work: Option<Arc<WorkPoolImpl>>,
   93|       |    callbacks: Option<NodeCallbacks>,
   94|       |}
   95|       |
   96|       |impl NodeBuilder {
   97|      3|    pub fn new(network: Networks) -> Self {
   98|      3|        Self {
   99|      3|            network,
  100|      3|            runtime: None,
  101|      3|            data_path: None,
  102|      3|            config: None,
  103|      3|            network_params: None,
  104|      3|            flags: None,
  105|      3|            work: None,
  106|      3|            callbacks: None,
  107|      3|        }
  108|      3|    }
  109|       |
  110|      0|    pub fn runtime(mut self, runtime: tokio::runtime::Handle) -> Self {
  111|      0|        self.runtime = Some(runtime);
  112|      0|        self
  113|      0|    }
  114|       |
  115|      3|    pub fn data_path(mut self, path: impl Into<PathBuf>) -> Self {
  116|      3|        self.data_path = Some(path.into());
  117|      3|        self
  118|      3|    }
  119|       |
  120|      3|    pub fn config(mut self, config: NodeConfig) -> Self {
  121|      3|        self.config = Some(config);
  122|      3|        self
  123|      3|    }
  124|       |
  125|      3|    pub fn network_params(mut self, network_params: NetworkParams) -> Self {
  126|      3|        self.network_params = Some(network_params);
  127|      3|        self
  128|      3|    }
  129|       |
  130|      0|    pub fn flags(mut self, flags: NodeFlags) -> Self {
  131|      0|        self.flags = Some(flags);
  132|      0|        self
  133|      0|    }
  134|       |
  135|      3|    pub fn work(mut self, work: Arc<WorkPoolImpl>) -> Self {
  136|      3|        self.work = Some(work);
  137|      3|        self
  138|      3|    }
  139|       |
  140|      0|    pub fn callbacks(mut self, callbacks: NodeCallbacks) -> Self {
  141|      0|        self.callbacks = Some(callbacks);
  142|      0|        self
  143|      0|    }
  144|       |
  145|      3|    pub fn get_data_path(&self) -> anyhow::Result<PathBuf> {
  146|      3|        match &self.data_path {
  147|      3|            Some(path) => Ok(path.clone()),
  148|      0|            None => working_path_for(self.network).ok_or_else(|| anyhow!("working path not found")),
  149|       |        }
  150|      3|    }
  151|       |
  152|      3|    pub fn finish(self) -> anyhow::Result<Node> {
  153|      3|        let data_path = self.get_data_path()?;
                                                          ^0
  154|      3|        let runtime = self
  155|      3|            .runtime
  156|      3|            .unwrap_or_else(|| tokio::runtime::Handle::current());
  157|      3|
  158|      3|        let network_params = self
  159|      3|            .network_params
  160|      3|            .unwrap_or_else(|| NetworkParams::new(self.network));
                                             ^0
  161|       |
  162|      3|        let config = match self.config {
  163|      3|            Some(c) => c,
  164|       |            None => {
  165|      0|                let cpu_count = get_cpu_count();
  166|      0|                let mut daemon_config = DaemonConfig::new(&network_params, cpu_count);
  167|      0|                let config_path = get_node_toml_config_path(&data_path);
  168|      0|                if config_path.exists() {
  169|      0|                    let toml_str = std::fs::read_to_string(config_path)?;
  170|      0|                    let daemon_toml: DaemonToml = toml::de::from_str(&toml_str)?;
  171|      0|                    daemon_config.merge_toml(&daemon_toml);
  172|      0|                }
  173|      0|                daemon_config.node
  174|       |            }
  175|       |        };
  176|       |
  177|      3|        let flags = self.flags.unwrap_or_default();
  178|      3|        let work = self.work.unwrap_or_else(|| {
  179|      0|            Arc::new(WorkPoolImpl::new(
  180|      0|                network_params.work.clone(),
  181|      0|                config.work_threads as usize,
  182|      0|                Duration::from_nanos(config.pow_sleep_interval_ns as u64),
  183|      0|            ))
  184|      3|        });
  185|      3|
  186|      3|        let callbacks = self.callbacks.unwrap_or_default();
  187|      3|
  188|      3|        let args = NodeArgs {
  189|      3|            runtime,
  190|      3|            data_path,
  191|      3|            config,
  192|      3|            network_params,
  193|      3|            flags,
  194|      3|            work,
  195|      3|            callbacks,
  196|      3|        };
  197|      3|
  198|      3|        Ok(Node::new_with_args(args))
  199|      3|    }
  200|       |}

/home/gustav/code/nano/rsnano-node/node/src/node_id_key_file.rs:
    1|       |use anyhow::Context;
    2|       |use rsnano_core::{PrivateKey, PrivateKeyFactory};
    3|       |use rsnano_nullable_fs::NullableFilesystem;
    4|       |use std::path::{Path, PathBuf};
    5|       |use tracing::info;
    6|       |
    7|       |/// The node creates a file called 'node_id_private.key' on its first start.
    8|       |/// In this file the private key of the node id is stored.
    9|       |#[derive(Default)]
   10|       |pub(crate) struct NodeIdKeyFile {
   11|       |    key_factory: PrivateKeyFactory,
   12|       |    fs: NullableFilesystem,
   13|       |}
   14|       |
   15|       |impl NodeIdKeyFile {
   16|       |    #[allow(dead_code)]
   17|     10|    fn new(fs: NullableFilesystem, key_factory: PrivateKeyFactory) -> Self {
   18|     10|        Self { fs, key_factory }
   19|     10|    }
   20|       |
   21|      0|    pub fn new_null() -> Self {
   22|      0|        Self::new(
   23|      0|            NullableFilesystem::new_null(),
   24|      0|            PrivateKeyFactory::new_null(),
   25|      0|        )
   26|      0|    }
   27|       |
   28|     13|    pub fn initialize(&mut self, app_path: impl AsRef<Path>) -> anyhow::Result<PrivateKey> {
   29|     13|        let app_path = app_path.as_ref();
   30|     13|        let file_path = Self::key_file_path(app_path);
   31|     13|        if self.fs.exists(&file_path) {
   32|      5|            self.load_key(&file_path)
   33|       |        } else {
   34|      8|            self.create_key(app_path, &file_path)
   35|       |        }
   36|     13|    }
   37|       |
   38|     21|    fn key_file_path(app_path: &Path) -> PathBuf {
   39|     21|        let mut key_file = PathBuf::from(app_path);
   40|     21|        key_file.push("node_id_private.key");
   41|     21|        key_file
   42|     21|    }
   43|       |
   44|      5|    fn load_key(&mut self, file_path: &Path) -> anyhow::Result<PrivateKey> {
   45|      5|        info!("Reading node id from: {:?}", file_path);
                            ^0
   46|       |
   47|      5|        let content = self
                          ^4
   48|      5|            .fs
   49|      5|            .read_to_string(&file_path)
   50|      5|            .context(format!("Could not read node id file {:?}", file_path))?;
                                                                                          ^1
   51|       |
   52|      4|        let first_line = content.lines().next().unwrap_or("");
   53|      4|        PrivateKey::from_hex_str(first_line).context(format!(
   54|      4|            "Could not decode node id key from file {:?}",
   55|      4|            file_path
   56|      4|        ))
   57|      5|    }
   58|       |
   59|      8|    fn create_key(&mut self, app_path: &Path, file_path: &Path) -> anyhow::Result<PrivateKey> {
   60|      8|        info!("Generating a new node id, saving to: {:?}", file_path);
                            ^0
   61|       |
   62|      8|        self.fs
   63|      8|            .create_dir_all(app_path)
   64|      8|            .context(format!("Could not create app dir: {:?}", app_path))?;
                                                                                       ^1
   65|       |
   66|      7|        let keypair = self.key_factory.create_key();
   67|      7|
   68|      7|        self.fs
   69|      7|            .write(
   70|      7|                file_path,
   71|      7|                format!("{}\n", keypair.raw_key().encode_hex()).as_bytes(),
   72|      7|            )
   73|      7|            .context(format!("Could not write node id key file: {:?}", file_path))?;
                                                                                                ^1
   74|       |
   75|      6|        Ok(keypair)
   76|      8|    }
   77|       |}
   78|       |
   79|       |#[cfg(test)]
   80|       |mod tests {
   81|       |    use super::*;
   82|       |    use rsnano_core::RawKey;
   83|       |    use rsnano_nullable_fs::FsEvent;
   84|       |    use std::io::ErrorKind;
   85|       |    use tracing_test::traced_test;
   86|       |
   87|       |    static EXPECTED_KEY: RawKey = RawKey::from_bytes([42; 32]);
   88|       |
   89|       |    #[test]
   90|      1|    fn node_id_key_file_path() {
   91|      1|        assert_eq!(
   92|      1|            NodeIdKeyFile::key_file_path(&PathBuf::from("/path/to/node")),
   93|      1|            PathBuf::from("/path/to/node/node_id_private.key")
   94|      1|        );
   95|      1|    }
   96|       |
   97|       |    mod key_file_exists {
   98|       |        use super::*;
   99|       |
  100|       |        #[test]
  101|      1|        fn load_key_from_file() {
  102|      1|            let (key_pair, _) = initialize_node_id_with_valid_existing_file();
  103|      1|            assert_eq!(key_pair.unwrap().raw_key(), EXPECTED_KEY);
  104|      1|        }
  105|       |
  106|       |        #[test]
  107|      1|        fn dont_change_the_filesystem() {
  108|      1|            let (_, fs_events) = initialize_node_id_with_valid_existing_file();
  109|      1|            assert!(fs_events.is_empty());
  110|      1|        }
  111|       |
  112|       |        #[test]
  113|      1|        #[traced_test]
  114|      1|        fn log_reading_file() {
  115|      1|            let _ = initialize_node_id_with_valid_existing_file();
  116|      1|            assert!(logs_contain(
  117|      1|                "Reading node id from: \"/path/to/node/node_id_private.key\""
  118|      1|            ));
  119|      1|        }
  120|       |
  121|       |        #[test]
  122|      1|        fn fail_if_file_is_inaccessable() {
  123|      1|            let fs = fs_with_inaccessable_key_file();
  124|      1|            let (Err(err), _) = initialize_node_id(fs, PrivateKeyFactory::new_null()) else {
  125|      0|                panic!("initialization should fail")
  126|       |            };
  127|      1|            assert_eq!(
  128|      1|                err.to_string(),
  129|      1|                "Could not read node id file \"/path/to/node/node_id_private.key\""
  130|      1|            )
  131|      1|        }
  132|       |
  133|       |        #[test]
  134|      1|        fn fail_if_file_cannot_be_parsed() {
  135|      1|            let fs = fs_with_key_file("invalid file content");
  136|      1|            let (Err(err), _) = initialize_node_id(fs, PrivateKeyFactory::new_null()) else {
  137|      0|                panic!("initialization should fail")
  138|       |            };
  139|      1|            assert_eq!(
  140|      1|                err.to_string(),
  141|      1|                "Could not decode node id key from file \"/path/to/node/node_id_private.key\""
  142|      1|            )
  143|      1|        }
  144|       |    }
  145|       |
  146|       |    mod no_file_exists_yet {
  147|       |        use super::*;
  148|       |
  149|       |        #[test]
  150|      1|        fn create_new_node_id() {
  151|      1|            let (key_pair, _) = initialize_node_id_without_existing_file();
  152|      1|            assert_eq!(key_pair.unwrap().raw_key(), EXPECTED_KEY);
  153|      1|        }
  154|       |
  155|       |        #[test]
  156|      1|        fn create_file_with_private_key() {
  157|      1|            let (_, fs_events) = initialize_node_id_without_existing_file();
  158|      1|            assert_eq!(fs_events.len(), 2);
  159|      1|            assert_eq!(fs_events[0], FsEvent::create_dir_all(test_app_path()));
  160|      1|            assert_eq!(
  161|      1|                fs_events[1],
  162|      1|                FsEvent::write(
  163|      1|                    test_key_file_path(),
  164|      1|                    format!("{}\n", EXPECTED_KEY.encode_hex())
  165|      1|                )
  166|      1|            );
  167|      1|        }
  168|       |
  169|       |        #[test]
  170|      0|        #[traced_test]
  171|      1|        fn log_file_creation() {
  172|      1|            let _ = initialize_node_id_without_existing_file();
  173|      1|            assert!(logs_contain(
  174|      1|                "Generating a new node id, saving to: \"/path/to/node/node_id_private.key\""
  175|      1|            ));
  176|      1|        }
  177|       |
  178|       |        #[test]
  179|      1|        fn fail_if_directory_cannot_be_created() {
  180|      1|            let fs = NullableFilesystem::null_builder()
  181|      1|                .create_dir_all_fails(
  182|      1|                    test_app_path(),
  183|      1|                    std::io::Error::new(ErrorKind::PermissionDenied, ""),
  184|      1|                )
  185|      1|                .finish();
  186|       |
  187|      1|            let (Err(err), _) = initialize_node_id(fs, PrivateKeyFactory::new_null()) else {
  188|      0|                panic!("should fail");
  189|       |            };
  190|      1|            assert_eq!(
  191|      1|                err.to_string(),
  192|      1|                "Could not create app dir: \"/path/to/node\""
  193|      1|            );
  194|      1|        }
  195|       |
  196|       |        #[test]
  197|      1|        fn fail_if_file_cannot_be_written() {
  198|      1|            let fs = NullableFilesystem::null_builder()
  199|      1|                .write_fails(
  200|      1|                    test_key_file_path(),
  201|      1|                    std::io::Error::new(ErrorKind::PermissionDenied, ""),
  202|      1|                )
  203|      1|                .finish();
  204|       |
  205|      1|            let (Err(err), _) = initialize_node_id(fs, PrivateKeyFactory::new_null()) else {
  206|      0|                panic!("should fail");
  207|       |            };
  208|      1|            assert_eq!(
  209|      1|                err.to_string(),
  210|      1|                "Could not write node id key file: \"/path/to/node/node_id_private.key\""
  211|      1|            );
  212|      1|        }
  213|       |    }
  214|       |
  215|      3|    fn initialize_node_id_without_existing_file() -> (anyhow::Result<PrivateKey>, Vec<FsEvent>) {
  216|      3|        let fs = NullableFilesystem::new_null();
  217|      3|        let key_pair_factory = PrivateKeyFactory::new_null_with(EXPECTED_KEY);
  218|      3|        initialize_node_id(fs, key_pair_factory)
  219|      3|    }
  220|       |
  221|      3|    fn initialize_node_id_with_valid_existing_file() -> (anyhow::Result<PrivateKey>, Vec<FsEvent>) {
  222|      3|        let fs = fs_with_key_file(format!("{}\n", EXPECTED_KEY.encode_hex()));
  223|      3|        initialize_node_id(fs, PrivateKeyFactory::new_null())
  224|      3|    }
  225|       |
  226|     10|    fn initialize_node_id(
  227|     10|        fs: NullableFilesystem,
  228|     10|        key_pair_factory: PrivateKeyFactory,
  229|     10|    ) -> (anyhow::Result<PrivateKey>, Vec<FsEvent>) {
  230|     10|        let fs_tracker = fs.track();
  231|     10|        let mut id_file = NodeIdKeyFile::new(fs, key_pair_factory);
  232|     10|        let key_pair = id_file.initialize(&test_app_path());
  233|     10|        let fs_events = fs_tracker.output();
  234|     10|        (key_pair, fs_events)
  235|     10|    }
  236|       |
  237|     19|    fn test_app_path() -> PathBuf {
  238|     19|        PathBuf::from("/path/to/node")
  239|     19|    }
  240|       |
  241|      7|    fn test_key_file_path() -> PathBuf {
  242|      7|        NodeIdKeyFile::key_file_path(&test_app_path())
  243|      7|    }
  244|       |
  245|      1|    fn fs_with_inaccessable_key_file() -> NullableFilesystem {
  246|      1|        let file_path = test_key_file_path();
  247|      1|        NullableFilesystem::null_builder()
  248|      1|            .path_exists(&file_path)
  249|      1|            .read_to_string_fails(
  250|      1|                &file_path,
  251|      1|                std::io::Error::new(ErrorKind::PermissionDenied, ""),
  252|      1|            )
  253|      1|            .finish()
  254|      1|    }
  255|       |
  256|      4|    fn fs_with_key_file(contents: impl Into<String>) -> NullableFilesystem {
  257|      4|        let file_path = test_key_file_path();
  258|      4|        NullableFilesystem::null_builder()
  259|      4|            .path_exists(&file_path)
  260|      4|            .read_to_string(&file_path, contents.into())
  261|      4|            .finish()
  262|      4|    }
  263|       |}

/home/gustav/code/nano/rsnano-node/node/src/pruning.rs:
    1|       |use crate::{
    2|       |    config::{NodeConfig, NodeFlags},
    3|       |    stats::{DetailType, StatType, Stats},
    4|       |    utils::{ThreadPool, ThreadPoolImpl},
    5|       |};
    6|       |use rsnano_core::{utils::UnixTimestamp, Account, BlockHash};
    7|       |use rsnano_ledger::{Ledger, Writer};
    8|       |use rsnano_store_lmdb::Transaction;
    9|       |use std::{
   10|       |    collections::VecDeque,
   11|       |    sync::{
   12|       |        atomic::{AtomicBool, Ordering},
   13|       |        Arc,
   14|       |    },
   15|       |    time::{Duration, SystemTime},
   16|       |};
   17|       |use tracing::debug;
   18|       |
   19|       |pub struct LedgerPruning {
   20|       |    config: NodeConfig,
   21|       |    flags: NodeFlags,
   22|       |    ledger: Arc<Ledger>,
   23|       |    stopped: AtomicBool,
   24|       |    workers: Arc<dyn ThreadPool>,
   25|       |    stats: Arc<Stats>,
   26|       |}
   27|       |
   28|       |impl LedgerPruning {
   29|      3|    pub fn new(
   30|      3|        config: NodeConfig,
   31|      3|        flags: NodeFlags,
   32|      3|        ledger: Arc<Ledger>,
   33|      3|        stats: Arc<Stats>,
   34|      3|    ) -> Self {
   35|      3|        Self {
   36|      3|            config,
   37|      3|            flags,
   38|      3|            ledger,
   39|      3|            workers: Arc::new(ThreadPoolImpl::create(1, "Pruning")),
   40|      3|            stats,
   41|      3|            stopped: AtomicBool::new(false),
   42|      3|        }
   43|      3|    }
   44|       |
   45|      3|    pub fn stop(&self) {
   46|      3|        self.stopped.store(true, Ordering::SeqCst);
   47|      3|        self.workers.stop();
   48|      3|    }
   49|       |
   50|      0|    pub fn ledger_pruning(&self, batch_size_a: u64, bootstrap_weight_reached: bool) {
   51|      0|        self.stats.inc(StatType::Pruning, DetailType::LedgerPruning);
   52|       |
   53|      0|        let max_depth = if self.config.max_pruning_depth != 0 {
   54|      0|            self.config.max_pruning_depth
   55|       |        } else {
   56|      0|            u64::MAX
   57|       |        };
   58|      0|        let cutoff_time: UnixTimestamp = if bootstrap_weight_reached {
   59|      0|            (SystemTime::now() - Duration::from_secs(self.config.max_pruning_age_s as u64))
   60|      0|                .try_into()
   61|      0|                .unwrap()
   62|       |        } else {
   63|      0|            UnixTimestamp::MAX
   64|       |        };
   65|      0|        let mut pruned_count = 0;
   66|      0|        let mut transaction_write_count = 0;
   67|      0|        let mut last_account = Account::from(1); // 0 Burn account is never opened. So it can be used to break loop
   68|      0|        let mut pruning_targets = VecDeque::new();
   69|      0|        let mut target_finished = false;
   70|      0|        while (transaction_write_count != 0 || !target_finished)
   71|      0|            && !self.stopped.load(Ordering::SeqCst)
   72|       |        {
   73|       |            // Search pruning targets
   74|      0|            while pruning_targets.len() < batch_size_a as usize
   75|      0|                && !target_finished
   76|      0|                && !self.stopped.load(Ordering::SeqCst)
   77|      0|            {
   78|      0|                self.stats
   79|      0|                    .inc(StatType::Pruning, DetailType::CollectTargets);
   80|      0|                target_finished = self.collect_ledger_pruning_targets(
   81|      0|                    &mut pruning_targets,
   82|      0|                    &mut last_account,
   83|      0|                    batch_size_a * 2,
   84|      0|                    max_depth,
   85|      0|                    cutoff_time,
   86|      0|                );
   87|      0|            }
   88|       |            // Pruning write operation
   89|      0|            transaction_write_count = 0;
   90|      0|            if !pruning_targets.is_empty() && !self.stopped.load(Ordering::SeqCst) {
   91|      0|                let _write_guard = self.ledger.write_queue.wait(Writer::Pruning);
   92|      0|                let mut tx = self.ledger.rw_txn();
   93|      0|                while !pruning_targets.is_empty()
   94|      0|                    && transaction_write_count < batch_size_a
   95|      0|                    && !self.stopped.load(Ordering::SeqCst)
   96|      0|                {
   97|      0|                    self.stats.inc(StatType::Pruning, DetailType::PruningTarget);
   98|      0|                    let pruning_hash = pruning_targets.front().unwrap();
   99|      0|                    let account_pruned_count =
  100|      0|                        self.ledger
  101|      0|                            .pruning_action(&mut tx, pruning_hash, batch_size_a);
  102|      0|                    transaction_write_count += account_pruned_count;
  103|      0|                    pruning_targets.pop_front();
  104|      0|
  105|      0|                    self.stats.add(
  106|      0|                        StatType::Pruning,
  107|      0|                        DetailType::PrunedCount,
  108|      0|                        account_pruned_count,
  109|      0|                    );
  110|      0|                }
  111|      0|                pruned_count += transaction_write_count;
  112|      0|
  113|      0|                debug!("Pruned blocks: {}", pruned_count);
  114|      0|            }
  115|       |        }
  116|       |
  117|      0|        debug!("Total recently pruned block count: {}", pruned_count);
  118|      0|    }
  119|       |
  120|      0|    pub fn collect_ledger_pruning_targets(
  121|      0|        &self,
  122|      0|        pruning_targets: &mut VecDeque<BlockHash>,
  123|      0|        last_account: &mut Account,
  124|      0|        batch_read_size: u64,
  125|      0|        max_depth: u64,
  126|      0|        cutoff_time: UnixTimestamp,
  127|      0|    ) -> bool {
  128|      0|        let mut read_operations = 0;
  129|      0|        let mut finish_transaction = false;
  130|      0|        let mut tx = self.ledger.read_txn();
  131|      0|        let mut it = self
  132|      0|            .ledger
  133|      0|            .store
  134|      0|            .confirmation_height
  135|      0|            .iter_range(&tx, *last_account..);
  136|       |
  137|      0|        while let Some((account, info)) = it.next() {
  138|      0|            read_operations += 1;
  139|      0|            let mut hash = info.frontier;
  140|      0|            let mut depth = 0;
  141|      0|            while !hash.is_zero() && depth < max_depth {
  142|      0|                if let Some(block) = self.ledger.any().get_block(&tx, &hash) {
  143|      0|                    if block.timestamp() > cutoff_time || depth == 0 {
  144|      0|                        hash = block.previous();
  145|      0|                    } else {
  146|      0|                        break;
  147|       |                    }
  148|       |                } else {
  149|      0|                    assert!(depth != 0);
  150|      0|                    hash = BlockHash::zero();
  151|       |                }
  152|      0|                depth += 1;
  153|      0|                if depth % batch_read_size == 0 {
  154|      0|                    drop(it);
  155|      0|                    tx.refresh();
  156|      0|                    it = self
  157|      0|                        .ledger
  158|      0|                        .store
  159|      0|                        .confirmation_height
  160|      0|                        .iter_range(&tx, account..);
  161|      0|                }
  162|       |            }
  163|      0|            if !hash.is_zero() {
  164|      0|                pruning_targets.push_back(hash);
  165|      0|            }
  166|      0|            read_operations += depth;
  167|      0|            if read_operations >= batch_read_size {
  168|      0|                *last_account = account.inc_or_max();
  169|      0|                finish_transaction = true;
  170|      0|                break;
  171|      0|            }
  172|       |        }
  173|       |
  174|      0|        !finish_transaction || last_account.is_zero()
  175|      0|    }
  176|       |}
  177|       |
  178|       |pub trait LedgerPruningExt {
  179|       |    fn start(&self);
  180|       |    fn ongoing_ledger_pruning(&self);
  181|       |}
  182|       |
  183|       |impl LedgerPruningExt for Arc<LedgerPruning> {
  184|      0|    fn start(&self) {
  185|      0|        let self_w = Arc::downgrade(self);
  186|      0|        self.workers.post(Box::new(move || {
  187|      0|            if let Some(self_l) = self_w.upgrade() {
  188|      0|                self_l.ongoing_ledger_pruning();
  189|      0|            }
  190|      0|        }));
  191|      0|    }
  192|       |
  193|      0|    fn ongoing_ledger_pruning(&self) {
  194|      0|        let bootstrap_weight_reached =
  195|      0|            self.ledger.block_count() >= self.ledger.bootstrap_weight_max_blocks();
  196|      0|        self.ledger_pruning(
  197|      0|            if self.flags.block_processor_batch_size != 0 {
  198|      0|                self.flags.block_processor_batch_size as u64
  199|       |            } else {
  200|      0|                2 * 1024
  201|       |            },
  202|      0|            bootstrap_weight_reached,
  203|       |        );
  204|      0|        let ledger_pruning_interval = if bootstrap_weight_reached {
  205|      0|            Duration::from_secs(self.config.max_pruning_age_s as u64)
  206|       |        } else {
  207|      0|            Duration::from_secs(std::cmp::min(self.config.max_pruning_age_s as u64, 15 * 60))
  208|       |        };
  209|      0|        let node_w = Arc::downgrade(self);
  210|      0|        self.workers.post_delayed(
  211|      0|            ledger_pruning_interval,
  212|      0|            Box::new(move || {
  213|      0|                if let Some(node) = node_w.upgrade() {
  214|      0|                    node.ongoing_ledger_pruning()
  215|      0|                }
  216|      0|            }),
  217|      0|        );
  218|      0|    }
  219|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/builder.rs:
    1|       |use super::OnlineReps;
    2|       |use rsnano_core::{Amount, Networks};
    3|       |use rsnano_ledger::RepWeightCache;
    4|       |use std::{sync::Arc, time::Duration};
    5|       |
    6|       |pub struct OnlineRepsBuilder {
    7|       |    rep_weights: Option<Arc<RepWeightCache>>,
    8|       |    weight_interval: Duration,
    9|       |    online_weight_minimum: Amount,
   10|       |    representative_weight_minimum: Amount,
   11|       |    trended: Option<Amount>,
   12|       |}
   13|       |
   14|       |impl OnlineRepsBuilder {
   15|     11|    pub(super) fn new() -> Self {
   16|     11|        Self {
   17|     11|            rep_weights: None,
   18|     11|            weight_interval: OnlineReps::default_interval_for(Networks::NanoLiveNetwork),
   19|     11|            online_weight_minimum: OnlineReps::DEFAULT_ONLINE_WEIGHT_MINIMUM,
   20|     11|            representative_weight_minimum: Amount::zero(),
   21|     11|            trended: None,
   22|     11|        }
   23|     11|    }
   24|      8|    pub fn rep_weights(mut self, weights: Arc<RepWeightCache>) -> Self {
   25|      8|        self.rep_weights = Some(weights);
   26|      8|        self
   27|      8|    }
   28|       |
   29|      4|    pub fn weight_interval(mut self, period: Duration) -> Self {
   30|      4|        self.weight_interval = period;
   31|      4|        self
   32|      4|    }
   33|       |
   34|      3|    pub fn online_weight_minimum(mut self, minimum: Amount) -> Self {
   35|      3|        self.online_weight_minimum = minimum;
   36|      3|        self
   37|      3|    }
   38|       |
   39|      3|    pub fn representative_weight_minimum(mut self, minimum: Amount) -> Self {
   40|      3|        self.representative_weight_minimum = minimum;
   41|      3|        self
   42|      3|    }
   43|       |
   44|      0|    pub fn trended(mut self, trended: Amount) -> Self {
   45|      0|        self.trended = Some(trended);
   46|      0|        self
   47|      0|    }
   48|       |
   49|     11|    pub fn finish(self) -> OnlineReps {
   50|     11|        let rep_weights = self
   51|     11|            .rep_weights
   52|     11|            .unwrap_or_else(|| Arc::new(RepWeightCache::new()));
                                             ^3
   53|     11|
   54|     11|        let mut online_reps = OnlineReps::new(
   55|     11|            rep_weights,
   56|     11|            self.weight_interval,
   57|     11|            self.online_weight_minimum,
   58|     11|            self.representative_weight_minimum,
   59|     11|        );
   60|     11|        if let Some(trended) = self.trended {
                                  ^0
   61|      0|            online_reps.set_trended(trended);
   62|     11|        }
   63|     11|        online_reps
   64|     11|    }
   65|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/cleanup.rs:
    1|       |use super::OnlineReps;
    2|       |use rsnano_core::Account;
    3|       |use rsnano_network::{ChannelId, DeadChannelCleanupStep};
    4|       |use std::sync::{Arc, Mutex};
    5|       |use tracing::info;
    6|       |
    7|       |/// Removes reps with dead channels
    8|       |pub struct OnlineRepsCleanup(Arc<Mutex<OnlineReps>>);
    9|       |
   10|       |impl OnlineRepsCleanup {
   11|      3|    pub fn new(reps: Arc<Mutex<OnlineReps>>) -> Self {
   12|      3|        Self(reps)
   13|      3|    }
   14|       |}
   15|       |
   16|       |impl DeadChannelCleanupStep for OnlineRepsCleanup {
   17|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
   18|      0|        let mut online_reps = self.0.lock().unwrap();
   19|      0|        for channel_id in dead_channel_ids {
   20|      0|            let removed_reps = online_reps.remove_peer(*channel_id);
   21|      0|            for rep in removed_reps {
   22|      0|                info!(
   23|      0|                    "Evicting representative {} with dead channel",
   24|      0|                    Account::from(rep).encode_account(),
   25|       |                );
   26|       |            }
   27|       |        }
   28|      0|    }
   29|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/mod.rs:
    1|       |mod builder;
    2|       |mod cleanup;
    3|       |mod online_container;
    4|       |mod peered_container;
    5|       |mod peered_rep;
    6|       |
    7|       |pub use builder::OnlineRepsBuilder;
    8|       |pub use cleanup::*;
    9|       |pub use peered_container::InsertResult;
   10|       |pub use peered_rep::PeeredRep;
   11|       |use primitive_types::U256;
   12|       |use rsnano_core::{utils::ContainerInfo, Amount, Networks, PublicKey};
   13|       |use rsnano_ledger::RepWeightCache;
   14|       |use rsnano_network::ChannelId;
   15|       |use rsnano_nullable_clock::Timestamp;
   16|       |use std::{cmp::max, sync::Arc, time::Duration};
   17|       |use {online_container::OnlineContainer, peered_container::PeeredContainer};
   18|       |
   19|       |const ONLINE_WEIGHT_QUORUM: u8 = 67;
   20|       |
   21|       |/// Keeps track of all representatives that are online
   22|       |/// and all representatives to which we have a direct connection
   23|       |pub struct OnlineReps {
   24|       |    rep_weights: Arc<RepWeightCache>,
   25|       |    online_reps: OnlineContainer,
   26|       |    peered_reps: PeeredContainer,
   27|       |    trended_weight: Amount,
   28|       |    online_weight: Amount,
   29|       |    /// Time between collecting online representative samples
   30|       |    weight_interval: Duration,
   31|       |    online_weight_minimum: Amount,
   32|       |    representative_weight_minimum: Amount,
   33|       |}
   34|       |
   35|       |impl OnlineReps {
   36|       |    pub const DEFAULT_ONLINE_WEIGHT_MINIMUM: Amount = Amount::nano(60_000_000);
   37|       |
   38|     17|    pub const fn default_interval_for(network: Networks) -> Duration {
   39|     17|        match network {
   40|      6|            Networks::NanoDevNetwork => Duration::from_secs(1),
   41|     11|            _ => Duration::from_secs(5 * 60),
   42|       |        }
   43|     17|    }
   44|       |
   45|     11|    pub(crate) fn new(
   46|     11|        rep_weights: Arc<RepWeightCache>,
   47|     11|        weight_interval: Duration,
   48|     11|        online_weight_minimum: Amount,
   49|     11|        representative_weight_minimum: Amount,
   50|     11|    ) -> Self {
   51|     11|        Self {
   52|     11|            rep_weights,
   53|     11|            online_reps: OnlineContainer::new(),
   54|     11|            peered_reps: PeeredContainer::new(),
   55|     11|            trended_weight: Amount::zero(),
   56|     11|            online_weight: Amount::zero(),
   57|     11|            weight_interval,
   58|     11|            online_weight_minimum,
   59|     11|            representative_weight_minimum,
   60|     11|        }
   61|     11|    }
   62|       |
   63|     11|    pub fn builder() -> OnlineRepsBuilder {
   64|     11|        OnlineRepsBuilder::new()
   65|     11|    }
   66|       |
   67|      1|    pub fn online_weight_minimum(&self) -> Amount {
   68|      1|        self.online_weight_minimum
   69|      1|    }
   70|       |
   71|       |    // TODO remove
   72|      0|    pub fn set_online(&mut self, amount: Amount) {
   73|      0|        self.online_weight = amount;
   74|      0|    }
   75|       |
   76|       |    #[allow(dead_code)]
   77|      3|    fn trended_weight(&self) -> Amount {
   78|      3|        self.trended_weight
   79|      3|    }
   80|       |
   81|     33|    pub fn trended_or_minimum_weight(&self) -> Amount {
   82|     33|        max(self.trended_weight, self.online_weight_minimum)
   83|     33|    }
   84|       |
   85|      6|    pub fn set_trended(&mut self, trended: Amount) {
   86|      6|        self.trended_weight = trended;
   87|      6|    }
   88|       |
   89|       |    /** Returns the current online stake */
   90|     13|    pub fn online_weight(&self) -> Amount {
   91|     13|        // TODO calculate on the fly
   92|     13|        self.online_weight
   93|     13|    }
   94|       |
   95|     18|    pub fn minimum_principal_weight(&self) -> Amount {
   96|     18|        self.trended_or_minimum_weight() / 1000 // 0.1% of trended online weight
   97|     18|    }
   98|       |
   99|       |    /// Query if a peer manages a principle representative
  100|      3|    pub fn is_pr(&self, channel_id: ChannelId) -> bool {
  101|      3|        let min_weight = self.minimum_principal_weight();
  102|      3|        self.peered_reps
  103|      3|            .accounts_by_channel(channel_id)
  104|      3|            .any(|account| self.rep_weights.weight(account) >= min_weight)
                                         ^2
  105|      3|    }
  106|       |
  107|       |    /// Get total available weight from peered representatives
  108|      9|    pub fn peered_weight(&self) -> Amount {
  109|      9|        let mut result = Amount::zero();
  110|      9|        let weights = self.rep_weights.read();
  111|      9|        for account in self.peered_reps.accounts() {
                          ^1
  112|      1|            result += weights.get(account).cloned().unwrap_or_default();
  113|      1|        }
  114|      9|        result
  115|      9|    }
  116|       |
  117|       |    /// Total number of peered representatives
  118|      1|    pub fn peered_reps_count(&self) -> usize {
  119|      1|        self.peered_reps.len()
  120|      1|    }
  121|       |
  122|      1|    pub fn quorum_percent(&self) -> u8 {
  123|      1|        ONLINE_WEIGHT_QUORUM
  124|      1|    }
  125|       |
  126|       |    /// Returns the quorum required for confirmation
  127|      9|    pub fn quorum_delta(&self) -> Amount {
  128|      9|        let weight = max(self.online_weight(), self.trended_or_minimum_weight());
  129|      9|
  130|      9|        // Using a larger container to ensure maximum precision
  131|      9|        let delta =
  132|      9|            U256::from(weight.number()) * U256::from(ONLINE_WEIGHT_QUORUM) / U256::from(100);
  133|      9|        Amount::raw(delta.as_u128())
  134|      9|    }
  135|       |
  136|      0|    pub fn on_rep_request(&mut self, channel_id: ChannelId, now: Timestamp) {
  137|      0|        // Find and update the timestamp on all reps available on the endpoint (a single host may have multiple reps)
  138|      0|        self.peered_reps.modify_by_channel(channel_id, |rep| {
  139|      0|            rep.last_request = now;
  140|      0|        });
  141|      0|    }
  142|       |
  143|      0|    pub fn last_request_elapsed(&self, channel_id: ChannelId, now: Timestamp) -> Option<Duration> {
  144|      0|        self.peered_reps
  145|      0|            .iter_by_channel(channel_id)
  146|      0|            .next()
  147|      0|            .map(|rep| rep.last_request.elapsed(now))
  148|      0|    }
  149|       |
  150|       |    /// List of online representatives, both the currently sampling ones and the ones observed in the previous sampling period
  151|      0|    pub fn online_reps(&self) -> impl Iterator<Item = &PublicKey> {
  152|      0|        self.online_reps.iter()
  153|      0|    }
  154|       |
  155|       |    /// Request a list of the top \p count known representatives in descending order of weight, with at least \p weight_a voting weight, and optionally with a minimum version \p minimum_protocol_version
  156|      0|    pub fn peered_reps(&self) -> Vec<PeeredRep> {
  157|      0|        self.representatives_filter(Amount::zero())
  158|      0|    }
  159|       |
  160|       |    /// Request a list of the top \p count known principal representatives in descending order of weight, optionally with a minimum version \p minimum_protocol_version
  161|      3|    pub fn peered_principal_reps(&self) -> Vec<PeeredRep> {
  162|      3|        self.representatives_filter(self.minimum_principal_weight())
  163|      3|    }
  164|       |
  165|       |    /// Request a list of known representatives in descending order
  166|       |    /// of weight, with at least **weight** voting weight
  167|      3|    pub fn representatives_filter(&self, min_weight: Amount) -> Vec<PeeredRep> {
  168|      3|        let mut reps_with_weight = Vec::new();
  169|       |
  170|      3|        for rep in self.peered_reps.iter() {
                          ^0
  171|      0|            let weight = self.rep_weights.weight(&rep.account);
  172|      0|            if weight > min_weight {
  173|      0|                reps_with_weight.push((rep.clone(), weight));
  174|      0|            }
  175|       |        }
  176|       |
  177|      3|        reps_with_weight.sort_by(|a, b| b.1.cmp(&a.1));
                                                      ^0
  178|      3|
  179|      3|        reps_with_weight.drain(..).map(|(rep, _)| rep).collect()
                                                                ^0
  180|      3|    }
  181|       |
  182|       |    /// Add voting account rep_account to the set of online representatives.
  183|       |    /// This can happen for directly connected or indirectly connected reps.
  184|       |    /// Returns whether it is a rep which has more than min weight
  185|      7|    pub fn vote_observed(&mut self, rep_account: PublicKey, now: Timestamp) -> bool {
  186|      7|        if self.rep_weights.weight(&rep_account) < self.representative_weight_minimum {
  187|      0|            return false;
  188|      7|        }
  189|      7|
  190|      7|        let new_insert = self.online_reps.insert(rep_account, now);
  191|      7|        let trimmed = self
  192|      7|            .online_reps
  193|      7|            .trim(now.checked_sub(self.weight_interval).unwrap_or_default());
  194|      7|
  195|      7|        if new_insert || trimmed {
                                       ^0
  196|      7|            self.calculate_online_weight();
  197|      7|        }
                       ^0
  198|      7|        true
  199|      7|    }
  200|       |
  201|      7|    fn calculate_online_weight(&mut self) {
  202|      7|        let mut current = Amount::zero();
  203|      9|        for account in self.online_reps.iter() {
                                     ^7
  204|      9|            current += self.rep_weights.weight(account);
  205|      9|        }
  206|      7|        self.online_weight = current;
  207|      7|    }
  208|       |
  209|       |    /// Add rep_account to the set of peered representatives
  210|      2|    pub fn vote_observed_directly(
  211|      2|        &mut self,
  212|      2|        rep_account: PublicKey,
  213|      2|        channel_id: ChannelId,
  214|      2|        now: Timestamp,
  215|      2|    ) -> InsertResult {
  216|      2|        let is_rep = self.vote_observed(rep_account, now);
  217|      2|        if is_rep {
  218|      2|            self.peered_reps
  219|      2|                .update_or_insert(rep_account, channel_id, now)
  220|       |        } else {
  221|      0|            InsertResult::Updated
  222|       |        }
  223|      2|    }
  224|       |
  225|      0|    pub fn remove_peer(&mut self, channel_id: ChannelId) -> Vec<PublicKey> {
  226|      0|        self.peered_reps.remove(channel_id)
  227|      0|    }
  228|       |
  229|      0|    pub fn container_info(&self) -> ContainerInfo {
  230|      0|        [
  231|      0|            (
  232|      0|                "online",
  233|      0|                self.online_reps.len(),
  234|      0|                OnlineContainer::ELEMENT_SIZE,
  235|      0|            ),
  236|      0|            (
  237|      0|                "peered",
  238|      0|                self.peered_reps.len(),
  239|      0|                PeeredContainer::ELEMENT_SIZE,
  240|      0|            ),
  241|      0|        ]
  242|      0|        .into()
  243|      0|    }
  244|       |}
  245|       |
  246|       |impl Default for OnlineReps {
  247|      3|    fn default() -> Self {
  248|      3|        Self::builder().finish()
  249|      3|    }
  250|       |}
  251|       |
  252|       |#[cfg(test)]
  253|       |mod tests {
  254|       |    use super::*;
  255|       |    use rsnano_nullable_clock::SteadyClock;
  256|       |    use std::time::Duration;
  257|       |
  258|       |    #[test]
  259|      1|    fn empty() {
  260|      1|        let online_reps = OnlineReps::default();
  261|      1|        assert_eq!(
  262|      1|            online_reps.online_weight_minimum(),
  263|      1|            Amount::nano(60_000_000)
  264|      1|        );
  265|      1|        assert_eq!(online_reps.trended_weight(), Amount::zero(), "trended");
                                                                               ^0
  266|      1|        assert_eq!(
  267|      1|            online_reps.trended_or_minimum_weight(),
  268|      1|            Amount::nano(60_000_000),
  269|      0|            "trended"
  270|       |        );
  271|      1|        assert_eq!(online_reps.online_weight(), Amount::zero(), "online");
                                                                              ^0
  272|      1|        assert_eq!(online_reps.peered_weight(), Amount::zero(), "peered");
                                                                              ^0
  273|      1|        assert_eq!(online_reps.peered_reps_count(), 0, "peered count");
                                                                     ^0
  274|      1|        assert_eq!(online_reps.quorum_percent(), 67, "quorum percent");
                                                                   ^0
  275|      1|        assert_eq!(
  276|      1|            online_reps.quorum_delta(),
  277|      1|            Amount::nano(40_200_000),
  278|      0|            "quorum delta"
  279|       |        );
  280|       |
  281|      1|        assert_eq!(online_reps.minimum_principal_weight(), Amount::nano(60_000));
  282|      1|    }
  283|       |
  284|       |    #[test]
  285|      1|    fn observe_vote() {
  286|      1|        let clock = SteadyClock::new_null();
  287|      1|        let account = PublicKey::from(1);
  288|      1|        let weight = Amount::nano(100_000);
  289|      1|        let weights = Arc::new(RepWeightCache::new());
  290|      1|        weights.set(account, weight);
  291|      1|        let mut online_reps = OnlineReps::builder().rep_weights(weights).finish();
  292|      1|
  293|      1|        online_reps.vote_observed(account, clock.now());
  294|      1|
  295|      1|        assert_eq!(online_reps.online_weight(), weight, "online");
                                                                      ^0
  296|      1|        assert_eq!(online_reps.peered_weight(), Amount::zero(), "peered");
                                                                              ^0
  297|      1|    }
  298|       |
  299|       |    #[test]
  300|      1|    fn observe_direct_vote() {
  301|      1|        let clock = SteadyClock::new_null();
  302|      1|        let account = PublicKey::from(1);
  303|      1|        let weight = Amount::nano(100_000);
  304|      1|        let weights = Arc::new(RepWeightCache::new());
  305|      1|        weights.set(account, weight);
  306|      1|        let mut online_reps = OnlineReps::builder().rep_weights(weights).finish();
  307|      1|
  308|      1|        online_reps.vote_observed_directly(account, ChannelId::from(1), clock.now());
  309|      1|
  310|      1|        assert_eq!(online_reps.online_weight(), weight, "online");
                                                                      ^0
  311|      1|        assert_eq!(online_reps.peered_weight(), weight, "peered");
                                                                      ^0
  312|      1|    }
  313|       |
  314|       |    #[test]
  315|      1|    fn trended_weight() {
  316|      1|        let mut online_reps = OnlineReps::default();
  317|      1|        online_reps.set_trended(Amount::nano(10_000));
  318|      1|        assert_eq!(online_reps.trended_weight(), Amount::nano(10_000));
  319|      1|        assert_eq!(
  320|      1|            online_reps.trended_or_minimum_weight(),
  321|      1|            Amount::nano(60_000_000)
  322|      1|        );
  323|       |
  324|      1|        online_reps.set_trended(Amount::nano(100_000_000));
  325|      1|        assert_eq!(online_reps.trended_weight(), Amount::nano(100_000_000));
  326|      1|        assert_eq!(
  327|      1|            online_reps.trended_or_minimum_weight(),
  328|      1|            Amount::nano(100_000_000)
  329|      1|        );
  330|      1|    }
  331|       |
  332|       |    #[test]
  333|      1|    fn minimum_principal_weight() {
  334|      1|        let mut online_reps = OnlineReps::default();
  335|      1|        assert_eq!(online_reps.minimum_principal_weight(), Amount::nano(60_000));
  336|       |
  337|      1|        online_reps.set_trended(Amount::nano(110_000_000));
  338|      1|        // 0.1% of trended weight
  339|      1|        assert_eq!(
  340|      1|            online_reps.minimum_principal_weight(),
  341|      1|            Amount::nano(110_000)
  342|      1|        );
  343|      1|    }
  344|       |
  345|       |    #[test]
  346|      1|    fn is_pr() {
  347|      1|        let clock = SteadyClock::new_null();
  348|      1|        let weights = Arc::new(RepWeightCache::new());
  349|      1|        let mut online_reps = OnlineReps::builder().rep_weights(weights.clone()).finish();
  350|      1|        let rep_account = PublicKey::from(42);
  351|      1|        let channel_id = ChannelId::from(1);
  352|      1|        weights.set(rep_account, Amount::nano(50_000));
  353|      1|
  354|      1|        // unknown channel
  355|      1|        assert_eq!(online_reps.is_pr(channel_id), false);
  356|       |
  357|       |        // below PR limit
  358|      1|        online_reps.vote_observed_directly(rep_account, channel_id, clock.now());
  359|      1|        assert_eq!(online_reps.is_pr(channel_id), false);
  360|       |
  361|       |        // above PR limit
  362|      1|        weights.set(rep_account, Amount::nano(100_000));
  363|      1|        assert_eq!(online_reps.is_pr(channel_id), true);
  364|      1|    }
  365|       |
  366|       |    #[test]
  367|      1|    fn quorum_delta() {
  368|      1|        let weights = Arc::new(RepWeightCache::new());
  369|      1|        let mut online_reps = OnlineReps::builder().rep_weights(weights.clone()).finish();
  370|      1|
  371|      1|        assert_eq!(online_reps.quorum_delta(), Amount::nano(40_200_000));
  372|       |
  373|      1|        let rep_account = PublicKey::from(42);
  374|      1|        weights.set(rep_account, Amount::nano(100_000_000));
  375|      1|        online_reps.vote_observed(rep_account, Timestamp::new_test_instance());
  376|      1|
  377|      1|        assert_eq!(online_reps.quorum_delta(), Amount::nano(67_000_000));
  378|      1|    }
  379|       |
  380|       |    #[test]
  381|      1|    fn discard_old_votes() {
  382|      1|        let rep_a = PublicKey::from(1);
  383|      1|        let rep_b = PublicKey::from(2);
  384|      1|        let rep_c = PublicKey::from(3);
  385|      1|        let weights = Arc::new(RepWeightCache::new());
  386|      1|        weights.set(rep_a, Amount::nano(100_000));
  387|      1|        weights.set(rep_b, Amount::nano(200_000));
  388|      1|        weights.set(rep_c, Amount::nano(400_000));
  389|      1|        let mut online_reps = OnlineReps::builder()
  390|      1|            .rep_weights(weights)
  391|      1|            .weight_interval(Duration::from_secs(30))
  392|      1|            .finish();
  393|      1|
  394|      1|        let now = SteadyClock::new_null().now();
  395|      1|        online_reps.vote_observed(rep_a, now);
  396|      1|        online_reps.vote_observed(rep_b, now + Duration::from_secs(10));
  397|      1|        online_reps.vote_observed(rep_c, now + Duration::from_secs(31));
  398|      1|
  399|      1|        assert_eq!(online_reps.online_weight(), Amount::nano(600_000));
  400|      1|    }
  401|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/online_container.rs:
    1|       |use rsnano_core::{Account, PublicKey};
    2|       |use rsnano_nullable_clock::Timestamp;
    3|       |use std::{
    4|       |    collections::{BTreeMap, HashMap},
    5|       |    mem::size_of,
    6|       |    time::Duration,
    7|       |};
    8|       |
    9|       |/// Collection of all representatives that are currently online
   10|       |#[derive(Default)]
   11|       |pub(super) struct OnlineContainer {
   12|       |    by_time: BTreeMap<Timestamp, Vec<PublicKey>>,
   13|       |    by_account: HashMap<PublicKey, Timestamp>,
   14|       |}
   15|       |
   16|       |impl OnlineContainer {
   17|     20|    pub fn new() -> Self {
   18|     20|        Default::default()
   19|     20|    }
   20|       |
   21|     14|    pub fn iter(&self) -> impl Iterator<Item = &PublicKey> {
   22|     14|        self.by_account.keys()
   23|     14|    }
   24|       |
   25|       |    /// Returns `true` if it was a new insert and `false` if an entry for that account was already present
   26|     20|    pub fn insert(&mut self, rep: PublicKey, now: Timestamp) -> bool {
   27|     20|        let new_insert = if let Some(time) = self.by_account.get_mut(&rep) {
                                                   ^2
   28|      2|            let old_time = *time;
   29|      2|            *time = now;
   30|      2|
   31|      2|            let accounts_for_old_time = self.by_time.get_mut(&old_time).unwrap();
   32|      2|            if accounts_for_old_time.len() == 1 {
   33|      2|                self.by_time.remove(&old_time);
   34|      2|            } else {
   35|      0|                accounts_for_old_time.retain(|acc| acc != &rep);
   36|      0|            }
   37|      2|            self.by_time.entry(now).or_default().push(rep);
   38|      2|
   39|      2|            false
   40|       |        } else {
   41|     18|            self.by_account.insert(rep, now);
   42|     18|            self.by_time.entry(now).or_default().push(rep);
   43|     18|            true
   44|       |        };
   45|       |
   46|     20|        new_insert
   47|     20|    }
   48|       |
   49|     11|    pub fn trim(&mut self, upper_bound: Timestamp) -> bool {
   50|     11|        let mut trimmed = false;
   51|       |
   52|     15|        while let Some((time, _)) = self.by_time.first_key_value() {
                                      ^13
   53|     13|            if *time >= upper_bound {
   54|      9|                break;
   55|      4|            }
   56|      4|
   57|      4|            let (_, accounts) = self.by_time.pop_first().unwrap();
   58|      9|            for account in accounts {
                              ^5
   59|      5|                self.by_account.remove(&account);
   60|      5|            }
   61|       |
   62|      4|            trimmed = true;
   63|       |        }
   64|       |
   65|     11|        trimmed
   66|     11|    }
   67|       |
   68|      7|    pub fn len(&self) -> usize {
   69|      7|        self.by_account.len()
   70|      7|    }
   71|       |
   72|       |    pub const ELEMENT_SIZE: usize =
   73|       |        size_of::<(Duration, Vec<Account>)>() + size_of::<(Account, Duration)>();
   74|       |}
   75|       |
   76|       |#[cfg(test)]
   77|       |mod tests {
   78|       |    use super::*;
   79|       |
   80|       |    #[test]
   81|      1|    fn empty_container() {
   82|      1|        let container = OnlineContainer::new();
   83|      1|        assert_eq!(container.len(), 0);
   84|      1|        assert_eq!(container.iter().count(), 0);
   85|      1|    }
   86|       |
   87|       |    #[test]
   88|      1|    fn insert_one_rep() {
   89|      1|        let mut container = OnlineContainer::new();
   90|      1|
   91|      1|        let new_insert = container.insert(PublicKey::from(1), Timestamp::new_test_instance());
   92|      1|
   93|      1|        assert_eq!(container.len(), 1);
   94|      1|        assert_eq!(container.iter().count(), 1);
   95|      1|        assert_eq!(container.iter().next().unwrap(), &PublicKey::from(1));
   96|      1|        assert_eq!(new_insert, true);
   97|      1|    }
   98|       |
   99|       |    #[test]
  100|      1|    fn insert_two_reps() {
  101|      1|        let mut container = OnlineContainer::new();
  102|      1|
  103|      1|        let now = Timestamp::new_test_instance();
  104|      1|        let new_insert_a = container.insert(PublicKey::from(1), now);
  105|      1|        let new_insert_b = container.insert(PublicKey::from(2), now + Duration::from_secs(1));
  106|      1|
  107|      1|        assert_eq!(container.len(), 2);
  108|      1|        assert_eq!(container.iter().count(), 2);
  109|      1|        assert_eq!(new_insert_a, true);
  110|      1|        assert_eq!(new_insert_b, true);
  111|      1|    }
  112|       |
  113|       |    #[test]
  114|      1|    fn insert_same_rep_twice_with_same_time() {
  115|      1|        let mut container = OnlineContainer::new();
  116|      1|
  117|      1|        let now = Timestamp::new_test_instance();
  118|      1|        let new_insert_a = container.insert(PublicKey::from(1), now);
  119|      1|        let new_insert_b = container.insert(PublicKey::from(1), now);
  120|      1|
  121|      1|        assert_eq!(container.len(), 1);
  122|      1|        assert_eq!(container.iter().count(), 1);
  123|      1|        assert_eq!(new_insert_a, true);
  124|      1|        assert_eq!(new_insert_b, false);
  125|      1|    }
  126|       |
  127|       |    #[test]
  128|      1|    fn insert_same_rep_twice_with_different_time() {
  129|      1|        let mut container = OnlineContainer::new();
  130|      1|
  131|      1|        let now = Timestamp::new_test_instance();
  132|      1|        let new_insert_a = container.insert(PublicKey::from(1), now);
  133|      1|        let new_insert_b = container.insert(PublicKey::from(1), now + Duration::from_secs(1));
  134|      1|
  135|      1|        assert_eq!(container.len(), 1);
  136|      1|        assert_eq!(container.iter().count(), 1);
  137|      1|        assert_eq!(new_insert_a, true);
  138|      1|        assert_eq!(new_insert_b, false);
  139|      1|        assert_eq!(container.by_time.len(), 1);
  140|      1|    }
  141|       |
  142|       |    #[test]
  143|      1|    fn trimming_empty_container_does_nothing() {
  144|      1|        let mut container = OnlineContainer::new();
  145|      1|        let now = Timestamp::new_test_instance();
  146|      1|        assert_eq!(container.trim(now), false);
  147|      1|    }
  148|       |
  149|       |    #[test]
  150|      1|    fn dont_trim_if_upper_bound_not_reached() {
  151|      1|        let mut container = OnlineContainer::new();
  152|      1|        let now = Timestamp::new_test_instance();
  153|      1|        container.insert(PublicKey::from(1), now);
  154|      1|        assert_eq!(container.trim(now), false);
  155|      1|    }
  156|       |
  157|       |    #[test]
  158|      1|    fn trim_if_upper_bound_reached() {
  159|      1|        let mut container = OnlineContainer::new();
  160|      1|        let now = Timestamp::new_test_instance();
  161|      1|        container.insert(PublicKey::from(1), now);
  162|      1|        assert_eq!(container.trim(now + Duration::from_millis(1)), true);
  163|      1|        assert_eq!(container.len(), 0);
  164|      1|    }
  165|       |
  166|       |    #[test]
  167|      1|    fn trim_multiple_entries() {
  168|      1|        let mut container = OnlineContainer::new();
  169|      1|
  170|      1|        let now = Timestamp::new_test_instance();
  171|      1|        container.insert(PublicKey::from(1), now);
  172|      1|        container.insert(PublicKey::from(2), now);
  173|      1|        container.insert(PublicKey::from(3), now + Duration::from_secs(1));
  174|      1|        container.insert(PublicKey::from(4), now + Duration::from_secs(2));
  175|      1|
  176|      1|        assert_eq!(container.trim(now + Duration::from_millis(1500)), true);
  177|      1|        assert_eq!(container.len(), 1);
  178|      1|        assert_eq!(container.iter().next().unwrap(), &PublicKey::from(4));
  179|      1|        assert_eq!(container.by_time.len(), 1);
  180|      1|    }
  181|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/peered_container.rs:
    1|       |use super::PeeredRep;
    2|       |use rsnano_core::{Account, PublicKey};
    3|       |use rsnano_network::ChannelId;
    4|       |use rsnano_nullable_clock::Timestamp;
    5|       |use std::{collections::HashMap, mem::size_of};
    6|       |
    7|       |#[derive(Debug, PartialEq, Eq)]
    8|       |pub enum InsertResult {
    9|       |    Inserted,
   10|       |    Updated,
   11|       |    /// Returns the old channel id
   12|       |    ChannelChanged(ChannelId),
   13|       |}
   14|       |
   15|       |/// Collection of all representatives that we have a direct connection to
   16|       |pub(super) struct PeeredContainer {
   17|       |    by_account: HashMap<PublicKey, PeeredRep>,
   18|       |    by_channel_id: HashMap<ChannelId, Vec<PublicKey>>,
   19|       |}
   20|       |
   21|       |impl PeeredContainer {
   22|       |    pub const ELEMENT_SIZE: usize =
   23|       |        size_of::<PeeredRep>() + size_of::<Account>() + size_of::<usize>() + size_of::<Account>();
   24|       |
   25|     20|    pub fn new() -> Self {
   26|     20|        Self {
   27|     20|            by_account: HashMap::new(),
   28|     20|            by_channel_id: HashMap::new(),
   29|     20|        }
   30|     20|    }
   31|       |
   32|     17|    pub fn update_or_insert(
   33|     17|        &mut self,
   34|     17|        account: PublicKey,
   35|     17|        channel_id: ChannelId,
   36|     17|        now: Timestamp,
   37|     17|    ) -> InsertResult {
   38|     17|        if let Some(rep) = self.by_account.get_mut(&account) {
                                  ^2
   39|       |            // Update if representative channel was changed
   40|      2|            if rep.channel_id != channel_id {
   41|      1|                let old_channel_id = rep.channel_id;
   42|      1|                let new_channel_id = channel_id;
   43|      1|                rep.channel_id = new_channel_id;
   44|      1|                self.remove_channel_id(&account, old_channel_id);
   45|      1|                self.by_channel_id
   46|      1|                    .entry(new_channel_id)
   47|      1|                    .or_default()
   48|      1|                    .push(account);
   49|      1|                InsertResult::ChannelChanged(old_channel_id)
   50|       |            } else {
   51|      1|                InsertResult::Updated
   52|       |            }
   53|       |        } else {
   54|     15|            self.by_account
   55|     15|                .insert(account, PeeredRep::new(account, channel_id, now));
   56|     15|
   57|     15|            let by_id = self.by_channel_id.entry(channel_id).or_default();
   58|     15|            by_id.push(account);
   59|     15|            InsertResult::Inserted
   60|       |        }
   61|     17|    }
   62|       |
   63|      1|    fn remove_channel_id(&mut self, account: &PublicKey, channel_id: ChannelId) {
   64|      1|        let accounts = self.by_channel_id.get_mut(&channel_id).unwrap();
   65|      1|
   66|      1|        if accounts.len() == 1 {
   67|      1|            self.by_channel_id.remove(&channel_id);
   68|      1|        } else {
   69|      0|            accounts.retain(|acc| acc != account);
   70|      0|        }
   71|      1|    }
   72|       |
   73|      7|    pub fn iter(&self) -> impl Iterator<Item = &PeeredRep> {
   74|      7|        self.by_account.values()
   75|      7|    }
   76|       |
   77|      7|    pub fn iter_by_channel(&self, channel_id: ChannelId) -> impl Iterator<Item = &PeeredRep> {
   78|      7|        self.accounts_by_channel(channel_id)
   79|      7|            .map(|account| self.by_account.get(account).unwrap())
                                         ^5
   80|      7|    }
   81|       |
   82|     12|    pub fn accounts_by_channel(&self, channel_id: ChannelId) -> impl Iterator<Item = &PublicKey> {
   83|     12|        self.by_channel_id.get(&channel_id).into_iter().flatten()
   84|     12|    }
   85|       |
   86|     12|    pub fn accounts(&self) -> impl Iterator<Item = &PublicKey> {
   87|     12|        self.by_account.keys()
   88|     12|    }
   89|       |
   90|      1|    pub fn modify_by_channel(
   91|      1|        &mut self,
   92|      1|        channel_id: ChannelId,
   93|      1|        mut modify: impl FnMut(&mut PeeredRep),
   94|      1|    ) {
   95|      1|        if let Some(rep_accounts) = self.by_channel_id.get(&channel_id) {
   96|      2|            for rep in rep_accounts {
                              ^1
   97|      1|                modify(self.by_account.get_mut(rep).unwrap());
   98|      1|            }
   99|      0|        }
  100|      1|    }
  101|       |
  102|      9|    pub fn len(&self) -> usize {
  103|      9|        self.by_account.len()
  104|      9|    }
  105|       |
  106|      2|    pub fn remove(&mut self, channel_id: ChannelId) -> Vec<PublicKey> {
  107|      2|        let Some(accounts) = self.by_channel_id.remove(&channel_id) else {
  108|      0|            return Vec::new();
  109|       |        };
  110|      4|        for account in &accounts {
                          ^2
  111|      2|            self.by_account.remove(account);
  112|      2|        }
  113|      2|        accounts
  114|      2|    }
  115|       |}
  116|       |
  117|       |#[cfg(test)]
  118|       |mod tests {
  119|       |    use std::time::Duration;
  120|       |
  121|       |    use super::*;
  122|       |
  123|       |    #[test]
  124|      1|    fn empty() {
  125|      1|        let container = PeeredContainer::new();
  126|      1|        assert_eq!(container.len(), 0);
  127|      1|        assert_eq!(container.iter().count(), 0);
  128|      1|        assert_eq!(container.iter_by_channel(42.into()).count(), 0);
  129|      1|        assert_eq!(container.accounts_by_channel(42.into()).count(), 0);
  130|      1|        assert_eq!(container.accounts().count(), 0);
  131|      1|    }
  132|       |
  133|       |    #[test]
  134|      1|    fn insert_one() {
  135|      1|        let mut container = PeeredContainer::new();
  136|      1|        let account = PublicKey::from(1);
  137|      1|        let channel_id = ChannelId::from(2);
  138|      1|        let now = Timestamp::new_test_instance();
  139|      1|        assert_eq!(
  140|      1|            container.update_or_insert(account, channel_id, now),
  141|      1|            InsertResult::Inserted
  142|      1|        );
  143|      1|        assert_eq!(container.len(), 1);
  144|       |
  145|      1|        assert_eq!(
  146|      1|            container.iter().cloned().collect::<Vec<_>>(),
  147|      1|            vec![PeeredRep::new(account, channel_id, now)]
  148|      1|        );
  149|      1|        assert_eq!(
  150|      1|            container
  151|      1|                .iter_by_channel(channel_id)
  152|      1|                .cloned()
  153|      1|                .collect::<Vec<_>>(),
  154|      1|            vec![PeeredRep::new(account, channel_id, now)]
  155|      1|        );
  156|      1|        assert_eq!(
  157|      1|            container
  158|      1|                .accounts_by_channel(channel_id)
  159|      1|                .cloned()
  160|      1|                .collect::<Vec<_>>(),
  161|      1|            vec![account]
  162|      1|        );
  163|      1|        assert_eq!(
  164|      1|            container.accounts().cloned().collect::<Vec<_>>(),
  165|      1|            vec![account]
  166|      1|        );
  167|      1|    }
  168|       |
  169|       |    #[test]
  170|      1|    fn insert_two() {
  171|      1|        let mut container = PeeredContainer::new();
  172|      1|        let now = Timestamp::new_test_instance();
  173|      1|        assert_eq!(
  174|      1|            container.update_or_insert(PublicKey::from(100), ChannelId::from(101), now,),
  175|      1|            InsertResult::Inserted
  176|      1|        );
  177|      1|        assert_eq!(
  178|      1|            container.update_or_insert(
  179|      1|                PublicKey::from(200),
  180|      1|                ChannelId::from(201),
  181|      1|                now + Duration::from_secs(1),
  182|      1|            ),
  183|      1|            InsertResult::Inserted
  184|      1|        );
  185|      1|        assert_eq!(container.len(), 2);
  186|      1|        assert_eq!(container.iter().count(), 2);
  187|      1|        assert_eq!(container.accounts().count(), 2);
  188|      1|    }
  189|       |
  190|       |    #[test]
  191|      1|    fn remove_one() {
  192|      1|        let mut container = PeeredContainer::new();
  193|      1|
  194|      1|        let channel_id = ChannelId::from(101);
  195|      1|        let now = Timestamp::new_test_instance();
  196|      1|        container.update_or_insert(PublicKey::from(100), channel_id, now);
  197|      1|
  198|      1|        container.remove(channel_id);
  199|      1|        assert_eq!(container.len(), 0);
  200|      1|        assert_eq!(container.iter().count(), 0);
  201|      1|    }
  202|       |
  203|       |    #[test]
  204|      1|    fn remove_from_container_with_multiple_entries() {
  205|      1|        let mut container = PeeredContainer::new();
  206|      1|
  207|      1|        let now = Timestamp::new_test_instance();
  208|      1|        let channel_id = ChannelId::from(1);
  209|      1|        container.update_or_insert(PublicKey::from(100), ChannelId::from(100), now);
  210|      1|        container.update_or_insert(
  211|      1|            PublicKey::from(200),
  212|      1|            channel_id,
  213|      1|            now + Duration::from_secs(1),
  214|      1|        );
  215|      1|        container.update_or_insert(
  216|      1|            PublicKey::from(300),
  217|      1|            ChannelId::from(101),
  218|      1|            now + Duration::from_secs(2),
  219|      1|        );
  220|      1|
  221|      1|        container.remove(channel_id);
  222|      1|        assert_eq!(container.len(), 2);
  223|      1|        assert_eq!(container.iter_by_channel(channel_id).count(), 0);
  224|      1|    }
  225|       |
  226|       |    #[test]
  227|      1|    fn modify_by_channel() {
  228|      1|        let mut container = PeeredContainer::new();
  229|      1|        let now = Timestamp::new_test_instance();
  230|      1|
  231|      1|        let channel_id = ChannelId::from(1);
  232|      1|        container.update_or_insert(PublicKey::from(100), ChannelId::from(100), now);
  233|      1|        container.update_or_insert(
  234|      1|            PublicKey::from(200),
  235|      1|            channel_id,
  236|      1|            now + Duration::from_secs(1),
  237|      1|        );
  238|      1|
  239|      1|        let new_value = now + Duration::from_secs(1234);
  240|      1|        container.modify_by_channel(channel_id, |rep| {
  241|      1|            rep.last_request = new_value;
  242|      1|        });
  243|      1|        assert_eq!(
  244|      1|            container
  245|      1|                .iter_by_channel(channel_id)
  246|      1|                .next()
  247|      1|                .unwrap()
  248|      1|                .last_request,
  249|      1|            new_value
  250|      1|        );
  251|      1|    }
  252|       |
  253|       |    #[test]
  254|      1|    fn update_entry() {
  255|      1|        let mut container = PeeredContainer::new();
  256|      1|        let now = Timestamp::new_test_instance();
  257|      1|
  258|      1|        let account = PublicKey::from(1);
  259|      1|        let channel_id = ChannelId::from(2);
  260|      1|        container.update_or_insert(account, channel_id, now);
  261|      1|        assert_eq!(
  262|      1|            container.update_or_insert(account, channel_id, now + Duration::from_secs(2)),
  263|      1|            InsertResult::Updated
  264|      1|        );
  265|      1|        assert_eq!(container.len(), 1);
  266|      1|    }
  267|       |
  268|       |    #[test]
  269|      1|    fn channel_changed() {
  270|      1|        let mut container = PeeredContainer::new();
  271|      1|        let now = Timestamp::new_test_instance();
  272|      1|
  273|      1|        let account = PublicKey::from(1);
  274|      1|        let channel_a = ChannelId::from(2);
  275|      1|        let channel_b = ChannelId::from(3);
  276|      1|        container.update_or_insert(account, channel_a, now);
  277|      1|        assert_eq!(
  278|      1|            container.update_or_insert(account, channel_b, now + Duration::from_secs(2)),
  279|      1|            InsertResult::ChannelChanged(channel_a)
  280|      1|        );
  281|      1|        assert_eq!(container.len(), 1);
  282|      1|        assert_eq!(container.iter_by_channel(channel_a).count(), 0);
  283|      1|        assert_eq!(container.iter_by_channel(channel_b).count(), 1);
  284|      1|    }
  285|       |
  286|       |    #[test]
  287|      1|    fn two_reps_in_same_channel() {
  288|      1|        let mut container = PeeredContainer::new();
  289|      1|        let now = Timestamp::new_test_instance();
  290|      1|
  291|      1|        let account_a = PublicKey::from(1);
  292|      1|        let account_b = PublicKey::from(2);
  293|      1|        let channel = ChannelId::from(100);
  294|      1|        assert_eq!(
  295|      1|            container.update_or_insert(account_a, channel, now),
  296|      1|            InsertResult::Inserted,
  297|      1|        );
  298|      1|        assert_eq!(
  299|      1|            container.update_or_insert(account_b, channel, now),
  300|      1|            InsertResult::Inserted,
  301|      1|        );
  302|       |
  303|      1|        assert_eq!(container.len(), 2);
  304|      1|        assert_eq!(container.iter_by_channel(channel).count(), 2);
  305|      1|    }
  306|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_reps/peered_rep.rs:
    1|       |use rsnano_core::PublicKey;
    2|       |use rsnano_network::ChannelId;
    3|       |use rsnano_nullable_clock::Timestamp;
    4|       |
    5|       |/// A representative to which we have a direct connection
    6|       |#[derive(Clone, Debug, PartialEq, Eq)]
    7|       |pub struct PeeredRep {
    8|       |    pub account: PublicKey,
    9|       |    pub channel_id: ChannelId,
   10|       |    pub last_request: Timestamp,
   11|       |}
   12|       |
   13|       |impl PeeredRep {
   14|     17|    pub fn new(account: PublicKey, channel_id: ChannelId, last_request: Timestamp) -> Self {
   15|     17|        Self {
   16|     17|            account,
   17|     17|            channel_id,
   18|     17|            last_request,
   19|     17|        }
   20|     17|    }
   21|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_weight_calculation.rs:
    1|       |use super::{OnlineReps, OnlineWeightSampler};
    2|       |use crate::utils::{CancellationToken, Runnable};
    3|       |use std::sync::{Arc, Mutex};
    4|       |use tracing::info;
    5|       |
    6|       |pub struct OnlineWeightCalculation {
    7|       |    sampler: OnlineWeightSampler,
    8|       |    online_reps: Arc<Mutex<OnlineReps>>,
    9|       |    first_run: bool,
   10|       |}
   11|       |
   12|       |impl OnlineWeightCalculation {
   13|      3|    pub fn new(sampler: OnlineWeightSampler, online_reps: Arc<Mutex<OnlineReps>>) -> Self {
   14|      3|        Self {
   15|      3|            sampler,
   16|      3|            online_reps,
   17|      3|            first_run: true,
   18|      3|        }
   19|      3|    }
   20|       |}
   21|       |
   22|       |impl Runnable for OnlineWeightCalculation {
   23|      3|    fn run(&mut self, _: &CancellationToken) {
   24|      3|        if self.first_run {
   25|      3|            // Don't sample online weight on first run, because it is always 0
   26|      3|            self.first_run = false;
   27|      3|            self.sampler.sanitize();
   28|      3|        } else {
   29|      0|            let online_weight = self.online_reps.lock().unwrap().online_weight();
   30|      0|            self.sampler.add_sample(online_weight);
   31|      0|        }
   32|      3|        let result = self.sampler.calculate_trend();
   33|      3|        info!(
   34|      0|            "Trended weight updated: {}, samples: {}",
   35|      0|            result.trended.format_balance(0),
   36|       |            result.sample_count
   37|       |        );
   38|      3|        self.online_reps.lock().unwrap().set_trended(result.trended);
   39|      3|    }
   40|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/online_weight_sampler.rs:
    1|       |use rsnano_core::utils::system_time_as_seconds;
    2|       |use rsnano_core::{Amount, Networks};
    3|       |use rsnano_ledger::{Ledger, Writer};
    4|       |use rsnano_store_lmdb::LmdbWriteTransaction;
    5|       |use std::sync::Arc;
    6|       |use std::time::{Duration, SystemTime};
    7|       |
    8|       |pub struct TrendResult {
    9|       |    pub trended: Amount,
   10|       |    pub sample_count: usize,
   11|       |}
   12|       |
   13|       |pub struct OnlineWeightSampler {
   14|       |    ledger: Arc<Ledger>,
   15|       |
   16|       |    /// The maximum time to keep online weight samples
   17|       |    cutoff: Duration,
   18|       |}
   19|       |
   20|       |impl OnlineWeightSampler {
   21|      3|    pub fn new(ledger: Arc<Ledger>, network: Networks) -> Self {
   22|      3|        Self {
   23|      3|            ledger,
   24|      3|            cutoff: Self::cutoff_for(network),
   25|      3|        }
   26|      3|    }
   27|       |
   28|      3|    fn cutoff_for(network: Networks) -> Duration {
   29|      3|        match network {
   30|       |            Networks::NanoLiveNetwork | Networks::NanoTestNetwork => {
   31|       |                // Two weeks
   32|      0|                Duration::from_secs(60 * 60 * 24 * 7 * 2)
   33|       |            }
   34|       |            _ => {
   35|       |                // One day
   36|      3|                Duration::from_secs(60 * 60 * 24)
   37|       |            }
   38|       |        }
   39|      3|    }
   40|       |
   41|      3|    pub fn calculate_trend(&self) -> TrendResult {
   42|      3|        let samples = self.load_samples();
   43|      3|        let sample_count = samples.len();
   44|      3|        let trended = self.medium_weight(samples);
   45|      3|        TrendResult {
   46|      3|            trended,
   47|      3|            sample_count,
   48|      3|        }
   49|      3|    }
   50|       |
   51|      3|    fn load_samples(&self) -> Vec<Amount> {
   52|      3|        let txn = self.ledger.read_txn();
   53|      3|        self.ledger
   54|      3|            .store
   55|      3|            .online_weight
   56|      3|            .iter(&txn)
   57|      3|            .map(|(_, amount)| amount)
                                             ^0
   58|      3|            .collect()
   59|      3|    }
   60|       |
   61|      3|    fn medium_weight(&self, mut items: Vec<Amount>) -> Amount {
   62|      3|        if items.is_empty() {
   63|      3|            Amount::zero()
   64|       |        } else {
   65|      0|            let median_idx = items.len() / 2;
   66|      0|            items.sort();
   67|      0|            items[median_idx]
   68|       |        }
   69|      3|    }
   70|       |
   71|       |    /// Called periodically to sample online weight
   72|      0|    pub fn add_sample(&self, current_online_weight: Amount) {
   73|      0|        let now = SystemTime::now();
   74|      0|        let _guard = self.ledger.write_queue.wait(Writer::OnlineReps);
   75|      0|        let mut txn = self.ledger.rw_txn();
   76|      0|        self.sanitize_samples(&mut txn, now);
   77|      0|        self.insert_new_sample(&mut txn, current_online_weight, now);
   78|      0|    }
   79|       |
   80|      3|    pub fn sanitize(&self) {
   81|      3|        let now = SystemTime::now();
   82|      3|        let _guard = self.ledger.write_queue.wait(Writer::OnlineReps);
   83|      3|        let mut txn = self.ledger.rw_txn();
   84|      3|        self.sanitize_samples(&mut txn, now);
   85|      3|    }
   86|       |
   87|      3|    fn sanitize_samples(&self, tx: &mut LmdbWriteTransaction, now: SystemTime) {
   88|      3|        let to_delete = self.samples_to_delete(tx, now);
   89|       |
   90|      3|        for timestamp in to_delete {
                          ^0
   91|      0|            self.ledger.store.online_weight.del(tx, timestamp);
   92|      0|        }
   93|      3|    }
   94|       |
   95|      3|    fn samples_to_delete(&self, tx: &LmdbWriteTransaction, now: SystemTime) -> Vec<u64> {
   96|      3|        let mut to_delete = Vec::new();
   97|      3|        to_delete.extend(self.old_samples(tx, now));
   98|      3|        to_delete.extend(self.future_samples(tx, now));
   99|      3|        to_delete
  100|      3|    }
  101|       |
  102|      3|    fn old_samples<'tx>(
  103|      3|        &self,
  104|      3|        tx: &'tx LmdbWriteTransaction,
  105|      3|        now: SystemTime,
  106|      3|    ) -> impl Iterator<Item = u64> + use<'tx> {
  107|      3|        let timestamp_cutoff = system_time_as_seconds(now - self.cutoff);
  108|      3|
  109|      3|        self.ledger
  110|      3|            .store
  111|      3|            .online_weight
  112|      3|            .iter(tx)
  113|      3|            .map(|(ts, _)| ts)
                                         ^0
  114|      3|            .take_while(move |ts| *ts < timestamp_cutoff)
                                                ^0
  115|      3|    }
  116|       |
  117|      3|    fn future_samples<'tx>(
  118|      3|        &self,
  119|      3|        tx: &'tx LmdbWriteTransaction,
  120|      3|        now: SystemTime,
  121|      3|    ) -> impl Iterator<Item = u64> + use<'tx> {
  122|      3|        let timestamp_now = system_time_as_seconds(now);
  123|      3|
  124|      3|        self.ledger
  125|      3|            .store
  126|      3|            .online_weight
  127|      3|            .iter_rev(tx)
  128|      3|            .map(|(ts, _)| ts)
                                         ^0
  129|      3|            .take_while(move |ts| *ts > timestamp_now)
                                                ^0
  130|      3|    }
  131|       |
  132|      0|    fn insert_new_sample(
  133|      0|        &self,
  134|      0|        txn: &mut LmdbWriteTransaction,
  135|      0|        current_online_weight: Amount,
  136|      0|        now: SystemTime,
  137|      0|    ) {
  138|      0|        self.ledger.store.online_weight.put(
  139|      0|            txn,
  140|      0|            system_time_as_seconds(now),
  141|      0|            &current_online_weight,
  142|      0|        );
  143|      0|    }
  144|       |}

/home/gustav/code/nano/rsnano-node/node/src/representatives/rep_crawler.rs:
    1|       |use super::{InsertResult, OnlineReps};
    2|       |use crate::{
    3|       |    config::NodeConfig,
    4|       |    consensus::ActiveElections,
    5|       |    stats::{DetailType, Direction, Sample, StatType, Stats},
    6|       |    transport::{
    7|       |        keepalive::{KeepalivePublisher, PreconfiguredPeersKeepalive},
    8|       |        MessageSender,
    9|       |    },
   10|       |    NetworkParams,
   11|       |};
   12|       |use bounded_vec_deque::BoundedVecDeque;
   13|       |use rsnano_core::{utils::ContainerInfo, Account, BlockHash, Root, Vote};
   14|       |use rsnano_ledger::Ledger;
   15|       |use rsnano_messages::{ConfirmReq, Message};
   16|       |use rsnano_network::{Channel, ChannelId, Network, TrafficType};
   17|       |use rsnano_nullable_clock::{SteadyClock, Timestamp};
   18|       |use std::{
   19|       |    collections::HashMap,
   20|       |    mem::size_of,
   21|       |    ops::DerefMut,
   22|       |    sync::{Arc, Condvar, Mutex, MutexGuard, RwLock},
   23|       |    thread::JoinHandle,
   24|       |    time::{Duration, Instant},
   25|       |};
   26|       |use tracing::{debug, info, warn};
   27|       |
   28|       |/// Crawls the network for representatives. Queries are performed by requesting confirmation of a
   29|       |/// random block and observing the corresponding vote.
   30|       |pub struct RepCrawler {
   31|       |    rep_crawler_impl: Mutex<RepCrawlerImpl>,
   32|       |    online_reps: Arc<Mutex<OnlineReps>>,
   33|       |    stats: Arc<Stats>,
   34|       |    config: NodeConfig,
   35|       |    network_params: NetworkParams,
   36|       |    network: Arc<RwLock<Network>>,
   37|       |    condition: Condvar,
   38|       |    ledger: Arc<Ledger>,
   39|       |    active: Arc<ActiveElections>,
   40|       |    thread: Mutex<Option<JoinHandle<()>>>,
   41|       |    steady_clock: Arc<SteadyClock>,
   42|       |    message_sender: Mutex<MessageSender>,
   43|       |    preconfigured_peers: Arc<PreconfiguredPeersKeepalive>,
   44|       |    tokio: tokio::runtime::Handle,
   45|       |}
   46|       |
   47|       |impl RepCrawler {
   48|       |    const MAX_RESPONSES: usize = 1024 * 4;
   49|       |
   50|      3|    pub(crate) fn new(
   51|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   52|      3|        stats: Arc<Stats>,
   53|      3|        query_timeout: Duration,
   54|      3|        config: NodeConfig,
   55|      3|        network_params: NetworkParams,
   56|      3|        network: Arc<RwLock<Network>>,
   57|      3|        ledger: Arc<Ledger>,
   58|      3|        active: Arc<ActiveElections>,
   59|      3|        steady_clock: Arc<SteadyClock>,
   60|      3|        message_sender: MessageSender,
   61|      3|        keepalive_publisher: Arc<KeepalivePublisher>,
   62|      3|        tokio: tokio::runtime::Handle,
   63|      3|    ) -> Self {
   64|      3|        let is_dev_network = network_params.network.is_dev_network();
   65|      3|        Self {
   66|      3|            online_reps: Arc::clone(&online_reps),
   67|      3|            stats: Arc::clone(&stats),
   68|      3|            config: config.clone(),
   69|      3|            network_params,
   70|      3|            network,
   71|      3|            condition: Condvar::new(),
   72|      3|            ledger,
   73|      3|            active,
   74|      3|            thread: Mutex::new(None),
   75|      3|            steady_clock,
   76|      3|            message_sender: Mutex::new(message_sender),
   77|      3|            preconfigured_peers: Arc::new(PreconfiguredPeersKeepalive::new(
   78|      3|                config.preconfigured_peers,
   79|      3|                keepalive_publisher,
   80|      3|            )),
   81|      3|            rep_crawler_impl: Mutex::new(RepCrawlerImpl {
   82|      3|                is_dev_network,
   83|      3|                queries: OrderedQueries::new(),
   84|      3|                online_reps,
   85|      3|                stats,
   86|      3|                query_timeout,
   87|      3|                stopped: false,
   88|      3|                last_query: None,
   89|      3|                responses: BoundedVecDeque::new(Self::MAX_RESPONSES),
   90|      3|                prioritized: Default::default(),
   91|      3|            }),
   92|      3|            tokio,
   93|      3|        }
   94|      3|    }
   95|       |
   96|      3|    pub fn stop(&self) {
   97|      3|        {
   98|      3|            let mut guard = self.rep_crawler_impl.lock().unwrap();
   99|      3|            guard.stopped = true;
  100|      3|        }
  101|      3|        self.condition.notify_all();
  102|      3|        let handle = self.thread.lock().unwrap().take();
  103|      3|        if let Some(handle) = handle {
  104|      3|            handle.join().unwrap();
  105|      3|        }
                       ^0
  106|      3|    }
  107|       |
  108|       |    /// Called when a non-replay vote arrives that might be of interest to rep crawler.
  109|       |    /// @return true, if the vote was of interest and was processed, this indicates that the rep is likely online and voting
  110|      0|    pub fn process(&self, vote: Arc<Vote>, channel_id: ChannelId) -> bool {
  111|      0|        let mut guard = self.rep_crawler_impl.lock().unwrap();
  112|      0|        let mut processed = false;
  113|      0|
  114|      0|        let query_timeout = guard.query_timeout;
  115|      0|        let x = guard.deref_mut();
  116|      0|        let queries = &mut x.queries;
  117|      0|        let responses = &mut x.responses;
  118|      0|        queries.modify_for_channel(channel_id, |query| {
  119|      0|            // TODO: This linear search could be slow, especially with large votes.
  120|      0|            let target_hash = query.hash;
  121|      0|            let found = vote.hashes.iter().any(|h| *h == target_hash);
  122|      0|            let done;
  123|      0|
  124|      0|            if found {
  125|      0|                debug!(
  126|      0|                    "Processing response for block: {} from channel: {}",
  127|       |                    target_hash, channel_id
  128|       |                );
  129|      0|                self.stats
  130|      0|                    .inc_dir(StatType::RepCrawler, DetailType::Response, Direction::In);
  131|      0|
  132|      0|                self.stats.sample(
  133|      0|                    Sample::RepResponseTime,
  134|      0|                    query.time.elapsed().as_millis() as i64,
  135|      0|                    (0, query_timeout.as_millis() as i64),
  136|      0|                );
  137|      0|
  138|      0|                responses.push_back((channel_id, Arc::clone(&vote)));
  139|      0|                query.replies += 1;
  140|      0|                self.condition.notify_all();
  141|      0|                processed = true;
  142|      0|                done = true
  143|       |            } else {
  144|      0|                done = false
  145|       |            }
  146|       |
  147|      0|            done
  148|      0|        });
  149|      0|
  150|      0|        processed
  151|      0|    }
  152|       |
  153|       |    /// Attempt to determine if the peer manages one or more representative accounts
  154|      3|    pub fn query(&self, target_channels: Vec<Arc<Channel>>) {
  155|      3|        let Some(hash_root) = self.prepare_query_target() else {
  156|      0|            debug!("No block to query");
  157|      0|            self.stats.inc_dir(
  158|      0|                StatType::RepCrawler,
  159|      0|                DetailType::QueryTargetFailed,
  160|      0|                Direction::In,
  161|      0|            );
  162|      0|            return;
  163|       |        };
  164|       |
  165|      3|        let mut guard = self.rep_crawler_impl.lock().unwrap();
  166|       |
  167|      3|        for channel in target_channels {
                          ^0
  168|      0|            guard.track_rep_request(hash_root, channel.channel_id(), self.steady_clock.now());
  169|      0|            debug!(
  170|      0|                "Sending query for block: {} to: {}",
  171|      0|                hash_root.0,
  172|      0|                channel.peer_addr()
  173|       |            );
  174|      0|            self.stats
  175|      0|                .inc_dir(StatType::RepCrawler, DetailType::QuerySent, Direction::In);
  176|      0|
  177|      0|            let req = Message::ConfirmReq(ConfirmReq::new(vec![hash_root]));
  178|      0|
  179|      0|            self.message_sender.lock().unwrap().try_send(
  180|      0|                channel.channel_id(),
  181|      0|                &req,
  182|      0|                TrafficType::RepCrawler,
  183|      0|            );
  184|       |        }
  185|      3|    }
  186|       |
  187|       |    /// Attempt to determine if the peer manages one or more representative accounts
  188|      0|    pub fn query_with_priority(&self, target_channel: Arc<Channel>) {
  189|      0|        {
  190|      0|            let mut guard = self.rep_crawler_impl.lock().unwrap();
  191|      0|            guard.prioritized.push(target_channel);
  192|      0|        }
  193|      0|        self.condition.notify_all();
  194|      0|    }
  195|       |
  196|       |    // Only for tests
  197|      0|    pub fn force_process(&self, vote: Arc<Vote>, channel_id: ChannelId) {
  198|      0|        assert!(self.network_params.network.is_dev_network());
  199|      0|        let mut guard = self.rep_crawler_impl.lock().unwrap();
  200|      0|        guard.responses.push_back((channel_id, vote));
  201|      0|    }
  202|       |
  203|       |    // Only for tests
  204|      0|    pub fn force_query(&self, hash: BlockHash, channel_id: ChannelId) {
  205|      0|        assert!(self.network_params.network.is_dev_network());
  206|      0|        let mut guard = self.rep_crawler_impl.lock().unwrap();
  207|      0|        guard.queries.insert(QueryEntry {
  208|      0|            hash,
  209|      0|            channel_id,
  210|      0|            time: Instant::now(),
  211|      0|            replies: 0,
  212|      0|        })
  213|      0|    }
  214|       |
  215|      3|    fn run(&self) {
  216|      3|        let mut guard = self.rep_crawler_impl.lock().unwrap();
  217|      6|        while !guard.stopped {
  218|      6|            drop(guard);
  219|      6|
  220|      6|            let current_total_weight;
  221|      6|            let sufficient_weight;
  222|      6|            {
  223|      6|                let reps = self.online_reps.lock().unwrap();
  224|      6|                current_total_weight = reps.peered_weight();
  225|      6|                sufficient_weight = current_total_weight > reps.quorum_delta();
  226|      6|            }
  227|      6|
  228|      6|            // If online weight drops below minimum, reach out to preconfigured peers
  229|      6|            if !sufficient_weight {
  230|      6|                self.stats
  231|      6|                    .inc_dir(StatType::RepCrawler, DetailType::Keepalive, Direction::In);
  232|      6|
  233|      6|                let peers = self.preconfigured_peers.clone();
  234|      6|                self.tokio.spawn(async move {
  235|      0|                    peers.keepalive().await;
  236|      6|                });
                              ^0
  237|      6|            }
                           ^0
  238|       |
  239|      6|            guard = self.rep_crawler_impl.lock().unwrap();
  240|      6|            let interval = self.query_interval(sufficient_weight);
  241|      6|            guard = self
  242|      6|                .condition
  243|      9|                .wait_timeout_while(guard, interval, |i| {
  244|      9|                    !i.stopped
  245|      6|                        && !i.query_predicate(interval)
  246|      3|                        && i.responses.is_empty()
  247|      3|                        && i.prioritized.is_empty()
  248|      9|                })
  249|      6|                .unwrap()
  250|      6|                .0;
  251|      6|
  252|      6|            if guard.stopped {
  253|      3|                return;
  254|      3|            }
  255|      3|
  256|      3|            self.stats
  257|      3|                .inc_dir(StatType::RepCrawler, DetailType::Loop, Direction::In);
  258|      3|
  259|      3|            if !guard.responses.is_empty() {
  260|      0|                self.validate_and_process(guard);
  261|      0|                guard = self.rep_crawler_impl.lock().unwrap();
  262|      3|            }
  263|       |
  264|      3|            guard.cleanup();
  265|      3|
  266|      3|            if !guard.prioritized.is_empty() {
  267|      0|                let mut prioritized_l = Vec::new();
  268|      0|                std::mem::swap(&mut prioritized_l, &mut guard.prioritized);
  269|      0|                drop(guard);
  270|      0|                self.query(prioritized_l);
  271|      0|                guard = self.rep_crawler_impl.lock().unwrap();
  272|      3|            }
  273|       |
  274|      3|            if guard.query_predicate(interval) {
  275|      3|                guard.last_query = Some(Instant::now());
  276|      3|                drop(guard);
  277|       |
  278|       |                // TODO: Make these values configurable
  279|      0|                const CONSERVATIVE_COUNT: usize = 160;
  280|      0|                const AGGRESSIVE_COUNT: usize = 160;
  281|       |
  282|       |                // Crawl more aggressively if we lack sufficient total peer weight.
  283|      3|                let required_peer_count = if sufficient_weight {
  284|      0|                    CONSERVATIVE_COUNT
  285|       |                } else {
  286|      3|                    AGGRESSIVE_COUNT
  287|       |                };
  288|       |
  289|       |                /* include channels with ephemeral remote ports */
  290|      3|                let random_peers = self
  291|      3|                    .network
  292|      3|                    .read()
  293|      3|                    .unwrap()
  294|      3|                    .random_realtime_channels(required_peer_count, 0);
  295|      3|
  296|      3|                guard = self.rep_crawler_impl.lock().unwrap();
  297|      3|                let targets = guard.prepare_crawl_targets(
  298|      3|                    sufficient_weight,
  299|      3|                    random_peers,
  300|      3|                    self.steady_clock.now(),
  301|      3|                );
  302|      3|                drop(guard);
  303|      3|                self.query(targets);
  304|      3|                guard = self.rep_crawler_impl.lock().unwrap();
  305|      0|            }
  306|       |        }
  307|      3|    }
  308|       |
  309|      0|    fn validate_and_process<'a>(&self, mut guard: MutexGuard<RepCrawlerImpl>) {
  310|      0|        let mut responses = BoundedVecDeque::new(Self::MAX_RESPONSES);
  311|      0|        std::mem::swap(&mut guard.responses, &mut responses);
  312|      0|        drop(guard);
  313|      0|
  314|      0|        // normally the rep_crawler only tracks principal reps but it can be made to track
  315|      0|        // reps with less weight by setting rep_crawler_weight_minimum to a low value
  316|      0|        let minimum = std::cmp::min(
  317|      0|            self.online_reps.lock().unwrap().minimum_principal_weight(),
  318|      0|            self.config.rep_crawler_weight_minimum,
  319|      0|        );
  320|       |
  321|       |        // TODO: Is it really faster to repeatedly lock/unlock the mutex for each response?
  322|      0|        for (channel_id, vote) in responses {
  323|      0|            if channel_id == ChannelId::LOOPBACK {
  324|      0|                debug!("Ignoring vote from loopback channel");
  325|      0|                continue;
  326|      0|            }
  327|      0|
  328|      0|            let rep_weight = self.ledger.weight(&vote.voting_account);
  329|      0|            if rep_weight < minimum {
  330|      0|                debug!(
  331|      0|                    "Ignoring vote from account: {} with too little voting weight: {}",
  332|      0|                    Account::from(vote.voting_account).encode_account(),
  333|      0|                    rep_weight.to_string_dec()
  334|       |                );
  335|      0|                continue;
  336|      0|            }
  337|      0|
  338|      0|            let result = self.online_reps.lock().unwrap().vote_observed_directly(
  339|      0|                vote.voting_account,
  340|      0|                channel_id,
  341|      0|                self.steady_clock.now(),
  342|      0|            );
  343|      0|
  344|      0|            match result {
  345|       |                InsertResult::Inserted => {
  346|      0|                    info!(
  347|      0|                        "Found representative: {} at channel: {}",
  348|      0|                        Account::from(vote.voting_account).encode_account(),
  349|       |                        channel_id
  350|       |                    );
  351|       |                }
  352|      0|                InsertResult::ChannelChanged(previous) => {
  353|      0|                    warn!(
  354|      0|                        "Updated representative: {} at channel: {} (was at: {})",
  355|      0|                        Account::from(vote.voting_account).encode_account(),
  356|       |                        channel_id,
  357|       |                        previous
  358|       |                    )
  359|       |                }
  360|      0|                InsertResult::Updated => {}
  361|       |            }
  362|       |        }
  363|      0|    }
  364|       |
  365|      3|    fn prepare_query_target(&self) -> Option<(BlockHash, Root)> {
  366|       |        const MAX_ATTEMPTS: usize = 10;
  367|       |
  368|      3|        let tx = self.ledger.read_txn();
  369|      3|        let random_blocks = self.ledger.random_blocks(&tx, MAX_ATTEMPTS);
  370|       |
  371|      3|        for block in &random_blocks {
  372|      3|            if !self.active.recently_confirmed.hash_exists(&block.hash()) {
  373|      3|                return Some((block.hash(), block.root()));
  374|      0|            }
  375|       |        }
  376|       |
  377|      0|        None
  378|      3|    }
  379|       |
  380|      6|    fn query_interval(&self, sufficient_weight: bool) -> Duration {
  381|      6|        if sufficient_weight {
  382|      0|            self.network_params.network.rep_crawler_normal_interval
  383|       |        } else {
  384|      6|            self.network_params.network.rep_crawler_warmup_interval
  385|       |        }
  386|      6|    }
  387|       |
  388|      0|    pub fn container_info(&self) -> ContainerInfo {
  389|      0|        let guard = self.rep_crawler_impl.lock().unwrap();
  390|      0|        [
  391|      0|            ("queries", guard.queries.len(), OrderedQueries::ELEMENT_SIZE),
  392|      0|            (
  393|      0|                "responses",
  394|      0|                guard.responses.len(),
  395|      0|                size_of::<Arc<Vote>>() * 2,
  396|      0|            ),
  397|      0|            ("prioritized", guard.prioritized.len(), 0),
  398|      0|        ]
  399|      0|        .into()
  400|      0|    }
  401|       |}
  402|       |
  403|       |impl Drop for RepCrawler {
  404|      3|    fn drop(&mut self) {
  405|      3|        // Thread must be stopped before destruction
  406|      3|        debug_assert!(self.thread.lock().unwrap().is_none())
  407|      3|    }
  408|       |}
  409|       |
  410|       |struct RepCrawlerImpl {
  411|       |    queries: OrderedQueries,
  412|       |    online_reps: Arc<Mutex<OnlineReps>>,
  413|       |    stats: Arc<Stats>,
  414|       |    query_timeout: Duration,
  415|       |    stopped: bool,
  416|       |    last_query: Option<Instant>,
  417|       |    responses: BoundedVecDeque<(ChannelId, Arc<Vote>)>,
  418|       |
  419|       |    /// Freshly established connections that should be queried asap
  420|       |    prioritized: Vec<Arc<Channel>>,
  421|       |    is_dev_network: bool,
  422|       |}
  423|       |
  424|       |impl RepCrawlerImpl {
  425|      9|    fn query_predicate(&self, query_interval: Duration) -> bool {
  426|      9|        match &self.last_query {
  427|      3|            Some(last) => last.elapsed() >= query_interval,
  428|      6|            None => true,
  429|       |        }
  430|      9|    }
  431|       |
  432|      3|    fn prepare_crawl_targets(
  433|      3|        &self,
  434|      3|        sufficient_weight: bool,
  435|      3|        mut random_peers: Vec<Arc<Channel>>,
  436|      3|        now: Timestamp,
  437|      3|    ) -> Vec<Arc<Channel>> {
  438|       |        // TODO: Make these values configurable
  439|       |        const CONSERVATIVE_MAX_ATTEMPTS: usize = 4;
  440|       |        const AGGRESSIVE_MAX_ATTEMPTS: usize = 8;
  441|       |
  442|      3|        let rep_query_interval = if self.is_dev_network {
  443|      3|            Duration::from_millis(500)
  444|       |        } else {
  445|      0|            Duration::from_secs(60)
  446|       |        };
  447|       |
  448|      3|        self.stats.inc_dir(
  449|      3|            StatType::RepCrawler,
  450|      3|            if sufficient_weight {
  451|      0|                DetailType::CrawlNormal
  452|       |            } else {
  453|      3|                DetailType::CrawlAggressive
  454|       |            },
  455|      3|            Direction::In,
  456|      3|        );
  457|      3|
  458|      3|        random_peers.retain(|channel| {
  459|      0|            let elapsed = self
  460|      0|                .online_reps
  461|      0|                .lock()
  462|      0|                .unwrap()
  463|      0|                .last_request_elapsed(channel.channel_id(), now);
  464|      0|
  465|      0|            match elapsed {
  466|      0|                Some(last_request_elapsed) => {
  467|      0|                    // Throttle queries to active reps
  468|      0|                    last_request_elapsed >= rep_query_interval
  469|       |                }
  470|       |                None => {
  471|       |                    // Avoid querying the same peer multiple times when rep crawler is warmed up
  472|      0|                    let max_attemts = if sufficient_weight {
  473|      0|                        CONSERVATIVE_MAX_ATTEMPTS
  474|       |                    } else {
  475|      0|                        AGGRESSIVE_MAX_ATTEMPTS
  476|       |                    };
  477|      0|                    self.queries.count_by_channel(channel.channel_id()) < max_attemts
  478|       |                }
  479|       |            }
  480|      3|        });
                      ^0
  481|      3|
  482|      3|        random_peers
  483|      3|    }
  484|       |
  485|      0|    fn track_rep_request(
  486|      0|        &mut self,
  487|      0|        hash_root: (BlockHash, Root),
  488|      0|        channel_id: ChannelId,
  489|      0|        now: Timestamp,
  490|      0|    ) {
  491|      0|        self.queries.insert(QueryEntry {
  492|      0|            hash: hash_root.0,
  493|      0|            channel_id,
  494|      0|            time: Instant::now(),
  495|      0|            replies: 0,
  496|      0|        });
  497|      0|        // Find and update the timestamp on all reps available on the endpoint (a single host may have multiple reps)
  498|      0|        self.online_reps
  499|      0|            .lock()
  500|      0|            .unwrap()
  501|      0|            .on_rep_request(channel_id, now);
  502|      0|    }
  503|       |
  504|      3|    fn cleanup(&mut self) {
  505|      3|        // Evict queries that haven't been responded to in a while
  506|      3|        self.queries.retain(|query| {
  507|      0|            if query.time.elapsed() < self.query_timeout {
  508|      0|                return true; // Retain
  509|      0|            }
  510|      0|
  511|      0|            if query.replies == 0 {
  512|      0|                debug!(
  513|      0|                    "Aborting unresponsive query for block: {} from channel: {}",
  514|       |                    query.hash, query.channel_id
  515|       |                );
  516|      0|                self.stats.inc_dir(
  517|      0|                    StatType::RepCrawler,
  518|      0|                    DetailType::QueryTimeout,
  519|      0|                    Direction::In,
  520|      0|                );
  521|       |            } else {
  522|      0|                debug!(
  523|      0|                    "Completion of query with: {} replies for block: {} from channel: {}",
  524|       |                    query.replies, query.hash, query.channel_id
  525|       |                );
  526|      0|                self.stats.inc_dir(
  527|      0|                    StatType::RepCrawler,
  528|      0|                    DetailType::QueryCompletion,
  529|      0|                    Direction::In,
  530|      0|                );
  531|       |            }
  532|       |
  533|      0|            false // Retain
  534|      3|        });
                      ^0
  535|      3|    }
  536|       |}
  537|       |
  538|       |struct QueryEntry {
  539|       |    hash: BlockHash,
  540|       |    channel_id: ChannelId,
  541|       |    time: Instant,
  542|       |    /// number of replies to the query
  543|       |    replies: usize,
  544|       |}
  545|       |
  546|       |struct OrderedQueries {
  547|       |    entries: HashMap<usize, QueryEntry>,
  548|       |    sequenced: Vec<usize>,
  549|       |    by_channel: HashMap<ChannelId, Vec<usize>>,
  550|       |    by_hash: HashMap<BlockHash, Vec<usize>>,
  551|       |    next_id: usize,
  552|       |}
  553|       |
  554|       |impl OrderedQueries {
  555|      3|    fn new() -> Self {
  556|      3|        Self {
  557|      3|            entries: HashMap::new(),
  558|      3|            sequenced: Vec::new(),
  559|      3|            by_channel: HashMap::new(),
  560|      3|            by_hash: HashMap::new(),
  561|      3|            next_id: 1,
  562|      3|        }
  563|      3|    }
  564|       |
  565|       |    pub const ELEMENT_SIZE: usize =
  566|       |        size_of::<QueryEntry>() + size_of::<BlockHash>() + size_of::<usize>() * 3;
  567|       |
  568|      0|    pub fn len(&self) -> usize {
  569|      0|        self.entries.len()
  570|      0|    }
  571|       |
  572|      0|    fn insert(&mut self, entry: QueryEntry) {
  573|      0|        let entry_id = self.next_id;
  574|      0|        self.next_id = self.next_id.wrapping_add(1);
  575|      0|        self.sequenced.push(entry_id);
  576|      0|        self.by_channel
  577|      0|            .entry(entry.channel_id)
  578|      0|            .or_default()
  579|      0|            .push(entry_id);
  580|      0|        self.by_hash.entry(entry.hash).or_default().push(entry_id);
  581|      0|        self.entries.insert(entry_id, entry);
  582|      0|    }
  583|       |
  584|      3|    fn retain(&mut self, predicate: impl Fn(&QueryEntry) -> bool) {
  585|      3|        let mut to_delete = Vec::new();
  586|      3|        for (&id, entry) in &self.entries {
                            ^0
  587|      0|            if !predicate(entry) {
  588|      0|                to_delete.push(id);
  589|      0|            }
  590|       |        }
  591|      3|        for id in to_delete {
                          ^0
  592|      0|            self.remove(id);
  593|      0|        }
  594|      3|    }
  595|       |
  596|      0|    fn remove(&mut self, entry_id: usize) {
  597|      0|        if let Some(entry) = self.entries.remove(&entry_id) {
  598|      0|            self.sequenced.retain(|id| *id != entry_id);
  599|      0|            if let Some(mut by_channel) = self.by_channel.remove(&entry.channel_id) {
  600|      0|                if by_channel.len() > 1 {
  601|      0|                    by_channel.retain(|i| *i != entry_id);
  602|      0|                    self.by_channel.insert(entry.channel_id, by_channel);
  603|      0|                }
  604|      0|            }
  605|      0|            if let Some(mut by_hash) = self.by_hash.remove(&entry.hash) {
  606|      0|                if by_hash.len() > 1 {
  607|      0|                    by_hash.retain(|i| *i != entry_id);
  608|      0|                    self.by_hash.insert(entry.hash, by_hash);
  609|      0|                }
  610|      0|            }
  611|      0|        }
  612|      0|    }
  613|       |
  614|      0|    fn count_by_channel(&self, channel_id: ChannelId) -> usize {
  615|      0|        self.by_channel
  616|      0|            .get(&channel_id)
  617|      0|            .map(|i| i.len())
  618|      0|            .unwrap_or_default()
  619|      0|    }
  620|       |
  621|      0|    fn modify_for_channel(
  622|      0|        &mut self,
  623|      0|        channel_id: ChannelId,
  624|      0|        mut f: impl FnMut(&mut QueryEntry) -> bool,
  625|      0|    ) {
  626|      0|        if let Some(ids) = self.by_channel.get(&channel_id) {
  627|      0|            for id in ids {
  628|      0|                if let Some(entry) = self.entries.get_mut(id) {
  629|      0|                    let done = f(entry);
  630|      0|                    if done {
  631|      0|                        return;
  632|      0|                    }
  633|      0|                }
  634|       |            }
  635|      0|        }
  636|      0|    }
  637|       |}
  638|       |
  639|       |pub trait RepCrawlerExt {
  640|       |    fn start(&self);
  641|       |}
  642|       |
  643|       |impl RepCrawlerExt for Arc<RepCrawler> {
  644|      3|    fn start(&self) {
  645|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  646|      3|        let self_l = Arc::clone(self);
  647|      3|        *self.thread.lock().unwrap() = Some(
  648|      3|            std::thread::Builder::new()
  649|      3|                .name("Rep Crawler".to_string())
  650|      3|                .spawn(Box::new(move || {
  651|      3|                    self_l.run();
  652|      3|                }))
  653|      3|                .unwrap(),
  654|      3|        );
  655|      3|    }
  656|       |}

/home/gustav/code/nano/rsnano-node/node/src/secure/bootstrap_constants.rs:
    1|       |use crate::config::NetworkConstants;
    2|       |
    3|       |#[derive(Clone)]
    4|       |pub struct BootstrapConstants {
    5|       |    pub lazy_max_pull_blocks: u32,
    6|       |    pub lazy_min_pull_blocks: u32,
    7|       |    pub frontier_retry_limit: u32,
    8|       |    pub lazy_retry_limit: u32,
    9|       |    pub lazy_destinations_retry_limit: u32,
   10|       |    pub gap_cache_bootstrap_start_interval_ms: i64,
   11|       |    pub default_frontiers_age_seconds: u32,
   12|       |}
   13|       |
   14|       |impl BootstrapConstants {
   15|      8|    pub fn new(network_constants: &NetworkConstants) -> Self {
   16|      8|        let frontier_retry_limit = if network_constants.is_dev_network() {
   17|      4|            2
   18|       |        } else {
   19|      4|            16
   20|       |        };
   21|       |        Self {
   22|      8|            lazy_max_pull_blocks: if network_constants.is_dev_network() {
   23|      4|                2
   24|       |            } else {
   25|      4|                512
   26|       |            },
   27|      8|            lazy_min_pull_blocks: if network_constants.is_dev_network() {
   28|      4|                1
   29|       |            } else {
   30|      4|                32
   31|       |            },
   32|      8|            frontier_retry_limit,
   33|      8|            lazy_retry_limit: if network_constants.is_dev_network() {
   34|      4|                2
   35|       |            } else {
   36|      4|                frontier_retry_limit * 4
   37|       |            },
   38|      8|            lazy_destinations_retry_limit: if network_constants.is_dev_network() {
   39|      4|                1
   40|       |            } else {
   41|      4|                frontier_retry_limit / 4
   42|       |            },
   43|      8|            gap_cache_bootstrap_start_interval_ms: if network_constants.is_dev_network() {
   44|      4|                5
   45|       |            } else {
   46|      4|                30 * 1000
   47|       |            },
   48|      8|            default_frontiers_age_seconds: if network_constants.is_dev_network() {
   49|      4|                1
   50|       |            } else {
   51|      4|                24 * 60 * 60
   52|       |            }, // 1 second for dev network, 24 hours for live/beta
   53|       |        }
   54|      8|    }
   55|       |}

/home/gustav/code/nano/rsnano-node/node/src/secure/network_params.rs:
    1|       |use crate::{
    2|       |    config::NetworkConstants, BootstrapConstants, NodeConstants, PortmappingConstants,
    3|       |    VotingConstants,
    4|       |};
    5|       |use once_cell::sync::Lazy;
    6|       |use rsnano_core::{work::WorkThresholds, Networks};
    7|       |use rsnano_ledger::LedgerConstants;
    8|       |
    9|       |pub static DEV_NETWORK_PARAMS: Lazy<NetworkParams> =
   10|      1|    Lazy::new(|| NetworkParams::new(Networks::NanoDevNetwork));
   11|       |
   12|       |#[derive(Clone)]
   13|       |pub struct NetworkParams {
   14|       |    pub kdf_work: u32,
   15|       |    pub work: WorkThresholds,
   16|       |    pub network: NetworkConstants,
   17|       |    pub ledger: LedgerConstants,
   18|       |    pub voting: VotingConstants,
   19|       |    pub node: NodeConstants,
   20|       |    pub portmapping: PortmappingConstants,
   21|       |    pub bootstrap: BootstrapConstants,
   22|       |}
   23|       |
   24|       |impl NetworkParams {
   25|      8|    pub fn new(network: Networks) -> Self {
   26|      8|        let work = if network == Networks::NanoLiveNetwork {
   27|      0|            WorkThresholds::publish_full()
   28|      8|        } else if network == Networks::NanoBetaNetwork {
   29|      4|            WorkThresholds::publish_beta()
   30|      4|        } else if network == Networks::NanoTestNetwork {
   31|      0|            WorkThresholds::publish_test()
   32|       |        } else {
   33|      4|            WorkThresholds::publish_dev()
   34|       |        };
   35|      8|        let network_constants = NetworkConstants::new(work.clone(), network);
   36|      8|        let kdf_full_work = 64 * 1024;
   37|      8|        let kdf_dev_work = 8;
   38|      8|        Self {
   39|      8|            kdf_work: if network_constants.is_dev_network() {
   40|      4|                kdf_dev_work
   41|       |            } else {
   42|      4|                kdf_full_work
   43|       |            },
   44|      8|            work: work.clone(),
   45|      8|            ledger: LedgerConstants::new(work.clone(), network),
   46|      8|            voting: VotingConstants::new(&network_constants),
   47|      8|            node: NodeConstants::new(&network_constants),
   48|      8|            portmapping: PortmappingConstants::new(&network_constants),
   49|      8|            bootstrap: BootstrapConstants::new(&network_constants),
   50|      8|            network: network_constants,
   51|      8|        }
   52|      8|    }
   53|       |}

/home/gustav/code/nano/rsnano-node/node/src/secure/node_constants.rs:
    1|       |use crate::config::NetworkConstants;
    2|       |
    3|       |#[derive(Clone)]
    4|       |pub struct NodeConstants {
    5|       |    pub backup_interval_m: i64,
    6|       |    pub search_pending_interval_s: i64,
    7|       |    pub unchecked_cleaning_interval_m: i64,
    8|       |    pub process_confirmed_interval_ms: i64,
    9|       |}
   10|       |
   11|       |impl NodeConstants {
   12|      8|    pub fn new(network_constants: &NetworkConstants) -> Self {
   13|      8|        Self {
   14|      8|            backup_interval_m: 5,
   15|      8|            search_pending_interval_s: if network_constants.is_dev_network() {
   16|      4|                1
   17|       |            } else {
   18|      4|                5 * 60
   19|       |            },
   20|       |            unchecked_cleaning_interval_m: 30,
   21|      8|            process_confirmed_interval_ms: if network_constants.is_dev_network() {
   22|      4|                50
   23|       |            } else {
   24|      4|                500
   25|       |            },
   26|       |        }
   27|      8|    }
   28|       |}

/home/gustav/code/nano/rsnano-node/node/src/secure/portmapping_constants.rs:
    1|       |use crate::config::NetworkConstants;
    2|       |
    3|       |#[derive(Clone)]
    4|       |pub struct PortmappingConstants {
    5|       |    pub lease_duration_s: i64,
    6|       |    pub health_check_period_s: i64,
    7|       |}
    8|       |
    9|       |impl PortmappingConstants {
   10|      8|    pub fn new(_: &NetworkConstants) -> Self {
   11|      8|        Self {
   12|      8|            lease_duration_s: 1787, // ~30 minutes
   13|      8|            health_check_period_s: 53,
   14|      8|        }
   15|      8|    }
   16|       |}

/home/gustav/code/nano/rsnano-node/node/src/secure/utility.rs:
    1|       |use once_cell::sync::Lazy;
    2|       |use rsnano_core::Networks;
    3|       |use std::{path::PathBuf, sync::Mutex};
    4|       |use uuid::Uuid;
    5|       |
    6|       |use crate::config::NetworkConstants;
    7|       |
    8|       |//todo refactor: this global state thing is not a good solution
    9|      0|static ALL_UNIQUE_PATHS: Lazy<Mutex<Vec<PathBuf>>> = Lazy::new(|| Mutex::new(Vec::new()));
   10|       |
   11|      0|pub fn working_path() -> Option<PathBuf> {
   12|      0|    working_path_for(NetworkConstants::active_network())
   13|      0|}
   14|      0|pub fn working_path_for(network: Networks) -> Option<PathBuf> {
   15|      0|    if let Ok(path_override) = std::env::var("NANO_APP_PATH") {
   16|      0|        eprintln!(
   17|      0|            "Application path overridden by NANO_APP_PATH environment variable: {path_override}"
   18|      0|        );
   19|      0|        return Some(path_override.into());
   20|      0|    }
   21|      0|
   22|      0|    dirs::home_dir().and_then(|mut path| {
   23|      0|        let subdir = match network {
   24|      0|            Networks::Invalid => return None,
   25|      0|            Networks::NanoDevNetwork => "NanoDev",
   26|      0|            Networks::NanoBetaNetwork => "NanoBeta",
   27|      0|            Networks::NanoLiveNetwork => "Nano",
   28|      0|            Networks::NanoTestNetwork => "NanoTest",
   29|       |        };
   30|      0|        path.push(subdir);
   31|      0|        Some(path)
   32|      0|    })
   33|      0|}
   34|       |
   35|      0|pub fn unique_path() -> Option<PathBuf> {
   36|      0|    unique_path_for(Networks::NanoDevNetwork)
   37|      0|}
   38|       |
   39|      0|pub fn unique_path_for(network: Networks) -> Option<PathBuf> {
   40|      0|    working_path_for(network).map(|mut path| {
   41|      0|        let uuid = Uuid::new_v4();
   42|      0|        path.push(uuid.to_string());
   43|      0|        ALL_UNIQUE_PATHS.lock().unwrap().push(path.clone());
   44|      0|        std::fs::create_dir_all(&path).unwrap();
   45|      0|        path
   46|      0|    })
   47|      0|}
   48|       |
   49|      0|pub fn remove_temporary_directories() {
   50|      0|    let mut all = ALL_UNIQUE_PATHS.lock().unwrap();
   51|      0|    for path in all.iter() {
   52|      0|        if let Ok(meta) = std::fs::metadata(path) {
   53|      0|            if meta.is_file() {
   54|      0|                if let Err(e) = std::fs::remove_file(path) {
   55|      0|                    eprintln!("Could not remove temporary file '{:?}': {}", path, e);
   56|      0|                }
   57|      0|            } else if meta.is_dir() {
   58|      0|                if let Err(e) = std::fs::remove_dir_all(path) {
   59|      0|                    eprintln!("Could not remove temporary directory '{:?}': {}", path, e);
   60|      0|                }
   61|      0|            }
   62|      0|        }
   63|       |    }
   64|      0|    all.clear();
   65|      0|}

/home/gustav/code/nano/rsnano-node/node/src/secure/voting_constants.rs:
    1|       |use crate::config::NetworkConstants;
    2|       |use std::time::Duration;
    3|       |
    4|       |#[derive(Clone)]
    5|       |pub struct VotingConstants {
    6|       |    pub max_cache: usize,
    7|       |    pub delay: Duration,
    8|       |}
    9|       |
   10|       |impl VotingConstants {
   11|      8|    pub fn new(network_constants: &NetworkConstants) -> Self {
   12|      8|        Self {
   13|      8|            max_cache: if network_constants.is_dev_network() {
   14|      4|                256
   15|       |            } else {
   16|      4|                128 * 1024
   17|       |            },
   18|      8|            delay: if network_constants.is_dev_network() {
   19|      4|                Duration::from_secs(1)
   20|       |            } else {
   21|      4|                Duration::from_secs(15)
   22|       |            },
   23|       |        }
   24|      8|    }
   25|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/adapters/ledger_stats.rs:
    1|       |use crate::stats::{DetailType, Direction, StatType, Stats};
    2|       |use rsnano_core::{Block, BlockSubType};
    3|       |use rsnano_ledger::LedgerObserver;
    4|       |use std::sync::Arc;
    5|       |
    6|       |pub struct LedgerStats {
    7|       |    stats: Arc<Stats>,
    8|       |}
    9|       |
   10|       |impl LedgerStats {
   11|      3|    pub fn new(stats: Arc<Stats>) -> Self {
   12|      3|        Self { stats }
   13|      3|    }
   14|       |}
   15|       |
   16|       |impl LedgerObserver for LedgerStats {
   17|      0|    fn blocks_cemented(&self, cemented_count: u64) {
   18|      0|        self.stats.add_dir(
   19|      0|            StatType::ConfirmationHeight,
   20|      0|            DetailType::BlocksConfirmed,
   21|      0|            Direction::In,
   22|      0|            cemented_count,
   23|      0|        );
   24|      0|    }
   25|       |
   26|      0|    fn block_rolled_back(&self, block_type: BlockSubType) {
   27|      0|        self.stats.inc(StatType::Rollback, block_type.into());
   28|      0|    }
   29|       |
   30|      0|    fn block_rolled_back2(&self, block: &Block, is_epoch: bool) {
   31|      0|        self.stats
   32|      0|            .inc(StatType::Ledger, block_detail_type(block, is_epoch));
   33|      0|    }
   34|       |
   35|      0|    fn dependent_unconfirmed(&self) {
   36|      0|        self.stats.inc(
   37|      0|            StatType::ConfirmationHeight,
   38|      0|            DetailType::DependentUnconfirmed,
   39|      0|        );
   40|      0|    }
   41|       |}
   42|       |
   43|      0|fn block_detail_type(block: &Block, is_epoch: bool) -> DetailType {
   44|      0|    match block {
   45|      0|        Block::LegacySend(_) => DetailType::Send,
   46|      0|        Block::LegacyReceive(_) => DetailType::Receive,
   47|      0|        Block::LegacyOpen(_) => DetailType::Open,
   48|      0|        Block::LegacyChange(_) => DetailType::Change,
   49|       |        Block::State(_) => {
   50|      0|            if is_epoch {
   51|      0|                DetailType::EpochBlock
   52|       |            } else {
   53|      0|                DetailType::StateBlock
   54|       |            }
   55|       |        }
   56|       |    }
   57|      0|}
   58|       |
   59|       |impl From<BlockSubType> for DetailType {
   60|      0|    fn from(block_type: BlockSubType) -> Self {
   61|      0|        match block_type {
   62|      0|            BlockSubType::Send => DetailType::Send,
   63|      0|            BlockSubType::Receive => DetailType::Receive,
   64|      0|            BlockSubType::Open => DetailType::Open,
   65|      0|            BlockSubType::Change => DetailType::Change,
   66|      0|            BlockSubType::Epoch => DetailType::EpochBlock,
   67|       |        }
   68|      0|    }
   69|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/adapters/mod.rs:
    1|       |mod ledger_stats;
    2|       |mod network_stats;
    3|       |mod parse_message_error;
    4|       |pub use ledger_stats::LedgerStats;
    5|       |pub use network_stats::*;
    6|       |
    7|       |use rsnano_core::VoteSource;
    8|       |use rsnano_ledger::BlockStatus;
    9|       |use rsnano_messages::Message;
   10|       |
   11|       |use super::DetailType;
   12|       |
   13|       |impl From<BlockStatus> for DetailType {
   14|      0|    fn from(value: BlockStatus) -> Self {
   15|      0|        match value {
   16|      0|            BlockStatus::Progress => Self::Progress,
   17|      0|            BlockStatus::BadSignature => Self::BadSignature,
   18|      0|            BlockStatus::Old => Self::Old,
   19|      0|            BlockStatus::NegativeSpend => Self::NegativeSpend,
   20|      0|            BlockStatus::Fork => Self::Fork,
   21|      0|            BlockStatus::Unreceivable => Self::Unreceivable,
   22|      0|            BlockStatus::GapPrevious => Self::GapPrevious,
   23|      0|            BlockStatus::GapSource => Self::GapSource,
   24|      0|            BlockStatus::GapEpochOpenPending => Self::GapEpochOpenPending,
   25|      0|            BlockStatus::OpenedBurnAccount => Self::OpenedBurnAccount,
   26|      0|            BlockStatus::BalanceMismatch => Self::BalanceMismatch,
   27|      0|            BlockStatus::RepresentativeMismatch => Self::RepresentativeMismatch,
   28|      0|            BlockStatus::BlockPosition => Self::BlockPosition,
   29|      0|            BlockStatus::InsufficientWork => Self::InsufficientWork,
   30|       |        }
   31|      0|    }
   32|       |}
   33|       |
   34|       |impl From<&Message> for DetailType {
   35|      0|    fn from(value: &Message) -> Self {
   36|      0|        value.message_type().into()
   37|      0|    }
   38|       |}
   39|       |
   40|       |impl From<VoteSource> for DetailType {
   41|      0|    fn from(value: VoteSource) -> Self {
   42|      0|        match value {
   43|      0|            VoteSource::Live => Self::Live,
   44|      0|            VoteSource::Rebroadcast => Self::Rebroadcast,
   45|      0|            VoteSource::Cache => Self::Cache,
   46|       |        }
   47|      0|    }
   48|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/adapters/network_stats.rs:
    1|       |use crate::stats::{DetailType, Direction, StatType, Stats};
    2|       |use anyhow::Error;
    3|       |use rsnano_network::{Channel, ChannelDirection, NetworkError, NetworkObserver, TrafficType};
    4|       |use std::{net::SocketAddrV6, sync::Arc};
    5|       |use tracing::{debug, trace};
    6|       |
    7|       |#[derive(Clone)]
    8|       |pub struct NetworkStats(Arc<Stats>);
    9|       |
   10|       |impl NetworkStats {
   11|      3|    pub fn new(stats: Arc<Stats>) -> Self {
   12|      3|        Self(stats)
   13|      3|    }
   14|       |}
   15|       |
   16|       |impl NetworkObserver for NetworkStats {
   17|      0|    fn send_succeeded(&self, buf_size: usize, traffic_type: TrafficType) {
   18|      0|        self.0.add_dir_aggregate(
   19|      0|            StatType::TrafficTcp,
   20|      0|            DetailType::All,
   21|      0|            Direction::Out,
   22|      0|            buf_size as u64,
   23|      0|        );
   24|      0|        self.0.add_dir(
   25|      0|            StatType::TrafficTcpType,
   26|      0|            traffic_type.into(),
   27|      0|            Direction::Out,
   28|      0|            buf_size as u64,
   29|      0|        );
   30|      0|    }
   31|       |
   32|      0|    fn send_failed(&self) {
   33|      0|        self.0
   34|      0|            .inc_dir(StatType::Tcp, DetailType::TcpWriteError, Direction::In);
   35|      0|    }
   36|       |
   37|      0|    fn channel_timed_out(&self, channel: &Channel) {
   38|      0|        self.0.inc_dir(
   39|      0|            StatType::Tcp,
   40|      0|            DetailType::TcpIoTimeoutDrop,
   41|      0|            if channel.direction() == ChannelDirection::Inbound {
   42|      0|                Direction::In
   43|       |            } else {
   44|      0|                Direction::Out
   45|       |            },
   46|       |        );
   47|      0|        debug!(
   48|      0|            channel_id = %channel.channel_id(),
   49|      0|            remote_addr = ?channel.peer_addr(),
   50|      0|            mode = ?channel.mode(),
   51|      0|            direction = ?channel.direction(),
   52|      0|            "Closing channel due to timeout");
   53|      0|    }
   54|       |
   55|      0|    fn read_succeeded(&self, count: usize) {
   56|      0|        self.0.add_dir(
   57|      0|            StatType::TrafficTcp,
   58|      0|            DetailType::All,
   59|      0|            Direction::In,
   60|      0|            count as u64,
   61|      0|        );
   62|      0|    }
   63|       |
   64|      0|    fn read_failed(&self) {
   65|      0|        self.0
   66|      0|            .inc_dir(StatType::Tcp, DetailType::TcpReadError, Direction::In);
   67|      0|    }
   68|       |
   69|      0|    fn connection_attempt(&self, peer: &SocketAddrV6) {
   70|      0|        self.0.inc_dir(
   71|      0|            StatType::TcpListener,
   72|      0|            DetailType::ConnectInitiate,
   73|      0|            Direction::Out,
   74|      0|        );
   75|      0|        debug!(?peer, "Initiate outgoing connection");
   76|      0|    }
   77|       |
   78|      0|    fn accepted(&self, peer: &SocketAddrV6, direction: ChannelDirection) {
   79|      0|        if direction == ChannelDirection::Outbound {
   80|      0|            self.0.inc_dir(
   81|      0|                StatType::TcpListener,
   82|      0|                DetailType::ConnectSuccess,
   83|      0|                direction.into(),
   84|      0|            );
   85|      0|        } else {
   86|      0|            self.0.inc_dir(
   87|      0|                StatType::TcpListener,
   88|      0|                DetailType::AcceptSuccess,
   89|      0|                direction.into(),
   90|      0|            );
   91|      0|        }
   92|      0|        debug!(%peer, ?direction, "New channel added");
   93|      0|    }
   94|       |
   95|      0|    fn error(&self, error: NetworkError, peer: &SocketAddrV6, direction: ChannelDirection) {
   96|      0|        match direction {
   97|      0|            ChannelDirection::Inbound => {
   98|      0|                self.0.inc_dir(
   99|      0|                    StatType::TcpListener,
  100|      0|                    DetailType::AcceptRejected,
  101|      0|                    Direction::In,
  102|      0|                );
  103|      0|            }
  104|      0|            ChannelDirection::Outbound => {
  105|      0|                self.0.inc_dir(
  106|      0|                    StatType::TcpListener,
  107|      0|                    DetailType::ConnectRejected,
  108|      0|                    Direction::Out,
  109|      0|                );
  110|      0|            }
  111|       |        }
  112|       |
  113|      0|        match error {
  114|       |            NetworkError::MaxConnections => {
  115|      0|                self.0.inc_dir(
  116|      0|                    StatType::TcpListenerRejected,
  117|      0|                    DetailType::MaxAttempts,
  118|      0|                    direction.into(),
  119|      0|                );
  120|      0|                debug!(
  121|       |                    %peer,
  122|       |                    ?direction,
  123|      0|                    "Max connections reached, unable to make new connection",
  124|       |                );
  125|       |            }
  126|       |            NetworkError::PeerExcluded => {
  127|      0|                self.0.inc_dir(
  128|      0|                    StatType::TcpListenerRejected,
  129|      0|                    DetailType::Excluded,
  130|      0|                    direction.into(),
  131|      0|                );
  132|      0|                debug!(
  133|       |                    %peer,
  134|       |                    ?direction,
  135|      0|                    "Peer excluded, unable to make new connection",
  136|       |                );
  137|       |            }
  138|       |            NetworkError::MaxConnectionsPerSubnetwork => {
  139|      0|                self.0.inc_dir(
  140|      0|                    StatType::TcpListenerRejected,
  141|      0|                    DetailType::MaxPerSubnetwork,
  142|      0|                    direction.into(),
  143|      0|                );
  144|      0|                self.0.inc_dir(
  145|      0|                    StatType::Tcp,
  146|      0|                    DetailType::MaxPerSubnetwork,
  147|      0|                    direction.into(),
  148|      0|                );
  149|      0|                debug!(
  150|       |                    %peer,
  151|       |                    ?direction,
  152|      0|                    "Max connections per subnetwork reached, unable to open new connection",
  153|       |                );
  154|       |            }
  155|       |            NetworkError::MaxConnectionsPerIp => {
  156|      0|                self.0.inc_dir(
  157|      0|                    StatType::TcpListenerRejected,
  158|      0|                    DetailType::MaxPerIp,
  159|      0|                    direction.into(),
  160|      0|                );
  161|      0|                self.0
  162|      0|                    .inc_dir(StatType::Tcp, DetailType::MaxPerIp, direction.into());
  163|      0|                debug!(
  164|       |                    %peer,
  165|       |                    ?direction,
  166|      0|                    "Max connections per IP reached, unable to open new connection");
  167|       |            }
  168|       |            NetworkError::InvalidIp => {
  169|      0|                self.0.inc_dir(
  170|      0|                    StatType::TcpListenerRejected,
  171|      0|                    DetailType::NotAPeer,
  172|      0|                    direction.into(),
  173|      0|                );
  174|      0|                debug!(
  175|       |                    %peer,
  176|       |                    ?direction,
  177|      0|                    "Invalid IP, unable to open new connection");
  178|       |            }
  179|       |            NetworkError::DuplicateConnection => {
  180|      0|                self.0.inc_dir(
  181|      0|                    StatType::TcpListenerRejected,
  182|      0|                    DetailType::Duplicate,
  183|      0|                    direction.into(),
  184|      0|                );
  185|      0|                trace!(
  186|       |                    %peer,
  187|       |                    ?direction,
  188|      0|                    "Already connected to that peer, unable to open new connection");
  189|       |            }
  190|       |        }
  191|      0|    }
  192|       |
  193|      0|    fn connect_error(&self, peer: SocketAddrV6, e: Error) {
  194|      0|        self.0.inc_dir(
  195|      0|            StatType::TcpListener,
  196|      0|            DetailType::ConnectError,
  197|      0|            Direction::Out,
  198|      0|        );
  199|      0|        debug!("Error connecting to: {} ({:?})", peer, e);
  200|      0|    }
  201|       |
  202|      0|    fn attempt_timeout(&self, peer: SocketAddrV6) {
  203|      0|        self.0
  204|      0|            .inc(StatType::TcpListener, DetailType::AttemptTimeout);
  205|      0|        debug!("Connection attempt timed out: {}", peer);
  206|      0|    }
  207|       |
  208|      0|    fn attempt_cancelled(&self, peer: SocketAddrV6) {
  209|      0|        debug!("Connection attempt cancelled: {}", peer,);
  210|      0|    }
  211|       |
  212|      0|    fn merge_peer(&self) {
  213|      0|        self.0.inc(StatType::Network, DetailType::MergePeer);
  214|      0|    }
  215|       |
  216|      0|    fn accept_failure(&self) {
  217|      0|        self.0.inc_dir(
  218|      0|            StatType::TcpListener,
  219|      0|            DetailType::AcceptFailure,
  220|      0|            Direction::In,
  221|      0|        );
  222|      0|    }
  223|       |}
  224|       |
  225|       |impl From<ChannelDirection> for Direction {
  226|      0|    fn from(value: ChannelDirection) -> Self {
  227|      0|        match value {
  228|      0|            ChannelDirection::Inbound => Direction::In,
  229|      0|            ChannelDirection::Outbound => Direction::Out,
  230|       |        }
  231|      0|    }
  232|       |}
  233|       |
  234|       |impl From<TrafficType> for DetailType {
  235|      0|    fn from(value: TrafficType) -> Self {
  236|      0|        match value {
  237|      0|            TrafficType::Generic => DetailType::Generic,
  238|      0|            TrafficType::BootstrapServer => DetailType::BootstrapServer,
  239|      0|            TrafficType::BootstrapRequests => DetailType::BootstrapRequests,
  240|      0|            TrafficType::BlockBroadcast => DetailType::BlockBroadcast,
  241|      0|            TrafficType::BlockBroadcastInitial => DetailType::BlockBroadcastInitial,
  242|      0|            TrafficType::BlockBroadcastRpc => DetailType::BlockBroadcastRpc,
  243|      0|            TrafficType::ConfirmationRequests => DetailType::ConfirmationRequests,
  244|      0|            TrafficType::Keepalive => DetailType::Keepalive,
  245|      0|            TrafficType::Vote => DetailType::Vote,
  246|      0|            TrafficType::VoteRebroadcast => DetailType::VoteRebroadcast,
  247|      0|            TrafficType::RepCrawler => DetailType::RepCrawler,
  248|      0|            TrafficType::VoteReply => DetailType::VoteReply,
  249|      0|            TrafficType::Telemetry => DetailType::Telemetry,
  250|       |        }
  251|      0|    }
  252|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/adapters/parse_message_error.rs:
    1|       |use super::DetailType;
    2|       |use rsnano_messages::{MessageType, ParseMessageError};
    3|       |
    4|       |impl From<&ParseMessageError> for DetailType {
    5|      0|    fn from(status: &ParseMessageError) -> Self {
    6|      0|        match status {
    7|      0|            ParseMessageError::Other(_) | ParseMessageError::Stopped => Self::All,
    8|      0|            ParseMessageError::InsufficientWork => Self::InsufficientWork,
    9|      0|            ParseMessageError::InvalidHeader => Self::InvalidHeader,
   10|      0|            ParseMessageError::InvalidMessageType => Self::InvalidMessageType,
   11|       |            ParseMessageError::InvalidMessage(MessageType::Keepalive) => {
   12|      0|                Self::InvalidKeepaliveMessage
   13|       |            }
   14|      0|            ParseMessageError::InvalidMessage(MessageType::Publish) => Self::InvalidPublishMessage,
   15|       |            ParseMessageError::InvalidMessage(MessageType::ConfirmReq) => {
   16|      0|                Self::InvalidConfirmReqMessage
   17|       |            }
   18|       |            ParseMessageError::InvalidMessage(MessageType::ConfirmAck) => {
   19|      0|                Self::InvalidConfirmAckMessage
   20|       |            }
   21|       |            ParseMessageError::InvalidMessage(MessageType::NodeIdHandshake) => {
   22|      0|                Self::InvalidNodeIdHandshakeMessage
   23|       |            }
   24|       |            ParseMessageError::InvalidMessage(MessageType::TelemetryReq) => {
   25|      0|                Self::InvalidTelemetryReqMessage
   26|       |            }
   27|       |            ParseMessageError::InvalidMessage(MessageType::TelemetryAck) => {
   28|      0|                Self::InvalidTelemetryAckMessage
   29|       |            }
   30|       |            ParseMessageError::InvalidMessage(MessageType::BulkPull) => {
   31|      0|                Self::InvalidBulkPullMessage
   32|       |            }
   33|       |            ParseMessageError::InvalidMessage(MessageType::BulkPullAccount) => {
   34|      0|                Self::InvalidBulkPullAccountMessage
   35|       |            }
   36|       |            ParseMessageError::InvalidMessage(MessageType::FrontierReq) => {
   37|      0|                Self::InvalidFrontierReqMessage
   38|       |            }
   39|       |            ParseMessageError::InvalidMessage(MessageType::AscPullReq) => {
   40|      0|                Self::InvalidAscPullReqMessage
   41|       |            }
   42|       |            ParseMessageError::InvalidMessage(MessageType::AscPullAck) => {
   43|      0|                Self::InvalidAscPullAckMessage
   44|       |            }
   45|      0|            ParseMessageError::InvalidMessage(MessageType::BulkPush) => Self::InvalidMessageType,
   46|       |            ParseMessageError::InvalidMessage(MessageType::Invalid)
   47|      0|            | ParseMessageError::InvalidMessage(MessageType::NotAType) => Self::InvalidMessageType,
   48|      0|            ParseMessageError::InvalidNetwork => Self::InvalidNetwork,
   49|      0|            ParseMessageError::OutdatedVersion => Self::OutdatedVersion,
   50|      0|            ParseMessageError::DuplicatePublishMessage => Self::DuplicatePublishMessage,
   51|      0|            ParseMessageError::DuplicateConfirmAckMessage => Self::DuplicateConfirmAckMessage,
   52|      0|            ParseMessageError::MessageSizeTooBig => Self::MessageSizeTooBig,
   53|       |        }
   54|      0|    }
   55|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/stats.rs:
    1|       |use super::{DetailType, Direction, Sample, StatType};
    2|       |use super::{StatFileWriter, StatsConfig, StatsLogSink};
    3|       |use anyhow::Result;
    4|       |use bounded_vec_deque::BoundedVecDeque;
    5|       |use once_cell::sync::Lazy;
    6|       |use rsnano_core::utils::get_env_bool;
    7|       |use rsnano_messages::MessageType;
    8|       |use std::{
    9|       |    collections::BTreeMap,
   10|       |    sync::{atomic::AtomicU64, Arc, Condvar, Mutex, RwLock},
   11|       |    thread::JoinHandle,
   12|       |    time::{Duration, Instant, SystemTime},
   13|       |};
   14|       |use tracing::debug;
   15|       |
   16|       |pub struct Stats {
   17|       |    config: StatsConfig,
   18|       |    mutables: Arc<RwLock<StatMutables>>,
   19|       |    thread: Mutex<Option<JoinHandle<()>>>,
   20|       |    stats_loop: Arc<StatsLoop>,
   21|       |    enable_logging: bool,
   22|       |}
   23|       |
   24|       |impl Default for Stats {
   25|     32|    fn default() -> Self {
   26|     32|        Self::new(StatsConfig::default())
   27|     32|    }
   28|       |}
   29|       |
   30|       |impl Stats {
   31|     59|    pub fn new(config: StatsConfig) -> Self {
   32|     59|        let mutables = Arc::new(RwLock::new(StatMutables {
   33|     59|            counters: BTreeMap::new(),
   34|     59|            samplers: BTreeMap::new(),
   35|     59|            timestamp: Instant::now(),
   36|     59|        }));
   37|     59|        Self {
   38|     59|            config: config.clone(),
   39|     59|            thread: Mutex::new(None),
   40|     59|            stats_loop: Arc::new(StatsLoop {
   41|     59|                condition: Condvar::new(),
   42|     59|                mutables: Arc::clone(&mutables),
   43|     59|                config,
   44|     59|                loop_state: Mutex::new(StatsLoopState {
   45|     59|                    stopped: false,
   46|     59|                    log_last_count_writeout: Instant::now(),
   47|     59|                    log_last_sample_writeout: Instant::now(),
   48|     59|                }),
   49|     59|            }),
   50|     59|            mutables,
   51|     59|            enable_logging: get_env_bool("NANO_LOG_STATS").unwrap_or(false),
   52|     59|        }
   53|     59|    }
   54|       |
   55|      3|    pub fn start(&self) {
   56|      3|        if !self.should_run() {
   57|      3|            return;
   58|      0|        };
   59|      0|
   60|      0|        let stats_loop = Arc::clone(&self.stats_loop);
   61|      0|        *self.thread.lock().unwrap() = Some(
   62|      0|            std::thread::Builder::new()
   63|      0|                .name("Stats".to_string())
   64|      0|                .spawn(move || stats_loop.run())
   65|      0|                .unwrap(),
   66|      0|        );
   67|      3|    }
   68|       |
   69|      3|    fn should_run(&self) -> bool {
   70|      3|        !self.config.log_counters_interval.is_zero() || !self.config.log_samples_interval.is_zero()
   71|      3|    }
   72|       |
   73|       |    /// Stop stats being output
   74|      3|    pub fn stop(&self) {
   75|      3|        self.stats_loop.loop_state.lock().unwrap().stopped = true;
   76|      3|        self.stats_loop.condition.notify_all();
   77|      3|        let handle = self.thread.lock().unwrap().take();
   78|      3|        if let Some(handle) = handle {
                                  ^0
   79|      0|            handle.join().unwrap();
   80|      3|        }
   81|      3|    }
   82|       |
   83|       |    /// Add `value` to given counter
   84|  16.4k|    pub fn add(&self, stat_type: StatType, detail: DetailType, value: u64) {
   85|  16.4k|        self.add_dir(stat_type, detail, Direction::In, value)
   86|  16.4k|    }
   87|       |
   88|       |    /// Add `value` to given counter
   89|  33.1k|    pub fn add_dir(&self, stat_type: StatType, detail: DetailType, dir: Direction, value: u64) {
   90|  33.1k|        if value == 0 {
   91|     33|            return;
   92|  33.1k|        }
   93|  33.1k|
   94|  33.1k|        self.log_add(stat_type, detail, dir, value);
   95|  33.1k|
   96|  33.1k|        let key = CounterKey::new(stat_type, detail, dir);
   97|  33.1k|
   98|  33.1k|        // This is a two-step process to avoid exclusively locking the mutex in the common case
   99|  33.1k|        {
  100|  33.1k|            let lock = self.mutables.read().unwrap();
  101|       |
  102|  33.1k|            if let Some(counter) = lock.counters.get(&key) {
                                      ^32.9k
  103|  32.9k|                counter.add(value);
  104|  32.9k|                return;
  105|    166|            }
  106|    166|        }
  107|    166|        // Not found, create a new entry
  108|    166|        {
  109|    166|            let mut lock = self.mutables.write().unwrap();
  110|    166|            let counter = lock.counters.entry(key).or_insert(CounterEntry::new());
  111|    166|            counter.add(value);
  112|    166|
  113|    166|            let all_key = CounterKey::new(stat_type, DetailType::All, dir);
  114|    166|            if key != all_key {
  115|    166|                lock.counters.entry(all_key).or_insert(CounterEntry::new());
  116|    166|            }
                           ^0
  117|       |        }
  118|  33.1k|    }
  119|       |
  120|  33.1k|    fn log_add(&self, stat_type: StatType, detail: DetailType, dir: Direction, value: u64) {
  121|  33.1k|        if self.enable_logging {
  122|      0|            debug!(
  123|      0|                "Stat: {:?}::{:?}::{:?} += {}",
  124|       |                stat_type, detail, dir, value
  125|       |            );
  126|  33.1k|        }
  127|  33.1k|    }
  128|       |
  129|      6|    pub fn add_dir_aggregate(
  130|      6|        &self,
  131|      6|        stat_type: StatType,
  132|      6|        detail: DetailType,
  133|      6|        dir: Direction,
  134|      6|        value: u64,
  135|      6|    ) {
  136|      6|        if value == 0 {
  137|      0|            return;
  138|      6|        }
  139|      6|
  140|      6|        self.log_add(stat_type, detail, dir, value);
  141|      6|
  142|      6|        let key = CounterKey::new(stat_type, detail, dir);
  143|      6|        let all_key = CounterKey::new(stat_type, DetailType::All, dir);
  144|      6|
  145|      6|        // This is a two-step process to avoid exclusively locking the mutex in the common case
  146|      6|        {
  147|      6|            let lock = self.mutables.read().unwrap();
  148|       |
  149|      6|            if let Some(counter) = lock.counters.get(&key) {
                                      ^3
  150|      3|                counter.add(value);
  151|      3|                if key != all_key {
  152|      1|                    let all_counter = lock.counters.get(&all_key).unwrap();
  153|      1|                    all_counter.add(value);
  154|      2|                }
  155|      3|                return;
  156|      3|            }
  157|      3|        }
  158|      3|        // Not found, create a new entry
  159|      3|        {
  160|      3|            let mut lock = self.mutables.write().unwrap();
  161|      3|            let counter = lock.counters.entry(key).or_insert(CounterEntry::new());
  162|      3|            counter.add(value);
  163|      3|            if key != all_key {
  164|      2|                let all_counter = lock.counters.entry(all_key).or_insert(CounterEntry::new());
  165|      2|                all_counter.add(value);
  166|      2|            }
                           ^1
  167|       |        }
  168|      6|    }
  169|       |
  170|  16.6k|    pub fn inc(&self, stat_type: StatType, detail: DetailType) {
  171|  16.6k|        self.add_dir(stat_type, detail, Direction::In, 1)
  172|  16.6k|    }
  173|       |
  174|     61|    pub fn inc_dir(&self, stat_type: StatType, detail: DetailType, dir: Direction) {
  175|     61|        self.add_dir(stat_type, detail, dir, 1)
  176|     61|    }
  177|       |
  178|      4|    pub fn inc_dir_aggregate(&self, stat_type: StatType, detail: DetailType, dir: Direction) {
  179|      4|        self.add_dir_aggregate(stat_type, detail, dir, 1)
  180|      4|    }
  181|       |
  182|      6|    pub fn sample(&self, sample: Sample, value: i64, expected_min_max: (i64, i64)) {
  183|      6|        self.log_sample(sample, value);
  184|      6|        let key = SamplerKey::new(sample);
  185|      6|        // This is a two-step process to avoid exclusively locking the mutex in the common case
  186|      6|        {
  187|      6|            let lock = self.mutables.read().unwrap();
  188|      6|            if let Some(sampler) = lock.samplers.get(&key) {
                                      ^4
  189|      4|                sampler.add(value);
  190|      4|                return;
  191|      2|            }
  192|      2|        }
  193|      2|        // Not found, create a new entry
  194|      2|        {
  195|      2|            let mut lock = self.mutables.write().unwrap();
  196|      2|            let sampler = lock
  197|      2|                .samplers
  198|      2|                .entry(key)
  199|      2|                .or_insert(SamplerEntry::new(self.config.max_samples, expected_min_max));
  200|      2|            sampler.add(value)
  201|       |        }
  202|      6|    }
  203|       |
  204|      6|    fn log_sample(&self, sample: Sample, value: i64) {
  205|      6|        if self.enable_logging {
  206|      0|            debug!("Sample: {:?} -> {}", sample, value);
  207|      6|        }
  208|      6|    }
  209|       |
  210|      4|    pub fn samples(&self, sample: Sample) -> Vec<i64> {
  211|      4|        let key = SamplerKey::new(sample);
  212|      4|        let lock = self.mutables.read().unwrap();
  213|      4|        if let Some(sampler) = lock.samplers.get(&key) {
  214|      4|            sampler.collect()
  215|       |        } else {
  216|      0|            Vec::new()
  217|       |        }
  218|      4|    }
  219|       |
  220|       |    /// Log counters to the given log link
  221|      0|    pub fn log_counters(&self, sink: &mut dyn StatsLogSink) -> Result<()> {
  222|      0|        let now = SystemTime::now();
  223|      0|        let lock = self.mutables.write().unwrap();
  224|      0|        lock.log_counters_impl(sink, &self.config, now)
  225|      0|    }
  226|       |
  227|       |    /// Log samples to the given log sink
  228|      0|    pub fn log_samples(&self, sink: &mut dyn StatsLogSink) -> Result<()> {
  229|      0|        let now = SystemTime::now();
  230|      0|        let lock = self.mutables.write().unwrap();
  231|      0|        lock.log_samples_impl(sink, &self.config, now)
  232|      0|    }
  233|       |
  234|       |    /// Returns the duration since `clear()` was last called, or node startup if it's never called.
  235|      0|    pub fn last_reset(&self) -> Duration {
  236|      0|        let lock = self.mutables.read().unwrap();
  237|      0|        lock.timestamp.elapsed()
  238|      0|    }
  239|       |
  240|       |    /// Clear all stats
  241|      0|    pub fn clear(&self) {
  242|      0|        let mut lock = self.mutables.write().unwrap();
  243|      0|        lock.counters.clear();
  244|      0|        lock.samplers.clear();
  245|      0|        lock.timestamp = Instant::now();
  246|      0|    }
  247|       |    ///
  248|       |    /// Returns current value for the given counter at the type level
  249|      0|    pub fn count_all(&self, stat_type: StatType, dir: Direction) -> u64 {
  250|      0|        let guard = self.mutables.read().unwrap();
  251|      0|        let start = CounterKey::new(stat_type, DetailType::All, dir);
  252|      0|        let mut result = 0u64;
  253|      0|        for (key, entry) in guard.counters.range(start..) {
  254|      0|            if key.stat_type != stat_type {
  255|      0|                break;
  256|      0|            }
  257|      0|            if key.dir == dir && key.detail != DetailType::All {
  258|      0|                result += u64::from(entry);
  259|      0|            }
  260|       |        }
  261|      0|        result
  262|      0|    }
  263|       |
  264|       |    /// Returns current value for the given counter at the type level
  265|     14|    pub fn count(&self, stat_type: StatType, detail: DetailType, dir: Direction) -> u64 {
  266|     14|        let key = CounterKey::new(stat_type, detail, dir);
  267|     14|        self.mutables
  268|     14|            .read()
  269|     14|            .unwrap()
  270|     14|            .counters
  271|     14|            .get(&key)
  272|     14|            .map(|i| i.into())
                                   ^11
  273|     14|            .unwrap_or_default()
  274|     14|    }
  275|       |}
  276|       |
  277|       |#[derive(PartialEq, Eq, PartialOrd, Ord, Clone, Copy)]
  278|       |struct CounterKey {
  279|       |    stat_type: StatType,
  280|       |    detail: DetailType,
  281|       |    dir: Direction,
  282|       |}
  283|       |
  284|       |impl CounterKey {
  285|  33.3k|    fn new(stat_type: StatType, detail: DetailType, dir: Direction) -> Self {
  286|  33.3k|        Self {
  287|  33.3k|            stat_type,
  288|  33.3k|            detail,
  289|  33.3k|            dir,
  290|  33.3k|        }
  291|  33.3k|    }
  292|       |}
  293|       |
  294|       |#[derive(PartialEq, Eq, PartialOrd, Ord, Clone, Copy)]
  295|       |struct SamplerKey {
  296|       |    sample: Sample,
  297|       |}
  298|       |
  299|       |impl SamplerKey {
  300|     10|    fn new(sample: Sample) -> Self {
  301|     10|        Self { sample }
  302|     10|    }
  303|       |}
  304|       |
  305|       |pub enum StatCategory {
  306|       |    Counters,
  307|       |    Samples,
  308|       |}
  309|       |
  310|       |struct StatMutables {
  311|       |    /// Stat entries are sorted by key to simplify processing of log output
  312|       |    counters: BTreeMap<CounterKey, CounterEntry>,
  313|       |    samplers: BTreeMap<SamplerKey, SamplerEntry>,
  314|       |
  315|       |    /// Time of last clear() call
  316|       |    timestamp: Instant,
  317|       |}
  318|       |
  319|       |impl StatMutables {
  320|       |    /// Unlocked implementation of log_samples() to avoid using recursive locking
  321|      0|    fn log_samples_impl(
  322|      0|        &self,
  323|      0|        sink: &mut dyn StatsLogSink,
  324|      0|        config: &StatsConfig,
  325|      0|        time: SystemTime,
  326|      0|    ) -> Result<()> {
  327|      0|        sink.begin()?;
  328|      0|        if sink.entries() >= config.log_rotation_count {
  329|      0|            sink.rotate()?;
  330|      0|        }
  331|       |
  332|      0|        if config.log_headers {
  333|      0|            let walltime = SystemTime::now();
  334|      0|            sink.write_header("samples", walltime)?;
  335|      0|        }
  336|       |
  337|      0|        for (&key, entry) in &self.samplers {
  338|      0|            let sample = key.sample.as_str();
  339|      0|            sink.write_sampler_entry(time, sample, entry.collect(), entry.expected_min_max)?;
  340|       |        }
  341|      0|        sink.inc_entries();
  342|      0|        sink.finalize();
  343|      0|        Ok(())
  344|      0|    }
  345|       |
  346|       |    /// Unlocked implementation of log_counters() to avoid using recursive locking
  347|      0|    fn log_counters_impl(
  348|      0|        &self,
  349|      0|        sink: &mut dyn StatsLogSink,
  350|      0|        config: &StatsConfig,
  351|      0|        time: SystemTime,
  352|      0|    ) -> Result<()> {
  353|      0|        sink.begin()?;
  354|      0|        if sink.entries() >= config.log_rotation_count {
  355|      0|            sink.rotate()?;
  356|      0|        }
  357|       |
  358|      0|        if config.log_headers {
  359|      0|            let walltime = SystemTime::now();
  360|      0|            sink.write_header("counters", walltime)?;
  361|      0|        }
  362|       |
  363|      0|        for (&key, entry) in &self.counters {
  364|      0|            let type_str = key.stat_type.as_str();
  365|      0|            let detail = key.detail.as_str();
  366|      0|            let dir = key.dir.as_str();
  367|      0|            sink.write_counter_entry(time, type_str, detail, dir, entry.into())?;
  368|       |        }
  369|      0|        sink.inc_entries();
  370|      0|        sink.finalize();
  371|      0|        Ok(())
  372|      0|    }
  373|       |}
  374|       |
  375|       |struct CounterEntry(AtomicU64);
  376|       |
  377|       |impl CounterEntry {
  378|    337|    fn new() -> Self {
  379|    337|        Self(AtomicU64::new(0))
  380|    337|    }
  381|       |
  382|  33.1k|    fn add(&self, value: u64) {
  383|  33.1k|        self.0.fetch_add(value, std::sync::atomic::Ordering::SeqCst);
  384|  33.1k|    }
  385|       |}
  386|       |
  387|       |impl From<&CounterEntry> for u64 {
  388|     11|    fn from(value: &CounterEntry) -> Self {
  389|     11|        value.0.load(std::sync::atomic::Ordering::SeqCst)
  390|     11|    }
  391|       |}
  392|       |
  393|       |struct SamplerEntry {
  394|       |    samples: Mutex<BoundedVecDeque<i64>>,
  395|       |    pub expected_min_max: (i64, i64),
  396|       |}
  397|       |
  398|       |impl SamplerEntry {
  399|      2|    pub fn new(max_samples: usize, expected_min_max: (i64, i64)) -> Self {
  400|      2|        Self {
  401|      2|            samples: Mutex::new(BoundedVecDeque::new(max_samples)),
  402|      2|            expected_min_max,
  403|      2|        }
  404|      2|    }
  405|       |
  406|      6|    fn add(&self, value: i64) {
  407|      6|        self.samples.lock().unwrap().push_back(value);
  408|      6|    }
  409|       |
  410|      4|    fn collect(&self) -> Vec<i64> {
  411|      4|        let mut guard = self.samples.lock().unwrap();
  412|      4|        guard.drain(..).collect()
  413|      4|    }
  414|       |}
  415|       |
  416|       |impl From<MessageType> for DetailType {
  417|      1|    fn from(msg: MessageType) -> Self {
  418|      1|        match msg {
  419|      0|            MessageType::Invalid => DetailType::Invalid,
  420|      0|            MessageType::NotAType => DetailType::NotAType,
  421|      0|            MessageType::Keepalive => DetailType::Keepalive,
  422|      0|            MessageType::Publish => DetailType::Publish,
  423|      0|            MessageType::ConfirmReq => DetailType::ConfirmReq,
  424|      0|            MessageType::ConfirmAck => DetailType::ConfirmAck,
  425|      0|            MessageType::BulkPull => DetailType::BulkPull,
  426|      1|            MessageType::BulkPush => DetailType::BulkPush,
  427|      0|            MessageType::FrontierReq => DetailType::FrontierReq,
  428|      0|            MessageType::NodeIdHandshake => DetailType::NodeIdHandshake,
  429|      0|            MessageType::BulkPullAccount => DetailType::BulkPullAccount,
  430|      0|            MessageType::TelemetryReq => DetailType::TelemetryReq,
  431|      0|            MessageType::TelemetryAck => DetailType::TelemetryAck,
  432|      0|            MessageType::AscPullReq => DetailType::AscPullReq,
  433|      0|            MessageType::AscPullAck => DetailType::AscPullAck,
  434|       |        }
  435|      1|    }
  436|       |}
  437|       |
  438|       |struct StatsLoop {
  439|       |    mutables: Arc<RwLock<StatMutables>>,
  440|       |    condition: Condvar,
  441|       |    loop_state: Mutex<StatsLoopState>,
  442|       |    config: StatsConfig,
  443|       |}
  444|       |
  445|       |impl StatsLoop {
  446|      0|    fn run(&self) {
  447|      0|        let mut guard = self.loop_state.lock().unwrap();
  448|      0|        while !guard.stopped {
  449|      0|            guard = self
  450|      0|                .condition
  451|      0|                .wait_timeout_while(guard, Duration::from_secs(1), |g| !g.stopped)
  452|      0|                .unwrap()
  453|      0|                .0;
  454|      0|
  455|      0|            if !guard.stopped {
  456|      0|                self.run_one(&mut guard).unwrap();
  457|      0|            }
  458|       |        }
  459|      0|    }
  460|       |
  461|      0|    fn run_one(&self, lock: &mut StatsLoopState) -> anyhow::Result<()> {
  462|      0|        let stats = self.mutables.read().unwrap();
  463|      0|        // Counters
  464|      0|        if !self.config.log_counters_interval.is_zero()
  465|      0|            && lock.log_last_count_writeout.elapsed() > self.config.log_counters_interval
  466|       |        {
  467|      0|            let mut log_count = LOG_COUNT.lock().unwrap();
  468|      0|            let writer = match log_count.as_mut() {
  469|      0|                Some(x) => x,
  470|       |                None => {
  471|      0|                    let writer = StatFileWriter::new(&self.config.log_counters_filename)?;
  472|      0|                    log_count.get_or_insert(writer)
  473|       |                }
  474|       |            };
  475|       |
  476|      0|            stats.log_counters_impl(writer, &self.config, SystemTime::now())?;
  477|      0|            lock.log_last_count_writeout = Instant::now();
  478|      0|        }
  479|       |
  480|       |        // Samples
  481|      0|        if !self.config.log_samples_interval.is_zero()
  482|      0|            && lock.log_last_sample_writeout.elapsed() > self.config.log_samples_interval
  483|       |        {
  484|      0|            let mut log_sample = LOG_SAMPLE.lock().unwrap();
  485|      0|            let writer = match log_sample.as_mut() {
  486|      0|                Some(x) => x,
  487|       |                None => {
  488|      0|                    let writer = StatFileWriter::new(&self.config.log_samples_filename)?;
  489|      0|                    log_sample.get_or_insert(writer)
  490|       |                }
  491|       |            };
  492|      0|            stats.log_samples_impl(writer, &self.config, SystemTime::now())?;
  493|      0|            lock.log_last_sample_writeout = Instant::now();
  494|      0|        }
  495|       |
  496|      0|        Ok(())
  497|      0|    }
  498|       |}
  499|       |
  500|       |struct StatsLoopState {
  501|       |    stopped: bool,
  502|       |    log_last_count_writeout: Instant,
  503|       |    log_last_sample_writeout: Instant,
  504|       |}
  505|       |
  506|      0|static LOG_COUNT: Lazy<Mutex<Option<StatFileWriter>>> = Lazy::new(|| Mutex::new(None));
  507|      0|static LOG_SAMPLE: Lazy<Mutex<Option<StatFileWriter>>> = Lazy::new(|| Mutex::new(None));
  508|       |
  509|       |#[cfg(test)]
  510|       |mod tests {
  511|       |    use super::*;
  512|       |
  513|       |    /// Test stat counting at both type and detail levels
  514|       |    #[test]
  515|      1|    fn counters() {
  516|      1|        let stats = Stats::new(StatsConfig::new());
  517|      1|        stats.add_dir_aggregate(StatType::Ledger, DetailType::All, Direction::In, 1);
  518|      1|        stats.add_dir_aggregate(StatType::Ledger, DetailType::All, Direction::In, 5);
  519|      1|        stats.inc_dir_aggregate(StatType::Ledger, DetailType::All, Direction::In);
  520|      1|        stats.inc_dir_aggregate(StatType::Ledger, DetailType::Send, Direction::In);
  521|      1|        stats.inc_dir_aggregate(StatType::Ledger, DetailType::Send, Direction::In);
  522|      1|        stats.inc_dir_aggregate(StatType::Ledger, DetailType::Receive, Direction::In);
  523|      1|        assert_eq!(
  524|      1|            10,
  525|      1|            stats.count(StatType::Ledger, DetailType::All, Direction::In)
  526|      1|        );
  527|      1|        assert_eq!(
  528|      1|            2,
  529|      1|            stats.count(StatType::Ledger, DetailType::Send, Direction::In)
  530|      1|        );
  531|      1|        assert_eq!(
  532|      1|            1,
  533|      1|            stats.count(StatType::Ledger, DetailType::Receive, Direction::In)
  534|      1|        );
  535|      1|    }
  536|       |
  537|       |    #[test]
  538|      1|    fn samples() {
  539|      1|        let stats = Stats::new(StatsConfig::new());
  540|      1|        stats.sample(Sample::ActiveElectionDuration, 5, (1, 10));
  541|      1|        stats.sample(Sample::ActiveElectionDuration, 5, (1, 10));
  542|      1|        stats.sample(Sample::ActiveElectionDuration, 11, (1, 10));
  543|      1|        stats.sample(Sample::ActiveElectionDuration, 37, (1, 10));
  544|      1|
  545|      1|        stats.sample(Sample::BootstrapTagDuration, 2137, (1, 10));
  546|      1|
  547|      1|        let samples1 = stats.samples(Sample::ActiveElectionDuration);
  548|      1|        assert_eq!(samples1, [5, 5, 11, 37]);
  549|       |
  550|      1|        let samples2 = stats.samples(Sample::ActiveElectionDuration);
  551|      1|        assert!(samples2.is_empty());
  552|       |
  553|      1|        stats.sample(Sample::ActiveElectionDuration, 3, (1, 10));
  554|      1|
  555|      1|        let samples3 = stats.samples(Sample::ActiveElectionDuration);
  556|      1|        assert_eq!(samples3, [3]);
  557|       |
  558|      1|        let samples4 = stats.samples(Sample::BootstrapTagDuration);
  559|      1|        assert_eq!(samples4, [2137]);
  560|      1|    }
  561|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/stats_config.rs:
    1|       |use std::time::Duration;
    2|       |
    3|       |#[derive(Clone, Debug, PartialEq)]
    4|       |pub struct StatsConfig {
    5|       |    /** How many sample intervals to keep in the ring buffer */
    6|       |    pub max_samples: usize,
    7|       |
    8|       |    /** How often to log sample array, in milliseconds. Default is 0 (no logging) */
    9|       |    pub log_samples_interval: Duration,
   10|       |
   11|       |    /** How often to log counters, in milliseconds. Default is 0 (no logging) */
   12|       |    pub log_counters_interval: Duration,
   13|       |
   14|       |    /** Maximum number of log outputs before rotating the file */
   15|       |    pub log_rotation_count: usize,
   16|       |
   17|       |    /** If true, write headers on each counter or samples writeout. The header contains log type and the current wall time. */
   18|       |    pub log_headers: bool,
   19|       |
   20|       |    /** Filename for the counter log  */
   21|       |    pub log_counters_filename: String,
   22|       |
   23|       |    /** Filename for the sampling log */
   24|       |    pub log_samples_filename: String,
   25|       |}
   26|       |
   27|       |impl Default for StatsConfig {
   28|     66|    fn default() -> Self {
   29|     66|        Self {
   30|     66|            max_samples: 1024 * 16,
   31|     66|            log_samples_interval: Duration::ZERO,
   32|     66|            log_counters_interval: Duration::ZERO,
   33|     66|            log_rotation_count: 100,
   34|     66|            log_headers: true,
   35|     66|            log_counters_filename: "counters.stat".to_string(),
   36|     66|            log_samples_filename: "samples.stat".to_string(),
   37|     66|        }
   38|     66|    }
   39|       |}
   40|       |
   41|       |impl StatsConfig {
   42|     11|    pub fn new() -> Self {
   43|     11|        Default::default()
   44|     11|    }
   45|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/stats_enums.rs:
    1|       |use serde::Serialize;
    2|       |use serde_variant::to_variant_name;
    3|       |
    4|       |/// Primary statistics type
    5|       |#[repr(u8)]
    6|      0|#[derive(FromPrimitive, Serialize, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug)]
    7|       |#[serde(rename_all = "snake_case")]
    8|       |pub enum StatType {
    9|       |    Error,
   10|       |    Message,
   11|       |    Block,
   12|       |    Ledger,
   13|       |    Rollback,
   14|       |    Network,
   15|       |    Vote,
   16|       |    VoteProcessor,
   17|       |    VoteProcessorTier,
   18|       |    VoteProcessorOverfill,
   19|       |    Election,
   20|       |    ElectionCleanup,
   21|       |    ElectionVote,
   22|       |    HttpCallbacks,
   23|       |    Ipc,
   24|       |    Tcp,
   25|       |    TcpServer,
   26|       |    TcpChannels,
   27|       |    TcpChannelsRejected,
   28|       |    TcpListener,
   29|       |    TcpListenerRejected,
   30|       |    TrafficTcp,
   31|       |    TrafficTcpType,
   32|       |    Channel,
   33|       |    Socket,
   34|       |    ConfirmationHeight,
   35|       |    ConfirmationObserver,
   36|       |    ConfirmingSet,
   37|       |    Drop,
   38|       |    Aggregator,
   39|       |    Requests,
   40|       |    RequestAggregator,
   41|       |    RequestAggregatorVote,
   42|       |    RequestAggregatorReplies,
   43|       |    Filter,
   44|       |    Telemetry,
   45|       |    VoteGenerator,
   46|       |    VoteCache,
   47|       |    VoteCacheProcessor,
   48|       |    Hinting,
   49|       |    BlockProcessor,
   50|       |    BlockProcessorSource,
   51|       |    BlockProcessorResult,
   52|       |    BlockProcessorOverfill,
   53|       |    Bootstrap,
   54|       |    BootstrapVerify,
   55|       |    BootstrapVerifyBlocks,
   56|       |    BootstrapVerifyFrontiers,
   57|       |    BootstrapProcess,
   58|       |    BootstrapRequest,
   59|       |    BootstrapRequestBlocks,
   60|       |    BootstrapReply,
   61|       |    BootstrapNext,
   62|       |    BootstrapFrontiers,
   63|       |    BootstrapAccountSets,
   64|       |    BootstrapFrontierScan,
   65|       |    BootstrapTimeout,
   66|       |    BootstrapServer,
   67|       |    BootstrapServerRequest,
   68|       |    BootstrapServerOverfill,
   69|       |    BootstrapServerResponse,
   70|       |    Active,
   71|       |    ActiveElections,
   72|       |    ActiveElectionsStarted,
   73|       |    ActiveElectionsStopped,
   74|       |    ActiveElectionsConfirmed,
   75|       |    ActiveElectionsDropped,
   76|       |    ActiveElectionsTimeout,
   77|       |    ActiveElectionsCancelled,
   78|       |    ActiveElectionsCemented,
   79|       |    ActiveTimeout,
   80|       |    Backlog,
   81|       |    BacklogScan,
   82|       |    BoundedBacklog,
   83|       |    Unchecked,
   84|       |    ElectionScheduler,
   85|       |    ElectionBucket,
   86|       |    OptimisticScheduler,
   87|       |    Handshake,
   88|       |    RepCrawler,
   89|       |    LocalBlockBroadcaster,
   90|       |    RepTiers,
   91|       |    SynCookies,
   92|       |    PeerHistory,
   93|       |    MessageProcessor,
   94|       |    MessageProcessorOverfill,
   95|       |    MessageProcessorType,
   96|       |    ProcessConfirmed,
   97|       |    Pruning,
   98|       |}
   99|       |
  100|       |impl StatType {
  101|      0|    pub fn as_str(&self) -> &'static str {
  102|      0|        to_variant_name(self).unwrap_or_default()
  103|      0|    }
  104|       |}
  105|       |
  106|       |// Optional detail type
  107|       |#[repr(u16)]
  108|      0|#[derive(FromPrimitive, Serialize, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Debug)]
  109|       |#[serde(rename_all = "snake_case")]
  110|       |pub enum DetailType {
  111|       |    // common
  112|       |    All = 0,
  113|       |    Ok,
  114|       |    Loop,
  115|       |    LoopCleanup,
  116|       |    Total,
  117|       |    Process,
  118|       |    Processed,
  119|       |    Ignored,
  120|       |    Update,
  121|       |    Updated,
  122|       |    Inserted,
  123|       |    Erased,
  124|       |    Request,
  125|       |    RequestFailed,
  126|       |    RequestSuccess,
  127|       |    Broadcast,
  128|       |    Cleanup,
  129|       |    Top,
  130|       |    None,
  131|       |    Success,
  132|       |    Unknown,
  133|       |    Cache,
  134|       |    Rebroadcast,
  135|       |    QueueOverflow,
  136|       |    Triggered,
  137|       |    Notify,
  138|       |    Duplicate,
  139|       |    Confirmed,
  140|       |    Unconfirmed,
  141|       |    Cemented,
  142|       |    Cooldown,
  143|       |    Empty,
  144|       |    Done,
  145|       |    Retry,
  146|       |    Prioritized,
  147|       |    Pending,
  148|       |    Sync,
  149|       |    Requeued,
  150|       |    Evicted,
  151|       |
  152|       |    // processing queue
  153|       |    Queue,
  154|       |    Overfill,
  155|       |    Batch,
  156|       |
  157|       |    // error specific
  158|       |    InsufficientWork,
  159|       |    HttpCallback,
  160|       |    UnreachableHost,
  161|       |    InvalidNetwork,
  162|       |
  163|       |    // confirmation_observer specific
  164|       |    ActiveQuorum,
  165|       |    ActiveConfHeight,
  166|       |    InactiveConfHeight,
  167|       |
  168|       |    // ledger, block, bootstrap
  169|       |    Send,
  170|       |    Receive,
  171|       |    Open,
  172|       |    Change,
  173|       |    StateBlock,
  174|       |    EpochBlock,
  175|       |    Fork,
  176|       |    Old,
  177|       |    GapPrevious,
  178|       |    GapSource,
  179|       |    Rollback,
  180|       |    RollbackFailed,
  181|       |    Progress,
  182|       |    BadSignature,
  183|       |    NegativeSpend,
  184|       |    Unreceivable,
  185|       |    GapEpochOpenPending,
  186|       |    OpenedBurnAccount,
  187|       |    BalanceMismatch,
  188|       |    RepresentativeMismatch,
  189|       |    BlockPosition,
  190|       |
  191|       |    // block processor
  192|       |    ProcessBlocking,
  193|       |    ProcessBlockingTimeout,
  194|       |    Force,
  195|       |
  196|       |    // block source
  197|       |    Live,
  198|       |    LiveOriginator,
  199|       |    Bootstrap,
  200|       |    BootstrapLegacy,
  201|       |    Unchecked,
  202|       |    Local,
  203|       |    Forced,
  204|       |    Election,
  205|       |
  206|       |    // message specific
  207|       |    NotAType,
  208|       |    Invalid,
  209|       |    Keepalive,
  210|       |    Publish,
  211|       |    ConfirmReq,
  212|       |    ConfirmAck,
  213|       |    NodeIdHandshake,
  214|       |    TelemetryReq,
  215|       |    TelemetryAck,
  216|       |    AscPullReq,
  217|       |    AscPullAck,
  218|       |
  219|       |    // dropped messages
  220|       |    ConfirmAckZeroAccount,
  221|       |
  222|       |    // bootstrap, callback
  223|       |    Initiate,
  224|       |    InitiateLegacyAge,
  225|       |    InitiateLazy,
  226|       |    InitiateWalletLazy,
  227|       |
  228|       |    // bootstrap specific
  229|       |    BulkPull,
  230|       |    BulkPullAccount,
  231|       |    BulkPullErrorStartingRequest,
  232|       |    BulkPullFailedAccount,
  233|       |    BulkPullRequestFailure,
  234|       |    BulkPush,
  235|       |    FrontierReq,
  236|       |    FrontierConfirmationFailed,
  237|       |    ErrorSocketClose,
  238|       |
  239|       |    // vote result
  240|       |    Vote,
  241|       |    Valid,
  242|       |    Replay,
  243|       |    Indeterminate,
  244|       |
  245|       |    // vote processor
  246|       |    VoteOverflow,
  247|       |    VoteIgnored,
  248|       |
  249|       |    // election specific
  250|       |    VoteNew,
  251|       |    VoteProcessed,
  252|       |    VoteCached,
  253|       |    ElectionBlockConflict,
  254|       |    ElectionRestart,
  255|       |    ElectionNotConfirmed,
  256|       |    ElectionHintedOverflow,
  257|       |    ElectionHintedConfirmed,
  258|       |    ElectionHintedDrop,
  259|       |    BroadcastVote,
  260|       |    BroadcastVoteNormal,
  261|       |    BroadcastVoteFinal,
  262|       |    GenerateVote,
  263|       |    GenerateVoteNormal,
  264|       |    GenerateVoteFinal,
  265|       |    BroadcastBlockInitial,
  266|       |    BroadcastBlockRepeat,
  267|       |    ConfirmOnce,
  268|       |    ConfirmOnceFailed,
  269|       |    ConfirmationRequest,
  270|       |
  271|       |    // election types
  272|       |    Manual,
  273|       |    Priority,
  274|       |    Hinted,
  275|       |    Optimistic,
  276|       |
  277|       |    // received messages
  278|       |    InvalidHeader,
  279|       |    InvalidMessageType,
  280|       |    InvalidKeepaliveMessage,
  281|       |    InvalidPublishMessage,
  282|       |    InvalidConfirmReqMessage,
  283|       |    InvalidConfirmAckMessage,
  284|       |    InvalidNodeIdHandshakeMessage,
  285|       |    InvalidTelemetryReqMessage,
  286|       |    InvalidTelemetryAckMessage,
  287|       |    InvalidBulkPullMessage,
  288|       |    InvalidBulkPullAccountMessage,
  289|       |    InvalidFrontierReqMessage,
  290|       |    InvalidAscPullReqMessage,
  291|       |    InvalidAscPullAckMessage,
  292|       |    MessageSizeTooBig,
  293|       |    OutdatedVersion,
  294|       |
  295|       |    // network
  296|       |    LoopKeepalive,
  297|       |    LoopReachout,
  298|       |    LoopReachoutCached,
  299|       |    MergePeer,
  300|       |    ReachoutLive,
  301|       |    ReachoutCached,
  302|       |
  303|       |    // traffic
  304|       |    Generic,
  305|       |    BootstrapServer,
  306|       |    BootstrapRequests,
  307|       |    BlockBroadcast,
  308|       |    BlockBroadcastRpc,
  309|       |    BlockBroadcastInitial,
  310|       |    ConfirmationRequests,
  311|       |    VoteRebroadcast,
  312|       |    RepCrawler,
  313|       |    VoteReply,
  314|       |    Telemetry,
  315|       |
  316|       |    // tcp
  317|       |    TcpWriteDrop,
  318|       |    TcpWriteNoSocketDrop,
  319|       |    TcpSilentConnectionDrop,
  320|       |    TcpIoTimeoutDrop,
  321|       |    TcpConnectError,
  322|       |    TcpReadError,
  323|       |    TcpWriteError,
  324|       |
  325|       |    // tcp_listener
  326|       |    AcceptSuccess,
  327|       |    AcceptFailure,
  328|       |    AcceptRejected,
  329|       |    CloseError,
  330|       |    MaxPerIp,
  331|       |    MaxPerSubnetwork,
  332|       |    MaxAttempts,
  333|       |    MaxAttemptsPerIp,
  334|       |    Excluded,
  335|       |    EraseDead,
  336|       |    ConnectInitiate,
  337|       |    ConnectFailure,
  338|       |    ConnectError,
  339|       |    ConnectRejected,
  340|       |    ConnectSuccess,
  341|       |    AttemptTimeout,
  342|       |    NotAPeer,
  343|       |
  344|       |    // tcp_channels
  345|       |    ChannelAccepted,
  346|       |    ChannelRejected,
  347|       |    ChannelDuplicate,
  348|       |    Outdated,
  349|       |
  350|       |    // tcp_server
  351|       |    Handshake,
  352|       |    HandshakeAbort,
  353|       |    HandshakeError,
  354|       |    HandshakeNetworkError,
  355|       |    HandshakeInitiate,
  356|       |    HandshakeResponse,
  357|       |    HandshakeResponseInvalid,
  358|       |
  359|       |    // ipc
  360|       |    Invocations,
  361|       |
  362|       |    // confirmation height
  363|       |    BlocksConfirmed,
  364|       |
  365|       |    // request aggregator
  366|       |    AggregatorAccepted,
  367|       |    AggregatorDropped,
  368|       |
  369|       |    // requests
  370|       |    RequestsCachedHashes,
  371|       |    RequestsGeneratedHashes,
  372|       |    RequestsCachedVotes,
  373|       |    RequestsGeneratedVotes,
  374|       |    RequestsCannotVote,
  375|       |    RequestsUnknown,
  376|       |    RequestsNonFinal,
  377|       |    RequestsFinal,
  378|       |
  379|       |    // request_aggregator
  380|       |    RequestHashes,
  381|       |    OverfillHashes,
  382|       |    NormalVote,
  383|       |    FinalVote,
  384|       |
  385|       |    // duplicate
  386|       |    DuplicatePublishMessage,
  387|       |    DuplicateConfirmAckMessage,
  388|       |
  389|       |    // telemetry
  390|       |    InvalidSignature,
  391|       |    NodeIdMismatch,
  392|       |    GenesisMismatch,
  393|       |    RequestWithinProtectionCacheZone,
  394|       |    NoResponseReceived,
  395|       |    UnsolicitedTelemetryAck,
  396|       |    FailedSendTelemetryReq,
  397|       |    EmptyPayload,
  398|       |    CleanupOutdated,
  399|       |
  400|       |    // vote generator
  401|       |    GeneratorBroadcasts,
  402|       |    GeneratorReplies,
  403|       |    GeneratorRepliesDiscarded,
  404|       |    GeneratorSpacing,
  405|       |
  406|       |    // hinting
  407|       |    MissingBlock,
  408|       |    DependentUnconfirmed,
  409|       |    AlreadyConfirmed,
  410|       |    Activate,
  411|       |    ActivateImmediate,
  412|       |    DependentActivated,
  413|       |
  414|       |    // bootstrap server
  415|       |    Response,
  416|       |    WriteError,
  417|       |    Blocks,
  418|       |    ChannelFull,
  419|       |    Frontiers,
  420|       |    AccountInfo,
  421|       |
  422|       |    // backlog
  423|       |    Activated,
  424|       |    ActivateFailed,
  425|       |    ActivateSkip,
  426|       |    ActivateFull,
  427|       |    Scanned,
  428|       |
  429|       |    // active
  430|       |    Insert,
  431|       |    InsertFailed,
  432|       |    TransitionPriority,
  433|       |    TransitionPriorityFailed,
  434|       |    ElectionCleanup,
  435|       |    ActivateImmediately,
  436|       |
  437|       |    // active_elections
  438|       |    Started,
  439|       |    Stopped,
  440|       |    ConfirmDependent,
  441|       |
  442|       |    // unchecked
  443|       |    Put,
  444|       |    Satisfied,
  445|       |    Trigger,
  446|       |
  447|       |    // election scheduler
  448|       |    InsertManual,
  449|       |    InsertPriority,
  450|       |    InsertPrioritySuccess,
  451|       |    EraseOldest,
  452|       |
  453|       |    // handshake
  454|       |    InvalidNodeId,
  455|       |    MissingCookie,
  456|       |    InvalidGenesis,
  457|       |
  458|       |    // bootstrap
  459|       |    MissingTag,
  460|       |    Reply,
  461|       |    Throttled,
  462|       |    Track,
  463|       |    Timeout,
  464|       |    NothingNew,
  465|       |    AccountInfoEmpty,
  466|       |    FrontiersEmpty,
  467|       |    LoopDatabase,
  468|       |    LoopDependencies,
  469|       |    LoopFrontiers,
  470|       |    LoopFrontiersProcessing,
  471|       |    DuplicateRequest,
  472|       |    InvalidResponseType,
  473|       |    InvalidResponse,
  474|       |    TimestampReset,
  475|       |    ProcessingFrontiers,
  476|       |    FrontiersDropped,
  477|       |    SyncAccounts,
  478|       |
  479|       |    Prioritize,
  480|       |    PrioritizeFailed,
  481|       |    Block,
  482|       |    BlockFailed,
  483|       |    Unblock,
  484|       |    UnblockFailed,
  485|       |    DependencyUpdate,
  486|       |    DependencyUpdateFailed,
  487|       |
  488|       |    DoneRange,
  489|       |    DoneEmpty,
  490|       |    NextByRequests,
  491|       |    NextByTimestamp,
  492|       |    Advance,
  493|       |    AdvanceFailed,
  494|       |
  495|       |    NextNone,
  496|       |    NextPriority,
  497|       |    NextDatabase,
  498|       |    NextBlocking,
  499|       |    NextDependency,
  500|       |    NextFrontier,
  501|       |
  502|       |    BlockingInsert,
  503|       |    BlockingOverflow,
  504|       |    PriorityInsert,
  505|       |    PrioritySet,
  506|       |    PriorityErase,
  507|       |    PriorityUnblocked,
  508|       |    EraseByThreshold,
  509|       |    EraseByBlocking,
  510|       |    PriorityEraseThreshold,
  511|       |    PriorityEraseBlock,
  512|       |    PriorityOverflow,
  513|       |    Deprioritize,
  514|       |    DeprioritizeFailed,
  515|       |    SyncDependencies,
  516|       |    DependencySynced,
  517|       |
  518|       |    RequestBlocks,
  519|       |    RequestAccountInfo,
  520|       |
  521|       |    Safe,
  522|       |    Base,
  523|       |
  524|       |    // active
  525|       |    StartedHinted,
  526|       |    StartedOptimistic,
  527|       |
  528|       |    // rep_crawler
  529|       |    ChannelDead,
  530|       |    QueryTargetFailed,
  531|       |    QueryChannelBusy,
  532|       |    QuerySent,
  533|       |    QueryDuplicate,
  534|       |    RepTimeout,
  535|       |    QueryTimeout,
  536|       |    QueryCompletion,
  537|       |    CrawlAggressive,
  538|       |    CrawlNormal,
  539|       |
  540|       |    // block broadcaster
  541|       |    BroadcastNormal,
  542|       |    BroadcastAggressive,
  543|       |    EraseOld,
  544|       |    EraseConfirmed,
  545|       |
  546|       |    // rep tiers
  547|       |    Tier1,
  548|       |    Tier2,
  549|       |    Tier3,
  550|       |
  551|       |    // confirming_set
  552|       |    NotifyCemented,
  553|       |    NotifyAlreadyCemented,
  554|       |    NotifyIntermediate,
  555|       |    AlreadyCemented,
  556|       |    Cementing,
  557|       |    CementedHash,
  558|       |    CementingFailed,
  559|       |
  560|       |    // election_state
  561|       |    Passive,
  562|       |    Active,
  563|       |    ExpiredConfirmed,
  564|       |    ExpiredUnconfirmed,
  565|       |    Cancelled,
  566|       |
  567|       |    // election_status_type
  568|       |    Ongoing,
  569|       |    ActiveConfirmedQuorum,
  570|       |    ActiveConfirmationHeight,
  571|       |    InactiveConfirmationHeight,
  572|       |
  573|       |    // election bucket
  574|       |    ActivateSuccess,
  575|       |    CancelLowest,
  576|       |
  577|       |    // query_type
  578|       |    BlocksByHash,
  579|       |    BlocksByAccount,
  580|       |    AccountInfoByHash,
  581|       |
  582|       |    // bounded backlog
  583|       |    GatheredTargets,
  584|       |    PerformingRollbacks,
  585|       |    NoTargets,
  586|       |    RollbackMissingBlock,
  587|       |    RollbackSkipped,
  588|       |    LoopScan,
  589|       |
  590|       |    // pruning
  591|       |    LedgerPruning,
  592|       |    PruningTarget,
  593|       |    PrunedCount,
  594|       |    CollectTargets,
  595|       |}
  596|       |
  597|       |impl DetailType {
  598|      0|    pub fn as_str(&self) -> &'static str {
  599|      0|        to_variant_name(self).unwrap_or_default()
  600|      0|    }
  601|       |}
  602|       |
  603|       |/// Direction of the stat. If the direction is irrelevant, use In
  604|      0|#[derive(FromPrimitive, PartialEq, PartialOrd, Eq, Ord, Clone, Copy, Debug)]
  605|       |#[repr(u8)]
  606|       |pub enum Direction {
  607|       |    In,
  608|       |    Out,
  609|       |}
  610|       |
  611|       |impl Direction {
  612|      0|    pub fn as_str(&self) -> &'static str {
  613|      0|        match self {
  614|      0|            Direction::In => "in",
  615|      0|            Direction::Out => "out",
  616|       |        }
  617|      0|    }
  618|       |}
  619|       |
  620|       |#[repr(u8)]
  621|      0|#[derive(FromPrimitive, Serialize, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Debug)]
  622|       |#[serde(rename_all = "snake_case")]
  623|       |pub enum Sample {
  624|       |    ActiveElectionDuration,
  625|       |    BootstrapTagDuration,
  626|       |    RepResponseTime,
  627|       |    VoteGeneratorFinalHashes,
  628|       |    VoteGeneratorHashes,
  629|       |}
  630|       |
  631|       |impl Sample {
  632|      0|    pub fn as_str(&self) -> &'static str {
  633|      0|        to_variant_name(self).unwrap_or_default()
  634|      0|    }
  635|       |}

/home/gustav/code/nano/rsnano-node/node/src/stats/stats_log_sink.rs:
    1|       |use anyhow::Result;
    2|       |use chrono::{DateTime, Local};
    3|       |use std::{any::Any, fs::File, io::Write, path::PathBuf, time::SystemTime};
    4|       |
    5|       |pub trait StatsLogSink {
    6|       |    /// Called before logging starts
    7|       |    fn begin(&mut self) -> Result<()>;
    8|       |
    9|       |    /// Called after logging is completed
   10|       |    fn finalize(&mut self);
   11|       |
   12|       |    /// Write a header enrty to the log
   13|       |    fn write_header(&mut self, header: &str, walltime: SystemTime) -> Result<()>;
   14|       |
   15|       |    /// Write a counter or sampling entry to the log. Some log sinks may support writing histograms as well.
   16|       |    fn write_counter_entry(
   17|       |        &mut self,
   18|       |        time: SystemTime,
   19|       |        entry_type: &str,
   20|       |        detail: &str,
   21|       |        dir: &str,
   22|       |        value: u64,
   23|       |    ) -> Result<()>;
   24|       |
   25|       |    fn write_sampler_entry(
   26|       |        &mut self,
   27|       |        time: SystemTime,
   28|       |        sample: &str,
   29|       |        values: Vec<i64>,
   30|       |        expected_min_max: (i64, i64),
   31|       |    ) -> Result<()>;
   32|       |
   33|       |    /// Rotates the log (e.g. empty file). This is a no-op for sinks where rotation is not supported.
   34|       |    fn rotate(&mut self) -> Result<()>;
   35|       |
   36|       |    /// Returns a reference to the log entry counter
   37|       |    fn entries(&self) -> usize;
   38|       |
   39|       |    fn inc_entries(&mut self);
   40|       |
   41|       |    /// Returns the string representation of the log. If not supported, an empty string is returned.
   42|       |    fn to_string(&self) -> String;
   43|       |
   44|       |    /// Returns the object representation of the log result. The type depends on the sink used.
   45|       |    /// returns Object, or nullptr if no object result is available.
   46|       |    fn to_object(&self) -> Option<&dyn Any>;
   47|       |}
   48|       |
   49|       |/// File sink with rotation support. This writes one counter per line and does not include histogram values.
   50|       |pub struct StatFileWriter {
   51|       |    filename: PathBuf,
   52|       |    file: File,
   53|       |    log_entries: usize,
   54|       |}
   55|       |
   56|       |impl StatFileWriter {
   57|      0|    pub fn new(filename: impl Into<PathBuf>) -> Result<Self> {
   58|      0|        let filename = filename.into();
   59|      0|        let file = File::create(filename.clone())?;
   60|      0|        Ok(Self {
   61|      0|            filename,
   62|      0|            file,
   63|      0|            log_entries: 0,
   64|      0|        })
   65|      0|    }
   66|       |}
   67|       |
   68|       |impl StatsLogSink for StatFileWriter {
   69|      0|    fn begin(&mut self) -> Result<()> {
   70|      0|        Ok(())
   71|      0|    }
   72|       |
   73|      0|    fn finalize(&mut self) {}
   74|       |
   75|      0|    fn write_header(&mut self, header: &str, walltime: SystemTime) -> Result<()> {
   76|      0|        let local = DateTime::<Local>::from(walltime);
   77|      0|        let local_fmt = local.format("%Y.%m.%d %H:%M:%S");
   78|      0|        writeln!(&mut self.file, "{header},{local_fmt}")?;
   79|      0|        Ok(())
   80|      0|    }
   81|       |
   82|      0|    fn write_counter_entry(
   83|      0|        &mut self,
   84|      0|        time: SystemTime,
   85|      0|        entry_type: &str,
   86|      0|        detail: &str,
   87|      0|        dir: &str,
   88|      0|        value: u64,
   89|      0|    ) -> Result<()> {
   90|      0|        let now = DateTime::<Local>::from(time).format("%H:%M:%S");
   91|      0|        writeln!(&mut self.file, "{now},{entry_type},{detail},{dir},{value}")?;
   92|      0|        Ok(())
   93|      0|    }
   94|       |
   95|      0|    fn write_sampler_entry(
   96|      0|        &mut self,
   97|      0|        time: SystemTime,
   98|      0|        sample: &str,
   99|      0|        values: Vec<i64>,
  100|      0|        _expected_min_max: (i64, i64),
  101|      0|    ) -> Result<()> {
  102|      0|        let time: chrono::DateTime<Local> = time.into();
  103|      0|        write!(&mut self.file, "{},{sample}", time.format("%H:%M:%S"))?;
  104|       |
  105|      0|        for value in values {
  106|      0|            write!(&mut self.file, ",{}", value)?;
  107|       |        }
  108|       |
  109|      0|        writeln!(&mut self.file, "")?;
  110|       |
  111|      0|        Ok(())
  112|      0|    }
  113|       |
  114|      0|    fn rotate(&mut self) -> Result<()> {
  115|      0|        self.file = File::create(self.filename.clone())?;
  116|      0|        self.log_entries = 0;
  117|      0|        Ok(())
  118|      0|    }
  119|       |
  120|      0|    fn entries(&self) -> usize {
  121|      0|        self.log_entries
  122|      0|    }
  123|       |
  124|      0|    fn inc_entries(&mut self) {
  125|      0|        self.log_entries += 1;
  126|      0|    }
  127|       |
  128|      0|    fn to_string(&self) -> String {
  129|      0|        String::new()
  130|      0|    }
  131|       |
  132|      0|    fn to_object(&self) -> Option<&dyn Any> {
  133|      0|        None
  134|      0|    }
  135|       |}
  136|       |
  137|       |pub struct StatsJsonWriterV2 {
  138|       |    tree: serde_json::Map<String, serde_json::Value>,
  139|       |    entries: Vec<serde_json::Value>,
  140|       |    log_entries: usize,
  141|       |}
  142|       |
  143|       |impl StatsJsonWriterV2 {
  144|      0|    pub fn new() -> Self {
  145|      0|        Self {
  146|      0|            tree: Default::default(),
  147|      0|            entries: Default::default(),
  148|      0|            log_entries: 0,
  149|      0|        }
  150|      0|    }
  151|       |
  152|      0|    pub fn add(&mut self, key: impl Into<String>, value: u64) {
  153|      0|        self.tree
  154|      0|            .insert(key.into(), serde_json::Value::String(value.to_string()));
  155|      0|    }
  156|       |
  157|      0|    pub fn finish(self) -> serde_json::Value {
  158|      0|        serde_json::Value::Object(self.tree)
  159|      0|    }
  160|       |}
  161|       |
  162|       |impl Default for StatsJsonWriterV2 {
  163|      0|    fn default() -> Self {
  164|      0|        Self::new()
  165|      0|    }
  166|       |}
  167|       |
  168|       |impl StatsLogSink for StatsJsonWriterV2 {
  169|      0|    fn begin(&mut self) -> Result<()> {
  170|      0|        self.tree.clear();
  171|      0|        Ok(())
  172|      0|    }
  173|       |
  174|      0|    fn finalize(&mut self) {
  175|      0|        let empty_entries = Vec::new();
  176|      0|        let entries = std::mem::replace(&mut self.entries, empty_entries);
  177|      0|        self.tree
  178|      0|            .insert("entries".to_owned(), serde_json::Value::Array(entries));
  179|      0|    }
  180|       |
  181|      0|    fn write_header(&mut self, header: &str, walltime: SystemTime) -> Result<()> {
  182|      0|        let now = DateTime::<Local>::from(walltime);
  183|      0|        self.tree.insert(
  184|      0|            "type".to_owned(),
  185|      0|            serde_json::Value::String(header.to_owned()),
  186|      0|        );
  187|      0|        self.tree.insert(
  188|      0|            "created".to_owned(),
  189|      0|            serde_json::Value::String(now.format("%Y.%m.%d %H:%M:%S").to_string()),
  190|      0|        );
  191|      0|        Ok(())
  192|      0|    }
  193|       |
  194|      0|    fn write_counter_entry(
  195|      0|        &mut self,
  196|      0|        time: SystemTime,
  197|      0|        entry_type: &str,
  198|      0|        detail: &str,
  199|      0|        dir: &str,
  200|      0|        value: u64,
  201|      0|    ) -> Result<()> {
  202|      0|        let mut entry = serde_json::Map::new();
  203|      0|        entry.insert(
  204|      0|            "time".to_owned(),
  205|      0|            serde_json::Value::String(DateTime::<Local>::from(time).format("%H:%M:%S").to_string()),
  206|      0|        );
  207|      0|        entry.insert(
  208|      0|            "type".to_owned(),
  209|      0|            serde_json::Value::String(entry_type.to_owned()),
  210|      0|        );
  211|      0|        entry.insert(
  212|      0|            "detail".to_owned(),
  213|      0|            serde_json::Value::String(detail.to_owned()),
  214|      0|        );
  215|      0|        entry.insert("dir".to_owned(), serde_json::Value::String(dir.to_owned()));
  216|      0|        entry.insert(
  217|      0|            "value".to_owned(),
  218|      0|            serde_json::Value::String(value.to_string()),
  219|      0|        );
  220|      0|        self.entries.push(serde_json::Value::Object(entry));
  221|      0|        Ok(())
  222|      0|    }
  223|       |
  224|      0|    fn rotate(&mut self) -> Result<()> {
  225|      0|        Ok(())
  226|      0|    }
  227|       |
  228|      0|    fn entries(&self) -> usize {
  229|      0|        self.log_entries
  230|      0|    }
  231|       |
  232|      0|    fn inc_entries(&mut self) {
  233|      0|        self.log_entries += 1;
  234|      0|    }
  235|       |
  236|      0|    fn to_string(&self) -> String {
  237|      0|        serde_json::Value::Object(self.tree.clone()).to_string()
  238|      0|    }
  239|       |
  240|      0|    fn to_object(&self) -> Option<&dyn Any> {
  241|      0|        None
  242|      0|    }
  243|       |
  244|      0|    fn write_sampler_entry(
  245|      0|        &mut self,
  246|      0|        time: SystemTime,
  247|      0|        sample: &str,
  248|      0|        values: Vec<i64>,
  249|      0|        expected_min_max: (i64, i64),
  250|      0|    ) -> Result<()> {
  251|      0|        let time: chrono::DateTime<Local> = time.into();
  252|      0|        let mut entry = serde_json::Map::new();
  253|      0|        entry.insert(
  254|      0|            "time".to_owned(),
  255|      0|            serde_json::Value::String(time.format("%H:%M:%S").to_string()),
  256|      0|        );
  257|      0|        entry.insert(
  258|      0|            "sample".to_owned(),
  259|      0|            serde_json::Value::String(sample.to_owned()),
  260|      0|        );
  261|      0|        entry.insert(
  262|      0|            "min".to_owned(),
  263|      0|            serde_json::Value::String(expected_min_max.0.to_string()),
  264|      0|        );
  265|      0|        entry.insert(
  266|      0|            "max".to_owned(),
  267|      0|            serde_json::Value::String(expected_min_max.1.to_string()),
  268|      0|        );
  269|      0|
  270|      0|        let mut values_tree = Vec::new();
  271|      0|        for value in values {
  272|      0|            values_tree.push(serde_json::Value::String(value.to_string()));
  273|      0|        }
  274|      0|        entry.insert("values".to_owned(), serde_json::Value::Array(values_tree));
  275|      0|        self.entries.push(serde_json::Value::Object(entry));
  276|      0|        Ok(())
  277|      0|    }
  278|       |}

/home/gustav/code/nano/rsnano-node/node/src/telemetry.rs:
    1|       |use rsnano_core::{utils::ContainerInfo, PrivateKey, Signature};
    2|       |use rsnano_ledger::Ledger;
    3|       |use rsnano_messages::{Message, TelemetryAck, TelemetryData, TelemetryMaker};
    4|       |use rsnano_nullable_clock::SteadyClock;
    5|       |use std::{
    6|       |    cmp::min,
    7|       |    collections::{HashMap, VecDeque},
    8|       |    mem::size_of,
    9|       |    net::SocketAddrV6,
   10|       |    sync::{Arc, Condvar, Mutex, RwLock},
   11|       |    thread::JoinHandle,
   12|       |    time::{Duration, Instant, SystemTime},
   13|       |};
   14|       |
   15|       |use crate::{
   16|       |    block_processing::UncheckedMap,
   17|       |    config::NodeConfig,
   18|       |    stats::{DetailType, StatType, Stats},
   19|       |    transport::MessageSender,
   20|       |    NetworkParams,
   21|       |};
   22|       |use rsnano_network::{
   23|       |    Channel, ChannelId, ChannelMode, DeadChannelCleanupStep, Network, TrafficType,
   24|       |};
   25|       |
   26|       |/**
   27|       | * This class periodically broadcasts and requests telemetry from peers.
   28|       | * Those intervals are configurable via `telemetry_request_interval` & `telemetry_broadcast_interval` network constants
   29|       | * Telemetry datas are only removed after becoming stale (configurable via `telemetry_cache_cutoff` network constant), so peer data will still be available for a short period after that peer is disconnected
   30|       | *
   31|       | * Broadcasts can be disabled via `disable_providing_telemetry_metrics` node flag
   32|       | *
   33|       | */
   34|       |pub struct Telemetry {
   35|       |    config: TelementryConfig,
   36|       |    node_config: NodeConfig,
   37|       |    stats: Arc<Stats>,
   38|       |    ledger: Arc<Ledger>,
   39|       |    unchecked: Arc<UncheckedMap>,
   40|       |    thread: Mutex<Option<JoinHandle<()>>>,
   41|       |    condition: Condvar,
   42|       |    mutex: Mutex<TelemetryImpl>,
   43|       |    network_params: NetworkParams,
   44|       |    network: Arc<RwLock<Network>>,
   45|       |    message_sender: Mutex<MessageSender>,
   46|       |    node_id: PrivateKey,
   47|       |    pub startup_time: Instant,
   48|       |    telemetry_processed_callbacks:
   49|       |        Mutex<Vec<Box<dyn Fn(&TelemetryData, &SocketAddrV6) + Send + Sync>>>,
   50|       |    clock: Arc<SteadyClock>,
   51|       |}
   52|       |
   53|       |impl Telemetry {
   54|       |    const MAX_SIZE: usize = 1024;
   55|       |
   56|      3|    pub(crate) fn new(
   57|      3|        config: TelementryConfig,
   58|      3|        node_config: NodeConfig,
   59|      3|        stats: Arc<Stats>,
   60|      3|        ledger: Arc<Ledger>,
   61|      3|        unchecked: Arc<UncheckedMap>,
   62|      3|        network_params: NetworkParams,
   63|      3|        network: Arc<RwLock<Network>>,
   64|      3|        message_sender: MessageSender,
   65|      3|        node_id: PrivateKey,
   66|      3|        clock: Arc<SteadyClock>,
   67|      3|    ) -> Self {
   68|      3|        Self {
   69|      3|            config,
   70|      3|            node_config,
   71|      3|            stats,
   72|      3|            ledger,
   73|      3|            unchecked,
   74|      3|            network_params,
   75|      3|            network,
   76|      3|            message_sender: Mutex::new(message_sender),
   77|      3|            thread: Mutex::new(None),
   78|      3|            condition: Condvar::new(),
   79|      3|            mutex: Mutex::new(TelemetryImpl {
   80|      3|                stopped: false,
   81|      3|                triggered: false,
   82|      3|                telemetries: Default::default(),
   83|      3|                last_broadcast: None,
   84|      3|                last_request: None,
   85|      3|            }),
   86|      3|            telemetry_processed_callbacks: Mutex::new(Vec::new()),
   87|      3|            node_id,
   88|      3|            startup_time: Instant::now(),
   89|      3|            clock,
   90|      3|        }
   91|      3|    }
   92|       |
   93|      3|    pub fn stop(&self) {
   94|      3|        self.mutex.lock().unwrap().stopped = true;
   95|      3|        self.condition.notify_all();
   96|      3|        let handle = self.thread.lock().unwrap().take();
   97|      3|        if let Some(handle) = handle {
   98|      3|            handle.join().unwrap();
   99|      3|        }
                       ^0
  100|      3|    }
  101|       |
  102|      0|    pub fn on_telemetry_processed(
  103|      0|        &self,
  104|      0|        f: Box<dyn Fn(&TelemetryData, &SocketAddrV6) + Send + Sync>,
  105|      0|    ) {
  106|      0|        self.telemetry_processed_callbacks.lock().unwrap().push(f);
  107|      0|    }
  108|       |
  109|      0|    fn verify(&self, telemetry: &TelemetryAck, channel: &Channel) -> bool {
  110|      0|        let Some(data) = &telemetry.0 else {
  111|      0|            self.stats
  112|      0|                .inc(StatType::Telemetry, DetailType::EmptyPayload);
  113|      0|            return false;
  114|       |        };
  115|       |
  116|       |        // Check if telemetry node id matches channel node id
  117|      0|        if Some(data.node_id) != channel.node_id() {
  118|      0|            self.stats
  119|      0|                .inc(StatType::Telemetry, DetailType::NodeIdMismatch);
  120|      0|            return false;
  121|      0|        }
  122|      0|
  123|      0|        // Check whether data is signed by node id presented in telemetry message
  124|      0|        if !data.validate_signature() {
  125|      0|            self.stats
  126|      0|                .inc(StatType::Telemetry, DetailType::InvalidSignature);
  127|      0|            return false;
  128|      0|        }
  129|      0|
  130|      0|        if data.genesis_block != self.network_params.ledger.genesis_block.hash() {
  131|      0|            self.network
  132|      0|                .write()
  133|      0|                .unwrap()
  134|      0|                .peer_misbehaved(channel.channel_id(), self.clock.now());
  135|      0|
  136|      0|            self.stats
  137|      0|                .inc(StatType::Telemetry, DetailType::GenesisMismatch);
  138|      0|            return false;
  139|      0|        }
  140|      0|
  141|      0|        return true; // Telemetry is OK
  142|      0|    }
  143|       |
  144|       |    /// Process telemetry message from network
  145|      0|    pub fn process(&self, telemetry: &TelemetryAck, channel: &Channel) {
  146|      0|        if !self.verify(telemetry, channel) {
  147|      0|            return;
  148|      0|        }
  149|      0|        let data = telemetry.0.as_ref().unwrap();
  150|      0|
  151|      0|        let mut guard = self.mutex.lock().unwrap();
  152|      0|        let peer_addr = channel.peer_addr();
  153|       |
  154|      0|        if let Some(entry) = guard.telemetries.get_mut(channel.channel_id()) {
  155|      0|            self.stats.inc(StatType::Telemetry, DetailType::Update);
  156|      0|            entry.data = data.clone();
  157|      0|            entry.last_updated = Instant::now();
  158|      0|        } else {
  159|      0|            self.stats.inc(StatType::Telemetry, DetailType::Insert);
  160|      0|            guard.telemetries.push_back(Entry {
  161|      0|                channel_id: channel.channel_id(),
  162|      0|                endpoint: peer_addr,
  163|      0|                data: data.clone(),
  164|      0|                last_updated: Instant::now(),
  165|      0|            });
  166|      0|
  167|      0|            if guard.telemetries.len() > Self::MAX_SIZE {
  168|      0|                self.stats.inc(StatType::Telemetry, DetailType::Overfill);
  169|      0|                guard.telemetries.pop_front(); // Erase oldest entry
  170|      0|            }
  171|       |        }
  172|       |
  173|      0|        drop(guard);
  174|      0|
  175|      0|        {
  176|      0|            let callbacks = self.telemetry_processed_callbacks.lock().unwrap();
  177|      0|            for callback in callbacks.iter() {
  178|      0|                (callback)(data, &peer_addr);
  179|      0|            }
  180|       |        }
  181|       |
  182|      0|        self.stats.inc(StatType::Telemetry, DetailType::Process);
  183|      0|    }
  184|       |
  185|       |    /// Trigger manual telemetry request to all peers
  186|      0|    pub fn trigger(&self) {
  187|      0|        self.mutex.lock().unwrap().triggered = true;
  188|      0|        self.condition.notify_all();
  189|      0|    }
  190|       |
  191|      0|    pub fn len(&self) -> usize {
  192|      0|        self.mutex.lock().unwrap().telemetries.len()
  193|      0|    }
  194|       |
  195|      3|    fn request_predicate(&self, data: &TelemetryImpl) -> bool {
  196|      3|        if data.triggered {
  197|      0|            return true;
  198|      3|        }
  199|      3|        if self.config.enable_ongoing_requests {
  200|      0|            return data.last_request.is_none()
  201|      0|                || data.last_request.unwrap().elapsed()
  202|      0|                    >= Duration::from_millis(
  203|      0|                        self.network_params.network.telemetry_request_interval_ms as u64,
  204|      0|                    );
  205|      3|        }
  206|      3|
  207|      3|        return false;
  208|      3|    }
  209|       |
  210|      3|    fn broadcast_predicate(&self, data: &TelemetryImpl) -> bool {
  211|      3|        if self.config.enable_ongoing_broadcasts {
  212|      3|            return data.last_broadcast.is_none()
  213|      0|                || data.last_broadcast.unwrap().elapsed()
  214|      0|                    >= Duration::from_millis(
  215|      0|                        self.network_params.network.telemetry_broadcast_interval_ms as u64,
  216|      0|                    );
  217|      0|        }
  218|      0|
  219|      0|        return false;
  220|      3|    }
  221|       |
  222|      3|    fn run(&self) {
  223|      3|        let mut guard = self.mutex.lock().unwrap();
  224|      6|        while !guard.stopped {
  225|      3|            self.stats.inc(StatType::Telemetry, DetailType::Loop);
  226|      3|            self.cleanup(&mut guard);
  227|      3|
  228|      3|            if self.request_predicate(&guard) {
  229|      0|                guard.triggered = false;
  230|      0|                drop(guard);
  231|      0|
  232|      0|                self.run_requests();
  233|      0|
  234|      0|                guard = self.mutex.lock().unwrap();
  235|      0|                guard.last_request = Some(Instant::now());
  236|      3|            }
  237|       |
  238|      3|            if self.broadcast_predicate(&guard) {
  239|      3|                drop(guard);
  240|      3|
  241|      3|                self.run_broadcasts();
  242|      3|
  243|      3|                guard = self.mutex.lock().unwrap();
  244|      3|                guard.last_broadcast = Some(Instant::now());
  245|      3|            }
                           ^0
  246|       |
  247|      3|            let wait_duration = min(
  248|      3|                self.network_params.network.telemetry_request_interval_ms,
  249|      3|                self.network_params.network.telemetry_broadcast_interval_ms / 2,
  250|      3|            );
  251|      3|            guard = self
  252|      3|                .condition
  253|      3|                .wait_timeout(guard, Duration::from_millis(wait_duration as u64))
  254|      3|                .unwrap()
  255|      3|                .0
  256|       |        }
  257|      3|    }
  258|       |
  259|      0|    fn run_requests(&self) {
  260|      0|        let channel_ids = self.network.read().unwrap().random_list_realtime_ids();
  261|      0|        for channel_id in channel_ids {
  262|      0|            self.request(channel_id);
  263|      0|        }
  264|      0|    }
  265|       |
  266|      0|    fn request(&self, channel_id: ChannelId) {
  267|      0|        self.stats.inc(StatType::Telemetry, DetailType::Request);
  268|      0|        self.message_sender.lock().unwrap().try_send(
  269|      0|            channel_id,
  270|      0|            &Message::TelemetryReq,
  271|      0|            TrafficType::Telemetry,
  272|      0|        );
  273|      0|    }
  274|       |
  275|      3|    fn run_broadcasts(&self) {
  276|      3|        let telemetry = self.local_telemetry();
  277|      3|        let channel_ids = self.network.read().unwrap().random_list_realtime_ids();
  278|      3|        let message = Message::TelemetryAck(TelemetryAck(Some(telemetry)));
  279|      3|        for channel_id in channel_ids {
                          ^0
  280|      0|            self.broadcast(channel_id, &message);
  281|      0|        }
  282|      3|    }
  283|       |
  284|      0|    fn broadcast(&self, channel_id: ChannelId, message: &Message) {
  285|      0|        self.stats.inc(StatType::Telemetry, DetailType::Broadcast);
  286|      0|        self.message_sender
  287|      0|            .lock()
  288|      0|            .unwrap()
  289|      0|            .try_send(channel_id, message, TrafficType::Telemetry);
  290|      0|    }
  291|       |
  292|      3|    fn cleanup(&self, data: &mut TelemetryImpl) {
  293|      3|        data.telemetries.retain(|entry| {
  294|      0|            // Remove if telemetry data is stale
  295|      0|            if self.has_timed_out(entry) {
  296|      0|                self.stats
  297|      0|                    .inc(StatType::Telemetry, DetailType::CleanupOutdated);
  298|      0|                false // Erase
  299|       |            } else {
  300|      0|                true // Retain
  301|       |            }
  302|      3|        })
                      ^0
  303|      3|    }
  304|       |
  305|      0|    fn has_timed_out(&self, entry: &Entry) -> bool {
  306|      0|        entry.last_updated.elapsed()
  307|      0|            > Duration::from_millis(self.network_params.network.telemetry_cache_cutoff_ms as u64)
  308|      0|    }
  309|       |
  310|       |    /// Returns telemetry for selected endpoint
  311|      0|    pub fn get_telemetry(&self, endpoint: &SocketAddrV6) -> Option<TelemetryData> {
  312|      0|        let guard = self.mutex.lock().unwrap();
  313|      0|        if let Some(entry) = guard.telemetries.get_by_endpoint(endpoint) {
  314|      0|            if !self.has_timed_out(entry) {
  315|      0|                return Some(entry.data.clone());
  316|      0|            }
  317|      0|        }
  318|      0|        None
  319|      0|    }
  320|       |
  321|      0|    pub fn get_all_telemetries(&self) -> HashMap<SocketAddrV6, TelemetryData> {
  322|      0|        let guard = self.mutex.lock().unwrap();
  323|      0|        let mut result = HashMap::new();
  324|      0|        for entry in guard.telemetries.iter() {
  325|      0|            if !self.has_timed_out(entry) {
  326|      0|                result.insert(entry.endpoint, entry.data.clone());
  327|      0|            }
  328|       |        }
  329|      0|        result
  330|      0|    }
  331|       |
  332|      0|    pub fn container_info(&self) -> ContainerInfo {
  333|      0|        let guard = self.mutex.lock().unwrap();
  334|      0|        [(
  335|      0|            "telemetries",
  336|      0|            guard.telemetries.len(),
  337|      0|            OrderedTelemetries::ELEMENT_SIZE,
  338|      0|        )]
  339|      0|        .into()
  340|      0|    }
  341|       |
  342|      3|    pub fn local_telemetry(&self) -> TelemetryData {
  343|      3|        let peer_count = self
  344|      3|            .network
  345|      3|            .read()
  346|      3|            .unwrap()
  347|      3|            .count_by_mode(ChannelMode::Realtime) as u32;
  348|      3|
  349|      3|        let mut telemetry_data = TelemetryData {
  350|      3|            node_id: self.node_id.public_key().into(),
  351|      3|            block_count: self.ledger.block_count(),
  352|      3|            cemented_count: self.ledger.cemented_count(),
  353|      3|            bandwidth_cap: self.node_config.bandwidth_limit as u64,
  354|      3|            protocol_version: self.network_params.network.protocol_version,
  355|      3|            uptime: self.startup_time.elapsed().as_secs(),
  356|      3|            unchecked_count: self.unchecked.len() as u64,
  357|      3|            genesis_block: self.network_params.ledger.genesis_block.hash(),
  358|      3|            peer_count,
  359|      3|            account_count: self.ledger.account_count(),
  360|      3|            major_version: MAJOR_VERSION,
  361|      3|            minor_version: MINOR_VERSION,
  362|      3|            patch_version: PATCH_VERSION,
  363|      3|            pre_release_version: PRE_RELEASE_VERSION,
  364|      3|            maker: TelemetryMaker::RsNano as u8,
  365|      3|            timestamp: SystemTime::now(),
  366|      3|            active_difficulty: self.network_params.work.threshold_base(),
  367|      3|            unknown_data: Vec::new(),
  368|      3|            signature: Signature::default(),
  369|      3|        };
  370|      3|        // Make sure this is the final operation!
  371|      3|        telemetry_data.sign(&self.node_id).unwrap();
  372|      3|        telemetry_data
  373|      3|    }
  374|       |}
  375|       |
  376|       |pub const MAJOR_VERSION: u8 = 2; // TODO: get this from cmake
  377|       |pub const MINOR_VERSION: u8 = 0; // TODO: get this from cmake
  378|       |pub const PATCH_VERSION: u8 = 0; // TODO: get this from cmake
  379|       |pub const PRE_RELEASE_VERSION: u8 = 99; // TODO: get this from cmake
  380|       |pub const BUILD_INFO: &'static str = "TODO get buildinfo";
  381|       |pub const VERSION_STRING: &'static str = "2.0"; // TODO: get this from cmake
  382|       |
  383|       |impl Drop for Telemetry {
  384|      3|    fn drop(&mut self) {
  385|      3|        // Thread must be stopped before destruction
  386|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  387|      3|    }
  388|       |}
  389|       |
  390|       |pub struct TelementryConfig {
  391|       |    pub enable_ongoing_requests: bool, // TODO: No longer used, remove
  392|       |    pub enable_ongoing_broadcasts: bool,
  393|       |}
  394|       |
  395|       |pub trait TelementryExt {
  396|       |    fn start(&self);
  397|       |}
  398|       |
  399|       |struct TelemetryImpl {
  400|       |    stopped: bool,
  401|       |    triggered: bool,
  402|       |    telemetries: OrderedTelemetries,
  403|       |    last_request: Option<Instant>,
  404|       |    last_broadcast: Option<Instant>,
  405|       |}
  406|       |
  407|       |impl TelementryExt for Arc<Telemetry> {
  408|      3|    fn start(&self) {
  409|      3|        debug_assert!(self.thread.lock().unwrap().is_none());
  410|      3|        let self_l = Arc::clone(self);
  411|      3|        *self.thread.lock().unwrap() = Some(
  412|      3|            std::thread::Builder::new()
  413|      3|                .name("Telemetry".to_string())
  414|      3|                .spawn(move || {
  415|      3|                    self_l.run();
  416|      3|                })
  417|      3|                .unwrap(),
  418|      3|        );
  419|      3|    }
  420|       |}
  421|       |
  422|       |struct Entry {
  423|       |    channel_id: ChannelId,
  424|       |    endpoint: SocketAddrV6,
  425|       |    data: TelemetryData,
  426|       |    last_updated: Instant,
  427|       |}
  428|       |
  429|       |#[derive(Default)]
  430|       |struct OrderedTelemetries {
  431|       |    by_channel_id: HashMap<ChannelId, Entry>,
  432|       |    by_endpoint: HashMap<SocketAddrV6, ChannelId>,
  433|       |    sequenced: VecDeque<ChannelId>,
  434|       |}
  435|       |
  436|       |impl OrderedTelemetries {
  437|       |    pub const ELEMENT_SIZE: usize = size_of::<Entry>() + size_of::<SocketAddrV6>() * 2;
  438|      0|    fn len(&self) -> usize {
  439|      0|        self.sequenced.len()
  440|      0|    }
  441|       |
  442|      0|    fn push_back(&mut self, entry: Entry) {
  443|      0|        let channel_id = entry.channel_id;
  444|      0|        let endpoint = entry.endpoint;
  445|      0|        if let Some(old) = self.by_channel_id.insert(channel_id, entry) {
  446|      0|            if old.endpoint != endpoint {
  447|      0|                // This should never be reached
  448|      0|                self.by_endpoint.remove(&old.endpoint);
  449|      0|            }
  450|       |            // already in sequenced
  451|      0|        } else {
  452|      0|            self.sequenced.push_back(channel_id);
  453|      0|        }
  454|      0|        self.by_endpoint.insert(endpoint, channel_id);
  455|      0|    }
  456|       |
  457|      0|    fn get_by_endpoint(&self, entpoint: &SocketAddrV6) -> Option<&Entry> {
  458|      0|        let channel_id = self.by_endpoint.get(entpoint)?;
  459|      0|        self.by_channel_id.get(channel_id)
  460|      0|    }
  461|       |
  462|      0|    fn get_mut(&mut self, channel_id: ChannelId) -> Option<&mut Entry> {
  463|      0|        self.by_channel_id.get_mut(&channel_id)
  464|      0|    }
  465|       |
  466|      0|    fn remove(&mut self, channel_id: ChannelId) {
  467|      0|        if let Some(entry) = self.by_channel_id.remove(&channel_id) {
  468|      0|            self.by_endpoint.remove(&entry.endpoint);
  469|      0|            self.sequenced.retain(|i| *i != channel_id);
  470|      0|        }
  471|      0|    }
  472|       |
  473|      0|    fn pop_front(&mut self) {
  474|      0|        if let Some(channel_id) = self.sequenced.pop_front() {
  475|      0|            if let Some(entry) = self.by_channel_id.remove(&channel_id) {
  476|      0|                self.by_endpoint.remove(&entry.endpoint);
  477|      0|            }
  478|      0|        }
  479|      0|    }
  480|       |
  481|      3|    fn retain(&mut self, mut f: impl FnMut(&Entry) -> bool) {
  482|      3|        self.by_channel_id.retain(|channel_id, entry| {
  483|      0|            let retain = f(entry);
  484|      0|            if !retain {
  485|      0|                self.sequenced.retain(|i| i != channel_id);
  486|      0|                self.by_endpoint.remove(&entry.endpoint);
  487|      0|            }
  488|      0|            retain
  489|      3|        })
  490|      3|    }
  491|       |
  492|      0|    fn iter(&self) -> impl Iterator<Item = &Entry> {
  493|      0|        self.by_channel_id.values()
  494|      0|    }
  495|       |}
  496|       |
  497|       |impl DeadChannelCleanupStep for Telemetry {
  498|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  499|      0|        let mut guard = self.mutex.lock().unwrap();
  500|      0|        for channel_id in dead_channel_ids {
  501|      0|            guard.telemetries.remove(*channel_id);
  502|      0|        }
  503|      0|    }
  504|       |}
  505|       |
  506|       |pub struct TelemetryDeadChannelCleanup(pub Arc<Telemetry>);
  507|       |
  508|       |impl DeadChannelCleanupStep for TelemetryDeadChannelCleanup {
  509|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  510|      0|        self.0.clean_up_dead_channels(dead_channel_ids);
  511|      0|    }
  512|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/block_deserializer.rs:
    1|       |use num_traits::FromPrimitive;
    2|       |use rsnano_core::{serialized_block_size, utils::BufferReader, Block, BlockType};
    3|       |use rsnano_network::AsyncBufferReader;
    4|       |
    5|      0|pub async fn read_block(input: &impl AsyncBufferReader) -> anyhow::Result<Option<Block>> {
    6|      0|    let mut buf = [0; 1];
    7|      0|    input.read(&mut buf, 1).await?;
    8|      0|    received_type(buf[0], input).await
    9|      0|}
   10|       |
   11|      0|async fn received_type(
   12|      0|    block_type_byte: u8,
   13|      0|    input: &impl AsyncBufferReader,
   14|      0|) -> anyhow::Result<Option<Block>> {
   15|      0|    match BlockType::from_u8(block_type_byte) {
   16|      0|        None | Some(BlockType::Invalid) => Err(anyhow!("Invalid block type: {block_type_byte}")),
   17|      0|        Some(BlockType::NotABlock) => Ok(None),
   18|      0|        Some(block_type) => {
   19|      0|            let block_size = serialized_block_size(block_type);
   20|      0|            let mut buffer = [0; 256];
   21|      0|            input.read(&mut buffer, block_size).await?;
   22|      0|            let mut stream = BufferReader::new(&buffer[..block_size]);
   23|      0|            let block = Block::deserialize_block_type(block_type, &mut stream)?;
   24|      0|            Ok(Some(block))
   25|       |        }
   26|       |    }
   27|      0|}

/home/gustav/code/nano/rsnano-node/node/src/transport/block_flooder.rs:
    1|       |use super::MessageFlooder;
    2|       |use crate::utils::ThreadPool;
    3|       |use rsnano_core::Block;
    4|       |use rsnano_messages::{Message, Publish};
    5|       |use rsnano_network::TrafficType;
    6|       |use std::{
    7|       |    collections::VecDeque,
    8|       |    sync::{Arc, Mutex},
    9|       |    time::Duration,
   10|       |};
   11|       |
   12|       |pub(crate) struct BlockFlooder {
   13|       |    pub message_flooder: Arc<Mutex<MessageFlooder>>,
   14|       |    pub workers: Arc<dyn ThreadPool>,
   15|       |}
   16|       |
   17|       |impl BlockFlooder {
   18|      0|    pub fn flood_block_many(
   19|      0|        &self,
   20|      0|        blocks: VecDeque<Block>,
   21|      0|        callback: Box<dyn FnOnce() + Send + Sync>,
   22|      0|        delay: Duration,
   23|      0|    ) {
   24|      0|        flood(
   25|      0|            blocks,
   26|      0|            callback,
   27|      0|            delay,
   28|      0|            self.message_flooder.clone(),
   29|      0|            self.workers.clone(),
   30|      0|        )
   31|      0|    }
   32|       |}
   33|       |
   34|      0|fn flood(
   35|      0|    mut blocks: VecDeque<Block>,
   36|      0|    callback: Box<dyn FnOnce() + Send + Sync>,
   37|      0|    delay: Duration,
   38|      0|    message_flooder: Arc<Mutex<MessageFlooder>>,
   39|      0|    workers: Arc<dyn ThreadPool>,
   40|      0|) {
   41|      0|    if let Some(block) = blocks.pop_front() {
   42|      0|        let publish = Message::Publish(Publish::new_forward(block));
   43|      0|        message_flooder
   44|      0|            .lock()
   45|      0|            .unwrap()
   46|      0|            .flood(&publish, TrafficType::BlockBroadcastRpc, 1.0);
   47|      0|        if blocks.is_empty() {
   48|      0|            callback()
   49|      0|        } else {
   50|      0|            let flooder_w = Arc::downgrade(&message_flooder);
   51|      0|            let workers_w = Arc::downgrade(&workers);
   52|      0|            workers.post_delayed(
   53|      0|                delay,
   54|      0|                Box::new(move || {
   55|      0|                    let Some(flooder) = flooder_w.upgrade() else {
   56|      0|                        return;
   57|       |                    };
   58|      0|                    let Some(workers) = workers_w.upgrade() else {
   59|      0|                        return;
   60|       |                    };
   61|      0|                    flood(blocks, callback, delay, flooder, workers);
   62|      0|                }),
   63|      0|            );
   64|      0|        }
   65|      0|    }
   66|      0|}

/home/gustav/code/nano/rsnano-node/node/src/transport/handshake_process.rs:
    1|       |use super::SynCookies;
    2|       |use crate::stats::{DetailType, Direction, StatType, Stats};
    3|       |use rsnano_core::{BlockHash, NodeId, PrivateKey};
    4|       |use rsnano_messages::{
    5|       |    Message, MessageSerializer, NodeIdHandshake, NodeIdHandshakeQuery, NodeIdHandshakeResponse,
    6|       |    ProtocolInfo,
    7|       |};
    8|       |use rsnano_network::{Channel, TrafficType};
    9|       |use std::{
   10|       |    net::SocketAddrV6,
   11|       |    sync::{
   12|       |        atomic::{AtomicBool, Ordering},
   13|       |        Arc,
   14|       |    },
   15|       |};
   16|       |use tracing::{debug, warn};
   17|       |
   18|       |pub enum HandshakeStatus {
   19|       |    Abort,
   20|       |    AbortOwnNodeId,
   21|       |    Handshake,
   22|       |    Realtime(NodeId),
   23|       |    Bootstrap,
   24|       |}
   25|       |
   26|       |/// Responsible for performing a correct handshake when connecting to another node
   27|       |pub(crate) struct HandshakeProcess {
   28|       |    genesis_hash: BlockHash,
   29|       |    node_id: PrivateKey,
   30|       |    syn_cookies: Arc<SynCookies>,
   31|       |    stats: Arc<Stats>,
   32|       |    handshake_received: AtomicBool,
   33|       |    protocol: ProtocolInfo,
   34|       |}
   35|       |
   36|       |impl HandshakeProcess {
   37|      0|    pub(crate) fn new(
   38|      0|        genesis_hash: BlockHash,
   39|      0|        node_id: PrivateKey,
   40|      0|        syn_cookies: Arc<SynCookies>,
   41|      0|        stats: Arc<Stats>,
   42|      0|        protocol: ProtocolInfo,
   43|      0|    ) -> Self {
   44|      0|        Self {
   45|      0|            genesis_hash,
   46|      0|            node_id,
   47|      0|            syn_cookies,
   48|      0|            stats,
   49|      0|            handshake_received: AtomicBool::new(false),
   50|      0|            protocol,
   51|      0|        }
   52|      0|    }
   53|       |
   54|       |    #[allow(dead_code)]
   55|      0|    pub fn new_null() -> Self {
   56|      0|        Self {
   57|      0|            genesis_hash: BlockHash::from(1),
   58|      0|            node_id: PrivateKey::from(2),
   59|      0|            syn_cookies: Arc::new(SynCookies::new(1)),
   60|      0|            stats: Arc::new(Stats::default()),
   61|      0|            handshake_received: AtomicBool::new(false),
   62|      0|            protocol: ProtocolInfo::default(),
   63|      0|        }
   64|      0|    }
   65|       |
   66|      0|    pub(crate) fn initiate_handshake(&self, channel: &Channel) -> Result<(), ()> {
   67|      0|        let peer = channel.peer_addr();
   68|      0|        let query = self.prepare_query(&peer);
   69|      0|        if query.is_none() {
   70|      0|            warn!("Could not create cookie for {:?}. Closing channel.", peer);
   71|      0|            return Err(());
   72|      0|        }
   73|      0|        let message = Message::NodeIdHandshake(NodeIdHandshake {
   74|      0|            query,
   75|      0|            response: None,
   76|      0|            is_v2: true,
   77|      0|        });
   78|      0|
   79|      0|        debug!("Initiating handshake query ({})", peer);
   80|       |
   81|      0|        let mut serializer = MessageSerializer::new(self.protocol);
   82|      0|        let data = serializer.serialize(&message);
   83|      0|
   84|      0|        let enqueued = channel.send(data, TrafficType::Generic);
   85|      0|
   86|      0|        if enqueued {
   87|      0|            self.stats
   88|      0|                .inc_dir(StatType::TcpServer, DetailType::Handshake, Direction::Out);
   89|      0|            self.stats.inc_dir(
   90|      0|                StatType::TcpServer,
   91|      0|                DetailType::HandshakeInitiate,
   92|      0|                Direction::Out,
   93|      0|            );
   94|      0|
   95|      0|            Ok(())
   96|       |        } else {
   97|      0|            self.stats
   98|      0|                .inc(StatType::TcpServer, DetailType::HandshakeNetworkError);
   99|      0|            debug!(peer = %peer, "Could not enqueue handshake query");
  100|       |            // Stop invalid handshake
  101|      0|            Err(())
  102|       |        }
  103|      0|    }
  104|       |
  105|      0|    pub(crate) fn process_handshake(
  106|      0|        &self,
  107|      0|        message: &NodeIdHandshake,
  108|      0|        channel: &Channel,
  109|      0|    ) -> HandshakeStatus {
  110|      0|        if message.query.is_none() && message.response.is_none() {
  111|      0|            self.stats.inc_dir(
  112|      0|                StatType::TcpServer,
  113|      0|                DetailType::HandshakeError,
  114|      0|                Direction::In,
  115|      0|            );
  116|      0|            debug!(
  117|      0|                "Invalid handshake message received ({})",
  118|      0|                channel.peer_addr()
  119|       |            );
  120|      0|            return HandshakeStatus::Abort;
  121|      0|        }
  122|      0|        if message.query.is_some() && self.handshake_received.load(Ordering::SeqCst) {
  123|       |            // Second handshake message should be a response only
  124|      0|            self.stats.inc_dir(
  125|      0|                StatType::TcpServer,
  126|      0|                DetailType::HandshakeError,
  127|      0|                Direction::In,
  128|      0|            );
  129|      0|            warn!(
  130|      0|                "Detected multiple handshake queries ({})",
  131|      0|                channel.peer_addr()
  132|       |            );
  133|      0|            return HandshakeStatus::Abort;
  134|      0|        }
  135|      0|
  136|      0|        self.handshake_received.store(true, Ordering::SeqCst);
  137|      0|
  138|      0|        self.stats.inc_dir(
  139|      0|            StatType::TcpServer,
  140|      0|            DetailType::NodeIdHandshake,
  141|      0|            Direction::In,
  142|      0|        );
  143|       |
  144|      0|        let log_type = match (message.query.is_some(), message.response.is_some()) {
  145|      0|            (true, true) => "query + response",
  146|      0|            (true, false) => "query",
  147|      0|            (false, true) => "response",
  148|      0|            (false, false) => "none",
  149|       |        };
  150|      0|        debug!(
  151|      0|            "Handshake message received: {} ({})",
  152|      0|            log_type,
  153|      0|            channel.peer_addr()
  154|       |        );
  155|       |
  156|      0|        if let Some(query) = message.query.clone() {
  157|       |            // Send response + our own query
  158|      0|            if self.send_response(&query, message.is_v2, &channel).is_err() {
  159|       |                // Stop invalid handshake
  160|      0|                return HandshakeStatus::Abort;
  161|      0|            }
  162|       |            // Fall through and continue handshake
  163|      0|        }
  164|      0|        if let Some(response) = &message.response {
  165|      0|            match self.verify_response(response, &channel.peer_addr()) {
  166|       |                Ok(()) => {
  167|      0|                    self.stats
  168|      0|                        .inc_dir(StatType::Handshake, DetailType::Ok, Direction::In);
  169|      0|                    return HandshakeStatus::Realtime(response.node_id); // Switch to realtime
  170|       |                }
  171|       |                Err(HandshakeResponseError::OwnNodeId) => {
  172|      0|                    warn!(
  173|      0|                        "This node tried to connect to itself. Closing channel ({})",
  174|      0|                        channel.peer_addr()
  175|       |                    );
  176|      0|                    return HandshakeStatus::AbortOwnNodeId;
  177|       |                }
  178|      0|                Err(e) => {
  179|      0|                    self.stats
  180|      0|                        .inc_dir(StatType::Handshake, e.into(), Direction::In);
  181|      0|                    self.stats.inc_dir(
  182|      0|                        StatType::TcpServer,
  183|      0|                        DetailType::HandshakeResponseInvalid,
  184|      0|                        Direction::In,
  185|      0|                    );
  186|      0|                    warn!(
  187|      0|                        "Invalid handshake response received ({}, {:?})",
  188|      0|                        channel.peer_addr(),
  189|       |                        e
  190|       |                    );
  191|      0|                    return HandshakeStatus::Abort;
  192|       |                }
  193|       |            }
  194|      0|        }
  195|      0|        HandshakeStatus::Handshake // Handshake is in progress
  196|      0|    }
  197|       |
  198|      0|    fn send_response(
  199|      0|        &self,
  200|      0|        query: &NodeIdHandshakeQuery,
  201|      0|        v2: bool,
  202|      0|        channel: &Channel,
  203|      0|    ) -> anyhow::Result<()> {
  204|      0|        let response = self.prepare_response(query, v2);
  205|      0|        let own_query = self.prepare_query(&channel.peer_addr());
  206|       |
  207|      0|        let handshake_response = Message::NodeIdHandshake(NodeIdHandshake {
  208|      0|            is_v2: own_query.is_some() || response.v2.is_some(),
  209|      0|            query: own_query,
  210|      0|            response: Some(response),
  211|      0|        });
  212|      0|
  213|      0|        debug!("Responding to handshake ({})", channel.peer_addr());
  214|       |
  215|      0|        let mut serializer = MessageSerializer::new(self.protocol);
  216|      0|        let buffer = serializer.serialize(&handshake_response);
  217|      0|
  218|      0|        let enqueued = channel.send(buffer, TrafficType::Generic);
  219|      0|
  220|      0|        if enqueued {
  221|      0|            self.stats
  222|      0|                .inc_dir(StatType::TcpServer, DetailType::Handshake, Direction::Out);
  223|      0|            self.stats.inc_dir(
  224|      0|                StatType::TcpServer,
  225|      0|                DetailType::HandshakeResponse,
  226|      0|                Direction::Out,
  227|      0|            );
  228|      0|            Ok(())
  229|       |        } else {
  230|      0|            self.stats.inc_dir(
  231|      0|                StatType::TcpServer,
  232|      0|                DetailType::HandshakeNetworkError,
  233|      0|                Direction::In,
  234|      0|            );
  235|      0|            warn!(peer = %channel.peer_addr(), "Error sending handshake response");
  236|      0|            Err(anyhow!("Could now enqueue handshake response"))
  237|       |        }
  238|      0|    }
  239|       |
  240|      0|    fn verify_response(
  241|      0|        &self,
  242|      0|        response: &NodeIdHandshakeResponse,
  243|      0|        peer_addr: &SocketAddrV6,
  244|      0|    ) -> Result<(), HandshakeResponseError> {
  245|      0|        // Prevent connection with ourselves
  246|      0|        if response.node_id == self.node_id.public_key().into() {
  247|      0|            return Err(HandshakeResponseError::OwnNodeId);
  248|      0|        }
  249|       |
  250|       |        // Prevent mismatched genesis
  251|      0|        if let Some(v2) = &response.v2 {
  252|      0|            if v2.genesis != self.genesis_hash {
  253|      0|                return Err(HandshakeResponseError::InvalidGenesis);
  254|      0|            }
  255|      0|        }
  256|       |
  257|      0|        let Some(cookie) = self.syn_cookies.cookie(peer_addr) else {
  258|      0|            return Err(HandshakeResponseError::MissingCookie);
  259|       |        };
  260|       |
  261|      0|        if response.validate(&cookie).is_err() {
  262|      0|            return Err(HandshakeResponseError::InvalidSignature);
  263|      0|        }
  264|      0|
  265|      0|        Ok(())
  266|      0|    }
  267|       |
  268|      0|    pub(crate) fn prepare_response(
  269|      0|        &self,
  270|      0|        query: &NodeIdHandshakeQuery,
  271|      0|        v2: bool,
  272|      0|    ) -> NodeIdHandshakeResponse {
  273|      0|        if v2 {
  274|      0|            NodeIdHandshakeResponse::new_v2(&query.cookie, &self.node_id, self.genesis_hash)
  275|       |        } else {
  276|      0|            NodeIdHandshakeResponse::new_v1(&query.cookie, &self.node_id)
  277|       |        }
  278|      0|    }
  279|       |
  280|      0|    pub(crate) fn prepare_query(&self, peer_addr: &SocketAddrV6) -> Option<NodeIdHandshakeQuery> {
  281|      0|        self.syn_cookies
  282|      0|            .assign(peer_addr)
  283|      0|            .map(|cookie| NodeIdHandshakeQuery { cookie })
  284|      0|    }
  285|       |}
  286|       |
  287|       |#[derive(Debug, Clone, Copy)]
  288|       |enum HandshakeResponseError {
  289|       |    /// The node tried to connect to itself
  290|       |    OwnNodeId,
  291|       |    InvalidGenesis,
  292|       |    MissingCookie,
  293|       |    InvalidSignature,
  294|       |}
  295|       |
  296|       |impl From<HandshakeResponseError> for DetailType {
  297|      0|    fn from(value: HandshakeResponseError) -> Self {
  298|      0|        match value {
  299|      0|            HandshakeResponseError::OwnNodeId => Self::InvalidNodeId,
  300|      0|            HandshakeResponseError::InvalidGenesis => Self::InvalidGenesis,
  301|      0|            HandshakeResponseError::MissingCookie => Self::MissingCookie,
  302|      0|            HandshakeResponseError::InvalidSignature => Self::InvalidSignature,
  303|       |        }
  304|      0|    }
  305|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/inbound_message_queue.rs:
    1|       |use super::MessageCallback;
    2|       |use crate::stats::{DetailType, StatType, Stats};
    3|       |use rsnano_core::utils::{ContainerInfo, FairQueue};
    4|       |use rsnano_messages::Message;
    5|       |use rsnano_network::{Channel, ChannelId, DeadChannelCleanupStep};
    6|       |use std::{
    7|       |    collections::VecDeque,
    8|       |    sync::{Arc, Condvar, Mutex},
    9|       |};
   10|       |
   11|       |pub struct InboundMessageQueue {
   12|       |    state: Mutex<State>,
   13|       |    condition: Condvar,
   14|       |    stats: Arc<Stats>,
   15|       |    inbound_callback: Option<MessageCallback>,
   16|       |    inbound_dropped_callback: Option<MessageCallback>,
   17|       |}
   18|       |
   19|       |impl InboundMessageQueue {
   20|      4|    pub fn new(max_queue: usize, stats: Arc<Stats>) -> Self {
   21|      4|        Self {
   22|      4|            state: Mutex::new(State {
   23|      4|                queue: FairQueue::new(move |_| max_queue, |_| 1),
                                                             ^1             ^1
   24|      4|                stopped: false,
   25|      4|            }),
   26|      4|            condition: Condvar::new(),
   27|      4|            stats,
   28|      4|            inbound_callback: None,
   29|      4|            inbound_dropped_callback: None,
   30|      4|        }
   31|      4|    }
   32|       |
   33|      0|    pub fn set_inbound_callback(&mut self, callback: MessageCallback) {
   34|      0|        self.inbound_callback = Some(callback);
   35|      0|    }
   36|       |
   37|      0|    pub fn set_inbound_dropped_callback(&mut self, callback: MessageCallback) {
   38|      0|        self.inbound_dropped_callback = Some(callback);
   39|      0|    }
   40|       |
   41|      1|    pub fn put(&self, message: Message, channel: Arc<Channel>) -> bool {
   42|      1|        let message_type = message.message_type();
   43|      1|        let added = self
   44|      1|            .state
   45|      1|            .lock()
   46|      1|            .unwrap()
   47|      1|            .queue
   48|      1|            .push(channel.channel_id(), (message.clone(), channel.clone()));
   49|      1|
   50|      1|        if added {
   51|      1|            self.stats
   52|      1|                .inc(StatType::MessageProcessor, DetailType::Process);
   53|      1|            self.stats
   54|      1|                .inc(StatType::MessageProcessorType, message_type.into());
   55|      1|
   56|      1|            self.condition.notify_all();
   57|      1|            if let Some(cb) = &self.inbound_callback {
                                      ^0
   58|      0|                cb(channel.channel_id(), &message);
   59|      1|            }
   60|       |        } else {
   61|      0|            self.stats
   62|      0|                .inc(StatType::MessageProcessor, DetailType::Overfill);
   63|      0|            self.stats
   64|      0|                .inc(StatType::MessageProcessorOverfill, message_type.into());
   65|      0|            if let Some(cb) = &self.inbound_dropped_callback {
   66|      0|                cb(channel.channel_id(), &message);
   67|      0|            }
   68|       |        }
   69|       |
   70|      1|        added
   71|      1|    }
   72|       |
   73|     13|    pub(crate) fn next_batch(
   74|     13|        &self,
   75|     13|        max_batch_size: usize,
   76|     13|    ) -> VecDeque<(ChannelId, (Message, Arc<Channel>))> {
   77|     13|        self.state.lock().unwrap().queue.next_batch(max_batch_size)
   78|     13|    }
   79|       |
   80|     12|    pub fn wait_for_messages(&self) {
   81|     12|        let state = self.state.lock().unwrap();
   82|     12|        if !state.queue.is_empty() {
   83|      0|            return;
   84|     12|        }
   85|     12|        drop(
   86|     12|            self.condition
   87|     24|                .wait_while(state, |s| !s.stopped && s.queue.is_empty()),
                                                                   ^12
   88|     12|        )
   89|     12|    }
   90|       |
   91|      3|    pub fn size(&self) -> usize {
   92|      3|        self.state.lock().unwrap().queue.len()
   93|      3|    }
   94|       |
   95|       |    /// Stop container and notify waiting threads
   96|      3|    pub fn stop(&self) {
   97|      3|        {
   98|      3|            let mut lock = self.state.lock().unwrap();
   99|      3|            lock.stopped = true;
  100|      3|        }
  101|      3|        self.condition.notify_all();
  102|      3|    }
  103|       |
  104|      0|    pub fn container_info(&self) -> ContainerInfo {
  105|      0|        let guard = self.state.lock().unwrap();
  106|      0|        ContainerInfo::builder()
  107|      0|            .node("queue", guard.queue.container_info())
  108|      0|            .finish()
  109|      0|    }
  110|       |}
  111|       |
  112|       |impl Default for InboundMessageQueue {
  113|      0|    fn default() -> Self {
  114|      0|        Self::new(64, Arc::new(Stats::default()))
  115|      0|    }
  116|       |}
  117|       |
  118|       |pub struct InboundMessageQueueCleanup(Arc<InboundMessageQueue>);
  119|       |
  120|       |impl InboundMessageQueueCleanup {
  121|      3|    pub fn new(queue: Arc<InboundMessageQueue>) -> Self {
  122|      3|        Self(queue)
  123|      3|    }
  124|       |}
  125|       |
  126|       |impl DeadChannelCleanupStep for InboundMessageQueueCleanup {
  127|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
  128|      0|        let mut guard = self.0.state.lock().unwrap();
  129|      0|        for channel_id in dead_channel_ids {
  130|      0|            guard.queue.remove(channel_id);
  131|      0|        }
  132|      0|    }
  133|       |}
  134|       |
  135|       |struct State {
  136|       |    queue: FairQueue<ChannelId, (Message, Arc<Channel>)>,
  137|       |    stopped: bool,
  138|       |}
  139|       |
  140|       |#[cfg(test)]
  141|       |mod tests {
  142|       |    use super::*;
  143|       |    use rsnano_messages::Message;
  144|       |
  145|       |    #[test]
  146|      1|    fn put_and_get_one_message() {
  147|      1|        let manager = InboundMessageQueue::new(1, Arc::new(Stats::default()));
  148|      1|        assert_eq!(manager.size(), 0);
  149|      1|        manager.put(Message::BulkPush, Arc::new(Channel::new_test_instance()));
  150|      1|        assert_eq!(manager.size(), 1);
  151|      1|        assert_eq!(manager.next_batch(1000).len(), 1);
  152|      1|        assert_eq!(manager.size(), 0);
  153|      1|    }
  154|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/keepalive/keepalive_message_factory.rs:
    1|       |use rsnano_core::utils::{Peer, NULL_ENDPOINT};
    2|       |use rsnano_messages::{Keepalive, Message};
    3|       |use rsnano_network::Network;
    4|       |use std::{
    5|       |    net::{Ipv6Addr, SocketAddrV6},
    6|       |    sync::{Arc, RwLock},
    7|       |};
    8|       |
    9|       |#[derive(Clone)]
   10|       |pub struct KeepaliveMessageFactory {
   11|       |    network: Arc<RwLock<Network>>,
   12|       |    external_addr: Peer,
   13|       |}
   14|       |
   15|       |impl KeepaliveMessageFactory {
   16|      3|    pub fn new(network: Arc<RwLock<Network>>, external_addr: Peer) -> Self {
   17|      3|        Self {
   18|      3|            network,
   19|      3|            external_addr,
   20|      3|        }
   21|      3|    }
   22|       |
   23|      0|    pub fn create_keepalive_self(&self) -> Message {
   24|      0|        let mut result = Keepalive::default();
   25|      0|        let network = self.network.read().unwrap();
   26|      0|        network.random_fill_realtime(&mut result.peers);
   27|      0|        // We will clobber values in index 0 and 1 and if there are only 2 nodes in the system, these are the only positions occupied
   28|      0|        // Move these items to index 2 and 3 so they propagate
   29|      0|        result.peers[2] = result.peers[0];
   30|      0|        result.peers[3] = result.peers[1];
   31|      0|        // Replace part of message with node external address or listening port
   32|      0|        result.peers[1] = SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0); // For node v19 (response channels)
   33|      0|        if self.external_addr.address != Ipv6Addr::UNSPECIFIED.to_string()
   34|      0|            && self.external_addr.port != 0
   35|      0|        {
   36|      0|            result.peers[0] = SocketAddrV6::new(
   37|      0|                self.external_addr.address.parse().unwrap(),
   38|      0|                self.external_addr.port,
   39|      0|                0,
   40|      0|                0,
   41|      0|            );
   42|      0|        } else {
   43|       |            // TODO Read external address from port_mapping!
   44|       |            //let external_address  node.port_mapping.external_address ());
   45|      0|            let external_address = SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, 0, 0, 0);
   46|      0|            if !external_address.ip().is_unspecified() {
   47|      0|                result.peers[0] =
   48|      0|                    SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, network.listening_port(), 0, 0);
   49|      0|                result.peers[1] = external_address;
   50|      0|            } else {
   51|      0|                result.peers[0] =
   52|      0|                    SocketAddrV6::new(Ipv6Addr::UNSPECIFIED, network.listening_port(), 0, 0);
   53|      0|            }
   54|       |        }
   55|      0|        Message::Keepalive(result)
   56|      0|    }
   57|       |
   58|      0|    pub fn create_keepalive(&self) -> Message {
   59|      0|        let mut peers = [NULL_ENDPOINT; 8];
   60|      0|        self.network
   61|      0|            .read()
   62|      0|            .unwrap()
   63|      0|            .random_fill_realtime(&mut peers);
   64|      0|
   65|      0|        Message::Keepalive(Keepalive { peers })
   66|      0|    }
   67|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/keepalive/keepalive_publisher.rs:
    1|       |use super::KeepaliveMessageFactory;
    2|       |use crate::transport::MessageSender;
    3|       |use rsnano_core::utils::Peer;
    4|       |use rsnano_network::{
    5|       |    utils::into_ipv6_socket_address, ChannelId, Network, PeerConnector, TrafficType,
    6|       |};
    7|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
    8|       |use std::{
    9|       |    net::SocketAddr,
   10|       |    sync::{Arc, Mutex, RwLock},
   11|       |};
   12|       |use tracing::error;
   13|       |
   14|       |/// Connects to a peer if we don't have a connection
   15|       |/// or it sends a keepalive message if we are already connected
   16|       |pub struct KeepalivePublisher {
   17|       |    keepalive_listener: OutputListenerMt<Peer>,
   18|       |    network: Arc<RwLock<Network>>,
   19|       |    peer_connector: Arc<PeerConnector>,
   20|       |    message_sender: Mutex<MessageSender>,
   21|       |    message_factory: Arc<KeepaliveMessageFactory>,
   22|       |}
   23|       |
   24|       |impl KeepalivePublisher {
   25|      3|    pub fn new(
   26|      3|        network: Arc<RwLock<Network>>,
   27|      3|        peer_connector: Arc<PeerConnector>,
   28|      3|        message_sender: MessageSender,
   29|      3|        message_factory: Arc<KeepaliveMessageFactory>,
   30|      3|    ) -> Self {
   31|      3|        Self {
   32|      3|            keepalive_listener: OutputListenerMt::new(),
   33|      3|            network,
   34|      3|            peer_connector,
   35|      3|            message_sender: Mutex::new(message_sender),
   36|      3|            message_factory,
   37|      3|        }
   38|      3|    }
   39|       |
   40|      0|    pub fn track_keepalives(&self) -> Arc<OutputTrackerMt<Peer>> {
   41|      0|        self.keepalive_listener.track()
   42|      0|    }
   43|       |
   44|      0|    pub async fn keepalive_or_connect(&self, address: String, port: u16) {
   45|      0|        self.keepalive_listener
   46|      0|            .emit(Peer::new(address.clone(), port));
   47|      0|        match tokio::net::lookup_host((address.as_str(), port)).await {
   48|      0|            Ok(addresses) => {
   49|      0|                for addr in addresses {
   50|      0|                    self.keepalive_or_connect_socket(addr);
   51|      0|                }
   52|       |            }
   53|      0|            Err(e) => {
   54|      0|                error!(
   55|      0|                    "Error resolving address for keepalive: {}:{} ({})",
   56|       |                    address, port, e
   57|       |                )
   58|       |            }
   59|       |        }
   60|      0|    }
   61|       |
   62|      0|    fn keepalive_or_connect_socket(&self, peer: SocketAddr) {
   63|      0|        let peer_v6 = into_ipv6_socket_address(peer);
   64|      0|
   65|      0|        let channel_id = self
   66|      0|            .network
   67|      0|            .read()
   68|      0|            .unwrap()
   69|      0|            .find_realtime_channel_by_peering_addr(&peer_v6);
   70|      0|
   71|      0|        match channel_id {
   72|      0|            Some(channel_id) => {
   73|      0|                self.try_send_keepalive(channel_id);
   74|      0|            }
   75|      0|            None => {
   76|      0|                self.peer_connector.connect_to(peer_v6);
   77|      0|            }
   78|       |        }
   79|      0|    }
   80|       |
   81|      0|    fn try_send_keepalive(&self, channel_id: ChannelId) {
   82|      0|        let keepalive = self.message_factory.create_keepalive();
   83|      0|
   84|      0|        self.message_sender.lock().unwrap().try_send(
   85|      0|            channel_id,
   86|      0|            &keepalive,
   87|      0|            TrafficType::Keepalive,
   88|      0|        );
   89|      0|    }
   90|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/keepalive/preconfigured_peers_keepalive.rs:
    1|       |use super::KeepalivePublisher;
    2|       |use rsnano_core::utils::Peer;
    3|       |use std::sync::Arc;
    4|       |
    5|       |/// Connect to preconfigured peers or send keepalive messages
    6|       |/// if we are already connected
    7|       |pub(crate) struct PreconfiguredPeersKeepalive {
    8|       |    peers: Vec<Peer>,
    9|       |    keepalive: Arc<KeepalivePublisher>,
   10|       |}
   11|       |
   12|       |impl PreconfiguredPeersKeepalive {
   13|      3|    pub(crate) fn new(peers: Vec<Peer>, keepalive: Arc<KeepalivePublisher>) -> Self {
   14|      3|        Self { peers, keepalive }
   15|      3|    }
   16|       |
   17|      0|    pub async fn keepalive(&self) {
   18|      0|        for peer in &self.peers {
   19|      0|            self.keepalive
   20|      0|                .keepalive_or_connect(peer.address.clone(), peer.port)
   21|      0|                .await;
   22|       |        }
   23|      0|    }
   24|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/latest_keepalives.rs:
    1|       |use rand::{seq::IteratorRandom, thread_rng};
    2|       |use rsnano_messages::Keepalive;
    3|       |use rsnano_network::{ChannelId, DeadChannelCleanupStep};
    4|       |use std::{
    5|       |    collections::HashMap,
    6|       |    sync::{Arc, Mutex},
    7|       |};
    8|       |
    9|       |/// Keeps the last keepalive message per channel in memory, so that we can
   10|       |/// later use that information, when we want to connect to more nodes
   11|       |pub struct LatestKeepalives {
   12|       |    entries: HashMap<ChannelId, Keepalive>,
   13|       |    max_len: usize,
   14|       |}
   15|       |
   16|       |impl Default for LatestKeepalives {
   17|     10|    fn default() -> Self {
   18|     10|        Self::with_max_len(1000)
   19|     10|    }
   20|       |}
   21|       |
   22|       |impl LatestKeepalives {
   23|     11|    pub fn with_max_len(max_len: usize) -> Self {
   24|     11|        Self {
   25|     11|            entries: HashMap::new(),
   26|     11|            max_len,
   27|     11|        }
   28|     11|    }
   29|       |
   30|     15|    pub fn insert(&mut self, channel_id: ChannelId, keepalive: Keepalive) {
   31|     16|        while self.len() >= self.max_len {
   32|      1|            self.pop_random();
   33|      1|        }
   34|     15|        self.entries.insert(channel_id, keepalive);
   35|     15|    }
   36|       |
   37|      4|    pub fn get(&self, channel_id: ChannelId) -> Option<&Keepalive> {
   38|      4|        self.entries.get(&channel_id)
   39|      4|    }
   40|       |
   41|       |    //TODO: randomize
   42|     10|    pub fn pop_random(&mut self) -> Option<Keepalive> {
   43|     10|        let mut rng = thread_rng();
   44|     10|        if let Some(&channel_id) = self.entries.keys().choose(&mut rng) {
                                   ^5
   45|      5|            self.entries.remove(&channel_id)
   46|       |        } else {
   47|      5|            None
   48|       |        }
   49|     10|    }
   50|       |
   51|      1|    pub fn remove(&mut self, channel_id: ChannelId) {
   52|      1|        self.entries.remove(&channel_id);
   53|      1|    }
   54|       |
   55|     23|    pub fn len(&self) -> usize {
   56|     23|        self.entries.len()
   57|     23|    }
   58|       |
   59|      2|    pub fn max_len(&self) -> usize {
   60|      2|        self.max_len
   61|      2|    }
   62|       |}
   63|       |
   64|       |pub(crate) struct LatestKeepalivesCleanup {
   65|       |    keepalives: Arc<Mutex<LatestKeepalives>>,
   66|       |}
   67|       |
   68|       |impl LatestKeepalivesCleanup {
   69|      3|    pub(crate) fn new(keepalives: Arc<Mutex<LatestKeepalives>>) -> Self {
   70|      3|        Self { keepalives }
   71|      3|    }
   72|       |}
   73|       |
   74|       |impl DeadChannelCleanupStep for LatestKeepalivesCleanup {
   75|      0|    fn clean_up_dead_channels(&self, dead_channel_ids: &[ChannelId]) {
   76|      0|        let mut keepalives = self.keepalives.lock().unwrap();
   77|      0|        for channel_id in dead_channel_ids {
   78|      0|            keepalives.remove(*channel_id);
   79|      0|        }
   80|      0|    }
   81|       |}
   82|       |
   83|       |#[cfg(test)]
   84|       |mod tests {
   85|       |    use super::*;
   86|       |    use rsnano_core::utils::{TEST_ENDPOINT_2, TEST_ENDPOINT_3};
   87|       |
   88|       |    #[test]
   89|      1|    fn empty() {
   90|      1|        let cache = LatestKeepalives::default();
   91|      1|        assert_eq!(cache.len(), 0);
   92|      1|        assert_eq!(cache.get(ChannelId::from(1)), None);
   93|      1|        assert_eq!(cache.max_len(), 1000);
   94|      1|    }
   95|       |
   96|       |    #[test]
   97|      1|    fn insert_one() {
   98|      1|        let mut cache = LatestKeepalives::default();
   99|      1|        let channel_id = ChannelId::from(1);
  100|      1|        cache.insert(channel_id, KEEPALIVE_1);
  101|      1|        assert_eq!(cache.len(), 1);
  102|      1|        assert_eq!(cache.get(channel_id).cloned(), Some(KEEPALIVE_1));
  103|      1|    }
  104|       |
  105|       |    #[test]
  106|      1|    fn insert_two_for_different_channel() {
  107|      1|        let mut cache = LatestKeepalives::default();
  108|      1|        cache.insert(ChannelId::from(1), KEEPALIVE_1);
  109|      1|        cache.insert(ChannelId::from(2), KEEPALIVE_2);
  110|      1|        assert_eq!(cache.len(), 2);
  111|      1|    }
  112|       |
  113|       |    #[test]
  114|      1|    fn inserting_for_same_channel_should_replace_previous_entry() {
  115|      1|        let mut cache = LatestKeepalives::default();
  116|      1|        let channel_id = ChannelId::from(1);
  117|      1|        cache.insert(channel_id, KEEPALIVE_1);
  118|      1|        cache.insert(channel_id, KEEPALIVE_2);
  119|      1|        assert_eq!(cache.len(), 1);
  120|      1|        assert_eq!(cache.get(channel_id).cloned(), Some(KEEPALIVE_2))
  121|      1|    }
  122|       |
  123|       |    #[test]
  124|      1|    fn pop_the_only_entry() {
  125|      1|        let mut cache = LatestKeepalives::default();
  126|      1|        cache.insert(ChannelId::from(1), KEEPALIVE_1);
  127|      1|
  128|      1|        let popped = cache.pop_random().unwrap();
  129|      1|
  130|      1|        assert_eq!(popped, KEEPALIVE_1);
  131|      1|        assert_eq!(cache.len(), 0);
  132|      1|    }
  133|       |
  134|       |    #[test]
  135|      1|    fn pop_multiple() {
  136|      1|        let mut cache = LatestKeepalives::default();
  137|      1|        cache.insert(ChannelId::from(1), KEEPALIVE_1);
  138|      1|        cache.insert(ChannelId::from(2), KEEPALIVE_2);
  139|      1|        cache.insert(ChannelId::from(3), KEEPALIVE_3);
  140|      1|
  141|      1|        assert!(cache.pop_random().is_some());
  142|      1|        assert!(cache.pop_random().is_some());
  143|      1|        assert!(cache.pop_random().is_some());
  144|      1|        assert_eq!(cache.pop_random(), None);
  145|      1|    }
  146|       |
  147|       |    #[test]
  148|      1|    fn max_len() {
  149|      1|        let mut cache = LatestKeepalives::with_max_len(2);
  150|      1|        assert_eq!(cache.max_len(), 2);
  151|      1|        cache.insert(ChannelId::from(1), KEEPALIVE_1);
  152|      1|        cache.insert(ChannelId::from(2), KEEPALIVE_2);
  153|      1|        cache.insert(ChannelId::from(3), KEEPALIVE_3);
  154|      1|
  155|      1|        assert_eq!(cache.len(), 2);
  156|      1|    }
  157|       |
  158|       |    #[test]
  159|      1|    fn remove() {
  160|      1|        let mut cache = LatestKeepalives::default();
  161|      1|        cache.insert(ChannelId::from(1), KEEPALIVE_1);
  162|      1|        cache.insert(ChannelId::from(2), KEEPALIVE_2);
  163|      1|        cache.insert(ChannelId::from(3), KEEPALIVE_3);
  164|      1|
  165|      1|        cache.remove(ChannelId::from(2));
  166|      1|
  167|      1|        assert_eq!(cache.len(), 2);
  168|      1|        assert_eq!(cache.get(ChannelId::from(2)), None);
  169|      1|    }
  170|       |
  171|       |    const KEEPALIVE_1: Keepalive = Keepalive::new_test_instance();
  172|       |    const KEEPALIVE_2: Keepalive = Keepalive {
  173|       |        peers: [TEST_ENDPOINT_2; 8],
  174|       |    };
  175|       |    const KEEPALIVE_3: Keepalive = Keepalive {
  176|       |        peers: [TEST_ENDPOINT_3; 8],
  177|       |    };
  178|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/message_flooder.rs:
    1|       |use super::{try_send_serialized_message, MessageSender};
    2|       |use crate::{representatives::OnlineReps, stats::Stats};
    3|       |use rsnano_messages::{Message, MessageSerializer};
    4|       |use rsnano_network::{Channel, Network, TrafficType};
    5|       |use std::{
    6|       |    ops::{Deref, DerefMut},
    7|       |    sync::{Arc, Mutex, RwLock},
    8|       |};
    9|       |
   10|       |/// Floods messages to PRs and non PRs
   11|       |#[derive(Clone)]
   12|       |pub struct MessageFlooder {
   13|       |    online_reps: Arc<Mutex<OnlineReps>>,
   14|       |    network: Arc<RwLock<Network>>,
   15|       |    stats: Arc<Stats>,
   16|       |    message_serializer: MessageSerializer,
   17|       |    sender: MessageSender,
   18|       |}
   19|       |
   20|       |impl MessageFlooder {
   21|      3|    pub fn new(
   22|      3|        online_reps: Arc<Mutex<OnlineReps>>,
   23|      3|        network: Arc<RwLock<Network>>,
   24|      3|        stats: Arc<Stats>,
   25|      3|        sender: MessageSender,
   26|      3|    ) -> Self {
   27|      3|        Self {
   28|      3|            online_reps,
   29|      3|            network,
   30|      3|            stats,
   31|      3|            message_serializer: sender.get_serializer(),
   32|      3|            sender,
   33|      3|        }
   34|      3|    }
   35|       |
   36|      0|    pub(crate) fn new_null() -> Self {
   37|      0|        Self::new(
   38|      0|            Arc::new(Mutex::new(OnlineReps::default())),
   39|      0|            Arc::new(RwLock::new(Network::new_test_instance())),
   40|      0|            Arc::new(Stats::default()),
   41|      0|            MessageSender::new_null(),
   42|      0|        )
   43|      0|    }
   44|       |
   45|      0|    pub(crate) fn flood_prs_and_some_non_prs(
   46|      0|        &mut self,
   47|      0|        message: &Message,
   48|      0|        traffic_type: TrafficType,
   49|      0|        scale: f32,
   50|      0|    ) {
   51|      0|        let peered_prs = self.online_reps.lock().unwrap().peered_principal_reps();
   52|      0|        for rep in peered_prs {
   53|      0|            self.sender.try_send(rep.channel_id, &message, traffic_type);
   54|      0|        }
   55|       |
   56|       |        let mut channels;
   57|       |        let fanout;
   58|       |        {
   59|      0|            let network = self.network.read().unwrap();
   60|      0|            fanout = network.fanout(scale);
   61|      0|            channels = network.random_list_realtime(usize::MAX, 0)
   62|      0|        }
   63|      0|
   64|      0|        self.remove_no_pr(&mut channels, fanout);
   65|      0|        for peer in channels {
   66|      0|            self.sender
   67|      0|                .try_send(peer.channel_id(), &message, traffic_type);
   68|      0|        }
   69|      0|    }
   70|       |
   71|      0|    fn remove_no_pr(&self, channels: &mut Vec<Arc<Channel>>, count: usize) {
   72|      0|        {
   73|      0|            let reps = self.online_reps.lock().unwrap();
   74|      0|            channels.retain(|c| !reps.is_pr(c.channel_id()));
   75|      0|        }
   76|      0|        channels.truncate(count);
   77|      0|    }
   78|       |
   79|      0|    pub fn flood(&mut self, message: &Message, traffic_type: TrafficType, scale: f32) {
   80|      0|        let buffer = self.message_serializer.serialize(message);
   81|      0|        let channels = self.network.read().unwrap().random_fanout_realtime(scale);
   82|      0|
   83|      0|        let network_info = self.network.read().unwrap();
   84|      0|        for channel in channels {
   85|      0|            try_send_serialized_message(
   86|      0|                &network_info,
   87|      0|                &self.stats,
   88|      0|                channel.channel_id(),
   89|      0|                buffer,
   90|      0|                message,
   91|      0|                traffic_type,
   92|      0|            );
   93|      0|        }
   94|      0|    }
   95|       |}
   96|       |
   97|       |impl Deref for MessageFlooder {
   98|       |    type Target = MessageSender;
   99|       |
  100|      0|    fn deref(&self) -> &Self::Target {
  101|      0|        &self.sender
  102|      0|    }
  103|       |}
  104|       |
  105|       |impl DerefMut for MessageFlooder {
  106|      0|    fn deref_mut(&mut self) -> &mut Self::Target {
  107|      0|        &mut self.sender
  108|      0|    }
  109|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/message_processor.rs:
    1|       |use super::{InboundMessageQueue, RealtimeMessageHandler};
    2|       |use crate::config::{NodeConfig, NodeFlags};
    3|       |use rsnano_messages::Message;
    4|       |use rsnano_network::{Channel, ChannelId};
    5|       |use std::{
    6|       |    cmp::{max, min},
    7|       |    collections::VecDeque,
    8|       |    sync::{
    9|       |        atomic::{AtomicBool, Ordering},
   10|       |        Arc,
   11|       |    },
   12|       |    thread::JoinHandle,
   13|       |    time::Instant,
   14|       |};
   15|       |use tracing::debug;
   16|       |
   17|       |#[derive(Clone, Debug, PartialEq)]
   18|       |pub struct MessageProcessorConfig {
   19|       |    pub threads: usize,
   20|       |    pub max_queue: usize,
   21|       |}
   22|       |
   23|       |impl MessageProcessorConfig {
   24|      9|    pub fn new(parallelism: usize) -> Self {
   25|      9|        Self {
   26|      9|            threads: min(2, max(parallelism / 4, 1)),
   27|      9|            max_queue: 64,
   28|      9|        }
   29|      9|    }
   30|       |}
   31|       |
   32|       |/// Process inbound messages from other nodes
   33|       |pub struct MessageProcessor {
   34|       |    flags: NodeFlags,
   35|       |    config: NodeConfig,
   36|       |    processing_threads: Vec<JoinHandle<()>>,
   37|       |    state: Arc<State>,
   38|       |}
   39|       |
   40|       |impl MessageProcessor {
   41|      3|    pub fn new(
   42|      3|        flags: NodeFlags,
   43|      3|        config: NodeConfig,
   44|      3|        inbound_queue: Arc<InboundMessageQueue>,
   45|      3|        realtime_handler: Arc<RealtimeMessageHandler>,
   46|      3|    ) -> Self {
   47|      3|        Self {
   48|      3|            flags,
   49|      3|            config,
   50|      3|            processing_threads: Vec::new(),
   51|      3|            state: Arc::new(State {
   52|      3|                inbound_queue,
   53|      3|                realtime_handler,
   54|      3|                stopped: AtomicBool::new(false),
   55|      3|            }),
   56|      3|        }
   57|      3|    }
   58|       |
   59|      3|    pub fn start(&mut self) {
   60|      3|        if !self.flags.disable_tcp_realtime {
   61|     12|            for _ in 0..self.config.network_threads {
                                      ^3
   62|     12|                let state = self.state.clone();
   63|     12|                self.processing_threads.push(
   64|     12|                    std::thread::Builder::new()
   65|     12|                        .name("Msg processing".to_string())
   66|     12|                        .spawn(move || {
   67|     12|                            state.run();
   68|     12|                        })
   69|     12|                        .unwrap(),
   70|     12|                );
   71|     12|            }
   72|      0|        }
   73|      3|    }
   74|       |
   75|      3|    pub fn stop(&mut self) {
   76|      3|        self.state.stopped.store(true, Ordering::SeqCst);
   77|      3|        self.state.inbound_queue.stop();
   78|     12|        for t in self.processing_threads.drain(..) {
                               ^3
   79|     12|            t.join().unwrap();
   80|     12|        }
   81|      3|    }
   82|       |}
   83|       |
   84|       |impl Drop for MessageProcessor {
   85|      3|    fn drop(&mut self) {
   86|      3|        // All threads must be stopped before this destructor
   87|      3|        debug_assert!(self.processing_threads.is_empty());
   88|      3|    }
   89|       |}
   90|       |
   91|       |struct State {
   92|       |    stopped: AtomicBool,
   93|       |    realtime_handler: Arc<RealtimeMessageHandler>,
   94|       |    inbound_queue: Arc<InboundMessageQueue>,
   95|       |}
   96|       |
   97|       |impl State {
   98|       |    const MAX_BATCH_SIZE: usize = 1024 * 4;
   99|       |
  100|     12|    fn run(&self) {
  101|     24|        while !self.stopped.load(Ordering::SeqCst) {
  102|     12|            let batch = self.inbound_queue.next_batch(Self::MAX_BATCH_SIZE);
  103|     12|            if !batch.is_empty() {
  104|      0|                self.handle_batch(batch);
  105|     12|            } else {
  106|     12|                self.inbound_queue.wait_for_messages();
  107|     12|            }
  108|       |        }
  109|     12|    }
  110|       |
  111|      0|    fn handle_batch(&self, batch: VecDeque<(ChannelId, (Message, Arc<Channel>))>) {
  112|      0|        let start = Instant::now();
  113|      0|        let batch_size = batch.len();
  114|      0|        for (_, (message, channel)) in batch {
  115|      0|            self.realtime_handler.process(message, &channel);
  116|      0|        }
  117|       |
  118|      0|        let elapsed_millis = start.elapsed().as_millis();
  119|      0|        if elapsed_millis > 100 {
  120|      0|            debug!(
  121|      0|                "Processed {} messages in {} milliseconds (rate of {} messages per second)",
  122|      0|                batch_size,
  123|      0|                elapsed_millis,
  124|      0|                batch_size as u128 * 1000 / elapsed_millis
  125|       |            );
  126|      0|        }
  127|      0|    }
  128|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/message_sender.rs:
    1|       |use crate::stats::{Direction, StatType, Stats};
    2|       |use rsnano_messages::{Message, MessageSerializer, ProtocolInfo};
    3|       |use rsnano_network::{ChannelId, Network, TrafficType};
    4|       |use std::sync::{Arc, RwLock};
    5|       |use tracing::trace;
    6|       |
    7|       |pub type MessageCallback = Arc<dyn Fn(ChannelId, &Message) + Send + Sync>;
    8|       |
    9|       |/// Sends messages via a given channel to a peered node
   10|       |#[derive(Clone)]
   11|       |pub struct MessageSender {
   12|       |    network: Arc<RwLock<Network>>,
   13|       |    stats: Arc<Stats>,
   14|       |    message_serializer: MessageSerializer,
   15|       |    published_callback: Option<MessageCallback>,
   16|       |}
   17|       |
   18|       |impl MessageSender {
   19|      3|    pub fn new(
   20|      3|        network: Arc<RwLock<Network>>,
   21|      3|        stats: Arc<Stats>,
   22|      3|        protocol_info: ProtocolInfo,
   23|      3|    ) -> Self {
   24|      3|        Self {
   25|      3|            network,
   26|      3|            stats,
   27|      3|            message_serializer: MessageSerializer::new(protocol_info),
   28|      3|            published_callback: None,
   29|      3|        }
   30|      3|    }
   31|       |
   32|      3|    pub fn new_with_buffer_size(
   33|      3|        network: Arc<RwLock<Network>>,
   34|      3|        stats: Arc<Stats>,
   35|      3|        protocol_info: ProtocolInfo,
   36|      3|        buffer_size: usize,
   37|      3|    ) -> Self {
   38|      3|        Self {
   39|      3|            network,
   40|      3|            stats,
   41|      3|            message_serializer: MessageSerializer::new_with_buffer_size(protocol_info, buffer_size),
   42|      3|            published_callback: None,
   43|      3|        }
   44|      3|    }
   45|       |
   46|      0|    pub fn set_published_callback(&mut self, callback: MessageCallback) {
   47|      0|        self.published_callback = Some(callback);
   48|      0|    }
   49|       |
   50|      0|    pub(crate) fn new_null() -> Self {
   51|      0|        Self::new(
   52|      0|            Arc::new(RwLock::new(Network::new_test_instance())),
   53|      0|            Arc::new(Stats::default()),
   54|      0|            Default::default(),
   55|      0|        )
   56|      0|    }
   57|       |
   58|      0|    pub fn try_send(
   59|      0|        &mut self,
   60|      0|        channel_id: ChannelId,
   61|      0|        message: &Message,
   62|      0|        traffic_type: TrafficType,
   63|      0|    ) -> bool {
   64|      0|        let buffer = self.message_serializer.serialize(message);
   65|      0|        let sent = {
   66|      0|            let network_info = self.network.read().unwrap();
   67|      0|            try_send_serialized_message(
   68|      0|                &network_info,
   69|      0|                &self.stats,
   70|      0|                channel_id,
   71|      0|                buffer,
   72|      0|                message,
   73|      0|                traffic_type,
   74|      0|            )
   75|       |        };
   76|       |
   77|      0|        if let Some(callback) = &self.published_callback {
   78|      0|            callback(channel_id, message);
   79|      0|        }
   80|       |
   81|      0|        sent
   82|      0|    }
   83|       |
   84|      3|    pub fn get_serializer(&self) -> MessageSerializer {
   85|      3|        self.message_serializer.clone()
   86|      3|    }
   87|       |
   88|      0|    pub fn try_send_serialized_message(
   89|      0|        &self,
   90|      0|        channel_id: ChannelId,
   91|      0|        buffer: &[u8],
   92|      0|        message: &Message,
   93|      0|        traffic_type: TrafficType,
   94|      0|    ) -> bool {
   95|      0|        let sent = self
   96|      0|            .network
   97|      0|            .read()
   98|      0|            .unwrap()
   99|      0|            .try_send_buffer(channel_id, buffer, traffic_type);
  100|      0|
  101|      0|        if sent {
  102|      0|            self.stats
  103|      0|                .inc_dir_aggregate(StatType::Message, message.into(), Direction::Out);
  104|      0|            trace!(%channel_id, message = ?message, "Message sent");
  105|       |        } else {
  106|      0|            let detail_type = message.into();
  107|      0|            self.stats
  108|      0|                .inc_dir_aggregate(StatType::Drop, detail_type, Direction::Out);
  109|      0|            trace!(%channel_id, message = ?message, "Message dropped");
  110|       |        }
  111|       |
  112|      0|        sent
  113|      0|    }
  114|       |}
  115|       |
  116|      0|pub(crate) fn try_send_serialized_message(
  117|      0|    network: &Network,
  118|      0|    stats: &Stats,
  119|      0|    channel_id: ChannelId,
  120|      0|    buffer: &[u8],
  121|      0|    message: &Message,
  122|      0|    traffic_type: TrafficType,
  123|      0|) -> bool {
  124|      0|    let sent = network.try_send_buffer(channel_id, buffer, traffic_type);
  125|      0|
  126|      0|    if sent {
  127|      0|        stats.inc_dir_aggregate(StatType::Message, message.into(), Direction::Out);
  128|      0|        trace!(%channel_id, message = ?message, "Message sent");
  129|       |    } else {
  130|      0|        let detail_type = message.into();
  131|      0|        stats.inc_dir_aggregate(StatType::Drop, detail_type, Direction::Out);
  132|      0|        trace!(%channel_id, message = ?message, "Message dropped");
  133|       |    }
  134|       |
  135|      0|    sent
  136|      0|}

/home/gustav/code/nano/rsnano-node/node/src/transport/nano_data_receiver.rs:
    1|       |use super::{HandshakeProcess, HandshakeStatus, InboundMessageQueue, LatestKeepalives};
    2|       |use crate::{
    3|       |    stats::{DetailType, Direction, StatType, Stats},
    4|       |    NetworkParams,
    5|       |};
    6|       |use rsnano_core::NodeId;
    7|       |use rsnano_messages::*;
    8|       |use rsnano_network::{
    9|       |    Channel, ChannelDirection, ChannelMode, DataReceiver, Network, ReceiveResult,
   10|       |};
   11|       |use std::{
   12|       |    sync::{Arc, Mutex, RwLock, Weak},
   13|       |    time::Instant,
   14|       |};
   15|       |use tracing::debug;
   16|       |
   17|       |pub(crate) struct NanoDataReceiver {
   18|       |    channel: Arc<Channel>,
   19|       |    handshake_process: HandshakeProcess,
   20|       |    message_deserializer: MessageDeserializer,
   21|       |    inbound_queue: Arc<InboundMessageQueue>,
   22|       |    last_telemetry_req: Mutex<Option<Instant>>,
   23|       |    network_params: Arc<NetworkParams>,
   24|       |    latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   25|       |    stats: Arc<Stats>,
   26|       |    network: Weak<RwLock<Network>>,
   27|       |    first_message: bool,
   28|       |    node_id: NodeId,
   29|       |}
   30|       |
   31|       |impl NanoDataReceiver {
   32|      0|    pub fn new(
   33|      0|        channel: Arc<Channel>,
   34|      0|        network_params: Arc<NetworkParams>,
   35|      0|        handshake_process: HandshakeProcess,
   36|      0|        message_deserializer: MessageDeserializer,
   37|      0|        inbound_queue: Arc<InboundMessageQueue>,
   38|      0|        latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   39|      0|        stats: Arc<Stats>,
   40|      0|        network: Weak<RwLock<Network>>,
   41|      0|    ) -> Self {
   42|      0|        Self {
   43|      0|            channel,
   44|      0|            handshake_process,
   45|      0|            message_deserializer,
   46|      0|            inbound_queue,
   47|      0|            last_telemetry_req: Mutex::new(None),
   48|      0|            network_params,
   49|      0|            latest_keepalives,
   50|      0|            stats,
   51|      0|            network,
   52|      0|            first_message: true,
   53|      0|            node_id: NodeId::ZERO,
   54|      0|        }
   55|      0|    }
   56|       |
   57|      0|    pub fn ensure_handshake(&mut self) {
   58|      0|        if self.channel.direction() == ChannelDirection::Outbound {
   59|      0|            self.initiate_handshake();
   60|      0|        }
   61|      0|    }
   62|       |
   63|      0|    fn initiate_handshake(&self) {
   64|      0|        if self
   65|      0|            .handshake_process
   66|      0|            .initiate_handshake(&self.channel)
   67|      0|            .is_err()
   68|      0|        {
   69|      0|            self.channel.close();
   70|      0|        }
   71|      0|    }
   72|       |
   73|      0|    fn queue_realtime(&self, message: Message) {
   74|      0|        self.inbound_queue.put(message, self.channel.clone());
   75|      0|        // TODO: Throttle if not added
   76|      0|    }
   77|       |
   78|      0|    fn is_outside_cooldown_period(&self) -> bool {
   79|      0|        let lock = self.last_telemetry_req.lock().unwrap();
   80|      0|        match *lock {
   81|      0|            Some(last_req) => {
   82|      0|                last_req.elapsed() >= self.network_params.network.telemetry_request_cooldown
   83|       |            }
   84|      0|            None => true,
   85|       |        }
   86|      0|    }
   87|       |
   88|      0|    fn set_last_telemetry_req(&self) {
   89|      0|        let mut lk = self.last_telemetry_req.lock().unwrap();
   90|      0|        *lk = Some(Instant::now());
   91|      0|    }
   92|       |
   93|      0|    fn set_last_keepalive(&self, keepalive: Keepalive) {
   94|      0|        self.latest_keepalives
   95|      0|            .lock()
   96|      0|            .unwrap()
   97|      0|            .insert(self.channel.channel_id(), keepalive);
   98|      0|    }
   99|       |
  100|      0|    fn process_realtime(&self, message: Message) -> ReceiveResult {
  101|      0|        let process = match &message {
  102|      0|            Message::Keepalive(keepalive) => {
  103|      0|                self.set_last_keepalive(keepalive.clone());
  104|      0|                true
  105|       |            }
  106|       |            Message::Publish(_)
  107|       |            | Message::AscPullAck(_)
  108|       |            | Message::AscPullReq(_)
  109|       |            | Message::ConfirmAck(_)
  110|       |            | Message::ConfirmReq(_)
  111|       |            | Message::FrontierReq(_)
  112|      0|            | Message::TelemetryAck(_) => true,
  113|       |            Message::TelemetryReq => {
  114|       |                // Only handle telemetry requests if they are outside of the cooldown period
  115|      0|                if self.is_outside_cooldown_period() {
  116|      0|                    self.set_last_telemetry_req();
  117|      0|                    true
  118|       |                } else {
  119|      0|                    self.stats.inc_dir(
  120|      0|                        StatType::Telemetry,
  121|      0|                        DetailType::RequestWithinProtectionCacheZone,
  122|      0|                        Direction::In,
  123|      0|                    );
  124|      0|                    false
  125|       |                }
  126|       |            }
  127|      0|            _ => false,
  128|       |        };
  129|       |
  130|      0|        if process {
  131|      0|            self.queue_realtime(message);
  132|      0|        }
  133|       |
  134|      0|        ReceiveResult::Continue
  135|      0|    }
  136|       |
  137|      0|    fn to_realtime_connection(&self, node_id: &NodeId) -> bool {
  138|      0|        if self.channel.mode() != ChannelMode::Undefined {
  139|      0|            return false;
  140|      0|        }
  141|       |
  142|      0|        let Some(network) = self.network.upgrade() else {
  143|      0|            return false;
  144|       |        };
  145|       |
  146|      0|        let result = network
  147|      0|            .read()
  148|      0|            .unwrap()
  149|      0|            .upgrade_to_realtime_connection(self.channel.channel_id(), *node_id);
  150|       |
  151|      0|        if let Some((channel, observers)) = result {
  152|      0|            for observer in observers {
  153|      0|                observer(channel.clone());
  154|      0|            }
  155|       |
  156|      0|            self.stats
  157|      0|                .inc(StatType::TcpChannels, DetailType::ChannelAccepted);
  158|      0|
  159|      0|            debug!(
  160|      0|                "Switched to realtime mode (addr: {}, node_id: {})",
  161|      0|                self.channel.peer_addr(),
  162|       |                node_id
  163|       |            );
  164|      0|            true
  165|       |        } else {
  166|      0|            debug!(
  167|      0|                channel_id = ?self.channel.channel_id(),
  168|      0|                peer = %self.channel.peer_addr(),
  169|      0|                %node_id,
  170|      0|                "Could not upgrade channel to realtime connection, because another channel for the same node ID was found",
  171|       |            );
  172|      0|            false
  173|       |        }
  174|      0|    }
  175|       |
  176|      0|    fn process_message(&mut self, message: Message) -> ReceiveResult {
  177|      0|        self.stats.inc_dir(
  178|      0|            StatType::TcpServer,
  179|      0|            DetailType::from(message.message_type()),
  180|      0|            Direction::In,
  181|      0|        );
  182|      0|
  183|      0|        /*
  184|      0|         * Server initially starts in undefined state, where it waits for either a handshake or booststrap request message
  185|      0|         * If the server receives a handshake (and it is successfully validated) it will switch to a realtime mode.
  186|      0|         * In realtime mode messages are deserialized and queued to `tcp_message_manager` for further processing.
  187|      0|         * In realtime mode any bootstrap requests are ignored.
  188|      0|         *
  189|      0|         * If the server receives a bootstrap request before receiving a handshake, it will switch to a bootstrap mode.
  190|      0|         * In bootstrap mode once a valid bootstrap request message is received, the server will start a corresponding bootstrap server and pass control to that server.
  191|      0|         * Once that server finishes its task, control is passed back to this server to read and process any subsequent messages.
  192|      0|         * In bootstrap mode any realtime messages are ignored
  193|      0|         */
  194|      0|        if self.channel.mode() == ChannelMode::Undefined {
  195|      0|            let result = match &message {
  196|       |                Message::BulkPull(_)
  197|       |                | Message::BulkPullAccount(_)
  198|       |                | Message::BulkPush
  199|      0|                | Message::FrontierReq(_) => HandshakeStatus::Bootstrap,
  200|      0|                Message::NodeIdHandshake(payload) => self
  201|      0|                    .handshake_process
  202|      0|                    .process_handshake(payload, &self.channel),
  203|       |
  204|      0|                _ => HandshakeStatus::Abort,
  205|       |            };
  206|       |
  207|      0|            match result {
  208|       |                HandshakeStatus::Abort | HandshakeStatus::AbortOwnNodeId => {
  209|      0|                    self.stats.inc_dir(
  210|      0|                        StatType::TcpServer,
  211|      0|                        DetailType::HandshakeAbort,
  212|      0|                        Direction::In,
  213|      0|                    );
  214|      0|                    debug!(
  215|      0|                        "Aborting handshake: {:?} ({})",
  216|      0|                        message.message_type(),
  217|      0|                        self.channel.peer_addr()
  218|       |                    );
  219|      0|                    if matches!(result, HandshakeStatus::AbortOwnNodeId) {
  220|      0|                        if let Some(peering_addr) = self.channel.peering_addr() {
  221|      0|                            if let Some(network) = self.network.upgrade() {
  222|      0|                                network.write().unwrap().perma_ban(peering_addr);
  223|      0|                            }
  224|      0|                        }
  225|      0|                    }
  226|      0|                    return ReceiveResult::Abort;
  227|       |                }
  228|       |                HandshakeStatus::Handshake => {
  229|      0|                    return ReceiveResult::Continue; // Continue handshake
  230|       |                }
  231|      0|                HandshakeStatus::Realtime(node_id) => {
  232|      0|                    self.node_id = node_id;
  233|      0|                    // Wait until send queue is empty for the handshake to complete
  234|      0|                    return ReceiveResult::Pause;
  235|       |                }
  236|       |                HandshakeStatus::Bootstrap => {
  237|      0|                    debug!(peer = ?self.channel.peer_addr(), "Legacy bootstrap isn't supported. Closing connection");
  238|       |                    // Legacy bootstrap is not supported anymore
  239|      0|                    return ReceiveResult::Abort;
  240|       |                }
  241|       |            }
  242|      0|        } else if self.channel.mode() == ChannelMode::Realtime {
  243|      0|            return self.process_realtime(message);
  244|      0|        }
  245|      0|
  246|      0|        debug_assert!(false);
  247|      0|        ReceiveResult::Abort
  248|      0|    }
  249|       |}
  250|       |
  251|       |impl DataReceiver for NanoDataReceiver {
  252|      0|    fn receive(&mut self, data: &[u8]) -> ReceiveResult {
  253|      0|        self.message_deserializer.push(data);
  254|      0|        while let Some(result) = self.message_deserializer.try_deserialize() {
  255|      0|            let result = match result {
  256|      0|                Ok(msg) => {
  257|      0|                    if self.first_message {
  258|      0|                        // TODO: if version using changes => peer misbehaved!
  259|      0|                        self.channel
  260|      0|                            .set_protocol_version(msg.protocol.version_using);
  261|      0|                        self.first_message = false;
  262|      0|                    }
  263|      0|                    self.process_message(msg.message)
  264|       |                }
  265|       |                Err(ParseMessageError::DuplicatePublishMessage) => {
  266|       |                    // Avoid too much noise about `duplicate_publish_message` errors
  267|      0|                    self.stats.inc_dir(
  268|      0|                        StatType::Filter,
  269|      0|                        DetailType::DuplicatePublishMessage,
  270|      0|                        Direction::In,
  271|      0|                    );
  272|      0|                    ReceiveResult::Continue
  273|       |                }
  274|       |                Err(ParseMessageError::DuplicateConfirmAckMessage) => {
  275|      0|                    self.stats.inc_dir(
  276|      0|                        StatType::Filter,
  277|      0|                        DetailType::DuplicateConfirmAckMessage,
  278|      0|                        Direction::In,
  279|      0|                    );
  280|      0|                    ReceiveResult::Continue
  281|       |                }
  282|       |                Err(ParseMessageError::InsufficientWork) => {
  283|       |                    // IO error or critical error when deserializing message
  284|      0|                    self.stats.inc_dir(
  285|      0|                        StatType::Error,
  286|      0|                        DetailType::InsufficientWork,
  287|      0|                        Direction::In,
  288|      0|                    );
  289|      0|                    ReceiveResult::Continue
  290|       |                }
  291|      0|                Err(e) => {
  292|      0|                    // IO error or critical error when deserializing message
  293|      0|                    self.stats
  294|      0|                        .inc_dir(StatType::Error, DetailType::from(&e), Direction::In);
  295|      0|                    debug!(
  296|      0|                        "Error reading message: {:?} ({})",
  297|      0|                        e,
  298|      0|                        self.channel.peer_addr()
  299|       |                    );
  300|      0|                    ReceiveResult::Abort
  301|       |                }
  302|       |            };
  303|       |
  304|      0|            if !matches!(result, ReceiveResult::Continue) {
  305|      0|                return result;
  306|      0|            }
  307|       |        }
  308|       |
  309|      0|        ReceiveResult::Continue
  310|      0|    }
  311|       |
  312|      0|    fn try_unpause(&self) -> ReceiveResult {
  313|      0|        if self.channel.mode() != ChannelMode::Undefined {
  314|       |            // Pausing is currently only needed during handshake
  315|      0|            return ReceiveResult::Continue;
  316|      0|        }
  317|      0|
  318|      0|        // Wait until all outbound messages are processed.
  319|      0|        // This is needed for the handshake because the channel can't be upgraded to
  320|      0|        // a realtime channel unless the handshake response is actually sent out
  321|      0|        if self.channel.queue_len() > 0 {
  322|      0|            return ReceiveResult::Pause;
  323|      0|        }
  324|      0|
  325|      0|        if !self.to_realtime_connection(&self.node_id) {
  326|      0|            self.stats.inc_dir(
  327|      0|                StatType::TcpServer,
  328|      0|                DetailType::HandshakeError,
  329|      0|                Direction::In,
  330|      0|            );
  331|      0|            debug!(
  332|      0|                "Error switching to realtime mode ({})",
  333|      0|                self.channel.peer_addr()
  334|       |            );
  335|      0|            return ReceiveResult::Abort;
  336|      0|        }
  337|      0|
  338|      0|        ReceiveResult::Continue
  339|      0|    }
  340|       |}
  341|       |
  342|       |impl Drop for NanoDataReceiver {
  343|      0|    fn drop(&mut self) {
  344|      0|        self.channel.close();
  345|      0|    }
  346|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/nano_data_receiver_factory.rs:
    1|       |use super::{
    2|       |    nano_data_receiver::NanoDataReceiver, HandshakeProcess, InboundMessageQueue, LatestKeepalives,
    3|       |    SynCookies,
    4|       |};
    5|       |use crate::{stats::Stats, NetworkParams};
    6|       |use rsnano_core::PrivateKey;
    7|       |use rsnano_messages::*;
    8|       |use rsnano_network::{Channel, DataReceiver, DataReceiverFactory, Network};
    9|       |use std::sync::{Arc, Mutex, RwLock, Weak};
   10|       |
   11|       |pub(crate) struct NanoDataReceiverFactory {
   12|       |    network_params: Arc<NetworkParams>,
   13|       |    stats: Arc<Stats>,
   14|       |    network: Weak<RwLock<Network>>,
   15|       |    inbound_queue: Arc<InboundMessageQueue>,
   16|       |    network_filter: Arc<NetworkFilter>,
   17|       |    syn_cookies: Arc<SynCookies>,
   18|       |    node_id: PrivateKey,
   19|       |    latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   20|       |}
   21|       |
   22|       |impl NanoDataReceiverFactory {
   23|      3|    pub fn new(
   24|      3|        network: &Arc<RwLock<Network>>,
   25|      3|        inbound_queue: Arc<InboundMessageQueue>,
   26|      3|        network_filter: Arc<NetworkFilter>,
   27|      3|        network_params: Arc<NetworkParams>,
   28|      3|        stats: Arc<Stats>,
   29|      3|        syn_cookies: Arc<SynCookies>,
   30|      3|        node_id: PrivateKey,
   31|      3|        latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   32|      3|    ) -> Self {
   33|      3|        Self {
   34|      3|            network: Arc::downgrade(network),
   35|      3|            inbound_queue,
   36|      3|            syn_cookies: syn_cookies.clone(),
   37|      3|            node_id: node_id.clone(),
   38|      3|            network_params,
   39|      3|            stats: stats.clone(),
   40|      3|            network_filter,
   41|      3|            latest_keepalives,
   42|      3|        }
   43|      3|    }
   44|       |}
   45|       |
   46|       |impl DataReceiverFactory for NanoDataReceiverFactory {
   47|      0|    fn create_receiver_for(&self, channel: Arc<Channel>) -> Box<dyn DataReceiver + Send> {
   48|      0|        let handshake_process = HandshakeProcess::new(
   49|      0|            self.network_params.ledger.genesis_block.hash(),
   50|      0|            self.node_id.clone(),
   51|      0|            self.syn_cookies.clone(),
   52|      0|            self.stats.clone(),
   53|      0|            self.network_params.network.protocol_info(),
   54|      0|        );
   55|      0|
   56|      0|        let message_deserializer = MessageDeserializer::new(
   57|      0|            self.network_params.network.protocol_info(),
   58|      0|            self.network_filter.clone(),
   59|      0|            self.network_params.network.work.clone(),
   60|      0|        );
   61|      0|        let mut receiver = NanoDataReceiver::new(
   62|      0|            channel,
   63|      0|            self.network_params.clone(),
   64|      0|            handshake_process,
   65|      0|            message_deserializer,
   66|      0|            self.inbound_queue.clone(),
   67|      0|            self.latest_keepalives.clone(),
   68|      0|            self.stats.clone(),
   69|      0|            self.network.clone(),
   70|      0|        );
   71|      0|
   72|      0|        receiver.ensure_handshake();
   73|      0|
   74|      0|        Box::new(receiver)
   75|      0|    }
   76|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/network_threads.rs:
    1|       |use super::{keepalive::KeepaliveMessageFactory, LatestKeepalives, MessageFlooder, SynCookies};
    2|       |use crate::{
    3|       |    config::NodeFlags,
    4|       |    stats::{DetailType, StatType, Stats},
    5|       |    NetworkParams,
    6|       |};
    7|       |use rsnano_messages::{Keepalive, Message, NetworkFilter};
    8|       |use rsnano_network::{DeadChannelCleanup, Network, PeerConnector, TrafficType};
    9|       |use rsnano_nullable_clock::SteadyClock;
   10|       |use std::{
   11|       |    sync::{Arc, Condvar, Mutex, RwLock},
   12|       |    thread::JoinHandle,
   13|       |    time::Duration,
   14|       |};
   15|       |
   16|       |pub(crate) struct NetworkThreads {
   17|       |    cleanup_thread: Option<JoinHandle<()>>,
   18|       |    keepalive_thread: Option<JoinHandle<()>>,
   19|       |    reachout_thread: Option<JoinHandle<()>>,
   20|       |    stopped: Arc<(Condvar, Mutex<bool>)>,
   21|       |    network: Arc<RwLock<Network>>,
   22|       |    peer_connector: Arc<PeerConnector>,
   23|       |    flags: NodeFlags,
   24|       |    network_params: NetworkParams,
   25|       |    stats: Arc<Stats>,
   26|       |    syn_cookies: Arc<SynCookies>,
   27|       |    network_filter: Arc<NetworkFilter>,
   28|       |    keepalive_factory: Arc<KeepaliveMessageFactory>,
   29|       |    latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   30|       |    dead_channel_cleanup: Option<DeadChannelCleanup>,
   31|       |    message_flooder: MessageFlooder,
   32|       |    clock: Arc<SteadyClock>,
   33|       |}
   34|       |
   35|       |impl NetworkThreads {
   36|      3|    pub fn new(
   37|      3|        network: Arc<RwLock<Network>>,
   38|      3|        peer_connector: Arc<PeerConnector>,
   39|      3|        flags: NodeFlags,
   40|      3|        network_params: NetworkParams,
   41|      3|        stats: Arc<Stats>,
   42|      3|        syn_cookies: Arc<SynCookies>,
   43|      3|        network_filter: Arc<NetworkFilter>,
   44|      3|        keepalive_factory: Arc<KeepaliveMessageFactory>,
   45|      3|        latest_keepalives: Arc<Mutex<LatestKeepalives>>,
   46|      3|        dead_channel_cleanup: DeadChannelCleanup,
   47|      3|        message_flooder: MessageFlooder,
   48|      3|        clock: Arc<SteadyClock>,
   49|      3|    ) -> Self {
   50|      3|        Self {
   51|      3|            cleanup_thread: None,
   52|      3|            keepalive_thread: None,
   53|      3|            reachout_thread: None,
   54|      3|            stopped: Arc::new((Condvar::new(), Mutex::new(false))),
   55|      3|            network,
   56|      3|            peer_connector,
   57|      3|            flags,
   58|      3|            network_params,
   59|      3|            stats,
   60|      3|            syn_cookies,
   61|      3|            network_filter,
   62|      3|            keepalive_factory,
   63|      3|            latest_keepalives,
   64|      3|            dead_channel_cleanup: Some(dead_channel_cleanup),
   65|      3|            message_flooder,
   66|      3|            clock,
   67|      3|        }
   68|      3|    }
   69|       |
   70|      3|    pub fn start(&mut self) {
   71|      3|        let cleanup = CleanupLoop {
   72|      3|            stopped: self.stopped.clone(),
   73|      3|            network_params: self.network_params.clone(),
   74|      3|            flags: self.flags.clone(),
   75|      3|            syn_cookies: self.syn_cookies.clone(),
   76|      3|            network_filter: self.network_filter.clone(),
   77|      3|            dead_channel_cleanup: self.dead_channel_cleanup.take().unwrap(),
   78|      3|        };
   79|      3|
   80|      3|        self.cleanup_thread = Some(
   81|      3|            std::thread::Builder::new()
   82|      3|                .name("Net cleanup".to_string())
   83|      3|                .spawn(move || cleanup.run())
   84|      3|                .unwrap(),
   85|      3|        );
   86|      3|
   87|      3|        let mut keepalive = KeepaliveLoop {
   88|      3|            stopped: self.stopped.clone(),
   89|      3|            network: self.network.clone(),
   90|      3|            keepalive_period: self.network_params.network.keepalive_period,
   91|      3|            stats: Arc::clone(&self.stats),
   92|      3|            keepalive_factory: self.keepalive_factory.clone(),
   93|      3|            message_flooder: self.message_flooder.clone(),
   94|      3|            clock: self.clock.clone(),
   95|      3|        };
   96|      3|
   97|      3|        self.keepalive_thread = Some(
   98|      3|            std::thread::Builder::new()
   99|      3|                .name("Net keepalive".to_string())
  100|      3|                .spawn(move || keepalive.run())
  101|      3|                .unwrap(),
  102|      3|        );
  103|      3|
  104|      3|        if !self.network_params.network.merge_period.is_zero() {
  105|      3|            let reachout = ReachoutLoop {
  106|      3|                stopped: self.stopped.clone(),
  107|      3|                reachout_interval: self.network_params.network.merge_period,
  108|      3|                stats: self.stats.clone(),
  109|      3|                peer_connector: self.peer_connector.clone(),
  110|      3|                latest_keepalives: self.latest_keepalives.clone(),
  111|      3|            };
  112|      3|
  113|      3|            self.reachout_thread = Some(
  114|      3|                std::thread::Builder::new()
  115|      3|                    .name("Net reachout".to_string())
  116|      3|                    .spawn(move || reachout.run())
  117|      3|                    .unwrap(),
  118|      3|            );
  119|      3|        }
                       ^0
  120|      3|    }
  121|      3|    pub fn stop(&mut self) {
  122|      3|        *self.stopped.1.lock().unwrap() = true;
  123|      3|        self.stopped.0.notify_all();
  124|      3|        self.network.write().unwrap().stop();
  125|      3|        if let Some(t) = self.keepalive_thread.take() {
  126|      3|            t.join().unwrap();
  127|      3|        }
                       ^0
  128|      3|        if let Some(t) = self.cleanup_thread.take() {
  129|      3|            t.join().unwrap();
  130|      3|        }
                       ^0
  131|      3|        if let Some(t) = self.reachout_thread.take() {
  132|      3|            t.join().unwrap();
  133|      3|        }
                       ^0
  134|      3|    }
  135|       |}
  136|       |
  137|       |impl Drop for NetworkThreads {
  138|      3|    fn drop(&mut self) {
  139|      3|        // All threads must be stopped before this destructor
  140|      3|        debug_assert!(self.cleanup_thread.is_none());
  141|      3|        debug_assert!(self.keepalive_thread.is_none());
  142|      3|    }
  143|       |}
  144|       |
  145|       |struct CleanupLoop {
  146|       |    stopped: Arc<(Condvar, Mutex<bool>)>,
  147|       |    network_params: NetworkParams,
  148|       |    flags: NodeFlags,
  149|       |    syn_cookies: Arc<SynCookies>,
  150|       |    network_filter: Arc<NetworkFilter>,
  151|       |    dead_channel_cleanup: DeadChannelCleanup,
  152|       |}
  153|       |
  154|       |impl CleanupLoop {
  155|      3|    fn run(&self) {
  156|      3|        let mut stopped = self.stopped.1.lock().unwrap();
  157|      3|        while !*stopped {
  158|      3|            let timeout = if self.network_params.network.is_dev_network() {
  159|      3|                Duration::from_secs(1)
  160|       |            } else {
  161|      0|                Duration::from_secs(5)
  162|       |            };
  163|      3|            stopped = self.stopped.0.wait_timeout(stopped, timeout).unwrap().0;
  164|      3|
  165|      3|            if *stopped {
  166|      3|                return;
  167|      0|            }
  168|      0|            drop(stopped);
  169|      0|
  170|      0|            if !self.flags.disable_connection_cleanup {
  171|      0|                self.dead_channel_cleanup.clean_up();
  172|      0|            }
  173|       |
  174|      0|            self.syn_cookies
  175|      0|                .purge(self.network_params.network.sync_cookie_cutoff);
  176|      0|
  177|      0|            self.network_filter.update(timeout.as_secs());
  178|      0|
  179|      0|            stopped = self.stopped.1.lock().unwrap();
  180|       |        }
  181|      3|    }
  182|       |}
  183|       |
  184|       |struct KeepaliveLoop {
  185|       |    stopped: Arc<(Condvar, Mutex<bool>)>,
  186|       |    stats: Arc<Stats>,
  187|       |    network: Arc<RwLock<Network>>,
  188|       |    keepalive_factory: Arc<KeepaliveMessageFactory>,
  189|       |    message_flooder: MessageFlooder,
  190|       |    clock: Arc<SteadyClock>,
  191|       |    keepalive_period: Duration,
  192|       |}
  193|       |
  194|       |impl KeepaliveLoop {
  195|      3|    fn run(&mut self) {
  196|      3|        let mut stopped = self.stopped.1.lock().unwrap();
  197|      3|        while !*stopped {
  198|      3|            stopped = self
  199|      3|                .stopped
  200|      3|                .0
  201|      3|                .wait_timeout(stopped, self.keepalive_period)
  202|      3|                .unwrap()
  203|      3|                .0;
  204|      3|
  205|      3|            if *stopped {
  206|      3|                return;
  207|      0|            }
  208|      0|            drop(stopped);
  209|      0|
  210|      0|            self.stats.inc(StatType::Network, DetailType::LoopKeepalive);
  211|      0|            self.flood_keepalive(0.75);
  212|      0|            self.flood_keepalive_self(0.25);
  213|      0|
  214|      0|            self.keepalive();
  215|      0|
  216|      0|            stopped = self.stopped.1.lock().unwrap();
  217|       |        }
  218|      3|    }
  219|       |
  220|      0|    fn keepalive(&mut self) {
  221|      0|        let (message, keepalive_list) = {
  222|      0|            let message = self.keepalive_factory.create_keepalive();
  223|      0|
  224|      0|            let network = self.network.read().unwrap();
  225|      0|            let list = network.idle_channels(self.keepalive_period, self.clock.now());
  226|      0|            (message, list)
  227|      0|        };
  228|       |
  229|      0|        for channel_id in keepalive_list {
  230|      0|            self.message_flooder
  231|      0|                .try_send(channel_id, &message, TrafficType::Keepalive);
  232|      0|        }
  233|      0|    }
  234|       |
  235|      0|    fn flood_keepalive(&mut self, scale: f32) {
  236|      0|        let mut keepalive = Keepalive::default();
  237|      0|        self.network
  238|      0|            .read()
  239|      0|            .unwrap()
  240|      0|            .random_fill_realtime(&mut keepalive.peers);
  241|      0|        self.message_flooder.flood(
  242|      0|            &Message::Keepalive(keepalive),
  243|      0|            TrafficType::Keepalive,
  244|      0|            scale,
  245|      0|        );
  246|      0|    }
  247|       |
  248|      0|    fn flood_keepalive_self(&mut self, scale: f32) {
  249|      0|        let keepalive = self.keepalive_factory.create_keepalive_self();
  250|      0|        self.message_flooder
  251|      0|            .flood(&keepalive, TrafficType::Keepalive, scale);
  252|      0|    }
  253|       |}
  254|       |
  255|       |struct ReachoutLoop {
  256|       |    stopped: Arc<(Condvar, Mutex<bool>)>,
  257|       |    reachout_interval: Duration,
  258|       |    stats: Arc<Stats>,
  259|       |    peer_connector: Arc<PeerConnector>,
  260|       |    latest_keepalives: Arc<Mutex<LatestKeepalives>>,
  261|       |}
  262|       |
  263|       |impl ReachoutLoop {
  264|      3|    fn run(&self) {
  265|      3|        let mut stopped = self.stopped.1.lock().unwrap();
  266|      7|        while !*stopped {
  267|      7|            stopped = self
  268|      7|                .stopped
  269|      7|                .0
  270|      7|                .wait_timeout(stopped, self.reachout_interval)
  271|      7|                .unwrap()
  272|      7|                .0;
  273|      7|
  274|      7|            if *stopped {
  275|      3|                return;
  276|      4|            }
  277|      4|            drop(stopped);
  278|      4|
  279|      4|            let keepalive = self.latest_keepalives.lock().unwrap().pop_random();
  280|      4|            if let Some(keepalive) = keepalive {
                                      ^0
  281|      0|                for peer in keepalive.peers {
  282|      0|                    if peer.ip().is_unspecified() {
  283|      0|                        continue;
  284|      0|                    }
  285|      0|                    self.stats.inc(StatType::Network, DetailType::ReachoutLive);
  286|      0|                    self.peer_connector.connect_to(peer);
  287|      0|
  288|      0|                    // Throttle reachout attempts
  289|      0|                    std::thread::sleep(self.reachout_interval);
  290|       |                }
  291|      4|            }
  292|       |
  293|      4|            stopped = self.stopped.1.lock().unwrap();
  294|       |        }
  295|      3|    }
  296|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/peer_cache_connector.rs:
    1|       |use crate::stats::{DetailType, StatType};
    2|       |use crate::{
    3|       |    stats::Stats,
    4|       |    utils::{CancellationToken, Runnable},
    5|       |};
    6|       |use rsnano_ledger::Ledger;
    7|       |use rsnano_network::PeerConnector;
    8|       |use std::{net::SocketAddrV6, sync::Arc, time::Duration};
    9|       |use tracing::info;
   10|       |
   11|       |// Tries to connect to peers that are stored in the peer cache
   12|       |pub struct PeerCacheConnector {
   13|       |    ledger: Arc<Ledger>,
   14|       |    peer_connector: Arc<PeerConnector>,
   15|       |    stats: Arc<Stats>,
   16|       |    first_run: bool,
   17|       |    ///Delay between each connection attempt. This throttles new connections.
   18|       |    reach_out_delay: Duration,
   19|       |}
   20|       |
   21|       |impl PeerCacheConnector {
   22|     11|    pub fn new(
   23|     11|        ledger: Arc<Ledger>,
   24|     11|        peer_connector: Arc<PeerConnector>,
   25|     11|        stats: Arc<Stats>,
   26|     11|        reach_out_delay: Duration,
   27|     11|    ) -> Self {
   28|     11|        Self {
   29|     11|            ledger,
   30|     11|            peer_connector,
   31|     11|            stats,
   32|     11|            first_run: true,
   33|     11|            reach_out_delay,
   34|     11|        }
   35|     11|    }
   36|       |
   37|     12|    fn load_peers_from_cache(&self) -> Vec<SocketAddrV6> {
   38|     12|        let tx = self.ledger.read_txn();
   39|     12|        self.ledger
   40|     12|            .store
   41|     12|            .peer
   42|     12|            .iter(&tx)
   43|     12|            .map(|(peer, _)| peer)
   44|     12|            .collect()
   45|     12|    }
   46|       |}
   47|       |
   48|       |impl Runnable for PeerCacheConnector {
   49|     12|    fn run(&mut self, cancel_token: &CancellationToken) {
   50|     12|        self.stats
   51|     12|            .inc(StatType::Network, DetailType::LoopReachoutCached);
   52|     12|        let cached_peers = self.load_peers_from_cache();
   53|     12|
   54|     12|        if self.first_run {
   55|     11|            info!("Adding cached initial peers: {}", cached_peers.len());
                                ^0
   56|     11|            self.first_run = false;
   57|      1|        }
   58|       |
   59|     22|        for peer in cached_peers {
                          ^11
   60|     11|            self.stats
   61|     11|                .inc(StatType::Network, DetailType::ReachoutCached);
   62|     11|            self.peer_connector.connect_to(peer);
   63|     11|            // Throttle reachout attempts
   64|     11|            if cancel_token.wait_for_cancellation(self.reach_out_delay) {
   65|      1|                break;
   66|     10|            }
   67|       |        }
   68|     12|    }
   69|       |}
   70|       |
   71|       |#[cfg(test)]
   72|       |mod tests {
   73|       |    use super::*;
   74|       |    use crate::stats::Direction;
   75|       |    use rsnano_core::utils::{parse_endpoint, TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3};
   76|       |    use rsnano_output_tracker::OutputTrackerMt;
   77|       |    use std::time::UNIX_EPOCH;
   78|       |    use tracing_test::traced_test;
   79|       |
   80|       |    const REACHOUT_DELAY: Duration = Duration::from_secs(3);
   81|       |
   82|       |    #[tokio::test]
   83|      1|    async fn no_cached_peers() {
   84|      1|        let merged_peers = run_connector([]).await;
   85|      1|        assert_eq!(merged_peers, Vec::new());
   86|      1|    }
   87|       |
   88|       |    #[tokio::test]
   89|      1|    async fn connect_to_cached_peers() {
   90|      1|        let peer1 = parse_endpoint("[::ffff:10.0.0.1]:1234");
   91|      1|        let peer2 = parse_endpoint("[::ffff:10.0.0.2]:1234");
   92|      1|
   93|      1|        let merged_peers = run_connector([peer1, peer2]).await;
   94|      1|
   95|      1|        assert_eq!(merged_peers, [peer1, peer2]);
   96|      1|    }
   97|       |
   98|       |    #[tokio::test]
   99|      0|    #[traced_test]
  100|      1|    async fn log_initial_peers() {
  101|      1|        let peer1 = parse_endpoint("[::ffff:10.0.0.1]:1234");
  102|      1|        let peer2 = parse_endpoint("[::ffff:10.0.0.2]:1234");
  103|      1|
  104|      1|        run_connector([peer1, peer2]).await;
  105|       |
  106|      1|        assert!(logs_contain("Adding cached initial peers: 2"));
  107|      1|    }
  108|       |
  109|       |    #[tokio::test]
  110|      1|    #[traced_test]
  111|      1|    async fn log_initial_peers_only_once() {
  112|      1|        let (mut connector, _, _) = create_test_connector([]).await;
  113|       |
  114|      1|        let cancel = CancellationToken::new_null();
  115|      1|        connector.run(&cancel);
  116|      1|        connector.run(&cancel);
  117|      1|
  118|      1|        logs_assert(|lines| {
  119|      1|            match lines
  120|      1|                .iter()
  121|      1|                .filter(|l| l.contains("Adding cached initial peers"))
  122|      1|                .count()
  123|      1|            {
  124|      1|                1 => Ok(()),
  125|      1|                c => Err(format!("Should only log once, but was {}", c)),
                              ^0
  126|      1|            }
  127|      1|        })
  128|      1|    }
  129|       |
  130|       |    #[tokio::test]
  131|      1|    async fn wait_between_connection_attempts() {
  132|      1|        let (mut connector, _, _) =
  133|      1|            create_test_connector([TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3]).await;
  134|      1|        let cancel_token = CancellationToken::new_null();
  135|      1|        let wait_tracker = cancel_token.track_waits();
  136|      1|
  137|      1|        connector.run(&cancel_token);
  138|      1|
  139|      1|        assert_eq!(wait_tracker.output(), [REACHOUT_DELAY; 3]);
  140|      1|    }
  141|       |
  142|       |    #[tokio::test]
  143|      1|    async fn cancel_during_connection_attempts() {
  144|      1|        let (mut connector, merge_tracker, _) =
  145|      1|            create_test_connector([TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3]).await;
  146|      1|        let cancel_token = CancellationToken::new_null_with_uncancelled_waits(1);
  147|      1|        let wait_tracker = cancel_token.track_waits();
  148|      1|
  149|      1|        connector.run(&cancel_token);
  150|      1|
  151|      1|        assert_eq!(merge_tracker.output(), [TEST_ENDPOINT_1, TEST_ENDPOINT_2]);
  152|      1|        assert_eq!(wait_tracker.output(), [REACHOUT_DELAY; 2]);
  153|      1|    }
  154|       |
  155|       |    #[tokio::test]
  156|      1|    async fn inc_stats_when_run() {
  157|      1|        let (mut connector, _, stats) = create_test_connector([]).await;
  158|      1|        connector.run(&CancellationToken::new_null());
  159|      1|        assert_eq!(
  160|      1|            stats.count(
  161|      1|                StatType::Network,
  162|      1|                DetailType::LoopReachoutCached,
  163|      1|                Direction::In
  164|      1|            ),
  165|      1|            1
  166|      1|        )
  167|      1|    }
  168|       |
  169|       |    #[tokio::test]
  170|      1|    async fn inc_stats_for_each_reachout() {
  171|      1|        let (mut connector, _, stats) =
  172|      1|            create_test_connector([TEST_ENDPOINT_1, TEST_ENDPOINT_2]).await;
  173|      1|        connector.run(&CancellationToken::new_null());
  174|      1|        assert_eq!(
  175|      1|            stats.count(StatType::Network, DetailType::ReachoutCached, Direction::In),
  176|      1|            2
  177|      1|        )
  178|      1|    }
  179|       |
  180|      3|    async fn run_connector(
  181|      3|        cached_peers: impl IntoIterator<Item = SocketAddrV6>,
  182|      3|    ) -> Vec<SocketAddrV6> {
  183|      3|        let (mut connector, merge_tracker, _) = create_test_connector(cached_peers).await;
  184|      3|        connector.run(&CancellationToken::new_null());
  185|      3|        merge_tracker.output()
  186|      3|    }
  187|       |
  188|      8|    async fn create_test_connector(
  189|      8|        cached_peers: impl IntoIterator<Item = SocketAddrV6>,
  190|      8|    ) -> (
  191|      8|        PeerCacheConnector,
  192|      8|        Arc<OutputTrackerMt<SocketAddrV6>>,
  193|      8|        Arc<Stats>,
  194|      8|    ) {
  195|      8|        let ledger = ledger_with_peers(cached_peers);
  196|      8|        let peer_connector = Arc::new(PeerConnector::new_null(tokio::runtime::Handle::current()));
  197|      8|        let merge_tracker = peer_connector.track_connections();
  198|      8|        let stats = Arc::new(Stats::default());
  199|      8|        let connector =
  200|      8|            PeerCacheConnector::new(ledger, peer_connector, stats.clone(), REACHOUT_DELAY);
  201|      8|        (connector, merge_tracker, stats)
  202|      8|    }
  203|       |
  204|      8|    fn ledger_with_peers(cached_peers: impl IntoIterator<Item = SocketAddrV6>) -> Arc<Ledger> {
  205|      8|        Arc::new(
  206|      8|            Ledger::new_null_builder()
  207|     12|                .peers(cached_peers.into_iter().map(|peer| (peer, UNIX_EPOCH)))
  208|      8|                .finish(),
  209|      8|        )
  210|      8|    }
  211|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/peer_cache_updater.rs:
    1|       |use crate::{
    2|       |    stats::{DetailType, StatType, Stats},
    3|       |    utils::{CancellationToken, Runnable},
    4|       |};
    5|       |use rsnano_ledger::Ledger;
    6|       |use rsnano_network::{Channel, Network};
    7|       |use rsnano_nullable_clock::SystemTimeFactory;
    8|       |use rsnano_store_lmdb::LmdbWriteTransaction;
    9|       |use std::{
   10|       |    net::SocketAddrV6,
   11|       |    sync::{Arc, RwLock},
   12|       |    time::Duration,
   13|       |};
   14|       |use tracing::debug;
   15|       |
   16|       |/// Writes a snapshot of the current peers to the database,
   17|       |/// so that we can reconnect to them when the node is restarted
   18|       |pub struct PeerCacheUpdater {
   19|       |    network: Arc<RwLock<Network>>,
   20|       |    ledger: Arc<Ledger>,
   21|       |    time_factory: SystemTimeFactory,
   22|       |    stats: Arc<Stats>,
   23|       |    erase_cutoff: Duration,
   24|       |}
   25|       |
   26|       |impl PeerCacheUpdater {
   27|     14|    pub fn new(
   28|     14|        network: Arc<RwLock<Network>>,
   29|     14|        ledger: Arc<Ledger>,
   30|     14|        time_factory: SystemTimeFactory,
   31|     14|        stats: Arc<Stats>,
   32|     14|        erase_cutoff: Duration,
   33|     14|    ) -> Self {
   34|     14|        Self {
   35|     14|            network,
   36|     14|            ledger,
   37|     14|            time_factory,
   38|     14|            stats,
   39|     14|            erase_cutoff,
   40|     14|        }
   41|     14|    }
   42|       |
   43|     11|    fn save_peers(&self, tx: &mut LmdbWriteTransaction) {
   44|     11|        let live_peers = self.network.read().unwrap().list_realtime_channels(0);
   45|     20|        for peer in &live_peers {
                          ^9
   46|      9|            self.save_peer(tx, peer);
   47|      9|        }
   48|     11|    }
   49|       |
   50|      9|    fn save_peer(&self, tx: &mut LmdbWriteTransaction, channel: &Channel) {
   51|      9|        let Some(endpoint) = channel.peering_addr() else {
   52|      0|            return;
   53|       |        };
   54|      9|        let exists = self.ledger.store.peer.exists(tx, endpoint);
   55|      9|
   56|      9|        self.ledger
   57|      9|            .store
   58|      9|            .peer
   59|      9|            .put(tx, endpoint, self.time_factory.now());
   60|      9|
   61|      9|        if !exists {
   62|      6|            self.stats.inc(StatType::PeerHistory, DetailType::Inserted);
   63|      6|            debug!("Saved new peer: {}", endpoint);
                                 ^0
   64|      3|        } else {
   65|      3|            self.stats.inc(StatType::PeerHistory, DetailType::Updated);
   66|      3|        }
   67|      9|    }
   68|       |
   69|     11|    fn delete_old_peers(&self, tx: &mut LmdbWriteTransaction) {
   70|     11|        for peer in self.get_old_peers(tx) {
                          ^2
   71|      2|            self.ledger.store.peer.del(tx, peer)
   72|       |        }
   73|     11|    }
   74|       |
   75|     11|    fn get_old_peers(&self, tx: &LmdbWriteTransaction) -> Vec<SocketAddrV6> {
   76|     11|        let cutoff = self.time_factory.now() - self.erase_cutoff;
   77|     11|        let now = self.time_factory.now();
   78|     11|        self.ledger
   79|     11|            .store
   80|     11|            .peer
   81|     11|            .iter(tx)
   82|     11|            .filter_map(|(peer, time)| {
   83|      5|                if time < cutoff || time > now {
                                                  ^4
   84|      2|                    Some(peer)
   85|       |                } else {
   86|      3|                    None
   87|       |                }
   88|     11|            })
                          ^5
   89|     11|            .collect()
   90|     11|    }
   91|       |}
   92|       |
   93|       |impl Runnable for PeerCacheUpdater {
   94|     11|    fn run(&mut self, _cancel_token: &CancellationToken) {
   95|     11|        self.stats.inc(StatType::PeerHistory, DetailType::Loop);
   96|     11|        let mut tx = self.ledger.rw_txn();
   97|     11|        self.save_peers(&mut tx);
   98|     11|        self.delete_old_peers(&mut tx);
   99|     11|    }
  100|       |}
  101|       |
  102|       |#[cfg(test)]
  103|       |mod tests {
  104|       |    use super::*;
  105|       |    use crate::stats::Direction;
  106|       |    use rsnano_core::utils::{
  107|       |        new_test_timestamp, NULL_ENDPOINT, TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3,
  108|       |    };
  109|       |    use rsnano_network::{ChannelDirection, ChannelMode};
  110|       |    use rsnano_nullable_clock::Timestamp;
  111|       |    use std::{net::SocketAddrV6, time::SystemTime};
  112|       |    use tracing_test::traced_test;
  113|       |
  114|       |    #[tokio::test]
  115|      1|    async fn no_peers() {
  116|      1|        let open_channels = Vec::new();
  117|      1|        let already_stored = Vec::new();
  118|      1|        let (written, _, _) =
  119|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  120|      1|        assert_eq!(written, Vec::new());
  121|      1|    }
  122|       |
  123|       |    #[tokio::test]
  124|      1|    async fn write_one_peer() {
  125|      1|        let now = new_test_timestamp();
  126|      1|        let endpoint = TEST_ENDPOINT_1;
  127|      1|        let open_channels = vec![endpoint];
  128|      1|        let already_stored = Vec::new();
  129|      1|
  130|      1|        let (written, _, _) = run_peer_history(now, open_channels, already_stored).await;
  131|      1|
  132|      1|        assert_eq!(written, vec![(endpoint, now)]);
  133|      1|    }
  134|       |
  135|       |    #[tokio::test]
  136|      1|    async fn write_multiple_peers() {
  137|      1|        let now = new_test_timestamp();
  138|      1|        let open_channels = vec![TEST_ENDPOINT_1, TEST_ENDPOINT_2, TEST_ENDPOINT_3];
  139|      1|        let already_stored = Vec::new();
  140|      1|
  141|      1|        let (written, deleted, _) = run_peer_history(now, open_channels, already_stored).await;
  142|      1|
  143|      1|        assert_eq!(
  144|      1|            written,
  145|      1|            vec![
  146|      1|                (TEST_ENDPOINT_1, now),
  147|      1|                (TEST_ENDPOINT_2, now),
  148|      1|                (TEST_ENDPOINT_3, now)
  149|      1|            ]
  150|      1|        );
  151|      1|        assert_eq!(deleted, Vec::new());
  152|      1|    }
  153|       |
  154|       |    #[tokio::test]
  155|      1|    async fn update_peer() {
  156|      1|        let endpoint = TEST_ENDPOINT_1;
  157|      1|        let now = new_test_timestamp();
  158|      1|        let open_channels = vec![endpoint];
  159|      1|        let already_stored = vec![(endpoint, now)];
  160|      1|
  161|      1|        let (written, deleted, _) = run_peer_history(now, open_channels, already_stored).await;
  162|      1|
  163|      1|        assert_eq!(written, vec![(endpoint, now)]);
  164|      1|        assert_eq!(deleted, Vec::new());
  165|      1|    }
  166|       |
  167|       |    #[tokio::test]
  168|      0|    #[traced_test]
  169|      1|    async fn log_when_new_peer_saved() {
  170|      1|        let open_channels = vec![TEST_ENDPOINT_1];
  171|      1|        let already_stored = Vec::new();
  172|      1|
  173|      1|        run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  174|       |
  175|      1|        assert!(logs_contain("Saved new peer: [::ffff:10:0:0:1]:1111"));
  176|      1|    }
  177|       |
  178|       |    #[tokio::test]
  179|      1|    #[traced_test]
  180|      1|    async fn dont_log_when_peer_updated() {
  181|      1|        let endpoint = TEST_ENDPOINT_1;
  182|      1|        let now = new_test_timestamp();
  183|      1|        let open_channels = vec![endpoint];
  184|      1|        let already_stored = vec![(endpoint, now)];
  185|      1|
  186|      1|        run_peer_history(now, open_channels, already_stored).await;
  187|       |
  188|      1|        logs_assert(|lines| {
  189|      1|            if lines.iter().any(|l| l.contains("Saved new peer")) {
                                                  ^0
  190|      1|                Err("log was written".to_string())
                              ^0
  191|      1|            } else {
  192|      1|                Ok(())
  193|      1|            }
  194|      1|        });
  195|      1|    }
  196|       |
  197|       |    #[tokio::test]
  198|      1|    async fn inc_stats_when_peer_inserted() {
  199|      1|        let endpoint = TEST_ENDPOINT_1;
  200|      1|        let open_channels = vec![endpoint];
  201|      1|        let already_stored = Vec::new();
  202|      1|
  203|      1|        let (_, _, stats) =
  204|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  205|      1|        assert_eq!(
  206|      1|            stats.count(StatType::PeerHistory, DetailType::Inserted, Direction::In),
  207|      1|            1
  208|      1|        );
  209|      1|        assert_eq!(
  210|      1|            stats.count(StatType::PeerHistory, DetailType::Updated, Direction::In),
  211|      1|            0
  212|      1|        );
  213|      1|    }
  214|       |
  215|       |    #[tokio::test]
  216|      1|    async fn inc_stats_when_peer_updated() {
  217|      1|        let endpoint = TEST_ENDPOINT_1;
  218|      1|        let open_channels = vec![endpoint];
  219|      1|        let already_stored = vec![(endpoint, new_test_timestamp())];
  220|      1|
  221|      1|        let (_, _, stats) =
  222|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  223|      1|        assert_eq!(
  224|      1|            stats.count(StatType::PeerHistory, DetailType::Inserted, Direction::In),
  225|      1|            0
  226|      1|        );
  227|      1|        assert_eq!(
  228|      1|            stats.count(StatType::PeerHistory, DetailType::Updated, Direction::In),
  229|      1|            1
  230|      1|        );
  231|      1|    }
  232|       |
  233|       |    #[tokio::test]
  234|      1|    async fn erase_entries_older_than_cutoff() {
  235|      1|        let open_channels = Vec::new();
  236|      1|        let endpoint = TEST_ENDPOINT_1;
  237|      1|        let now = new_test_timestamp();
  238|      1|        let already_stored = vec![(endpoint, now - Duration::from_secs(60 * 61))];
  239|      1|
  240|      1|        let (written, deleted, _) =
  241|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  242|      1|
  243|      1|        assert_eq!(written, Vec::new());
  244|      1|        assert_eq!(deleted, vec![endpoint]);
  245|      1|    }
  246|       |
  247|       |    #[tokio::test]
  248|      1|    async fn erase_entries_newer_than_now() {
  249|      1|        let open_channels = Vec::new();
  250|      1|        let endpoint = TEST_ENDPOINT_1;
  251|      1|        let now = new_test_timestamp();
  252|      1|        let already_stored = vec![(endpoint, now + Duration::from_secs(60 * 61))];
  253|      1|
  254|      1|        let (written, deleted, _) =
  255|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  256|      1|
  257|      1|        assert_eq!(written, Vec::new());
  258|      1|        assert_eq!(deleted, vec![endpoint]);
  259|      1|    }
  260|       |
  261|       |    #[tokio::test]
  262|      1|    async fn inc_loop_stats() {
  263|      1|        let open_channels = Vec::new();
  264|      1|        let already_stored = Vec::new();
  265|      1|
  266|      1|        let (_, _, stats) =
  267|      1|            run_peer_history(new_test_timestamp(), open_channels, already_stored).await;
  268|      1|
  269|      1|        assert_eq!(
  270|      1|            stats.count(StatType::PeerHistory, DetailType::Loop, Direction::In),
  271|      1|            1
  272|      1|        );
  273|      1|    }
  274|       |
  275|     11|    async fn run_peer_history(
  276|     11|        now: SystemTime,
  277|     11|        open_channels: Vec<SocketAddrV6>,
  278|     11|        already_stored: Vec<(SocketAddrV6, SystemTime)>,
  279|     11|    ) -> (
  280|     11|        Vec<(SocketAddrV6, SystemTime)>,
  281|     11|        Vec<SocketAddrV6>,
  282|     11|        Arc<Stats>,
  283|     11|    ) {
  284|     11|        let mut network = Network::new_test_instance();
  285|     20|        for endpoint in open_channels {
                          ^9
  286|      9|            let (channel, _) = network
  287|      9|                .add(
  288|      9|                    NULL_ENDPOINT,
  289|      9|                    endpoint,
  290|      9|                    ChannelDirection::Outbound,
  291|      9|                    Timestamp::new_test_instance(),
  292|      9|                )
  293|      9|                .unwrap();
  294|      9|            channel.set_mode(ChannelMode::Realtime);
  295|      9|        }
  296|     11|        let ledger = Arc::new(Ledger::new_null_builder().peers(already_stored).finish());
  297|     11|        let time_factory = SystemTimeFactory::new_null_with(now);
  298|     11|        let stats = Arc::new(Stats::default());
  299|     11|        let put_tracker = ledger.store.peer.track_puts();
  300|     11|        let delete_tracker = ledger.store.peer.track_deletions();
  301|     11|        let erase_cutoff = Duration::from_secs(60 * 60);
  302|     11|        let mut peer_history = PeerCacheUpdater::new(
  303|     11|            Arc::new(RwLock::new(network)),
  304|     11|            ledger,
  305|     11|            time_factory,
  306|     11|            Arc::clone(&stats),
  307|     11|            erase_cutoff,
  308|     11|        );
  309|     11|
  310|     11|        peer_history.run(&CancellationToken::new());
  311|     11|
  312|     11|        (put_tracker.output(), delete_tracker.output(), stats)
  313|     11|    }
  314|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/realtime_message_handler.rs:
    1|       |use crate::{
    2|       |    block_processing::{BlockProcessor, BlockSource},
    3|       |    bootstrap::{BootstrapResponder, Bootstrapper},
    4|       |    config::NodeConfig,
    5|       |    consensus::{RequestAggregator, VoteProcessorQueue},
    6|       |    stats::{DetailType, Direction, StatType, Stats},
    7|       |    wallets::Wallets,
    8|       |    Telemetry,
    9|       |};
   10|       |use rsnano_core::VoteSource;
   11|       |use rsnano_messages::{Message, NetworkFilter};
   12|       |use rsnano_network::{Channel, Network};
   13|       |use std::{
   14|       |    net::SocketAddrV6,
   15|       |    sync::{Arc, RwLock},
   16|       |};
   17|       |use tracing::trace;
   18|       |
   19|       |/// Handle realtime messages (as opposed to bootstrap messages)
   20|       |pub struct RealtimeMessageHandler {
   21|       |    stats: Arc<Stats>,
   22|       |    network_filter: Arc<NetworkFilter>,
   23|       |    network: Arc<RwLock<Network>>,
   24|       |    block_processor: Arc<BlockProcessor>,
   25|       |    config: NodeConfig,
   26|       |    wallets: Arc<Wallets>,
   27|       |    request_aggregator: Arc<RequestAggregator>,
   28|       |    vote_processor_queue: Arc<VoteProcessorQueue>,
   29|       |    telemetry: Arc<Telemetry>,
   30|       |    bootstrap_responder: Arc<BootstrapResponder>,
   31|       |    bootstrapper: Arc<Bootstrapper>,
   32|       |}
   33|       |
   34|       |impl RealtimeMessageHandler {
   35|      3|    pub(crate) fn new(
   36|      3|        stats: Arc<Stats>,
   37|      3|        network: Arc<RwLock<Network>>,
   38|      3|        network_filter: Arc<NetworkFilter>,
   39|      3|        block_processor: Arc<BlockProcessor>,
   40|      3|        config: NodeConfig,
   41|      3|        wallets: Arc<Wallets>,
   42|      3|        request_aggregator: Arc<RequestAggregator>,
   43|      3|        vote_processor_queue: Arc<VoteProcessorQueue>,
   44|      3|        telemetry: Arc<Telemetry>,
   45|      3|        bootstrap_responder: Arc<BootstrapResponder>,
   46|      3|        bootstrapper: Arc<Bootstrapper>,
   47|      3|    ) -> Self {
   48|      3|        Self {
   49|      3|            stats,
   50|      3|            network,
   51|      3|            network_filter,
   52|      3|            block_processor,
   53|      3|            config,
   54|      3|            wallets,
   55|      3|            request_aggregator,
   56|      3|            vote_processor_queue,
   57|      3|            telemetry,
   58|      3|            bootstrap_responder,
   59|      3|            bootstrapper,
   60|      3|        }
   61|      3|    }
   62|       |
   63|      0|    pub fn process(&self, message: Message, channel: &Arc<Channel>) {
   64|      0|        self.stats.inc_dir(
   65|      0|            StatType::Message,
   66|      0|            message.message_type().into(),
   67|      0|            Direction::In,
   68|      0|        );
   69|      0|        trace!(?message, "network processed");
   70|       |
   71|      0|        match message {
   72|      0|            Message::Keepalive(keepalive) => {
   73|      0|                // Check for special node port data
   74|      0|                let peer0 = keepalive.peers[0];
   75|      0|                // The first entry is used to inform us of the peering address of the sending node
   76|      0|                if peer0.ip().is_unspecified() && peer0.port() != 0 {
   77|      0|                    let peering_addr =
   78|      0|                        SocketAddrV6::new(*channel.peer_addr().ip(), peer0.port(), 0, 0);
   79|      0|
   80|      0|                    // Remember this for future forwarding to other peers
   81|      0|                    self.network
   82|      0|                        .read()
   83|      0|                        .unwrap()
   84|      0|                        .set_peering_addr(channel.channel_id(), peering_addr);
   85|      0|                }
   86|       |            }
   87|      0|            Message::Publish(publish) => {
   88|       |                // Put blocks that are being initially broadcasted in a separate queue, so that they won't have to compete with rebroadcasted blocks
   89|       |                // Both queues have the same priority and size, so the potential for exploiting this is limited
   90|      0|                let source = if publish.is_originator {
   91|      0|                    BlockSource::LiveOriginator
   92|       |                } else {
   93|      0|                    BlockSource::Live
   94|       |                };
   95|      0|                let added = self
   96|      0|                    .block_processor
   97|      0|                    .add(publish.block, source, channel.channel_id());
   98|      0|                if !added {
   99|      0|                    // The message couldn't be handled. We have to remove it from the duplicate
  100|      0|                    // filter, so that it can be retransmitted and handled later
  101|      0|                    self.network_filter.clear(publish.digest);
  102|      0|                    self.stats
  103|      0|                        .inc_dir(StatType::Drop, DetailType::Publish, Direction::In);
  104|      0|                }
  105|       |            }
  106|      0|            Message::ConfirmReq(req) => {
  107|      0|                // Don't load nodes with disabled voting
  108|      0|                // TODO: This check should be cached somewhere
  109|      0|                if self.config.enable_voting && self.wallets.voting_reps_count() > 0 {
  110|      0|                    self.request_aggregator
  111|      0|                        .request(req.roots_hashes, channel.channel_id());
  112|      0|                }
  113|       |            }
  114|      0|            Message::ConfirmAck(ack) => {
  115|      0|                // Ignore zero account votes
  116|      0|                if ack.vote().voting_account.is_zero() {
  117|      0|                    self.stats.inc_dir(
  118|      0|                        StatType::Drop,
  119|      0|                        DetailType::ConfirmAckZeroAccount,
  120|      0|                        Direction::In,
  121|      0|                    );
  122|      0|                }
  123|       |
  124|      0|                let source = match ack.is_rebroadcasted() {
  125|      0|                    true => VoteSource::Rebroadcast,
  126|      0|                    false => VoteSource::Live,
  127|       |                };
  128|       |
  129|      0|                let added = self.vote_processor_queue.vote(
  130|      0|                    Arc::new(ack.vote().clone()),
  131|      0|                    channel.channel_id(),
  132|      0|                    source,
  133|      0|                );
  134|      0|
  135|      0|                if !added {
  136|      0|                    // The message couldn't be handled. We have to remove it from the duplicate
  137|      0|                    // filter, so that it can be retransmitted and handled later
  138|      0|                    self.network_filter.clear(ack.digest);
  139|      0|                    self.stats
  140|      0|                        .inc_dir(StatType::Drop, DetailType::ConfirmAck, Direction::In);
  141|      0|                }
  142|       |            }
  143|      0|            Message::NodeIdHandshake(_) => {
  144|      0|                self.stats.inc_dir(
  145|      0|                    StatType::Message,
  146|      0|                    DetailType::NodeIdHandshake,
  147|      0|                    Direction::In,
  148|      0|                );
  149|      0|            }
  150|      0|            Message::TelemetryReq => {
  151|      0|                // Ignore telemetry requests as telemetry is being periodically broadcasted since V25+
  152|      0|            }
  153|      0|            Message::TelemetryAck(ack) => self.telemetry.process(&ack, channel),
  154|      0|            Message::AscPullReq(req) => {
  155|      0|                self.bootstrap_responder.enqueue(req, channel.clone());
  156|      0|            }
  157|      0|            Message::AscPullAck(ack) => self.bootstrapper.process(ack, channel.channel_id()),
  158|       |            Message::FrontierReq(_)
  159|       |            | Message::BulkPush
  160|       |            | Message::BulkPull(_)
  161|      0|            | Message::BulkPullAccount(_) => unreachable!(),
  162|       |        }
  163|      0|    }
  164|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/syn_cookies.rs:
    1|       |use std::{
    2|       |    collections::HashMap,
    3|       |    net::{Ipv6Addr, SocketAddrV6},
    4|       |    sync::Mutex,
    5|       |    time::{Duration, Instant},
    6|       |};
    7|       |
    8|       |use anyhow::Result;
    9|       |use rand::Rng;
   10|       |use rsnano_core::{utils::ContainerInfo, Account, Signature};
   11|       |use rsnano_messages::Cookie;
   12|       |
   13|       |/// Node ID cookies for node ID handshakes
   14|       |pub struct SynCookies {
   15|       |    data: Mutex<LockedSynCookies>,
   16|       |    max_cookies_per_ip: usize,
   17|       |}
   18|       |
   19|       |impl SynCookies {
   20|      3|    pub fn new(max_cookies_per_ip: usize) -> Self {
   21|      3|        Self {
   22|      3|            data: Mutex::new(LockedSynCookies {
   23|      3|                cookies: HashMap::new(),
   24|      3|                cookies_per_ip: HashMap::new(),
   25|      3|            }),
   26|      3|            max_cookies_per_ip,
   27|      3|        }
   28|      3|    }
   29|       |
   30|       |    /// Returns `None` if the IP is rate capped on syn cookie requests,
   31|       |    /// or if the endpoint already has a syn cookie query
   32|      0|    pub fn assign(&self, endpoint: &SocketAddrV6) -> Option<Cookie> {
   33|      0|        let ip_addr = endpoint.ip();
   34|      0|        let mut lock = self.data.lock().unwrap();
   35|      0|
   36|      0|        if lock.cookies.contains_key(endpoint) {
   37|      0|            return None;
   38|      0|        }
   39|      0|
   40|      0|        let ip_cookies = lock.cookies_per_ip.entry(*ip_addr).or_default();
   41|      0|        if *ip_cookies < self.max_cookies_per_ip {
   42|      0|            *ip_cookies += 1;
   43|      0|            let cookie = rand::thread_rng().gen::<Cookie>();
   44|      0|            lock.cookies.insert(
   45|      0|                *endpoint,
   46|      0|                SynCookieInfo {
   47|      0|                    cookie,
   48|      0|                    created_at: Instant::now(),
   49|      0|                },
   50|      0|            );
   51|      0|            Some(cookie)
   52|       |        } else {
   53|      0|            None
   54|       |        }
   55|      0|    }
   56|       |
   57|       |    // Returns `false` if invalid, `true` if valid
   58|       |    // Also removes the syn cookie from the store if valid
   59|      0|    pub fn validate(
   60|      0|        &self,
   61|      0|        endpoint: &SocketAddrV6,
   62|      0|        node_id: &Account,
   63|      0|        signature: &Signature,
   64|      0|    ) -> Result<()> {
   65|      0|        let ip_addr = endpoint.ip();
   66|      0|        let mut lock = self.data.lock().unwrap();
   67|      0|        if let Some(info) = lock.cookies.get(endpoint) {
   68|      0|            node_id.as_key().verify(&info.cookie, signature)?;
   69|      0|            lock.cookies.remove(endpoint);
   70|      0|            lock.dec_cookie_count(*ip_addr);
   71|      0|        }
   72|      0|        Ok(())
   73|      0|    }
   74|       |
   75|      0|    pub fn purge(&self, cutoff: Duration) {
   76|      0|        let mut lock = self.data.lock().unwrap();
   77|      0|        let now = Instant::now();
   78|      0|        //todo use drain_filter once it is stabelized
   79|      0|        let mut removed_endpoints = Vec::new();
   80|      0|        for (endpoint, _info) in lock
   81|      0|            .cookies
   82|      0|            .iter()
   83|      0|            .filter(|(_k, v)| v.exceeds_cutoff(cutoff, now))
   84|      0|        {
   85|      0|            removed_endpoints.push(*endpoint);
   86|      0|        }
   87|       |
   88|      0|        for endpoint in &removed_endpoints {
   89|      0|            lock.cookies.remove(endpoint);
   90|      0|            lock.dec_cookie_count(*endpoint.ip());
   91|      0|        }
   92|      0|    }
   93|       |
   94|       |    /// Get cookie associated with endpoint and erases that cookie from this container
   95|      0|    pub fn cookie(&self, endpoint: &SocketAddrV6) -> Option<Cookie> {
   96|      0|        let ip_addr = endpoint.ip();
   97|      0|        let mut lock = self.data.lock().unwrap();
   98|      0|        let info = lock.cookies.remove(endpoint);
   99|      0|        if info.is_some() {
  100|      0|            lock.dec_cookie_count(*ip_addr);
  101|      0|        }
  102|      0|        info.map(|i| i.cookie)
  103|      0|    }
  104|       |
  105|      0|    pub fn cookies_count(&self) -> usize {
  106|      0|        self.data.lock().unwrap().cookies.len()
  107|      0|    }
  108|       |
  109|      0|    pub fn cookies_per_ip_count(&self) -> usize {
  110|      0|        self.data.lock().unwrap().cookies_per_ip.len()
  111|      0|    }
  112|       |
  113|      0|    pub fn cookie_info_size() -> usize {
  114|      0|        std::mem::size_of::<SynCookieInfo>()
  115|      0|    }
  116|       |
  117|      0|    pub fn cookies_per_ip_size() -> usize {
  118|      0|        std::mem::size_of::<usize>()
  119|      0|    }
  120|       |
  121|      0|    pub fn container_info(&self) -> ContainerInfo {
  122|      0|        [
  123|      0|            (
  124|      0|                "syn_cookies",
  125|      0|                self.cookies_count(),
  126|      0|                Self::cookie_info_size(),
  127|      0|            ),
  128|      0|            (
  129|      0|                "syn_cookies_per_ip",
  130|      0|                self.cookies_per_ip_count(),
  131|      0|                Self::cookies_per_ip_size(),
  132|      0|            ),
  133|      0|        ]
  134|      0|        .into()
  135|      0|    }
  136|       |}
  137|       |
  138|       |impl Default for SynCookies {
  139|      0|    fn default() -> Self {
  140|      0|        Self::new(10)
  141|      0|    }
  142|       |}
  143|       |
  144|       |struct LockedSynCookies {
  145|       |    cookies: HashMap<SocketAddrV6, SynCookieInfo>,
  146|       |    cookies_per_ip: HashMap<Ipv6Addr, usize>,
  147|       |}
  148|       |
  149|       |impl LockedSynCookies {
  150|      0|    fn dec_cookie_count(&mut self, ip_addr: Ipv6Addr) {
  151|      0|        let ip_cookies = self.cookies_per_ip.entry(ip_addr).or_default();
  152|      0|        if *ip_cookies > 0 {
  153|      0|            *ip_cookies -= 1;
  154|      0|        } else {
  155|      0|            panic!("More SYN cookies deleted than created for IP");
  156|       |        }
  157|      0|    }
  158|       |}
  159|       |
  160|       |struct SynCookieInfo {
  161|       |    cookie: Cookie,
  162|       |    created_at: Instant,
  163|       |}
  164|       |
  165|       |impl SynCookieInfo {
  166|      0|    fn exceeds_cutoff(&self, cutoff: Duration, now: Instant) -> bool {
  167|      0|        now.duration_since(self.created_at) > cutoff
  168|      0|    }
  169|       |}

/home/gustav/code/nano/rsnano-node/node/src/transport/vec_buffer_reader.rs:
    1|       |use async_trait::async_trait;
    2|       |use rsnano_network::AsyncBufferReader;
    3|       |use std::sync::atomic::{AtomicUsize, Ordering};
    4|       |
    5|       |pub struct VecBufferReader {
    6|       |    buffer: Vec<u8>,
    7|       |    position: AtomicUsize,
    8|       |}
    9|       |
   10|       |impl VecBufferReader {
   11|      3|    pub fn new(buffer: Vec<u8>) -> Self {
   12|      3|        Self {
   13|      3|            buffer,
   14|      3|            position: AtomicUsize::new(0),
   15|      3|        }
   16|      3|    }
   17|       |}
   18|       |
   19|       |#[async_trait]
   20|       |impl AsyncBufferReader for VecBufferReader {
   21|      6|    async fn read(&self, buffer: &mut [u8], count: usize) -> anyhow::Result<()> {
   22|      6|        let pos = self.position.load(Ordering::SeqCst);
   23|      6|        if count > self.buffer.len() - pos {
   24|      2|            bail!("no more data to read");
   25|      4|        }
   26|      4|        buffer[..count].copy_from_slice(&self.buffer[pos..pos + count]);
   27|      4|        self.position.store(pos + count, Ordering::SeqCst);
   28|      4|        Ok(())
   29|     12|    }
   30|       |}
   31|       |
   32|       |#[cfg(test)]
   33|       |mod tests {
   34|       |    use super::*;
   35|       |
   36|       |    #[tokio::test]
   37|      1|    async fn empty_vec() {
   38|      1|        let reader = VecBufferReader::new(Vec::new());
   39|      1|        let mut buffer = vec![0u8; 3];
   40|      1|        let result = reader.read(&mut buffer, 1).await;
   41|      1|        assert!(result.is_err());
   42|      1|    }
   43|       |
   44|       |    #[tokio::test]
   45|      1|    async fn read_one_byte() {
   46|      1|        let reader = VecBufferReader::new(vec![42]);
   47|      1|        let mut buffer = vec![0u8; 1];
   48|      1|        let result = reader.read(&mut buffer, 1).await;
   49|      1|        assert!(result.is_ok());
   50|      1|        assert_eq!(buffer[0], 42);
   51|      1|    }
   52|       |
   53|       |    #[tokio::test]
   54|      1|    async fn multiple_reads() {
   55|      1|        let reader = VecBufferReader::new(vec![1, 2, 3, 4, 5]);
   56|      1|        let mut buffer = vec![0u8; 2];
   57|      1|        reader.read(&mut buffer, 1).await.unwrap();
   58|      1|        assert_eq!(buffer[0], 1);
   59|      1|
   60|      1|        reader.read(&mut buffer, 2).await.unwrap();
   61|      1|        assert_eq!(buffer[0], 2);
   62|      1|        assert_eq!(buffer[1], 3);
   63|      1|
   64|      1|        reader.read(&mut buffer, 2).await.unwrap();
   65|      1|        assert_eq!(buffer[0], 4);
   66|      1|        assert_eq!(buffer[1], 5);
   67|      1|
   68|      1|        assert!(reader.read(&mut buffer, 1).await.is_err());
   69|      1|    }
   70|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/async_runtime.rs:
    1|       |pub struct AsyncRuntime {
    2|       |    pub tokio: tokio::runtime::Runtime,
    3|       |}
    4|       |
    5|       |impl AsyncRuntime {
    6|      0|    pub fn new(tokio: tokio::runtime::Runtime) -> Self {
    7|      0|        Self { tokio }
    8|      0|    }
    9|       |
   10|      0|    pub fn post<F>(&self, action: F)
   11|      0|    where
   12|      0|        F: FnOnce() + Send + 'static,
   13|      0|    {
   14|      0|        self.tokio.spawn_blocking(action);
   15|      0|    }
   16|       |}
   17|       |
   18|       |impl Default for AsyncRuntime {
   19|      0|    fn default() -> Self {
   20|      0|        let tokio = tokio::runtime::Builder::new_multi_thread()
   21|      0|            .thread_name("tokio runtime")
   22|      0|            .enable_all()
   23|      0|            .build()
   24|      0|            .unwrap();
   25|      0|        AsyncRuntime::new(tokio)
   26|      0|    }
   27|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/blake2b.rs:
    1|       |use anyhow::Result;
    2|       |use blake2::{
    3|       |    digest::{Update, VariableOutput},
    4|       |    Blake2bVar,
    5|       |};
    6|       |
    7|       |pub trait Blake2b {
    8|       |    fn init(&mut self, outlen: usize) -> Result<()>;
    9|       |    fn update(&mut self, bytes: &[u8]) -> Result<()>;
   10|       |    fn finalize(&mut self, out: &mut [u8]) -> Result<()>;
   11|       |}
   12|       |
   13|       |#[derive(Default)]
   14|       |pub struct RustBlake2b {
   15|       |    instance: Option<Blake2bVar>,
   16|       |}
   17|       |
   18|       |impl RustBlake2b {
   19|      0|    pub fn new() -> Self {
   20|      0|        Default::default()
   21|      0|    }
   22|       |}
   23|       |
   24|       |impl Blake2b for RustBlake2b {
   25|      0|    fn init(&mut self, outlen: usize) -> Result<()> {
   26|      0|        self.instance = Some(Blake2bVar::new(outlen)?);
   27|      0|        Ok(())
   28|      0|    }
   29|       |
   30|      0|    fn update(&mut self, bytes: &[u8]) -> Result<()> {
   31|      0|        self.instance
   32|      0|            .as_mut()
   33|      0|            .ok_or_else(|| anyhow!("not initialized"))?
   34|      0|            .update(bytes);
   35|      0|        Ok(())
   36|      0|    }
   37|       |
   38|      0|    fn finalize(&mut self, out: &mut [u8]) -> Result<()> {
   39|      0|        let i = self
   40|      0|            .instance
   41|      0|            .take()
   42|      0|            .ok_or_else(|| anyhow!("not initialized"))?;
   43|       |
   44|      0|        if out.len() != i.output_size() {
   45|      0|            return Err(anyhow!("output size does not match"));
   46|      0|        }
   47|      0|
   48|      0|        i.finalize_variable(out)?;
   49|      0|        Ok(())
   50|      0|    }
   51|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/hardened_constants.rs:
    1|       |use once_cell::sync::Lazy;
    2|       |use rand::Rng;
    3|       |use rsnano_core::{Account, PublicKey};
    4|       |
    5|       |pub struct HardenedConstants {
    6|       |    pub not_an_account: Account,
    7|       |    pub not_an_account_key: PublicKey,
    8|       |    pub random_128: u128,
    9|       |}
   10|       |
   11|       |impl HardenedConstants {
   12|      0|    pub fn get() -> &'static HardenedConstants {
   13|      0|        &INSTANCE
   14|      0|    }
   15|       |}
   16|       |
   17|      0|static INSTANCE: Lazy<HardenedConstants> = Lazy::new(|| {
   18|      0|    let mut rng = rand::thread_rng();
   19|      0|    let not_an_account = Account::from_bytes(rng.gen::<[u8; 32]>());
   20|      0|    HardenedConstants {
   21|      0|        not_an_account_key: not_an_account.into(),
   22|      0|        not_an_account,
   23|      0|        random_128: u128::from_ne_bytes(rng.gen::<[u8; 16]>()),
   24|      0|    }
   25|      0|});

/home/gustav/code/nano/rsnano-node/node/src/utils/long_running_transaction_logger.rs:
    1|       |use backtrace::Backtrace;
    2|       |use rsnano_store_lmdb::TransactionTracker;
    3|       |use std::{
    4|       |    collections::HashMap,
    5|       |    sync::Mutex,
    6|       |    time::{Duration, Instant},
    7|       |};
    8|       |use tracing::warn;
    9|       |
   10|       |#[derive(Clone, Debug, PartialEq)]
   11|       |pub struct TxnTrackingConfig {
   12|       |    /** If true, enable tracking for transaction read/writes held open longer than the min time variables */
   13|       |    pub enable: bool,
   14|       |    pub min_read_txn_time_ms: i64,
   15|       |    pub min_write_txn_time_ms: i64,
   16|       |    pub ignore_writes_below_block_processor_max_time: bool,
   17|       |}
   18|       |
   19|       |impl TxnTrackingConfig {
   20|     10|    pub fn new() -> Self {
   21|     10|        Default::default()
   22|     10|    }
   23|       |}
   24|       |
   25|       |impl Default for TxnTrackingConfig {
   26|     11|    fn default() -> Self {
   27|     11|        Self {
   28|     11|            enable: false,
   29|     11|            min_read_txn_time_ms: 5000,
   30|     11|            min_write_txn_time_ms: 500,
   31|     11|            ignore_writes_below_block_processor_max_time: true,
   32|     11|        }
   33|     11|    }
   34|       |}
   35|       |
   36|       |pub struct LongRunningTransactionLogger {
   37|       |    stats: Mutex<HashMap<u64, TxnStats>>,
   38|       |    config: TxnTrackingConfig,
   39|       |    block_processor_batch_max_time: Duration,
   40|       |}
   41|       |
   42|       |impl LongRunningTransactionLogger {
   43|      0|    pub fn new(config: TxnTrackingConfig, block_processor_batch_max_time: Duration) -> Self {
   44|      0|        Self {
   45|      0|            config,
   46|      0|            block_processor_batch_max_time,
   47|      0|            stats: Mutex::new(HashMap::new()),
   48|      0|        }
   49|      0|    }
   50|       |
   51|      0|    pub fn add(&self, txn_id: u64, is_write: bool) {
   52|      0|        let mut stats = self.stats.lock().unwrap();
   53|      0|        stats.insert(
   54|      0|            txn_id,
   55|      0|            TxnStats {
   56|      0|                is_write,
   57|      0|                start: Instant::now(),
   58|      0|                thread_name: std::thread::current().name().map(|s| s.to_owned()),
   59|      0|                stacktrace: Backtrace::new_unresolved(),
   60|      0|            },
   61|      0|        );
   62|      0|    }
   63|       |
   64|      0|    pub fn erase(&self, txn_id: u64, _is_write: bool) {
   65|      0|        let entry = {
   66|      0|            let mut stats = self.stats.lock().unwrap();
   67|      0|            stats.remove(&txn_id)
   68|       |        };
   69|       |
   70|      0|        if let Some(mut entry) = entry {
   71|      0|            self.log_if_held_long_enough(&mut entry);
   72|      0|        }
   73|      0|    }
   74|       |
   75|      0|    fn log_if_held_long_enough(&self, txn: &mut TxnStats) {
   76|      0|        // Only log these transactions if they were held for longer than the min_read_txn_time/min_write_txn_time config values
   77|      0|        let time_open = txn.start.elapsed();
   78|      0|        // Reduce noise in log files by removing any entries from the block processor (if enabled) which are less than the max batch time (+ a few second buffer) because these are expected writes during bootstrapping.
   79|      0|        let is_below_max_time =
   80|      0|            time_open <= (self.block_processor_batch_max_time + Duration::from_secs(3));
   81|      0|        let is_blk_processing_thread = txn.thread_name.as_deref() == Some("Blck processing");
   82|      0|        if self.config.ignore_writes_below_block_processor_max_time
   83|      0|            && is_blk_processing_thread
   84|      0|            && txn.is_write
   85|      0|            && is_below_max_time
   86|       |        {
   87|      0|            return;
   88|      0|        }
   89|      0|
   90|      0|        if (txn.is_write
   91|      0|            && time_open >= Duration::from_millis(self.config.min_write_txn_time_ms as u64))
   92|      0|            || (!txn.is_write
   93|      0|                && time_open >= Duration::from_millis(self.config.min_read_txn_time_ms as u64))
   94|       |        {
   95|      0|            let txn_type = if txn.is_write { "write lock" } else { "read" };
   96|      0|            txn.stacktrace.resolve();
   97|      0|            warn!(
   98|      0|                "{}ms {} held on thread {}\n{:?}",
   99|      0|                time_open.as_millis(),
  100|      0|                txn_type,
  101|      0|                txn.thread_name.as_deref().unwrap_or("unnamed"),
  102|       |                txn.stacktrace
  103|       |            );
  104|      0|        }
  105|      0|    }
  106|       |}
  107|       |
  108|       |#[derive(Clone)]
  109|       |struct TxnStats {
  110|       |    is_write: bool,
  111|       |    thread_name: Option<String>,
  112|       |    start: Instant,
  113|       |    stacktrace: Backtrace,
  114|       |}
  115|       |
  116|       |impl TransactionTracker for LongRunningTransactionLogger {
  117|      0|    fn txn_start(&self, txn_id: u64, is_write: bool) {
  118|      0|        self.add(txn_id, is_write);
  119|      0|    }
  120|       |
  121|      0|    fn txn_end(&self, txn_id: u64, is_write: bool) {
  122|      0|        self.erase(txn_id, is_write);
  123|      0|    }
  124|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/mod.rs:
    1|       |mod async_runtime;
    2|       |mod blake2b;
    3|       |mod hardened_constants;
    4|       |mod long_running_transaction_logger;
    5|       |mod processing_queue;
    6|       |mod thread_pool;
    7|       |mod timer;
    8|       |mod timer_thread;
    9|       |
   10|       |pub use crate::utils::timer::{NullTimer, Timer, TimerStrategy, TimerWrapper};
   11|       |pub use async_runtime::AsyncRuntime;
   12|       |use blake2::{
   13|       |    digest::{Update, VariableOutput},
   14|       |    Blake2bVar,
   15|       |};
   16|       |pub use blake2b::*;
   17|       |pub use hardened_constants::HardenedConstants;
   18|       |pub use long_running_transaction_logger::{LongRunningTransactionLogger, TxnTrackingConfig};
   19|       |pub use processing_queue::*;
   20|       |use std::net::Ipv6Addr;
   21|       |pub use thread_pool::*;
   22|       |pub use timer_thread::*;
   23|       |
   24|       |#[derive(Clone, Copy, Debug, PartialEq, Eq)]
   25|       |pub struct ErrorCode {
   26|       |    pub val: i32,
   27|       |    pub category: u8,
   28|       |}
   29|       |
   30|       |pub mod error_category {
   31|       |    pub const GENERIC: u8 = 0;
   32|       |    pub const SYSTEM: u8 = 1;
   33|       |}
   34|       |
   35|       |impl Default for ErrorCode {
   36|      0|    fn default() -> Self {
   37|      0|        Self {
   38|      0|            val: 0,
   39|      0|            category: error_category::SYSTEM,
   40|      0|        }
   41|      0|    }
   42|       |}
   43|       |
   44|       |impl ErrorCode {
   45|      0|    pub fn new() -> Self {
   46|      0|        Default::default()
   47|      0|    }
   48|       |
   49|      0|    pub fn is_ok(&self) -> bool {
   50|      0|        !self.is_err()
   51|      0|    }
   52|       |
   53|      0|    pub fn is_err(&self) -> bool {
   54|      0|        self.val != 0
   55|      0|    }
   56|       |
   57|      0|    pub fn not_supported() -> Self {
   58|      0|        ErrorCode {
   59|      0|            val: 95,
   60|      0|            category: error_category::GENERIC,
   61|      0|        }
   62|      0|    }
   63|       |
   64|      0|    pub fn no_buffer_space() -> Self {
   65|      0|        ErrorCode {
   66|      0|            val: 105,
   67|      0|            category: error_category::GENERIC,
   68|      0|        }
   69|      0|    }
   70|       |
   71|      0|    pub fn host_unreachable() -> Self {
   72|      0|        ErrorCode {
   73|      0|            val: 113,
   74|      0|            category: error_category::GENERIC,
   75|      0|        }
   76|      0|    }
   77|       |
   78|      0|    pub fn fault() -> Self {
   79|      0|        ErrorCode {
   80|      0|            val: 14,
   81|      0|            category: error_category::GENERIC,
   82|      0|        }
   83|      0|    }
   84|       |}
   85|       |
   86|      0|pub fn ip_address_hash_raw(address: &Ipv6Addr, port: u16) -> u64 {
   87|      0|    let address_bytes = address.octets();
   88|      0|    let mut hasher = Blake2bVar::new(8).unwrap();
   89|      0|    hasher.update(&HardenedConstants::get().random_128.to_be_bytes());
   90|      0|    if port != 0 {
   91|      0|        hasher.update(&port.to_ne_bytes());
   92|      0|    }
   93|      0|    hasher.update(&address_bytes);
   94|      0|    let mut result_bytes = [0; 8];
   95|      0|    hasher.finalize_variable(&mut result_bytes).unwrap();
   96|      0|    u64::from_ne_bytes(result_bytes)
   97|      0|}

/home/gustav/code/nano/rsnano-node/node/src/utils/processing_queue.rs:
    1|       |use std::{
    2|       |    collections::VecDeque,
    3|       |    ops::DerefMut,
    4|       |    sync::{
    5|       |        atomic::{AtomicBool, Ordering},
    6|       |        Arc, Condvar, Mutex, MutexGuard,
    7|       |    },
    8|       |    thread::{self, JoinHandle},
    9|       |};
   10|       |
   11|       |use crate::stats::{DetailType, Direction, StatType, Stats};
   12|       |
   13|       |/**
   14|       | * Queue that processes enqueued elements in (possibly parallel) batches
   15|       | */
   16|       |pub struct ProcessingQueue<T: Send + 'static> {
   17|       |    thread_name: String,
   18|       |    thread_count: usize,
   19|       |    max_queue_size: usize,
   20|       |    threads: Mutex<Vec<JoinHandle<()>>>,
   21|       |    shared_state: Arc<SharedState<T>>,
   22|       |    stats: Arc<Stats>,
   23|       |    stat_type: StatType,
   24|       |}
   25|       |
   26|       |impl<T: Send + 'static> ProcessingQueue<T> {
   27|       |    /**
   28|       |     * @param thread_count Number of processing threads
   29|       |     * @param max_queue_size Max number of items enqueued, items beyond this value will be discarded
   30|       |     * @param max_batch_size Max number of elements processed in single batch, 0 for unlimited (default)
   31|       |     */
   32|     10|    pub fn new(
   33|     10|        stats: Arc<Stats>,
   34|     10|        stat_type: StatType,
   35|     10|        thread_name: String,
   36|     10|        thread_count: usize,
   37|     10|        max_queue_size: usize,
   38|     10|        max_batch_size: usize,
   39|     10|        process_batch: Box<dyn Fn(VecDeque<T>) + Send + Sync>,
   40|     10|    ) -> Self {
   41|     10|        Self {
   42|     10|            thread_name,
   43|     10|            thread_count,
   44|     10|            stats: Arc::clone(&stats),
   45|     10|            stat_type,
   46|     10|            max_queue_size,
   47|     10|            threads: Mutex::new(Vec::with_capacity(thread_count)),
   48|     10|            shared_state: Arc::new(SharedState::new(
   49|     10|                max_batch_size,
   50|     10|                stats,
   51|     10|                stat_type,
   52|     10|                process_batch,
   53|     10|            )),
   54|     10|        }
   55|     10|    }
   56|       |
   57|     10|    pub fn start(&self) {
   58|     10|        let mut threads = self.threads.lock().unwrap();
   59|     10|        for _ in 0..self.thread_count {
   60|     22|            let state = Arc::clone(&self.shared_state);
   61|     22|            threads.push(
   62|     22|                thread::Builder::new()
   63|     22|                    .name(self.thread_name.clone())
   64|     22|                    .spawn(move || state.run())
   65|     22|                    .unwrap(),
   66|     22|            )
   67|       |        }
   68|     10|    }
   69|       |
   70|     17|    pub fn stop(&self) {
   71|     17|        {
   72|     17|            let _guard = self.shared_state.queue.lock().unwrap();
   73|     17|            self.shared_state.stopped.store(true, Ordering::SeqCst);
   74|     17|        }
   75|     17|        self.shared_state.condition.notify_all();
   76|     17|        let threads = {
   77|     17|            let mut t = Vec::new();
   78|     17|            let mut guard = self.threads.lock().unwrap();
   79|     17|            std::mem::swap(guard.deref_mut(), &mut t);
   80|     17|            t
   81|       |        };
   82|     39|        for thread in threads {
                          ^22
   83|     22|            thread.join().unwrap();
   84|     22|        }
   85|     17|    }
   86|       |
   87|       |    /// Queues item for batch processing
   88|     43|    pub fn add(&self, item: T) {
   89|     43|        let mut queue = self.shared_state.queue.lock().unwrap();
   90|     43|        if queue.len() < self.max_queue_size {
   91|     27|            queue.push_back(item);
   92|     27|            drop(queue);
   93|     27|            self.shared_state.condition.notify_one();
   94|     27|            self.stats
   95|     27|                .inc_dir(self.stat_type, DetailType::Queue, Direction::In);
   96|     27|        } else {
   97|     16|            self.stats
   98|     16|                .inc_dir(self.stat_type, DetailType::Overfill, Direction::In);
   99|     16|        }
  100|     43|    }
  101|       |
  102|      2|    pub fn len(&self) -> usize {
  103|      2|        self.shared_state.queue.lock().unwrap().len()
  104|      2|    }
  105|       |}
  106|       |
  107|       |impl<T: Send + 'static> Drop for ProcessingQueue<T> {
  108|     10|    fn drop(&mut self) {
  109|     10|        self.stop()
  110|     10|    }
  111|       |}
  112|       |
  113|       |struct SharedState<T> {
  114|       |    condition: Condvar,
  115|       |    queue: Mutex<VecDeque<T>>,
  116|       |    stopped: AtomicBool,
  117|       |    max_batch_size: usize,
  118|       |    stats: Arc<Stats>,
  119|       |    stat_type: StatType,
  120|       |    process_batch: Box<dyn Fn(VecDeque<T>) + Send + Sync>,
  121|       |}
  122|       |
  123|       |impl<T> SharedState<T> {
  124|     10|    pub fn new(
  125|     10|        max_batch_size: usize,
  126|     10|        stats: Arc<Stats>,
  127|     10|        stat_type: StatType,
  128|     10|        process_batch: Box<dyn Fn(VecDeque<T>) + Send + Sync>,
  129|     10|    ) -> Self {
  130|     10|        Self {
  131|     10|            condition: Condvar::new(),
  132|     10|            queue: Mutex::new(VecDeque::new()),
  133|     10|            stopped: AtomicBool::new(false),
  134|     10|            max_batch_size,
  135|     10|            stats,
  136|     10|            stat_type,
  137|     10|            process_batch,
  138|     10|        }
  139|     10|    }
  140|       |
  141|     22|    fn run(&self) {
  142|     22|        let mut guard = self.queue.lock().unwrap();
  143|     43|        while !self.stopped.load(Ordering::SeqCst) {
  144|     21|            let batch = self.next_batch(guard);
  145|     21|            if !batch.is_empty() {
  146|      6|                self.stats
  147|      6|                    .inc_dir(self.stat_type, DetailType::Batch, Direction::In);
  148|      6|                (self.process_batch)(batch);
  149|     15|            }
  150|     21|            guard = self.queue.lock().unwrap();
  151|       |        }
  152|     22|    }
  153|       |
  154|     21|    fn next_batch<'a>(&self, guard: MutexGuard<'a, VecDeque<T>>) -> VecDeque<T> {
  155|     21|        let mut guard = self
  156|     21|            .condition
  157|     38|            .wait_while(guard, |queue| {
  158|     38|                queue.is_empty() && !self.stopped.load(Ordering::SeqCst)
                                                  ^29
  159|     38|            })
  160|     21|            .unwrap();
  161|     21|
  162|     21|        if self.stopped.load(Ordering::SeqCst) {
  163|     15|            VecDeque::new()
  164|       |        }
  165|       |        // Unlimited batch size or queue smaller than max batch size, return the whole current queue
  166|      6|        else if self.max_batch_size == 0 || guard.len() < self.max_batch_size {
  167|      2|            let mut queue_l = VecDeque::new();
  168|      2|            std::mem::swap(&mut queue_l, &mut guard);
  169|      2|            queue_l
  170|       |        }
  171|       |        // Larger than max batch size, return limited number of elements
  172|       |        else {
  173|      4|            let mut queue_l = VecDeque::with_capacity(self.max_batch_size);
  174|      4|            for _ in 0..self.max_batch_size {
  175|      8|                if let Some(item) = guard.pop_front() {
  176|      8|                    queue_l.push_back(item);
  177|      8|                }
                               ^0
  178|       |            }
  179|       |
  180|      4|            queue_l
  181|       |        }
  182|     21|    }
  183|       |}
  184|       |
  185|       |#[cfg(test)]
  186|       |mod tests {
  187|       |    use super::*;
  188|       |    use std::time::Duration;
  189|       |
  190|       |    #[test]
  191|      1|    fn empty_queue() {
  192|      1|        let fixture = create_fixture();
  193|      1|        assert_eq!(fixture.queue.len(), 0);
  194|      1|    }
  195|       |
  196|       |    #[test]
  197|      1|    fn process_one() {
  198|      1|        let fixture = create_fixture();
  199|      1|        fixture.queue.add(1);
  200|      1|        fixture.wait_until_process_count_is(1);
  201|      1|    }
  202|       |
  203|       |    #[test]
  204|      1|    fn process_many() {
  205|      1|        let fixture = create_fixture();
  206|     11|        for _ in 0..10 {
  207|     10|            fixture.queue.add(1);
  208|     10|        }
  209|      1|        fixture.wait_until_process_count_is(10);
  210|      1|    }
  211|       |
  212|       |    #[test]
  213|      1|    fn max_queue_size() {
  214|      1|        let fixture = create_fixture();
  215|      1|        fixture.queue.stop();
  216|     32|        for _ in 0..2 * MAX_TEST_QUEUE_LEN {
  217|     32|            fixture.queue.add(1);
  218|     32|        }
  219|      1|        assert_eq!(fixture.queue.len(), MAX_TEST_QUEUE_LEN)
  220|      1|    }
  221|       |
  222|       |    struct TestFixture {
  223|       |        processed: Arc<Mutex<usize>>,
  224|       |        condition: Arc<Condvar>,
  225|       |        queue: ProcessingQueue<i32>,
  226|       |    }
  227|       |
  228|       |    impl TestFixture {
  229|      2|        fn wait_until_process_count_is(&self, expected: usize) {
  230|      2|            let guard = self.processed.lock().unwrap();
  231|      2|            if *guard != expected {
  232|      2|                let (guard, result) = self
  233|      2|                    .condition
  234|      2|                    .wait_timeout_while(guard, Duration::from_secs(5), |count| *count == expected)
  235|      2|                    .unwrap();
  236|      2|                assert_eq!(result.timed_out(), false, "timeout! count was {}", *guard);
                                                                    ^0
  237|      0|            }
  238|      2|        }
  239|       |    }
  240|       |
  241|       |    const MAX_TEST_QUEUE_LEN: usize = 16;
  242|       |
  243|      4|    fn create_fixture() -> TestFixture {
  244|      4|        let processed = Arc::new(Mutex::new(0));
  245|      4|        let condition = Arc::new(Condvar::new());
  246|      4|        let processed_clone = Arc::clone(&processed);
  247|      4|        let condition_clone = Arc::clone(&condition);
  248|      4|
  249|      4|        let queue = ProcessingQueue::new(
  250|      4|            Arc::new(Stats::new(Default::default())),
  251|      4|            StatType::BootstrapServer,
  252|      4|            "processing test thread".to_string(),
  253|      4|            4,
  254|      4|            MAX_TEST_QUEUE_LEN,
  255|      4|            2,
  256|      6|            Box::new(move |i| {
  257|      6|                {
  258|      6|                    *processed_clone.lock().unwrap() += i.len();
  259|      6|                }
  260|      6|                condition_clone.notify_all();
  261|      6|            }),
  262|      4|        );
  263|      4|        queue.start();
  264|      4|        TestFixture {
  265|      4|            queue,
  266|      4|            processed,
  267|      4|            condition,
  268|      4|        }
  269|      4|    }
  270|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/thread_pool.rs:
    1|       |use std::{
    2|       |    sync::{Arc, Mutex},
    3|       |    time::Duration,
    4|       |};
    5|       |
    6|       |#[cfg(feature = "output_tracking")]
    7|       |use super::timer::TimerEvent;
    8|       |#[cfg(feature = "output_tracking")]
    9|       |use rsnano_output_tracker::OutputTrackerMt;
   10|       |
   11|       |use super::{NullTimer, Timer, TimerStrategy, TimerWrapper};
   12|       |
   13|       |pub trait ThreadPool: Send + Sync {
   14|       |    fn post(&self, callback: Box<dyn FnOnce() + Send>);
   15|       |    fn post_delayed(&self, delay: Duration, callback: Box<dyn FnOnce() + Send>);
   16|       |    fn stop(&self);
   17|       |    fn num_queued_tasks(&self) -> usize;
   18|       |}
   19|       |
   20|       |pub struct ThreadPoolImpl<T: TimerStrategy + 'static = TimerWrapper> {
   21|       |    data: Arc<Mutex<Option<ThreadPoolData<T>>>>,
   22|       |    stopped: Arc<Mutex<bool>>,
   23|       |}
   24|       |
   25|       |struct ThreadPoolData<T: TimerStrategy> {
   26|       |    pool: threadpool::ThreadPool,
   27|       |    timer: Timer<T>,
   28|       |}
   29|       |
   30|       |impl<T: TimerStrategy> ThreadPoolData<T> {
   31|     12|    fn push_task(&self, callback: Box<dyn FnOnce() + Send>) {
   32|     12|        self.pool.execute(callback);
   33|     12|    }
   34|       |}
   35|       |
   36|       |impl ThreadPoolImpl<TimerWrapper> {
   37|     21|    pub fn create(num_threads: usize, thread_name: impl Into<String>) -> Self {
   38|     21|        Self::new(num_threads, thread_name.into(), Timer::new())
   39|     21|    }
   40|       |
   41|      0|    pub fn new_test_instance() -> Self {
   42|      0|        Self::create(2, "test pool")
   43|      0|    }
   44|       |}
   45|       |
   46|       |impl ThreadPoolImpl<NullTimer> {
   47|      1|    pub fn new_null() -> Self {
   48|      1|        Self::new(1, "nulled thread pool".to_string(), Timer::new_null())
   49|      1|    }
   50|       |}
   51|       |
   52|       |impl<T: TimerStrategy> ThreadPoolImpl<T> {
   53|     24|    pub fn new(num_threads: usize, thread_name: String, timer: Timer<T>) -> Self {
   54|     24|        Self {
   55|     24|            stopped: Arc::new(Mutex::new(false)),
   56|     24|            data: Arc::new(Mutex::new(Some(ThreadPoolData {
   57|     24|                pool: threadpool::Builder::new()
   58|     24|                    .num_threads(num_threads)
   59|     24|                    .thread_name(thread_name)
   60|     24|                    .build(),
   61|     24|                timer,
   62|     24|            }))),
   63|     24|        }
   64|     24|    }
   65|       |
   66|       |    #[cfg(feature = "output_tracking")]
   67|      1|    pub fn track(&self) -> Arc<OutputTrackerMt<TimerEvent>> {
   68|      1|        self.data.lock().unwrap().as_ref().unwrap().timer.track()
   69|      1|    }
   70|       |}
   71|       |
   72|       |impl<T: TimerStrategy + 'static> ThreadPool for ThreadPoolImpl<T> {
   73|      2|    fn post(&self, callback: Box<dyn FnOnce() + Send>) {
   74|      2|        let stopped_guard = self.stopped.lock().unwrap();
   75|      2|        if !*stopped_guard {
   76|      2|            let data_guard = self.data.lock().unwrap();
   77|      2|            drop(stopped_guard);
   78|      2|            if let Some(data) = data_guard.as_ref() {
   79|      2|                data.push_task(callback);
   80|      2|            }
                           ^0
   81|      0|        }
   82|      2|    }
   83|       |
   84|     19|    fn post_delayed(&self, delay: Duration, callback: Box<dyn FnOnce() + Send>) {
   85|     19|        let stopped_guard = self.stopped.lock().unwrap();
   86|     19|        if !*stopped_guard {
   87|     19|            let data_guard = self.data.lock().unwrap();
   88|     19|            drop(stopped_guard);
   89|     19|            let mut option_callback = Some(callback);
   90|     19|            let data_clone = self.data.clone();
   91|     19|            let stopped_clone = self.stopped.clone();
   92|     19|            if let Some(data) = data_guard.as_ref() {
   93|     19|                data.timer.schedule_with_delay(
   94|     19|                    chrono::Duration::from_std(delay).unwrap(),
   95|     19|                    move || {
                                          ^10
   96|     10|                        if let Some(cb) = option_callback.take() {
   97|     10|                            let stopped_guard = stopped_clone.lock().unwrap();
   98|     10|                            if !*stopped_guard {
   99|     10|                                let data_guard = data_clone.lock().unwrap();
  100|     10|                                drop(stopped_guard);
  101|     10|                                if let Some(data) = data_guard.as_ref() {
  102|     10|                                    data.push_task(cb);
  103|     10|                                }
                                               ^0
  104|      0|                            }
  105|      0|                        }
  106|     19|                    },
                                  ^10
  107|     19|                );
  108|     19|            }
                           ^0
  109|      0|        }
  110|     19|    }
  111|       |
  112|     44|    fn stop(&self) {
  113|     44|        let mut stopped_guard = self.stopped.lock().unwrap();
  114|     44|        if !*stopped_guard {
  115|     24|            let mut data_guard = self.data.lock().unwrap();
  116|     24|            *stopped_guard = true;
  117|     24|            drop(stopped_guard);
  118|     24|            if let Some(data) = data_guard.take() {
  119|     24|                drop(data_guard);
  120|     24|                data.pool.join();
  121|     24|            }
                           ^0
  122|     20|        }
  123|     44|    }
  124|       |
  125|      4|    fn num_queued_tasks(&self) -> usize {
  126|      4|        self.data
  127|      4|            .lock()
  128|      4|            .unwrap()
  129|      4|            .as_ref()
  130|      4|            .map(|i| i.pool.queued_count())
  131|      4|            .unwrap_or_default()
  132|      4|    }
  133|       |}
  134|       |
  135|       |impl<T: TimerStrategy + 'static> Drop for ThreadPoolImpl<T> {
  136|     24|    fn drop(&mut self) {
  137|     24|        self.stop()
  138|     24|    }
  139|       |}
  140|       |
  141|       |#[cfg(test)]
  142|       |mod tests {
  143|       |    use super::*;
  144|       |
  145|       |    #[test]
  146|      1|    fn push_task() {
  147|      1|        let (tx, rx) = std::sync::mpsc::channel();
  148|      1|        let pool = ThreadPoolImpl::create(1, "test thread".to_string());
  149|      1|        pool.post(Box::new(move || {
  150|      1|            tx.send("foo").unwrap();
  151|      1|        }));
  152|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  153|      1|        assert_eq!(result, Ok("foo"));
  154|      1|    }
  155|       |
  156|       |    #[test]
  157|      1|    fn add_delayed_task() {
  158|      1|        let timer = Timer::new_null();
  159|      1|        let timer_tracker = timer.track();
  160|      1|        let pool = ThreadPoolImpl::new(1, "test pool".to_string(), timer);
  161|      1|        let (tx, rx) = std::sync::mpsc::channel();
  162|      1|
  163|      1|        pool.post_delayed(
  164|      1|            Duration::from_secs(10),
  165|      1|            Box::new(move || {
  166|      1|                tx.send("foo").unwrap();
  167|      1|            }),
  168|      1|        );
  169|      1|
  170|      1|        let tasks = timer_tracker.output();
  171|      1|        assert_eq!(tasks.len(), 1, "timer not triggered");
                                                 ^0
  172|      1|        assert_eq!(tasks[0].delay, chrono::Duration::seconds(10));
  173|       |
  174|      1|        tasks[0].execute_callback();
  175|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  176|      1|        assert_eq!(result, Ok("foo"));
  177|      1|    }
  178|       |
  179|       |    #[test]
  180|      1|    fn add_multiple_delayed_tasks() {
  181|      1|        let timer = Timer::new_null();
  182|      1|        let timer_tracker = timer.track();
  183|      1|        let pool = ThreadPoolImpl::new(1, "test pool".to_string(), timer);
  184|      1|        let (tx, rx) = std::sync::mpsc::channel();
  185|      1|        let tx2 = tx.clone();
  186|      1|
  187|      1|        pool.post_delayed(
  188|      1|            Duration::from_secs(10),
  189|      1|            Box::new(move || {
  190|      1|                tx.send("foo").unwrap();
  191|      1|            }),
  192|      1|        );
  193|      1|        pool.post_delayed(
  194|      1|            Duration::from_secs(10),
  195|      1|            Box::new(move || {
  196|      1|                tx2.send("bar").unwrap();
  197|      1|            }),
  198|      1|        );
  199|      1|
  200|      1|        let tasks = timer_tracker.output();
  201|      1|        assert_eq!(tasks.len(), 2, "timers not triggered");
                                                 ^0
  202|      1|        tasks[0].execute_callback();
  203|      1|        tasks[1].execute_callback();
  204|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  205|      1|        assert_eq!(result, Ok("foo"));
  206|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  207|      1|        assert_eq!(result, Ok("bar"));
  208|      1|    }
  209|       |
  210|       |    #[test]
  211|      1|    fn can_be_nulled() {
  212|      1|        let pool = ThreadPoolImpl::new_null();
  213|      1|        let (tx, rx) = std::sync::mpsc::channel();
  214|      1|
  215|      1|        let tracker = pool.track();
  216|      1|        pool.post_delayed(
  217|      1|            Duration::from_secs(10),
  218|      1|            Box::new(move || {
  219|      1|                tx.send("foo").unwrap();
  220|      1|            }),
  221|      1|        );
  222|      1|
  223|      1|        let tasks = tracker.output();
  224|      1|        assert_eq!(tasks.len(), 1, "timer not triggered");
                                                 ^0
  225|      1|        assert_eq!(tasks[0].delay, chrono::Duration::seconds(10));
  226|       |
  227|      1|        tasks[0].execute_callback();
  228|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  229|      1|        assert_eq!(result, Ok("foo"));
  230|      1|    }
  231|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/timer.rs:
    1|       |#[cfg(feature = "output_tracking")]
    2|       |use std::sync::{Arc, Mutex};
    3|       |
    4|       |#[cfg(feature = "output_tracking")]
    5|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
    6|       |
    7|       |pub trait TimerStrategy: Send {
    8|       |    fn schedule_with_delay<F>(&self, delay: chrono::Duration, cb: F)
    9|       |    where
   10|       |        F: 'static + FnMut() + Send;
   11|       |}
   12|       |
   13|       |pub struct TimerWrapper(timer::Timer);
   14|       |
   15|       |impl TimerStrategy for TimerWrapper {
   16|     16|    fn schedule_with_delay<F>(&self, delay: chrono::Duration, cb: F)
   17|     16|    where
   18|     16|        F: 'static + FnMut() + Send,
   19|     16|    {
   20|     16|        self.0.schedule_with_delay(delay, cb).ignore();
   21|     16|    }
   22|       |}
   23|       |
   24|       |pub struct NullTimer;
   25|       |impl TimerStrategy for NullTimer {
   26|      5|    fn schedule_with_delay<F>(&self, _delay: chrono::Duration, _cb: F)
   27|      5|    where
   28|      5|        F: 'static + FnMut() + Send,
   29|      5|    {
   30|      5|    }
   31|       |}
   32|       |
   33|       |pub struct Timer<T: TimerStrategy = TimerWrapper> {
   34|       |    timer: T,
   35|       |    #[cfg(feature = "output_tracking")]
   36|       |    listener: OutputListenerMt<TimerEvent>,
   37|       |}
   38|       |
   39|       |#[cfg(feature = "output_tracking")]
   40|       |#[derive(Clone)]
   41|       |pub struct TimerEvent {
   42|       |    callback: Arc<dyn Fn() + Send + Sync>,
   43|       |    pub delay: chrono::Duration,
   44|       |}
   45|       |
   46|       |#[cfg(feature = "output_tracking")]
   47|       |impl TimerEvent {
   48|      5|    pub fn execute_callback(&self) {
   49|      5|        (self.callback)()
   50|      5|    }
   51|       |}
   52|       |
   53|       |impl Timer<NullTimer> {
   54|      4|    pub fn new_null() -> Self {
   55|      4|        Self::new_with(NullTimer {})
   56|      4|    }
   57|       |}
   58|       |
   59|       |impl Timer<TimerWrapper> {
   60|     22|    pub fn new() -> Self {
   61|     22|        Self::new_with(TimerWrapper(timer::Timer::new()))
   62|     22|    }
   63|       |}
   64|       |
   65|       |impl<T: TimerStrategy> Timer<T> {
   66|     26|    fn new_with(t: T) -> Self {
   67|     26|        Self {
   68|     26|            timer: t,
   69|     26|            #[cfg(feature = "output_tracking")]
   70|     26|            listener: OutputListenerMt::new(),
   71|     26|        }
   72|     26|    }
   73|       |
   74|       |    #[cfg(feature = "output_tracking")]
   75|      4|    pub fn track(&self) -> Arc<OutputTrackerMt<TimerEvent>> {
   76|      4|        self.listener.track()
   77|      4|    }
   78|       |
   79|     21|    pub fn schedule_with_delay<F>(&self, delay: chrono::Duration, cb: F)
   80|     21|    where
   81|     21|        F: 'static + FnMut() + Send,
   82|     21|    {
   83|     21|        #[cfg(feature = "output_tracking")]
   84|     21|        let cb = {
   85|     21|            let option_cb = Arc::new(Mutex::new(Some(cb)));
   86|     21|            let arc_cb: Arc<dyn Fn() + Send + Sync> = Arc::new(move || {
   87|     12|                let cb = option_cb.lock().unwrap().take();
   88|     12|                if let Some(mut cb) = cb {
   89|     12|                    cb();
   90|     12|                }
                               ^0
   91|     21|            });
                          ^12
   92|     21|
   93|     21|            self.listener.emit(TimerEvent {
   94|     21|                callback: arc_cb.clone(),
   95|     21|                delay,
   96|     21|            });
   97|      7|            move || arc_cb()
   98|       |        };
   99|       |
  100|     21|        self.timer.schedule_with_delay(delay, cb);
  101|     21|    }
  102|       |}
  103|       |
  104|       |#[cfg(test)]
  105|       |mod tests {
  106|       |    use std::{sync::mpsc::channel, time::Duration};
  107|       |
  108|       |    use super::*;
  109|       |
  110|       |    #[test]
  111|      1|    fn schedule_with_delay() {
  112|      1|        let t = Timer::new();
  113|      1|        let (tx, rx) = channel();
  114|      1|        t.schedule_with_delay(chrono::Duration::microseconds(1), move || {
  115|      1|            tx.send("done").unwrap();
  116|      1|        });
  117|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  118|      1|        assert_eq!(result, Ok("done"));
  119|      1|    }
  120|       |
  121|       |    #[test]
  122|      1|    fn can_be_tracked() {
  123|      1|        let t = Timer::new_null();
  124|      1|        let tracker = t.track();
  125|      1|        let (tx, rx) = channel();
  126|      1|        t.schedule_with_delay(chrono::Duration::seconds(10), move || {
  127|      1|            tx.send("done").unwrap();
  128|      1|        });
  129|      1|        let output = tracker.output();
  130|      1|        assert_eq!(output.len(), 1, "nothing tracked");
                                                  ^0
  131|      1|        assert_eq!(output[0].delay, chrono::Duration::seconds(10), "delay");
                                                                                 ^0
  132|      1|        output[0].execute_callback();
  133|      1|        let result = rx.recv_timeout(Duration::from_millis(300));
  134|      1|        assert_eq!(result, Ok("done"));
  135|      1|    }
  136|       |}

/home/gustav/code/nano/rsnano-node/node/src/utils/timer_thread.rs:
    1|       |use std::{
    2|       |    sync::{
    3|       |        atomic::{AtomicBool, Ordering},
    4|       |        Arc, Condvar, Mutex,
    5|       |    },
    6|       |    thread::JoinHandle,
    7|       |    time::Duration,
    8|       |};
    9|       |
   10|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   11|       |
   12|       |// Runs a task periodically in it's own thread
   13|       |pub struct TimerThread<T: Runnable + 'static> {
   14|       |    thread_name: String,
   15|       |    task: Mutex<Option<T>>,
   16|       |    thread: Mutex<Option<JoinHandle<()>>>,
   17|       |    cancel_token: CancellationToken,
   18|       |    start_listener: OutputListenerMt<TimerStartEvent>,
   19|       |}
   20|       |
   21|       |#[derive(Clone, Debug, PartialEq, Eq)]
   22|       |pub struct TimerStartEvent {
   23|       |    pub thread_name: String,
   24|       |    pub start_type: TimerStartType,
   25|       |    pub interval: Duration,
   26|       |}
   27|       |
   28|       |#[derive(Copy, Clone, Debug, PartialEq, Eq)]
   29|       |pub enum TimerStartType {
   30|       |    Start,
   31|       |    StartDelayed,
   32|       |    RunOnceThenStart,
   33|       |}
   34|       |
   35|       |impl<T: Runnable> TimerThread<T> {
   36|     12|    pub fn new(name: impl Into<String>, task: T) -> Self {
   37|     12|        Self {
   38|     12|            thread_name: name.into(),
   39|     12|            task: Mutex::new(Some(task)),
   40|     12|            thread: Mutex::new(None),
   41|     12|            cancel_token: CancellationToken::new(),
   42|     12|            start_listener: OutputListenerMt::new(),
   43|     12|        }
   44|     12|    }
   45|       |
   46|      2|    pub fn is_running(&self) -> bool {
   47|      2|        self.thread.lock().unwrap().is_some()
   48|      2|    }
   49|       |
   50|      2|    pub fn track_start(&self) -> Arc<OutputTrackerMt<TimerStartEvent>> {
   51|      2|        self.start_listener.track()
   52|      2|    }
   53|       |
   54|       |    /// Start the thread which periodically runs the task
   55|      3|    pub fn start(&self, interval: Duration) {
   56|      3|        self.start_impl(interval, TimerStartType::Start);
   57|      3|    }
   58|       |
   59|       |    /// Starts the thread and waits for the given interval before the first run
   60|      6|    pub fn start_delayed(&self, interval: Duration) {
   61|      6|        self.start_impl(interval, TimerStartType::StartDelayed);
   62|      6|    }
   63|       |
   64|       |    /// Runs the task in the current thread once before the thread is started
   65|      3|    pub fn run_once_then_start(&self, interval: Duration) {
   66|      3|        self.start_impl(interval, TimerStartType::RunOnceThenStart);
   67|      3|    }
   68|       |
   69|     12|    fn start_impl(&self, interval: Duration, start_type: TimerStartType) {
   70|     12|        self.start_listener.emit(TimerStartEvent {
   71|     12|            thread_name: self.thread_name.clone(),
   72|     12|            interval,
   73|     12|            start_type,
   74|     12|        });
   75|     12|
   76|     12|        let mut task = self
   77|     12|            .task
   78|     12|            .lock()
   79|     12|            .unwrap()
   80|     12|            .take()
   81|     12|            .expect("task already taken");
   82|     12|
   83|     12|        let cancel_token = self.cancel_token.clone();
   84|     12|
   85|     12|        if start_type == TimerStartType::RunOnceThenStart {
   86|      3|            task.run(&cancel_token);
   87|      9|        }
   88|       |
   89|     12|        let handle = std::thread::Builder::new()
   90|     12|            .name(self.thread_name.clone())
   91|     12|            .spawn(move || {
   92|     12|                if start_type == TimerStartType::Start {
   93|      3|                    task.run(&cancel_token);
   94|      9|                }
   95|       |
   96|     12|                while !cancel_token.wait_for_cancellation(interval) {
   97|      0|                    task.run(&cancel_token);
   98|      0|                }
   99|     12|            })
  100|     12|            .unwrap();
  101|     12|
  102|     12|        *self.thread.lock().unwrap() = Some(handle);
  103|     12|    }
  104|       |
  105|     24|    pub fn stop(&self) {
  106|     24|        self.cancel_token.cancel();
  107|     24|        let handle = self.thread.lock().unwrap().take();
  108|     24|        if let Some(handle) = handle {
                                  ^12
  109|     12|            handle.join().unwrap();
  110|     12|        }
  111|     24|    }
  112|       |}
  113|       |
  114|       |impl<T: Runnable> Drop for TimerThread<T> {
  115|     12|    fn drop(&mut self) {
  116|     12|        self.stop();
  117|     12|    }
  118|       |}
  119|       |
  120|       |pub trait Runnable: Send {
  121|       |    fn run(&mut self, cancel_token: &CancellationToken);
  122|       |}
  123|       |
  124|       |#[derive(Clone)]
  125|       |pub struct CancellationToken {
  126|       |    strategy: Arc<CancellationTokenStrategy>,
  127|       |    wait_listener: Arc<OutputListenerMt<Duration>>,
  128|       |}
  129|       |
  130|       |impl CancellationToken {
  131|     23|    pub fn new() -> Self {
  132|     23|        Self {
  133|     23|            strategy: Arc::new(CancellationTokenStrategy::Real(CancellationTokenImpl {
  134|     23|                mutex: Mutex::new(()),
  135|     23|                condition: Condvar::new(),
  136|     23|                stopped: AtomicBool::new(false),
  137|     23|            })),
  138|     23|            wait_listener: Arc::new(OutputListenerMt::new()),
  139|     23|        }
  140|     23|    }
  141|       |
  142|      9|    pub fn new_null() -> Self {
  143|      9|        Self::new_null_with_uncancelled_waits(usize::MAX)
  144|      9|    }
  145|       |
  146|     11|    pub fn new_null_with_uncancelled_waits(uncancelled_wait_count: usize) -> Self {
  147|     11|        Self {
  148|     11|            strategy: Arc::new(CancellationTokenStrategy::Nulled(
  149|     11|                CancellationTokenStub::new(uncancelled_wait_count),
  150|     11|            )),
  151|     11|            wait_listener: Arc::new(OutputListenerMt::new()),
  152|     11|        }
  153|     11|    }
  154|       |
  155|     30|    pub fn wait_for_cancellation(&self, timeout: Duration) -> bool {
  156|     30|        self.wait_listener.emit(timeout);
  157|     30|        match &*self.strategy {
  158|     12|            CancellationTokenStrategy::Real(i) => i.wait_for_cancellation(timeout),
  159|     18|            CancellationTokenStrategy::Nulled(i) => i.wait_for_cancellation(),
  160|       |        }
  161|     30|    }
  162|       |
  163|     24|    pub fn cancel(&self) {
  164|     24|        match &*self.strategy {
  165|     24|            CancellationTokenStrategy::Real(i) => i.cancel(),
  166|      0|            CancellationTokenStrategy::Nulled(_) => {}
  167|       |        }
  168|     24|    }
  169|       |
  170|      6|    pub fn is_cancelled(&self) -> bool {
  171|      6|        match &*self.strategy {
  172|      0|            CancellationTokenStrategy::Real(i) => i.is_cancelled(),
  173|      6|            CancellationTokenStrategy::Nulled(i) => i.is_cancelled(),
  174|       |        }
  175|      6|    }
  176|       |
  177|      3|    pub fn track_waits(&self) -> Arc<OutputTrackerMt<Duration>> {
  178|      3|        self.wait_listener.track()
  179|      3|    }
  180|       |}
  181|       |
  182|       |enum CancellationTokenStrategy {
  183|       |    Real(CancellationTokenImpl),
  184|       |    Nulled(CancellationTokenStub),
  185|       |}
  186|       |
  187|       |struct CancellationTokenImpl {
  188|       |    mutex: Mutex<()>,
  189|       |    condition: Condvar,
  190|       |    stopped: AtomicBool,
  191|       |}
  192|       |
  193|       |impl CancellationTokenImpl {
  194|     12|    fn wait_for_cancellation(&self, timeout: Duration) -> bool {
  195|     12|        let guard = self.mutex.lock().unwrap();
  196|     12|        if self.is_cancelled() {
  197|      0|            return true;
  198|     12|        }
  199|     12|
  200|     12|        drop(
  201|     12|            self.condition
  202|     24|                .wait_timeout_while(guard, timeout, |_| !self.is_cancelled())
  203|     12|                .unwrap()
  204|     12|                .0,
  205|     12|        );
  206|     12|
  207|     12|        self.is_cancelled()
  208|     12|    }
  209|       |
  210|     24|    fn cancel(&self) {
  211|     24|        {
  212|     24|            let _guard = self.mutex.lock().unwrap();
  213|     24|            self.stopped.store(true, Ordering::SeqCst);
  214|     24|        }
  215|     24|        self.condition.notify_all();
  216|     24|    }
  217|       |
  218|     48|    fn is_cancelled(&self) -> bool {
  219|     48|        self.stopped.load(Ordering::SeqCst)
  220|     48|    }
  221|       |}
  222|       |
  223|       |struct CancellationTokenStub {
  224|       |    uncancelled_waits: Mutex<usize>,
  225|       |    cancelled: AtomicBool,
  226|       |}
  227|       |
  228|       |impl CancellationTokenStub {
  229|     11|    fn new(uncancelled_waits: usize) -> Self {
  230|     11|        Self {
  231|     11|            cancelled: AtomicBool::new(uncancelled_waits == 0),
  232|     11|            uncancelled_waits: Mutex::new(uncancelled_waits),
  233|     11|        }
  234|     11|    }
  235|       |
  236|     18|    fn wait_for_cancellation(&self) -> bool {
  237|     18|        let mut waits = self.uncancelled_waits.lock().unwrap();
  238|     18|        if *waits > 0 {
  239|     15|            *waits -= 1;
  240|     15|            false
  241|       |        } else {
  242|      3|            self.cancelled.store(true, Ordering::SeqCst);
  243|      3|            true
  244|       |        }
  245|     18|    }
  246|       |
  247|      6|    fn is_cancelled(&self) -> bool {
  248|      6|        self.cancelled.load(Ordering::SeqCst)
  249|      6|    }
  250|       |}
  251|       |
  252|       |#[cfg(test)]
  253|       |mod tests {
  254|       |    use super::*;
  255|       |
  256|       |    #[test]
  257|      1|    fn can_be_nulled() {
  258|      1|        let token = CancellationToken::new_null();
  259|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), false);
  260|      1|        assert_eq!(token.is_cancelled(), false);
  261|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), false);
  262|      1|        assert_eq!(token.is_cancelled(), false);
  263|      1|    }
  264|       |
  265|       |    #[test]
  266|      1|    fn nulled_cancellation_token_returns_configured_responses() {
  267|      1|        let token = CancellationToken::new_null_with_uncancelled_waits(2);
  268|      1|
  269|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), false);
  270|      1|        assert_eq!(token.is_cancelled(), false);
  271|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), false);
  272|      1|        assert_eq!(token.is_cancelled(), false);
  273|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), true);
  274|      1|        assert_eq!(token.is_cancelled(), true);
  275|      1|        assert_eq!(token.wait_for_cancellation(Duration::MAX), true);
  276|      1|        assert_eq!(token.is_cancelled(), true);
  277|      1|    }
  278|       |
  279|       |    #[test]
  280|      1|    fn can_track_waits() {
  281|      1|        let token = CancellationToken::new_null();
  282|      1|        let wait_tracker = token.track_waits();
  283|      1|        let duration = Duration::from_secs(123);
  284|      1|
  285|      1|        token.wait_for_cancellation(duration);
  286|      1|
  287|      1|        assert_eq!(wait_tracker.output(), [duration]);
  288|      1|    }
  289|       |}

/home/gustav/code/nano/rsnano-node/node/src/wallets/receivable_search.rs:
    1|       |use super::{Wallets, WalletsExt};
    2|       |use crate::utils::ThreadPool;
    3|       |use std::{sync::Arc, time::Duration};
    4|       |
    5|       |pub(crate) struct ReceivableSearch {
    6|       |    pub wallets: Arc<Wallets>,
    7|       |    pub workers: Arc<dyn ThreadPool>,
    8|       |    pub interval: Duration,
    9|       |}
   10|       |
   11|       |impl ReceivableSearch {
   12|      3|    pub fn start(&self) {
   13|      3|        search_receivables(
   14|      3|            self.wallets.clone(),
   15|      3|            self.workers.clone(),
   16|      3|            self.interval.clone(),
   17|      3|        );
   18|      3|    }
   19|       |}
   20|       |
   21|      3|fn search_receivables(wallets: Arc<Wallets>, workers: Arc<dyn ThreadPool>, interval: Duration) {
   22|      3|    // Reload wallets from disk
   23|      3|    wallets.reload();
   24|      3|    // Search pending
   25|      3|    wallets.search_receivable_all();
   26|      3|
   27|      3|    let wallets_w = Arc::downgrade(&wallets);
   28|      3|    let workers_w = Arc::downgrade(&workers);
   29|      3|
   30|      3|    workers.post_delayed(
   31|      3|        interval,
   32|      3|        Box::new(move || {
                                       ^0
   33|      0|            let Some(wallets) = wallets_w.upgrade() else {
   34|      0|                return;
   35|       |            };
   36|      0|            let Some(workers) = workers_w.upgrade() else {
   37|      0|                return;
   38|       |            };
   39|      0|            search_receivables(wallets, workers, interval);
   40|      3|        }),
                      ^0
   41|      3|    )
   42|      3|}

/home/gustav/code/nano/rsnano-node/node/src/wallets/wallet.rs:
    1|       |use anyhow::Context;
    2|       |use rsnano_core::{work::WorkThresholds, KeyDerivationFunction, PrivateKey, PublicKey, Root};
    3|       |use rsnano_ledger::Ledger;
    4|       |use rsnano_store_lmdb::{LmdbWalletStore, LmdbWriteTransaction, Transaction};
    5|       |use std::{
    6|       |    collections::HashSet,
    7|       |    path::Path,
    8|       |    sync::{Arc, Mutex},
    9|       |};
   10|       |use tracing::warn;
   11|       |
   12|       |pub struct Wallet {
   13|       |    pub representatives: Mutex<HashSet<PublicKey>>,
   14|       |    pub store: Arc<LmdbWalletStore>,
   15|       |    ledger: Arc<Ledger>,
   16|       |    work_thresholds: WorkThresholds,
   17|       |}
   18|       |
   19|       |impl Wallet {
   20|      0|    pub fn new(
   21|      0|        ledger: Arc<Ledger>,
   22|      0|        work_thresholds: WorkThresholds,
   23|      0|        txn: &mut LmdbWriteTransaction,
   24|      0|        fanout: usize,
   25|      0|        kdf: KeyDerivationFunction,
   26|      0|        representative: PublicKey,
   27|      0|        wallet_path: &Path,
   28|      0|    ) -> anyhow::Result<Self> {
   29|      0|        let store = LmdbWalletStore::new(fanout, kdf, txn, &representative, &wallet_path)
   30|      0|            .context("could not create wallet store")?;
   31|       |
   32|      0|        Ok(Self {
   33|      0|            representatives: Mutex::new(HashSet::new()),
   34|      0|            store: Arc::new(store),
   35|      0|            ledger,
   36|      0|            work_thresholds,
   37|      0|        })
   38|      0|    }
   39|       |
   40|      0|    pub fn new_from_json(
   41|      0|        ledger: Arc<Ledger>,
   42|      0|        work_thresholds: WorkThresholds,
   43|      0|        txn: &mut LmdbWriteTransaction,
   44|      0|        fanout: usize,
   45|      0|        kdf: KeyDerivationFunction,
   46|      0|        wallet_path: &Path,
   47|      0|        json: &str,
   48|      0|    ) -> anyhow::Result<Self> {
   49|      0|        let store = LmdbWalletStore::new_from_json(fanout, kdf, txn, &wallet_path, json)
   50|      0|            .context("could not create wallet store")?;
   51|       |
   52|      0|        Ok(Self {
   53|      0|            representatives: Mutex::new(HashSet::new()),
   54|      0|            store: Arc::new(store),
   55|      0|            ledger,
   56|      0|            work_thresholds,
   57|      0|        })
   58|      0|    }
   59|       |
   60|      0|    pub fn work_update(
   61|      0|        &self,
   62|      0|        txn: &mut LmdbWriteTransaction,
   63|      0|        pub_key: &PublicKey,
   64|      0|        root: &Root,
   65|      0|        work: u64,
   66|      0|    ) {
   67|      0|        debug_assert!(self.work_thresholds.validate_entry(root, work));
   68|      0|        debug_assert!(self.store.exists(txn, pub_key));
   69|      0|        let block_txn = self.ledger.read_txn();
   70|      0|        let latest = self.ledger.latest_root(&block_txn, &pub_key.into());
   71|      0|        if latest == *root {
   72|      0|            self.store.work_put(txn, pub_key, work);
   73|      0|        } else {
   74|      0|            warn!("Cached work no longer valid, discarding");
   75|       |        }
   76|      0|    }
   77|       |
   78|      0|    pub fn deterministic_check(&self, txn: &dyn Transaction, index: u32) -> u32 {
   79|      0|        let mut result = index;
   80|      0|        let block_txn = self.ledger.read_txn();
   81|      0|        let mut i = index + 1;
   82|      0|        let mut n = index + 64;
   83|      0|        while i < n {
   84|      0|            let prv = self.store.deterministic_key(txn, i);
   85|      0|            let pair = PrivateKey::from_bytes(prv.as_bytes());
   86|      0|            // Check if account received at least 1 block
   87|      0|            let latest = self.ledger.any().account_head(&block_txn, &pair.account());
   88|      0|            match latest {
   89|      0|                Some(_) => {
   90|      0|                    result = i;
   91|      0|                    // i + 64 - Check additional 64 accounts
   92|      0|                    // i/64 - Check additional accounts for large wallets. I.e. 64000/64 = 1000 accounts to check
   93|      0|                    n = i + 64 + (i / 64);
   94|      0|                }
   95|       |                None => {
   96|       |                    // Check if there are pending blocks for account
   97|      0|                    if self
   98|      0|                        .ledger
   99|      0|                        .any()
  100|      0|                        .receivable_exists(&block_txn, pair.account())
  101|      0|                    {
  102|      0|                        result = i;
  103|      0|                        n = i + 64 + (i / 64);
  104|      0|                    }
  105|       |                }
  106|       |            }
  107|       |
  108|      0|            i += 1;
  109|       |        }
  110|      0|        result
  111|      0|    }
  112|       |
  113|      0|    pub fn live(&self) -> bool {
  114|      0|        self.store.is_open()
  115|      0|    }
  116|       |}

/home/gustav/code/nano/rsnano-node/node/src/wallets/wallet_action_thread.rs:
    1|       |use super::Wallet;
    2|       |use rsnano_core::Amount;
    3|       |use std::{
    4|       |    collections::BTreeMap,
    5|       |    sync::{
    6|       |        atomic::{AtomicBool, Ordering},
    7|       |        Arc, Condvar, Mutex, MutexGuard,
    8|       |    },
    9|       |    thread::JoinHandle,
   10|       |};
   11|       |
   12|       |pub struct WalletActionThread {
   13|       |    action_loop: Arc<WalletActionLoop>,
   14|       |    join_handle: Mutex<Option<JoinHandle<()>>>,
   15|       |}
   16|       |
   17|       |impl Drop for WalletActionThread {
   18|      3|    fn drop(&mut self) {
   19|      3|        assert!(
   20|      3|            self.join_handle.lock().unwrap().is_none(),
   21|      0|            "wallet action thread wasn't stopped"
   22|       |        );
   23|      3|    }
   24|       |}
   25|       |
   26|       |impl WalletActionThread {
   27|      3|    pub fn new() -> Self {
   28|      3|        Self {
   29|      3|            action_loop: Arc::new(WalletActionLoop::new()),
   30|      3|            join_handle: Mutex::new(None),
   31|      3|        }
   32|      3|    }
   33|       |
   34|      3|    pub fn start(&self) {
   35|      3|        let loop_clone = Arc::clone(&self.action_loop);
   36|      3|        let mut guard = self.join_handle.lock().unwrap();
   37|      3|        assert!(guard.is_none(), "wallet action thread already running");
                                               ^0
   38|      3|        *guard = Some(
   39|      3|            std::thread::Builder::new()
   40|      3|                .name("Wallet actions".to_string())
   41|      3|                .spawn(move || {
   42|      3|                    loop_clone.do_wallet_actions();
   43|      3|                })
   44|      3|                .unwrap(),
   45|      3|        );
   46|      3|    }
   47|       |
   48|      6|    pub fn stop(&self) {
   49|      6|        self.action_loop.stop();
   50|      6|        let join_handle = self.join_handle.lock().unwrap().take();
   51|      6|        if let Some(join_handle) = join_handle {
                                  ^3
   52|      3|            join_handle.join().unwrap();
   53|      3|        }
   54|      6|    }
   55|       |
   56|      0|    pub fn queue_wallet_action(
   57|      0|        &self,
   58|      0|        amount: Amount,
   59|      0|        wallet: Arc<Wallet>,
   60|      0|        action: Box<dyn Fn(Arc<Wallet>) + Send>,
   61|      0|    ) {
   62|      0|        self.action_loop.queue_wallet_action(amount, wallet, action);
   63|      0|    }
   64|       |
   65|      0|    pub fn len(&self) -> usize {
   66|      0|        self.action_loop.len()
   67|      0|    }
   68|       |
   69|      0|    pub fn set_observer(&self, observer: Box<dyn Fn(bool) + Send>) {
   70|      0|        self.action_loop.set_observer(observer);
   71|      0|    }
   72|       |
   73|      0|    pub fn lock_safe(
   74|      0|        &self,
   75|      0|    ) -> MutexGuard<BTreeMap<Amount, Vec<(Arc<Wallet>, Box<dyn Fn(Arc<Wallet>) + Send>)>>> {
   76|      0|        self.action_loop.mutex.lock().unwrap()
   77|      0|    }
   78|       |
   79|      0|    pub unsafe fn lock(
   80|      0|        &self,
   81|      0|    ) -> MutexGuard<'static, BTreeMap<Amount, Vec<(Arc<Wallet>, Box<dyn Fn(Arc<Wallet>) + Send>)>>>
   82|      0|    {
   83|      0|        let guard = self.action_loop.mutex.lock().unwrap();
   84|      0|        std::mem::transmute::<
   85|      0|            MutexGuard<BTreeMap<Amount, Vec<(Arc<Wallet>, Box<dyn Fn(Arc<Wallet>) + Send>)>>>,
   86|      0|            MutexGuard<
   87|      0|                'static,
   88|      0|                BTreeMap<Amount, Vec<(Arc<Wallet>, Box<dyn Fn(Arc<Wallet>) + Send>)>>,
   89|      0|            >,
   90|      0|        >(guard)
   91|      0|    }
   92|       |}
   93|       |
   94|       |struct WalletActionLoop {
   95|       |    mutex: Mutex<BTreeMap<Amount, Vec<(Arc<Wallet>, Box<dyn Fn(Arc<Wallet>) + Send>)>>>,
   96|       |    stopped: AtomicBool,
   97|       |    condition: Condvar,
   98|       |    observer: Mutex<Box<dyn Fn(bool) + Send>>,
   99|       |}
  100|       |
  101|       |impl WalletActionLoop {
  102|      3|    fn new() -> Self {
  103|      3|        Self {
  104|      3|            mutex: Mutex::new(BTreeMap::new()),
  105|      3|            stopped: AtomicBool::new(false),
  106|      3|            condition: Condvar::new(),
  107|      3|            observer: Mutex::new(Box::new(|_| {})),
                                                            ^0
  108|      3|        }
  109|      3|    }
  110|       |
  111|      6|    fn stop(&self) {
  112|      6|        {
  113|      6|            let mut guard = self.mutex.lock().unwrap();
  114|      6|            self.stopped.store(true, Ordering::SeqCst);
  115|      6|            guard.clear();
  116|      6|        }
  117|      6|        self.condition.notify_all();
  118|      6|    }
  119|       |
  120|      0|    fn queue_wallet_action(
  121|      0|        &self,
  122|      0|        amount: Amount,
  123|      0|        wallet: Arc<Wallet>,
  124|      0|        action: Box<dyn Fn(Arc<Wallet>) + Send>,
  125|      0|    ) {
  126|      0|        {
  127|      0|            let mut guard = self.mutex.lock().unwrap();
  128|      0|            guard.entry(amount).or_default().push((wallet, action));
  129|      0|        }
  130|      0|        self.condition.notify_all();
  131|      0|    }
  132|       |
  133|      0|    fn len(&self) -> usize {
  134|      0|        self.mutex.lock().unwrap().len()
  135|      0|    }
  136|       |
  137|      0|    fn set_observer(&self, observer: Box<dyn Fn(bool) + Send>) {
  138|      0|        *self.observer.lock().unwrap() = observer;
  139|      0|    }
  140|       |
  141|      3|    fn do_wallet_actions(&self) {
  142|      3|        let mut guard = self.mutex.lock().unwrap();
  143|      6|        while !self.stopped.load(Ordering::SeqCst) {
  144|      3|            if let Some((_, wallets)) = guard.pop_first() {
                                          ^0
  145|      0|                for (wallet, action) in wallets {
  146|      0|                    if self.stopped.load(Ordering::SeqCst) {
  147|      0|                        break;
  148|      0|                    }
  149|      0|
  150|      0|                    if wallet.live() {
  151|      0|                        drop(guard);
  152|      0|                        (self.observer.lock().unwrap())(true);
  153|      0|                        action(wallet);
  154|      0|                        (self.observer.lock().unwrap())(false);
  155|      0|                        guard = self.mutex.lock().unwrap();
  156|      0|                    }
  157|       |                }
  158|      3|            } else {
  159|      3|                guard = self.condition.wait(guard).unwrap();
  160|      3|            }
  161|       |        }
  162|      3|    }
  163|       |}

/home/gustav/code/nano/rsnano-node/node/src/wallets/wallet_backup.rs:
    1|       |use super::Wallets;
    2|       |use crate::utils::ThreadPool;
    3|       |use std::{path::PathBuf, sync::Arc, time::Duration};
    4|       |use tracing::error;
    5|       |
    6|       |pub(crate) struct WalletBackup {
    7|       |    pub data_path: PathBuf,
    8|       |    pub backup_interval: Duration,
    9|       |    pub workers: Arc<dyn ThreadPool>,
   10|       |    pub wallets: Arc<Wallets>,
   11|       |}
   12|       |
   13|       |impl WalletBackup {
   14|      3|    pub fn start(&self) {
   15|      3|        let mut backup_path = self.data_path.clone();
   16|      3|        backup_path.push("backup");
   17|      3|        ongoing_backup(
   18|      3|            backup_path,
   19|      3|            self.backup_interval.clone(),
   20|      3|            self.workers.clone(),
   21|      3|            self.wallets.clone(),
   22|      3|        );
   23|      3|    }
   24|       |}
   25|       |
   26|      3|fn ongoing_backup(
   27|      3|    backup_path: PathBuf,
   28|      3|    backup_interval: Duration,
   29|      3|    workers: Arc<dyn ThreadPool>,
   30|      3|    wallets: Arc<Wallets>,
   31|      3|) {
   32|      3|    if let Err(e) = wallets.backup(&backup_path) {
                             ^0
   33|      0|        error!(error = ?e, "Could not create backup of wallets");
   34|      3|    }
   35|       |
   36|      3|    let workers_w = Arc::downgrade(&workers);
   37|      3|    let wallets_w = Arc::downgrade(&wallets);
   38|      3|
   39|      3|    workers.post_delayed(
   40|      3|        backup_interval,
   41|      3|        Box::new(move || {
                                       ^0
   42|      0|            let Some(workers) = workers_w.upgrade() else {
   43|      0|                return;
   44|       |            };
   45|      0|            let Some(wallets) = wallets_w.upgrade() else {
   46|      0|                return;
   47|       |            };
   48|      0|            ongoing_backup(backup_path, backup_interval, workers, wallets);
   49|      3|        }),
                      ^0
   50|      3|    )
   51|      3|}

/home/gustav/code/nano/rsnano-node/node/src/wallets/wallet_representatives.rs:
    1|       |use std::{collections::HashSet, sync::Arc};
    2|       |
    3|       |use rsnano_core::{Account, Amount, PublicKey};
    4|       |use rsnano_ledger::Ledger;
    5|       |
    6|       |pub struct WalletRepresentatives {
    7|       |    /// has representatives with at least 50% of principal representative requirements
    8|       |    half_principal: bool,
    9|       |    /// Number of representatives with at least the configured minimum voting weight
   10|       |    voting: u64,
   11|       |    /// Representatives with at least the configured minimum voting weight
   12|       |    accounts: HashSet<Account>,
   13|       |    vote_minimum: Amount,
   14|       |    ledger: Arc<Ledger>,
   15|       |}
   16|       |
   17|       |impl WalletRepresentatives {
   18|      3|    pub fn new(vote_minimum: Amount, ledger: Arc<Ledger>) -> Self {
   19|      3|        Self {
   20|      3|            half_principal: false,
   21|      3|            voting: 0,
   22|      3|            accounts: HashSet::new(),
   23|      3|            vote_minimum,
   24|      3|            ledger,
   25|      3|        }
   26|      3|    }
   27|      0|    pub fn have_half_rep(&self) -> bool {
   28|      0|        self.half_principal
   29|      0|    }
   30|       |
   31|      6|    pub fn voting_reps(&self) -> u64 {
   32|      6|        self.voting
   33|      6|    }
   34|       |
   35|      0|    pub fn exists(&self, rep: &Account) -> bool {
   36|      0|        self.accounts.contains(rep)
   37|      0|    }
   38|       |
   39|      9|    pub fn clear(&mut self) {
   40|      9|        self.voting = 0;
   41|      9|        self.half_principal = false;
   42|      9|        self.accounts.clear();
   43|      9|    }
   44|       |
   45|      0|    pub fn check_rep(&mut self, pub_key: PublicKey, half_principal_weight: Amount) -> bool {
   46|      0|        let weight = self.ledger.weight(&pub_key);
   47|      0|
   48|      0|        if weight < self.vote_minimum {
   49|      0|            return false; // account not a representative
   50|      0|        }
   51|      0|
   52|      0|        if weight >= half_principal_weight {
   53|      0|            self.half_principal = true;
   54|      0|        }
   55|       |
   56|      0|        if !self.accounts.insert(pub_key.into()) {
   57|      0|            return false; // account already exists
   58|      0|        }
   59|      0|
   60|      0|        self.voting += 1;
   61|      0|        true
   62|      0|    }
   63|       |}

/home/gustav/code/nano/rsnano-node/node/src/wallets/wallets.rs:
    1|       |use super::{Wallet, WalletActionThread, WalletRepresentatives};
    2|       |use crate::{
    3|       |    block_processing::{BlockProcessor, BlockSource},
    4|       |    cementation::{ConfirmingSet, ConfirmingSetConfig},
    5|       |    config::{NetworkConstants, NodeConfig},
    6|       |    representatives::OnlineReps,
    7|       |    stats::Stats,
    8|       |    transport::MessageFlooder,
    9|       |    utils::{ThreadPool, ThreadPoolImpl},
   10|       |    work::DistributedWorkFactory,
   11|       |    NetworkParams,
   12|       |};
   13|       |use rand::{thread_rng, Rng};
   14|       |use rsnano_core::{
   15|       |    utils::{get_env_or_default_string, ContainerInfo},
   16|       |    work::{WorkPoolImpl, WorkThresholds},
   17|       |    Account, Amount, Block, BlockDetails, BlockHash, Epoch, KeyDerivationFunction, Link,
   18|       |    PendingKey, PrivateKey, PublicKey, RawKey, Root, SavedBlock, StateBlockArgs, WalletId,
   19|       |};
   20|       |use rsnano_ledger::{Ledger, RepWeightCache};
   21|       |use rsnano_messages::{Message, Publish};
   22|       |use rsnano_nullable_lmdb::{DatabaseFlags, LmdbDatabase, WriteFlags};
   23|       |use rsnano_store_lmdb::{
   24|       |    create_backup_file, KeyType, LmdbEnv, LmdbIterator, LmdbWalletStore, LmdbWriteTransaction,
   25|       |    Transaction,
   26|       |};
   27|       |use serde::{Deserialize, Serialize};
   28|       |use std::{
   29|       |    collections::{HashMap, HashSet},
   30|       |    fmt,
   31|       |    fs::Permissions,
   32|       |    mem::size_of,
   33|       |    os::unix::fs::PermissionsExt,
   34|       |    path::{Path, PathBuf},
   35|       |    sync::{Arc, Condvar, Mutex},
   36|       |    time::{Duration, Instant},
   37|       |};
   38|       |use tracing::{info, warn};
   39|       |
   40|      0|#[derive(FromPrimitive, Debug, Serialize, Deserialize, PartialEq, Eq)]
   41|       |pub enum WalletsError {
   42|       |    None,
   43|       |    Generic,
   44|       |    WalletNotFound,
   45|       |    WalletLocked,
   46|       |    AccountNotFound,
   47|       |    InvalidPassword,
   48|       |    BadPublicKey,
   49|       |}
   50|       |
   51|       |impl WalletsError {
   52|      0|    pub fn as_str(&self) -> &'static str {
   53|      0|        match self {
   54|      0|            WalletsError::None => "No error",
   55|      0|            WalletsError::Generic => "Unknown error",
   56|      0|            WalletsError::WalletNotFound => "Wallet not found",
   57|      0|            WalletsError::WalletLocked => "Wallet is locked",
   58|      0|            WalletsError::AccountNotFound => "Account not found",
   59|      0|            WalletsError::InvalidPassword => "Invalid password",
   60|      0|            WalletsError::BadPublicKey => "Bad public key",
   61|       |        }
   62|      0|    }
   63|       |}
   64|       |
   65|       |impl fmt::Display for WalletsError {
   66|      0|    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
   67|      0|        write!(f, "{}", self.as_str())
   68|      0|    }
   69|       |}
   70|       |
   71|       |impl std::error::Error for WalletsError {}
   72|       |
   73|       |pub enum PreparedSend {
   74|       |    Cached(SavedBlock),
   75|       |    New(Block, BlockDetails),
   76|       |}
   77|       |
   78|       |pub struct Wallets {
   79|       |    db: Option<LmdbDatabase>,
   80|       |    send_action_ids_handle: Option<LmdbDatabase>,
   81|       |    env: Arc<LmdbEnv>,
   82|       |    pub mutex: Mutex<HashMap<WalletId, Arc<Wallet>>>,
   83|       |    node_config: NodeConfig,
   84|       |    ledger: Arc<Ledger>,
   85|       |    last_log: Mutex<Option<Instant>>,
   86|       |    distributed_work: Arc<DistributedWorkFactory>,
   87|       |    work_thresholds: WorkThresholds,
   88|       |    network_params: NetworkParams,
   89|       |    pub delayed_work: Mutex<HashMap<Account, Root>>,
   90|       |    workers: Arc<dyn ThreadPool>,
   91|       |    wallet_actions: WalletActionThread,
   92|       |    block_processor: Arc<BlockProcessor>,
   93|       |    pub representative_wallets: Mutex<WalletRepresentatives>,
   94|       |    online_reps: Arc<Mutex<OnlineReps>>,
   95|       |    pub kdf: KeyDerivationFunction,
   96|       |    start_election: Mutex<Option<Box<dyn Fn(SavedBlock) + Send + Sync>>>,
   97|       |    confirming_set: Arc<ConfirmingSet>,
   98|       |    message_flooder: Mutex<MessageFlooder>,
   99|       |}
  100|       |
  101|       |impl Wallets {
  102|      0|    pub fn new_null_with_env(env: Arc<LmdbEnv>, tokio_handle: tokio::runtime::Handle) -> Self {
  103|      0|        Wallets::new(
  104|      0|            env,
  105|      0|            Arc::new(Ledger::new_null()),
  106|      0|            &NodeConfig::new_test_instance(),
  107|      0|            8,
  108|      0|            WorkThresholds::new(0, 0, 0),
  109|      0|            Arc::new(DistributedWorkFactory::new(
  110|      0|                Arc::new(WorkPoolImpl::disabled()),
  111|      0|                tokio_handle.clone(),
  112|      0|            )),
  113|      0|            NetworkParams::new(NetworkConstants::active_network()),
  114|      0|            Arc::new(ThreadPoolImpl::new_null()),
  115|      0|            Arc::new(BlockProcessor::new_null()),
  116|      0|            Arc::new(Mutex::new(OnlineReps::new(
  117|      0|                Arc::new(RepWeightCache::new()),
  118|      0|                Duration::default(),
  119|      0|                Amount::zero(),
  120|      0|                Amount::zero(),
  121|      0|            ))),
  122|      0|            Arc::new(ConfirmingSet::new(
  123|      0|                ConfirmingSetConfig::default(),
  124|      0|                Arc::new(Ledger::new_null()),
  125|      0|                Arc::new(Stats::default()),
  126|      0|            )),
  127|      0|            MessageFlooder::new_null(),
  128|      0|        )
  129|      0|    }
  130|       |
  131|      3|    pub fn new(
  132|      3|        env: Arc<LmdbEnv>,
  133|      3|        ledger: Arc<Ledger>,
  134|      3|        node_config: &NodeConfig,
  135|      3|        kdf_work: u32,
  136|      3|        work: WorkThresholds,
  137|      3|        distributed_work: Arc<DistributedWorkFactory>,
  138|      3|        network_params: NetworkParams,
  139|      3|        workers: Arc<dyn ThreadPool>,
  140|      3|        block_processor: Arc<BlockProcessor>,
  141|      3|        online_reps: Arc<Mutex<OnlineReps>>,
  142|      3|        confirming_set: Arc<ConfirmingSet>,
  143|      3|        message_flooder: MessageFlooder,
  144|      3|    ) -> Self {
  145|      3|        let kdf = KeyDerivationFunction::new(kdf_work);
  146|      3|        Self {
  147|      3|            db: None,
  148|      3|            send_action_ids_handle: None,
  149|      3|            mutex: Mutex::new(HashMap::new()),
  150|      3|            env,
  151|      3|            node_config: node_config.clone(),
  152|      3|            ledger: Arc::clone(&ledger),
  153|      3|            last_log: Mutex::new(None),
  154|      3|            distributed_work,
  155|      3|            work_thresholds: work.clone(),
  156|      3|            network_params,
  157|      3|            delayed_work: Mutex::new(HashMap::new()),
  158|      3|            workers,
  159|      3|            wallet_actions: WalletActionThread::new(),
  160|      3|            block_processor,
  161|      3|            representative_wallets: Mutex::new(WalletRepresentatives::new(
  162|      3|                node_config.vote_minimum,
  163|      3|                Arc::clone(&ledger),
  164|      3|            )),
  165|      3|            online_reps,
  166|      3|            kdf: kdf.clone(),
  167|      3|            start_election: Mutex::new(None),
  168|      3|            confirming_set,
  169|      3|            message_flooder: Mutex::new(message_flooder),
  170|      3|        }
  171|      3|    }
  172|       |
  173|      3|    pub fn start(&self) {
  174|      3|        self.wallet_actions.start();
  175|      3|    }
  176|       |
  177|      6|    pub fn stop(&self) {
  178|      6|        self.wallet_actions.stop();
  179|      6|    }
  180|       |
  181|      3|    pub fn set_start_election_callback(&self, callback: Box<dyn Fn(SavedBlock) + Send + Sync>) {
  182|      3|        *self.start_election.lock().unwrap() = Some(callback);
  183|      3|    }
  184|       |
  185|      3|    pub fn initialize(&mut self) -> anyhow::Result<()> {
  186|      3|        let mut txn = self.env.tx_begin_write();
  187|      3|        self.db = Some(unsafe { txn.rw_txn_mut().create_db(None, DatabaseFlags::empty())? });
                                                                                                      ^0
  188|       |        self.send_action_ids_handle = Some(unsafe {
  189|      3|            txn.rw_txn_mut()
  190|      3|                .create_db(Some("send_action_ids"), DatabaseFlags::empty())?
                                                                                         ^0
  191|       |        });
  192|       |        {
  193|      3|            let mut guard = self.mutex.lock().unwrap();
  194|      3|            let wallet_ids = self.get_wallet_ids(&txn);
  195|      3|            for id in wallet_ids {
                              ^0
  196|      0|                assert!(!guard.contains_key(&id));
  197|      0|                let representative = self.node_config.random_representative();
  198|      0|                let text = PathBuf::from(id.encode_hex());
  199|      0|                let wallet = Wallet::new(
  200|      0|                    self.ledger.clone(),
  201|      0|                    self.work_thresholds.clone(),
  202|      0|                    &mut txn,
  203|      0|                    self.node_config.password_fanout as usize,
  204|      0|                    self.kdf.clone(),
  205|      0|                    representative,
  206|      0|                    &text,
  207|      0|                )?;
  208|       |
  209|      0|                guard.insert(id, Arc::new(wallet));
  210|       |            }
  211|       |
  212|       |            // Backup before upgrade wallets
  213|      3|            let mut backup_required = false;
  214|      3|            if self.node_config.backup_before_upgrade {
  215|      0|                let txn = self.env.tx_begin_read();
  216|      0|                for wallet in guard.values() {
  217|      0|                    if wallet.store.version(&txn) != LmdbWalletStore::VERSION_CURRENT {
  218|      0|                        backup_required = true;
  219|      0|                        break;
  220|      0|                    }
  221|       |                }
  222|      3|            }
  223|      3|            if backup_required {
  224|      0|                create_backup_file(&self.env)?;
  225|      3|            }
  226|       |        }
  227|      3|        Ok(())
  228|      3|    }
  229|       |
  230|      6|    pub fn voting_reps_count(&self) -> u64 {
  231|      6|        self.representative_wallets.lock().unwrap().voting_reps()
  232|      6|    }
  233|       |
  234|      6|    fn iter_wallets<'tx>(&self, tx: &'tx dyn Transaction) -> impl Iterator<Item = WalletId> + 'tx {
  235|      6|        let cursor = tx
  236|      6|            .open_ro_cursor(self.db.unwrap())
  237|      6|            .expect("Could not read from wallets db");
  238|      6|
  239|      6|        LmdbIterator::new(cursor, |k, _| {
  240|       |            // wallet tables are identified by their wallet id hex string which is 64 bytes
  241|      6|            let key = if k.len() == 64 {
  242|      0|                WalletId::decode_hex(std::str::from_utf8(k).unwrap()).unwrap()
  243|       |            } else {
  244|      6|                WalletId::zero()
  245|       |            };
  246|      6|            (key, ())
  247|      6|        })
  248|      6|        .filter_map(|(k, _)| if k.is_zero() { None } else { Some(k) })
                                                                          ^0
  249|      6|    }
  250|       |
  251|      0|    pub fn wallet_ids(&self) -> Vec<WalletId> {
  252|      0|        let tx = self.env.tx_begin_read();
  253|      0|        self.get_wallet_ids(&tx)
  254|      0|    }
  255|       |
  256|      6|    pub fn get_wallet_ids(&self, tx: &dyn Transaction) -> Vec<WalletId> {
  257|      6|        self.iter_wallets(tx).collect()
  258|      6|    }
  259|       |
  260|      0|    pub fn get_block_hash(
  261|      0|        &self,
  262|      0|        txn: &dyn Transaction,
  263|      0|        id: &str,
  264|      0|    ) -> anyhow::Result<Option<BlockHash>> {
  265|      0|        match txn.get(self.send_action_ids_handle.unwrap(), id.as_bytes()) {
  266|      0|            Ok(bytes) => Ok(Some(
  267|      0|                BlockHash::from_slice(bytes).ok_or_else(|| anyhow!("invalid block hash"))?,
  268|       |            )),
  269|      0|            Err(rsnano_nullable_lmdb::Error::NotFound) => Ok(None),
  270|      0|            Err(e) => Err(e.into()),
  271|       |        }
  272|      0|    }
  273|       |
  274|      0|    pub fn set_block_hash(
  275|      0|        &self,
  276|      0|        txn: &mut LmdbWriteTransaction,
  277|      0|        id: &str,
  278|      0|        hash: &BlockHash,
  279|      0|    ) -> anyhow::Result<()> {
  280|      0|        txn.rw_txn_mut().put(
  281|      0|            self.send_action_ids_handle.unwrap(),
  282|      0|            id.as_bytes(),
  283|      0|            hash.as_bytes(),
  284|      0|            WriteFlags::empty(),
  285|      0|        )?;
  286|      0|        Ok(())
  287|      0|    }
  288|       |
  289|      0|    pub fn clear_send_ids(&self) {
  290|      0|        let mut tx = self.env.tx_begin_write();
  291|      0|        tx.clear_db(self.send_action_ids_handle.unwrap()).unwrap();
  292|      0|    }
  293|       |
  294|      0|    pub fn foreach_representative<F>(&self, mut action: F)
  295|      0|    where
  296|      0|        F: FnMut(&PrivateKey),
  297|      0|    {
  298|      0|        if self.node_config.enable_voting {
  299|      0|            let mut action_accounts_l: Vec<PrivateKey> = Vec::new();
  300|      0|            {
  301|      0|                let transaction_l = self.env.tx_begin_read();
  302|      0|                let ledger_txn = self.ledger.read_txn();
  303|      0|                let lock = self.mutex.lock().unwrap();
  304|      0|                for (wallet_id, wallet) in lock.iter() {
  305|      0|                    let representatives_l = wallet.representatives.lock().unwrap().clone();
  306|      0|                    for account in representatives_l {
  307|      0|                        if wallet.store.exists(&transaction_l, &account.into()) {
  308|      0|                            if !self.ledger.weight_exact(&ledger_txn, account).is_zero() {
  309|      0|                                if wallet.store.valid_password(&transaction_l) {
  310|      0|                                    let prv = wallet
  311|      0|                                        .store
  312|      0|                                        .fetch(&transaction_l, &account.into())
  313|      0|                                        .expect("could not fetch account from wallet");
  314|      0|
  315|      0|                                    action_accounts_l.push(prv.into());
  316|      0|                                } else {
  317|      0|                                    let mut last_log_guard = self.last_log.lock().unwrap();
  318|      0|                                    let should_log = match last_log_guard.as_ref() {
  319|      0|                                        Some(i) => i.elapsed() >= Duration::from_secs(60),
  320|      0|                                        None => true,
  321|       |                                    };
  322|      0|                                    if should_log {
  323|      0|                                        *last_log_guard = Some(Instant::now());
  324|      0|                                        warn!("Representative locked inside wallet {}", wallet_id);
  325|      0|                                    }
  326|       |                                }
  327|      0|                            }
  328|      0|                        }
  329|       |                    }
  330|       |                }
  331|       |            }
  332|      0|            for keys in action_accounts_l {
  333|      0|                action(&keys);
  334|      0|            }
  335|      0|        }
  336|      0|    }
  337|       |
  338|      0|    pub fn work_cache_blocking2(
  339|      0|        &self,
  340|      0|        wallet_id: &WalletId,
  341|      0|        pub_key: &PublicKey,
  342|      0|        root: &Root,
  343|      0|    ) -> Result<(), WalletsError> {
  344|      0|        let guard = self.mutex.lock().unwrap();
  345|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  346|      0|        self.work_cache_blocking(wallet, pub_key, root);
  347|      0|        Ok(())
  348|      0|    }
  349|       |
  350|      0|    fn work_cache_blocking(&self, wallet: &Wallet, pub_key: &PublicKey, root: &Root) {
  351|      0|        if self.distributed_work.work_generation_enabled() {
  352|      0|            let difficulty = self.work_thresholds.threshold_base();
  353|      0|            if let Some(work) =
  354|      0|                self.distributed_work
  355|      0|                    .make_blocking(*root, difficulty, Some(pub_key.into()))
  356|       |            {
  357|      0|                let mut tx = self.env.tx_begin_write();
  358|      0|                if wallet.live() && wallet.store.exists(&tx, pub_key) {
  359|      0|                    wallet.work_update(&mut tx, pub_key, root, work);
  360|      0|                }
  361|       |            } else {
  362|      0|                warn!(
  363|      0|                    "Could not precache work for root {} due to work generation failure",
  364|       |                    root
  365|       |                );
  366|       |            }
  367|      0|        }
  368|      0|    }
  369|       |
  370|      0|    fn get_wallet<'a>(
  371|      0|        guard: &'a HashMap<WalletId, Arc<Wallet>>,
  372|      0|        wallet_id: &WalletId,
  373|      0|    ) -> Result<&'a Arc<Wallet>, WalletsError> {
  374|      0|        guard.get(wallet_id).ok_or(WalletsError::WalletNotFound)
  375|      0|    }
  376|       |
  377|      0|    pub fn insert_watch(
  378|      0|        &self,
  379|      0|        wallet_id: &WalletId,
  380|      0|        accounts: &[Account],
  381|      0|    ) -> Result<(), WalletsError> {
  382|      0|        let guard = self.mutex.lock().unwrap();
  383|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  384|      0|        let mut tx = self.env.tx_begin_write();
  385|      0|        if !wallet.store.valid_password(&tx) {
  386|      0|            return Err(WalletsError::WalletLocked);
  387|      0|        }
  388|       |
  389|      0|        for account in accounts {
  390|      0|            if wallet.store.insert_watch(&mut tx, &account.into()).is_err() {
  391|      0|                return Err(WalletsError::BadPublicKey);
  392|      0|            }
  393|       |        }
  394|       |
  395|      0|        Ok(())
  396|      0|    }
  397|       |
  398|      0|    pub fn valid_password(&self, wallet_id: &WalletId) -> Result<bool, WalletsError> {
  399|      0|        let guard = self.mutex.lock().unwrap();
  400|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  401|      0|        let tx = self.env.tx_begin_read();
  402|      0|        Ok(wallet.store.valid_password(&tx))
  403|      0|    }
  404|       |
  405|      0|    pub fn attempt_password(
  406|      0|        &self,
  407|      0|        wallet_id: &WalletId,
  408|      0|        password: impl AsRef<str>,
  409|      0|    ) -> Result<(), WalletsError> {
  410|      0|        let guard = self.mutex.lock().unwrap();
  411|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  412|      0|        let tx = self.env.tx_begin_write();
  413|      0|        if wallet.store.attempt_password(&tx, password.as_ref()) {
  414|      0|            Ok(())
  415|       |        } else {
  416|      0|            Err(WalletsError::InvalidPassword)
  417|       |        }
  418|      0|    }
  419|       |
  420|      0|    pub fn lock(&self, wallet_id: &WalletId) -> Result<(), WalletsError> {
  421|      0|        let guard = self.mutex.lock().unwrap();
  422|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  423|      0|        wallet.store.lock();
  424|      0|        Ok(())
  425|      0|    }
  426|       |
  427|      0|    pub fn rekey(
  428|      0|        &self,
  429|      0|        wallet_id: &WalletId,
  430|      0|        password: impl AsRef<str>,
  431|      0|    ) -> Result<(), WalletsError> {
  432|      0|        let guard = self.mutex.lock().unwrap();
  433|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  434|      0|        let mut tx = self.env.tx_begin_write();
  435|      0|        if !wallet.store.valid_password(&tx) {
  436|      0|            return Err(WalletsError::WalletLocked);
  437|      0|        }
  438|      0|
  439|      0|        wallet
  440|      0|            .store
  441|      0|            .rekey(&mut tx, password.as_ref())
  442|      0|            .map_err(|_| WalletsError::Generic)
  443|      0|    }
  444|       |
  445|      0|    pub fn set_observer(&self, observer: Box<dyn Fn(bool) + Send>) {
  446|      0|        self.wallet_actions.set_observer(observer);
  447|      0|    }
  448|       |
  449|      9|    pub fn compute_reps(&self) {
  450|      9|        let wallets_guard = self.mutex.lock().unwrap();
  451|      9|        let mut reps_guard = self.representative_wallets.lock().unwrap();
  452|      9|        reps_guard.clear();
  453|      9|        let half_principal_weight = self.online_reps.lock().unwrap().minimum_principal_weight() / 2;
  454|      9|        let tx = self.env.tx_begin_read();
  455|      9|        for (_, wallet) in wallets_guard.iter() {
                              ^0
  456|      0|            let mut representatives = HashSet::new();
  457|       |
  458|      0|            for (pub_key, _) in wallet.store.iter(&tx) {
  459|      0|                if reps_guard.check_rep(pub_key, half_principal_weight) {
  460|      0|                    representatives.insert(pub_key.into());
  461|      0|                }
  462|       |            }
  463|       |
  464|      0|            *wallet.representatives.lock().unwrap() = representatives;
  465|       |        }
  466|      9|    }
  467|       |
  468|      0|    pub fn exists(&self, pub_key: &PublicKey) -> bool {
  469|      0|        let guard = self.mutex.lock().unwrap();
  470|      0|        let tx = self.env.tx_begin_read();
  471|      0|        guard
  472|      0|            .values()
  473|      0|            .any(|wallet| wallet.store.exists(&tx, pub_key))
  474|      0|    }
  475|       |
  476|      3|    pub fn reload(&self) {
  477|      3|        let mut guard = self.mutex.lock().unwrap();
  478|      3|        let mut tx = self.env.tx_begin_write();
  479|      3|        let mut stored_items = HashSet::new();
  480|      3|        let wallet_ids = self.get_wallet_ids(&tx);
  481|      3|        for id in wallet_ids {
                          ^0
  482|       |            // New wallet
  483|      0|            if !guard.contains_key(&id) {
  484|      0|                let text = PathBuf::from(id.encode_hex());
  485|      0|                let representative = self.node_config.random_representative();
  486|      0|                if let Ok(wallet) = Wallet::new(
  487|      0|                    Arc::clone(&self.ledger),
  488|      0|                    self.work_thresholds.clone(),
  489|      0|                    &mut tx,
  490|      0|                    self.node_config.password_fanout as usize,
  491|      0|                    self.kdf.clone(),
  492|      0|                    representative,
  493|      0|                    &text,
  494|      0|                ) {
  495|      0|                    guard.insert(id, Arc::new(wallet));
  496|      0|                }
  497|      0|            }
  498|       |            // List of wallets on disk
  499|      0|            stored_items.insert(id);
  500|       |        }
  501|       |        // Delete non existing wallets from memory
  502|      3|        let mut deleted_items = Vec::new();
  503|      3|        for &id in guard.keys() {
                           ^0
  504|      0|            if !stored_items.contains(&id) {
  505|      0|                deleted_items.push(id);
  506|      0|            }
  507|       |        }
  508|      3|        for i in &deleted_items {
                          ^0
  509|      0|            guard.remove(i);
  510|      0|        }
  511|      3|    }
  512|       |
  513|      0|    pub fn wallet_exists(&self, wallet_id: &WalletId) -> bool {
  514|      0|        self.mutex.lock().unwrap().contains_key(wallet_id)
  515|      0|    }
  516|       |
  517|      0|    pub fn destroy(&self, id: &WalletId) {
  518|      0|        let mut guard = self.mutex.lock().unwrap();
  519|      0|        let mut tx = self.env.tx_begin_write();
  520|      0|        // action_mutex should be locked after transactions to prevent deadlocks in deterministic_insert () & insert_adhoc ()
  521|      0|        let _action_guard = self.wallet_actions.lock_safe();
  522|      0|        let wallet = guard.remove(id).unwrap();
  523|      0|        wallet.store.destroy(&mut tx);
  524|      0|    }
  525|       |
  526|      0|    pub fn remove_key(
  527|      0|        &self,
  528|      0|        wallet_id: &WalletId,
  529|      0|        pub_key: &PublicKey,
  530|      0|    ) -> Result<(), WalletsError> {
  531|      0|        let guard = self.mutex.lock().unwrap();
  532|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  533|      0|        let mut tx = self.env.tx_begin_write();
  534|      0|        if !wallet.store.valid_password(&tx) {
  535|      0|            return Err(WalletsError::WalletLocked);
  536|      0|        }
  537|      0|        if wallet.store.find(&tx, pub_key).is_none() {
  538|      0|            return Err(WalletsError::AccountNotFound);
  539|      0|        }
  540|      0|        wallet.store.erase(&mut tx, pub_key);
  541|      0|        Ok(())
  542|      0|    }
  543|       |
  544|      0|    pub fn work_set(
  545|      0|        &self,
  546|      0|        wallet_id: &WalletId,
  547|      0|        pub_key: &PublicKey,
  548|      0|        work: u64,
  549|      0|    ) -> Result<(), WalletsError> {
  550|      0|        let guard = self.mutex.lock().unwrap();
  551|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  552|      0|        let mut tx = self.env.tx_begin_write();
  553|      0|        if wallet.store.find(&tx, pub_key).is_none() {
  554|      0|            return Err(WalletsError::AccountNotFound);
  555|      0|        }
  556|      0|        wallet.store.work_put(&mut tx, pub_key, work);
  557|      0|        Ok(())
  558|      0|    }
  559|       |
  560|      0|    pub fn move_accounts(
  561|      0|        &self,
  562|      0|        source_id: &WalletId,
  563|      0|        target_id: &WalletId,
  564|      0|        accounts: &[PublicKey],
  565|      0|    ) -> Result<(), WalletsError> {
  566|      0|        let guard = self.mutex.lock().unwrap();
  567|      0|        let source = Self::get_wallet(&guard, source_id)?;
  568|      0|        let target = Self::get_wallet(&guard, target_id)?;
  569|      0|        let tx = self.env.tx_begin_read();
  570|      0|        if !source.store.valid_password(&tx) || !target.store.valid_password(&tx) {
  571|      0|            return Err(WalletsError::WalletLocked);
  572|      0|        }
  573|      0|        let mut tx = self.env.tx_begin_write();
  574|      0|        target
  575|      0|            .store
  576|      0|            .move_keys(&mut tx, &source.store, accounts)
  577|      0|            .map_err(|_| WalletsError::AccountNotFound)
  578|      0|    }
  579|       |
  580|      3|    pub fn backup(&self, path: &Path) -> anyhow::Result<()> {
  581|      3|        let guard = self.mutex.lock().unwrap();
  582|      3|        let tx = self.env.tx_begin_read();
  583|      3|        for (id, wallet) in guard.iter() {
                           ^0
  584|      0|            std::fs::create_dir_all(path)?;
  585|      0|            std::fs::set_permissions(path, Permissions::from_mode(0o700))?;
  586|      0|            let mut backup_path = PathBuf::from(path);
  587|      0|            backup_path.push(format!("{}.json", id));
  588|      0|            wallet.store.write_backup(&tx, &backup_path)?;
  589|       |        }
  590|      3|        Ok(())
  591|      3|    }
  592|       |
  593|      0|    pub fn deterministic_index_get(&self, wallet_id: &WalletId) -> Result<u32, WalletsError> {
  594|      0|        let guard = self.mutex.lock().unwrap();
  595|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  596|      0|        let tx = self.env.tx_begin_read();
  597|      0|        Ok(wallet.store.deterministic_index_get(&tx))
  598|      0|    }
  599|       |
  600|      0|    fn prepare_send(
  601|      0|        &self,
  602|      0|        tx: &dyn Transaction,
  603|      0|        wallet: &Arc<Wallet>,
  604|      0|        source: Account,
  605|      0|        account: Account,
  606|      0|        amount: Amount,
  607|      0|        mut work: u64,
  608|      0|    ) -> anyhow::Result<PreparedSend> {
  609|      0|        let block_tx = self.ledger.read_txn();
  610|      0|        if !wallet.store.valid_password(tx) {
  611|      0|            bail!("invalid password");
  612|      0|        }
  613|      0|        let balance = self
  614|      0|            .ledger
  615|      0|            .any()
  616|      0|            .account_balance(&block_tx, &source)
  617|      0|            .unwrap_or_default();
  618|      0|
  619|      0|        if balance.is_zero() || balance < amount {
  620|      0|            bail!("insufficient balance");
  621|      0|        }
  622|      0|
  623|      0|        let info = self.ledger.account_info(&block_tx, &source).unwrap();
  624|      0|        let prv_key_raw = wallet.store.fetch(tx, &source.into()).unwrap();
  625|      0|        if work == 0 {
  626|      0|            work = wallet
  627|      0|                .store
  628|      0|                .work_get(tx, &source.into())
  629|      0|                .unwrap_or_default();
  630|      0|        }
  631|      0|        let priv_key = PrivateKey::from(prv_key_raw);
  632|      0|        let state_block: Block = StateBlockArgs {
  633|      0|            key: &priv_key,
  634|      0|            previous: info.head,
  635|      0|            representative: info.representative,
  636|      0|            balance: balance - amount,
  637|      0|            link: account.into(),
  638|      0|            work,
  639|      0|        }
  640|      0|        .into();
  641|      0|        let details = BlockDetails::new(info.epoch, true, false, false);
  642|      0|        Ok(PreparedSend::New(state_block, details))
  643|      0|    }
  644|       |
  645|      0|    fn prepare_send_with_id(
  646|      0|        &self,
  647|      0|        tx: &mut LmdbWriteTransaction,
  648|      0|        id: &str,
  649|      0|        wallet: &Arc<Wallet>,
  650|      0|        source: Account,
  651|      0|        account: Account,
  652|      0|        amount: Amount,
  653|      0|        mut work: u64,
  654|      0|    ) -> anyhow::Result<PreparedSend> {
  655|      0|        let block_tx = self.ledger.read_txn();
  656|       |
  657|      0|        let block = match self.get_block_hash(tx, id)? {
  658|      0|            Some(hash) => Some(self.ledger.any().get_block(&block_tx, &hash).unwrap()),
  659|      0|            None => None,
  660|       |        };
  661|       |
  662|      0|        if let Some(block) = block {
  663|      0|            let msg = Message::Publish(Publish::new_forward(block.clone().into()));
  664|      0|            self.message_flooder.lock().unwrap().flood(
  665|      0|                &msg,
  666|      0|                rsnano_network::TrafficType::BlockBroadcastInitial,
  667|      0|                1.0,
  668|      0|            );
  669|      0|            Ok(PreparedSend::Cached(block))
  670|       |        } else {
  671|      0|            if !wallet.store.valid_password(tx) {
  672|      0|                bail!("invalid password");
  673|      0|            }
  674|      0|
  675|      0|            let balance = self
  676|      0|                .ledger
  677|      0|                .any()
  678|      0|                .account_balance(&block_tx, &source)
  679|      0|                .unwrap_or_default();
  680|      0|
  681|      0|            if balance.is_zero() || balance < amount {
  682|      0|                bail!("insufficient balance");
  683|      0|            }
  684|      0|
  685|      0|            let info = self.ledger.account_info(&block_tx, &source).unwrap();
  686|      0|            let prv_key_raw = wallet.store.fetch(tx, &source.into()).unwrap();
  687|      0|            if work == 0 {
  688|      0|                work = wallet
  689|      0|                    .store
  690|      0|                    .work_get(tx, &source.into())
  691|      0|                    .unwrap_or_default();
  692|      0|            }
  693|      0|            let priv_key = PrivateKey::from(prv_key_raw);
  694|      0|            let state_block: Block = StateBlockArgs {
  695|      0|                key: &priv_key,
  696|      0|                previous: info.head,
  697|      0|                representative: info.representative,
  698|      0|                balance: balance - amount,
  699|      0|                link: account.into(),
  700|      0|                work,
  701|      0|            }
  702|      0|            .into();
  703|      0|            let details = BlockDetails::new(info.epoch, true, false, false);
  704|      0|            self.set_block_hash(tx, id, &state_block.hash())?;
  705|      0|            Ok(PreparedSend::New(state_block, details))
  706|       |        }
  707|      0|    }
  708|       |
  709|      0|    pub fn work_get(&self, wallet_id: &WalletId, pub_key: &PublicKey) -> u64 {
  710|      0|        let guard = self.mutex.lock().unwrap();
  711|      0|        let tx = self.env.tx_begin_read();
  712|      0|        let Some(wallet) = guard.get(&wallet_id) else {
  713|      0|            return 1;
  714|       |        };
  715|      0|        wallet.store.work_get(&tx, pub_key).unwrap_or(1)
  716|      0|    }
  717|       |
  718|      0|    pub fn work_get2(
  719|      0|        &self,
  720|      0|        wallet_id: &WalletId,
  721|      0|        pub_key: &PublicKey,
  722|      0|    ) -> Result<u64, WalletsError> {
  723|      0|        let guard = self.mutex.lock().unwrap();
  724|      0|        let tx = self.env.tx_begin_read();
  725|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  726|      0|        if wallet.store.find(&tx, pub_key).is_none() {
  727|      0|            return Err(WalletsError::AccountNotFound);
  728|      0|        }
  729|      0|        Ok(wallet.store.work_get(&tx, pub_key).unwrap_or(1))
  730|      0|    }
  731|       |
  732|      0|    pub fn get_accounts(&self, max_results: usize) -> Vec<Account> {
  733|      0|        let mut accounts = Vec::new();
  734|      0|        let guard = self.mutex.lock().unwrap();
  735|      0|        let tx = self.env.tx_begin_read();
  736|      0|        for wallet in guard.values() {
  737|      0|            for (pub_key, _) in wallet.store.iter(&tx) {
  738|      0|                if accounts.len() >= max_results {
  739|      0|                    break;
  740|      0|                }
  741|      0|
  742|      0|                accounts.push(pub_key.into());
  743|       |            }
  744|       |        }
  745|      0|        accounts
  746|      0|    }
  747|       |
  748|      0|    pub fn get_accounts_of_wallet(
  749|      0|        &self,
  750|      0|        wallet_id: &WalletId,
  751|      0|    ) -> Result<Vec<Account>, WalletsError> {
  752|      0|        let guard = self.mutex.lock().unwrap();
  753|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  754|      0|        let tx = self.env.tx_begin_read();
  755|      0|        let mut accounts = Vec::new();
  756|      0|        for (account, _) in wallet.store.iter(&tx) {
  757|      0|            accounts.push(account.into());
  758|      0|        }
  759|      0|        Ok(accounts)
  760|      0|    }
  761|       |
  762|      0|    pub fn fetch(&self, wallet_id: &WalletId, pub_key: &PublicKey) -> Result<RawKey, WalletsError> {
  763|      0|        let guard = self.mutex.lock().unwrap();
  764|      0|        let wallet = Self::get_wallet(&guard, wallet_id)?;
  765|      0|        let tx = self.env.tx_begin_read();
  766|      0|        if !wallet.store.valid_password(&tx) {
  767|      0|            return Err(WalletsError::WalletLocked);
  768|      0|        }
  769|      0|        if wallet.store.find(&tx, pub_key).is_none() {
  770|      0|            return Err(WalletsError::AccountNotFound);
  771|      0|        }
  772|      0|        wallet
  773|      0|            .store
  774|      0|            .fetch(&tx, pub_key)
  775|      0|            .map_err(|_| WalletsError::Generic)
  776|      0|    }
  777|       |
  778|      0|    pub fn import(&self, wallet_id: WalletId, json: &str) -> anyhow::Result<()> {
  779|      0|        let _guard = self.mutex.lock().unwrap();
  780|      0|        let mut tx = self.env.tx_begin_write();
  781|      0|        let _wallet = Wallet::new_from_json(
  782|      0|            Arc::clone(&self.ledger),
  783|      0|            self.work_thresholds.clone(),
  784|      0|            &mut tx,
  785|      0|            self.node_config.password_fanout as usize,
  786|      0|            self.kdf.clone(),
  787|      0|            &PathBuf::from(wallet_id.to_string()),
  788|      0|            json,
  789|      0|        )?;
  790|      0|        Ok(())
  791|      0|    }
  792|       |
  793|      0|    pub fn import_replace(
  794|      0|        &self,
  795|      0|        wallet_id: WalletId,
  796|      0|        json: &str,
  797|      0|        password: &str,
  798|      0|    ) -> anyhow::Result<()> {
  799|      0|        let guard = self.mutex.lock().unwrap();
  800|      0|        let existing = guard
  801|      0|            .get(&wallet_id)
  802|      0|            .ok_or_else(|| anyhow!("wallet not found"))?;
  803|      0|        let mut tx = self.env.tx_begin_write();
  804|      0|        let id = WalletId::from_bytes(thread_rng().gen());
  805|      0|        let temp = LmdbWalletStore::new_from_json(
  806|      0|            1,
  807|      0|            self.kdf.clone(),
  808|      0|            &mut tx,
  809|      0|            &PathBuf::from(id.to_string()),
  810|      0|            json,
  811|      0|        )?;
  812|       |
  813|      0|        let result = if temp.attempt_password(&tx, password) {
  814|      0|            existing.store.import(&mut tx, &temp)
  815|       |        } else {
  816|      0|            Err(anyhow!("bad password"))
  817|       |        };
  818|      0|        temp.destroy(&mut tx);
  819|      0|        result
  820|      0|    }
  821|       |
  822|      0|    pub fn get_seed(&self, wallet_id: WalletId) -> Result<RawKey, WalletsError> {
  823|      0|        let guard = self.mutex.lock().unwrap();
  824|      0|        let wallet = Self::get_wallet(&guard, &wallet_id)?;
  825|      0|        let tx = self.env.tx_begin_read();
  826|      0|        if !wallet.store.valid_password(&tx) {
  827|      0|            return Err(WalletsError::WalletLocked);
  828|      0|        }
  829|      0|        Ok(wallet.store.seed(&tx))
  830|      0|    }
  831|       |
  832|      0|    pub fn key_type(&self, wallet_id: WalletId, pub_key: &PublicKey) -> KeyType {
  833|      0|        let guard = self.mutex.lock().unwrap();
  834|      0|        match guard.get(&wallet_id) {
  835|      0|            Some(wallet) => {
  836|      0|                let tx = self.env.tx_begin_read();
  837|      0|                wallet.store.get_key_type(&tx, pub_key)
  838|       |            }
  839|      0|            None => KeyType::Unknown,
  840|       |        }
  841|      0|    }
  842|       |
  843|      0|    pub fn get_representative(&self, wallet_id: WalletId) -> Result<PublicKey, WalletsError> {
  844|      0|        let guard = self.mutex.lock().unwrap();
  845|      0|        let wallet = Self::get_wallet(&guard, &wallet_id)?;
  846|      0|        let tx = self.env.tx_begin_read();
  847|      0|        Ok(wallet.store.representative(&tx))
  848|      0|    }
  849|       |
  850|      0|    pub fn decrypt(&self, wallet_id: WalletId) -> Result<Vec<(PublicKey, RawKey)>, WalletsError> {
  851|      0|        let guard = self.mutex.lock().unwrap();
  852|      0|        let wallet = Self::get_wallet(&guard, &wallet_id)?;
  853|      0|        let tx = self.env.tx_begin_read();
  854|      0|        if !wallet.store.valid_password(&tx) {
  855|      0|            return Err(WalletsError::WalletLocked);
  856|      0|        }
  857|      0|
  858|      0|        let mut result = Vec::new();
  859|      0|        for (account, _) in wallet.store.iter(&tx) {
  860|      0|            let key = wallet
  861|      0|                .store
  862|      0|                .fetch(&tx, &account)
  863|      0|                .map_err(|_| WalletsError::Generic)?;
  864|      0|            result.push((account, key));
  865|       |        }
  866|       |
  867|      0|        Ok(result)
  868|      0|    }
  869|       |
  870|      0|    pub fn serialize(&self, wallet_id: WalletId) -> Result<String, WalletsError> {
  871|      0|        let guard = self.mutex.lock().unwrap();
  872|      0|        let wallet = Self::get_wallet(&guard, &wallet_id)?;
  873|      0|        let tx = self.env.tx_begin_read();
  874|      0|        Ok(wallet.store.serialize_json(&tx))
  875|      0|    }
  876|       |
  877|      0|    pub fn should_republish_vote(&self, voting_account: Account) -> bool {
  878|      0|        let guard = self.representative_wallets.lock().unwrap();
  879|      0|        !guard.have_half_rep() && !guard.exists(&voting_account)
  880|      0|    }
  881|       |
  882|      0|    pub fn container_info(&self) -> ContainerInfo {
  883|      0|        [
  884|      0|            (
  885|      0|                "items",
  886|      0|                self.mutex.lock().unwrap().len(),
  887|      0|                size_of::<usize>() * size_of::<WalletId>(),
  888|      0|            ),
  889|      0|            ("actions", self.wallet_actions.len(), size_of::<usize>() * 2),
  890|      0|        ]
  891|      0|        .into()
  892|      0|    }
  893|       |}
  894|       |
  895|       |impl Drop for Wallets {
  896|      3|    fn drop(&mut self) {
  897|      3|        self.stop();
  898|      3|    }
  899|       |}
  900|       |
  901|       |const GENERATE_PRIORITY: Amount = Amount::MAX;
  902|       |const HIGH_PRIORITY: Amount = Amount::raw(u128::MAX - 1);
  903|       |
  904|       |pub trait WalletsExt {
  905|       |    fn deterministic_insert(
  906|       |        &self,
  907|       |        wallet: &Arc<Wallet>,
  908|       |        tx: &mut LmdbWriteTransaction,
  909|       |        generate_work: bool,
  910|       |    ) -> PublicKey;
  911|       |
  912|       |    fn deterministic_insert_at(
  913|       |        &self,
  914|       |        wallet_id: &WalletId,
  915|       |        index: u32,
  916|       |        generate_work: bool,
  917|       |    ) -> Result<PublicKey, WalletsError>;
  918|       |
  919|       |    fn deterministic_insert2(
  920|       |        &self,
  921|       |        wallet_id: &WalletId,
  922|       |        generate_work: bool,
  923|       |    ) -> Result<PublicKey, WalletsError>;
  924|       |
  925|       |    fn insert_adhoc(&self, wallet: &Arc<Wallet>, key: &RawKey, generate_work: bool) -> PublicKey;
  926|       |
  927|       |    fn insert_adhoc2(
  928|       |        &self,
  929|       |        wallet_id: &WalletId,
  930|       |        key: &RawKey,
  931|       |        generate_work: bool,
  932|       |    ) -> Result<PublicKey, WalletsError>;
  933|       |
  934|       |    fn work_ensure(&self, wallet: &Arc<Wallet>, account: Account, root: Root);
  935|       |
  936|       |    fn action_complete(
  937|       |        &self,
  938|       |        wallet: Arc<Wallet>,
  939|       |        block: Block,
  940|       |        account: Account,
  941|       |        generate_work: bool,
  942|       |        details: &BlockDetails,
  943|       |    ) -> anyhow::Result<SavedBlock>;
  944|       |
  945|       |    fn ongoing_compute_reps(&self);
  946|       |
  947|       |    fn change_seed(
  948|       |        &self,
  949|       |        wallet_id: WalletId,
  950|       |        prv_key: &RawKey,
  951|       |        count: u32,
  952|       |    ) -> Result<(u32, Account), WalletsError>;
  953|       |
  954|       |    fn change_seed_wallet(
  955|       |        &self,
  956|       |        wallet: &Arc<Wallet>,
  957|       |        tx: &mut LmdbWriteTransaction,
  958|       |        prv_key: &RawKey,
  959|       |        count: u32,
  960|       |    ) -> PublicKey;
  961|       |
  962|       |    fn send_action(
  963|       |        &self,
  964|       |        wallet: &Arc<Wallet>,
  965|       |        source: Account,
  966|       |        account: Account,
  967|       |        amount: Amount,
  968|       |        work: u64,
  969|       |        generate_work: bool,
  970|       |        id: Option<String>,
  971|       |    ) -> anyhow::Result<SavedBlock>;
  972|       |
  973|       |    fn send_action2(
  974|       |        &self,
  975|       |        wallet_id: &WalletId,
  976|       |        source: Account,
  977|       |        account: Account,
  978|       |        amount: Amount,
  979|       |        work: u64,
  980|       |        generate_work: bool,
  981|       |        id: Option<String>,
  982|       |    ) -> Result<SavedBlock, WalletsError>;
  983|       |
  984|       |    fn change_action(
  985|       |        &self,
  986|       |        wallet: &Arc<Wallet>,
  987|       |        source: Account,
  988|       |        representative: PublicKey,
  989|       |        work: u64,
  990|       |        generate_work: bool,
  991|       |    ) -> Option<Block>;
  992|       |
  993|       |    fn change_action2(
  994|       |        &self,
  995|       |        wallet_id: &WalletId,
  996|       |        source: Account,
  997|       |        representative: PublicKey,
  998|       |        work: u64,
  999|       |        generate_work: bool,
 1000|       |    ) -> Option<Block>;
 1001|       |
 1002|       |    fn receive_action2(
 1003|       |        &self,
 1004|       |        wallet_id: &WalletId,
 1005|       |        send_hash: BlockHash,
 1006|       |        representative: PublicKey,
 1007|       |        amount: Amount,
 1008|       |        account: Account,
 1009|       |        work: u64,
 1010|       |        generate_work: bool,
 1011|       |    ) -> Result<Option<SavedBlock>, WalletsError>;
 1012|       |
 1013|       |    fn receive_action(
 1014|       |        &self,
 1015|       |        wallet: &Arc<Wallet>,
 1016|       |        send_hash: BlockHash,
 1017|       |        representative: PublicKey,
 1018|       |        amount: Amount,
 1019|       |        account: Account,
 1020|       |        work: u64,
 1021|       |        generate_work: bool,
 1022|       |    ) -> Option<SavedBlock>;
 1023|       |
 1024|       |    fn receive_async_wallet(
 1025|       |        &self,
 1026|       |        wallet: Arc<Wallet>,
 1027|       |        hash: BlockHash,
 1028|       |        representative: PublicKey,
 1029|       |        amount: Amount,
 1030|       |        account: Account,
 1031|       |        action: Box<dyn Fn(Option<SavedBlock>) + Send + Sync>,
 1032|       |        work: u64,
 1033|       |        generate_work: bool,
 1034|       |    );
 1035|       |
 1036|       |    fn receive_async(
 1037|       |        &self,
 1038|       |        wallet_id: WalletId,
 1039|       |        hash: BlockHash,
 1040|       |        representative: PublicKey,
 1041|       |        amount: Amount,
 1042|       |        account: Account,
 1043|       |        action: Box<dyn Fn(Option<SavedBlock>) + Send + Sync>,
 1044|       |        work: u64,
 1045|       |        generate_work: bool,
 1046|       |    ) -> Result<(), WalletsError>;
 1047|       |
 1048|       |    fn receive_sync(
 1049|       |        &self,
 1050|       |        wallet: Arc<Wallet>,
 1051|       |        block: BlockHash,
 1052|       |        representative: PublicKey,
 1053|       |        amount: Amount,
 1054|       |        account: Account,
 1055|       |        work: u64,
 1056|       |        generate_work: bool,
 1057|       |    ) -> Result<SavedBlock, ()>;
 1058|       |
 1059|       |    fn send_async_wallet(
 1060|       |        &self,
 1061|       |        wallet: Arc<Wallet>,
 1062|       |        source: Account,
 1063|       |        account: Account,
 1064|       |        amount: Amount,
 1065|       |        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1066|       |        work: u64,
 1067|       |        generate_work: bool,
 1068|       |        id: Option<String>,
 1069|       |    );
 1070|       |
 1071|       |    fn send_async(
 1072|       |        &self,
 1073|       |        wallet_id: WalletId,
 1074|       |        source: Account,
 1075|       |        account: Account,
 1076|       |        amount: Amount,
 1077|       |        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1078|       |        work: u64,
 1079|       |        generate_work: bool,
 1080|       |        id: Option<String>,
 1081|       |    ) -> Result<(), WalletsError>;
 1082|       |
 1083|       |    fn send_sync(
 1084|       |        &self,
 1085|       |        wallet_id: WalletId,
 1086|       |        source: Account,
 1087|       |        account: Account,
 1088|       |        amount: Amount,
 1089|       |        work: u64,
 1090|       |        generate_work: bool,
 1091|       |        id: Option<String>,
 1092|       |    ) -> BlockHash;
 1093|       |
 1094|       |    fn search_receivable(
 1095|       |        &self,
 1096|       |        wallet: &Arc<Wallet>,
 1097|       |        wallet_tx: &dyn Transaction,
 1098|       |    ) -> Result<(), ()>;
 1099|       |
 1100|       |    fn receive_confirmed(&self, hash: BlockHash, destinaton: Account);
 1101|       |    fn search_receivable_all(&self);
 1102|       |    fn search_receivable_wallet(&self, wallet_id: WalletId) -> Result<(), WalletsError>;
 1103|       |
 1104|       |    fn enter_password(&self, wallet_id: WalletId, password: &str) -> Result<(), WalletsError>;
 1105|       |
 1106|       |    fn enter_password_wallet(
 1107|       |        &self,
 1108|       |        wallet: &Arc<Wallet>,
 1109|       |        wallet_tx: &dyn Transaction,
 1110|       |        password: &str,
 1111|       |    ) -> Result<(), ()>;
 1112|       |
 1113|       |    fn enter_initial_password(&self, wallet: &Arc<Wallet>);
 1114|       |    fn create(&self, wallet_id: WalletId);
 1115|       |    fn change_async_wallet(
 1116|       |        &self,
 1117|       |        wallet: Arc<Wallet>,
 1118|       |        source: Account,
 1119|       |        representative: PublicKey,
 1120|       |        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1121|       |        work: u64,
 1122|       |        generate_work: bool,
 1123|       |    );
 1124|       |
 1125|       |    fn change_sync_wallet(
 1126|       |        &self,
 1127|       |        wallet: Arc<Wallet>,
 1128|       |        source: Account,
 1129|       |        representative: PublicKey,
 1130|       |    ) -> Result<(), ()>;
 1131|       |
 1132|       |    fn change_async(
 1133|       |        &self,
 1134|       |        wallet_id: WalletId,
 1135|       |        source: Account,
 1136|       |        representative: PublicKey,
 1137|       |        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1138|       |        work: u64,
 1139|       |        generate_work: bool,
 1140|       |    ) -> Result<(), WalletsError>;
 1141|       |
 1142|       |    fn set_representative(
 1143|       |        &self,
 1144|       |        wallet_id: WalletId,
 1145|       |        rep: PublicKey,
 1146|       |        update_existing_accounts: bool,
 1147|       |    ) -> Result<(), WalletsError>;
 1148|       |
 1149|       |    fn ensure_wallet_is_unlocked(&self, wallet_id: WalletId, password: &str) -> bool;
 1150|       |
 1151|       |    fn initialize2(&self);
 1152|       |}
 1153|       |
 1154|       |impl WalletsExt for Arc<Wallets> {
 1155|      0|    fn receive_action2(
 1156|      0|        &self,
 1157|      0|        wallet_id: &WalletId,
 1158|      0|        send_hash: BlockHash,
 1159|      0|        representative: PublicKey,
 1160|      0|        amount: Amount,
 1161|      0|        account: Account,
 1162|      0|        work: u64,
 1163|      0|        generate_work: bool,
 1164|      0|    ) -> Result<Option<SavedBlock>, WalletsError> {
 1165|      0|        let guard = self.mutex.lock().unwrap();
 1166|      0|        let wallet = Wallets::get_wallet(&guard, wallet_id)?;
 1167|      0|        let tx = self.env.tx_begin_read();
 1168|      0|        if !wallet.store.valid_password(&tx) {
 1169|      0|            return Err(WalletsError::WalletLocked);
 1170|      0|        }
 1171|      0|
 1172|      0|        if wallet.store.find(&tx, &account.into()).is_none() {
 1173|      0|            return Err(WalletsError::AccountNotFound);
 1174|      0|        }
 1175|      0|
 1176|      0|        Ok(self.receive_action(
 1177|      0|            wallet,
 1178|      0|            send_hash,
 1179|      0|            representative,
 1180|      0|            amount,
 1181|      0|            account,
 1182|      0|            work,
 1183|      0|            generate_work,
 1184|      0|        ))
 1185|      0|    }
 1186|       |
 1187|      0|    fn deterministic_insert(
 1188|      0|        &self,
 1189|      0|        wallet: &Arc<Wallet>,
 1190|      0|        tx: &mut LmdbWriteTransaction,
 1191|      0|        generate_work: bool,
 1192|      0|    ) -> PublicKey {
 1193|      0|        if !wallet.store.valid_password(tx) {
 1194|      0|            return PublicKey::zero();
 1195|      0|        }
 1196|      0|        let key = wallet.store.deterministic_insert(tx);
 1197|      0|
 1198|      0|        info!(account=%key.as_account().encode_account(), "Deterministically inserted new account");
 1199|       |
 1200|      0|        if generate_work {
 1201|      0|            self.work_ensure(wallet, key.into(), key.into());
 1202|      0|        }
 1203|      0|        let half_principal_weight = self.online_reps.lock().unwrap().minimum_principal_weight() / 2;
 1204|      0|        let mut reps = self.representative_wallets.lock().unwrap();
 1205|      0|        if reps.check_rep(key, half_principal_weight) {
 1206|      0|            info!(account=%key.as_account().encode_account(), "New account qualified as representative");
 1207|      0|            wallet.representatives.lock().unwrap().insert(key);
 1208|      0|        }
 1209|      0|        key
 1210|      0|    }
 1211|       |
 1212|      0|    fn deterministic_insert_at(
 1213|      0|        &self,
 1214|      0|        wallet_id: &WalletId,
 1215|      0|        index: u32,
 1216|      0|        generate_work: bool,
 1217|      0|    ) -> Result<PublicKey, WalletsError> {
 1218|      0|        let guard = self.mutex.lock().unwrap();
 1219|      0|        let wallet = Wallets::get_wallet(&guard, wallet_id)?;
 1220|      0|        let mut tx = self.env.tx_begin_write();
 1221|      0|        if !wallet.store.valid_password(&tx) {
 1222|      0|            return Err(WalletsError::WalletLocked);
 1223|      0|        }
 1224|      0|        let account = wallet.store.deterministic_insert_at(&mut tx, index);
 1225|      0|
 1226|      0|        info!(account=%account.as_account().encode_account(), "Deterministically inserted new account");
 1227|       |
 1228|      0|        if generate_work {
 1229|      0|            self.work_ensure(wallet, account.into(), account.into());
 1230|      0|        }
 1231|      0|        Ok(account)
 1232|      0|    }
 1233|       |
 1234|      0|    fn deterministic_insert2(
 1235|      0|        &self,
 1236|      0|        wallet_id: &WalletId,
 1237|      0|        generate_work: bool,
 1238|      0|    ) -> Result<PublicKey, WalletsError> {
 1239|      0|        let guard = self.mutex.lock().unwrap();
 1240|      0|        let wallet = Wallets::get_wallet(&guard, wallet_id)?;
 1241|      0|        let mut tx = self.env.tx_begin_write();
 1242|      0|        if !wallet.store.valid_password(&tx) {
 1243|      0|            return Err(WalletsError::WalletLocked);
 1244|      0|        }
 1245|      0|        Ok(self.deterministic_insert(wallet, &mut tx, generate_work))
 1246|      0|    }
 1247|       |
 1248|      0|    fn insert_adhoc(&self, wallet: &Arc<Wallet>, key: &RawKey, generate_work: bool) -> PublicKey {
 1249|      0|        let mut tx = self.env.tx_begin_write();
 1250|      0|        if !wallet.store.valid_password(&tx) {
 1251|      0|            return PublicKey::zero();
 1252|      0|        }
 1253|      0|        let key = wallet.store.insert_adhoc(&mut tx, key);
 1254|      0|        let block_tx = self.ledger.read_txn();
 1255|      0|        if generate_work {
 1256|      0|            self.work_ensure(
 1257|      0|                wallet,
 1258|      0|                key.into(),
 1259|      0|                self.ledger.latest_root(&block_tx, &key.into()),
 1260|      0|            );
 1261|      0|        }
 1262|      0|        let half_principal_weight = self.online_reps.lock().unwrap().minimum_principal_weight() / 2;
 1263|      0|        // Makes sure that the representatives container will
 1264|      0|        // be in sync with any added keys.
 1265|      0|        tx.commit();
 1266|      0|        let mut rep_guard = self.representative_wallets.lock().unwrap();
 1267|      0|        if rep_guard.check_rep(key, half_principal_weight) {
 1268|      0|            wallet.representatives.lock().unwrap().insert(key);
 1269|      0|        }
 1270|      0|        key
 1271|      0|    }
 1272|       |
 1273|      0|    fn insert_adhoc2(
 1274|      0|        &self,
 1275|      0|        wallet_id: &WalletId,
 1276|      0|        key: &RawKey,
 1277|      0|        generate_work: bool,
 1278|      0|    ) -> Result<PublicKey, WalletsError> {
 1279|      0|        let guard = self.mutex.lock().unwrap();
 1280|      0|        let wallet = Wallets::get_wallet(&guard, wallet_id)?;
 1281|      0|        let mut tx = self.env.tx_begin_read();
 1282|      0|        if !wallet.store.valid_password(&tx) {
 1283|      0|            return Err(WalletsError::WalletLocked);
 1284|      0|        }
 1285|      0|        tx.reset();
 1286|      0|        Ok(self.insert_adhoc(wallet, key, generate_work))
 1287|      0|    }
 1288|       |
 1289|      0|    fn work_ensure(&self, wallet: &Arc<Wallet>, account: Account, root: Root) {
 1290|      0|        let precache_delay = if self.network_params.network.is_dev_network() {
 1291|      0|            Duration::from_secs(1)
 1292|       |        } else {
 1293|      0|            Duration::from_secs(10)
 1294|       |        };
 1295|      0|        self.delayed_work.lock().unwrap().insert(account, root);
 1296|      0|        let self_clone = Arc::clone(self);
 1297|      0|        let wallet = Arc::clone(wallet);
 1298|      0|        self.workers.post_delayed(
 1299|      0|            precache_delay,
 1300|      0|            Box::new(move || {
 1301|      0|                let mut guard = self_clone.delayed_work.lock().unwrap();
 1302|      0|                if let Some(&existing) = guard.get(&account) {
 1303|      0|                    if existing == root {
 1304|      0|                        guard.remove(&account);
 1305|      0|                        let self_clone_2 = Arc::clone(&self_clone);
 1306|      0|                        self_clone.wallet_actions.queue_wallet_action(
 1307|      0|                            GENERATE_PRIORITY,
 1308|      0|                            wallet,
 1309|      0|                            Box::new(move |w| {
 1310|      0|                                self_clone_2.work_cache_blocking(&w, &account.into(), &root);
 1311|      0|                            }),
 1312|      0|                        );
 1313|      0|                    }
 1314|      0|                }
 1315|      0|            }),
 1316|      0|        );
 1317|      0|    }
 1318|       |
 1319|      0|    fn action_complete(
 1320|      0|        &self,
 1321|      0|        wallet: Arc<Wallet>,
 1322|      0|        mut block: Block,
 1323|      0|        account: Account,
 1324|      0|        generate_work: bool,
 1325|      0|        details: &BlockDetails,
 1326|      0|    ) -> anyhow::Result<SavedBlock> {
 1327|      0|        // Unschedule any work caching for this account
 1328|      0|        self.delayed_work.lock().unwrap().remove(&account);
 1329|      0|        let hash = block.hash();
 1330|      0|        let required_difficulty = self.network_params.work.threshold(details);
 1331|      0|        if self.network_params.work.difficulty_block(&block) < required_difficulty {
 1332|      0|            info!(
 1333|      0|                "Cached or provided work for block {} account {} is invalid, regenerating...",
 1334|      0|                block.hash(),
 1335|      0|                account.encode_account()
 1336|       |            );
 1337|      0|            self.distributed_work
 1338|      0|                .make_blocking_block(&mut block, required_difficulty)
 1339|      0|                .ok_or_else(|| anyhow!("no work generated"))?;
 1340|      0|        }
 1341|      0|        let arc_block = Arc::new(block.clone());
 1342|      0|        let saved_block = self
 1343|      0|            .block_processor
 1344|      0|            .add_blocking(arc_block.clone(), BlockSource::Local)?
 1345|      0|            .map_err(|s| anyhow!("block processor failed: {:?}", s))?;
 1346|       |
 1347|      0|        if generate_work {
 1348|      0|            // Pregenerate work for next block based on the block just created
 1349|      0|            self.work_ensure(&wallet, account, hash.into());
 1350|      0|        }
 1351|      0|        Ok(saved_block)
 1352|      0|    }
 1353|       |
 1354|      9|    fn ongoing_compute_reps(&self) {
 1355|      9|        self.compute_reps();
 1356|       |
 1357|       |        // Representation drifts quickly on the test network but very slowly on the live network
 1358|      9|        let compute_delay = if self.network_params.network.is_dev_network() {
 1359|      9|            Duration::from_millis(10)
 1360|      0|        } else if self.network_params.network.is_test_network() {
 1361|      0|            test_scan_wallet_reps_delay()
 1362|       |        } else {
 1363|      0|            Duration::from_secs(60 * 15)
 1364|       |        };
 1365|       |
 1366|      9|        let self_l = Arc::clone(self);
 1367|      9|        self.workers.post_delayed(
 1368|      9|            compute_delay,
 1369|      9|            Box::new(move || {
 1370|      6|                self_l.ongoing_compute_reps();
 1371|      9|            }),
 1372|      9|        );
 1373|      9|    }
 1374|       |
 1375|      0|    fn change_seed_wallet(
 1376|      0|        &self,
 1377|      0|        wallet: &Arc<Wallet>,
 1378|      0|        tx: &mut LmdbWriteTransaction,
 1379|      0|        prv_key: &RawKey,
 1380|      0|        mut count: u32,
 1381|      0|    ) -> PublicKey {
 1382|      0|        info!("Changing wallet seed");
 1383|      0|        wallet.store.set_seed(tx, prv_key);
 1384|      0|        let mut account = self.deterministic_insert(wallet, tx, true);
 1385|      0|        if count == 0 {
 1386|      0|            count = wallet.deterministic_check(tx, 0);
 1387|      0|            info!("Auto-detected {} accounts to generate", count);
 1388|      0|        }
 1389|      0|        for _ in 0..count {
 1390|      0|            // Disable work generation to prevent weak CPU nodes stuck
 1391|      0|            account = self.deterministic_insert(wallet, tx, false);
 1392|      0|        }
 1393|      0|        info!("Completed changing wallet seed and generating accounts");
 1394|      0|        account
 1395|      0|    }
 1396|       |
 1397|      0|    fn change_seed(
 1398|      0|        &self,
 1399|      0|        wallet_id: WalletId,
 1400|      0|        prv_key: &RawKey,
 1401|      0|        count: u32,
 1402|      0|    ) -> Result<(u32, Account), WalletsError> {
 1403|      0|        let guard = self.mutex.lock().unwrap();
 1404|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 1405|      0|        let mut tx = self.env.tx_begin_write();
 1406|      0|        if !wallet.store.valid_password(&tx) {
 1407|      0|            return Err(WalletsError::WalletLocked);
 1408|      0|        }
 1409|      0|        let first_account = self.change_seed_wallet(wallet, &mut tx, prv_key, count);
 1410|      0|        let restored_count = wallet.store.deterministic_index_get(&tx);
 1411|      0|        Ok((restored_count, first_account.into()))
 1412|      0|    }
 1413|       |
 1414|      0|    fn send_action2(
 1415|      0|        &self,
 1416|      0|        wallet_id: &WalletId,
 1417|      0|        source: Account,
 1418|      0|        account: Account,
 1419|      0|        amount: Amount,
 1420|      0|        work: u64,
 1421|      0|        generate_work: bool,
 1422|      0|        id: Option<String>,
 1423|      0|    ) -> Result<SavedBlock, WalletsError> {
 1424|      0|        let guard = self.mutex.lock().unwrap();
 1425|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 1426|      0|        self.send_action(wallet, source, account, amount, work, generate_work, id)
 1427|      0|            .map_err(|_| WalletsError::Generic)
 1428|      0|    }
 1429|       |
 1430|      0|    fn send_action(
 1431|      0|        &self,
 1432|      0|        wallet: &Arc<Wallet>,
 1433|      0|        source: Account,
 1434|      0|        account: Account,
 1435|      0|        amount: Amount,
 1436|      0|        work: u64,
 1437|      0|        generate_work: bool,
 1438|      0|        id: Option<String>,
 1439|      0|    ) -> anyhow::Result<SavedBlock> {
 1440|      0|        let result = match id {
 1441|      0|            Some(id) => {
 1442|      0|                let mut tx = self.env.tx_begin_write();
 1443|      0|                self.prepare_send_with_id(&mut tx, &id, wallet, source, account, amount, work)?
 1444|       |            }
 1445|       |            None => {
 1446|      0|                let tx = self.env.tx_begin_read();
 1447|      0|                self.prepare_send(&tx, wallet, source, account, amount, work)?
 1448|       |            }
 1449|       |        };
 1450|       |
 1451|      0|        match result {
 1452|      0|            PreparedSend::Cached(block) => Ok(block),
 1453|      0|            PreparedSend::New(block, details) => {
 1454|      0|                self.action_complete(Arc::clone(wallet), block, source, generate_work, &details)
 1455|       |            }
 1456|       |        }
 1457|      0|    }
 1458|       |
 1459|      0|    fn change_action(
 1460|      0|        &self,
 1461|      0|        wallet: &Arc<Wallet>,
 1462|      0|        source: Account,
 1463|      0|        representative: PublicKey,
 1464|      0|        mut work: u64,
 1465|      0|        generate_work: bool,
 1466|      0|    ) -> Option<Block> {
 1467|      0|        let mut epoch = Epoch::Epoch0;
 1468|      0|        let mut block = None;
 1469|      0|        {
 1470|      0|            let wallet_tx = self.env.tx_begin_read();
 1471|      0|            let block_tx = self.ledger.read_txn();
 1472|      0|            if !wallet.store.valid_password(&wallet_tx) {
 1473|      0|                warn!(
 1474|      0|                    "Changing representative for account {} failed, wallet locked",
 1475|      0|                    source.encode_account()
 1476|       |                );
 1477|      0|                return None;
 1478|      0|            }
 1479|      0|
 1480|      0|            let existing = wallet.store.find(&wallet_tx, &source.into());
 1481|      0|            if existing.is_some() && self.ledger.any().account_head(&block_tx, &source).is_some() {
 1482|      0|                info!(
 1483|      0|                    "Changing representative for account {} to {}",
 1484|      0|                    source.encode_account(),
 1485|      0|                    representative.as_account().encode_account()
 1486|       |                );
 1487|      0|                let info = self.ledger.account_info(&block_tx, &source).unwrap();
 1488|      0|                let prv = wallet.store.fetch(&wallet_tx, &source.into()).unwrap();
 1489|      0|                if work == 0 {
 1490|      0|                    work = wallet
 1491|      0|                        .store
 1492|      0|                        .work_get(&wallet_tx, &source.into())
 1493|      0|                        .unwrap_or_default();
 1494|      0|                }
 1495|      0|                let priv_key = PrivateKey::from(prv);
 1496|      0|                let state_block: Block = StateBlockArgs {
 1497|      0|                    key: &priv_key,
 1498|      0|                    previous: info.head,
 1499|      0|                    representative,
 1500|      0|                    balance: info.balance,
 1501|      0|                    link: Link::zero(),
 1502|      0|                    work,
 1503|      0|                }
 1504|      0|                .into();
 1505|      0|                block = Some(state_block);
 1506|      0|                epoch = info.epoch;
 1507|       |            } else {
 1508|      0|                warn!("Changing representative for account {} failed, wallet locked or account not found",
 1509|      0|                    source.encode_account());
 1510|       |            }
 1511|       |        }
 1512|       |
 1513|      0|        let block = block?;
 1514|       |
 1515|      0|        let details = BlockDetails::new(epoch, false, false, false);
 1516|      0|        self.action_complete(Arc::clone(&wallet), block, source, generate_work, &details)
 1517|      0|            .ok()
 1518|      0|            .map(|b| b.into())
 1519|      0|    }
 1520|       |
 1521|      0|    fn change_action2(
 1522|      0|        &self,
 1523|      0|        wallet_id: &WalletId,
 1524|      0|        source: Account,
 1525|      0|        representative: PublicKey,
 1526|      0|        work: u64,
 1527|      0|        generate_work: bool,
 1528|      0|    ) -> Option<Block> {
 1529|      0|        let guard = self.mutex.lock().unwrap();
 1530|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id).ok()?;
 1531|      0|        self.change_action(&wallet, source, representative, work, generate_work)
 1532|      0|    }
 1533|       |
 1534|      0|    fn receive_action(
 1535|      0|        &self,
 1536|      0|        wallet: &Arc<Wallet>,
 1537|      0|        send_hash: BlockHash,
 1538|      0|        representative: PublicKey,
 1539|      0|        amount: Amount,
 1540|      0|        account: Account,
 1541|      0|        mut work: u64,
 1542|      0|        generate_work: bool,
 1543|      0|    ) -> Option<SavedBlock> {
 1544|      0|        if amount < self.node_config.receive_minimum {
 1545|      0|            warn!(
 1546|      0|                "Not receiving block {} due to minimum receive threshold",
 1547|       |                send_hash
 1548|       |            );
 1549|      0|            return None;
 1550|      0|        }
 1551|      0|
 1552|      0|        let mut block = None;
 1553|      0|        let mut epoch = Epoch::Epoch0;
 1554|      0|        let block_tx = self.ledger.read_txn();
 1555|      0|        let wallet_tx = self.env.tx_begin_read();
 1556|      0|        if self
 1557|      0|            .ledger
 1558|      0|            .any()
 1559|      0|            .block_exists_or_pruned(&block_tx, &send_hash)
 1560|       |        {
 1561|      0|            if let Some(pending_info) = self
 1562|      0|                .ledger
 1563|      0|                .any()
 1564|      0|                .get_pending(&block_tx, &PendingKey::new(account, send_hash))
 1565|       |            {
 1566|      0|                if let Ok(prv) = wallet.store.fetch(&wallet_tx, &account.into()) {
 1567|      0|                    info!(
 1568|      0|                        "Receiving block {} from account {}, amount {}",
 1569|      0|                        send_hash,
 1570|      0|                        account.encode_account(),
 1571|      0|                        pending_info.amount.number()
 1572|       |                    );
 1573|      0|                    if work == 0 {
 1574|      0|                        work = wallet
 1575|      0|                            .store
 1576|      0|                            .work_get(&wallet_tx, &account.into())
 1577|      0|                            .unwrap_or_default();
 1578|      0|                    }
 1579|      0|                    let priv_key = PrivateKey::from(prv);
 1580|      0|                    if let Some(info) = self.ledger.account_info(&block_tx, &account) {
 1581|      0|                        block = Some(
 1582|      0|                            StateBlockArgs {
 1583|      0|                                key: &priv_key,
 1584|      0|                                previous: info.head,
 1585|      0|                                representative: info.representative,
 1586|      0|                                balance: info.balance + pending_info.amount,
 1587|      0|                                link: send_hash.into(),
 1588|      0|                                work,
 1589|      0|                            }
 1590|      0|                            .into(),
 1591|      0|                        );
 1592|      0|                        epoch = std::cmp::max(info.epoch, pending_info.epoch);
 1593|      0|                    } else {
 1594|      0|                        block = Some(
 1595|      0|                            StateBlockArgs {
 1596|      0|                                key: &priv_key,
 1597|      0|                                previous: BlockHash::zero(),
 1598|      0|                                representative,
 1599|      0|                                balance: pending_info.amount,
 1600|      0|                                link: send_hash.into(),
 1601|      0|                                work,
 1602|      0|                            }
 1603|      0|                            .into(),
 1604|      0|                        );
 1605|      0|                        epoch = pending_info.epoch;
 1606|      0|                    }
 1607|       |                } else {
 1608|      0|                    warn!(
 1609|      0|                        "Unable to receive, wallet locked, block {} to account: {}",
 1610|      0|                        send_hash,
 1611|      0|                        account.encode_account()
 1612|       |                    );
 1613|       |                }
 1614|       |            } else {
 1615|       |                // Ledger doesn't have this marked as available to receive anymore
 1616|      0|                warn!("Not receiving block {}, block already received", send_hash);
 1617|       |            }
 1618|       |        } else {
 1619|       |            // Ledger doesn't have this block anymore.
 1620|      0|            warn!(
 1621|      0|                "Not receiving block {}, block no longer exists or pruned",
 1622|       |                send_hash
 1623|       |            );
 1624|       |        }
 1625|       |
 1626|      0|        let block = block?;
 1627|      0|        let details = BlockDetails::new(epoch, false, true, false);
 1628|      0|        self.action_complete(Arc::clone(wallet), block, account, generate_work, &details)
 1629|      0|            .ok()
 1630|      0|    }
 1631|       |
 1632|      0|    fn receive_async_wallet(
 1633|      0|        &self,
 1634|      0|        wallet: Arc<Wallet>,
 1635|      0|        hash: BlockHash,
 1636|      0|        representative: PublicKey,
 1637|      0|        amount: Amount,
 1638|      0|        account: Account,
 1639|      0|        action: Box<dyn Fn(Option<SavedBlock>) + Send + Sync>,
 1640|      0|        work: u64,
 1641|      0|        generate_work: bool,
 1642|      0|    ) {
 1643|      0|        let self_l = Arc::clone(self);
 1644|      0|        self.wallet_actions.queue_wallet_action(
 1645|      0|            amount,
 1646|      0|            wallet,
 1647|      0|            Box::new(move |wallet| {
 1648|      0|                let block = self_l.receive_action(
 1649|      0|                    &wallet,
 1650|      0|                    hash,
 1651|      0|                    representative,
 1652|      0|                    amount,
 1653|      0|                    account,
 1654|      0|                    work,
 1655|      0|                    generate_work,
 1656|      0|                );
 1657|      0|                action(block);
 1658|      0|            }),
 1659|      0|        );
 1660|      0|    }
 1661|       |
 1662|      0|    fn receive_async(
 1663|      0|        &self,
 1664|      0|        wallet_id: WalletId,
 1665|      0|        hash: BlockHash,
 1666|      0|        representative: PublicKey,
 1667|      0|        amount: Amount,
 1668|      0|        account: Account,
 1669|      0|        action: Box<dyn Fn(Option<SavedBlock>) + Send + Sync>,
 1670|      0|        work: u64,
 1671|      0|        generate_work: bool,
 1672|      0|    ) -> Result<(), WalletsError> {
 1673|      0|        let guard = self.mutex.lock().unwrap();
 1674|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 1675|      0|        let tx = self.env.tx_begin_write();
 1676|      0|        if !wallet.store.valid_password(&tx) {
 1677|      0|            return Err(WalletsError::WalletLocked);
 1678|      0|        }
 1679|      0|
 1680|      0|        if wallet.store.find(&tx, &account.into()).is_none() {
 1681|      0|            return Err(WalletsError::AccountNotFound);
 1682|      0|        }
 1683|      0|
 1684|      0|        self.receive_async_wallet(
 1685|      0|            Arc::clone(wallet),
 1686|      0|            hash,
 1687|      0|            representative,
 1688|      0|            amount,
 1689|      0|            account,
 1690|      0|            action,
 1691|      0|            work,
 1692|      0|            generate_work,
 1693|      0|        );
 1694|      0|        Ok(())
 1695|      0|    }
 1696|       |
 1697|      0|    fn receive_sync(
 1698|      0|        &self,
 1699|      0|        wallet: Arc<Wallet>,
 1700|      0|        block_hash: BlockHash,
 1701|      0|        representative: PublicKey,
 1702|      0|        amount: Amount,
 1703|      0|        account: Account,
 1704|      0|        work: u64,
 1705|      0|        generate_work: bool,
 1706|      0|    ) -> Result<SavedBlock, ()> {
 1707|      0|        let result = Arc::new((Condvar::new(), Mutex::new((false, None)))); // done, result
 1708|      0|        let result_clone = Arc::clone(&result);
 1709|      0|        self.receive_async_wallet(
 1710|      0|            wallet,
 1711|      0|            block_hash,
 1712|      0|            representative,
 1713|      0|            amount,
 1714|      0|            account,
 1715|      0|            Box::new(move |block| {
 1716|      0|                *result_clone.1.lock().unwrap() = (true, block.clone());
 1717|      0|                result_clone.0.notify_all();
 1718|      0|            }),
 1719|      0|            work,
 1720|      0|            generate_work,
 1721|      0|        );
 1722|      0|        let mut guard = result.1.lock().unwrap();
 1723|      0|        guard = result.0.wait_while(guard, |i| !i.0).unwrap();
 1724|      0|        if let Some(block) = guard.1.clone() {
 1725|      0|            Ok(block)
 1726|       |        } else {
 1727|      0|            Err(())
 1728|       |        }
 1729|      0|    }
 1730|       |
 1731|      0|    fn send_async_wallet(
 1732|      0|        &self,
 1733|      0|        wallet: Arc<Wallet>,
 1734|      0|        source: Account,
 1735|      0|        account: Account,
 1736|      0|        amount: Amount,
 1737|      0|        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1738|      0|        work: u64,
 1739|      0|        generate_work: bool,
 1740|      0|        id: Option<String>,
 1741|      0|    ) {
 1742|      0|        let self_l = Arc::clone(self);
 1743|      0|        self.wallet_actions.queue_wallet_action(
 1744|      0|            HIGH_PRIORITY,
 1745|      0|            wallet,
 1746|      0|            Box::new(move |wallet| {
 1747|      0|                let block = self_l
 1748|      0|                    .send_action(
 1749|      0|                        &wallet,
 1750|      0|                        source,
 1751|      0|                        account,
 1752|      0|                        amount,
 1753|      0|                        work,
 1754|      0|                        generate_work,
 1755|      0|                        id.clone(),
 1756|      0|                    )
 1757|      0|                    .ok()
 1758|      0|                    .map(|b| b.into());
 1759|      0|                action(block);
 1760|      0|            }),
 1761|      0|        );
 1762|      0|    }
 1763|       |
 1764|      0|    fn send_async(
 1765|      0|        &self,
 1766|      0|        wallet_id: WalletId,
 1767|      0|        source: Account,
 1768|      0|        account: Account,
 1769|      0|        amount: Amount,
 1770|      0|        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 1771|      0|        work: u64,
 1772|      0|        generate_work: bool,
 1773|      0|        id: Option<String>,
 1774|      0|    ) -> Result<(), WalletsError> {
 1775|      0|        let guard = self.mutex.lock().unwrap();
 1776|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 1777|      0|        let tx = self.env.tx_begin_write();
 1778|      0|        if !wallet.store.valid_password(&tx) {
 1779|      0|            return Err(WalletsError::WalletLocked);
 1780|      0|        }
 1781|      0|        if wallet.store.find(&tx, &source.into()).is_none() {
 1782|      0|            return Err(WalletsError::AccountNotFound);
 1783|      0|        }
 1784|      0|        self.send_async_wallet(
 1785|      0|            Arc::clone(wallet),
 1786|      0|            source,
 1787|      0|            account,
 1788|      0|            amount,
 1789|      0|            action,
 1790|      0|            work,
 1791|      0|            generate_work,
 1792|      0|            id,
 1793|      0|        );
 1794|      0|
 1795|      0|        Ok(())
 1796|      0|    }
 1797|       |
 1798|      0|    fn send_sync(
 1799|      0|        &self,
 1800|      0|        wallet_id: WalletId,
 1801|      0|        source: Account,
 1802|      0|        account: Account,
 1803|      0|        amount: Amount,
 1804|      0|        work: u64,
 1805|      0|        generate_work: bool,
 1806|      0|        id: Option<String>,
 1807|      0|    ) -> BlockHash {
 1808|      0|        let guard = self.mutex.lock().unwrap();
 1809|      0|        let Some(wallet) = guard.get(&wallet_id) else {
 1810|      0|            panic!("wallet not found")
 1811|       |        };
 1812|       |
 1813|      0|        let result = Arc::new((Condvar::new(), Mutex::new((false, BlockHash::zero())))); // done, result
 1814|      0|        let result_clone = Arc::clone(&result);
 1815|      0|
 1816|      0|        self.send_async_wallet(
 1817|      0|            Arc::clone(wallet),
 1818|      0|            source,
 1819|      0|            account,
 1820|      0|            amount,
 1821|      0|            Box::new(move |block| {
 1822|      0|                *result_clone.1.lock().unwrap() =
 1823|      0|                    (true, block.map(|b| b.hash()).unwrap_or_default());
 1824|      0|                result_clone.0.notify_all();
 1825|      0|            }),
 1826|      0|            work,
 1827|      0|            generate_work,
 1828|      0|            id,
 1829|      0|        );
 1830|      0|
 1831|      0|        let mut guard = result.1.lock().unwrap();
 1832|      0|        guard = result.0.wait_while(guard, |i| !i.0).unwrap();
 1833|      0|        guard.1
 1834|      0|    }
 1835|       |
 1836|      0|    fn search_receivable(
 1837|      0|        &self,
 1838|      0|        wallet: &Arc<Wallet>,
 1839|      0|        wallet_tx: &dyn Transaction,
 1840|      0|    ) -> Result<(), ()> {
 1841|      0|        if !wallet.store.valid_password(wallet_tx) {
 1842|      0|            info!("Unable to search receivable blocks, wallet is locked");
 1843|      0|            return Err(());
 1844|      0|        }
 1845|      0|
 1846|      0|        info!("Beginning receivable block search");
 1847|       |
 1848|      0|        for (account, wallet_value) in wallet.store.iter(wallet_tx) {
 1849|      0|            let block_tx = self.ledger.read_txn();
 1850|      0|            // Don't search pending for watch-only accounts
 1851|      0|            if !wallet_value.key.is_zero() {
 1852|      0|                for (key, info) in self.ledger.any().account_receivable_upper_bound(
 1853|      0|                    &block_tx,
 1854|      0|                    account.into(),
 1855|      0|                    BlockHash::zero(),
 1856|      0|                ) {
 1857|      0|                    let hash = key.send_block_hash;
 1858|      0|                    let amount = info.amount;
 1859|      0|                    if self.node_config.receive_minimum <= amount {
 1860|      0|                        info!(
 1861|      0|                            "Found a receivable block {} for account {}",
 1862|      0|                            hash,
 1863|      0|                            info.source.encode_account()
 1864|       |                        );
 1865|      0|                        if self
 1866|      0|                            .ledger
 1867|      0|                            .confirmed()
 1868|      0|                            .block_exists_or_pruned(&block_tx, &hash)
 1869|      0|                        {
 1870|      0|                            let representative = wallet.store.representative(wallet_tx);
 1871|      0|                            // Receive confirmed block
 1872|      0|                            self.receive_async_wallet(
 1873|      0|                                Arc::clone(wallet),
 1874|      0|                                hash,
 1875|      0|                                representative,
 1876|      0|                                amount,
 1877|      0|                                account.into(),
 1878|      0|                                Box::new(|_| {}),
 1879|      0|                                0,
 1880|      0|                                true,
 1881|      0|                            );
 1882|      0|                        } else if !self.confirming_set.contains(&hash) {
 1883|      0|                            let block = self.ledger.any().get_block(&block_tx, &hash);
 1884|      0|                            if let Some(block) = block {
 1885|       |                                // Request confirmation for block which is not being processed yet
 1886|      0|                                let guard = self.start_election.lock().unwrap();
 1887|      0|                                if let Some(callback) = guard.as_ref() {
 1888|      0|                                    callback(block);
 1889|      0|                                }
 1890|      0|                            }
 1891|      0|                        }
 1892|      0|                    }
 1893|       |                }
 1894|      0|            }
 1895|       |        }
 1896|       |
 1897|      0|        info!("Receivable block search phase completed");
 1898|      0|        Ok(())
 1899|      0|    }
 1900|       |
 1901|      0|    fn receive_confirmed(&self, hash: BlockHash, destination: Account) {
 1902|      0|        //std::unordered_map<nano::wallet_id, std::shared_ptr<nano::wallet>> wallets_l;
 1903|      0|        let (wallet_tx, wallets) = {
 1904|      0|            let guard = self.mutex.lock().unwrap();
 1905|      0|            (self.env.tx_begin_read(), guard.clone())
 1906|      0|        };
 1907|       |
 1908|      0|        for (_id, wallet) in wallets {
 1909|      0|            if wallet.store.exists(&wallet_tx, &destination.into()) {
 1910|      0|                let representative = wallet.store.representative(&wallet_tx);
 1911|      0|                let pending = self
 1912|      0|                    .ledger
 1913|      0|                    .any()
 1914|      0|                    .get_pending(&self.ledger.read_txn(), &PendingKey::new(destination, hash));
 1915|      0|                if let Some(pending) = pending {
 1916|      0|                    let amount = pending.amount;
 1917|      0|                    self.receive_async_wallet(
 1918|      0|                        wallet,
 1919|      0|                        hash,
 1920|      0|                        representative,
 1921|      0|                        amount,
 1922|      0|                        destination,
 1923|      0|                        Box::new(|_| {}),
 1924|      0|                        0,
 1925|      0|                        true,
 1926|      0|                    );
 1927|      0|                } else {
 1928|      0|                    if !self
 1929|      0|                        .ledger
 1930|      0|                        .any()
 1931|      0|                        .block_exists_or_pruned(&self.ledger.read_txn(), &hash)
 1932|       |                    {
 1933|      0|                        warn!("Confirmed block is missing:  {}", hash);
 1934|      0|                        debug_assert!(false);
 1935|       |                    } else {
 1936|      0|                        warn!("Block %1% has already been received: {}", hash);
 1937|       |                    }
 1938|       |                }
 1939|      0|            }
 1940|       |        }
 1941|      0|    }
 1942|       |
 1943|      3|    fn search_receivable_all(&self) {
 1944|      3|        let wallets = self.mutex.lock().unwrap().clone();
 1945|      3|        let wallet_tx = self.env.tx_begin_read();
 1946|      3|        for (_, wallet) in wallets {
                              ^0
 1947|      0|            let _ = self.search_receivable(&wallet, &wallet_tx);
 1948|      0|        }
 1949|      3|    }
 1950|       |
 1951|      0|    fn search_receivable_wallet(&self, wallet_id: WalletId) -> Result<(), WalletsError> {
 1952|      0|        let guard = self.mutex.lock().unwrap();
 1953|      0|        if let Some(wallet) = guard.get(&wallet_id) {
 1954|      0|            let tx = self.env.tx_begin_read();
 1955|      0|            if wallet.store.valid_password(&tx) {
 1956|      0|                let _ = self.search_receivable(wallet, &tx);
 1957|      0|                Ok(())
 1958|       |            } else {
 1959|      0|                Err(WalletsError::WalletLocked)
 1960|       |            }
 1961|       |        } else {
 1962|      0|            Err(WalletsError::WalletNotFound)
 1963|       |        }
 1964|      0|    }
 1965|       |
 1966|      0|    fn enter_password(&self, wallet_id: WalletId, password: &str) -> Result<(), WalletsError> {
 1967|      0|        let guard = self.mutex.lock().unwrap();
 1968|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 1969|      0|        let tx = self.env.tx_begin_write();
 1970|      0|        let result = self
 1971|      0|            .enter_password_wallet(wallet, &tx, password)
 1972|      0|            .map_err(|_| WalletsError::InvalidPassword);
 1973|      0|        if result.is_ok() {
 1974|      0|            info!("Wallet unlocked");
 1975|       |        } else {
 1976|      0|            warn!("Invalid password, wallet locked");
 1977|       |        }
 1978|      0|        result
 1979|      0|    }
 1980|       |
 1981|      0|    fn enter_password_wallet(
 1982|      0|        &self,
 1983|      0|        wallet: &Arc<Wallet>,
 1984|      0|        wallet_tx: &dyn Transaction,
 1985|      0|        password: &str,
 1986|      0|    ) -> Result<(), ()> {
 1987|      0|        if !wallet.store.attempt_password(wallet_tx, password) {
 1988|      0|            warn!("Invalid password, wallet locked");
 1989|      0|            Err(())
 1990|       |        } else {
 1991|      0|            info!("Wallet unlocked");
 1992|      0|            let self_l = Arc::clone(self);
 1993|      0|            self.wallet_actions.queue_wallet_action(
 1994|      0|                HIGH_PRIORITY,
 1995|      0|                Arc::clone(wallet),
 1996|      0|                Box::new(move |wallet| {
 1997|      0|                    // Wallets must survive node lifetime
 1998|      0|                    let tx = self_l.env.tx_begin_read();
 1999|      0|                    let _ = self_l.search_receivable(&wallet, &tx);
 2000|      0|                }),
 2001|      0|            );
 2002|      0|            Ok(())
 2003|       |        }
 2004|      0|    }
 2005|       |
 2006|      0|    fn enter_initial_password(&self, wallet: &Arc<Wallet>) {
 2007|      0|        let password = wallet.store.password();
 2008|      0|        if password.is_zero() {
 2009|      0|            let mut tx = self.env.tx_begin_write();
 2010|      0|            if wallet.store.valid_password(&tx) {
 2011|      0|                // Newly created wallets have a zero key
 2012|      0|                let _ = wallet.store.rekey(&mut tx, "");
 2013|      0|            } else {
 2014|      0|                let _ = self.enter_password_wallet(wallet, &tx, "");
 2015|      0|            }
 2016|      0|        }
 2017|      0|    }
 2018|       |
 2019|      0|    fn create(&self, wallet_id: WalletId) {
 2020|      0|        let mut guard = self.mutex.lock().unwrap();
 2021|      0|        debug_assert!(!guard.contains_key(&wallet_id));
 2022|      0|        let wallet = {
 2023|      0|            let mut tx = self.env.tx_begin_write();
 2024|      0|            let Ok(wallet) = Wallet::new(
 2025|      0|                Arc::clone(&self.ledger),
 2026|      0|                self.work_thresholds.clone(),
 2027|      0|                &mut tx,
 2028|      0|                self.node_config.password_fanout as usize,
 2029|      0|                self.kdf.clone(),
 2030|      0|                self.node_config.random_representative(),
 2031|      0|                &PathBuf::from(wallet_id.to_string()),
 2032|      0|            ) else {
 2033|      0|                return;
 2034|       |            };
 2035|      0|            Arc::new(wallet)
 2036|      0|        };
 2037|      0|        guard.insert(wallet_id, Arc::clone(&wallet));
 2038|      0|        self.enter_initial_password(&wallet);
 2039|      0|    }
 2040|       |
 2041|      0|    fn change_async_wallet(
 2042|      0|        &self,
 2043|      0|        wallet: Arc<Wallet>,
 2044|      0|        source: Account,
 2045|      0|        representative: PublicKey,
 2046|      0|        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 2047|      0|        work: u64,
 2048|      0|        generate_work: bool,
 2049|      0|    ) {
 2050|      0|        let self_l = Arc::clone(self);
 2051|      0|        self.wallet_actions.queue_wallet_action(
 2052|      0|            HIGH_PRIORITY,
 2053|      0|            wallet,
 2054|      0|            Box::new(move |wallet| {
 2055|      0|                let block =
 2056|      0|                    self_l.change_action(&wallet, source, representative, work, generate_work);
 2057|      0|                action(block);
 2058|      0|            }),
 2059|      0|        );
 2060|      0|    }
 2061|       |
 2062|      0|    fn change_sync_wallet(
 2063|      0|        &self,
 2064|      0|        wallet: Arc<Wallet>,
 2065|      0|        source: Account,
 2066|      0|        representative: PublicKey,
 2067|      0|    ) -> Result<(), ()> {
 2068|      0|        let result = Arc::new((Condvar::new(), Mutex::new((false, false)))); // done, result
 2069|      0|        let result_clone = Arc::clone(&result);
 2070|      0|        self.change_async_wallet(
 2071|      0|            wallet,
 2072|      0|            source,
 2073|      0|            representative,
 2074|      0|            Box::new(move |block| {
 2075|      0|                *result_clone.1.lock().unwrap() = (true, block.is_some());
 2076|      0|                result_clone.0.notify_all();
 2077|      0|            }),
 2078|      0|            0,
 2079|      0|            true,
 2080|      0|        );
 2081|      0|        let mut guard = result.1.lock().unwrap();
 2082|      0|        guard = result.0.wait_while(guard, |i| !i.0).unwrap();
 2083|      0|        if guard.1 {
 2084|      0|            Ok(())
 2085|       |        } else {
 2086|      0|            Err(())
 2087|       |        }
 2088|      0|    }
 2089|       |
 2090|      0|    fn change_async(
 2091|      0|        &self,
 2092|      0|        wallet_id: WalletId,
 2093|      0|        source: Account,
 2094|      0|        representative: PublicKey,
 2095|      0|        action: Box<dyn Fn(Option<Block>) + Send + Sync>,
 2096|      0|        work: u64,
 2097|      0|        generate_work: bool,
 2098|      0|    ) -> Result<(), WalletsError> {
 2099|      0|        let guard = self.mutex.lock().unwrap();
 2100|      0|        let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 2101|      0|        let tx = self.env.tx_begin_write();
 2102|      0|        if !wallet.store.valid_password(&tx) {
 2103|      0|            return Err(WalletsError::WalletLocked);
 2104|      0|        }
 2105|      0|
 2106|      0|        if wallet.store.find(&tx, &source.into()).is_none() {
 2107|      0|            return Err(WalletsError::AccountNotFound);
 2108|      0|        }
 2109|      0|
 2110|      0|        self.change_async_wallet(
 2111|      0|            Arc::clone(wallet),
 2112|      0|            source,
 2113|      0|            representative,
 2114|      0|            action,
 2115|      0|            work,
 2116|      0|            generate_work,
 2117|      0|        );
 2118|      0|        Ok(())
 2119|      0|    }
 2120|       |
 2121|      0|    fn set_representative(
 2122|      0|        &self,
 2123|      0|        wallet_id: WalletId,
 2124|      0|        rep: PublicKey,
 2125|      0|        update_existing_accounts: bool,
 2126|      0|    ) -> Result<(), WalletsError> {
 2127|      0|        let mut accounts = Vec::new();
 2128|      0|        {
 2129|      0|            let guard = self.mutex.lock().unwrap();
 2130|      0|            let wallet = Wallets::get_wallet(&guard, &wallet_id)?;
 2131|       |
 2132|       |            {
 2133|      0|                let mut tx = self.env.tx_begin_write();
 2134|      0|                if update_existing_accounts && !wallet.store.valid_password(&tx) {
 2135|      0|                    return Err(WalletsError::WalletLocked);
 2136|      0|                }
 2137|      0|
 2138|      0|                wallet.store.representative_set(&mut tx, &rep);
 2139|      0|            }
 2140|      0|
 2141|      0|            // Change representative for all wallet accounts
 2142|      0|            if update_existing_accounts {
 2143|      0|                let tx = self.env.tx_begin_read();
 2144|      0|                let block_tx = self.ledger.read_txn();
 2145|      0|                for (account, _) in wallet.store.iter(&tx) {
 2146|      0|                    if let Some(info) = self.ledger.account_info(&block_tx, &account.into()) {
 2147|      0|                        if info.representative != rep {
 2148|      0|                            accounts.push(account);
 2149|      0|                        }
 2150|      0|                    }
 2151|       |                }
 2152|      0|            }
 2153|       |        }
 2154|       |
 2155|      0|        for account in accounts {
 2156|      0|            self.change_async(wallet_id, account.into(), rep, Box::new(|_| {}), 0, false)?;
 2157|       |        }
 2158|       |
 2159|      0|        Ok(())
 2160|      0|    }
 2161|       |
 2162|      0|    fn ensure_wallet_is_unlocked(&self, wallet_id: WalletId, password: &str) -> bool {
 2163|      0|        let guard = self.mutex.lock().unwrap();
 2164|      0|        let Some(existing) = guard.get(&wallet_id) else {
 2165|      0|            return false;
 2166|       |        };
 2167|      0|        let tx = self.env.tx_begin_write();
 2168|      0|        let mut valid = existing.store.valid_password(&tx);
 2169|      0|        if !valid {
 2170|      0|            valid = self.enter_password_wallet(existing, &tx, password).is_ok();
 2171|      0|        }
 2172|       |
 2173|      0|        valid
 2174|      0|    }
 2175|       |
 2176|      3|    fn initialize2(&self) {
 2177|      3|        {
 2178|      3|            let guard = self.mutex.lock().unwrap();
 2179|      3|            for (_, wallet) in guard.iter() {
                                  ^0
 2180|      0|                self.enter_initial_password(wallet);
 2181|      0|            }
 2182|       |        }
 2183|      3|        if self.node_config.enable_voting {
 2184|      3|            self.ongoing_compute_reps();
 2185|      3|        }
                       ^0
 2186|      3|    }
 2187|       |}
 2188|       |
 2189|      0|fn test_scan_wallet_reps_delay() -> Duration {
 2190|      0|    let test_env = get_env_or_default_string("NANO_TEST_WALLET_SCAN_REPS_DELAY", "900000"); // 15 minutes by default
 2191|      0|    Duration::from_millis(test_env.parse().unwrap())
 2192|      0|}

/home/gustav/code/nano/rsnano-node/node/src/work/distributed_work_factory.rs:
    1|       |use rsnano_core::{
    2|       |    to_hex_string,
    3|       |    work::{WorkPool, WorkPoolImpl},
    4|       |    Account, Block, Root,
    5|       |};
    6|       |use serde::{Deserialize, Serialize};
    7|       |use std::sync::Arc;
    8|       |use tokio::sync::oneshot;
    9|       |
   10|       |#[derive(Serialize)]
   11|       |pub struct HttpWorkRequest {
   12|       |    action: &'static str,
   13|       |    hash: String,
   14|       |    difficulty: String,
   15|       |    #[serde(skip_serializing_if = "Option::is_none")]
   16|       |    account: Option<String>,
   17|       |}
   18|       |
   19|       |impl HttpWorkRequest {
   20|      0|    pub fn new(root: Root, difficulty: u64, account: Option<Account>) -> Self {
   21|      0|        Self {
   22|      0|            action: "work_generate",
   23|      0|            hash: root.to_string(),
   24|      0|            difficulty: to_hex_string(difficulty),
   25|      0|            account: account.map(|a| a.encode_account()),
   26|      0|        }
   27|      0|    }
   28|       |}
   29|       |
   30|      0|#[derive(Serialize, Deserialize)]
   31|       |pub struct HttpWorkResponse {
   32|       |    work: String,
   33|       |}
   34|       |
   35|       |#[derive(Clone)]
   36|       |pub struct WorkRequest {
   37|       |    pub root: Root,
   38|       |    pub difficulty: u64,
   39|       |    pub account: Option<Account>,
   40|       |    pub peers: Vec<(String, u16)>,
   41|       |}
   42|       |
   43|       |impl WorkRequest {
   44|      1|    pub fn new_test_instance() -> Self {
   45|      1|        Self {
   46|      1|            root: Root::from(100),
   47|      1|            difficulty: 42,
   48|      1|            account: Some(Account::from(200)),
   49|      1|            peers: vec![("127.0.0.1".to_string(), 9999)],
   50|      1|        }
   51|      1|    }
   52|       |}
   53|       |
   54|       |pub struct DistributedWorkFactory {
   55|       |    work_pool: Arc<WorkPoolImpl>,
   56|       |    pub tokio: tokio::runtime::Handle,
   57|       |}
   58|       |
   59|       |impl DistributedWorkFactory {
   60|      4|    pub fn new(work_pool: Arc<WorkPoolImpl>, tokio: tokio::runtime::Handle) -> Self {
   61|      4|        Self { work_pool, tokio }
   62|      4|    }
   63|       |
   64|      0|    pub fn make_blocking_block(&self, block: &mut Block, difficulty: u64) -> Option<u64> {
   65|      0|        let work = self.tokio.block_on(self.generate_work(WorkRequest {
   66|      0|            root: block.root(),
   67|      0|            difficulty,
   68|      0|            account: None,
   69|      0|            peers: Vec::new(),
   70|      0|        }));
   71|       |
   72|      0|        if let Some(work) = work {
   73|      0|            block.set_work(work);
   74|      0|        }
   75|       |
   76|      0|        work
   77|      0|    }
   78|       |
   79|      0|    pub fn make_blocking(
   80|      0|        &self,
   81|      0|        root: Root,
   82|      0|        difficulty: u64,
   83|      0|        account: Option<Account>,
   84|      0|    ) -> Option<u64> {
   85|      0|        self.tokio.block_on(self.generate_work(WorkRequest {
   86|      0|            root,
   87|      0|            difficulty,
   88|      0|            account,
   89|      0|            peers: Vec::new(),
   90|      0|        }))
   91|      0|    }
   92|       |
   93|      0|    pub async fn make(&self, root: Root, difficulty: u64, account: Option<Account>) -> Option<u64> {
   94|      0|        self.generate_work(WorkRequest {
   95|      0|            root,
   96|      0|            difficulty,
   97|      0|            account,
   98|      0|            peers: Vec::new(),
   99|      0|        })
  100|      0|        .await
  101|      0|    }
  102|       |
  103|      1|    async fn generate_work(&self, request: WorkRequest) -> Option<u64> {
  104|      1|        self.generate_in_local_work_pool(request.root, request.difficulty)
  105|      1|            .await
  106|      1|    }
  107|       |
  108|      1|    async fn generate_in_local_work_pool(&self, root: Root, difficulty: u64) -> Option<u64> {
  109|      1|        let (tx, rx) = oneshot::channel::<Option<u64>>();
  110|      1|        self.work_pool.generate_async(
  111|      1|            root,
  112|      1|            difficulty,
  113|      1|            Some(Box::new(move |work| {
  114|      1|                tx.send(work).unwrap();
  115|      1|            })),
  116|      1|        );
  117|      1|        rx.await.ok()?
                                   ^0
  118|      1|    }
  119|       |
  120|      0|    pub fn cancel(&self, root: Root) {
  121|      0|        self.work_pool.cancel(&root);
  122|      0|    }
  123|       |
  124|      3|    pub fn work_generation_enabled(&self) -> bool {
  125|      3|        self.work_pool.work_generation_enabled()
  126|      3|    }
  127|       |
  128|      3|    pub fn stop(&self) {
  129|      3|        //TODO
  130|      3|    }
  131|       |}
  132|       |
  133|       |#[cfg(test)]
  134|       |mod tests {
  135|       |    use super::*;
  136|       |    use rsnano_core::work::WorkPoolImpl;
  137|       |    use std::sync::Arc;
  138|       |
  139|       |    #[tokio::test]
  140|      1|    async fn use_local_work_factor_when_no_peers_given() {
  141|      1|        let expected_work = 12345;
  142|      1|        let work_pool = Arc::new(WorkPoolImpl::new_null(expected_work));
  143|      1|        let work_factory =
  144|      1|            DistributedWorkFactory::new(work_pool, tokio::runtime::Handle::current());
  145|      1|
  146|      1|        let request = WorkRequest {
  147|      1|            peers: vec![],
  148|      1|            ..WorkRequest::new_test_instance()
  149|      1|        };
  150|      1|
  151|      1|        let work = work_factory.generate_work(request.clone()).await;
  152|      1|
  153|      1|        assert_eq!(work, Some(expected_work));
  154|      1|    }
  155|       |
  156|       |    // TODO:
  157|       |    // Backoff + Workrequest
  158|       |    // Cancel
  159|       |    // Local work
  160|       |    // resolve hostnames
  161|       |    // multiple peers
  162|       |    // secondary peers
  163|       |    // work generation disabled
  164|       |    // unresponsive work peers => use local work
  165|       |}

/home/gustav/code/nano/rsnano-node/nullables/clock/src/steady_clock.rs:
    1|       |use std::{
    2|       |    ops::{Add, Sub},
    3|       |    time::{Duration, Instant},
    4|       |};
    5|       |
    6|       |pub struct SteadyClock {
    7|       |    time_source: TimeSource,
    8|       |}
    9|       |
   10|       |impl SteadyClock {
   11|     12|    pub fn new_null() -> Self {
   12|     12|        Self {
   13|     12|            time_source: TimeSource::Stub(DEFAULT_STUB_DURATION),
   14|     12|        }
   15|     12|    }
   16|       |
   17|     21|    pub fn now(&self) -> Timestamp {
   18|     21|        Timestamp(self.time_source.now())
   19|     21|    }
   20|       |}
   21|       |
   22|       |impl Default for SteadyClock {
   23|      3|    fn default() -> Self {
   24|      3|        SteadyClock {
   25|      3|            time_source: TimeSource::System(Instant::now()),
   26|      3|        }
   27|      3|    }
   28|       |}
   29|       |
   30|       |enum TimeSource {
   31|       |    System(Instant),
   32|       |    Stub(i64),
   33|       |}
   34|       |
   35|       |impl TimeSource {
   36|     21|    fn now(&self) -> i64 {
   37|     21|        match self {
   38|      6|            TimeSource::System(instant) => instant.elapsed().as_millis() as i64,
   39|     15|            TimeSource::Stub(value) => *value,
   40|       |        }
   41|     21|    }
   42|       |}
   43|       |
   44|       |const DEFAULT_STUB_DURATION: i64 = 1000 * 60 * 60 * 24 * 365;
   45|       |
   46|       |#[derive(PartialEq, Eq, PartialOrd, Ord, Debug, Clone, Copy, Default, Hash)]
   47|       |pub struct Timestamp(i64);
   48|       |
   49|       |impl Timestamp {
   50|       |    pub const MAX: Self = Self(i64::MAX);
   51|       |
   52|     80|    pub const fn new_test_instance() -> Self {
   53|     80|        Self(DEFAULT_STUB_DURATION)
   54|     80|    }
   55|       |
   56|      1|    pub fn elapsed(&self, now: Timestamp) -> Duration {
   57|      1|        Duration::from_millis(now.0.checked_sub(self.0).unwrap_or_default() as u64)
   58|      1|    }
   59|       |
   60|      7|    pub fn checked_sub(&self, rhs: Duration) -> Option<Self> {
   61|      7|        self.0.checked_sub(rhs.as_millis() as i64).map(Self)
   62|      7|    }
   63|       |}
   64|       |
   65|       |impl Add<Duration> for Timestamp {
   66|       |    type Output = Timestamp;
   67|       |
   68|     37|    fn add(self, rhs: Duration) -> Self::Output {
   69|     37|        Self(self.0.add(rhs.as_millis() as i64))
   70|     37|    }
   71|       |}
   72|       |
   73|       |impl Sub<Timestamp> for Timestamp {
   74|       |    type Output = Duration;
   75|       |
   76|      0|    fn sub(self, rhs: Timestamp) -> Self::Output {
   77|      0|        Duration::from_millis((self.0 - rhs.0) as u64)
   78|      0|    }
   79|       |}
   80|       |
   81|       |impl Sub<Duration> for Timestamp {
   82|       |    type Output = Timestamp;
   83|       |
   84|     30|    fn sub(self, rhs: Duration) -> Self::Output {
   85|     30|        Self(self.0 - rhs.as_millis() as i64)
   86|     30|    }
   87|       |}
   88|       |
   89|       |impl From<i64> for Timestamp {
   90|      0|    fn from(value: i64) -> Self {
   91|      0|        Self(value)
   92|      0|    }
   93|       |}
   94|       |
   95|       |impl From<Timestamp> for i64 {
   96|     10|    fn from(value: Timestamp) -> Self {
   97|     10|        value.0
   98|     10|    }
   99|       |}
  100|       |
  101|       |#[cfg(test)]
  102|       |mod tests {
  103|       |    use super::*;
  104|       |    use std::thread::sleep;
  105|       |
  106|       |    mod timestamp {
  107|       |        use super::*;
  108|       |
  109|       |        #[test]
  110|       |        fn add_duration() {
  111|       |            assert_eq!(
  112|       |                Timestamp::from(1000) + Duration::from_millis(300),
  113|       |                Timestamp::from(1300)
  114|       |            );
  115|       |        }
  116|       |
  117|       |        #[test]
  118|       |        fn sub() {
  119|       |            assert_eq!(
  120|       |                Timestamp::from(1000) - Timestamp::from(300),
  121|       |                Duration::from_millis(700)
  122|       |            );
  123|       |        }
  124|       |    }
  125|       |
  126|       |    #[test]
  127|       |    fn now() {
  128|       |        let clock = SteadyClock::default();
  129|       |        let now1 = clock.now();
  130|       |        sleep(Duration::from_millis(1));
  131|       |        let now2 = clock.now();
  132|       |        assert!(now2 > now1);
  133|       |    }
  134|       |
  135|       |    mod nullability {
  136|       |        use super::*;
  137|       |        #[test]
  138|       |        fn can_be_nulled() {
  139|       |            let clock = SteadyClock::new_null();
  140|       |            let now1 = clock.now();
  141|       |            let now2 = clock.now();
  142|       |            assert_eq!(now1, now2);
  143|       |        }
  144|       |    }
  145|       |}

/home/gustav/code/nano/rsnano-node/nullables/clock/src/system_time_factory.rs:
    1|       |use std::time::{Duration, SystemTime, UNIX_EPOCH};
    2|       |
    3|       |pub struct SystemTimeFactory(TimeStrategy);
    4|       |
    5|       |impl SystemTimeFactory {
    6|      0|    pub fn new_null() -> Self {
    7|      0|        Self(TimeStrategy::Stub(
    8|      0|            UNIX_EPOCH + Duration::from_secs(60 * 60 * 24 * 365 * 50),
    9|      0|        ))
   10|      0|    }
   11|       |
   12|     11|    pub fn new_null_with(configured_response: SystemTime) -> Self {
   13|     11|        Self(TimeStrategy::Stub(configured_response))
   14|     11|    }
   15|       |
   16|     31|    pub fn now(&self) -> SystemTime {
   17|     31|        match &self.0 {
   18|      0|            TimeStrategy::Real => SystemTime::now(),
   19|     31|            TimeStrategy::Stub(now) => *now,
   20|       |        }
   21|     31|    }
   22|       |}
   23|       |
   24|       |impl Default for SystemTimeFactory {
   25|      3|    fn default() -> Self {
   26|      3|        Self(TimeStrategy::Real)
   27|      3|    }
   28|       |}
   29|       |
   30|       |enum TimeStrategy {
   31|       |    Real,
   32|       |    Stub(SystemTime),
   33|       |}
   34|       |
   35|       |#[cfg(test)]
   36|       |mod tests {
   37|       |    use super::*;
   38|       |    use std::time::{Duration, UNIX_EPOCH};
   39|       |
   40|       |    #[test]
   41|       |    fn get_real_system_time() {
   42|       |        let system_now = SystemTime::now();
   43|       |        let now = SystemTimeFactory::default().now();
   44|       |        assert!(now >= system_now - Duration::from_secs(60 * 10));
   45|       |        assert!(now < system_now + Duration::from_secs(60 * 10));
   46|       |    }
   47|       |
   48|       |    #[test]
   49|       |    fn nulled_time_factory_returns_stub_time() {
   50|       |        assert_eq!(
   51|       |            SystemTimeFactory::new_null().now(),
   52|       |            UNIX_EPOCH + Duration::from_secs(60 * 60 * 24 * 365 * 50)
   53|       |        );
   54|       |    }
   55|       |
   56|       |    #[test]
   57|       |    fn nulled_time_factory_returns_configured_response() {
   58|       |        let configured_response = UNIX_EPOCH + Duration::from_secs(1_000_000);
   59|       |        assert_eq!(
   60|       |            SystemTimeFactory::new_null_with(configured_response).now(),
   61|       |            configured_response
   62|       |        );
   63|       |    }
   64|       |}

/home/gustav/code/nano/rsnano-node/nullables/fs/src/lib.rs:
    1|       |use rsnano_output_tracker::{OutputListener, OutputTracker};
    2|       |use std::{
    3|       |    cell::RefCell,
    4|       |    collections::{HashMap, HashSet},
    5|       |    io::ErrorKind,
    6|       |    ops::{Deref, DerefMut},
    7|       |    path::{Path, PathBuf},
    8|       |    rc::Rc,
    9|       |};
   10|       |
   11|       |#[derive(Clone, Debug, PartialEq, Eq)]
   12|       |pub struct FsEvent {
   13|       |    event_type: EventType,
   14|       |    path: PathBuf,
   15|       |    contents: String,
   16|       |}
   17|       |
   18|       |impl FsEvent {
   19|      9|    pub fn create_dir_all(path: impl Into<PathBuf>) -> Self {
   20|      9|        Self {
   21|      9|            event_type: EventType::CreateDirAll,
   22|      9|            path: path.into(),
   23|      9|            contents: String::new(),
   24|      9|        }
   25|      9|    }
   26|       |
   27|      8|    pub fn write(path: impl Into<PathBuf>, contents: impl AsRef<[u8]>) -> Self {
   28|      8|        Self {
   29|      8|            event_type: EventType::Write,
   30|      8|            path: path.into(),
   31|      8|            contents: String::from_utf8_lossy(contents.as_ref()).to_string(),
   32|      8|        }
   33|      8|    }
   34|       |}
   35|       |
   36|       |#[derive(Clone, Debug, PartialEq, Eq)]
   37|       |pub enum EventType {
   38|       |    CreateDirAll,
   39|       |    Write,
   40|       |}
   41|       |
   42|       |pub struct NullableFilesystem {
   43|       |    fs: RefCell<FsStrategy>,
   44|       |    listener: OutputListener<FsEvent>,
   45|       |}
   46|       |
   47|       |#[allow(dead_code)]
   48|       |enum FsStrategy {
   49|       |    Real(RealFilesystem),
   50|       |    Nulled(FilesystemStub),
   51|       |}
   52|       |
   53|       |impl Deref for FsStrategy {
   54|       |    type Target = dyn Filesystem;
   55|       |
   56|     13|    fn deref(&self) -> &Self::Target {
   57|     13|        match self {
   58|      3|            FsStrategy::Real(i) => i,
   59|     10|            FsStrategy::Nulled(i) => i,
   60|       |        }
   61|     13|    }
   62|       |}
   63|       |
   64|       |impl DerefMut for FsStrategy {
   65|     20|    fn deref_mut(&mut self) -> &mut Self::Target {
   66|     20|        match self {
   67|      6|            FsStrategy::Real(i) => i,
   68|     14|            FsStrategy::Nulled(i) => i,
   69|       |        }
   70|     20|    }
   71|       |}
   72|       |
   73|       |impl NullableFilesystem {
   74|      3|    pub fn new() -> Self {
   75|      3|        Self {
   76|      3|            fs: RefCell::new(FsStrategy::Real(RealFilesystem {})),
   77|      3|            listener: OutputListener::new(),
   78|      3|        }
   79|      3|    }
   80|       |
   81|       |    #[allow(dead_code)]
   82|      3|    pub fn new_null() -> Self {
   83|      3|        Self {
   84|      3|            fs: RefCell::new(FsStrategy::Nulled(FilesystemStub::default())),
   85|      3|            listener: OutputListener::new(),
   86|      3|        }
   87|      3|    }
   88|       |
   89|       |    #[allow(dead_code)]
   90|      7|    pub fn null_builder() -> NullableFilesystemBuilder {
   91|      7|        NullableFilesystemBuilder {
   92|      7|            stub: FilesystemStub::default(),
   93|      7|        }
   94|      7|    }
   95|       |
   96|     13|    pub fn exists(&self, f: impl AsRef<Path>) -> bool {
   97|     13|        self.fs.borrow().exists(f.as_ref())
   98|     13|    }
   99|       |
  100|      5|    pub fn read_to_string(&self, f: impl AsRef<Path>) -> std::io::Result<String> {
  101|      5|        self.fs.borrow_mut().read_to_string(f.as_ref())
  102|      5|    }
  103|       |
  104|      8|    pub fn create_dir_all(&self, f: impl AsRef<Path>) -> std::io::Result<()> {
  105|      8|        let path = f.as_ref();
  106|      8|        self.listener.emit(FsEvent::create_dir_all(path));
  107|      8|        self.fs.borrow_mut().create_dir_all(path)
  108|      8|    }
  109|       |
  110|      7|    pub fn write(&self, path: impl AsRef<Path>, contents: impl AsRef<[u8]>) -> std::io::Result<()> {
  111|      7|        let path = path.as_ref();
  112|      7|        let contents = contents.as_ref();
  113|      7|        self.listener.emit(FsEvent::write(path, contents));
  114|      7|        self.fs.borrow_mut().write(path, contents)
  115|      7|    }
  116|       |
  117|       |    #[allow(dead_code)]
  118|     10|    pub fn track(&self) -> Rc<OutputTracker<FsEvent>> {
  119|     10|        self.listener.track()
  120|     10|    }
  121|       |}
  122|       |
  123|       |impl Default for NullableFilesystem {
  124|      3|    fn default() -> Self {
  125|      3|        Self::new()
  126|      3|    }
  127|       |}
  128|       |
  129|       |#[allow(dead_code)]
  130|       |pub struct NullableFilesystemBuilder {
  131|       |    stub: FilesystemStub,
  132|       |}
  133|       |
  134|       |#[allow(dead_code)]
  135|       |impl NullableFilesystemBuilder {
  136|      5|    pub fn path_exists(mut self, path: impl Into<PathBuf>) -> Self {
  137|      5|        self.stub.exists.insert(path.into());
  138|      5|        self
  139|      5|    }
  140|       |
  141|      4|    pub fn read_to_string(mut self, path: impl Into<PathBuf>, contents: String) -> Self {
  142|      4|        self.stub.read_to_string.insert(path.into(), Ok(contents));
  143|      4|        self
  144|      4|    }
  145|       |
  146|      1|    pub fn read_to_string_fails(mut self, path: impl Into<PathBuf>, error: std::io::Error) -> Self {
  147|      1|        self.stub.read_to_string.insert(path.into(), Err(error));
  148|      1|        self
  149|      1|    }
  150|       |
  151|      1|    pub fn create_dir_all_fails(mut self, path: impl Into<PathBuf>, error: std::io::Error) -> Self {
  152|      1|        self.stub.create_dir_all_errors.insert(path.into(), error);
  153|      1|        self
  154|      1|    }
  155|       |
  156|      1|    pub fn write_fails(mut self, path: impl Into<PathBuf>, error: std::io::Error) -> Self {
  157|      1|        self.stub.write_errors.insert(path.into(), error);
  158|      1|        self
  159|      1|    }
  160|       |
  161|      7|    pub fn finish(self) -> NullableFilesystem {
  162|      7|        NullableFilesystem {
  163|      7|            fs: RefCell::new(FsStrategy::Nulled(self.stub)),
  164|      7|            listener: OutputListener::new(),
  165|      7|        }
  166|      7|    }
  167|       |}
  168|       |
  169|       |trait Filesystem {
  170|       |    fn exists(&self, path: &Path) -> bool;
  171|       |    fn read_to_string(&mut self, f: &Path) -> std::io::Result<String>;
  172|       |    fn create_dir_all(&mut self, path: &Path) -> std::io::Result<()>;
  173|       |    fn write(&mut self, path: &Path, contents: &[u8]) -> std::io::Result<()>;
  174|       |}
  175|       |
  176|       |struct RealFilesystem {}
  177|       |
  178|       |impl Filesystem for RealFilesystem {
  179|      3|    fn exists(&self, path: &Path) -> bool {
  180|      3|        path.exists()
  181|      3|    }
  182|       |
  183|      0|    fn read_to_string(&mut self, f: &Path) -> std::io::Result<String> {
  184|      0|        std::fs::read_to_string(f)
  185|      0|    }
  186|       |
  187|      3|    fn create_dir_all(&mut self, path: &Path) -> std::io::Result<()> {
  188|      3|        std::fs::create_dir_all(path)
  189|      3|    }
  190|       |
  191|      3|    fn write(&mut self, path: &Path, contents: &[u8]) -> std::io::Result<()> {
  192|      3|        std::fs::write(path, contents)
  193|      3|    }
  194|       |}
  195|       |
  196|       |#[derive(Default)]
  197|       |struct FilesystemStub {
  198|       |    exists: HashSet<PathBuf>,
  199|       |    read_to_string: HashMap<PathBuf, std::io::Result<String>>,
  200|       |    create_dir_all_errors: HashMap<PathBuf, std::io::Error>,
  201|       |    write_errors: HashMap<PathBuf, std::io::Error>,
  202|       |}
  203|       |
  204|       |impl Filesystem for FilesystemStub {
  205|     10|    fn exists(&self, path: &Path) -> bool {
  206|     10|        self.exists.contains(path)
  207|     10|    }
  208|       |
  209|      5|    fn read_to_string(&mut self, f: &Path) -> std::io::Result<String> {
  210|      5|        match self.read_to_string.remove(f) {
  211|      5|            Some(contents) => contents,
  212|      0|            None => Err(std::io::Error::new(
  213|      0|                ErrorKind::NotFound,
  214|      0|                format!("no response configured for file {f:?}"),
  215|      0|            )),
  216|       |        }
  217|      5|    }
  218|       |
  219|      5|    fn create_dir_all(&mut self, path: &Path) -> std::io::Result<()> {
  220|      5|        match self.create_dir_all_errors.remove(path) {
  221|      1|            Some(err) => Err(err),
  222|      4|            None => Ok(()),
  223|       |        }
  224|      5|    }
  225|       |
  226|      4|    fn write(&mut self, path: &Path, _contents: &[u8]) -> std::io::Result<()> {
  227|      4|        match self.write_errors.remove(path) {
  228|      1|            Some(err) => Err(err),
  229|      3|            None => Ok(()),
  230|       |        }
  231|      4|    }
  232|       |}
  233|       |
  234|       |#[cfg(test)]
  235|       |mod tests {
  236|       |    use super::*;
  237|       |
  238|       |    #[test]
  239|       |    fn path_exists() {
  240|       |        let path: PathBuf = "/tmp/nullable-fs-test.txt".into();
  241|       |        if path.exists() {
  242|       |            std::fs::remove_file(&path).unwrap();
  243|       |        }
  244|       |
  245|       |        let fs = NullableFilesystem::new();
  246|       |        assert_eq!(fs.exists(&path), false);
  247|       |
  248|       |        std::fs::write(&path, b"test").unwrap();
  249|       |        assert_eq!(fs.exists(&path), true);
  250|       |
  251|       |        std::fs::remove_file(path).unwrap();
  252|       |    }
  253|       |
  254|       |    #[test]
  255|       |    fn read_to_string() {
  256|       |        let path: PathBuf = "/tmp/nullable-fs-read-to-string.txt".into();
  257|       |        std::fs::write(&path, b"hello world").unwrap();
  258|       |        let result = NullableFilesystem::new().read_to_string(&path);
  259|       |        std::fs::remove_file(path).unwrap();
  260|       |        assert_eq!(result.unwrap(), "hello world")
  261|       |    }
  262|       |
  263|       |    #[test]
  264|       |    fn create_dir_all() {
  265|       |        let p = PathBuf::from("/tmp/a");
  266|       |        if p.exists() {
  267|       |            std::fs::remove_dir_all(&p).unwrap();
  268|       |        }
  269|       |
  270|       |        NullableFilesystem::new()
  271|       |            .create_dir_all("/tmp/a/b/c")
  272|       |            .unwrap();
  273|       |
  274|       |        assert!(PathBuf::from("/tmp/a/b/c").exists());
  275|       |        std::fs::remove_dir_all(p).unwrap()
  276|       |    }
  277|       |
  278|       |    #[test]
  279|       |    fn write() {
  280|       |        let f = PathBuf::from("/tmp/nullable-fs-write-test.txt");
  281|       |        NullableFilesystem::new().write(&f, b"foo").unwrap();
  282|       |        assert_eq!(std::fs::read_to_string(&f).unwrap(), "foo");
  283|       |        std::fs::remove_file(f).unwrap();
  284|       |    }
  285|       |
  286|       |    mod observability {
  287|       |        use super::*;
  288|       |
  289|       |        #[test]
  290|       |        fn create_dir_all_can_be_tracked() {
  291|       |            let fs = NullableFilesystem::new_null();
  292|       |            let tracker = fs.track();
  293|       |            let path = PathBuf::from("/foo/bar");
  294|       |            fs.create_dir_all(&path).unwrap();
  295|       |            let output = tracker.output();
  296|       |            assert_eq!(output.len(), 1);
  297|       |            assert_eq!(output[0].event_type, EventType::CreateDirAll);
  298|       |            assert_eq!(output[0].path, path);
  299|       |        }
  300|       |
  301|       |        #[test]
  302|       |        fn write_can_be_tracked() {
  303|       |            let fs = NullableFilesystem::new_null();
  304|       |            let tracker = fs.track();
  305|       |            let path = PathBuf::from("/foo/bar");
  306|       |            fs.write(&path, b"hello").unwrap();
  307|       |            let output = tracker.output();
  308|       |            assert_eq!(output.len(), 1);
  309|       |            assert_eq!(output[0].event_type, EventType::Write);
  310|       |            assert_eq!(output[0].path, path);
  311|       |            assert_eq!(output[0].contents, "hello");
  312|       |        }
  313|       |    }
  314|       |
  315|       |    mod nullability {
  316|       |        use super::*;
  317|       |
  318|       |        #[test]
  319|       |        fn is_nullable() {
  320|       |            let fs = NullableFilesystem::new_null();
  321|       |            assert_eq!(fs.exists("/foo/bar"), false);
  322|       |            assert!(fs.read_to_string("/foo/bar").is_err());
  323|       |            assert!(fs.create_dir_all("/foo/bar").is_ok());
  324|       |            assert!(fs.write("/foo/bar", "abc").is_ok());
  325|       |        }
  326|       |
  327|       |        #[test]
  328|       |        fn file_exists() {
  329|       |            let fs = NullableFilesystem::null_builder()
  330|       |                .path_exists("/foo/bar")
  331|       |                .finish();
  332|       |            assert_eq!(fs.exists("/foo/bar"), true);
  333|       |            assert_eq!(fs.exists("/foo/bar"), true);
  334|       |            assert_eq!(fs.exists("/foo/bar2"), false);
  335|       |        }
  336|       |
  337|       |        #[test]
  338|       |        fn read_to_string_file_not_found() {
  339|       |            let fs = NullableFilesystem::new_null();
  340|       |            let err = fs.read_to_string("/foo/bar").unwrap_err();
  341|       |            assert_eq!(err.kind(), ErrorKind::NotFound);
  342|       |            assert_eq!(
  343|       |                err.to_string(),
  344|       |                "no response configured for file \"/foo/bar\""
  345|       |            );
  346|       |        }
  347|       |
  348|       |        #[test]
  349|       |        fn read_to_string() {
  350|       |            let path = PathBuf::from("/foo/bar");
  351|       |            let fs = NullableFilesystem::null_builder()
  352|       |                .read_to_string(&path, "hello world".to_string())
  353|       |                .finish();
  354|       |
  355|       |            assert_eq!(fs.read_to_string(path).unwrap(), "hello world");
  356|       |        }
  357|       |
  358|       |        #[test]
  359|       |        fn read_to_string_fails() {
  360|       |            let path = PathBuf::from("/foo/bar");
  361|       |            let fs = NullableFilesystem::null_builder()
  362|       |                .read_to_string_fails(&path, std::io::Error::new(ErrorKind::PermissionDenied, ""))
  363|       |                .finish();
  364|       |
  365|       |            let err = fs.read_to_string(path).unwrap_err();
  366|       |            assert_eq!(err.kind(), ErrorKind::PermissionDenied);
  367|       |        }
  368|       |
  369|       |        #[test]
  370|       |        fn create_dir_failure() {
  371|       |            let path = PathBuf::from("/foo/bar");
  372|       |            let fs = NullableFilesystem::null_builder()
  373|       |                .create_dir_all_fails(&path, std::io::Error::new(ErrorKind::PermissionDenied, ""))
  374|       |                .finish();
  375|       |
  376|       |            let err = fs.create_dir_all(path).unwrap_err();
  377|       |            assert_eq!(err.kind(), ErrorKind::PermissionDenied);
  378|       |        }
  379|       |
  380|       |        #[test]
  381|       |        fn write_fails() {
  382|       |            let path = PathBuf::from("/foo/bar");
  383|       |            let fs = NullableFilesystem::null_builder()
  384|       |                .write_fails(&path, std::io::Error::new(ErrorKind::PermissionDenied, ""))
  385|       |                .finish();
  386|       |
  387|       |            let err = fs.write(path, b"test").unwrap_err();
  388|       |            assert_eq!(err.kind(), ErrorKind::PermissionDenied);
  389|       |        }
  390|       |    }
  391|       |}

/home/gustav/code/nano/rsnano-node/nullables/http_client/src/lib.rs:
    1|       |use anyhow::anyhow;
    2|       |use reqwest::{IntoUrl, Method, StatusCode};
    3|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
    4|       |use serde::{de::DeserializeOwned, Serialize};
    5|       |use std::{collections::HashMap, sync::Arc};
    6|       |
    7|       |pub use reqwest::Url;
    8|       |
    9|       |pub struct HttpClient {
   10|       |    strategy: HttpClientStrategy,
   11|       |    request_listener: OutputListenerMt<TrackedRequest>,
   12|       |}
   13|       |
   14|       |impl HttpClient {
   15|      0|    pub fn new() -> Self {
   16|      0|        Self::new_with_strategy(HttpClientStrategy::Real(reqwest::Client::new()))
   17|      0|    }
   18|       |
   19|      0|    pub fn new_null() -> Self {
   20|      0|        Self::new_with_strategy(HttpClientStrategy::Nulled(HttpClientStub::with_response(
   21|      0|            ConfiguredResponse::default(),
   22|      0|        )))
   23|      0|    }
   24|       |
   25|      0|    fn new_with_strategy(strategy: HttpClientStrategy) -> Self {
   26|      0|        Self {
   27|      0|            strategy,
   28|      0|            request_listener: OutputListenerMt::new(),
   29|      0|        }
   30|      0|    }
   31|       |
   32|      0|    pub fn null_builder() -> NulledHttpClientBuilder {
   33|      0|        NulledHttpClientBuilder {
   34|      0|            responses: HashMap::new(),
   35|      0|        }
   36|      0|    }
   37|       |
   38|      0|    pub async fn post_json<U: IntoUrl, T: Serialize + ?Sized>(
   39|      0|        &self,
   40|      0|        url: U,
   41|      0|        json: &T,
   42|      0|    ) -> anyhow::Result<Response> {
   43|      0|        let url = url.into_url()?;
   44|      0|        if self.request_listener.is_tracked() {
   45|      0|            self.request_listener.emit(TrackedRequest {
   46|      0|                url: url.clone(),
   47|      0|                method: Method::POST,
   48|      0|                json: serde_json::to_value(json)?,
   49|       |            });
   50|      0|        }
   51|       |
   52|      0|        match &self.strategy {
   53|      0|            HttpClientStrategy::Real(client) => {
   54|      0|                Ok(client.post(url).json(json).send().await?.into())
   55|       |            }
   56|      0|            HttpClientStrategy::Nulled(client) => client.get_response(Method::POST, url),
   57|       |        }
   58|      0|    }
   59|       |
   60|      0|    pub fn track_requests(&self) -> Arc<OutputTrackerMt<TrackedRequest>> {
   61|      0|        self.request_listener.track()
   62|      0|    }
   63|       |}
   64|       |
   65|       |impl Default for HttpClient {
   66|      0|    fn default() -> Self {
   67|      0|        Self::new()
   68|      0|    }
   69|       |}
   70|       |
   71|       |enum HttpClientStrategy {
   72|       |    Real(reqwest::Client),
   73|       |    Nulled(HttpClientStub),
   74|       |}
   75|       |
   76|       |pub struct NulledHttpClientBuilder {
   77|       |    responses: HashMap<(Url, Method), ConfiguredResponse>,
   78|       |}
   79|       |
   80|       |impl NulledHttpClientBuilder {
   81|      0|    pub fn respond(self, response: ConfiguredResponse) -> HttpClient {
   82|      0|        HttpClient::new_with_strategy(HttpClientStrategy::Nulled(HttpClientStub {
   83|      0|            the_only_response: Some(response),
   84|      0|            responses: HashMap::new(),
   85|      0|        }))
   86|      0|    }
   87|       |
   88|      0|    pub fn respond_url(
   89|      0|        mut self,
   90|      0|        method: Method,
   91|      0|        url: impl IntoUrl,
   92|      0|        response: ConfiguredResponse,
   93|      0|    ) -> Self {
   94|      0|        self.responses
   95|      0|            .insert((url.into_url().unwrap(), method), response);
   96|      0|        self
   97|      0|    }
   98|       |
   99|      0|    pub fn finish(self) -> HttpClient {
  100|      0|        HttpClient::new_with_strategy(HttpClientStrategy::Nulled(HttpClientStub {
  101|      0|            the_only_response: None,
  102|      0|            responses: self.responses,
  103|      0|        }))
  104|      0|    }
  105|       |}
  106|       |
  107|       |struct HttpClientStub {
  108|       |    the_only_response: Option<ConfiguredResponse>,
  109|       |    responses: HashMap<(Url, Method), ConfiguredResponse>,
  110|       |}
  111|       |
  112|       |impl HttpClientStub {
  113|      0|    fn with_response(response: ConfiguredResponse) -> Self {
  114|      0|        Self {
  115|      0|            the_only_response: Some(response),
  116|      0|            responses: HashMap::new(),
  117|      0|        }
  118|      0|    }
  119|       |
  120|      0|    fn get_response(&self, method: Method, url: Url) -> anyhow::Result<Response> {
  121|      0|        let response = if let Some(r) = &self.the_only_response {
  122|      0|            Some(r)
  123|       |        } else {
  124|      0|            self.responses.get(&(url.clone(), method.clone()))
  125|       |        };
  126|       |
  127|      0|        response
  128|      0|            .map(|r| r.clone().into())
  129|      0|            .ok_or_else(|| anyhow!("no response configured for {} {}", method, url))
  130|      0|    }
  131|       |}
  132|       |
  133|       |#[derive(Clone)]
  134|       |pub struct TrackedRequest {
  135|       |    pub url: Url,
  136|       |    pub method: Method,
  137|       |    pub json: serde_json::Value,
  138|       |}
  139|       |
  140|       |pub struct Response {
  141|       |    strategy: ResponseStrategy,
  142|       |}
  143|       |
  144|       |impl Response {
  145|      0|    pub fn status(&self) -> StatusCode {
  146|      0|        match &self.strategy {
  147|      0|            ResponseStrategy::Real(resp) => resp.status(),
  148|      0|            ResponseStrategy::Nulled(resp) => resp.status,
  149|       |        }
  150|      0|    }
  151|       |
  152|      0|    pub async fn json<T: DeserializeOwned>(self) -> anyhow::Result<T> {
  153|      0|        match self.strategy {
  154|      0|            ResponseStrategy::Real(resp) => Ok(resp.json().await?),
  155|      0|            ResponseStrategy::Nulled(resp) => resp.json(),
  156|       |        }
  157|      0|    }
  158|       |}
  159|       |
  160|       |enum ResponseStrategy {
  161|       |    Real(reqwest::Response),
  162|       |    Nulled(ConfiguredResponse),
  163|       |}
  164|       |
  165|       |impl From<reqwest::Response> for Response {
  166|      0|    fn from(value: reqwest::Response) -> Self {
  167|      0|        Self {
  168|      0|            strategy: ResponseStrategy::Real(value),
  169|      0|        }
  170|      0|    }
  171|       |}
  172|       |
  173|       |#[derive(Clone)]
  174|       |pub struct ConfiguredResponse {
  175|       |    status: StatusCode,
  176|       |    body: serde_json::Value,
  177|       |}
  178|       |
  179|       |impl ConfiguredResponse {
  180|      0|    pub fn new(status: StatusCode, json: impl Serialize) -> Self {
  181|      0|        Self {
  182|      0|            status,
  183|      0|            body: serde_json::to_value(json).unwrap(),
  184|      0|        }
  185|      0|    }
  186|      0|    pub fn json<T: DeserializeOwned>(&self) -> anyhow::Result<T> {
  187|      0|        let deserialized = serde_json::from_value(self.body.clone())?;
  188|      0|        Ok(deserialized)
  189|      0|    }
  190|       |}
  191|       |
  192|       |impl Default for ConfiguredResponse {
  193|      0|    fn default() -> Self {
  194|      0|        Self {
  195|      0|            status: StatusCode::OK,
  196|      0|            body: serde_json::Value::Null,
  197|      0|        }
  198|      0|    }
  199|       |}
  200|       |
  201|       |impl From<ConfiguredResponse> for Response {
  202|      0|    fn from(value: ConfiguredResponse) -> Self {
  203|      0|        Self {
  204|      0|            strategy: ResponseStrategy::Nulled(value),
  205|      0|        }
  206|      0|    }
  207|       |}
  208|       |
  209|       |#[cfg(test)]
  210|       |mod tests {
  211|       |    use super::*;
  212|       |    use reqwest::StatusCode;
  213|       |    use tokio::net::TcpListener;
  214|       |
  215|       |    #[tokio::test]
  216|       |    async fn make_real_request() {
  217|       |        let port = get_available_port().await;
  218|       |        let _server = test_http_server::start(("0.0.0.0", port)).await;
  219|       |
  220|       |        let client = HttpClient::new();
  221|       |        let result = client
  222|       |            .post_json(format!("http://127.0.0.1:{}", port), &vec!["hello"])
  223|       |            .await
  224|       |            .unwrap();
  225|       |        assert_eq!(result.status(), StatusCode::OK);
  226|       |        let response = result.json::<Vec<String>>().await.unwrap();
  227|       |        assert_eq!(response, vec!["hello".to_string(), "world".to_string()]);
  228|       |    }
  229|       |
  230|       |    #[tokio::test]
  231|       |    async fn track_requests() {
  232|       |        let client = HttpClient::new_null();
  233|       |        let tracker = client.track_requests();
  234|       |        let target_url: Url = "http://127.0.0.1:42/foobar".parse().unwrap();
  235|       |        let data = vec![1, 2, 3];
  236|       |
  237|       |        client.post_json(target_url.clone(), &data).await.unwrap();
  238|       |
  239|       |        let requests = tracker.output();
  240|       |        assert_eq!(requests.len(), 1);
  241|       |        assert_eq!(requests[0].url, target_url);
  242|       |        assert_eq!(requests[0].method, Method::POST);
  243|       |        assert_eq!(requests[0].json, serde_json::to_value(&data).unwrap());
  244|       |    }
  245|       |
  246|       |    mod nullability {
  247|       |        use super::*;
  248|       |
  249|       |        #[tokio::test]
  250|       |        async fn can_be_nulled() {
  251|       |            let client = HttpClient::new_null();
  252|       |            let response = client
  253|       |                .post_json("http://127.0.0.1:42", "foobar")
  254|       |                .await
  255|       |                .unwrap();
  256|       |            assert_eq!(response.status(), StatusCode::OK);
  257|       |        }
  258|       |
  259|       |        #[tokio::test]
  260|       |        async fn return_configured_json_response() {
  261|       |            let client = HttpClient::null_builder()
  262|       |                .respond(ConfiguredResponse::new(StatusCode::OK, vec![1, 2, 3]));
  263|       |
  264|       |            let response = client.post_json("http://127.0.0.1:42", "").await.unwrap();
  265|       |            assert_eq!(response.json::<Vec<i32>>().await.unwrap(), vec![1, 2, 3]);
  266|       |        }
  267|       |    }
  268|       |
  269|       |    mod test_http_server {
  270|       |        use axum::{routing::post, Json, Router};
  271|       |        use tokio::{
  272|       |            net::{TcpListener, ToSocketAddrs},
  273|       |            sync::oneshot,
  274|       |        };
  275|       |        use tokio_util::sync::CancellationToken;
  276|       |
  277|       |        pub(crate) struct DropGuard {
  278|       |            cancel_token: CancellationToken,
  279|       |        }
  280|       |
  281|       |        impl Drop for DropGuard {
  282|       |            fn drop(&mut self) {
  283|       |                self.cancel_token.cancel();
  284|       |            }
  285|       |        }
  286|       |
  287|       |        pub(crate) async fn start(addr: impl ToSocketAddrs + Send + 'static) -> DropGuard {
  288|       |            let guard = DropGuard {
  289|       |                cancel_token: CancellationToken::new(),
  290|       |            };
  291|       |            let cancel_token = guard.cancel_token.clone();
  292|       |            let (tx_ready, rx_ready) = oneshot::channel::<()>();
  293|       |
  294|       |            tokio::spawn(async move { run_server(addr, cancel_token, tx_ready).await });
  295|       |
  296|       |            rx_ready.await.unwrap();
  297|       |
  298|       |            guard
  299|       |        }
  300|       |
  301|       |        async fn run_server(
  302|       |            addr: impl ToSocketAddrs,
  303|       |            cancel_token: CancellationToken,
  304|       |            tx_ready: oneshot::Sender<()>,
  305|       |        ) {
  306|       |            let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
  307|       |            tx_ready.send(()).unwrap();
  308|       |            tokio::select! {
  309|       |                _ = serve(listener) => { },
  310|       |                _ = cancel_token.cancelled() => { }
  311|       |            }
  312|       |        }
  313|       |
  314|       |        async fn serve(tcp_listener: TcpListener) {
  315|       |            let app = Router::new().route("/", post(root));
  316|       |            axum::serve(tcp_listener, app).await.unwrap()
  317|       |        }
  318|       |
  319|       |        async fn root(Json(mut payload): Json<Vec<String>>) -> Json<Vec<String>> {
  320|       |            payload.push("world".to_string());
  321|       |            Json(payload)
  322|       |        }
  323|       |    }
  324|       |
  325|       |    async fn get_available_port() -> u16 {
  326|       |        for port in 1025..65535 {
  327|       |            if is_port_available(port).await {
  328|       |                return port;
  329|       |            }
  330|       |        }
  331|       |
  332|       |        panic!("Could not find an available port");
  333|       |    }
  334|       |
  335|       |    async fn is_port_available(port: u16) -> bool {
  336|       |        match TcpListener::bind(("127.0.0.1", port)).await {
  337|       |            Ok(_) => true,
  338|       |            Err(_) => false,
  339|       |        }
  340|       |    }
  341|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/configured_database.rs:
    1|       |use crate::EnvironmentStubBuilder;
    2|       |
    3|       |use super::LmdbDatabase;
    4|       |use std::collections::BTreeMap;
    5|       |
    6|       |#[derive(Clone)]
    7|       |pub struct ConfiguredDatabase {
    8|       |    pub dbi: LmdbDatabase,
    9|       |    pub db_name: String,
   10|       |    pub entries: BTreeMap<Vec<u8>, Vec<u8>>,
   11|       |}
   12|       |
   13|       |pub static EMPTY_DATABASE: ConfiguredDatabase = ConfiguredDatabase::new_empty();
   14|       |
   15|       |impl ConfiguredDatabase {
   16|    120|    pub fn new(dbi: LmdbDatabase, name: impl Into<String>) -> Self {
   17|    120|        Self {
   18|    120|            dbi,
   19|    120|            db_name: name.into(),
   20|    120|            entries: BTreeMap::new(),
   21|    120|        }
   22|    120|    }
   23|       |
   24|      0|    const fn new_empty() -> Self {
   25|      0|        Self {
   26|      0|            dbi: LmdbDatabase::new_null(42),
   27|      0|            db_name: String::new(),
   28|      0|            entries: BTreeMap::new(),
   29|      0|        }
   30|      0|    }
   31|       |}
   32|       |
   33|       |impl Default for ConfiguredDatabase {
   34|      0|    fn default() -> Self {
   35|      0|        Self {
   36|      0|            dbi: LmdbDatabase::new_null(42),
   37|      0|            db_name: "nulled_database".to_string(),
   38|      0|            entries: Default::default(),
   39|      0|        }
   40|      0|    }
   41|       |}
   42|       |
   43|       |pub struct ConfiguredDatabaseBuilder {
   44|       |    data: ConfiguredDatabase,
   45|       |    env_builder: EnvironmentStubBuilder,
   46|       |}
   47|       |
   48|       |impl ConfiguredDatabaseBuilder {
   49|      0|    pub fn new(
   50|      0|        name: impl Into<String>,
   51|      0|        dbi: LmdbDatabase,
   52|      0|        env_builder: EnvironmentStubBuilder,
   53|      0|    ) -> Self {
   54|      0|        Self {
   55|      0|            data: ConfiguredDatabase {
   56|      0|                dbi,
   57|      0|                db_name: name.into(),
   58|      0|                entries: BTreeMap::new(),
   59|      0|            },
   60|      0|            env_builder,
   61|      0|        }
   62|      0|    }
   63|       |
   64|      0|    pub fn entry(mut self, key: &[u8], value: &[u8]) -> Self {
   65|      0|        self.data.entries.insert(key.to_vec(), value.to_vec());
   66|      0|        self
   67|      0|    }
   68|      0|    pub fn finish(self) -> EnvironmentStubBuilder {
   69|      0|        self.env_builder.configured_database(self.data)
   70|      0|    }
   71|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/database.rs:
    1|       |#[derive(Clone, Debug, PartialEq, Eq, Copy)]
    2|       |pub struct LmdbDatabase(DatabaseType);
    3|       |
    4|       |impl LmdbDatabase {
    5|     61|    pub const fn new(db: lmdb::Database) -> Self {
    6|     61|        Self(DatabaseType::Real(db))
    7|     61|    }
    8|       |
    9|    220|    pub const fn new_null(id: u32) -> Self {
   10|    220|        Self(DatabaseType::Stub(id))
   11|    220|    }
   12|       |
   13|  1.06k|    pub fn as_real(&self) -> lmdb::Database {
   14|  1.06k|        let DatabaseType::Real(db) = &self.0 else {
   15|      0|            panic!("database handle was not a real handle");
   16|       |        };
   17|  1.06k|        *db
   18|  1.06k|    }
   19|       |
   20|      0|    pub fn as_nulled(&self) -> u32 {
   21|      0|        let DatabaseType::Stub(db) = self.0 else {
   22|      0|            panic!("database handle was not a nulled handle");
   23|       |        };
   24|      0|        db
   25|      0|    }
   26|       |}
   27|       |
   28|       |#[derive(PartialEq, Eq, Clone, Copy, Debug)]
   29|       |enum DatabaseType {
   30|       |    Real(lmdb::Database),
   31|       |    Stub(u32),
   32|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/environment.rs:
    1|       |use crate::ConfiguredDatabaseBuilder;
    2|       |
    3|       |use super::{ConfiguredDatabase, LmdbDatabase, RoTransaction, RwTransaction};
    4|       |use lmdb::{DatabaseFlags, EnvironmentFlags, Stat};
    5|       |use lmdb_sys::MDB_env;
    6|       |use std::path::Path;
    7|       |
    8|       |pub struct EnvironmentOptions<'a> {
    9|       |    pub max_dbs: u32,
   10|       |    pub map_size: usize,
   11|       |    pub flags: EnvironmentFlags,
   12|       |    pub path: &'a Path,
   13|       |    pub file_mode: u32,
   14|       |}
   15|       |
   16|       |pub struct LmdbEnvironment(EnvironmentStrategy);
   17|       |
   18|       |impl LmdbEnvironment {
   19|     18|    pub fn new(options: EnvironmentOptions) -> lmdb::Result<Self> {
   20|     18|        Ok(Self(EnvironmentStrategy::Real(EnvironmentWrapper::build(
   21|     18|            options,
   22|     18|        )?)))
                       ^0
   23|     18|    }
   24|       |
   25|      0|    pub fn new_with(env: lmdb::Environment) -> Self {
   26|      0|        Self(EnvironmentStrategy::Real(EnvironmentWrapper::new(env)))
   27|      0|    }
   28|       |
   29|      2|    pub fn new_null() -> Self {
   30|      2|        Self(EnvironmentStrategy::Nulled(EnvironmentStub {
   31|      2|            databases: Vec::new(),
   32|      2|        }))
   33|      2|    }
   34|       |
   35|     20|    pub fn new_null_with(databases: Vec<ConfiguredDatabase>) -> Self {
   36|     20|        Self(EnvironmentStrategy::Nulled(EnvironmentStub { databases }))
   37|     20|    }
   38|       |
   39|      0|    pub fn null_builder() -> EnvironmentStubBuilder {
   40|      0|        EnvironmentStubBuilder::default()
   41|      0|    }
   42|       |
   43|  2.34k|    pub fn begin_ro_txn(&self) -> lmdb::Result<RoTransaction> {
   44|  2.34k|        match &self.0 {
   45|    534|            EnvironmentStrategy::Real(s) => s.begin_ro_txn(),
   46|  1.81k|            EnvironmentStrategy::Nulled(s) => s.begin_ro_txn(),
   47|       |        }
   48|  2.34k|    }
   49|       |
   50|     91|    pub fn begin_rw_txn(&self) -> lmdb::Result<RwTransaction> {
   51|     91|        match &self.0 {
   52|     51|            EnvironmentStrategy::Real(s) => s.begin_rw_txn(),
   53|     40|            EnvironmentStrategy::Nulled(s) => s.begin_rw_txn(),
   54|       |        }
   55|     91|    }
   56|       |
   57|    275|    pub fn create_db(
   58|    275|        &self,
   59|    275|        name: Option<&str>,
   60|    275|        flags: DatabaseFlags,
   61|    275|    ) -> lmdb::Result<LmdbDatabase> {
   62|    275|        match &self.0 {
   63|     55|            EnvironmentStrategy::Real(s) => s.create_db(name, flags),
   64|    220|            EnvironmentStrategy::Nulled(s) => s.create_db(name, flags),
   65|       |        }
   66|    275|    }
   67|       |
   68|      0|    pub fn env(&self) -> *mut MDB_env {
   69|      0|        match &self.0 {
   70|      0|            EnvironmentStrategy::Real(s) => s.env(),
   71|      0|            EnvironmentStrategy::Nulled(_) => unimplemented!(),
   72|       |        }
   73|      0|    }
   74|       |
   75|      5|    pub fn open_db(&self, name: Option<&str>) -> lmdb::Result<LmdbDatabase> {
   76|      5|        match &self.0 {
   77|      5|            EnvironmentStrategy::Real(s) => s.open_db(name),
   78|      0|            EnvironmentStrategy::Nulled(s) => s.open_db(name),
   79|       |        }
   80|      5|    }
   81|       |
   82|     40|    pub fn sync(&self, force: bool) -> lmdb::Result<()> {
   83|     40|        if let EnvironmentStrategy::Real(s) = &self.0 {
                                                       ^18
   84|     18|            s.sync(force)?;
                                       ^0
   85|     22|        }
   86|     40|        Ok(())
   87|     40|    }
   88|       |
   89|      0|    pub fn stat(&self) -> lmdb::Result<Stat> {
   90|      0|        match &self.0 {
   91|      0|            EnvironmentStrategy::Real(s) => s.stat(),
   92|      0|            EnvironmentStrategy::Nulled(s) => s.stat(),
   93|       |        }
   94|      0|    }
   95|       |}
   96|       |
   97|       |enum EnvironmentStrategy {
   98|       |    Nulled(EnvironmentStub),
   99|       |    Real(EnvironmentWrapper),
  100|       |}
  101|       |
  102|       |struct EnvironmentWrapper(lmdb::Environment);
  103|       |
  104|       |impl EnvironmentWrapper {
  105|      0|    fn new(env: lmdb::Environment) -> Self {
  106|      0|        Self(env)
  107|      0|    }
  108|       |
  109|     18|    fn build(options: EnvironmentOptions) -> lmdb::Result<Self> {
  110|     18|        let env = lmdb::Environment::new()
  111|     18|            .set_max_dbs(options.max_dbs)
  112|     18|            .set_map_size(options.map_size)
  113|     18|            .set_flags(options.flags)
  114|     18|            .open_with_permissions(options.path, options.file_mode.try_into().unwrap())?;
                                                                                                     ^0
  115|     18|        Ok(Self(env))
  116|     18|    }
  117|       |
  118|    534|    fn begin_ro_txn(&self) -> lmdb::Result<RoTransaction> {
  119|    534|        self.0.begin_ro_txn().map(|txn| {
  120|    534|            // todo: don't use static life time
  121|    534|            let txn = unsafe {
  122|    534|                std::mem::transmute::<lmdb::RoTransaction<'_>, lmdb::RoTransaction<'static>>(txn)
  123|    534|            };
  124|    534|            RoTransaction::new(txn)
  125|    534|        })
  126|    534|    }
  127|       |
  128|     51|    fn begin_rw_txn(&self) -> lmdb::Result<RwTransaction> {
  129|     51|        self.0.begin_rw_txn().map(|txn| {
  130|     51|            // todo: don't use static life time
  131|     51|            let txn = unsafe {
  132|     51|                std::mem::transmute::<lmdb::RwTransaction<'_>, lmdb::RwTransaction<'static>>(txn)
  133|     51|            };
  134|     51|            RwTransaction::new(txn)
  135|     51|        })
  136|     51|    }
  137|       |
  138|     55|    fn create_db(&self, name: Option<&str>, flags: DatabaseFlags) -> lmdb::Result<LmdbDatabase> {
  139|     55|        self.0.create_db(name, flags).map(LmdbDatabase::new)
  140|     55|    }
  141|       |
  142|      0|    fn env(&self) -> *mut MDB_env {
  143|      0|        self.0.env()
  144|      0|    }
  145|       |
  146|      5|    fn open_db(&self, name: Option<&str>) -> lmdb::Result<LmdbDatabase> {
  147|      5|        self.0.open_db(name).map(LmdbDatabase::new)
  148|      5|    }
  149|       |
  150|     18|    fn sync(&self, force: bool) -> lmdb::Result<()> {
  151|     18|        self.0.sync(force)
  152|     18|    }
  153|       |
  154|      0|    fn stat(&self) -> lmdb::Result<Stat> {
  155|      0|        self.0.stat()
  156|      0|    }
  157|       |}
  158|       |
  159|       |struct EnvironmentStub {
  160|       |    databases: Vec<ConfiguredDatabase>,
  161|       |}
  162|       |
  163|       |impl EnvironmentStub {
  164|  1.81k|    fn begin_ro_txn(&self) -> lmdb::Result<RoTransaction> {
  165|  1.81k|        //todo  don't clone!
  166|  1.81k|        Ok(RoTransaction::new_null(self.databases.clone()))
  167|  1.81k|    }
  168|       |
  169|     40|    fn begin_rw_txn(&self) -> lmdb::Result<RwTransaction> {
  170|     40|        //todo  don't clone!
  171|     40|        Ok(RwTransaction::new_null(self.databases.clone()))
  172|     40|    }
  173|       |
  174|    220|    fn create_db(&self, name: Option<&str>, _flags: DatabaseFlags) -> lmdb::Result<LmdbDatabase> {
  175|    220|        Ok(self
  176|    220|            .databases
  177|    220|            .iter()
  178|    900|            .find(|x| name == Some(&x.db_name))
  179|    220|            .map(|x| x.dbi)
                                   ^120
  180|    220|            .unwrap_or(LmdbDatabase::new_null(42)))
  181|    220|    }
  182|       |
  183|      0|    fn open_db(&self, name: Option<&str>) -> lmdb::Result<LmdbDatabase> {
  184|      0|        self.create_db(name, DatabaseFlags::empty())
  185|      0|    }
  186|       |
  187|      0|    fn stat(&self) -> lmdb::Result<Stat> {
  188|      0|        todo!()
  189|       |    }
  190|       |}
  191|       |
  192|       |#[derive(Default)]
  193|       |pub struct EnvironmentStubBuilder {
  194|       |    databases: Vec<ConfiguredDatabase>,
  195|       |}
  196|       |
  197|       |impl EnvironmentStubBuilder {
  198|      0|    pub fn database(self, name: impl Into<String>, dbi: LmdbDatabase) -> ConfiguredDatabaseBuilder {
  199|      0|        ConfiguredDatabaseBuilder::new(name, dbi, self)
  200|      0|    }
  201|       |
  202|    120|    pub fn configured_database(mut self, db: ConfiguredDatabase) -> Self {
  203|    120|        if self
  204|    120|            .databases
  205|    120|            .iter()
  206|    300|            .any(|x| x.dbi == db.dbi || x.db_name == db.db_name)
                                                                             ^120
  207|       |        {
  208|      0|            panic!(
  209|      0|                "trying to duplicated database for {} / {}",
  210|      0|                db.dbi.as_nulled(),
  211|      0|                db.db_name
  212|      0|            );
  213|    120|        }
  214|    120|        self.databases.push(db);
  215|    120|        self
  216|    120|    }
  217|       |
  218|     20|    pub fn finish(self) -> LmdbEnvironment {
  219|     20|        LmdbEnvironment::new_null_with(self.databases)
  220|     20|    }
  221|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/ro_cursor.rs:
    1|       |use crate::EMPTY_DATABASE;
    2|       |
    3|       |use super::ConfiguredDatabase;
    4|       |use lmdb_sys::{MDB_FIRST, MDB_LAST, MDB_NEXT, MDB_PREV, MDB_SET_RANGE};
    5|       |use std::{cell::Cell, collections::btree_map};
    6|       |
    7|       |pub struct RoCursor<'txn>(RoCursorStrategy<'txn>);
    8|       |
    9|       |impl<'txn> RoCursor<'txn> {
   10|      0|    pub fn new_null() -> Self {
   11|      0|        Self::new_null_with(&EMPTY_DATABASE)
   12|      0|    }
   13|       |
   14|  1.80k|    pub fn new_null_with(database: &'txn ConfiguredDatabase) -> Self {
   15|  1.80k|        Self(RoCursorStrategy::Nulled(RoCursorStub {
   16|  1.80k|            database,
   17|  1.80k|            current: Cell::new(0),
   18|  1.80k|        }))
   19|  1.80k|    }
   20|       |
   21|    558|    pub fn new(cursor: lmdb::RoCursor<'txn>) -> Self {
   22|    558|        Self(RoCursorStrategy::Real(cursor))
   23|    558|    }
   24|       |
   25|      0|    pub fn iter_start(&mut self) -> Iter<'txn> {
   26|      0|        match &mut self.0 {
   27|      0|            RoCursorStrategy::Real(s) => Iter::Real(lmdb::Cursor::iter_start(s)),
   28|      0|            RoCursorStrategy::Nulled(s) => s.iter_start(),
   29|       |        }
   30|      0|    }
   31|       |
   32|  2.48k|    pub fn get(
   33|  2.48k|        &self,
   34|  2.48k|        key: Option<&[u8]>,
   35|  2.48k|        data: Option<&[u8]>,
   36|  2.48k|        op: u32,
   37|  2.48k|    ) -> lmdb::Result<(Option<&'txn [u8]>, &'txn [u8])> {
   38|  2.48k|        match &self.0 {
   39|    667|            RoCursorStrategy::Real(s) => lmdb::Cursor::get(s, key, data, op),
   40|  1.82k|            RoCursorStrategy::Nulled(s) => s.get(key, data, op),
   41|       |        }
   42|  2.48k|    }
   43|       |}
   44|       |
   45|       |enum RoCursorStrategy<'txn> {
   46|       |    //todo don't use static lifetimes!
   47|       |    Real(lmdb::RoCursor<'txn>),
   48|       |    Nulled(RoCursorStub<'txn>),
   49|       |}
   50|       |
   51|       |struct RoCursorStub<'txn> {
   52|       |    database: &'txn ConfiguredDatabase,
   53|       |    current: Cell<i32>,
   54|       |}
   55|       |
   56|       |impl<'txn> RoCursorStub<'txn> {
   57|  1.82k|    fn get(
   58|  1.82k|        &self,
   59|  1.82k|        key: Option<&[u8]>,
   60|  1.82k|        _data: Option<&[u8]>,
   61|  1.82k|        op: u32,
   62|  1.82k|    ) -> lmdb::Result<(Option<&'txn [u8]>, &'txn [u8])> {
   63|  1.82k|        if op == MDB_FIRST {
   64|     42|            self.current.set(0);
   65|  1.77k|        } else if op == MDB_LAST {
   66|      0|            let entry_count = self.database.entries.len();
   67|      0|            self.current.set((entry_count as i32) - 1);
   68|  1.77k|        } else if op == MDB_NEXT {
   69|     18|            self.current.set(self.current.get() + 1);
   70|  1.76k|        } else if op == MDB_PREV {
   71|      0|            self.current.set(self.current.get() - 1);
   72|  1.76k|        } else if op == MDB_SET_RANGE {
   73|  1.76k|            self.current.set(
   74|  1.76k|                self.database
   75|  1.76k|                    .entries
   76|  1.76k|                    .keys()
   77|  1.76k|                    .enumerate()
   78|  1.76k|                    .find_map(|(i, k)| {
   79|     40|                        if Some(k.as_slice()) >= key {
   80|     28|                            Some(i as i32)
   81|       |                        } else {
   82|     12|                            None
   83|       |                        }
   84|  1.76k|                    })
                                  ^40
   85|  1.76k|                    .unwrap_or(i32::MAX),
   86|  1.76k|            );
   87|  1.76k|        } else {
   88|      0|            unimplemented!()
   89|       |        }
   90|       |
   91|  1.82k|        let current = self.current.get();
   92|  1.82k|        if current < 0 {
   93|      0|            return Err(lmdb::Error::NotFound);
   94|  1.82k|        }
   95|  1.82k|
   96|  1.82k|        self.database
   97|  1.82k|            .entries
   98|  1.82k|            .iter()
   99|  1.82k|            .nth(current as usize)
  100|  1.82k|            .map(|(k, v)| (Some(k.as_slice()), v.as_slice()))
                                        ^45
  101|  1.82k|            .ok_or(lmdb::Error::NotFound)
  102|  1.82k|    }
  103|       |
  104|      0|    fn iter_start(&self) -> Iter<'txn> {
  105|      0|        Iter::Stub(self.database.entries.iter())
  106|      0|    }
  107|       |}
  108|       |
  109|       |pub enum Iter<'a> {
  110|       |    Real(lmdb::Iter<'static>),
  111|       |    Stub(btree_map::Iter<'a, Vec<u8>, Vec<u8>>),
  112|       |}
  113|       |
  114|       |impl<'a> Iterator for Iter<'a> {
  115|       |    type Item = lmdb::Result<(&'static [u8], &'static [u8])>;
  116|       |
  117|      0|    fn next(&mut self) -> Option<Self::Item> {
  118|      0|        match self {
  119|      0|            Iter::Real(i) => i.next(),
  120|      0|            Iter::Stub(iter) => iter.next().map(|(k, v)| unsafe {
  121|      0|                Ok((
  122|      0|                    std::mem::transmute::<&'a [u8], &'static [u8]>(k.as_slice()),
  123|      0|                    std::mem::transmute::<&'a [u8], &'static [u8]>(v.as_slice()),
  124|      0|                ))
  125|      0|            }),
  126|       |        }
  127|      0|    }
  128|       |}
  129|       |
  130|       |#[cfg(test)]
  131|       |mod tests {
  132|       |    use super::*;
  133|       |    use crate::{LmdbDatabase, LmdbEnvironment};
  134|       |    use lmdb::{DatabaseFlags, EnvironmentFlags, Transaction, WriteFlags};
  135|       |    use std::path::Path;
  136|       |
  137|       |    #[test]
  138|       |    fn iter() {
  139|       |        let _guard1 = FileDropGuard::new("/tmp/rsnano-cursor-test.ldb".as_ref());
  140|       |        let _guard2 = FileDropGuard::new("/tmp/rsnano-cursor-test.ldb-lock".as_ref());
  141|       |        let env = create_real_lmdb_env("/tmp/rsnano-cursor-test.ldb");
  142|       |        create_test_database(&env);
  143|       |        let env = LmdbEnvironment::new_with(env);
  144|       |        let database = env.open_db(Some("foo")).unwrap();
  145|       |        let tx = env.begin_ro_txn().unwrap();
  146|       |        let mut cursor = tx.open_ro_cursor(database).unwrap();
  147|       |
  148|       |        let result: Vec<_> = cursor.iter_start().map(|i| i.unwrap()).collect();
  149|       |
  150|       |        assert_eq!(
  151|       |            result,
  152|       |            vec![
  153|       |                (b"hello".as_ref(), b"world".as_ref()),
  154|       |                (b"hello2", b"world2"),
  155|       |                (b"hello3", b"world3")
  156|       |            ]
  157|       |        );
  158|       |    }
  159|       |
  160|       |    #[test]
  161|       |    fn iter_backwards() {
  162|       |        let _guard1 = FileDropGuard::new("/tmp/rsnano-rev-cursor-test.ldb".as_ref());
  163|       |        let _guard2 = FileDropGuard::new("/tmp/rsnano-rev-cursor-test.ldb-lock".as_ref());
  164|       |        let env = create_real_lmdb_env("/tmp/rsnano-rev-cursor-test.ldb");
  165|       |        create_test_database(&env);
  166|       |        let env = LmdbEnvironment::new_with(env);
  167|       |        let database = env.open_db(Some("foo")).unwrap();
  168|       |        let tx = env.begin_ro_txn().unwrap();
  169|       |        let cursor = tx.open_ro_cursor(database).unwrap();
  170|       |
  171|       |        assert_eq!(
  172|       |            cursor.get(None, None, MDB_LAST).unwrap(),
  173|       |            (Some(b"hello3".as_ref()), b"world3".as_ref())
  174|       |        );
  175|       |
  176|       |        assert_eq!(
  177|       |            cursor.get(None, None, MDB_PREV).unwrap(),
  178|       |            (Some(b"hello2".as_ref()), b"world2".as_ref())
  179|       |        );
  180|       |    }
  181|       |
  182|       |    mod nullability {
  183|       |        use super::*;
  184|       |
  185|       |        const TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(42);
  186|       |        const TEST_DATABASE_NAME: &str = "foo";
  187|       |
  188|       |        #[test]
  189|       |        fn iter_from_start() {
  190|       |            let env = nulled_env_with_foo_database();
  191|       |            let txn = env.begin_ro_txn().unwrap();
  192|       |            let mut cursor = txn.open_ro_cursor(TEST_DATABASE).unwrap();
  193|       |
  194|       |            let result: Vec<([u8; 3], [u8; 3])> = cursor
  195|       |                .iter_start()
  196|       |                .map(|i| i.unwrap())
  197|       |                .map(|(k, v)| (k.try_into().unwrap(), v.try_into().unwrap()))
  198|       |                .collect();
  199|       |
  200|       |            assert_eq!(
  201|       |                result,
  202|       |                vec![
  203|       |                    ([1, 1, 1], [6, 6, 6]),
  204|       |                    ([2, 2, 2], [7, 7, 7]),
  205|       |                    ([3, 3, 3], [8, 8, 8])
  206|       |                ]
  207|       |            )
  208|       |        }
  209|       |
  210|       |        #[test]
  211|       |        fn nulled_cursor_can_be_iterated_forwards() {
  212|       |            let env = nulled_env_with_foo_database();
  213|       |            let txn = env.begin_ro_txn().unwrap();
  214|       |
  215|       |            let cursor = txn.open_ro_cursor(LmdbDatabase::new_null(42)).unwrap();
  216|       |
  217|       |            let (k, v) = cursor.get(None, None, MDB_FIRST).unwrap();
  218|       |            assert_eq!(k, Some([1, 1, 1].as_slice()));
  219|       |            assert_eq!(v, [6, 6, 6].as_slice());
  220|       |
  221|       |            let (k, v) = cursor.get(None, None, MDB_NEXT).unwrap();
  222|       |            assert_eq!(k, Some([2, 2, 2].as_slice()));
  223|       |            assert_eq!(v, [7, 7, 7].as_slice());
  224|       |
  225|       |            let (k, v) = cursor.get(None, None, MDB_NEXT).unwrap();
  226|       |            assert_eq!(k, Some([3, 3, 3].as_slice()));
  227|       |            assert_eq!(v, [8, 8, 8].as_slice());
  228|       |
  229|       |            let result = cursor.get(None, None, MDB_NEXT);
  230|       |            assert_eq!(result, Err(lmdb::Error::NotFound));
  231|       |        }
  232|       |
  233|       |        #[test]
  234|       |        fn nulled_cursor_can_be_iterated_backwards() {
  235|       |            let env = nulled_env_with_foo_database();
  236|       |            let txn = env.begin_ro_txn().unwrap();
  237|       |            let cursor = txn.open_ro_cursor(TEST_DATABASE).unwrap();
  238|       |
  239|       |            let (k, v) = cursor.get(None, None, MDB_LAST).unwrap();
  240|       |            assert_eq!(k, Some([3, 3, 3].as_slice()));
  241|       |            assert_eq!(v, [8, 8, 8].as_slice());
  242|       |
  243|       |            let (k, v) = cursor.get(None, None, MDB_PREV).unwrap();
  244|       |            assert_eq!(k, Some([2, 2, 2].as_slice()));
  245|       |            assert_eq!(v, [7, 7, 7].as_slice());
  246|       |
  247|       |            let (k, v) = cursor.get(None, None, MDB_PREV).unwrap();
  248|       |            assert_eq!(k, Some([1, 1, 1].as_slice()));
  249|       |            assert_eq!(v, [6, 6, 6].as_slice());
  250|       |
  251|       |            let result = cursor.get(None, None, MDB_PREV);
  252|       |            assert_eq!(result, Err(lmdb::Error::NotFound));
  253|       |        }
  254|       |
  255|       |        #[test]
  256|       |        fn nulled_cursor_can_start_at_specified_key() {
  257|       |            let env = nulled_env_with_foo_database();
  258|       |            let txn = env.begin_ro_txn().unwrap();
  259|       |
  260|       |            let cursor = txn.open_ro_cursor(TEST_DATABASE).unwrap();
  261|       |            let (k, v) = cursor
  262|       |                .get(Some([2u8, 2, 2].as_slice()), None, MDB_SET_RANGE)
  263|       |                .unwrap();
  264|       |            assert_eq!(k, Some([2, 2, 2].as_slice()));
  265|       |            assert_eq!(v, [7, 7, 7].as_slice());
  266|       |
  267|       |            let (k, v) = cursor
  268|       |                .get(Some([2u8, 1, 0].as_slice()), None, MDB_SET_RANGE)
  269|       |                .unwrap();
  270|       |            assert_eq!(k, Some([2, 2, 2].as_slice()));
  271|       |            assert_eq!(v, [7, 7, 7].as_slice());
  272|       |        }
  273|       |
  274|       |        fn nulled_env_with_foo_database() -> LmdbEnvironment {
  275|       |            LmdbEnvironment::null_builder()
  276|       |                .database(TEST_DATABASE_NAME, TEST_DATABASE)
  277|       |                .entry(&[1, 1, 1], &[6, 6, 6])
  278|       |                .entry(&[2, 2, 2], &[7, 7, 7])
  279|       |                .entry(&[3, 3, 3], &[8, 8, 8])
  280|       |                .finish()
  281|       |                .finish()
  282|       |        }
  283|       |    }
  284|       |
  285|       |    fn create_test_database(env: &lmdb::Environment) {
  286|       |        env.create_db(Some("foo"), DatabaseFlags::empty()).unwrap();
  287|       |        let database = env.open_db(Some("foo")).unwrap();
  288|       |        {
  289|       |            let mut tx = env.begin_rw_txn().unwrap();
  290|       |            tx.put(database, b"hello", b"world", WriteFlags::empty())
  291|       |                .unwrap();
  292|       |            tx.put(database, b"hello2", b"world2", WriteFlags::empty())
  293|       |                .unwrap();
  294|       |            tx.put(database, b"hello3", b"world3", WriteFlags::empty())
  295|       |                .unwrap();
  296|       |            tx.commit().unwrap();
  297|       |        }
  298|       |    }
  299|       |
  300|       |    fn create_real_lmdb_env(path: impl AsRef<Path>) -> lmdb::Environment {
  301|       |        lmdb::Environment::new()
  302|       |            .set_max_dbs(1)
  303|       |            .set_map_size(1024 * 1024)
  304|       |            .set_flags(
  305|       |                EnvironmentFlags::NO_SUB_DIR
  306|       |                    | EnvironmentFlags::NO_TLS
  307|       |                    | EnvironmentFlags::NO_READAHEAD,
  308|       |            )
  309|       |            .open(path.as_ref())
  310|       |            .expect("Could not create LMDB environment")
  311|       |    }
  312|       |
  313|       |    struct FileDropGuard<'a> {
  314|       |        path: &'a Path,
  315|       |    }
  316|       |
  317|       |    impl<'a> FileDropGuard<'a> {
  318|       |        fn new(path: &'a Path) -> Self {
  319|       |            Self { path }
  320|       |        }
  321|       |    }
  322|       |
  323|       |    impl<'a> Drop for FileDropGuard<'a> {
  324|       |        fn drop(&mut self) {
  325|       |            if self.path.exists() {
  326|       |                let _ = std::fs::remove_file(self.path);
  327|       |            }
  328|       |        }
  329|       |    }
  330|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/ro_transaction.rs:
    1|       |use super::{ConfiguredDatabase, LmdbDatabase, RoCursor};
    2|       |use crate::EMPTY_DATABASE;
    3|       |
    4|       |pub struct RoTransaction {
    5|       |    strategy: RoTransactionStrategy,
    6|       |}
    7|       |
    8|       |impl RoTransaction {
    9|    534|    pub fn new(tx: lmdb::RoTransaction<'static>) -> Self {
   10|    534|        Self {
   11|    534|            strategy: RoTransactionStrategy::Real(RoTransactionWrapper(tx)),
   12|    534|        }
   13|    534|    }
   14|       |
   15|  1.81k|    pub fn new_null(databases: Vec<ConfiguredDatabase>) -> Self {
   16|  1.81k|        Self {
   17|  1.81k|            strategy: RoTransactionStrategy::Nulled(RoTransactionStub { databases }),
   18|  1.81k|        }
   19|  1.81k|    }
   20|       |
   21|      0|    pub fn reset(self) -> InactiveTransaction {
   22|      0|        match self.strategy {
   23|      0|            RoTransactionStrategy::Real(s) => InactiveTransaction {
   24|      0|                strategy: InactiveTransactionStrategy::Real(s.reset()),
   25|      0|            },
   26|      0|            RoTransactionStrategy::Nulled(s) => InactiveTransaction {
   27|      0|                strategy: InactiveTransactionStrategy::Nulled(s.reset()),
   28|      0|            },
   29|       |        }
   30|      0|    }
   31|       |
   32|  2.34k|    pub fn commit(self) -> lmdb::Result<()> {
   33|  2.34k|        if let RoTransactionStrategy::Real(s) = self.strategy {
                                                         ^534
   34|    534|            s.commit()?;
                                    ^0
   35|  1.81k|        }
   36|  2.34k|        Ok(())
   37|  2.34k|    }
   38|       |
   39|     36|    pub fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
   40|     36|        match &self.strategy {
   41|     36|            RoTransactionStrategy::Real(s) => s.get(database, key),
   42|      0|            RoTransactionStrategy::Nulled(s) => s.get(database, key),
   43|       |        }
   44|     36|    }
   45|       |
   46|  2.30k|    pub fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
   47|  2.30k|        match &self.strategy {
   48|    514|            RoTransactionStrategy::Real(s) => s.open_ro_cursor(database),
   49|  1.79k|            RoTransactionStrategy::Nulled(s) => s.open_ro_cursor(database),
   50|       |        }
   51|  2.30k|    }
   52|       |
   53|     30|    pub fn count(&self, database: LmdbDatabase) -> u64 {
   54|     30|        match &self.strategy {
   55|      8|            RoTransactionStrategy::Real(s) => s.count(database),
   56|     22|            RoTransactionStrategy::Nulled(s) => s.count(database),
   57|       |        }
   58|     30|    }
   59|       |}
   60|       |
   61|       |enum RoTransactionStrategy {
   62|       |    Real(RoTransactionWrapper),
   63|       |    Nulled(RoTransactionStub),
   64|       |}
   65|       |
   66|       |struct RoTransactionWrapper(lmdb::RoTransaction<'static>);
   67|       |
   68|       |impl RoTransactionWrapper {
   69|      0|    fn reset(self) -> InactiveTransactionWrapper {
   70|      0|        InactiveTransactionWrapper {
   71|      0|            inactive: self.0.reset(),
   72|      0|        }
   73|      0|    }
   74|       |
   75|    534|    fn commit(self) -> lmdb::Result<()> {
   76|    534|        lmdb::Transaction::commit(self.0)
   77|    534|    }
   78|       |
   79|     36|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
   80|     36|        lmdb::Transaction::get(&self.0, database.as_real(), &key)
   81|     36|    }
   82|       |
   83|    514|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
   84|    514|        lmdb::Transaction::open_ro_cursor(&self.0, database.as_real()).map(|c| {
   85|    514|            //todo don't use static lifetime
   86|    514|            let c =
   87|    514|                unsafe { std::mem::transmute::<lmdb::RoCursor<'_>, lmdb::RoCursor<'static>>(c) };
   88|    514|            RoCursor::new(c)
   89|    514|        })
   90|    514|    }
   91|       |
   92|      8|    fn count(&self, database: LmdbDatabase) -> u64 {
   93|      8|        let stat = lmdb::Transaction::stat(&self.0, database.as_real());
   94|      8|        stat.unwrap().entries() as u64
   95|      8|    }
   96|       |}
   97|       |
   98|       |struct RoTransactionStub {
   99|       |    databases: Vec<ConfiguredDatabase>,
  100|       |}
  101|       |
  102|       |impl RoTransactionStub {
  103|  1.81k|    fn get_database(&self, database: LmdbDatabase) -> Option<&ConfiguredDatabase> {
  104|  5.77k|        self.databases.iter().find(|d| d.dbi == database)
  105|  1.81k|    }
  106|       |
  107|      0|    fn reset(self) -> NullInactiveTransaction
  108|      0|    where
  109|      0|        Self: Sized,
  110|      0|    {
  111|      0|        NullInactiveTransaction {
  112|      0|            databases: self.databases,
  113|      0|        }
  114|      0|    }
  115|       |
  116|      0|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
  117|      0|        let Some(db) = self.get_database(database) else {
  118|      0|            return Err(lmdb::Error::NotFound);
  119|       |        };
  120|      0|        match db.entries.get(key) {
  121|      0|            Some(value) => Ok(value),
  122|      0|            None => Err(lmdb::Error::NotFound),
  123|       |        }
  124|      0|    }
  125|       |
  126|  1.79k|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
  127|  1.79k|        match self.get_database(database) {
  128|  1.62k|            Some(db) => Ok(RoCursor::new_null_with(db)),
  129|    162|            None => Ok(RoCursor::new_null_with(&EMPTY_DATABASE)),
  130|       |        }
  131|  1.79k|    }
  132|       |
  133|     22|    fn count(&self, database: LmdbDatabase) -> u64 {
  134|     22|        self.get_database(database)
  135|     22|            .map(|db| db.entries.len())
                                    ^20
  136|     22|            .unwrap_or_default() as u64
  137|     22|    }
  138|       |}
  139|       |
  140|       |pub struct InactiveTransaction {
  141|       |    strategy: InactiveTransactionStrategy,
  142|       |}
  143|       |
  144|       |enum InactiveTransactionStrategy {
  145|       |    Real(InactiveTransactionWrapper),
  146|       |    Nulled(NullInactiveTransaction),
  147|       |}
  148|       |
  149|       |impl InactiveTransaction {
  150|      0|    pub fn renew(self) -> lmdb::Result<RoTransaction> {
  151|      0|        match self.strategy {
  152|      0|            InactiveTransactionStrategy::Real(s) => Ok(RoTransaction {
  153|      0|                strategy: RoTransactionStrategy::Real(s.renew()?),
  154|       |            }),
  155|      0|            InactiveTransactionStrategy::Nulled(s) => Ok(RoTransaction {
  156|      0|                strategy: RoTransactionStrategy::Nulled(s.renew()?),
  157|       |            }),
  158|       |        }
  159|      0|    }
  160|       |}
  161|       |
  162|       |pub struct InactiveTransactionWrapper {
  163|       |    inactive: lmdb::InactiveTransaction<'static>,
  164|       |}
  165|       |
  166|       |impl InactiveTransactionWrapper {
  167|      0|    fn renew(self) -> lmdb::Result<RoTransactionWrapper> {
  168|      0|        self.inactive.renew().map(RoTransactionWrapper)
  169|      0|    }
  170|       |}
  171|       |
  172|       |pub struct NullInactiveTransaction {
  173|       |    databases: Vec<ConfiguredDatabase>,
  174|       |}
  175|       |
  176|       |impl NullInactiveTransaction {
  177|      0|    fn renew(self) -> lmdb::Result<RoTransactionStub> {
  178|      0|        Ok(RoTransactionStub {
  179|      0|            databases: self.databases,
  180|      0|        })
  181|      0|    }
  182|       |}

/home/gustav/code/nano/rsnano-node/nullables/lmdb/src/rw_transaction.rs:
    1|       |use super::{ConfiguredDatabase, LmdbDatabase, RoCursor};
    2|       |use lmdb::DatabaseFlags;
    3|       |
    4|       |pub struct RwTransaction {
    5|       |    strategy: RwTransactionStrategy,
    6|       |}
    7|       |
    8|       |impl RwTransaction {
    9|     51|    pub fn new(tx: lmdb::RwTransaction<'static>) -> Self {
   10|     51|        Self {
   11|     51|            strategy: RwTransactionStrategy::Real(RwTransactionWrapper(tx)),
   12|     51|        }
   13|     51|    }
   14|       |
   15|     40|    pub fn new_null(databases: Vec<ConfiguredDatabase>) -> Self {
   16|     40|        Self {
   17|     40|            strategy: RwTransactionStrategy::Nulled(RwTransactionStub { databases }),
   18|     40|        }
   19|     40|    }
   20|       |
   21|   164k|    pub fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
   22|   164k|        match &self.strategy {
   23|    285|            RwTransactionStrategy::Real(s) => s.get(database, key),
   24|   163k|            RwTransactionStrategy::Nulled(s) => s.get(database, key),
   25|       |        }
   26|   164k|    }
   27|       |
   28|  16.6k|    pub fn put(
   29|  16.6k|        &mut self,
   30|  16.6k|        database: LmdbDatabase,
   31|  16.6k|        key: &[u8],
   32|  16.6k|        data: &[u8],
   33|  16.6k|        flags: lmdb::WriteFlags,
   34|  16.6k|    ) -> lmdb::Result<()> {
   35|  16.6k|        if let RwTransactionStrategy::Real(s) = &mut self.strategy {
                                                         ^177
   36|    177|            s.put(database.as_real(), key, data, flags)?;
                                                                     ^0
   37|  16.4k|        }
   38|  16.6k|        Ok(())
   39|  16.6k|    }
   40|       |
   41|      6|    pub fn del(
   42|      6|        &mut self,
   43|      6|        database: LmdbDatabase,
   44|      6|        key: &[u8],
   45|      6|        flags: Option<&[u8]>,
   46|      6|    ) -> lmdb::Result<()> {
   47|      6|        if let RwTransactionStrategy::Real(s) = &mut self.strategy {
                                                         ^4
   48|      4|            s.del(database.as_real(), key, flags)?;
                                                               ^0
   49|      2|        }
   50|      6|        Ok(())
   51|      6|    }
   52|       |
   53|       |    /// ## Safety
   54|       |    ///
   55|       |    /// This function (as well as `Environment::open_db`,
   56|       |    /// `Environment::create_db`, and `Database::open`) **must not** be called
   57|       |    /// from multiple concurrent transactions in the same environment. A
   58|       |    /// transaction which uses this function must finish (either commit or
   59|       |    /// abort) before any other transaction may use this function.
   60|      6|    pub unsafe fn create_db(
   61|      6|        &self,
   62|      6|        name: Option<&str>,
   63|      6|        flags: DatabaseFlags,
   64|      6|    ) -> lmdb::Result<LmdbDatabase> {
   65|      6|        match &self.strategy {
   66|      6|            RwTransactionStrategy::Real(s) => s.create_db(name, flags),
   67|      0|            RwTransactionStrategy::Nulled(s) => s.create_db(name, flags),
   68|       |        }
   69|      6|    }
   70|       |
   71|       |    /// ## Safety
   72|       |    ///
   73|       |    /// This method is unsafe in the same ways as `Environment::close_db`, and
   74|       |    /// should be used accordingly.
   75|      0|    pub unsafe fn drop_db(&mut self, database: LmdbDatabase) -> lmdb::Result<()> {
   76|      0|        if let RwTransactionStrategy::Real(s) = &mut self.strategy {
   77|      0|            s.drop_db(database.as_real())?;
   78|      0|        }
   79|      0|        Ok(())
   80|      0|    }
   81|       |
   82|      0|    pub fn clear_db(&mut self, database: LmdbDatabase) -> lmdb::Result<()> {
   83|      0|        if let RwTransactionStrategy::Real(s) = &mut self.strategy {
   84|      0|            s.clear_db(database.as_real())?;
   85|      0|        }
   86|      0|        Ok(())
   87|      0|    }
   88|       |
   89|     55|    pub fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
   90|     55|        match &self.strategy {
   91|     44|            RwTransactionStrategy::Real(s) => s.open_ro_cursor(database),
   92|     11|            RwTransactionStrategy::Nulled(s) => s.open_ro_cursor(database),
   93|       |        }
   94|     55|    }
   95|       |
   96|      0|    pub fn count(&self, database: LmdbDatabase) -> u64 {
   97|      0|        match &self.strategy {
   98|      0|            RwTransactionStrategy::Real(s) => s.count(database.as_real()),
   99|      0|            RwTransactionStrategy::Nulled(_) => 0,
  100|       |        }
  101|      0|    }
  102|       |
  103|     91|    pub fn commit(self) -> lmdb::Result<()> {
  104|     91|        if let RwTransactionStrategy::Real(s) = self.strategy {
                                                         ^51
  105|     51|            s.commit()?;
                                    ^0
  106|     40|        }
  107|     91|        Ok(())
  108|     91|    }
  109|       |}
  110|       |
  111|       |enum RwTransactionStrategy {
  112|       |    Real(RwTransactionWrapper),
  113|       |    Nulled(RwTransactionStub),
  114|       |}
  115|       |
  116|       |pub struct RwTransactionWrapper(lmdb::RwTransaction<'static>);
  117|       |
  118|       |impl RwTransactionWrapper {
  119|    285|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
  120|    285|        lmdb::Transaction::get(&self.0, database.as_real(), &key)
  121|    285|    }
  122|       |
  123|    177|    fn put(
  124|    177|        &mut self,
  125|    177|        database: lmdb::Database,
  126|    177|        key: &[u8],
  127|    177|        data: &[u8],
  128|    177|        flags: lmdb::WriteFlags,
  129|    177|    ) -> lmdb::Result<()> {
  130|    177|        lmdb::RwTransaction::put(&mut self.0, database, &key, &data, flags)
  131|    177|    }
  132|       |
  133|      4|    fn del(
  134|      4|        &mut self,
  135|      4|        database: lmdb::Database,
  136|      4|        key: &[u8],
  137|      4|        flags: Option<&[u8]>,
  138|      4|    ) -> lmdb::Result<()> {
  139|      4|        lmdb::RwTransaction::del(&mut self.0, database, &key, flags)
  140|      4|    }
  141|       |
  142|      0|    fn clear_db(&mut self, database: lmdb::Database) -> lmdb::Result<()> {
  143|      0|        lmdb::RwTransaction::clear_db(&mut self.0, database)
  144|      0|    }
  145|       |
  146|     51|    fn commit(self) -> lmdb::Result<()> {
  147|     51|        lmdb::Transaction::commit(self.0)
  148|     51|    }
  149|       |
  150|     44|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
  151|     44|        let cursor = lmdb::Transaction::open_ro_cursor(&self.0, database.as_real());
  152|     44|        cursor.map(RoCursor::new)
  153|     44|    }
  154|       |
  155|      0|    fn count(&self, database: lmdb::Database) -> u64 {
  156|      0|        let stat = lmdb::Transaction::stat(&self.0, database);
  157|      0|        stat.unwrap().entries() as u64
  158|      0|    }
  159|       |
  160|       |    /// ## Safety
  161|       |    ///
  162|       |    /// This method is unsafe in the same ways as `Environment::close_db`, and
  163|       |    /// should be used accordingly.
  164|      0|    unsafe fn drop_db(&mut self, database: lmdb::Database) -> lmdb::Result<()> {
  165|      0|        lmdb::RwTransaction::drop_db(&mut self.0, database)
  166|      0|    }
  167|       |
  168|       |    /// ## Safety
  169|       |    ///
  170|       |    /// This function (as well as `Environment::open_db`,
  171|       |    /// `Environment::create_db`, and `Database::open`) **must not** be called
  172|       |    /// from multiple concurrent transactions in the same environment. A
  173|       |    /// transaction which uses this function must finish (either commit or
  174|       |    /// abort) before any other transaction may use this function.
  175|      6|    unsafe fn create_db(
  176|      6|        &self,
  177|      6|        name: Option<&str>,
  178|      6|        flags: DatabaseFlags,
  179|      6|    ) -> lmdb::Result<LmdbDatabase> {
  180|      6|        lmdb::RwTransaction::create_db(&self.0, name, flags).map(LmdbDatabase::new)
  181|      6|    }
  182|       |}
  183|       |
  184|       |pub struct RwTransactionStub {
  185|       |    databases: Vec<ConfiguredDatabase>,
  186|       |}
  187|       |
  188|       |impl RwTransactionStub {
  189|   163k|    fn get_database(&self, database: LmdbDatabase) -> Option<&ConfiguredDatabase> {
  190|   458k|        self.databases.iter().find(|d| d.dbi == database)
  191|   163k|    }
  192|       |
  193|   163k|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
  194|   163k|        let Some(db) = self.get_database(database) else {
  195|      0|            return Err(lmdb::Error::NotFound);
  196|       |        };
  197|   163k|        match db.entries.get(key) {
  198|   131k|            Some(value) => Ok(value),
  199|  32.7k|            None => Err(lmdb::Error::NotFound),
  200|       |        }
  201|   163k|    }
  202|       |
  203|     11|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
  204|     11|        Ok(RoCursor::new_null_with(
  205|     66|            self.databases.iter().find(|db| db.dbi == database).unwrap(),
  206|     11|        ))
  207|     11|    }
  208|       |
  209|      0|    fn create_db(&self, _name: Option<&str>, _flags: DatabaseFlags) -> lmdb::Result<LmdbDatabase> {
  210|      0|        Ok(LmdbDatabase::new_null(42))
  211|      0|    }
  212|       |}

/home/gustav/code/nano/rsnano-node/nullables/output_tracker/src/output_tracker.rs:
    1|       |use std::{
    2|       |    cell::RefCell,
    3|       |    rc::{Rc, Weak},
    4|       |};
    5|       |
    6|       |pub struct OutputTracker<T: Clone + 'static> {
    7|       |    output: RefCell<Vec<T>>,
    8|       |}
    9|       |
   10|       |impl<T: Clone + 'static> OutputTracker<T> {
   11|     10|    pub fn new() -> Self {
   12|     10|        Self {
   13|     10|            output: RefCell::new(Vec::new()),
   14|     10|        }
   15|     10|    }
   16|       |
   17|      9|    pub fn add(&self, t: T) {
   18|      9|        self.output.borrow_mut().push(t);
   19|      9|    }
   20|       |
   21|     10|    pub fn output(&self) -> Vec<T> {
   22|     10|        self.output.borrow().clone()
   23|     10|    }
   24|       |}
   25|       |
   26|       |impl<T> Default for OutputTracker<T>
   27|       |where
   28|       |    T: Clone + 'static,
   29|       |{
   30|       |    fn default() -> Self {
   31|       |        Self::new()
   32|       |    }
   33|       |}
   34|       |
   35|       |pub struct OutputListener<T: Clone + 'static> {
   36|       |    trackers: RefCell<Vec<Weak<OutputTracker<T>>>>,
   37|       |}
   38|       |
   39|       |impl<T: Clone + 'static> OutputListener<T> {
   40|     13|    pub fn new() -> Self {
   41|     13|        Self {
   42|     13|            trackers: RefCell::new(Vec::new()),
   43|     13|        }
   44|     13|    }
   45|       |
   46|     10|    pub fn track(&self) -> Rc<OutputTracker<T>> {
   47|     10|        let tracker = Rc::new(OutputTracker::new());
   48|     10|        self.trackers.borrow_mut().push(Rc::downgrade(&tracker));
   49|     10|        tracker
   50|     10|    }
   51|       |
   52|     15|    pub fn emit(&self, t: T) {
   53|     15|        let mut guard = self.trackers.borrow_mut();
   54|     15|        let mut should_clean = false;
   55|     15|        for tracker in guard.iter() {
                          ^9
   56|      9|            if let Some(tracker) = tracker.upgrade() {
   57|      9|                tracker.add(t.clone());
   58|      9|            } else {
   59|      0|                should_clean = true;
   60|      0|            }
   61|       |        }
   62|       |
   63|     15|        if should_clean {
   64|      0|            guard.retain(|t| t.strong_count() > 0);
   65|     15|        }
   66|     15|    }
   67|       |
   68|       |    pub fn is_tracked(&self) -> bool {
   69|       |        self.tracker_count() > 0
   70|       |    }
   71|       |
   72|       |    pub fn tracker_count(&self) -> usize {
   73|       |        self.trackers.borrow().len()
   74|       |    }
   75|       |}
   76|       |
   77|       |impl<T> Default for OutputListener<T>
   78|       |where
   79|       |    T: Clone + 'static,
   80|       |{
   81|       |    fn default() -> Self {
   82|       |        Self::new()
   83|       |    }
   84|       |}
   85|       |
   86|       |#[cfg(test)]
   87|       |mod tests {
   88|       |    use super::*;
   89|       |
   90|       |    #[test]
   91|       |    fn not_active_trackers() {
   92|       |        let listener = OutputListener::new();
   93|       |        listener.emit("foo");
   94|       |    }
   95|       |
   96|       |    #[test]
   97|       |    fn track_one_output() {
   98|       |        let listener = OutputListener::new();
   99|       |        let tracker = listener.track();
  100|       |        listener.emit("foo");
  101|       |        assert_eq!(tracker.output(), vec!["foo"]);
  102|       |    }
  103|       |
  104|       |    #[test]
  105|       |    fn track_multiple_outputs() {
  106|       |        let listener = OutputListener::new();
  107|       |        let tracker = listener.track();
  108|       |        listener.emit("foo");
  109|       |        listener.emit("bar");
  110|       |        listener.emit("test");
  111|       |        assert_eq!(tracker.output(), vec!["foo", "bar", "test"]);
  112|       |    }
  113|       |
  114|       |    #[test]
  115|       |    fn multiple_trackers() {
  116|       |        let listener = OutputListener::new();
  117|       |        let tracker1 = listener.track();
  118|       |        listener.emit("foo");
  119|       |        let tracker2 = listener.track();
  120|       |        listener.emit("bar");
  121|       |        listener.emit("test");
  122|       |        assert_eq!(tracker1.output(), vec!["foo", "bar", "test"]);
  123|       |        assert_eq!(tracker2.output(), vec!["bar", "test"]);
  124|       |    }
  125|       |
  126|       |    #[test]
  127|       |    fn stop_tracking_if_tracker_dropped() {
  128|       |        let listener = OutputListener::new();
  129|       |        let tracker = listener.track();
  130|       |        listener.emit("foo");
  131|       |        assert_eq!(listener.tracker_count(), 1);
  132|       |        drop(tracker);
  133|       |        listener.emit("bar");
  134|       |        assert_eq!(listener.tracker_count(), 0);
  135|       |    }
  136|       |}

/home/gustav/code/nano/rsnano-node/nullables/output_tracker/src/output_tracker_mt.rs:
    1|       |use std::sync::{
    2|       |    atomic::{AtomicUsize, Ordering},
    3|       |    Arc, Mutex, Weak,
    4|       |};
    5|       |
    6|       |// Multi threaded output tracker
    7|       |pub struct OutputTrackerMt<T: Clone + 'static> {
    8|       |    output: Mutex<Vec<T>>,
    9|       |}
   10|       |
   11|       |impl<T: Clone + 'static> OutputTrackerMt<T> {
   12|     39|    pub fn new() -> Self {
   13|     39|        Self {
   14|     39|            output: Mutex::new(Vec::new()),
   15|     39|        }
   16|     39|    }
   17|       |
   18|     30|    pub fn add(&self, t: T) {
   19|     30|        self.output.lock().unwrap().push(t);
   20|     30|    }
   21|       |
   22|     35|    pub fn output(&self) -> Vec<T> {
   23|     35|        self.output.lock().unwrap().clone()
   24|     35|    }
   25|       |
   26|       |    pub fn clear(&self) {
   27|       |        self.output.lock().unwrap().clear();
   28|       |    }
   29|       |}
   30|       |
   31|       |impl<T> Default for OutputTrackerMt<T>
   32|       |where
   33|       |    T: Clone + 'static,
   34|       |{
   35|       |    fn default() -> Self {
   36|       |        Self::new()
   37|       |    }
   38|       |}
   39|       |
   40|       |pub struct OutputListenerMt<T: Clone + 'static> {
   41|       |    trackers: Mutex<Vec<Weak<OutputTrackerMt<T>>>>,
   42|       |    count: AtomicUsize,
   43|       |}
   44|       |
   45|       |impl<T: Clone + 'static> OutputListenerMt<T> {
   46|    149|    pub fn new() -> Self {
   47|    149|        Self {
   48|    149|            trackers: Mutex::new(Vec::new()),
   49|    149|            count: AtomicUsize::new(0),
   50|    149|        }
   51|    149|    }
   52|       |
   53|      0|    pub fn is_tracked(&self) -> bool {
   54|      0|        self.trackers.lock().unwrap().len() > 0
   55|      0|    }
   56|       |
   57|     39|    pub fn track(&self) -> Arc<OutputTrackerMt<T>> {
   58|     39|        let tracker = Arc::new(OutputTrackerMt::new());
   59|     39|        let mut guard = self.trackers.lock().unwrap();
   60|     39|        guard.push(Arc::downgrade(&tracker));
   61|     39|        self.count.store(guard.len(), Ordering::SeqCst);
   62|     39|        tracker
   63|     39|    }
   64|       |
   65|     95|    pub fn emit(&self, t: T) {
   66|     95|        if self.count.load(Ordering::SeqCst) == 0 {
   67|     63|            return;
   68|     32|        }
   69|     32|
   70|     32|        let mut guard = self.trackers.lock().unwrap();
   71|     32|        let mut should_clean = false;
   72|     32|        for tracker in guard.iter() {
   73|     32|            if let Some(tracker) = tracker.upgrade() {
                                      ^30
   74|     30|                tracker.add(t.clone());
   75|     30|            } else {
   76|      2|                should_clean = true;
   77|      2|            }
   78|       |        }
   79|       |
   80|     32|        if should_clean {
   81|      2|            guard.retain(|t| t.strong_count() > 0);
   82|      2|            self.count.store(guard.len(), Ordering::SeqCst);
   83|     30|        }
   84|     95|    }
   85|       |
   86|       |    pub fn tracker_count(&self) -> usize {
   87|       |        self.trackers.lock().unwrap().len()
   88|       |    }
   89|       |}
   90|       |
   91|       |impl<T> Default for OutputListenerMt<T>
   92|       |where
   93|       |    T: Clone + 'static,
   94|       |{
   95|       |    fn default() -> Self {
   96|       |        Self::new()
   97|       |    }
   98|       |}
   99|       |
  100|       |#[cfg(test)]
  101|       |mod tests {
  102|       |    use super::*;
  103|       |
  104|       |    #[test]
  105|       |    fn not_active_trackers() {
  106|       |        let listener = OutputListenerMt::new();
  107|       |        listener.emit("foo");
  108|       |    }
  109|       |
  110|       |    #[test]
  111|       |    fn track_one_output() {
  112|       |        let listener = OutputListenerMt::new();
  113|       |        let tracker = listener.track();
  114|       |        listener.emit("foo");
  115|       |        assert_eq!(tracker.output(), vec!["foo"]);
  116|       |    }
  117|       |
  118|       |    #[test]
  119|       |    fn track_multiple_outputs() {
  120|       |        let listener = OutputListenerMt::new();
  121|       |        let tracker = listener.track();
  122|       |        listener.emit("foo");
  123|       |        listener.emit("bar");
  124|       |        listener.emit("test");
  125|       |        assert_eq!(tracker.output(), vec!["foo", "bar", "test"]);
  126|       |    }
  127|       |
  128|       |    #[test]
  129|       |    fn multiple_trackers() {
  130|       |        let listener = OutputListenerMt::new();
  131|       |        let tracker1 = listener.track();
  132|       |        listener.emit("foo");
  133|       |        let tracker2 = listener.track();
  134|       |        listener.emit("bar");
  135|       |        listener.emit("test");
  136|       |        assert_eq!(tracker1.output(), vec!["foo", "bar", "test"]);
  137|       |        assert_eq!(tracker2.output(), vec!["bar", "test"]);
  138|       |    }
  139|       |
  140|       |    #[test]
  141|       |    fn stop_tracking_if_tracker_dropped() {
  142|       |        let listener = OutputListenerMt::new();
  143|       |        let tracker = listener.track();
  144|       |        listener.emit("foo");
  145|       |        assert_eq!(listener.tracker_count(), 1);
  146|       |        drop(tracker);
  147|       |        listener.emit("bar");
  148|       |        assert_eq!(listener.tracker_count(), 0);
  149|       |    }
  150|       |}

/home/gustav/code/nano/rsnano-node/nullables/random/src/lib.rs:
    1|       |use rand::{rngs::ThreadRng, CryptoRng, RngCore};
    2|       |
    3|       |pub struct NullableRng {
    4|       |    strategy: RngStrategy,
    5|       |}
    6|       |
    7|       |impl NullableRng {
    8|      7|    pub fn new_null() -> Self {
    9|      7|        Self::new_null_u64(42)
   10|      7|    }
   11|       |
   12|      7|    pub fn new_null_u64(val: u64) -> Self {
   13|      7|        Self {
   14|      7|            strategy: RngStrategy::Nulled(RngStub::new(val.to_be_bytes().to_vec())),
   15|      7|        }
   16|      7|    }
   17|       |
   18|      3|    pub fn new_null_bytes(bytes: &[u8]) -> Self {
   19|      3|        Self {
   20|      3|            strategy: RngStrategy::Nulled(RngStub::new(bytes.to_vec())),
   21|      3|        }
   22|      3|    }
   23|       |
   24|     45|    pub fn thread_rng() -> Self {
   25|     45|        Self {
   26|     45|            strategy: RngStrategy::Thread(rand::thread_rng()),
   27|     45|        }
   28|     45|    }
   29|       |
   30|     49|    fn as_rng_core(&mut self) -> &mut dyn RngCore {
   31|     49|        match &mut self.strategy {
   32|     45|            RngStrategy::Thread(i) => i,
   33|      4|            RngStrategy::Nulled(i) => i,
   34|       |        }
   35|     49|    }
   36|       |}
   37|       |
   38|       |impl RngCore for NullableRng {
   39|      0|    fn next_u32(&mut self) -> u32 {
   40|      0|        self.as_rng_core().next_u32()
   41|      0|    }
   42|       |
   43|      0|    fn next_u64(&mut self) -> u64 {
   44|      0|        self.as_rng_core().next_u64()
   45|      0|    }
   46|       |
   47|     49|    fn fill_bytes(&mut self, dest: &mut [u8]) {
   48|     49|        self.as_rng_core().fill_bytes(dest)
   49|     49|    }
   50|       |
   51|      0|    fn try_fill_bytes(&mut self, dest: &mut [u8]) -> Result<(), rand::Error> {
   52|      0|        self.as_rng_core().try_fill_bytes(dest)
   53|      0|    }
   54|       |}
   55|       |
   56|       |enum RngStrategy {
   57|       |    Thread(ThreadRng),
   58|       |    Nulled(RngStub),
   59|       |}
   60|       |
   61|       |impl CryptoRng for NullableRng {}
   62|       |
   63|       |struct RngStub {
   64|       |    data: Vec<u8>,
   65|       |    index: usize,
   66|       |}
   67|       |
   68|       |impl RngStub {
   69|     10|    pub fn new(data: Vec<u8>) -> Self {
   70|     10|        Self { data, index: 0 }
   71|     10|    }
   72|       |}
   73|       |
   74|       |impl RngCore for RngStub {
   75|      0|    fn next_u32(&mut self) -> u32 {
   76|      0|        let mut buf = [0u8; 4];
   77|      0|        self.fill_bytes(&mut buf);
   78|      0|        u32::from_be_bytes(buf)
   79|      0|    }
   80|       |
   81|      0|    fn next_u64(&mut self) -> u64 {
   82|      0|        let mut buf = [0u8; 8];
   83|      0|        self.fill_bytes(&mut buf);
   84|      0|        u64::from_be_bytes(buf)
   85|      0|    }
   86|       |
   87|      4|    fn fill_bytes(&mut self, dest: &mut [u8]) {
   88|    132|        for i in dest {
                          ^128
   89|    128|            *i = self.data[self.index];
   90|    128|            self.index += 1;
   91|    128|            if self.index >= self.data.len() {
   92|      7|                self.index = 0;
   93|    121|            }
   94|       |        }
   95|      4|    }
   96|       |
   97|      0|    fn try_fill_bytes(&mut self, dest: &mut [u8]) -> Result<(), rand::Error> {
   98|      0|        self.fill_bytes(dest);
   99|      0|        Ok(())
  100|      0|    }
  101|       |}
  102|       |
  103|       |#[cfg(test)]
  104|       |mod tests {
  105|       |    use super::*;
  106|       |
  107|       |    #[test]
  108|       |    fn real_rng() {
  109|       |        let mut rng = NullableRng::thread_rng();
  110|       |        let a1 = rng.next_u64();
  111|       |        let a2 = rng.next_u64();
  112|       |        let a3 = rng.next_u64();
  113|       |        assert!(a1 > 0 || a2 > 0 || a3 > 0);
  114|       |
  115|       |        let b1 = rng.next_u32();
  116|       |        let b2 = rng.next_u32();
  117|       |        let b3 = rng.next_u32();
  118|       |        assert!(b1 > 0 || b2 > 0 || b3 > 0);
  119|       |
  120|       |        let mut buffer = [0; 32];
  121|       |
  122|       |        rng.fill_bytes(&mut buffer);
  123|       |        assert_eq!(buffer.iter().all(|&b| b == 0), false);
  124|       |
  125|       |        buffer = [0; 32];
  126|       |        rng.try_fill_bytes(&mut buffer).unwrap();
  127|       |        assert_eq!(buffer.iter().all(|&b| b == 0), false);
  128|       |    }
  129|       |
  130|       |    #[test]
  131|       |    fn nullable_with_u64() {
  132|       |        let mut rng = NullableRng::new_null();
  133|       |        assert_eq!(rng.next_u64(), 42);
  134|       |
  135|       |        assert_eq!(rng.next_u32(), 0);
  136|       |        assert_eq!(rng.next_u32(), 42);
  137|       |
  138|       |        let mut buffer = [0; 32];
  139|       |        rng.fill_bytes(&mut buffer);
  140|       |        assert_eq!(
  141|       |            buffer,
  142|       |            [
  143|       |                0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0,
  144|       |                0, 0, 0, 0, 42,
  145|       |            ]
  146|       |        );
  147|       |
  148|       |        buffer = [0; 32];
  149|       |        rng.try_fill_bytes(&mut buffer).unwrap();
  150|       |        assert_eq!(
  151|       |            buffer,
  152|       |            [
  153|       |                0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0,
  154|       |                0, 0, 0, 0, 42,
  155|       |            ]
  156|       |        );
  157|       |    }
  158|       |
  159|       |    #[test]
  160|       |    fn nullable_with_byte_slice() {
  161|       |        let mut rng = NullableRng::new_null_bytes(&[1, 2, 3, 4, 5, 6]);
  162|       |        let mut buffer = [0; 10];
  163|       |        rng.fill_bytes(&mut buffer);
  164|       |        assert_eq!(buffer, [1, 2, 3, 4, 5, 6, 1, 2, 3, 4]);
  165|       |    }
  166|       |}

/home/gustav/code/nano/rsnano-node/nullables/tcp/src/tcp_stream.rs:
    1|       |use std::{
    2|       |    cmp::min,
    3|       |    net::{Ipv6Addr, SocketAddr, SocketAddrV6},
    4|       |    sync::atomic::{AtomicUsize, Ordering},
    5|       |};
    6|       |
    7|       |use async_trait::async_trait;
    8|       |use tokio::io::{AsyncWriteExt, ErrorKind};
    9|       |
   10|       |pub const TEST_ENDPOINT_1: SocketAddrV6 =
   11|       |    SocketAddrV6::new(Ipv6Addr::new(0, 0, 0, 0xffff, 0x10, 0, 0, 1), 1111, 0, 0);
   12|       |
   13|       |pub struct TcpStream {
   14|       |    stream: Box<dyn InternalTcpStream>,
   15|       |}
   16|       |
   17|       |impl TcpStream {
   18|      0|    pub fn new(stream: tokio::net::TcpStream) -> Self {
   19|      0|        Self {
   20|      0|            stream: Box::new(TokioTcpStreamWrapper(stream)),
   21|      0|        }
   22|      0|    }
   23|       |
   24|      0|    pub fn new_null() -> Self {
   25|      0|        Self {
   26|      0|            stream: Box::new(TcpStreamStub::new(TEST_ENDPOINT_1, Vec::new())),
   27|      0|        }
   28|      0|    }
   29|       |
   30|      0|    pub fn new_null_with_peer_addr(peer_addr: SocketAddrV6) -> Self {
   31|      0|        Self {
   32|      0|            stream: Box::new(TcpStreamStub::new(peer_addr, Vec::new())),
   33|      0|        }
   34|      0|    }
   35|       |
   36|      0|    pub fn new_null_with(incoming: Vec<u8>) -> Self {
   37|      0|        Self {
   38|      0|            stream: Box::new(TcpStreamStub::new(TEST_ENDPOINT_1, incoming)),
   39|      0|        }
   40|      0|    }
   41|       |
   42|      0|    pub async fn shutdown(&mut self) -> tokio::io::Result<()> {
   43|      0|        self.stream.shutdown().await
   44|      0|    }
   45|       |
   46|      0|    pub async fn readable(&self) -> tokio::io::Result<()> {
   47|      0|        self.stream.readable().await
   48|      0|    }
   49|       |
   50|      0|    pub fn try_read(&self, buf: &mut [u8]) -> tokio::io::Result<usize> {
   51|      0|        self.stream.try_read(buf)
   52|      0|    }
   53|       |
   54|      0|    pub fn local_addr(&self) -> std::io::Result<SocketAddr> {
   55|      0|        self.stream.local_addr()
   56|      0|    }
   57|       |
   58|      0|    pub fn peer_addr(&self) -> std::io::Result<SocketAddr> {
   59|      0|        self.stream.peer_addr()
   60|      0|    }
   61|       |
   62|      0|    pub async fn writable(&self) -> tokio::io::Result<()> {
   63|      0|        self.stream.writable().await
   64|      0|    }
   65|       |
   66|      0|    pub fn try_write(&self, buf: &[u8]) -> tokio::io::Result<usize> {
   67|      0|        self.stream.try_write(buf)
   68|      0|    }
   69|       |}
   70|       |
   71|       |#[async_trait]
   72|       |trait InternalTcpStream: Send + Sync {
   73|       |    async fn readable(&self) -> tokio::io::Result<()>;
   74|       |    fn try_read(&self, buf: &mut [u8]) -> tokio::io::Result<usize>;
   75|       |    fn local_addr(&self) -> std::io::Result<SocketAddr>;
   76|       |    fn peer_addr(&self) -> std::io::Result<SocketAddr>;
   77|       |    async fn writable(&self) -> tokio::io::Result<()>;
   78|       |    fn try_write(&self, buf: &[u8]) -> tokio::io::Result<usize>;
   79|       |    async fn shutdown(&mut self) -> tokio::io::Result<()>;
   80|       |}
   81|       |
   82|       |struct TokioTcpStreamWrapper(tokio::net::TcpStream);
   83|       |
   84|       |#[async_trait]
   85|       |impl InternalTcpStream for TokioTcpStreamWrapper {
   86|      0|    async fn readable(&self) -> tokio::io::Result<()> {
   87|      0|        self.0.readable().await
   88|      0|    }
   89|       |
   90|      0|    fn try_read(&self, buf: &mut [u8]) -> tokio::io::Result<usize> {
   91|      0|        self.0.try_read(buf)
   92|      0|    }
   93|       |
   94|      0|    fn local_addr(&self) -> std::io::Result<SocketAddr> {
   95|      0|        self.0.local_addr()
   96|      0|    }
   97|       |
   98|      0|    fn peer_addr(&self) -> std::io::Result<SocketAddr> {
   99|      0|        self.0.peer_addr()
  100|      0|    }
  101|       |
  102|      0|    async fn writable(&self) -> tokio::io::Result<()> {
  103|      0|        self.0.writable().await
  104|      0|    }
  105|       |
  106|      0|    fn try_write(&self, buf: &[u8]) -> tokio::io::Result<usize> {
  107|      0|        self.0.try_write(buf)
  108|      0|    }
  109|       |
  110|      0|    async fn shutdown(&mut self) -> tokio::io::Result<()> {
  111|      0|        self.0.shutdown().await
  112|      0|    }
  113|       |}
  114|       |
  115|       |struct TcpStreamStub {
  116|       |    incoming: Vec<u8>,
  117|       |    position: AtomicUsize,
  118|       |    peer_addr: SocketAddrV6,
  119|       |}
  120|       |
  121|       |impl TcpStreamStub {
  122|      0|    pub fn new(peer_addr: SocketAddrV6, incoming: Vec<u8>) -> Self {
  123|      0|        Self {
  124|      0|            incoming,
  125|      0|            position: AtomicUsize::new(0),
  126|      0|            peer_addr,
  127|      0|        }
  128|      0|    }
  129|       |
  130|      0|    fn no_data_error() -> tokio::io::Error {
  131|      0|        tokio::io::Error::new(ErrorKind::Other, "nulled tcp stream has no data")
  132|      0|    }
  133|       |
  134|      0|    fn next_bytes(&self) -> &[u8] {
  135|      0|        let pos = self.position.load(Ordering::SeqCst);
  136|      0|        &self.incoming[pos..]
  137|      0|    }
  138|       |}
  139|       |
  140|       |#[async_trait]
  141|       |impl InternalTcpStream for TcpStreamStub {
  142|      0|    async fn readable(&self) -> tokio::io::Result<()> {
  143|      0|        if self.next_bytes().is_empty() {
  144|      0|            Err(Self::no_data_error())
  145|       |        } else {
  146|      0|            Ok(())
  147|       |        }
  148|      0|    }
  149|       |
  150|      0|    fn try_read(&self, buf: &mut [u8]) -> tokio::io::Result<usize> {
  151|      0|        let next_bytes = self.next_bytes();
  152|      0|        if next_bytes.is_empty() {
  153|      0|            Err(Self::no_data_error())
  154|       |        } else {
  155|      0|            let read_count = min(buf.len(), next_bytes.len());
  156|      0|            buf[..read_count].copy_from_slice(&next_bytes[..read_count]);
  157|      0|            self.position.fetch_add(read_count, Ordering::SeqCst);
  158|      0|            Ok(read_count)
  159|       |        }
  160|      0|    }
  161|       |
  162|      0|    fn local_addr(&self) -> std::io::Result<SocketAddr> {
  163|      0|        Ok(SocketAddr::V6(TEST_ENDPOINT_1))
  164|      0|    }
  165|       |
  166|      0|    fn peer_addr(&self) -> std::io::Result<SocketAddr> {
  167|      0|        Ok(SocketAddr::V6(self.peer_addr))
  168|      0|    }
  169|       |
  170|      0|    async fn writable(&self) -> tokio::io::Result<()> {
  171|      0|        Ok(())
  172|      0|    }
  173|       |
  174|      0|    fn try_write(&self, buf: &[u8]) -> tokio::io::Result<usize> {
  175|      0|        Ok(buf.len())
  176|      0|    }
  177|       |
  178|      0|    async fn shutdown(&mut self) -> tokio::io::Result<()> {
  179|      0|        Ok(())
  180|      0|    }
  181|       |}
  182|       |
  183|       |#[cfg(test)]
  184|       |mod tests {
  185|       |    use super::*;
  186|       |    use crate::TcpStreamFactory;
  187|       |    use std::{
  188|       |        io::ErrorKind,
  189|       |        net::{IpAddr, Ipv4Addr, SocketAddr},
  190|       |    };
  191|       |    use tokio::{net::TcpListener, spawn};
  192|       |
  193|       |    #[tokio::test]
  194|       |    async fn connects_to_real_server() {
  195|       |        let endpoint = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), 8088);
  196|       |        start_test_tcp_server(endpoint).await;
  197|       |
  198|       |        let stream_factory = TcpStreamFactory::new();
  199|       |        let stream = stream_factory.connect("127.0.0.1:8088").await.unwrap();
  200|       |
  201|       |        let mut buf = [0; 3];
  202|       |        loop {
  203|       |            stream.readable().await.unwrap();
  204|       |            match stream.try_read(&mut buf) {
  205|       |                Ok(0) => break,
  206|       |                Ok(_) => {
  207|       |                    break;
  208|       |                }
  209|       |                Err(ref e) if e.kind() == ErrorKind::WouldBlock => {
  210|       |                    continue;
  211|       |                }
  212|       |                Err(e) => {
  213|       |                    panic!("unexpected error when reading {:?}", e);
  214|       |                }
  215|       |            }
  216|       |        }
  217|       |        assert_eq!(buf, [1, 2, 3]);
  218|       |    }
  219|       |
  220|       |    #[tokio::test]
  221|       |    async fn nulled_stream_returns_error_when_calling_readable() {
  222|       |        let stream = TcpStream::new_null();
  223|       |        let error = stream.readable().await.expect_err("readable should fail");
  224|       |        assert_eq!(error.kind(), ErrorKind::Other);
  225|       |        assert_eq!(error.to_string(), "nulled tcp stream has no data");
  226|       |    }
  227|       |
  228|       |    #[tokio::test]
  229|       |    async fn nulled_stream_returns_error_when_calling_try_read() {
  230|       |        let stream = TcpStream::new_null();
  231|       |        let error = stream.try_read(&mut [0]).expect_err("try_read should fail");
  232|       |        assert_eq!(error.kind(), ErrorKind::Other);
  233|       |        assert_eq!(error.to_string(), "nulled tcp stream has no data");
  234|       |    }
  235|       |
  236|       |    #[tokio::test]
  237|       |    async fn nulled_stream_should_read_configured_data() {
  238|       |        let stream = TcpStream::new_null_with(vec![1, 2, 3]);
  239|       |        stream.readable().await.expect("readable should not fail");
  240|       |        let mut buf = [0; 3];
  241|       |        let read_count = stream.try_read(&mut buf).expect("try_read should not fail");
  242|       |        assert_eq!(read_count, 3);
  243|       |        assert_eq!(buf, [1, 2, 3]);
  244|       |    }
  245|       |
  246|       |    #[tokio::test]
  247|       |    async fn nulled_stream_should_read_configured_data_into_bigger_buffer() {
  248|       |        let stream = TcpStream::new_null_with(vec![1, 2, 3]);
  249|       |        stream.readable().await.expect("readable should not fail");
  250|       |        let mut buf = [0; 5];
  251|       |        let read_count = stream.try_read(&mut buf).expect("try_read should not fail");
  252|       |        assert_eq!(read_count, 3);
  253|       |        assert_eq!(buf, [1, 2, 3, 0, 0]);
  254|       |    }
  255|       |
  256|       |    #[tokio::test]
  257|       |    async fn nulled_stream_can_read_configured_data_with_multiple_reads() {
  258|       |        let stream = TcpStream::new_null_with(vec![1, 2, 3]);
  259|       |
  260|       |        //read first chunk
  261|       |        stream.readable().await.expect("readable should not fail");
  262|       |        let mut buf = [0; 2];
  263|       |        let read_count = stream.try_read(&mut buf).expect("try_read should not fail");
  264|       |        assert_eq!(read_count, 2);
  265|       |        assert_eq!(buf, [1, 2]);
  266|       |
  267|       |        //read second chunk
  268|       |        let mut buf = [0; 2];
  269|       |        stream.readable().await.expect("readable should not fail");
  270|       |        let read_count = stream.try_read(&mut buf).expect("try_read should not fail");
  271|       |        assert_eq!(read_count, 1);
  272|       |        assert_eq!(buf, [3, 0]);
  273|       |    }
  274|       |
  275|       |    #[tokio::test]
  276|       |    async fn nulled_stream_should_fail_after_all_incoming_data_was_read() {
  277|       |        let stream = TcpStream::new_null_with(vec![1, 2, 3]);
  278|       |        stream.readable().await.expect("readable should not fail");
  279|       |        let mut buf = [0; 5];
  280|       |        let read_count = stream.try_read(&mut buf).expect("try_read should not fail");
  281|       |        assert_eq!(read_count, 3);
  282|       |
  283|       |        stream
  284|       |            .readable()
  285|       |            .await
  286|       |            .expect_err("readable should fail on second call");
  287|       |        stream
  288|       |            .try_read(&mut buf)
  289|       |            .expect_err("try_read should fail on second call");
  290|       |    }
  291|       |
  292|       |    async fn start_test_tcp_server(endpoint: SocketAddr) {
  293|       |        let listener = TcpListener::bind(endpoint).await.unwrap();
  294|       |
  295|       |        spawn(async move {
  296|       |            let (socket, _) = listener.accept().await.unwrap();
  297|       |            loop {
  298|       |                socket.writable().await.unwrap();
  299|       |                match socket.try_write(&[1, 2, 3]) {
  300|       |                    Ok(_) => {
  301|       |                        break;
  302|       |                    }
  303|       |                    Err(ref e) if e.kind() == ErrorKind::WouldBlock => {
  304|       |                        continue;
  305|       |                    }
  306|       |                    Err(e) => {
  307|       |                        panic!("unexpected error: {:?}", e);
  308|       |                    }
  309|       |                }
  310|       |            }
  311|       |        });
  312|       |    }
  313|       |}

/home/gustav/code/nano/rsnano-node/nullables/tcp/src/tcp_stream_factory.rs:
    1|       |use super::tcp_stream::TcpStream;
    2|       |use async_trait::async_trait;
    3|       |use std::net::{SocketAddr, ToSocketAddrs};
    4|       |
    5|       |pub struct TcpStreamFactory {
    6|       |    inner: Box<dyn InternalTcpStreamFactory>,
    7|       |}
    8|       |
    9|       |impl TcpStreamFactory {
   10|       |    pub fn new() -> Self {
   11|       |        Self {
   12|       |            inner: Box::new(TcpStreamFactoryWrapper {}),
   13|       |        }
   14|       |    }
   15|       |
   16|       |    pub fn new_null() -> Self {
   17|       |        Self {
   18|       |            inner: Box::new(NullTcpStreamFactory {}),
   19|       |        }
   20|       |    }
   21|       |
   22|      0|    pub async fn connect<A: ToSocketAddrs>(&self, addr: A) -> tokio::io::Result<TcpStream> {
   23|      0|        self.inner
   24|      0|            .connect(addr.to_socket_addrs().unwrap().next().unwrap())
   25|      0|            .await
   26|      0|    }
   27|       |}
   28|       |
   29|       |impl Default for TcpStreamFactory {
   30|       |    fn default() -> Self {
   31|       |        Self::new()
   32|       |    }
   33|       |}
   34|       |
   35|       |#[async_trait]
   36|       |trait InternalTcpStreamFactory: Send + Sync {
   37|       |    async fn connect(&self, addr: SocketAddr) -> tokio::io::Result<TcpStream>;
   38|       |}
   39|       |
   40|       |struct NullTcpStreamFactory {}
   41|       |
   42|       |#[async_trait]
   43|       |impl InternalTcpStreamFactory for NullTcpStreamFactory {
   44|       |    async fn connect(&self, _addr: SocketAddr) -> tokio::io::Result<TcpStream> {
   45|       |        Err(tokio::io::Error::new(
   46|       |            std::io::ErrorKind::Other,
   47|       |            "nulled TcpStreamFactory has no configured connections",
   48|       |        ))
   49|       |    }
   50|       |}
   51|       |
   52|       |struct TcpStreamFactoryWrapper {}
   53|       |
   54|       |#[async_trait]
   55|       |impl InternalTcpStreamFactory for TcpStreamFactoryWrapper {
   56|       |    async fn connect(&self, addr: SocketAddr) -> tokio::io::Result<TcpStream> {
   57|       |        let tokio_stream = tokio::net::TcpStream::connect(addr).await?;
   58|       |        Ok(TcpStream::new(tokio_stream))
   59|       |    }
   60|       |}
   61|       |
   62|       |#[cfg(test)]
   63|       |mod tests {
   64|       |    use super::*;
   65|       |    use std::io::ErrorKind;
   66|       |
   67|       |    #[tokio::test]
   68|       |    async fn can_be_nulled() {
   69|       |        let factory = TcpStreamFactory::new_null();
   70|       |        match factory.connect("127.0.0.1:42").await {
   71|       |            Ok(_) => panic!("connect should fail"),
   72|       |            Err(e) => {
   73|       |                assert_eq!(e.kind(), ErrorKind::Other);
   74|       |                assert_eq!(
   75|       |                    e.to_string(),
   76|       |                    "nulled TcpStreamFactory has no configured connections"
   77|       |                );
   78|       |            }
   79|       |        }
   80|       |    }
   81|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/account_store.rs:
    1|       |use crate::{
    2|       |    iterator::{LmdbIterator, LmdbRangeIterator},
    3|       |    parallel_traversal, LmdbDatabase, LmdbEnv, LmdbWriteTransaction, Transaction,
    4|       |    ACCOUNT_TEST_DATABASE,
    5|       |};
    6|       |use lmdb::{DatabaseFlags, WriteFlags};
    7|       |use rsnano_core::{
    8|       |    utils::{BufferReader, Deserialize},
    9|       |    Account, AccountInfo,
   10|       |};
   11|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
   12|       |#[cfg(feature = "output_tracking")]
   13|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   14|       |use std::{ops::RangeBounds, sync::Arc};
   15|       |
   16|       |pub struct LmdbAccountStore {
   17|       |    env: Arc<LmdbEnv>,
   18|       |
   19|       |    /// U256 (arbitrary key) -> blob
   20|       |    database: LmdbDatabase,
   21|       |    #[cfg(feature = "output_tracking")]
   22|       |    put_listener: OutputListenerMt<(Account, AccountInfo)>,
   23|       |}
   24|       |
   25|       |impl LmdbAccountStore {
   26|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   27|     27|        let database = env
   28|     27|            .environment
   29|     27|            .create_db(Some("accounts"), DatabaseFlags::empty())?;
                                                                              ^0
   30|     27|        Ok(Self {
   31|     27|            env,
   32|     27|            database,
   33|     27|            #[cfg(feature = "output_tracking")]
   34|     27|            put_listener: OutputListenerMt::new(),
   35|     27|        })
   36|     27|    }
   37|       |
   38|       |    #[cfg(feature = "output_tracking")]
   39|       |    pub fn track_puts(&self) -> Arc<OutputTrackerMt<(Account, AccountInfo)>> {
   40|       |        self.put_listener.track()
   41|       |    }
   42|       |
   43|      0|    pub fn database(&self) -> LmdbDatabase {
   44|      0|        self.database
   45|      0|    }
   46|       |
   47|     59|    pub fn put(
   48|     59|        &self,
   49|     59|        transaction: &mut LmdbWriteTransaction,
   50|     59|        account: &Account,
   51|     59|        info: &AccountInfo,
   52|     59|    ) {
   53|     59|        #[cfg(feature = "output_tracking")]
   54|     59|        self.put_listener.emit((*account, info.clone()));
   55|     59|        transaction
   56|     59|            .put(
   57|     59|                self.database,
   58|     59|                account.as_bytes(),
   59|     59|                &info.to_bytes(),
   60|     59|                WriteFlags::empty(),
   61|     59|            )
   62|     59|            .unwrap();
   63|     59|    }
   64|       |
   65|     32|    pub fn get(&self, transaction: &dyn Transaction, account: &Account) -> Option<AccountInfo> {
   66|     32|        let result = transaction.get(self.database, account.as_bytes());
   67|      4|        match result {
   68|      4|            Err(lmdb::Error::NotFound) => None,
   69|     28|            Ok(bytes) => {
   70|     28|                let mut stream = BufferReader::new(bytes);
   71|     28|                AccountInfo::deserialize(&mut stream).ok()
   72|       |            }
   73|      0|            Err(e) => panic!("Could not load account info {:?}", e),
   74|       |        }
   75|     32|    }
   76|       |
   77|      0|    pub fn del(&self, transaction: &mut LmdbWriteTransaction, account: &Account) {
   78|      0|        transaction
   79|      0|            .delete(self.database, account.as_bytes(), None)
   80|      0|            .unwrap();
   81|      0|    }
   82|       |
   83|     27|    pub fn iter<'txn>(
   84|     27|        &self,
   85|     27|        tx: &'txn dyn Transaction,
   86|     27|    ) -> impl Iterator<Item = (Account, AccountInfo)> + 'txn {
   87|     27|        let cursor = tx
   88|     27|            .open_ro_cursor(self.database)
   89|     27|            .expect("could not read from account store");
   90|     27|
   91|     27|        LmdbIterator::new(cursor, |key, value| {
   92|      0|            let account = Account::from_bytes(key.try_into().unwrap());
   93|      0|            let mut stream = BufferReader::new(value);
   94|      0|            let info = AccountInfo::deserialize(&mut stream).unwrap();
   95|      0|            (account, info)
   96|     27|        })
   97|     27|    }
   98|       |
   99|  1.14k|    pub fn iter_range<'txn>(
  100|  1.14k|        &self,
  101|  1.14k|        tx: &'txn dyn Transaction,
  102|  1.14k|        range: impl RangeBounds<Account> + 'static,
  103|  1.14k|    ) -> impl Iterator<Item = (Account, AccountInfo)> + 'txn {
  104|  1.14k|        let cursor = tx.open_ro_cursor(self.database).unwrap();
  105|  1.14k|        LmdbRangeIterator::new(cursor, range)
  106|  1.14k|    }
  107|       |
  108|     27|    pub fn for_each_par(
  109|     27|        &self,
  110|     27|        action: impl Fn(&mut dyn Iterator<Item = (Account, AccountInfo)>) + Send + Sync,
  111|     27|    ) {
  112|  1.08k|        parallel_traversal(&|start, end, is_last| {
  113|  1.08k|            let tx = self.env.tx_begin_read();
  114|  1.08k|            let start_account = Account::from(start);
  115|  1.08k|            let end_account = Account::from(end);
  116|  1.08k|            if is_last {
  117|     27|                let mut iter = self.iter_range(&tx, start_account..);
  118|     27|                action(&mut iter);
  119|  1.05k|            } else {
  120|  1.05k|                let mut iter = self.iter_range(&tx, start_account..end_account);
  121|  1.05k|                action(&mut iter);
  122|  1.05k|            }
  123|  1.08k|        })
  124|     27|    }
  125|       |
  126|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
  127|      0|        txn.count(self.database)
  128|      0|    }
  129|       |}
  130|       |
  131|       |pub struct ConfiguredAccountDatabaseBuilder {
  132|       |    database: ConfiguredDatabase,
  133|       |}
  134|       |
  135|       |impl ConfiguredAccountDatabaseBuilder {
  136|     20|    pub fn new() -> Self {
  137|     20|        Self {
  138|     20|            database: ConfiguredDatabase::new(ACCOUNT_TEST_DATABASE, "accounts"),
  139|     20|        }
  140|     20|    }
  141|       |
  142|      0|    pub fn account(mut self, account: &Account, info: &AccountInfo) -> Self {
  143|      0|        self.database
  144|      0|            .entries
  145|      0|            .insert(account.as_bytes().to_vec(), info.to_bytes().to_vec());
  146|      0|        self
  147|      0|    }
  148|       |
  149|     20|    pub fn build(self) -> ConfiguredDatabase {
  150|     20|        self.database
  151|     20|    }
  152|       |
  153|      0|    pub fn create(frontiers: Vec<(Account, AccountInfo)>) -> ConfiguredDatabase {
  154|      0|        let mut builder = Self::new();
  155|      0|        for (account, info) in frontiers {
  156|      0|            builder = builder.account(&account, &info);
  157|      0|        }
  158|      0|        builder.build()
  159|      0|    }
  160|       |}
  161|       |
  162|       |#[cfg(test)]
  163|       |mod tests {
  164|       |    use super::*;
  165|       |    use crate::{DeleteEvent, PutEvent};
  166|       |    use rsnano_core::{Amount, BlockHash};
  167|       |    use std::sync::Mutex;
  168|       |
  169|       |    struct Fixture {
  170|       |        env: Arc<LmdbEnv>,
  171|       |        store: LmdbAccountStore,
  172|       |    }
  173|       |
  174|       |    impl Fixture {
  175|       |        fn new() -> Self {
  176|       |            Self::with_stored_accounts(Vec::new())
  177|       |        }
  178|       |
  179|       |        fn with_stored_accounts(accounts: Vec<(Account, AccountInfo)>) -> Self {
  180|       |            let env = LmdbEnv::new_null_with()
  181|       |                .configured_database(ConfiguredAccountDatabaseBuilder::create(accounts))
  182|       |                .build();
  183|       |            Self::with_env(env)
  184|       |        }
  185|       |
  186|       |        fn with_env(env: LmdbEnv) -> Self {
  187|       |            let env = Arc::new(env);
  188|       |            let store = LmdbAccountStore::new(env.clone()).unwrap();
  189|       |
  190|       |            Fixture { env, store }
  191|       |        }
  192|       |    }
  193|       |
  194|       |    #[test]
  195|       |    fn empty_store() {
  196|       |        let fixture = Fixture::new();
  197|       |        let txn = fixture.env.tx_begin_read();
  198|       |        let account = Account::from(1);
  199|       |        let result = fixture.store.get(&txn, &account);
  200|       |        assert_eq!(result, None);
  201|       |        assert_eq!(fixture.store.count(&txn), 0);
  202|       |    }
  203|       |
  204|       |    #[test]
  205|       |    fn add_one_account() {
  206|       |        let fixture = Fixture::new();
  207|       |        let mut txn = fixture.env.tx_begin_write();
  208|       |        let put_tracker = txn.track_puts();
  209|       |
  210|       |        let account = Account::from(1);
  211|       |        let info = AccountInfo::new_test_instance();
  212|       |        fixture.store.put(&mut txn, &account, &info);
  213|       |
  214|       |        assert_eq!(
  215|       |            put_tracker.output(),
  216|       |            vec![PutEvent {
  217|       |                database: ACCOUNT_TEST_DATABASE.into(),
  218|       |                key: account.as_bytes().to_vec(),
  219|       |                value: info.to_bytes().to_vec(),
  220|       |                flags: lmdb::WriteFlags::empty()
  221|       |            }]
  222|       |        );
  223|       |    }
  224|       |
  225|       |    #[test]
  226|       |    fn load_account() {
  227|       |        let account = Account::from(1);
  228|       |        let info = AccountInfo::new_test_instance();
  229|       |        let fixture = Fixture::with_stored_accounts(vec![(account.clone(), info.clone())]);
  230|       |        let txn = fixture.env.tx_begin_read();
  231|       |
  232|       |        let result = fixture.store.get(&txn, &account);
  233|       |
  234|       |        assert_eq!(result, Some(info));
  235|       |    }
  236|       |
  237|       |    #[test]
  238|       |    fn count() {
  239|       |        let fixture = Fixture::with_stored_accounts(vec![
  240|       |            (Account::from(1), AccountInfo::new_test_instance()),
  241|       |            (Account::from(2), AccountInfo::new_test_instance()),
  242|       |        ]);
  243|       |        let txn = fixture.env.tx_begin_read();
  244|       |
  245|       |        let count = fixture.store.count(&txn);
  246|       |
  247|       |        assert_eq!(count, 2);
  248|       |    }
  249|       |
  250|       |    #[test]
  251|       |    fn delete_account() {
  252|       |        let fixture = Fixture::new();
  253|       |        let mut txn = fixture.env.tx_begin_write();
  254|       |        let delete_tracker = txn.track_deletions();
  255|       |
  256|       |        let account = Account::from(1);
  257|       |        fixture.store.del(&mut txn, &account);
  258|       |
  259|       |        assert_eq!(
  260|       |            delete_tracker.output(),
  261|       |            vec![DeleteEvent {
  262|       |                database: ACCOUNT_TEST_DATABASE.into(),
  263|       |                key: account.as_bytes().to_vec()
  264|       |            }]
  265|       |        )
  266|       |    }
  267|       |
  268|       |    #[test]
  269|       |    fn begin_empty_store_nullable() {
  270|       |        let fixture = Fixture::new();
  271|       |        let txn = fixture.env.tx_begin_read();
  272|       |        let mut it = fixture.store.iter(&txn);
  273|       |        assert_eq!(it.next(), None);
  274|       |    }
  275|       |
  276|       |    #[test]
  277|       |    fn begin() {
  278|       |        let account1 = Account::from(1);
  279|       |        let account2 = Account::from(2);
  280|       |        let info1 = AccountInfo {
  281|       |            head: BlockHash::from(1),
  282|       |            ..Default::default()
  283|       |        };
  284|       |        let info2 = AccountInfo {
  285|       |            head: BlockHash::from(2),
  286|       |            ..Default::default()
  287|       |        };
  288|       |
  289|       |        let fixture = Fixture::with_stored_accounts(vec![
  290|       |            (account1.clone(), info1.clone()),
  291|       |            (account2.clone(), info2.clone()),
  292|       |        ]);
  293|       |        let txn = fixture.env.tx_begin_read();
  294|       |
  295|       |        let mut it = fixture.store.iter(&txn);
  296|       |        assert_eq!(it.next(), Some((account1, info1)));
  297|       |        assert_eq!(it.next(), Some((account2, info2)));
  298|       |        assert_eq!(it.next(), None);
  299|       |    }
  300|       |
  301|       |    #[test]
  302|       |    fn begin_account() {
  303|       |        let account1 = Account::from(1);
  304|       |        let account3 = Account::from(3);
  305|       |        let info1 = AccountInfo {
  306|       |            head: BlockHash::from(1),
  307|       |            ..Default::default()
  308|       |        };
  309|       |        let info3 = AccountInfo {
  310|       |            head: BlockHash::from(3),
  311|       |            ..Default::default()
  312|       |        };
  313|       |
  314|       |        let fixture = Fixture::with_stored_accounts(vec![
  315|       |            (account1.clone(), info1.clone()),
  316|       |            (account3.clone(), info3.clone()),
  317|       |        ]);
  318|       |        let txn = fixture.env.tx_begin_read();
  319|       |
  320|       |        let mut it = fixture.store.iter_range(&txn, Account::from(2)..);
  321|       |
  322|       |        assert_eq!(it.next(), Some((account3, info3)));
  323|       |        assert_eq!(it.next(), None);
  324|       |    }
  325|       |
  326|       |    #[test]
  327|       |    fn for_each_par() {
  328|       |        let account1 = Account::from(1);
  329|       |        let account3 = Account::from(3);
  330|       |        let info1 = AccountInfo {
  331|       |            balance: Amount::raw(1),
  332|       |            ..Default::default()
  333|       |        };
  334|       |        let info3 = AccountInfo {
  335|       |            balance: Amount::raw(3),
  336|       |            ..Default::default()
  337|       |        };
  338|       |
  339|       |        let fixture = Fixture::with_stored_accounts(vec![
  340|       |            (account1.clone(), info1.clone()),
  341|       |            (account3.clone(), info3.clone()),
  342|       |        ]);
  343|       |
  344|       |        let balance_sum = Mutex::new(Amount::zero());
  345|       |        fixture.store.for_each_par(|iter| {
  346|       |            for (_, info) in iter {
  347|       |                *balance_sum.lock().unwrap() += info.balance;
  348|       |            }
  349|       |        });
  350|       |        assert_eq!(*balance_sum.lock().unwrap(), Amount::raw(4));
  351|       |    }
  352|       |
  353|       |    #[test]
  354|       |    fn track_inserted_account_info() {
  355|       |        let fixture = Fixture::new();
  356|       |        let put_tracker = fixture.store.track_puts();
  357|       |        let mut txn = fixture.env.tx_begin_write();
  358|       |        let account = Account::from(1);
  359|       |        let info = AccountInfo::new_test_instance();
  360|       |
  361|       |        fixture.store.put(&mut txn, &account, &info);
  362|       |
  363|       |        assert_eq!(put_tracker.output(), vec![(account, info)]);
  364|       |    }
  365|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/block_store.rs:
    1|       |use crate::{
    2|       |    LmdbDatabase, LmdbEnv, LmdbIterator, LmdbRangeIterator, LmdbWriteTransaction, Transaction,
    3|       |    BLOCK_TEST_DATABASE,
    4|       |};
    5|       |use lmdb::{DatabaseFlags, WriteFlags};
    6|       |use num_traits::FromPrimitive;
    7|       |use rsnano_core::{
    8|       |    utils::{BufferReader, Deserialize, FixedSizeSerialize},
    9|       |    Block, BlockHash, BlockSideband, BlockType, SavedBlock,
   10|       |};
   11|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
   12|       |#[cfg(feature = "output_tracking")]
   13|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   14|       |use std::{ops::RangeBounds, sync::Arc};
   15|       |
   16|       |pub struct LmdbBlockStore {
   17|       |    _env: Arc<LmdbEnv>,
   18|       |    database: LmdbDatabase,
   19|       |    #[cfg(feature = "output_tracking")]
   20|       |    put_listener: OutputListenerMt<SavedBlock>,
   21|       |}
   22|       |
   23|       |pub struct ConfiguredBlockDatabaseBuilder {
   24|       |    database: ConfiguredDatabase,
   25|       |}
   26|       |
   27|       |impl ConfiguredBlockDatabaseBuilder {
   28|     20|    pub fn new() -> Self {
   29|     20|        Self {
   30|     20|            database: ConfiguredDatabase::new(BLOCK_TEST_DATABASE, "blocks"),
   31|     20|        }
   32|     20|    }
   33|       |
   34|      2|    pub fn block(mut self, block: &SavedBlock) -> Self {
   35|      2|        self.database.entries.insert(
   36|      2|            block.hash().as_bytes().to_vec(),
   37|      2|            block.serialize_with_sideband(),
   38|      2|        );
   39|      2|        self
   40|      2|    }
   41|       |
   42|     20|    pub fn build(self) -> ConfiguredDatabase {
   43|     20|        self.database
   44|     20|    }
   45|       |}
   46|       |
   47|       |impl LmdbBlockStore {
   48|      0|    pub fn configured_responses() -> ConfiguredBlockDatabaseBuilder {
   49|      0|        ConfiguredBlockDatabaseBuilder::new()
   50|      0|    }
   51|       |
   52|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   53|     27|        let database = env
   54|     27|            .environment
   55|     27|            .create_db(Some("blocks"), DatabaseFlags::empty())?;
                                                                            ^0
   56|     27|        Ok(Self {
   57|     27|            _env: env,
   58|     27|            database,
   59|     27|            #[cfg(feature = "output_tracking")]
   60|     27|            put_listener: OutputListenerMt::new(),
   61|     27|        })
   62|     27|    }
   63|       |
   64|      0|    pub fn database(&self) -> LmdbDatabase {
   65|      0|        self.database
   66|      0|    }
   67|       |
   68|       |    #[cfg(feature = "output_tracking")]
   69|       |    pub fn track_puts(&self) -> Arc<OutputTrackerMt<SavedBlock>> {
   70|       |        self.put_listener.track()
   71|       |    }
   72|       |
   73|     59|    pub fn put(&self, txn: &mut LmdbWriteTransaction, block: &SavedBlock) {
   74|     59|        #[cfg(feature = "output_tracking")]
   75|     59|        self.put_listener.emit(block.clone());
   76|     59|
   77|     59|        let hash = block.hash();
   78|     59|        debug_assert!(
   79|     59|            block.successor().is_none() || self.exists(txn, &block.successor().unwrap_or_default())
                                                         ^0
   80|       |        );
   81|       |
   82|     59|        self.raw_put(txn, &block.serialize_with_sideband(), &hash);
   83|     59|        self.update_predecessor(txn, &block);
   84|     59|    }
   85|       |
   86|  16.4k|    pub fn exists(&self, transaction: &dyn Transaction, hash: &BlockHash) -> bool {
   87|  16.4k|        transaction.exists(self.database, hash.as_bytes())
   88|  16.4k|    }
   89|       |
   90|      0|    pub fn successor(&self, txn: &dyn Transaction, hash: &BlockHash) -> Option<BlockHash> {
   91|      0|        self.block_raw_get(txn, hash).and_then(|data| {
   92|      0|            debug_assert!(data.len() >= 32);
   93|      0|            let block_type = BlockType::from_u8(data[0]).unwrap();
   94|      0|            let offset = block_successor_offset(data.len(), block_type);
   95|      0|            let successor = BlockHash::from_bytes(data[offset..offset + 32].try_into().unwrap());
   96|      0|            if successor.is_zero() {
   97|      0|                None
   98|       |            } else {
   99|      0|                Some(successor)
  100|       |            }
  101|      0|        })
  102|      0|    }
  103|       |
  104|      0|    pub fn successor_clear(&self, txn: &mut LmdbWriteTransaction, hash: &BlockHash) {
  105|      0|        let value = self.block_raw_get(txn, hash).unwrap();
  106|      0|        let block_type = BlockType::from_u8(value[0]).unwrap();
  107|      0|
  108|      0|        let mut data = value.to_vec();
  109|      0|        let offset = block_successor_offset(value.len(), block_type);
  110|      0|        data[offset..offset + BlockHash::serialized_size()].fill(0);
  111|      0|        self.raw_put(txn, &data, hash)
  112|      0|    }
  113|       |
  114|  65.5k|    pub fn get(&self, txn: &dyn Transaction, hash: &BlockHash) -> Option<SavedBlock> {
  115|  65.5k|        self.block_raw_get(txn, hash).map(|bytes| {
  116|  65.5k|            let mut stream = BufferReader::new(bytes);
  117|  65.5k|            SavedBlock::deserialize(&mut stream)
  118|  65.5k|                .unwrap_or_else(|_| panic!("Could not deserialize block {}!", hash))
                                                  ^0
  119|  65.5k|        })
  120|  65.5k|    }
  121|       |
  122|      0|    pub fn get_no_sideband(&self, txn: &dyn Transaction, hash: &BlockHash) -> Option<Block> {
  123|      0|        match self.block_raw_get(txn, hash) {
  124|      0|            None => None,
  125|      0|            Some(bytes) => {
  126|      0|                let mut stream = BufferReader::new(bytes);
  127|      0|                Some(Block::deserialize(&mut stream).unwrap())
  128|       |            }
  129|       |        }
  130|      0|    }
  131|       |
  132|      0|    pub fn del(&self, txn: &mut LmdbWriteTransaction, hash: &BlockHash) {
  133|      0|        txn.delete(self.database, hash.as_bytes(), None).unwrap();
  134|      0|    }
  135|       |
  136|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
  137|      0|        txn.count(self.database)
  138|      0|    }
  139|       |
  140|      0|    pub fn iter<'tx>(&self, tx: &'tx dyn Transaction) -> impl Iterator<Item = SavedBlock> + 'tx {
  141|      0|        let cursor = tx
  142|      0|            .open_ro_cursor(self.database)
  143|      0|            .expect("Could not open cursor for block table");
  144|      0|
  145|      0|        LmdbIterator::new(cursor, |k, v| {
  146|      0|            let hash = BlockHash::from_slice(k).unwrap();
  147|      0|            let mut stream = BufferReader::new(v);
  148|      0|            let block = SavedBlock::deserialize(&mut stream).unwrap();
  149|      0|            (hash, block)
  150|      0|        })
  151|      0|        .map(|(_, v)| v)
  152|      0|    }
  153|       |
  154|     33|    pub fn iter_range<'txn>(
  155|     33|        &self,
  156|     33|        tx: &'txn dyn Transaction,
  157|     33|        range: impl RangeBounds<BlockHash> + 'static,
  158|     33|    ) -> impl Iterator<Item = SavedBlock> + 'txn {
  159|     33|        let cursor = tx
  160|     33|            .open_ro_cursor(self.database)
  161|     33|            .expect("Could not open cursor for block table");
  162|     33|
  163|     33|        LmdbRangeIterator::new(cursor, range).map(|(_, v)| v)
                                                                         ^30
  164|     33|    }
  165|       |
  166|     87|    pub fn raw_put(&self, txn: &mut LmdbWriteTransaction, data: &[u8], hash: &BlockHash) {
  167|     87|        txn.put(self.database, hash.as_bytes(), data, WriteFlags::empty())
  168|     87|            .unwrap();
  169|     87|    }
  170|       |
  171|  65.5k|    pub fn block_raw_get<'a>(
  172|  65.5k|        &self,
  173|  65.5k|        txn: &'a dyn Transaction,
  174|  65.5k|        hash: &BlockHash,
  175|  65.5k|    ) -> Option<&'a [u8]> {
  176|  65.5k|        match txn.get(self.database, hash.as_bytes()) {
  177|      0|            Err(lmdb::Error::NotFound) => None,
  178|  65.5k|            Ok(bytes) => Some(bytes),
  179|      0|            Err(e) => panic!("Could not load block. {:?}", e),
  180|       |        }
  181|  65.5k|    }
  182|       |
  183|       |    /// Update the "successor" value of the block's predecesssor
  184|     59|    fn update_predecessor(&self, txn: &mut LmdbWriteTransaction, block: &SavedBlock) {
  185|     59|        if block.previous().is_zero() {
  186|     31|            return;
  187|     28|        }
  188|     28|        let hash = block.hash();
  189|     28|        let value = self
  190|     28|            .block_raw_get(txn, &block.previous())
  191|     28|            .expect("block not found by fill_value");
  192|     28|        let mut data = value.to_vec();
  193|     28|        let block_type = BlockType::from_u8(data[0]).unwrap();
  194|     28|
  195|     28|        let offset = block_successor_offset(data.len(), block_type);
  196|     28|        data[offset..offset + hash.as_bytes().len()].copy_from_slice(hash.as_bytes());
  197|     28|
  198|     28|        self.raw_put(txn, &data, &block.previous());
  199|     59|    }
  200|       |}
  201|       |
  202|     28|fn block_successor_offset(entry_size: usize, block_type: BlockType) -> usize {
  203|     28|    entry_size - BlockSideband::serialized_size(block_type)
  204|     28|}
  205|       |
  206|       |#[cfg(test)]
  207|       |mod tests {
  208|       |    use crate::PutEvent;
  209|       |    use rsnano_core::TestBlockBuilder;
  210|       |
  211|       |    use super::*;
  212|       |
  213|       |    struct Fixture {
  214|       |        env: Arc<LmdbEnv>,
  215|       |        store: LmdbBlockStore,
  216|       |    }
  217|       |
  218|       |    impl Fixture {
  219|       |        fn new() -> Self {
  220|       |            Self::with_env(LmdbEnv::new_null())
  221|       |        }
  222|       |
  223|       |        fn with_env(env: LmdbEnv) -> Self {
  224|       |            let env = Arc::new(env);
  225|       |            Self {
  226|       |                env: env.clone(),
  227|       |                store: LmdbBlockStore::new(env).unwrap(),
  228|       |            }
  229|       |        }
  230|       |    }
  231|       |
  232|       |    #[test]
  233|       |    fn empty() {
  234|       |        let fixture = Fixture::new();
  235|       |        let store = &fixture.store;
  236|       |        let txn = fixture.env.tx_begin_read();
  237|       |
  238|       |        assert!(store.get(&txn, &BlockHash::from(1)).is_none());
  239|       |        assert_eq!(store.exists(&txn, &BlockHash::from(1)), false);
  240|       |        assert_eq!(store.count(&txn), 0);
  241|       |    }
  242|       |
  243|       |    #[test]
  244|       |    fn load_block_by_hash() {
  245|       |        let block = SavedBlock::new_test_instance();
  246|       |
  247|       |        let env = LmdbEnv::new_null_with()
  248|       |            .database("blocks", LmdbDatabase::new_null(100))
  249|       |            .entry(block.hash().as_bytes(), &block.serialize_with_sideband())
  250|       |            .build()
  251|       |            .build();
  252|       |        let fixture = Fixture::with_env(env);
  253|       |        let txn = fixture.env.tx_begin_read();
  254|       |
  255|       |        let result = fixture.store.get(&txn, &block.hash());
  256|       |        assert_eq!(result, Some(block));
  257|       |    }
  258|       |
  259|       |    #[test]
  260|       |    fn add_block() {
  261|       |        let fixture = Fixture::new();
  262|       |        let mut txn = fixture.env.tx_begin_write();
  263|       |        let put_tracker = txn.track_puts();
  264|       |        let block = SavedBlock::new_test_open_block();
  265|       |
  266|       |        fixture.store.put(&mut txn, &block);
  267|       |
  268|       |        assert_eq!(
  269|       |            put_tracker.output(),
  270|       |            vec![PutEvent {
  271|       |                database: LmdbDatabase::new_null(42),
  272|       |                key: block.hash().as_bytes().to_vec(),
  273|       |                value: block.serialize_with_sideband(),
  274|       |                flags: lmdb::WriteFlags::empty(),
  275|       |            }]
  276|       |        );
  277|       |    }
  278|       |
  279|       |    #[test]
  280|       |    fn clear_successor() {
  281|       |        let block = TestBlockBuilder::legacy_open().build();
  282|       |        let sideband = BlockSideband {
  283|       |            successor: BlockHash::from(123),
  284|       |            ..BlockSideband::new_test_instance()
  285|       |        };
  286|       |        let block = SavedBlock::new(block, sideband.clone());
  287|       |
  288|       |        let env = LmdbEnv::new_null_with()
  289|       |            .database("blocks", LmdbDatabase::new_null(100))
  290|       |            .entry(block.hash().as_bytes(), &block.serialize_with_sideband())
  291|       |            .build()
  292|       |            .build();
  293|       |        let fixture = Fixture::with_env(env);
  294|       |        let mut txn = fixture.env.tx_begin_write();
  295|       |        let put_tracker = txn.track_puts();
  296|       |
  297|       |        fixture.store.successor_clear(&mut txn, &block.hash());
  298|       |
  299|       |        let mut expected_block = block.clone();
  300|       |        expected_block.set_sideband(BlockSideband {
  301|       |            successor: BlockHash::zero(),
  302|       |            ..sideband
  303|       |        });
  304|       |
  305|       |        assert_eq!(
  306|       |            put_tracker.output(),
  307|       |            vec![PutEvent {
  308|       |                database: LmdbDatabase::new_null(100),
  309|       |                key: expected_block.hash().as_bytes().to_vec(),
  310|       |                value: expected_block.serialize_with_sideband(),
  311|       |                flags: WriteFlags::empty(),
  312|       |            }]
  313|       |        );
  314|       |    }
  315|       |
  316|       |    #[test]
  317|       |    fn track_inserted_blocks() {
  318|       |        let fixture = Fixture::new();
  319|       |        let block = SavedBlock::new_test_open_block();
  320|       |        let mut txn = fixture.env.tx_begin_write();
  321|       |        let put_tracker = fixture.store.track_puts();
  322|       |
  323|       |        fixture.store.put(&mut txn, &block);
  324|       |
  325|       |        assert_eq!(put_tracker.output(), vec![block]);
  326|       |    }
  327|       |
  328|       |    #[test]
  329|       |    fn can_be_nulled() {
  330|       |        let block = SavedBlock::new_test_instance();
  331|       |        let configured_responses = LmdbBlockStore::configured_responses().block(&block).build();
  332|       |        let env = LmdbEnv::new_null_with()
  333|       |            .configured_database(configured_responses)
  334|       |            .build();
  335|       |        let txn = env.tx_begin_read();
  336|       |        let block_store = LmdbBlockStore::new(Arc::new(env)).unwrap();
  337|       |        assert_eq!(block_store.get(&txn, &block.hash()), Some(block));
  338|       |    }
  339|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/confirmation_height_store.rs:
    1|       |use crate::{
    2|       |    parallel_traversal, LmdbDatabase, LmdbEnv, LmdbIterator, LmdbRangeIterator,
    3|       |    LmdbWriteTransaction, Transaction, CONFIRMATION_HEIGHT_TEST_DATABASE,
    4|       |};
    5|       |use lmdb::{DatabaseFlags, WriteFlags};
    6|       |use rsnano_core::{
    7|       |    utils::{BufferReader, Deserialize},
    8|       |    Account, ConfirmationHeightInfo,
    9|       |};
   10|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
   11|       |use std::{ops::RangeBounds, sync::Arc};
   12|       |
   13|       |pub struct LmdbConfirmationHeightStore {
   14|       |    env: Arc<LmdbEnv>,
   15|       |    database: LmdbDatabase,
   16|       |}
   17|       |
   18|       |impl LmdbConfirmationHeightStore {
   19|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   20|     27|        let database = env
   21|     27|            .environment
   22|     27|            .create_db(Some("confirmation_height"), DatabaseFlags::empty())?;
                                                                                         ^0
   23|     27|        Ok(Self { env, database })
   24|     27|    }
   25|       |
   26|      0|    pub fn database(&self) -> LmdbDatabase {
   27|      0|        self.database
   28|      0|    }
   29|       |
   30|  16.4k|    pub fn put(
   31|  16.4k|        &self,
   32|  16.4k|        txn: &mut LmdbWriteTransaction,
   33|  16.4k|        account: &Account,
   34|  16.4k|        info: &ConfirmationHeightInfo,
   35|  16.4k|    ) {
   36|  16.4k|        txn.put(
   37|  16.4k|            self.database,
   38|  16.4k|            account.as_bytes(),
   39|  16.4k|            &info.to_bytes(),
   40|  16.4k|            WriteFlags::empty(),
   41|  16.4k|        )
   42|  16.4k|        .unwrap();
   43|  16.4k|    }
   44|       |
   45|  49.1k|    pub fn get(&self, txn: &dyn Transaction, account: &Account) -> Option<ConfirmationHeightInfo> {
   46|  49.1k|        match txn.get(self.database, account.as_bytes()) {
   47|      0|            Err(lmdb::Error::NotFound) => None,
   48|  49.1k|            Ok(bytes) => {
   49|  49.1k|                let mut stream = BufferReader::new(bytes);
   50|  49.1k|                ConfirmationHeightInfo::deserialize(&mut stream).ok()
   51|       |            }
   52|      0|            Err(e) => {
   53|      0|                panic!("Could not load confirmation height info: {:?}", e);
   54|       |            }
   55|       |        }
   56|  49.1k|    }
   57|       |
   58|      0|    pub fn exists(&self, txn: &dyn Transaction, account: &Account) -> bool {
   59|      0|        txn.exists(self.database, account.as_bytes())
   60|      0|    }
   61|       |
   62|      0|    pub fn del(&self, txn: &mut LmdbWriteTransaction, account: &Account) {
   63|      0|        txn.delete(self.database, account.as_bytes(), None).unwrap();
   64|      0|    }
   65|       |
   66|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
   67|      0|        txn.count(self.database)
   68|      0|    }
   69|       |
   70|      0|    pub fn clear(&self, txn: &mut LmdbWriteTransaction) {
   71|      0|        txn.clear_db(self.database).unwrap()
   72|      0|    }
   73|       |
   74|      0|    pub fn iter<'tx>(
   75|      0|        &self,
   76|      0|        tx: &'tx dyn Transaction,
   77|      0|    ) -> impl Iterator<Item = (Account, ConfirmationHeightInfo)> + 'tx {
   78|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   79|      0|
   80|      0|        LmdbIterator::new(cursor, |key, value| {
   81|      0|            let account = Account::from_bytes(key.try_into().unwrap());
   82|      0|            let mut stream = BufferReader::new(value);
   83|      0|            let info = ConfirmationHeightInfo::deserialize(&mut stream).unwrap();
   84|      0|            (account, info)
   85|      0|        })
   86|      0|    }
   87|       |
   88|  1.08k|    pub fn iter_range<'txn>(
   89|  1.08k|        &self,
   90|  1.08k|        tx: &'txn dyn Transaction,
   91|  1.08k|        range: impl RangeBounds<Account> + 'static,
   92|  1.08k|    ) -> impl Iterator<Item = (Account, ConfirmationHeightInfo)> + 'txn {
   93|  1.08k|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   94|  1.08k|        LmdbRangeIterator::new(cursor, range)
   95|  1.08k|    }
   96|       |
   97|     27|    pub fn for_each_par(
   98|     27|        &self,
   99|     27|        action: impl Fn(&mut dyn Iterator<Item = (Account, ConfirmationHeightInfo)>) + Send + Sync,
  100|     27|    ) {
  101|  1.08k|        parallel_traversal(&|start, end, is_last| {
  102|  1.08k|            let tx = self.env.tx_begin_read();
  103|  1.08k|            let start_account = Account::from(start);
  104|  1.08k|            let end_account = Account::from(end);
  105|  1.08k|            if is_last {
  106|     27|                let mut iter = self.iter_range(&tx, start_account..);
  107|     27|                action(&mut iter);
  108|  1.05k|            } else {
  109|  1.05k|                let mut iter = self.iter_range(&tx, start_account..end_account);
  110|  1.05k|                action(&mut iter);
  111|  1.05k|            }
  112|  1.08k|        })
  113|     27|    }
  114|       |}
  115|       |
  116|       |pub struct ConfiguredConfirmationHeightDatabaseBuilder {
  117|       |    database: ConfiguredDatabase,
  118|       |}
  119|       |
  120|       |impl ConfiguredConfirmationHeightDatabaseBuilder {
  121|     20|    pub fn new() -> Self {
  122|     20|        Self {
  123|     20|            database: ConfiguredDatabase::new(
  124|     20|                CONFIRMATION_HEIGHT_TEST_DATABASE,
  125|     20|                "confirmation_height",
  126|     20|            ),
  127|     20|        }
  128|     20|    }
  129|       |
  130|      1|    pub fn height(mut self, account: &Account, info: &ConfirmationHeightInfo) -> Self {
  131|      1|        self.database
  132|      1|            .entries
  133|      1|            .insert(account.as_bytes().to_vec(), info.to_bytes().to_vec());
  134|      1|        self
  135|      1|    }
  136|       |
  137|     20|    pub fn build(self) -> ConfiguredDatabase {
  138|     20|        self.database
  139|     20|    }
  140|       |
  141|      0|    pub fn create(hashes: Vec<(Account, ConfirmationHeightInfo)>) -> ConfiguredDatabase {
  142|      0|        let mut builder = Self::new();
  143|      0|        for (account, info) in hashes {
  144|      0|            builder = builder.height(&account, &info);
  145|      0|        }
  146|      0|        builder.build()
  147|      0|    }
  148|       |}
  149|       |
  150|       |#[cfg(test)]
  151|       |mod tests {
  152|       |    use super::*;
  153|       |    use crate::PutEvent;
  154|       |    use rsnano_core::BlockHash;
  155|       |
  156|       |    struct Fixture {
  157|       |        env: Arc<LmdbEnv>,
  158|       |        store: LmdbConfirmationHeightStore,
  159|       |    }
  160|       |
  161|       |    impl Fixture {
  162|       |        fn new() -> Self {
  163|       |            Self::with_env(LmdbEnv::new_null())
  164|       |        }
  165|       |
  166|       |        fn with_env(env: LmdbEnv) -> Self {
  167|       |            let env = Arc::new(env);
  168|       |            Self {
  169|       |                env: env.clone(),
  170|       |                store: LmdbConfirmationHeightStore::new(env).unwrap(),
  171|       |            }
  172|       |        }
  173|       |    }
  174|       |
  175|       |    #[test]
  176|       |    fn empty_store() {
  177|       |        let fixture = Fixture::new();
  178|       |        let store = &fixture.store;
  179|       |        let tx = fixture.env.tx_begin_read();
  180|       |        assert!(store.get(&tx, &Account::from(0)).is_none());
  181|       |        assert_eq!(store.exists(&tx, &Account::from(0)), false);
  182|       |        assert!(store.iter(&tx).next().is_none());
  183|       |        assert!(store.iter_range(&tx, Account::from(0)..).next().is_none());
  184|       |    }
  185|       |
  186|       |    #[test]
  187|       |    fn add_account() {
  188|       |        let fixture = Fixture::new();
  189|       |        let mut txn = fixture.env.tx_begin_write();
  190|       |        let put_tracker = txn.track_puts();
  191|       |
  192|       |        let account = Account::from(1);
  193|       |        let info = ConfirmationHeightInfo::new(1, BlockHash::from(2));
  194|       |        fixture.store.put(&mut txn, &account, &info);
  195|       |
  196|       |        assert_eq!(
  197|       |            put_tracker.output(),
  198|       |            vec![PutEvent {
  199|       |                database: LmdbDatabase::new_null(42),
  200|       |                key: account.as_bytes().to_vec(),
  201|       |                value: info.to_bytes().to_vec(),
  202|       |                flags: WriteFlags::empty(),
  203|       |            }]
  204|       |        )
  205|       |    }
  206|       |
  207|       |    #[test]
  208|       |    fn load() {
  209|       |        let account = Account::from(1);
  210|       |        let info = ConfirmationHeightInfo::new(1, BlockHash::from(2));
  211|       |
  212|       |        let env = LmdbEnv::new_null_with()
  213|       |            .database("confirmation_height", LmdbDatabase::new_null(100))
  214|       |            .entry(account.as_bytes(), &info.to_bytes())
  215|       |            .build()
  216|       |            .build();
  217|       |
  218|       |        let fixture = Fixture::with_env(env);
  219|       |        let txn = fixture.env.tx_begin_read();
  220|       |        let result = fixture.store.get(&txn, &account);
  221|       |
  222|       |        assert_eq!(result, Some(info))
  223|       |    }
  224|       |
  225|       |    #[test]
  226|       |    fn iterate_one_account() -> anyhow::Result<()> {
  227|       |        let account = Account::from(1);
  228|       |        let info = ConfirmationHeightInfo::new(1, BlockHash::from(2));
  229|       |
  230|       |        let env = LmdbEnv::new_null_with()
  231|       |            .database("confirmation_height", LmdbDatabase::new_null(100))
  232|       |            .entry(account.as_bytes(), &info.to_bytes())
  233|       |            .build()
  234|       |            .build();
  235|       |
  236|       |        let fixture = Fixture::with_env(env);
  237|       |        let tx = fixture.env.tx_begin_read();
  238|       |        let mut it = fixture.store.iter(&tx);
  239|       |        assert_eq!(it.next(), Some((account, info)));
  240|       |        assert!(it.next().is_none());
  241|       |        Ok(())
  242|       |    }
  243|       |
  244|       |    #[test]
  245|       |    fn clear() {
  246|       |        let fixture = Fixture::new();
  247|       |        let mut txn = fixture.env.tx_begin_write();
  248|       |        let clear_tracker = txn.track_clears();
  249|       |
  250|       |        fixture.store.clear(&mut txn);
  251|       |
  252|       |        assert_eq!(clear_tracker.output(), vec![LmdbDatabase::new_null(42)])
  253|       |    }
  254|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/fan.rs:
    1|       |use rand::{thread_rng, Rng};
    2|       |use rsnano_core::RawKey;
    3|       |
    4|       |/// The fan spreads a key out over the heap to decrease the likelihood of it being recovered by memory inspection
    5|       |pub struct Fan {
    6|       |    values: Vec<Box<RawKey>>,
    7|       |}
    8|       |
    9|       |impl Fan {
   10|      0|    pub fn new(key: RawKey, count: usize) -> Self {
   11|      0|        let mut first = Box::new(key);
   12|      0|        let mut values = Vec::with_capacity(count);
   13|      0|        let mut rng = thread_rng();
   14|      0|        for _ in 1..count {
   15|      0|            let entry = Box::new(RawKey::from_bytes(rng.gen()));
   16|      0|            *first.as_mut() ^= entry.as_ref().clone();
   17|      0|            values.push(entry);
   18|      0|        }
   19|      0|        values.push(first);
   20|      0|
   21|      0|        Self { values }
   22|      0|    }
   23|       |
   24|      0|    pub fn value(&self) -> RawKey {
   25|      0|        let mut key = RawKey::zero();
   26|      0|        for i in self.values.iter() {
   27|      0|            key ^= i.as_ref().clone();
   28|      0|        }
   29|      0|        key
   30|      0|    }
   31|       |
   32|      0|    pub fn value_set(&mut self, new_value: RawKey) {
   33|      0|        let old_value = self.value();
   34|      0|        *self.values[0] ^= old_value;
   35|      0|        *self.values[0] ^= new_value;
   36|      0|    }
   37|       |}
   38|       |
   39|       |#[cfg(test)]
   40|       |mod tests {
   41|       |    use super::*;
   42|       |
   43|       |    #[test]
   44|       |    fn reconstitute_fan() {
   45|       |        let value0 = RawKey::from_bytes([0; 32]);
   46|       |        let fan = Fan::new(value0, 1024);
   47|       |        for i in fan.values.iter() {
   48|       |            assert_ne!(i.as_ref(), &value0);
   49|       |        }
   50|       |        let value1 = fan.value();
   51|       |        assert_eq!(value0, value1);
   52|       |    }
   53|       |
   54|       |    #[test]
   55|       |    fn change_fan() {
   56|       |        let value0 = RawKey::from_bytes([0; 32]);
   57|       |        let value1 = RawKey::from_bytes([1; 32]);
   58|       |        let mut fan = Fan::new(value0, 1024);
   59|       |        assert_eq!(fan.values.len(), 1024);
   60|       |        assert_eq!(fan.value(), value0);
   61|       |        fan.value_set(value1);
   62|       |        assert_eq!(fan.value(), value1);
   63|       |    }
   64|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/final_vote_store.rs:
    1|       |use crate::{
    2|       |    LmdbDatabase, LmdbEnv, LmdbIterator, LmdbRangeIterator, LmdbWriteTransaction, Transaction,
    3|       |};
    4|       |use lmdb::{DatabaseFlags, WriteFlags};
    5|       |use rsnano_core::{
    6|       |    utils::{BufferReader, Deserialize},
    7|       |    BlockHash, QualifiedRoot,
    8|       |};
    9|       |use std::{ops::RangeBounds, sync::Arc};
   10|       |
   11|       |/// Maps root to block hash for generated final votes.
   12|       |/// nano::qualified_root -> nano::block_hash
   13|       |pub struct LmdbFinalVoteStore {
   14|       |    _env: Arc<LmdbEnv>,
   15|       |    database: LmdbDatabase,
   16|       |}
   17|       |
   18|       |impl LmdbFinalVoteStore {
   19|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   20|     27|        let database = env
   21|     27|            .environment
   22|     27|            .create_db(Some("final_votes"), DatabaseFlags::empty())?;
                                                                                 ^0
   23|     27|        Ok(Self {
   24|     27|            _env: env,
   25|     27|            database,
   26|     27|        })
   27|     27|    }
   28|       |
   29|      0|    pub fn database(&self) -> LmdbDatabase {
   30|      0|        self.database
   31|      0|    }
   32|       |
   33|       |    /// Returns *true* if root + hash was inserted or the same root/hash pair was already in the database
   34|      0|    pub fn put(
   35|      0|        &self,
   36|      0|        txn: &mut LmdbWriteTransaction,
   37|      0|        root: &QualifiedRoot,
   38|      0|        hash: &BlockHash,
   39|      0|    ) -> bool {
   40|      0|        let root_bytes = root.to_bytes();
   41|      0|        match txn.get(self.database, &root_bytes) {
   42|       |            Err(lmdb::Error::NotFound) => {
   43|      0|                txn.put(
   44|      0|                    self.database,
   45|      0|                    &root_bytes,
   46|      0|                    hash.as_bytes(),
   47|      0|                    WriteFlags::empty(),
   48|      0|                )
   49|      0|                .unwrap();
   50|      0|                true
   51|       |            }
   52|      0|            Ok(bytes) => BlockHash::from_slice(bytes).unwrap() == *hash,
   53|      0|            Err(e) => {
   54|      0|                panic!("Could not get final vote: {:?}", e);
   55|       |            }
   56|       |        }
   57|      0|    }
   58|       |
   59|      0|    pub fn iter<'tx>(
   60|      0|        &self,
   61|      0|        tx: &'tx dyn Transaction,
   62|      0|    ) -> impl Iterator<Item = (QualifiedRoot, BlockHash)> + 'tx {
   63|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   64|      0|
   65|      0|        LmdbIterator::new(cursor, |key, value| {
   66|      0|            let mut stream = BufferReader::new(key);
   67|      0|            let root = QualifiedRoot::deserialize(&mut stream).unwrap();
   68|      0|            let hash = BlockHash::from_slice(value).unwrap();
   69|      0|            (root, hash)
   70|      0|        })
   71|      0|    }
   72|       |
   73|      0|    pub fn iter_range<'tx>(
   74|      0|        &self,
   75|      0|        tx: &'tx dyn Transaction,
   76|      0|        range: impl RangeBounds<QualifiedRoot> + 'static,
   77|      0|    ) -> impl Iterator<Item = (QualifiedRoot, BlockHash)> + 'tx {
   78|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   79|      0|        LmdbRangeIterator::new(cursor, range)
   80|      0|    }
   81|       |
   82|      0|    pub fn get(&self, tx: &dyn Transaction, root: &QualifiedRoot) -> Option<BlockHash> {
   83|      0|        let result = tx.get(self.database, &root.to_bytes());
   84|      0|        match result {
   85|      0|            Err(lmdb::Error::NotFound) => None,
   86|      0|            Ok(bytes) => {
   87|      0|                let mut stream = BufferReader::new(bytes);
   88|      0|                BlockHash::deserialize(&mut stream).ok()
   89|       |            }
   90|      0|            Err(e) => panic!("Could not load final vote info {:?}", e),
   91|       |        }
   92|      0|    }
   93|       |
   94|      0|    pub fn del(&self, tx: &mut LmdbWriteTransaction, root: &QualifiedRoot) {
   95|      0|        let root_bytes = root.to_bytes();
   96|      0|        tx.delete(self.database, &root_bytes, None).unwrap();
   97|      0|    }
   98|       |
   99|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
  100|      0|        txn.count(self.database)
  101|      0|    }
  102|       |
  103|      0|    pub fn clear(&self, txn: &mut LmdbWriteTransaction) {
  104|      0|        txn.clear_db(self.database).unwrap();
  105|      0|    }
  106|       |}
  107|       |
  108|       |#[cfg(test)]
  109|       |mod tests {
  110|       |    use super::*;
  111|       |    use crate::DeleteEvent;
  112|       |
  113|       |    const TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(100);
  114|       |
  115|       |    struct Fixture {
  116|       |        env: Arc<LmdbEnv>,
  117|       |        store: LmdbFinalVoteStore,
  118|       |    }
  119|       |
  120|       |    impl Fixture {
  121|       |        fn new() -> Self {
  122|       |            Self::with_stored_entries(Vec::new())
  123|       |        }
  124|       |
  125|       |        fn with_stored_entries(entries: Vec<(QualifiedRoot, BlockHash)>) -> Self {
  126|       |            let mut env = LmdbEnv::new_null_with().database("final_votes", TEST_DATABASE);
  127|       |            for (key, value) in entries {
  128|       |                env = env.entry(&key.to_bytes(), value.as_bytes());
  129|       |            }
  130|       |            Self::with_env(env.build().build())
  131|       |        }
  132|       |
  133|       |        fn with_env(env: LmdbEnv) -> Self {
  134|       |            let env = Arc::new(env);
  135|       |            Self {
  136|       |                env: env.clone(),
  137|       |                store: LmdbFinalVoteStore::new(env).unwrap(),
  138|       |            }
  139|       |        }
  140|       |    }
  141|       |
  142|       |    #[test]
  143|       |    fn load() {
  144|       |        let root = QualifiedRoot::new_test_instance();
  145|       |        let hash = BlockHash::from(333);
  146|       |        let fixture = Fixture::with_stored_entries(vec![(root.clone(), hash)]);
  147|       |        let txn = fixture.env.tx_begin_read();
  148|       |
  149|       |        let result = fixture.store.get(&txn, &root);
  150|       |
  151|       |        assert_eq!(result, Some(hash));
  152|       |    }
  153|       |
  154|       |    #[test]
  155|       |    fn delete() {
  156|       |        let root = QualifiedRoot::new_test_instance();
  157|       |        let fixture = Fixture::with_stored_entries(vec![(root.clone(), BlockHash::from(333))]);
  158|       |        let mut txn = fixture.env.tx_begin_write();
  159|       |        let delete_tracker = txn.track_deletions();
  160|       |
  161|       |        fixture.store.del(&mut txn, &root);
  162|       |
  163|       |        assert_eq!(
  164|       |            delete_tracker.output(),
  165|       |            vec![DeleteEvent {
  166|       |                key: root.to_bytes().to_vec(),
  167|       |                database: TEST_DATABASE.into(),
  168|       |            }]
  169|       |        )
  170|       |    }
  171|       |
  172|       |    #[test]
  173|       |    fn clear() {
  174|       |        let fixture = Fixture::new();
  175|       |        let mut txn = fixture.env.tx_begin_write();
  176|       |        let clear_tracker = txn.track_clears();
  177|       |
  178|       |        fixture.store.clear(&mut txn);
  179|       |
  180|       |        assert_eq!(clear_tracker.output(), vec![TEST_DATABASE.into()]);
  181|       |    }
  182|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/iterator.rs:
    1|       |use lmdb_sys::{MDB_cursor_op, MDB_FIRST, MDB_LAST, MDB_NEXT, MDB_PREV, MDB_SET_RANGE};
    2|       |use rsnano_core::utils::{BufferReader, Deserialize, MutStreamAdapter, Serialize};
    3|       |use rsnano_nullable_lmdb::{RoCursor, EMPTY_DATABASE};
    4|       |use std::{
    5|       |    cmp::Ordering,
    6|       |    marker::PhantomData,
    7|       |    ops::{Bound, RangeBounds},
    8|       |};
    9|       |
   10|       |pub struct LmdbRangeIterator<'txn, K, V, R> {
   11|       |    cursor: RoCursor<'txn>,
   12|       |    range: R,
   13|       |    initialized: bool,
   14|       |    empty: bool,
   15|       |    phantom: PhantomData<(K, V)>,
   16|       |}
   17|       |
   18|       |impl<'txn, K, V, R> LmdbRangeIterator<'txn, K, V, R>
   19|       |where
   20|       |    K: Deserialize<Target = K> + Serialize + Ord,
   21|       |    V: Deserialize<Target = V>,
   22|       |    R: RangeBounds<K>,
   23|       |{
   24|  2.29k|    pub fn new(cursor: RoCursor<'txn>, range: R) -> Self {
   25|  2.29k|        Self {
   26|  2.29k|            cursor,
   27|  2.29k|            range,
   28|  2.29k|            initialized: false,
   29|  2.29k|            empty: false,
   30|  2.29k|            phantom: Default::default(),
   31|  2.29k|        }
   32|  2.29k|    }
   33|       |
   34|      0|    pub fn empty(range: R) -> Self {
   35|      0|        Self {
   36|      0|            cursor: RoCursor::new_null_with(&EMPTY_DATABASE),
   37|      0|            range,
   38|      0|            initialized: false,
   39|      0|            empty: true,
   40|      0|            phantom: Default::default(),
   41|      0|        }
   42|      0|    }
   43|       |
   44|  2.39k|    fn get_next_result(&mut self) -> lmdb::Result<(Option<&'txn [u8]>, &'txn [u8])> {
   45|  2.39k|        if self.empty {
   46|      0|            Err(lmdb::Error::NotFound)
   47|  2.39k|        } else if !self.initialized {
   48|  2.29k|            self.initialized = true;
   49|  2.29k|            self.get_first_result()
   50|       |        } else {
   51|    104|            self.cursor.get(None, None, MDB_NEXT)
   52|       |        }
   53|  2.39k|    }
   54|       |
   55|  2.29k|    fn get_first_result(&self) -> lmdb::Result<(Option<&'txn [u8]>, &'txn [u8])> {
   56|  2.29k|        match self.range.start_bound() {
   57|  2.29k|            Bound::Included(start) => {
   58|  2.29k|                let mut key_bytes = [0u8; 64];
   59|  2.29k|                let mut stream = MutStreamAdapter::new(&mut key_bytes);
   60|  2.29k|                start.serialize(&mut stream);
   61|  2.29k|                self.cursor.get(Some(stream.written()), None, MDB_SET_RANGE)
   62|       |            }
   63|      0|            Bound::Excluded(_) => unimplemented!(),
   64|      0|            Bound::Unbounded => self.cursor.get(None, None, MDB_FIRST),
   65|       |        }
   66|  2.29k|    }
   67|       |
   68|    414|    fn deserialize(&self, key_bytes: Option<&[u8]>, value_bytes: &[u8]) -> (K, V) {
   69|    414|        let mut stream = BufferReader::new(key_bytes.unwrap());
   70|    414|        let key = K::deserialize(&mut stream).unwrap();
   71|    414|        let mut stream = BufferReader::new(value_bytes);
   72|    414|        let value = V::deserialize(&mut stream).unwrap();
   73|    414|        (key, value)
   74|    414|    }
   75|       |
   76|    414|    fn should_include(&self, key: &K) -> bool {
   77|    414|        match self.range.end_bound() {
   78|      0|            Bound::Included(end) => {
   79|      0|                matches!(key.cmp(end), Ordering::Less | Ordering::Equal)
   80|       |            }
   81|    308|            Bound::Excluded(end) => matches!(key.cmp(end), Ordering::Less),
                                                  ^297
   82|    106|            Bound::Unbounded => true,
   83|       |        }
   84|    414|    }
   85|       |}
   86|       |
   87|       |impl<'txn, K, V, R> Iterator for LmdbRangeIterator<'txn, K, V, R>
   88|       |where
   89|       |    K: Deserialize<Target = K> + Serialize + Ord,
   90|       |    V: Deserialize<Target = V>,
   91|       |    R: RangeBounds<K>,
   92|       |{
   93|       |    type Item = (K, V);
   94|       |
   95|  2.39k|    fn next(&mut self) -> Option<Self::Item> {
   96|  2.39k|        match self.get_next_result() {
   97|    414|            Ok((key, value)) => {
   98|    414|                let result = self.deserialize(key, value);
   99|    414|                if self.should_include(&result.0) {
  100|    117|                    Some(result)
  101|       |                } else {
  102|    297|                    None
  103|       |                }
  104|       |            }
  105|  1.98k|            Err(lmdb::Error::NotFound) => None,
  106|      0|            Err(e) => panic!("Could not read from cursor: {:?}", e),
  107|       |        }
  108|  2.39k|    }
  109|       |}
  110|       |
  111|       |pub struct LmdbIterator<'txn, K, V>
  112|       |where
  113|       |    K: Serialize,
  114|       |{
  115|       |    cursor: RoCursor<'txn>,
  116|       |    operation: MDB_cursor_op,
  117|       |    next_op: MDB_cursor_op,
  118|       |    convert: fn(&[u8], &[u8]) -> (K, V),
  119|       |}
  120|       |
  121|       |impl<'txn, K, V> LmdbIterator<'txn, K, V>
  122|       |where
  123|       |    K: Serialize,
  124|       |{
  125|     62|    pub fn new(cursor: RoCursor<'txn>, convert: fn(&[u8], &[u8]) -> (K, V)) -> Self {
  126|     62|        Self {
  127|     62|            cursor,
  128|     62|            operation: MDB_FIRST,
  129|     62|            next_op: MDB_NEXT,
  130|     62|            convert,
  131|     62|        }
  132|     62|    }
  133|       |
  134|      3|    pub fn new_descending(cursor: RoCursor<'txn>, convert: fn(&[u8], &[u8]) -> (K, V)) -> Self {
  135|      3|        Self {
  136|      3|            cursor,
  137|      3|            operation: MDB_LAST,
  138|      3|            next_op: MDB_PREV,
  139|      3|            convert,
  140|      3|        }
  141|      3|    }
  142|       |}
  143|       |
  144|       |impl<'txn, K, V> Iterator for LmdbIterator<'txn, K, V>
  145|       |where
  146|       |    K: Serialize,
  147|       |{
  148|       |    type Item = (K, V);
  149|       |
  150|     88|    fn next(&mut self) -> Option<Self::Item> {
  151|     88|        let result = match self.cursor.get(None, None, self.operation) {
  152|     65|            Err(lmdb::Error::NotFound) => None,
  153|     23|            Ok((Some(k), v)) => Some((self.convert)(k, v)),
  154|      0|            Ok(_) => panic!("No key returned"),
  155|      0|            Err(e) => panic!("Read error {:?}", e),
  156|       |        };
  157|     88|        self.operation = self.next_op;
  158|     88|        result
  159|     88|    }
  160|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/lib.rs:
    1|       |#[macro_use]
    2|       |extern crate num_derive;
    3|       |
    4|       |#[macro_use]
    5|       |extern crate anyhow;
    6|       |
    7|       |mod account_store;
    8|       |mod block_store;
    9|       |mod confirmation_height_store;
   10|       |mod fan;
   11|       |mod final_vote_store;
   12|       |mod iterator;
   13|       |mod lmdb_config;
   14|       |mod lmdb_env;
   15|       |mod online_weight_store;
   16|       |mod peer_store;
   17|       |mod pending_store;
   18|       |mod pruned_store;
   19|       |mod rep_weight_store;
   20|       |mod store;
   21|       |mod version_store;
   22|       |mod wallet_store;
   23|       |
   24|       |pub use account_store::{ConfiguredAccountDatabaseBuilder, LmdbAccountStore};
   25|       |pub use block_store::{ConfiguredBlockDatabaseBuilder, LmdbBlockStore};
   26|       |pub use confirmation_height_store::*;
   27|       |pub use fan::Fan;
   28|       |pub use final_vote_store::LmdbFinalVoteStore;
   29|       |pub use iterator::{LmdbIterator, LmdbRangeIterator};
   30|       |pub use lmdb_config::{LmdbConfig, SyncStrategy};
   31|       |pub use lmdb_env::*;
   32|       |pub use online_weight_store::LmdbOnlineWeightStore;
   33|       |pub use peer_store::*;
   34|       |pub use pending_store::{ConfiguredPendingDatabaseBuilder, LmdbPendingStore};
   35|       |pub use pruned_store::{ConfiguredPrunedDatabaseBuilder, LmdbPrunedStore};
   36|       |pub use rep_weight_store::*;
   37|       |use rsnano_nullable_lmdb::{
   38|       |    InactiveTransaction, LmdbDatabase, LmdbEnvironment, RoCursor, RoTransaction, RwTransaction,
   39|       |};
   40|       |pub use store::{create_backup_file, LedgerCache, LmdbStore};
   41|       |pub use version_store::LmdbVersionStore;
   42|       |pub use wallet_store::{Fans, KeyType, LmdbWalletStore, WalletValue};
   43|       |
   44|       |use primitive_types::U256;
   45|       |use rsnano_core::utils::get_cpu_count;
   46|       |use std::{
   47|       |    any::Any,
   48|       |    cmp::{max, min},
   49|       |    mem,
   50|       |    sync::Arc,
   51|       |    time::{Duration, Instant},
   52|       |};
   53|       |
   54|       |#[cfg(feature = "output_tracking")]
   55|       |use rsnano_output_tracker::{OutputListener, OutputTracker};
   56|       |#[cfg(feature = "output_tracking")]
   57|       |use std::rc::Rc;
   58|       |
   59|       |pub trait Transaction {
   60|       |    fn as_any(&self) -> &dyn Any;
   61|       |    fn refresh(&mut self);
   62|       |    fn refresh_if_needed(&mut self) -> bool;
   63|       |    fn is_refresh_needed(&self) -> bool;
   64|       |    fn is_refresh_needed_with(&self, max_duration: Duration) -> bool;
   65|       |    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]>;
   66|  49.3k|    fn exists(&self, db: LmdbDatabase, key: &[u8]) -> bool {
   67|  49.3k|        match self.get(db, key) {
   68|  16.3k|            Ok(_) => true,
   69|  32.9k|            Err(lmdb::Error::NotFound) => false,
   70|      0|            Err(e) => panic!("exists failed: {:?}", e),
   71|       |        }
   72|  49.3k|    }
   73|       |    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor>;
   74|       |    fn count(&self, database: LmdbDatabase) -> u64;
   75|       |}
   76|       |
   77|       |pub trait TransactionTracker: Send + Sync {
   78|       |    fn txn_start(&self, txn_id: u64, is_write: bool);
   79|       |    fn txn_end(&self, txn_id: u64, is_write: bool);
   80|       |}
   81|       |
   82|       |pub struct NullTransactionTracker {}
   83|       |
   84|       |impl NullTransactionTracker {
   85|     40|    pub fn new() -> Self {
   86|     40|        Self {}
   87|     40|    }
   88|       |}
   89|       |
   90|       |impl TransactionTracker for NullTransactionTracker {
   91|  2.43k|    fn txn_start(&self, _txn_id: u64, _is_write: bool) {}
   92|  2.43k|    fn txn_end(&self, _txn_id: u64, _is_write: bool) {}
   93|       |}
   94|       |
   95|       |enum RoTxnState {
   96|       |    Inactive(InactiveTransaction),
   97|       |    Active(RoTransaction),
   98|       |    Transitioning,
   99|       |}
  100|       |
  101|       |pub struct LmdbReadTransaction {
  102|       |    txn_id: u64,
  103|       |    callbacks: Arc<dyn TransactionTracker>,
  104|       |    txn: RoTxnState,
  105|       |    start: Instant,
  106|       |}
  107|       |
  108|       |impl LmdbReadTransaction {
  109|  2.34k|    pub fn new(
  110|  2.34k|        txn_id: u64,
  111|  2.34k|        env: &LmdbEnvironment,
  112|  2.34k|        callbacks: Arc<dyn TransactionTracker>,
  113|  2.34k|    ) -> lmdb::Result<Self> {
  114|  2.34k|        let txn = env.begin_ro_txn()?;
                                                  ^0
  115|  2.34k|        callbacks.txn_start(txn_id, false);
  116|  2.34k|
  117|  2.34k|        Ok(Self {
  118|  2.34k|            txn_id,
  119|  2.34k|            callbacks,
  120|  2.34k|            txn: RoTxnState::Active(txn),
  121|  2.34k|            start: Instant::now(),
  122|  2.34k|        })
  123|  2.34k|    }
  124|       |
  125|  2.37k|    pub fn txn(&self) -> &RoTransaction {
  126|  2.37k|        match &self.txn {
  127|  2.37k|            RoTxnState::Active(t) => t,
  128|      0|            _ => panic!("LMDB read transaction not active"),
  129|       |        }
  130|  2.37k|    }
  131|       |
  132|      0|    pub fn reset(&mut self) {
  133|      0|        let t = mem::replace(&mut self.txn, RoTxnState::Transitioning);
  134|      0|        self.txn = match t {
  135|      0|            RoTxnState::Active(t) => RoTxnState::Inactive(t.reset()),
  136|      0|            RoTxnState::Inactive(_) => panic!("Cannot reset inactive transaction"),
  137|      0|            RoTxnState::Transitioning => unreachable!(),
  138|       |        };
  139|      0|        self.callbacks.txn_end(self.txn_id, false);
  140|      0|    }
  141|       |
  142|      0|    pub fn renew(&mut self) {
  143|      0|        let t = mem::replace(&mut self.txn, RoTxnState::Transitioning);
  144|      0|        self.txn = match t {
  145|      0|            RoTxnState::Active(_) => panic!("Cannot renew active transaction"),
  146|      0|            RoTxnState::Inactive(t) => RoTxnState::Active(t.renew().unwrap()),
  147|      0|            RoTxnState::Transitioning => unreachable!(),
  148|       |        };
  149|      0|        self.callbacks.txn_start(self.txn_id, false);
  150|      0|        self.start = Instant::now();
  151|      0|    }
  152|       |}
  153|       |
  154|       |impl Drop for LmdbReadTransaction {
  155|  2.34k|    fn drop(&mut self) {
  156|  2.34k|        let t = mem::replace(&mut self.txn, RoTxnState::Transitioning);
  157|       |        // This uses commit rather than abort, as it is needed when opening databases with a read only transaction
  158|  2.34k|        if let RoTxnState::Active(t) = t {
  159|  2.34k|            t.commit().unwrap()
  160|      0|        }
  161|  2.34k|        self.callbacks.txn_end(self.txn_id, false);
  162|  2.34k|    }
  163|       |}
  164|       |
  165|       |impl Transaction for LmdbReadTransaction {
  166|      0|    fn as_any(&self) -> &dyn std::any::Any {
  167|      0|        self
  168|      0|    }
  169|       |
  170|      0|    fn refresh(&mut self) {
  171|      0|        self.reset();
  172|      0|        self.renew();
  173|      0|    }
  174|       |
  175|      0|    fn is_refresh_needed(&self) -> bool {
  176|      0|        self.is_refresh_needed_with(Duration::from_millis(500))
  177|      0|    }
  178|       |
  179|      0|    fn is_refresh_needed_with(&self, max_duration: Duration) -> bool {
  180|      0|        self.start.elapsed() > max_duration
  181|      0|    }
  182|       |
  183|      0|    fn refresh_if_needed(&mut self) -> bool {
  184|      0|        if self.is_refresh_needed() {
  185|      0|            self.refresh();
  186|      0|            true
  187|       |        } else {
  188|      0|            false
  189|       |        }
  190|      0|    }
  191|       |
  192|     36|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
  193|     36|        self.txn().get(database, key)
  194|     36|    }
  195|       |
  196|  2.30k|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
  197|  2.30k|        self.txn().open_ro_cursor(database)
  198|  2.30k|    }
  199|       |
  200|     30|    fn count(&self, database: LmdbDatabase) -> u64 {
  201|     30|        self.txn().count(database)
  202|     30|    }
  203|       |}
  204|       |
  205|       |enum RwTxnState {
  206|       |    Inactive,
  207|       |    Active(RwTransaction),
  208|       |    Transitioning,
  209|       |}
  210|       |
  211|       |#[cfg(feature = "output_tracking")]
  212|       |#[derive(Clone, Debug, PartialEq)]
  213|       |pub struct PutEvent {
  214|       |    database: LmdbDatabase,
  215|       |    key: Vec<u8>,
  216|       |    value: Vec<u8>,
  217|       |    flags: lmdb::WriteFlags,
  218|       |}
  219|       |
  220|       |#[cfg(feature = "output_tracking")]
  221|       |#[derive(Clone, Debug, PartialEq)]
  222|       |pub struct DeleteEvent {
  223|       |    database: LmdbDatabase,
  224|       |    key: Vec<u8>,
  225|       |}
  226|       |
  227|       |pub struct LmdbWriteTransaction {
  228|       |    env: &'static LmdbEnvironment,
  229|       |    txn_id: u64,
  230|       |    callbacks: Arc<dyn TransactionTracker>,
  231|       |    txn: RwTxnState,
  232|       |    #[cfg(feature = "output_tracking")]
  233|       |    put_listener: OutputListener<PutEvent>,
  234|       |    #[cfg(feature = "output_tracking")]
  235|       |    delete_listener: OutputListener<DeleteEvent>,
  236|       |    #[cfg(feature = "output_tracking")]
  237|       |    clear_listener: OutputListener<LmdbDatabase>,
  238|       |    start: Instant,
  239|       |}
  240|       |
  241|       |impl LmdbWriteTransaction {
  242|     85|    pub fn new<'a>(
  243|     85|        txn_id: u64,
  244|     85|        env: &'a LmdbEnvironment,
  245|     85|        callbacks: Arc<dyn TransactionTracker>,
  246|     85|    ) -> lmdb::Result<Self> {
  247|     85|        let env =
  248|     85|            unsafe { std::mem::transmute::<&'a LmdbEnvironment, &'static LmdbEnvironment>(env) };
  249|     85|        let mut tx = Self {
  250|     85|            env,
  251|     85|            txn_id,
  252|     85|            callbacks,
  253|     85|            txn: RwTxnState::Inactive,
  254|     85|            #[cfg(feature = "output_tracking")]
  255|     85|            put_listener: OutputListener::new(),
  256|     85|            #[cfg(feature = "output_tracking")]
  257|     85|            delete_listener: OutputListener::new(),
  258|     85|            #[cfg(feature = "output_tracking")]
  259|     85|            clear_listener: OutputListener::new(),
  260|     85|            start: Instant::now(),
  261|     85|        };
  262|     85|        tx.renew();
  263|     85|        Ok(tx)
  264|     85|    }
  265|       |
  266|   164k|    pub fn rw_txn(&self) -> &RwTransaction {
  267|   164k|        match &self.txn {
  268|   164k|            RwTxnState::Active(t) => t,
  269|      0|            _ => panic!("txn not active"),
  270|       |        }
  271|   164k|    }
  272|       |
  273|  16.6k|    pub fn rw_txn_mut(&mut self) -> &mut RwTransaction {
  274|  16.6k|        match &mut self.txn {
  275|  16.6k|            RwTxnState::Active(t) => t,
  276|      0|            _ => panic!("txn not active"),
  277|       |        }
  278|  16.6k|    }
  279|       |
  280|  16.3k|    pub fn elapsed(&self) -> Duration {
  281|  16.3k|        self.start.elapsed()
  282|  16.3k|    }
  283|       |
  284|     91|    pub fn renew(&mut self) {
  285|     91|        let t = mem::replace(&mut self.txn, RwTxnState::Transitioning);
  286|     91|        self.txn = match t {
  287|      0|            RwTxnState::Active(_) => panic!("Cannot renew active RwTransaction"),
  288|     91|            RwTxnState::Inactive => RwTxnState::Active(self.env.begin_rw_txn().unwrap()),
  289|      0|            RwTxnState::Transitioning => unreachable!(),
  290|       |        };
  291|     91|        self.callbacks.txn_start(self.txn_id, true);
  292|     91|        self.start = Instant::now();
  293|     91|    }
  294|       |
  295|     91|    pub fn commit(&mut self) {
  296|     91|        let t = mem::replace(&mut self.txn, RwTxnState::Transitioning);
  297|     91|        match t {
  298|      0|            RwTxnState::Inactive => {}
  299|     91|            RwTxnState::Active(t) => {
  300|     91|                t.commit().unwrap();
  301|     91|                self.callbacks.txn_end(self.txn_id, true);
  302|     91|            }
  303|      0|            RwTxnState::Transitioning => unreachable!(),
  304|       |        };
  305|     91|        self.txn = RwTxnState::Inactive;
  306|     91|    }
  307|       |
  308|       |    #[cfg(feature = "output_tracking")]
  309|       |    pub fn track_puts(&self) -> Rc<OutputTracker<PutEvent>> {
  310|       |        self.put_listener.track()
  311|       |    }
  312|       |
  313|       |    #[cfg(feature = "output_tracking")]
  314|       |    pub fn track_deletions(&self) -> Rc<OutputTracker<DeleteEvent>> {
  315|       |        self.delete_listener.track()
  316|       |    }
  317|       |
  318|       |    #[cfg(feature = "output_tracking")]
  319|       |    pub fn track_clears(&self) -> Rc<OutputTracker<LmdbDatabase>> {
  320|       |        self.clear_listener.track()
  321|       |    }
  322|       |
  323|      0|    pub unsafe fn create_db(
  324|      0|        &mut self,
  325|      0|        name: Option<&str>,
  326|      0|        flags: lmdb::DatabaseFlags,
  327|      0|    ) -> lmdb::Result<LmdbDatabase> {
  328|      0|        self.rw_txn().create_db(name, flags)
  329|      0|    }
  330|       |
  331|  16.6k|    pub fn put(
  332|  16.6k|        &mut self,
  333|  16.6k|        database: LmdbDatabase,
  334|  16.6k|        key: &[u8],
  335|  16.6k|        value: &[u8],
  336|  16.6k|        flags: lmdb::WriteFlags,
  337|  16.6k|    ) -> lmdb::Result<()> {
  338|  16.6k|        #[cfg(feature = "output_tracking")]
  339|  16.6k|        self.put_listener.emit(PutEvent {
  340|  16.6k|            database,
  341|  16.6k|            key: key.to_vec(),
  342|  16.6k|            value: value.to_vec(),
  343|  16.6k|            flags,
  344|  16.6k|        });
  345|  16.6k|        self.rw_txn_mut().put(database, key, value, flags)
  346|  16.6k|    }
  347|       |
  348|      6|    pub fn delete(
  349|      6|        &mut self,
  350|      6|        database: LmdbDatabase,
  351|      6|        key: &[u8],
  352|      6|        flags: Option<&[u8]>,
  353|      6|    ) -> lmdb::Result<()> {
  354|      6|        #[cfg(feature = "output_tracking")]
  355|      6|        self.delete_listener.emit(DeleteEvent {
  356|      6|            database,
  357|      6|            key: key.to_vec(),
  358|      6|        });
  359|      6|        self.rw_txn_mut().del(database, key, flags)
  360|      6|    }
  361|       |
  362|      0|    pub fn clear_db(&mut self, database: LmdbDatabase) -> lmdb::Result<()> {
  363|      0|        #[cfg(feature = "output_tracking")]
  364|      0|        self.clear_listener.emit(database);
  365|      0|        self.rw_txn_mut().clear_db(database)
  366|      0|    }
  367|       |}
  368|       |
  369|       |impl Drop for LmdbWriteTransaction {
  370|     85|    fn drop(&mut self) {
  371|     85|        self.commit();
  372|     85|    }
  373|       |}
  374|       |
  375|       |impl Transaction for LmdbWriteTransaction {
  376|      0|    fn as_any(&self) -> &dyn std::any::Any {
  377|      0|        self
  378|      0|    }
  379|       |
  380|      2|    fn refresh(&mut self) {
  381|      2|        self.commit();
  382|      2|        self.renew();
  383|      2|    }
  384|       |
  385|   164k|    fn get(&self, database: LmdbDatabase, key: &[u8]) -> lmdb::Result<&[u8]> {
  386|   164k|        self.rw_txn().get(database, key)
  387|   164k|    }
  388|       |
  389|     55|    fn open_ro_cursor(&self, database: LmdbDatabase) -> lmdb::Result<RoCursor> {
  390|     55|        self.rw_txn().open_ro_cursor(database)
  391|     55|    }
  392|       |
  393|      0|    fn count(&self, database: LmdbDatabase) -> u64 {
  394|      0|        self.rw_txn().count(database)
  395|      0|    }
  396|       |
  397|  16.3k|    fn is_refresh_needed(&self) -> bool {
  398|  16.3k|        self.is_refresh_needed_with(Duration::from_millis(500))
  399|  16.3k|    }
  400|       |
  401|  16.3k|    fn is_refresh_needed_with(&self, max_duration: Duration) -> bool {
  402|  16.3k|        self.start.elapsed() > max_duration
  403|  16.3k|    }
  404|  16.3k|    fn refresh_if_needed(&mut self) -> bool {
  405|  16.3k|        if self.is_refresh_needed() {
  406|      2|            self.refresh();
  407|      2|            true
  408|       |        } else {
  409|  16.3k|            false
  410|       |        }
  411|  16.3k|    }
  412|       |}
  413|       |
  414|     54|pub fn parallel_traversal(action: &(impl Fn(U256, U256, bool) + Send + Sync)) {
  415|     54|    // Between 10 and 40 threads, scales well even in low power systems as long as actions are I/O bound
  416|     54|    let thread_count = max(10, min(40, 11 * get_cpu_count()));
  417|     54|    let split = U256::max_value() / thread_count;
  418|     54|
  419|     54|    std::thread::scope(|s| {
  420|  2.16k|        for thread in 0..thread_count {
                                       ^54
  421|  2.16k|            let start = split * thread;
  422|  2.16k|            let end = split * (thread + 1);
  423|  2.16k|            let is_last = thread == thread_count - 1;
  424|  2.16k|
  425|  2.16k|            std::thread::Builder::new()
  426|  2.16k|                .name("DB par traversl".to_owned())
  427|  2.16k|                .spawn_scoped(s, move || {
  428|  2.16k|                    action(start, end, is_last);
  429|  2.16k|                })
  430|  2.16k|                .unwrap();
  431|  2.16k|        }
  432|     54|    });
  433|     54|}
  434|       |
  435|       |pub const STORE_VERSION_MINIMUM: i32 = 24;
  436|       |pub const STORE_VERSION_CURRENT: i32 = 24;
  437|       |
  438|       |pub const BLOCK_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(1);
  439|       |pub const FRONTIER_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(2);
  440|       |pub const ACCOUNT_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(3);
  441|       |pub const PENDING_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(4);
  442|       |pub const PRUNED_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(5);
  443|       |pub const REP_WEIGHT_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(6);
  444|       |pub const CONFIRMATION_HEIGHT_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(7);
  445|       |pub const PEERS_TEST_DATABASE: LmdbDatabase = LmdbDatabase::new_null(8);
  446|       |
  447|       |#[cfg(test)]
  448|       |mod test {
  449|       |    use super::*;
  450|       |
  451|       |    #[test]
  452|       |    fn tracks_deletes() {
  453|       |        let env = LmdbEnv::new_null();
  454|       |        let mut txn = env.tx_begin_write();
  455|       |        let delete_tracker = txn.track_deletions();
  456|       |
  457|       |        let database = LmdbDatabase::new_null(42);
  458|       |        let key = vec![1, 2, 3];
  459|       |        txn.delete(database, &key, None).unwrap();
  460|       |
  461|       |        assert_eq!(delete_tracker.output(), vec![DeleteEvent { database, key }])
  462|       |    }
  463|       |
  464|       |    #[test]
  465|       |    fn tracks_clears() {
  466|       |        let env = LmdbEnv::new_null();
  467|       |        let mut txn = env.tx_begin_write();
  468|       |        let clear_tracker = txn.track_clears();
  469|       |
  470|       |        let database = LmdbDatabase::new_null(42);
  471|       |        txn.clear_db(database).unwrap();
  472|       |
  473|       |        assert_eq!(clear_tracker.output(), vec![database])
  474|       |    }
  475|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/lmdb_config.rs:
    1|       |#[derive(PartialEq, Eq, Clone, Copy, Debug)]
    2|       |pub enum SyncStrategy {
    3|       |    /** Always flush to disk on commit. This is default. */
    4|       |    Always,
    5|       |    /** Do not flush meta data eagerly. This may cause loss of transactions, but maintains integrity. */
    6|       |    NosyncSafe,
    7|       |
    8|       |    /**
    9|       |     * Let the OS decide when to flush to disk. On filesystems with write ordering, this has the same
   10|       |     * guarantees as nosync_safe, otherwise corruption may occur on system crash.
   11|       |     */
   12|       |    NosyncUnsafe,
   13|       |    /**
   14|       |     * Use a writeable memory map. Let the OS decide when to flush to disk, and make the request asynchronous.
   15|       |     * This may give better performance on systems where the database fits entirely in memory, otherwise is
   16|       |     * may be slower.
   17|       |     * @warning Do not use this option if external processes uses the database concurrently.
   18|       |     */
   19|       |    NosyncUnsafeLargeMemory,
   20|       |}
   21|       |
   22|       |#[derive(Clone, Debug, PartialEq)]
   23|       |pub struct LmdbConfig {
   24|       |    pub sync: SyncStrategy,
   25|       |    pub max_databases: u32,
   26|       |    pub map_size: usize,
   27|       |}
   28|       |
   29|       |impl Default for LmdbConfig {
   30|     25|    fn default() -> Self {
   31|     25|        Self {
   32|     25|            sync: SyncStrategy::Always,
   33|     25|            max_databases: 128,
   34|     25|            map_size: 256 * 1024 * 1024 * 1024,
   35|     25|        }
   36|     25|    }
   37|       |}
   38|       |
   39|       |impl LmdbConfig {
   40|      9|    pub fn new() -> Self {
   41|      9|        Default::default()
   42|      9|    }
   43|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/lmdb_env.rs:
    1|       |use crate::{
    2|       |    LmdbConfig, LmdbReadTransaction, LmdbWriteTransaction, NullTransactionTracker, SyncStrategy,
    3|       |    TransactionTracker,
    4|       |};
    5|       |use anyhow::bail;
    6|       |use lmdb::EnvironmentFlags;
    7|       |use lmdb_sys::MDB_SUCCESS;
    8|       |use rsnano_core::utils::memory_intensive_instrumentation;
    9|       |use rsnano_nullable_lmdb::{
   10|       |    ConfiguredDatabase, ConfiguredDatabaseBuilder, EnvironmentOptions, EnvironmentStubBuilder,
   11|       |    LmdbDatabase, LmdbEnvironment,
   12|       |};
   13|       |use std::{
   14|       |    ffi::{c_char, CStr, OsStr},
   15|       |    fs::{create_dir_all, set_permissions, Permissions},
   16|       |    ops::Deref,
   17|       |    os::unix::prelude::PermissionsExt,
   18|       |    path::{Path, PathBuf},
   19|       |    sync::{
   20|       |        atomic::{AtomicU64, AtomicUsize, Ordering},
   21|       |        Arc,
   22|       |    },
   23|       |};
   24|       |use tracing::debug;
   25|       |
   26|       |#[derive(Default, Debug)]
   27|       |pub struct EnvOptions {
   28|       |    pub config: LmdbConfig,
   29|       |    pub use_no_mem_init: bool,
   30|       |}
   31|       |
   32|       |pub struct NullLmdbEnvBuilder {
   33|       |    env_builder: EnvironmentStubBuilder,
   34|       |}
   35|       |
   36|       |impl NullLmdbEnvBuilder {
   37|      0|    pub fn database(self, name: impl Into<String>, dbi: LmdbDatabase) -> NullDatabaseBuilder {
   38|      0|        NullDatabaseBuilder {
   39|      0|            db_builder: ConfiguredDatabaseBuilder::new(name, dbi, self.env_builder),
   40|      0|        }
   41|      0|    }
   42|       |
   43|    120|    pub fn configured_database(mut self, db: ConfiguredDatabase) -> Self {
   44|    120|        self.env_builder = self.env_builder.configured_database(db);
   45|    120|        self
   46|    120|    }
   47|       |
   48|     20|    pub fn build(self) -> LmdbEnv {
   49|     20|        let env = self.env_builder.finish();
   50|     20|        LmdbEnv::new_with_env(env)
   51|     20|    }
   52|       |}
   53|       |
   54|       |pub struct NullDatabaseBuilder {
   55|       |    db_builder: ConfiguredDatabaseBuilder,
   56|       |}
   57|       |
   58|       |impl NullDatabaseBuilder {
   59|      0|    pub fn entry(mut self, key: &[u8], value: &[u8]) -> Self {
   60|      0|        self.db_builder = self.db_builder.entry(key, value);
   61|      0|        self
   62|      0|    }
   63|       |
   64|      0|    pub fn build(self) -> NullLmdbEnvBuilder {
   65|      0|        NullLmdbEnvBuilder {
   66|      0|            env_builder: self.db_builder.finish(),
   67|      0|        }
   68|      0|    }
   69|       |}
   70|       |
   71|       |pub struct LmdbEnv {
   72|       |    pub environment: LmdbEnvironment,
   73|       |    next_txn_id: AtomicU64,
   74|       |    txn_tracker: Arc<dyn TransactionTracker>,
   75|       |    env_id: usize,
   76|       |}
   77|       |
   78|       |static ENV_COUNT: AtomicUsize = AtomicUsize::new(0);
   79|       |static NEXT_ENV_ID: AtomicUsize = AtomicUsize::new(0);
   80|       |
   81|       |impl LmdbEnv {
   82|      2|    pub fn new_null() -> Self {
   83|      2|        Self::new_with_env(LmdbEnvironment::new_null())
   84|      2|    }
   85|       |
   86|     20|    pub fn new_null_with() -> NullLmdbEnvBuilder {
   87|     20|        NullLmdbEnvBuilder {
   88|     20|            env_builder: EnvironmentStubBuilder::default(),
   89|     20|        }
   90|     20|    }
   91|       |
   92|     10|    pub fn new(path: impl AsRef<Path>) -> anyhow::Result<Self> {
   93|     10|        Self::new_with_options(path, &EnvOptions::default())
   94|     10|    }
   95|       |
   96|     13|    pub fn new_with_options(path: impl AsRef<Path>, options: &EnvOptions) -> anyhow::Result<Self> {
   97|     13|        let environment = Self::init(path.as_ref(), options)?;
                                                                          ^0
   98|     13|        Ok(Self::new_with_env(environment))
   99|     13|    }
  100|       |
  101|     35|    pub fn new_with_env(env: LmdbEnvironment) -> Self {
  102|     35|        let env_id = NEXT_ENV_ID.fetch_add(1, Ordering::SeqCst);
  103|     35|        let alive = ENV_COUNT.fetch_add(1, Ordering::SeqCst) + 1;
  104|     35|        debug!(env_id, alive, "LMDB env created",);
                                            ^0
  105|     35|        Self {
  106|     35|            environment: env,
  107|     35|            next_txn_id: AtomicU64::new(0),
  108|     35|            txn_tracker: Arc::new(NullTransactionTracker::new()),
  109|     35|            env_id,
  110|     35|        }
  111|     35|    }
  112|       |
  113|      5|    pub fn new_with_txn_tracker(
  114|      5|        path: &Path,
  115|      5|        options: &EnvOptions,
  116|      5|        txn_tracker: Arc<dyn TransactionTracker>,
  117|      5|    ) -> anyhow::Result<Self> {
  118|      5|        let env = Self {
  119|      5|            environment: Self::init(path, options)?,
                                                                ^0
  120|      5|            next_txn_id: AtomicU64::new(0),
  121|      5|            txn_tracker,
  122|      5|            env_id: NEXT_ENV_ID.fetch_add(1, Ordering::SeqCst),
  123|      5|        };
  124|      5|        let alive = ENV_COUNT.fetch_add(1, Ordering::SeqCst) + 1;
  125|      5|        debug!(env_id = env.env_id, alive, ?path, "LMDB env created",);
                                                                ^0
  126|      5|        Ok(env)
  127|      5|    }
  128|       |
  129|     18|    pub fn init(path: impl AsRef<Path>, options: &EnvOptions) -> anyhow::Result<LmdbEnvironment> {
  130|     18|        let path = path.as_ref();
  131|     18|        debug_assert!(
  132|     18|            path.extension() == Some(&OsStr::new("ldb")),
  133|      0|            "invalid filename extension for lmdb database file"
  134|       |        );
  135|     18|        try_create_parent_dir(path)?;
                                                 ^0
  136|     18|        let mut map_size = options.config.map_size;
  137|     18|        let max_instrumented_map_size = 16 * 1024 * 1024;
  138|     18|        if memory_intensive_instrumentation() && map_size > max_instrumented_map_size {
                                                               ^0
  139|      0|            // In order to run LMDB under Valgrind, the maximum map size must be smaller than half your available RAM
  140|      0|            map_size = max_instrumented_map_size;
  141|     18|        }
  142|       |
  143|       |        // It seems if there's ever more threads than mdb_env_set_maxreaders has read slots available, we get failures on transaction creation unless MDB_NOTLS is specified
  144|       |        // This can happen if something like 256 io_threads are specified in the node config
  145|       |        // MDB_NORDAHEAD will allow platforms that support it to load the DB in memory as needed.
  146|       |        // MDB_NOMEMINIT prevents zeroing malloc'ed pages. Can provide improvement for non-sensitive data but may make memory checkers noisy (e.g valgrind).
  147|     18|        let mut environment_flags = EnvironmentFlags::NO_SUB_DIR
  148|     18|            | EnvironmentFlags::NO_TLS
  149|     18|            | EnvironmentFlags::NO_READAHEAD;
  150|     18|        if options.config.sync == SyncStrategy::NosyncSafe {
  151|      0|            environment_flags |= EnvironmentFlags::NO_META_SYNC;
  152|     18|        } else if options.config.sync == SyncStrategy::NosyncUnsafe {
  153|      0|            environment_flags |= EnvironmentFlags::NO_SYNC;
  154|     18|        } else if options.config.sync == SyncStrategy::NosyncUnsafeLargeMemory {
  155|      0|            environment_flags |= EnvironmentFlags::NO_SYNC
  156|      0|                | EnvironmentFlags::WRITE_MAP
  157|      0|                | EnvironmentFlags::MAP_ASYNC;
  158|     18|        }
  159|       |
  160|     18|        if !memory_intensive_instrumentation() && options.use_no_mem_init {
  161|      3|            environment_flags |= EnvironmentFlags::NO_MEM_INIT;
  162|     15|        }
  163|     18|        let env_options = EnvironmentOptions {
  164|     18|            max_dbs: options.config.max_databases,
  165|     18|            map_size,
  166|     18|            flags: environment_flags,
  167|     18|            path,
  168|     18|            file_mode: 0o600,
  169|     18|        };
  170|     18|        let env = LmdbEnvironment::new(env_options)?;
                                                                 ^0
  171|     18|        Ok(env)
  172|     18|    }
  173|       |
  174|  2.34k|    pub fn tx_begin_read(&self) -> LmdbReadTransaction {
  175|  2.34k|        let txn_id = self.next_txn_id.fetch_add(1, Ordering::Relaxed);
  176|  2.34k|        LmdbReadTransaction::new(txn_id, &self.environment, self.create_txn_callbacks())
  177|  2.34k|            .expect("Could not create LMDB read-only transaction")
  178|  2.34k|    }
  179|       |
  180|     85|    pub fn tx_begin_write(&self) -> LmdbWriteTransaction {
  181|     85|        // For IO threads, we do not want them to block on creating write transactions.
  182|     85|        debug_assert!(std::thread::current().name() != Some("I/O"));
  183|     85|        let txn_id = self.next_txn_id.fetch_add(1, Ordering::Relaxed);
  184|     85|        LmdbWriteTransaction::new(txn_id, &self.environment, self.create_txn_callbacks())
  185|     85|            .expect("Could not create LMDB read-write transaction")
  186|     85|    }
  187|       |
  188|      0|    pub fn file_path(&self) -> anyhow::Result<PathBuf> {
  189|      0|        let mut path: *const c_char = std::ptr::null();
  190|      0|        let status = unsafe { lmdb_sys::mdb_env_get_path(self.environment.env(), &mut path) };
  191|      0|        if status != MDB_SUCCESS {
  192|      0|            bail!("could not get env path");
  193|      0|        }
  194|      0|        let source_path: PathBuf = unsafe { CStr::from_ptr(path) }.to_str()?.into();
  195|      0|        Ok(source_path)
  196|      0|    }
  197|       |
  198|  2.43k|    fn create_txn_callbacks(&self) -> Arc<dyn TransactionTracker> {
  199|  2.43k|        Arc::clone(&self.txn_tracker)
  200|  2.43k|    }
  201|       |}
  202|       |
  203|     18|fn try_create_parent_dir(path: &Path) -> std::io::Result<()> {
  204|     18|    if let Some(parent) = path.parent() {
  205|     18|        if parent != Path::new("") && !parent.is_dir() {
  206|      0|            create_dir_all(parent)?;
  207|      0|            set_permissions(parent, Permissions::from_mode(0o700))?;
  208|     18|        }
  209|      0|    }
  210|     18|    Ok(())
  211|     18|}
  212|       |
  213|       |impl Drop for LmdbEnv {
  214|     40|    fn drop(&mut self) {
  215|     40|        let alive = ENV_COUNT.fetch_sub(1, Ordering::Relaxed) - 1;
  216|     40|        debug!(env_id = self.env_id, alive, "LMDB env dropped",);
                                                          ^0
  217|     40|        let _ = self.environment.sync(true);
  218|     40|    }
  219|       |}
  220|       |
  221|       |pub struct TestDbFile {
  222|       |    pub path: PathBuf,
  223|       |}
  224|       |
  225|       |impl TestDbFile {
  226|      2|    fn new(path: impl AsRef<Path>) -> Self {
  227|      2|        Self {
  228|      2|            path: Path::new("/tmp").join(path),
  229|      2|        }
  230|      2|    }
  231|       |
  232|      2|    pub fn random() -> Self {
  233|      2|        Self::new(Self::temp_file_name())
  234|      2|    }
  235|       |
  236|      2|    fn temp_file_name() -> PathBuf {
  237|      2|        PathBuf::from(format!("{}.ldb", uuid::Uuid::new_v4().simple()))
  238|      2|    }
  239|       |
  240|      2|    fn lock_file_path(&self) -> PathBuf {
  241|      2|        let mut lock_file_path = self.path.parent().unwrap().to_owned();
  242|      2|        let mut fname = self.path.file_name().unwrap().to_os_string();
  243|      2|        fname.push("-lock");
  244|      2|        lock_file_path.push(fname);
  245|      2|        lock_file_path
  246|      2|    }
  247|       |}
  248|       |
  249|       |impl Drop for TestDbFile {
  250|      2|    fn drop(&mut self) {
  251|      2|        if self.path.exists() {
  252|      2|            std::fs::remove_file(&self.path).unwrap();
  253|      2|            let lock_file = self.lock_file_path();
  254|      2|            if lock_file.exists() {
  255|      2|                std::fs::remove_file(&lock_file).unwrap();
  256|      2|            }
                           ^0
  257|       |
  258|      2|            if let Some(parent) = self.path.parent() {
  259|      2|                if parent != Path::new("/tmp") {
  260|      0|                    std::fs::remove_dir(parent).unwrap();
  261|      2|                }
  262|      0|            }
  263|      0|        }
  264|      2|    }
  265|       |}
  266|       |
  267|       |pub struct TestLmdbEnv {
  268|       |    env: Arc<LmdbEnv>,
  269|       |    _file: TestDbFile,
  270|       |}
  271|       |
  272|       |impl TestLmdbEnv {
  273|      0|    pub fn new() -> Self {
  274|      0|        let file = TestDbFile::random();
  275|      0|        let env = Arc::new(LmdbEnv::new(&file.path).unwrap());
  276|      0|        Self { _file: file, env }
  277|      0|    }
  278|       |
  279|      0|    pub fn env(&self) -> Arc<LmdbEnv> {
  280|      0|        self.env.clone()
  281|      0|    }
  282|       |}
  283|       |
  284|       |impl Deref for TestLmdbEnv {
  285|       |    type Target = LmdbEnv;
  286|       |
  287|      0|    fn deref(&self) -> &Self::Target {
  288|      0|        &self.env
  289|      0|    }
  290|       |}
  291|       |
  292|       |#[cfg(test)]
  293|       |mod tests {
  294|       |    use super::*;
  295|       |
  296|       |    mod rw_txn {
  297|       |        use super::*;
  298|       |        use crate::PutEvent;
  299|       |        use lmdb::WriteFlags;
  300|       |
  301|       |        #[test]
  302|       |        fn can_track_puts() {
  303|       |            let env = LmdbEnv::new_null();
  304|       |            let mut txn = env.tx_begin_write();
  305|       |            let tracker = txn.track_puts();
  306|       |
  307|       |            let database = LmdbDatabase::new_null(42);
  308|       |            let key = &[1, 2, 3];
  309|       |            let value = &[4, 5, 6];
  310|       |            let flags = WriteFlags::APPEND;
  311|       |            txn.put(database, key, value, flags).unwrap();
  312|       |
  313|       |            let puts = tracker.output();
  314|       |            assert_eq!(
  315|       |                puts,
  316|       |                vec![PutEvent {
  317|       |                    database,
  318|       |                    key: key.to_vec(),
  319|       |                    value: value.to_vec(),
  320|       |                    flags
  321|       |                }]
  322|       |            )
  323|       |        }
  324|       |    }
  325|       |
  326|       |    mod test_db_file {
  327|       |        use super::*;
  328|       |
  329|       |        #[test]
  330|       |        fn tmp_test() {
  331|       |            let path = Path::new("foo.tmp");
  332|       |            assert_eq!(path.parent(), Some(Path::new("")));
  333|       |            assert_eq!(Path::new(""), Path::new(""))
  334|       |        }
  335|       |
  336|       |        #[test]
  337|       |        fn dont_panic_when_file_not_found() {
  338|       |            let file = TestDbFile::new("does-not-exist.ldb");
  339|       |            drop(file)
  340|       |        }
  341|       |
  342|       |        #[test]
  343|       |        fn delete_file_when_dropped() {
  344|       |            let file = TestDbFile::new("drop-test.ldb");
  345|       |            let mut lock_file_path = file.path.parent().unwrap().to_owned();
  346|       |            lock_file_path.push("drop-test.ldb-lock");
  347|       |            std::fs::write(&file.path, "foo").unwrap();
  348|       |            std::fs::write(&lock_file_path, "foo").unwrap();
  349|       |            let path = file.path.clone();
  350|       |            drop(file);
  351|       |            assert_eq!(path.exists(), false, "db file was not deleted");
  352|       |            assert_eq!(lock_file_path.exists(), false, "lock file was not deleted");
  353|       |        }
  354|       |
  355|       |        #[test]
  356|       |        fn delete_dir_when_dropped() {
  357|       |            let file = TestDbFile::new("drop-dir/db.ldb");
  358|       |            std::fs::create_dir(file.path.parent().unwrap()).unwrap();
  359|       |            std::fs::write(&file.path, "foo").unwrap();
  360|       |            let path = file.path.clone();
  361|       |            drop(file);
  362|       |            assert_eq!(path.exists(), false);
  363|       |            assert_eq!(path.parent().unwrap().exists(), false);
  364|       |        }
  365|       |
  366|       |        #[test]
  367|       |        fn tmp_file_name() {
  368|       |            let filename = TestDbFile::temp_file_name();
  369|       |            assert_eq!(filename.extension().unwrap(), "ldb");
  370|       |            assert_eq!(filename.file_stem().unwrap().len(), 32);
  371|       |            assert_ne!(TestDbFile::temp_file_name(), TestDbFile::temp_file_name());
  372|       |        }
  373|       |    }
  374|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/online_weight_store.rs:
    1|       |use crate::{LmdbDatabase, LmdbEnv, LmdbIterator, LmdbWriteTransaction, Transaction};
    2|       |use lmdb::{DatabaseFlags, WriteFlags};
    3|       |use rsnano_core::Amount;
    4|       |use std::sync::Arc;
    5|       |
    6|       |pub struct LmdbOnlineWeightStore {
    7|       |    _env: Arc<LmdbEnv>,
    8|       |    database: LmdbDatabase,
    9|       |}
   10|       |
   11|       |impl LmdbOnlineWeightStore {
   12|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   13|     27|        let database = env
   14|     27|            .environment
   15|     27|            .create_db(Some("online_weight"), DatabaseFlags::empty())?;
                                                                                   ^0
   16|     27|        Ok(Self {
   17|     27|            _env: env,
   18|     27|            database,
   19|     27|        })
   20|     27|    }
   21|       |
   22|      0|    pub fn database(&self) -> LmdbDatabase {
   23|      0|        self.database
   24|      0|    }
   25|       |
   26|      0|    pub fn put(&self, txn: &mut LmdbWriteTransaction, time: u64, amount: &Amount) {
   27|      0|        let time_bytes = time.to_be_bytes();
   28|      0|        let amount_bytes = amount.to_be_bytes();
   29|      0|        txn.put(
   30|      0|            self.database,
   31|      0|            &time_bytes,
   32|      0|            &amount_bytes,
   33|      0|            WriteFlags::empty(),
   34|      0|        )
   35|      0|        .unwrap();
   36|      0|    }
   37|       |
   38|      0|    pub fn del(&self, txn: &mut LmdbWriteTransaction, time: u64) {
   39|      0|        let time_bytes = time.to_be_bytes();
   40|      0|        txn.delete(self.database, &time_bytes, None).unwrap();
   41|      0|    }
   42|       |
   43|      6|    pub fn iter<'txn>(
   44|      6|        &self,
   45|      6|        tx: &'txn dyn Transaction,
   46|      6|    ) -> impl Iterator<Item = (u64, Amount)> + 'txn {
   47|      6|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   48|      6|
   49|      6|        LmdbIterator::new(cursor, |key, value| {
   50|      0|            let time = u64::from_be_bytes(key.try_into().unwrap());
   51|      0|            let amount = Amount::from_be_bytes(value.try_into().unwrap());
   52|      0|            (time, amount)
   53|      6|        })
   54|      6|    }
   55|       |
   56|       |    /// Iterate in descending order
   57|      3|    pub fn iter_rev<'txn>(
   58|      3|        &self,
   59|      3|        tx: &'txn dyn Transaction,
   60|      3|    ) -> impl Iterator<Item = (u64, Amount)> + 'txn {
   61|      3|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   62|      3|
   63|      3|        LmdbIterator::new_descending(cursor, |key, value| {
   64|      0|            let time = u64::from_be_bytes(key.try_into().unwrap());
   65|      0|            let amount = Amount::from_be_bytes(value.try_into().unwrap());
   66|      0|            (time, amount)
   67|      3|        })
   68|      3|    }
   69|       |
   70|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
   71|      0|        txn.count(self.database)
   72|      0|    }
   73|       |
   74|      0|    pub fn clear(&self, txn: &mut LmdbWriteTransaction) {
   75|      0|        txn.clear_db(self.database).unwrap();
   76|      0|    }
   77|       |}
   78|       |
   79|       |#[cfg(test)]
   80|       |mod tests {
   81|       |    use super::*;
   82|       |    use crate::{DeleteEvent, PutEvent};
   83|       |
   84|       |    struct Fixture {
   85|       |        env: Arc<LmdbEnv>,
   86|       |        store: LmdbOnlineWeightStore,
   87|       |    }
   88|       |
   89|       |    impl Fixture {
   90|       |        fn new() -> Self {
   91|       |            Self::with_stored_data(Vec::new())
   92|       |        }
   93|       |
   94|       |        fn with_stored_data(entries: Vec<(u64, Amount)>) -> Self {
   95|       |            let mut env =
   96|       |                LmdbEnv::new_null_with().database("online_weight", LmdbDatabase::new_null(42));
   97|       |
   98|       |            for (key, value) in entries {
   99|       |                env = env.entry(&key.to_be_bytes(), &value.to_be_bytes())
  100|       |            }
  101|       |
  102|       |            Self::with_env(env.build().build())
  103|       |        }
  104|       |
  105|       |        fn with_env(env: LmdbEnv) -> Self {
  106|       |            let env = Arc::new(env);
  107|       |            Self {
  108|       |                env: env.clone(),
  109|       |                store: LmdbOnlineWeightStore::new(env).unwrap(),
  110|       |            }
  111|       |        }
  112|       |    }
  113|       |
  114|       |    #[test]
  115|       |    fn empty_store() {
  116|       |        let fixture = Fixture::new();
  117|       |        let tx = fixture.env.tx_begin_read();
  118|       |        let store = &fixture.store;
  119|       |        assert_eq!(store.count(&tx), 0);
  120|       |        assert!(store.iter(&tx).next().is_none());
  121|       |        assert!(store.iter_rev(&tx).next().is_none());
  122|       |    }
  123|       |
  124|       |    #[test]
  125|       |    fn count() {
  126|       |        let fixture = Fixture::with_stored_data(vec![(1, Amount::raw(100)), (2, Amount::raw(200))]);
  127|       |        let txn = fixture.env.tx_begin_read();
  128|       |
  129|       |        let count = fixture.store.count(&txn);
  130|       |
  131|       |        assert_eq!(count, 2);
  132|       |    }
  133|       |
  134|       |    #[test]
  135|       |    fn add() {
  136|       |        let fixture = Fixture::new();
  137|       |        let mut txn = fixture.env.tx_begin_write();
  138|       |        let put_tracker = txn.track_puts();
  139|       |
  140|       |        let time = 1;
  141|       |        let amount = Amount::raw(2);
  142|       |        fixture.store.put(&mut txn, time, &amount);
  143|       |
  144|       |        assert_eq!(
  145|       |            put_tracker.output(),
  146|       |            vec![PutEvent {
  147|       |                database: LmdbDatabase::new_null(42),
  148|       |                key: time.to_be_bytes().to_vec(),
  149|       |                value: amount.to_be_bytes().to_vec(),
  150|       |                flags: WriteFlags::empty(),
  151|       |            }]
  152|       |        );
  153|       |    }
  154|       |
  155|       |    #[test]
  156|       |    fn iterate_ascending() {
  157|       |        let fixture = Fixture::with_stored_data(vec![(1, Amount::raw(100)), (2, Amount::raw(200))]);
  158|       |        let txn = fixture.env.tx_begin_read();
  159|       |
  160|       |        let mut it = fixture.store.iter(&txn);
  161|       |        assert_eq!(it.next(), Some((1, Amount::raw(100))));
  162|       |        assert_eq!(it.next(), Some((2, Amount::raw(200))));
  163|       |        assert_eq!(it.next(), None);
  164|       |    }
  165|       |
  166|       |    #[test]
  167|       |    fn iterate_descending() {
  168|       |        let fixture = Fixture::with_stored_data(vec![(1, Amount::raw(100)), (2, Amount::raw(200))]);
  169|       |        let txn = fixture.env.tx_begin_read();
  170|       |
  171|       |        let mut it = fixture.store.iter_rev(&txn);
  172|       |        assert_eq!(it.next(), Some((2, Amount::raw(200))));
  173|       |        assert_eq!(it.next(), Some((1, Amount::raw(100))));
  174|       |        assert_eq!(it.next(), None);
  175|       |    }
  176|       |
  177|       |    #[test]
  178|       |    fn delete() {
  179|       |        let fixture = Fixture::new();
  180|       |        let mut txn = fixture.env.tx_begin_write();
  181|       |        let delete_tracker = txn.track_deletions();
  182|       |
  183|       |        let time = 1;
  184|       |        fixture.store.del(&mut txn, time);
  185|       |
  186|       |        assert_eq!(
  187|       |            delete_tracker.output(),
  188|       |            vec![DeleteEvent {
  189|       |                database: LmdbDatabase::new_null(42),
  190|       |                key: time.to_be_bytes().to_vec()
  191|       |            }]
  192|       |        );
  193|       |    }
  194|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/peer_store.rs:
    1|       |use crate::{
    2|       |    iterator::LmdbIterator, LmdbDatabase, LmdbEnv, LmdbWriteTransaction, Transaction,
    3|       |    PEERS_TEST_DATABASE,
    4|       |};
    5|       |use lmdb::{DatabaseFlags, WriteFlags};
    6|       |use rsnano_core::utils::{BufferWriter, Serialize};
    7|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
    8|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
    9|       |use std::{
   10|       |    array::TryFromSliceError,
   11|       |    net::SocketAddrV6,
   12|       |    ops::Deref,
   13|       |    sync::Arc,
   14|       |    time::{Duration, SystemTime, UNIX_EPOCH},
   15|       |};
   16|       |
   17|       |pub struct LmdbPeerStore {
   18|       |    database: LmdbDatabase,
   19|       |    put_listener: OutputListenerMt<(SocketAddrV6, SystemTime)>,
   20|       |    delete_listener: OutputListenerMt<SocketAddrV6>,
   21|       |}
   22|       |
   23|       |impl LmdbPeerStore {
   24|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   25|     27|        let database = env
   26|     27|            .environment
   27|     27|            .create_db(Some("peers"), DatabaseFlags::empty())?;
                                                                           ^0
   28|       |
   29|     27|        Ok(Self {
   30|     27|            database,
   31|     27|            put_listener: OutputListenerMt::new(),
   32|     27|            delete_listener: OutputListenerMt::new(),
   33|     27|        })
   34|     27|    }
   35|       |
   36|      0|    pub fn database(&self) -> LmdbDatabase {
   37|      0|        self.database
   38|      0|    }
   39|       |
   40|     11|    pub fn track_puts(&self) -> Arc<OutputTrackerMt<(SocketAddrV6, SystemTime)>> {
   41|     11|        self.put_listener.track()
   42|     11|    }
   43|       |
   44|      9|    pub fn put(&self, txn: &mut LmdbWriteTransaction, endpoint: SocketAddrV6, time: SystemTime) {
   45|      9|        self.put_listener.emit((endpoint.clone(), time));
   46|      9|        txn.put(
   47|      9|            self.database,
   48|      9|            &EndpointBytes::from(endpoint),
   49|      9|            &TimeBytes::from(time),
   50|      9|            WriteFlags::empty(),
   51|      9|        )
   52|      9|        .unwrap();
   53|      9|    }
   54|       |
   55|     11|    pub fn track_deletions(&self) -> Arc<OutputTrackerMt<SocketAddrV6>> {
   56|     11|        self.delete_listener.track()
   57|     11|    }
   58|       |
   59|      2|    pub fn del(&self, txn: &mut LmdbWriteTransaction, endpoint: SocketAddrV6) {
   60|      2|        self.delete_listener.emit(endpoint);
   61|      2|        txn.delete(self.database, &EndpointBytes::from(endpoint), None)
   62|      2|            .unwrap();
   63|      2|    }
   64|       |
   65|      9|    pub fn exists(&self, txn: &dyn Transaction, endpoint: SocketAddrV6) -> bool {
   66|      9|        txn.exists(self.database, &EndpointBytes::from(endpoint))
   67|      9|    }
   68|       |
   69|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
   70|      0|        txn.count(self.database)
   71|      0|    }
   72|       |
   73|      0|    pub fn clear(&self, txn: &mut LmdbWriteTransaction) {
   74|      0|        txn.clear_db(self.database).unwrap();
   75|      0|    }
   76|       |
   77|     23|    pub fn iter<'a>(
   78|     23|        &self,
   79|     23|        txn: &'a dyn Transaction,
   80|     23|    ) -> impl Iterator<Item = (SocketAddrV6, SystemTime)> + 'a {
   81|     23|        let cursor = txn
   82|     23|            .open_ro_cursor(self.database)
   83|     23|            .expect("Could not read peer store database");
   84|     23|        PeerIterator(LmdbIterator::new(cursor, |k, v| {
   85|     17|            (
   86|     17|                EndpointBytes::try_from(k).unwrap().into(),
   87|     17|                TimeBytes::try_from(v).unwrap().into(),
   88|     17|            )
   89|     23|        }))
   90|     23|    }
   91|       |}
   92|       |
   93|       |pub struct PeerIterator<'txn>(LmdbIterator<'txn, EndpointBytes, TimeBytes>);
   94|       |
   95|       |impl<'txn> Iterator for PeerIterator<'txn> {
   96|       |    type Item = (SocketAddrV6, SystemTime);
   97|       |
   98|     40|    fn next(&mut self) -> Option<Self::Item> {
   99|     40|        self.0.next().map(|(k, v)| (k.into(), v.into()))
                                                 ^17
  100|     40|    }
  101|       |}
  102|       |
  103|       |pub struct EndpointBytes([u8; 18]);
  104|       |
  105|       |impl Deref for EndpointBytes {
  106|       |    type Target = [u8];
  107|       |
  108|     37|    fn deref(&self) -> &Self::Target {
  109|     37|        &self.0
  110|     37|    }
  111|       |}
  112|       |
  113|       |impl Serialize for EndpointBytes {
  114|      0|    fn serialize(&self, stream: &mut dyn BufferWriter) {
  115|      0|        stream.write_bytes_safe(&self.0)
  116|      0|    }
  117|       |}
  118|       |
  119|       |impl TryFrom<&[u8]> for EndpointBytes {
  120|       |    type Error = TryFromSliceError;
  121|       |
  122|     17|    fn try_from(value: &[u8]) -> Result<Self, Self::Error> {
  123|     17|        let buffer: [u8; 18] = value.try_into()?;
                                                             ^0
  124|     17|        Ok(Self(buffer))
  125|     17|    }
  126|       |}
  127|       |
  128|       |impl From<SocketAddrV6> for EndpointBytes {
  129|     37|    fn from(value: SocketAddrV6) -> Self {
  130|     37|        let mut bytes = [0; 18];
  131|     37|        let (ip, port) = bytes.split_at_mut(16);
  132|     37|        ip.copy_from_slice(&value.ip().octets());
  133|     37|        port.copy_from_slice(&value.port().to_be_bytes());
  134|     37|        Self(bytes)
  135|     37|    }
  136|       |}
  137|       |
  138|       |impl From<EndpointBytes> for SocketAddrV6 {
  139|     17|    fn from(value: EndpointBytes) -> Self {
  140|     17|        let (ip, port) = value.0.split_at(16);
  141|     17|        let ip: [u8; 16] = ip.try_into().unwrap();
  142|     17|        let port: [u8; 2] = port.try_into().unwrap();
  143|     17|        SocketAddrV6::new(ip.into(), u16::from_be_bytes(port), 0, 0)
  144|     17|    }
  145|       |}
  146|       |
  147|       |pub struct TimeBytes([u8; 8]);
  148|       |
  149|       |impl Deref for TimeBytes {
  150|       |    type Target = [u8];
  151|       |
  152|     26|    fn deref(&self) -> &Self::Target {
  153|     26|        &self.0
  154|     26|    }
  155|       |}
  156|       |
  157|       |impl TryFrom<&[u8]> for TimeBytes {
  158|       |    type Error = TryFromSliceError;
  159|       |
  160|     17|    fn try_from(value: &[u8]) -> Result<Self, Self::Error> {
  161|     17|        let buffer: [u8; 8] = value.try_into()?;
                                                            ^0
  162|     17|        Ok(Self(buffer))
  163|     17|    }
  164|       |}
  165|       |
  166|       |impl From<SystemTime> for TimeBytes {
  167|     26|    fn from(value: SystemTime) -> Self {
  168|     26|        Self(
  169|     26|            (value
  170|     26|                .duration_since(UNIX_EPOCH)
  171|     26|                .unwrap_or_default()
  172|     26|                .as_millis() as u64)
  173|     26|                .to_be_bytes(),
  174|     26|        )
  175|     26|    }
  176|       |}
  177|       |
  178|       |impl From<TimeBytes> for SystemTime {
  179|     17|    fn from(value: TimeBytes) -> Self {
  180|     17|        UNIX_EPOCH + Duration::from_millis(u64::from_be_bytes(value.0))
  181|     17|    }
  182|       |}
  183|       |
  184|       |pub struct ConfiguredPeersDatabaseBuilder {
  185|       |    database: ConfiguredDatabase,
  186|       |}
  187|       |
  188|       |impl ConfiguredPeersDatabaseBuilder {
  189|     20|    pub fn new() -> Self {
  190|     20|        Self {
  191|     20|            database: ConfiguredDatabase::new(PEERS_TEST_DATABASE, "peers"),
  192|     20|        }
  193|     20|    }
  194|       |
  195|     17|    pub fn peer(mut self, endpoint: SocketAddrV6, time: SystemTime) -> Self {
  196|     17|        self.database.entries.insert(
  197|     17|            EndpointBytes::from(endpoint).to_vec(),
  198|     17|            TimeBytes::from(time).to_vec(),
  199|     17|        );
  200|     17|        self
  201|     17|    }
  202|       |
  203|     20|    pub fn build(self) -> ConfiguredDatabase {
  204|     20|        self.database
  205|     20|    }
  206|       |}
  207|       |
  208|       |#[cfg(test)]
  209|       |mod tests {
  210|       |    use super::*;
  211|       |    use crate::{DeleteEvent, PutEvent};
  212|       |    use std::{
  213|       |        net::Ipv6Addr,
  214|       |        time::{Duration, UNIX_EPOCH},
  215|       |    };
  216|       |
  217|       |    #[test]
  218|       |    fn empty_store() {
  219|       |        let fixture = Fixture::new();
  220|       |        let txn = fixture.env.tx_begin_read();
  221|       |        let store = &fixture.store;
  222|       |        assert_eq!(store.count(&txn), 0);
  223|       |        assert_eq!(store.exists(&txn, TEST_PEER_A), false);
  224|       |        assert_eq!(store.iter(&txn).next(), None);
  225|       |    }
  226|       |
  227|       |    #[test]
  228|       |    fn add_one_endpoint() {
  229|       |        let fixture = Fixture::new();
  230|       |        let mut txn = fixture.env.tx_begin_write();
  231|       |        let put_tracker = txn.track_puts();
  232|       |
  233|       |        let key = TEST_PEER_A;
  234|       |        let time = UNIX_EPOCH + Duration::from_secs(1261440000);
  235|       |        fixture.store.put(&mut txn, key, time);
  236|       |
  237|       |        assert_eq!(
  238|       |            put_tracker.output(),
  239|       |            vec![PutEvent {
  240|       |                database: LmdbDatabase::new_null(42),
  241|       |                key: vec![0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0, 6, 0, 7, 0, 8, 0x3, 0xE8],
  242|       |                value: 1261440000000u64.to_be_bytes().to_vec(),
  243|       |                flags: WriteFlags::empty()
  244|       |            }]
  245|       |        )
  246|       |    }
  247|       |
  248|       |    #[test]
  249|       |    fn exists() {
  250|       |        let fixture = Fixture::with_stored_data(vec![TEST_PEER_A.clone(), TEST_PEER_B.clone()]);
  251|       |
  252|       |        let txn = fixture.env.tx_begin_read();
  253|       |
  254|       |        assert_eq!(fixture.store.exists(&txn, TEST_PEER_A), true);
  255|       |        assert_eq!(fixture.store.exists(&txn, TEST_PEER_B), true);
  256|       |        assert_eq!(fixture.store.exists(&txn, UNKNOWN_PEER), false);
  257|       |    }
  258|       |
  259|       |    #[test]
  260|       |    fn count() {
  261|       |        let fixture = Fixture::with_stored_data(vec![TEST_PEER_A, TEST_PEER_B]);
  262|       |        let txn = fixture.env.tx_begin_read();
  263|       |        assert_eq!(fixture.store.count(&txn), 2);
  264|       |    }
  265|       |
  266|       |    #[test]
  267|       |    fn delete() {
  268|       |        let fixture = Fixture::new();
  269|       |        let mut txn = fixture.env.tx_begin_write();
  270|       |        let delete_tracker = txn.track_deletions();
  271|       |
  272|       |        fixture.store.del(&mut txn, TEST_PEER_A);
  273|       |
  274|       |        assert_eq!(
  275|       |            delete_tracker.output(),
  276|       |            vec![DeleteEvent {
  277|       |                database: LmdbDatabase::new_null(42),
  278|       |                key: EndpointBytes::from(TEST_PEER_A).to_vec()
  279|       |            }]
  280|       |        )
  281|       |    }
  282|       |
  283|       |    #[test]
  284|       |    fn track_puts() {
  285|       |        let fixture = Fixture::new();
  286|       |        let mut tx = fixture.env.tx_begin_write();
  287|       |        let time = UNIX_EPOCH + Duration::from_secs(1261440000);
  288|       |        let put_tracker = fixture.store.track_puts();
  289|       |
  290|       |        fixture.store.put(&mut tx, TEST_PEER_A, time);
  291|       |
  292|       |        let output = put_tracker.output();
  293|       |        assert_eq!(output, vec![(TEST_PEER_A, time)]);
  294|       |    }
  295|       |
  296|       |    #[test]
  297|       |    fn track_deletes() {
  298|       |        let fixture = Fixture::new();
  299|       |        let mut tx = fixture.env.tx_begin_write();
  300|       |        let delete_tracker = fixture.store.track_deletions();
  301|       |
  302|       |        fixture.store.del(&mut tx, TEST_PEER_A);
  303|       |
  304|       |        let output = delete_tracker.output();
  305|       |        assert_eq!(output, vec![TEST_PEER_A]);
  306|       |    }
  307|       |
  308|       |    const TEST_PEER_A: SocketAddrV6 =
  309|       |        SocketAddrV6::new(Ipv6Addr::new(1, 2, 3, 4, 5, 6, 7, 8), 1000, 0, 0);
  310|       |
  311|       |    const TEST_PEER_B: SocketAddrV6 =
  312|       |        SocketAddrV6::new(Ipv6Addr::new(3, 3, 3, 3, 3, 3, 3, 3), 2000, 0, 0);
  313|       |
  314|       |    const UNKNOWN_PEER: SocketAddrV6 =
  315|       |        SocketAddrV6::new(Ipv6Addr::new(4, 4, 4, 4, 4, 4, 4, 4), 4000, 0, 0);
  316|       |
  317|       |    struct Fixture {
  318|       |        env: Arc<LmdbEnv>,
  319|       |        store: LmdbPeerStore,
  320|       |    }
  321|       |
  322|       |    impl Fixture {
  323|       |        fn new() -> Self {
  324|       |            Self::with_env(LmdbEnv::new_null())
  325|       |        }
  326|       |
  327|       |        fn with_stored_data(entries: Vec<SocketAddrV6>) -> Self {
  328|       |            let mut env = LmdbEnv::new_null_with().database("peers", LmdbDatabase::new_null(42));
  329|       |
  330|       |            for entry in entries {
  331|       |                env = env.entry(&EndpointBytes::from(entry), &[]);
  332|       |            }
  333|       |
  334|       |            Self::with_env(env.build().build())
  335|       |        }
  336|       |
  337|       |        fn with_env(env: LmdbEnv) -> Self {
  338|       |            let env = Arc::new(env);
  339|       |            Self {
  340|       |                env: env.clone(),
  341|       |                store: LmdbPeerStore::new(env).unwrap(),
  342|       |            }
  343|       |        }
  344|       |    }
  345|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/pending_store.rs:
    1|       |use crate::{
    2|       |    iterator::LmdbRangeIterator, LmdbDatabase, LmdbEnv, LmdbIterator, LmdbWriteTransaction,
    3|       |    Transaction, PENDING_TEST_DATABASE,
    4|       |};
    5|       |use lmdb::{DatabaseFlags, WriteFlags};
    6|       |use rsnano_core::{
    7|       |    utils::{BufferReader, Deserialize},
    8|       |    Account, BlockHash, PendingInfo, PendingKey,
    9|       |};
   10|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
   11|       |#[cfg(feature = "output_tracking")]
   12|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   13|       |use std::{ops::RangeBounds, sync::Arc};
   14|       |
   15|       |pub struct LmdbPendingStore {
   16|       |    _env: Arc<LmdbEnv>,
   17|       |    database: LmdbDatabase,
   18|       |    #[cfg(feature = "output_tracking")]
   19|       |    put_listener: OutputListenerMt<(PendingKey, PendingInfo)>,
   20|       |    #[cfg(feature = "output_tracking")]
   21|       |    delete_listener: OutputListenerMt<PendingKey>,
   22|       |}
   23|       |
   24|       |impl LmdbPendingStore {
   25|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   26|     27|        let database = env
   27|     27|            .environment
   28|     27|            .create_db(Some("pending"), DatabaseFlags::empty())?;
                                                                             ^0
   29|       |
   30|     27|        Ok(Self {
   31|     27|            _env: env,
   32|     27|            database,
   33|     27|            #[cfg(feature = "output_tracking")]
   34|     27|            put_listener: OutputListenerMt::new(),
   35|     27|            #[cfg(feature = "output_tracking")]
   36|     27|            delete_listener: OutputListenerMt::new(),
   37|     27|        })
   38|     27|    }
   39|       |
   40|     32|    pub fn database(&self) -> LmdbDatabase {
   41|     32|        self.database
   42|     32|    }
   43|       |
   44|       |    #[cfg(feature = "output_tracking")]
   45|       |    pub fn track_puts(&self) -> Arc<OutputTrackerMt<(PendingKey, PendingInfo)>> {
   46|       |        self.put_listener.track()
   47|       |    }
   48|       |
   49|       |    #[cfg(feature = "output_tracking")]
   50|       |    pub fn track_deletions(&self) -> Arc<OutputTrackerMt<PendingKey>> {
   51|       |        self.delete_listener.track()
   52|       |    }
   53|       |
   54|     28|    pub fn put(&self, txn: &mut LmdbWriteTransaction, key: &PendingKey, pending: &PendingInfo) {
   55|     28|        #[cfg(feature = "output_tracking")]
   56|     28|        self.put_listener.emit((key.clone(), pending.clone()));
   57|     28|        let key_bytes = key.to_bytes();
   58|     28|        let pending_bytes = pending.to_bytes();
   59|     28|        txn.put(
   60|     28|            self.database,
   61|     28|            &key_bytes,
   62|     28|            &pending_bytes,
   63|     28|            WriteFlags::empty(),
   64|     28|        )
   65|     28|        .unwrap();
   66|     28|    }
   67|       |
   68|      4|    pub fn del(&self, txn: &mut LmdbWriteTransaction, key: &PendingKey) {
   69|      4|        #[cfg(feature = "output_tracking")]
   70|      4|        self.delete_listener.emit(key.clone());
   71|      4|        let key_bytes = key.to_bytes();
   72|      4|        txn.delete(self.database, &key_bytes, None).unwrap();
   73|      4|    }
   74|       |
   75|     32|    pub fn get(&self, txn: &dyn Transaction, key: &PendingKey) -> Option<PendingInfo> {
   76|     32|        let key_bytes = key.to_bytes();
   77|     32|        match txn.get(self.database, &key_bytes) {
   78|      4|            Ok(bytes) => {
   79|      4|                let mut stream = BufferReader::new(bytes);
   80|      4|                PendingInfo::deserialize(&mut stream).ok()
   81|       |            }
   82|     28|            Err(lmdb::Error::NotFound) => None,
   83|      0|            Err(e) => {
   84|      0|                panic!("Could not load pending info: {:?}", e);
   85|       |            }
   86|       |        }
   87|     32|    }
   88|       |
   89|      0|    pub fn iter<'tx>(
   90|      0|        &self,
   91|      0|        tx: &'tx dyn Transaction,
   92|      0|    ) -> impl Iterator<Item = (PendingKey, PendingInfo)> + 'tx {
   93|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   94|      0|
   95|      0|        LmdbIterator::new(cursor, |key, value| {
   96|      0|            let mut stream = BufferReader::new(key);
   97|      0|            let key = PendingKey::deserialize(&mut stream).unwrap();
   98|      0|            let mut stream = BufferReader::new(value);
   99|      0|            let info = PendingInfo::deserialize(&mut stream).unwrap();
  100|      0|            (key, info)
  101|      0|        })
  102|      0|    }
  103|       |
  104|      6|    pub fn iter_range<'tx>(
  105|      6|        &self,
  106|      6|        tx: &'tx dyn Transaction,
  107|      6|        range: impl RangeBounds<PendingKey> + 'static,
  108|      6|    ) -> impl Iterator<Item = (PendingKey, PendingInfo)> + 'tx {
  109|      6|        let cursor = tx.open_ro_cursor(self.database).unwrap();
  110|      6|        LmdbRangeIterator::new(cursor, range)
  111|      6|    }
  112|       |
  113|      0|    pub fn exists(&self, txn: &dyn Transaction, key: &PendingKey) -> bool {
  114|      0|        self.iter_range(txn, *key..)
  115|      0|            .next()
  116|      0|            .map(|(k, _)| k == *key)
  117|      0|            .unwrap_or(false)
  118|      0|    }
  119|       |
  120|      0|    pub fn any(&self, tx: &dyn Transaction, account: &Account) -> bool {
  121|      0|        let key = PendingKey::new(*account, BlockHash::zero());
  122|      0|        self.iter_range(tx, key..)
  123|      0|            .next()
  124|      0|            .map(|(k, _)| k.receiving_account == *account)
  125|      0|            .unwrap_or(false)
  126|      0|    }
  127|       |}
  128|       |
  129|       |pub struct ConfiguredPendingDatabaseBuilder {
  130|       |    database: ConfiguredDatabase,
  131|       |}
  132|       |
  133|       |impl ConfiguredPendingDatabaseBuilder {
  134|     20|    pub fn new() -> Self {
  135|     20|        Self {
  136|     20|            database: ConfiguredDatabase::new(PENDING_TEST_DATABASE, "pending"),
  137|     20|        }
  138|     20|    }
  139|       |
  140|      0|    pub fn pending(mut self, key: &PendingKey, info: &PendingInfo) -> Self {
  141|      0|        self.database
  142|      0|            .entries
  143|      0|            .insert(key.to_bytes().to_vec(), info.to_bytes().to_vec());
  144|      0|        self
  145|      0|    }
  146|       |
  147|     20|    pub fn build(self) -> ConfiguredDatabase {
  148|     20|        self.database
  149|     20|    }
  150|       |
  151|      0|    pub fn create(frontiers: Vec<(PendingKey, PendingInfo)>) -> ConfiguredDatabase {
  152|      0|        let mut builder = Self::new();
  153|      0|        for (key, info) in frontiers {
  154|      0|            builder = builder.pending(&key, &info);
  155|      0|        }
  156|      0|        builder.build()
  157|      0|    }
  158|       |}
  159|       |
  160|       |#[cfg(test)]
  161|       |mod tests {
  162|       |    use super::*;
  163|       |    use crate::{DeleteEvent, PutEvent};
  164|       |
  165|       |    struct Fixture {
  166|       |        env: Arc<LmdbEnv>,
  167|       |        store: LmdbPendingStore,
  168|       |    }
  169|       |
  170|       |    impl Fixture {
  171|       |        pub fn new() -> Self {
  172|       |            Self::with_stored_data(Vec::new())
  173|       |        }
  174|       |
  175|       |        pub fn with_stored_data(entries: Vec<(PendingKey, PendingInfo)>) -> Self {
  176|       |            let env = LmdbEnv::new_null_with()
  177|       |                .configured_database(ConfiguredPendingDatabaseBuilder::create(entries))
  178|       |                .build();
  179|       |
  180|       |            let env = Arc::new(env);
  181|       |            Self {
  182|       |                env: env.clone(),
  183|       |                store: LmdbPendingStore::new(env).unwrap(),
  184|       |            }
  185|       |        }
  186|       |    }
  187|       |
  188|       |    #[test]
  189|       |    fn not_found() {
  190|       |        let fixture = Fixture::new();
  191|       |        let txn = fixture.env.tx_begin_read();
  192|       |        let result = fixture.store.get(&txn, &PendingKey::new_test_instance());
  193|       |        assert!(result.is_none());
  194|       |        assert_eq!(
  195|       |            fixture.store.exists(&txn, &PendingKey::new_test_instance()),
  196|       |            false
  197|       |        );
  198|       |    }
  199|       |
  200|       |    #[test]
  201|       |    fn load_pending_info() {
  202|       |        let key = PendingKey::new_test_instance();
  203|       |        let info = PendingInfo::new_test_instance();
  204|       |        let fixture = Fixture::with_stored_data(vec![(key.clone(), info.clone())]);
  205|       |        let txn = fixture.env.tx_begin_read();
  206|       |
  207|       |        let result = fixture.store.get(&txn, &key);
  208|       |
  209|       |        assert_eq!(result, Some(info));
  210|       |        assert_eq!(fixture.store.exists(&txn, &key), true);
  211|       |    }
  212|       |
  213|       |    #[test]
  214|       |    fn add_pending() {
  215|       |        let fixture = Fixture::new();
  216|       |        let mut txn = fixture.env.tx_begin_write();
  217|       |        let put_tracker = txn.track_puts();
  218|       |        let pending_key = PendingKey::new_test_instance();
  219|       |        let pending = PendingInfo::new_test_instance();
  220|       |
  221|       |        fixture.store.put(&mut txn, &pending_key, &pending);
  222|       |
  223|       |        assert_eq!(
  224|       |            put_tracker.output(),
  225|       |            vec![PutEvent {
  226|       |                database: PENDING_TEST_DATABASE.into(),
  227|       |                key: pending_key.to_bytes().to_vec(),
  228|       |                value: pending.to_bytes().to_vec(),
  229|       |                flags: WriteFlags::empty()
  230|       |            }]
  231|       |        );
  232|       |    }
  233|       |
  234|       |    #[test]
  235|       |    fn delete() {
  236|       |        let fixture = Fixture::new();
  237|       |        let mut txn = fixture.env.tx_begin_write();
  238|       |        let delete_tracker = txn.track_deletions();
  239|       |        let pending_key = PendingKey::new_test_instance();
  240|       |
  241|       |        fixture.store.del(&mut txn, &pending_key);
  242|       |
  243|       |        assert_eq!(
  244|       |            delete_tracker.output(),
  245|       |            vec![DeleteEvent {
  246|       |                database: PENDING_TEST_DATABASE.into(),
  247|       |                key: pending_key.to_bytes().to_vec()
  248|       |            }]
  249|       |        )
  250|       |    }
  251|       |
  252|       |    #[test]
  253|       |    fn iter_empty() {
  254|       |        let fixture = Fixture::new();
  255|       |        let tx = fixture.env.tx_begin_read();
  256|       |        assert!(fixture.store.iter(&tx).next().is_none());
  257|       |    }
  258|       |
  259|       |    #[test]
  260|       |    fn iter() {
  261|       |        let key = PendingKey::new_test_instance();
  262|       |        let info = PendingInfo::new_test_instance();
  263|       |        let fixture = Fixture::with_stored_data(vec![(key.clone(), info.clone())]);
  264|       |        let tx = fixture.env.tx_begin_read();
  265|       |
  266|       |        let mut it = fixture.store.iter(&tx);
  267|       |        let (k, v) = it.next().unwrap();
  268|       |        assert_eq!(k, key);
  269|       |        assert_eq!(v, info);
  270|       |        assert!(it.next().is_none());
  271|       |    }
  272|       |
  273|       |    #[test]
  274|       |    fn tracks_puts() {
  275|       |        let fixture = Fixture::new();
  276|       |        let mut txn = fixture.env.tx_begin_write();
  277|       |        let key = PendingKey::new_test_instance();
  278|       |        let info = PendingInfo::new_test_instance();
  279|       |        let put_tracker = fixture.store.track_puts();
  280|       |
  281|       |        fixture.store.put(&mut txn, &key, &info);
  282|       |
  283|       |        assert_eq!(put_tracker.output(), vec![(key, info)]);
  284|       |    }
  285|       |
  286|       |    #[test]
  287|       |    fn tracks_deletions() {
  288|       |        let fixture = Fixture::new();
  289|       |        let mut txn = fixture.env.tx_begin_write();
  290|       |        let key = PendingKey::new_test_instance();
  291|       |        let delete_tracker = fixture.store.track_deletions();
  292|       |
  293|       |        fixture.store.del(&mut txn, &key);
  294|       |
  295|       |        assert_eq!(delete_tracker.output(), vec![key]);
  296|       |    }
  297|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/pruned_store.rs:
    1|       |use crate::{
    2|       |    LmdbDatabase, LmdbEnv, LmdbIterator, LmdbRangeIterator, LmdbWriteTransaction, Transaction,
    3|       |    PRUNED_TEST_DATABASE,
    4|       |};
    5|       |use lmdb::{DatabaseFlags, WriteFlags};
    6|       |use rand::{thread_rng, Rng};
    7|       |use rsnano_core::{BlockHash, NoValue};
    8|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
    9|       |use std::{ops::RangeBounds, sync::Arc};
   10|       |
   11|       |pub struct LmdbPrunedStore {
   12|       |    database: LmdbDatabase,
   13|       |}
   14|       |
   15|       |impl LmdbPrunedStore {
   16|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   17|     27|        let database = env
   18|     27|            .environment
   19|     27|            .create_db(Some("pruned"), DatabaseFlags::empty())?;
                                                                            ^0
   20|     27|        Ok(Self { database })
   21|     27|    }
   22|       |
   23|      0|    pub fn database(&self) -> LmdbDatabase {
   24|      0|        self.database
   25|      0|    }
   26|       |
   27|      0|    pub fn put(&self, tx: &mut LmdbWriteTransaction, hash: &BlockHash) {
   28|      0|        tx.put(self.database, hash.as_bytes(), &[0; 0], WriteFlags::empty())
   29|      0|            .unwrap();
   30|      0|    }
   31|       |
   32|      0|    pub fn del(&self, tx: &mut LmdbWriteTransaction, hash: &BlockHash) {
   33|      0|        tx.delete(self.database, hash.as_bytes(), None).unwrap();
   34|      0|    }
   35|       |
   36|  32.8k|    pub fn exists(&self, tx: &dyn Transaction, hash: &BlockHash) -> bool {
   37|  32.8k|        tx.exists(self.database, hash.as_bytes())
   38|  32.8k|    }
   39|       |
   40|      0|    pub fn iter<'tx>(&self, tx: &'tx dyn Transaction) -> impl Iterator<Item = BlockHash> + 'tx {
   41|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   42|      0|
   43|      0|        LmdbIterator::new(cursor, |key, _| {
   44|      0|            let hash = BlockHash::from_slice(key).unwrap();
   45|      0|            (hash, NoValue {})
   46|      0|        })
   47|      0|        .map(|(k, _)| k)
   48|      0|    }
   49|       |
   50|      0|    pub fn iter_range<'tx>(
   51|      0|        &self,
   52|      0|        tx: &'tx dyn Transaction,
   53|      0|        range: impl RangeBounds<BlockHash> + 'static,
   54|      0|    ) -> impl Iterator<Item = BlockHash> + 'tx {
   55|      0|        let cursor = tx.open_ro_cursor(self.database).unwrap();
   56|      0|        LmdbRangeIterator::<BlockHash, NoValue, _>::new(cursor, range).map(|(k, _)| k)
   57|      0|    }
   58|       |
   59|      0|    pub fn random(&self, tx: &dyn Transaction) -> Option<BlockHash> {
   60|      0|        let random_hash = BlockHash::from_bytes(thread_rng().gen());
   61|      0|        self.iter_range(tx, random_hash..)
   62|      0|            .next()
   63|      0|            .or_else(|| self.iter(tx).next())
   64|      0|    }
   65|       |
   66|     30|    pub fn count(&self, tx: &dyn Transaction) -> u64 {
   67|     30|        tx.count(self.database)
   68|     30|    }
   69|       |
   70|      0|    pub fn clear(&self, tx: &mut LmdbWriteTransaction) {
   71|      0|        tx.clear_db(self.database).unwrap();
   72|      0|    }
   73|       |}
   74|       |
   75|       |pub struct ConfiguredPrunedDatabaseBuilder {
   76|       |    database: ConfiguredDatabase,
   77|       |}
   78|       |
   79|       |impl ConfiguredPrunedDatabaseBuilder {
   80|     20|    pub fn new() -> Self {
   81|     20|        Self {
   82|     20|            database: ConfiguredDatabase::new(PRUNED_TEST_DATABASE, "pruned"),
   83|     20|        }
   84|     20|    }
   85|       |
   86|      0|    pub fn pruned(mut self, hash: &BlockHash) -> Self {
   87|      0|        self.database
   88|      0|            .entries
   89|      0|            .insert(hash.as_bytes().to_vec(), Vec::new());
   90|      0|        self
   91|      0|    }
   92|       |
   93|     20|    pub fn build(self) -> ConfiguredDatabase {
   94|     20|        self.database
   95|     20|    }
   96|       |
   97|      0|    pub fn create(hashes: Vec<BlockHash>) -> ConfiguredDatabase {
   98|      0|        let mut builder = Self::new();
   99|      0|        for hash in hashes {
  100|      0|            builder = builder.pruned(&hash);
  101|      0|        }
  102|      0|        builder.build()
  103|      0|    }
  104|       |}
  105|       |
  106|       |#[cfg(test)]
  107|       |mod tests {
  108|       |    use super::*;
  109|       |    use crate::{DeleteEvent, PutEvent};
  110|       |
  111|       |    struct Fixture {
  112|       |        env: Arc<LmdbEnv>,
  113|       |        store: LmdbPrunedStore,
  114|       |    }
  115|       |
  116|       |    impl Fixture {
  117|       |        pub fn new() -> Self {
  118|       |            Self::with_stored_data(Vec::new())
  119|       |        }
  120|       |
  121|       |        pub fn with_stored_data(entries: Vec<BlockHash>) -> Self {
  122|       |            let env = LmdbEnv::new_null_with()
  123|       |                .configured_database(ConfiguredPrunedDatabaseBuilder::create(entries))
  124|       |                .build();
  125|       |            let env = Arc::new(env);
  126|       |            Self {
  127|       |                env: env.clone(),
  128|       |                store: LmdbPrunedStore::new(env).unwrap(),
  129|       |            }
  130|       |        }
  131|       |    }
  132|       |
  133|       |    #[test]
  134|       |    fn empty_store() {
  135|       |        let fixture = Fixture::new();
  136|       |        let tx = fixture.env.tx_begin_read();
  137|       |        let store = &fixture.store;
  138|       |
  139|       |        assert_eq!(store.count(&tx), 0);
  140|       |        assert_eq!(store.exists(&tx, &BlockHash::from(1)), false);
  141|       |        assert!(store.iter(&tx).next().is_none());
  142|       |        assert!(store.random(&tx).is_none());
  143|       |    }
  144|       |
  145|       |    #[test]
  146|       |    fn add_pruned_info() {
  147|       |        let fixture = Fixture::new();
  148|       |        let mut tx = fixture.env.tx_begin_write();
  149|       |        let put_tracker = tx.track_puts();
  150|       |        let hash = BlockHash::from(1);
  151|       |
  152|       |        fixture.store.put(&mut tx, &hash);
  153|       |
  154|       |        assert_eq!(
  155|       |            put_tracker.output(),
  156|       |            vec![PutEvent {
  157|       |                database: PRUNED_TEST_DATABASE.into(),
  158|       |                key: hash.as_bytes().to_vec(),
  159|       |                value: Vec::new(),
  160|       |                flags: WriteFlags::empty()
  161|       |            }]
  162|       |        );
  163|       |    }
  164|       |
  165|       |    #[test]
  166|       |    fn count() {
  167|       |        let fixture = Fixture::with_stored_data(vec![BlockHash::from(1), BlockHash::from(2)]);
  168|       |        let tx = fixture.env.tx_begin_read();
  169|       |
  170|       |        assert_eq!(fixture.store.count(&tx), 2);
  171|       |        assert_eq!(fixture.store.exists(&tx, &BlockHash::from(1)), true);
  172|       |        assert_eq!(fixture.store.exists(&tx, &BlockHash::from(3)), false);
  173|       |    }
  174|       |
  175|       |    #[test]
  176|       |    fn iterate() {
  177|       |        let fixture = Fixture::with_stored_data(vec![BlockHash::from(1), BlockHash::from(2)]);
  178|       |        let tx = fixture.env.tx_begin_read();
  179|       |
  180|       |        assert_eq!(fixture.store.iter(&tx).next(), Some(BlockHash::from(1)));
  181|       |        assert_eq!(
  182|       |            fixture.store.iter_range(&tx, BlockHash::from(2)..).next(),
  183|       |            Some(BlockHash::from(2))
  184|       |        );
  185|       |    }
  186|       |
  187|       |    #[test]
  188|       |    fn delete() {
  189|       |        let fixture = Fixture::new();
  190|       |        let mut tx = fixture.env.tx_begin_write();
  191|       |        let delete_tracker = tx.track_deletions();
  192|       |        let hash = BlockHash::from(1);
  193|       |
  194|       |        fixture.store.del(&mut tx, &hash);
  195|       |
  196|       |        assert_eq!(
  197|       |            delete_tracker.output(),
  198|       |            vec![DeleteEvent {
  199|       |                database: PRUNED_TEST_DATABASE.into(),
  200|       |                key: hash.as_bytes().to_vec()
  201|       |            }]
  202|       |        )
  203|       |    }
  204|       |
  205|       |    #[test]
  206|       |    fn pruned_random() {
  207|       |        let fixture = Fixture::with_stored_data(vec![BlockHash::from(42)]);
  208|       |        let tx = fixture.env.tx_begin_read();
  209|       |        let random_hash = fixture.store.random(&tx);
  210|       |        assert_eq!(random_hash, Some(BlockHash::from(42)));
  211|       |    }
  212|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/rep_weight_store.rs:
    1|       |use crate::{
    2|       |    LmdbDatabase, LmdbEnv, LmdbWriteTransaction, RoCursor, Transaction, REP_WEIGHT_TEST_DATABASE,
    3|       |};
    4|       |use lmdb::{DatabaseFlags, WriteFlags};
    5|       |use lmdb_sys::{MDB_cursor_op, MDB_FIRST, MDB_NEXT};
    6|       |use rsnano_core::{
    7|       |    utils::{BufferReader, Deserialize},
    8|       |    Amount, PublicKey,
    9|       |};
   10|       |use rsnano_nullable_lmdb::ConfiguredDatabase;
   11|       |#[cfg(feature = "output_tracking")]
   12|       |use rsnano_output_tracker::{OutputListenerMt, OutputTrackerMt};
   13|       |use std::sync::Arc;
   14|       |
   15|       |pub struct LmdbRepWeightStore {
   16|       |    _env: Arc<LmdbEnv>,
   17|       |    database: LmdbDatabase,
   18|       |    #[cfg(feature = "output_tracking")]
   19|       |    delete_listener: OutputListenerMt<PublicKey>,
   20|       |    #[cfg(feature = "output_tracking")]
   21|       |    put_listener: OutputListenerMt<(PublicKey, Amount)>,
   22|       |}
   23|       |
   24|       |impl LmdbRepWeightStore {
   25|     27|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   26|     27|        let database = env
   27|     27|            .environment
   28|     27|            .create_db(Some("rep_weights"), DatabaseFlags::empty())?;
                                                                                 ^0
   29|     27|        Ok(Self {
   30|     27|            _env: env,
   31|     27|            database,
   32|     27|            #[cfg(feature = "output_tracking")]
   33|     27|            delete_listener: OutputListenerMt::new(),
   34|     27|            #[cfg(feature = "output_tracking")]
   35|     27|            put_listener: OutputListenerMt::new(),
   36|     27|        })
   37|     27|    }
   38|       |
   39|       |    #[cfg(feature = "output_tracking")]
   40|       |    pub fn track_deletions(&self) -> Arc<OutputTrackerMt<PublicKey>> {
   41|       |        self.delete_listener.track()
   42|       |    }
   43|       |
   44|       |    #[cfg(feature = "output_tracking")]
   45|       |    pub fn track_puts(&self) -> Arc<OutputTrackerMt<(PublicKey, Amount)>> {
   46|       |        self.put_listener.track()
   47|       |    }
   48|       |
   49|     32|    pub fn get(&self, txn: &dyn Transaction, pub_key: &PublicKey) -> Option<Amount> {
   50|     32|        match txn.get(self.database, pub_key.as_bytes()) {
   51|     28|            Ok(bytes) => {
   52|     28|                let mut stream = BufferReader::new(bytes);
   53|     28|                Amount::deserialize(&mut stream).ok()
   54|       |            }
   55|      4|            Err(lmdb::Error::NotFound) => None,
   56|      0|            Err(e) => {
   57|      0|                panic!("Could not load rep_weight: {:?}", e);
   58|       |            }
   59|       |        }
   60|     32|    }
   61|       |
   62|     59|    pub fn put(&self, txn: &mut LmdbWriteTransaction, representative: PublicKey, weight: Amount) {
   63|     59|        #[cfg(feature = "output_tracking")]
   64|     59|        self.put_listener.emit((representative, weight));
   65|     59|
   66|     59|        txn.put(
   67|     59|            self.database,
   68|     59|            representative.as_bytes(),
   69|     59|            &weight.to_be_bytes(),
   70|     59|            WriteFlags::empty(),
   71|     59|        )
   72|     59|        .unwrap();
   73|     59|    }
   74|       |
   75|      0|    pub fn del(&self, txn: &mut LmdbWriteTransaction, representative: &PublicKey) {
   76|      0|        #[cfg(feature = "output_tracking")]
   77|      0|        self.delete_listener.emit(*representative);
   78|      0|
   79|      0|        txn.delete(self.database, representative.as_bytes(), None)
   80|      0|            .unwrap();
   81|      0|    }
   82|       |
   83|      0|    pub fn count(&self, txn: &dyn Transaction) -> u64 {
   84|      0|        txn.count(self.database)
   85|      0|    }
   86|       |
   87|      0|    pub fn iter<'a>(&self, txn: &'a dyn Transaction) -> RepWeightIterator<'a> {
   88|      0|        let cursor = txn.open_ro_cursor(self.database).unwrap();
   89|      0|        RepWeightIterator {
   90|      0|            cursor,
   91|      0|            operation: MDB_FIRST,
   92|      0|        }
   93|      0|    }
   94|       |}
   95|       |
   96|       |pub struct RepWeightIterator<'txn> {
   97|       |    cursor: RoCursor<'txn>,
   98|       |    operation: MDB_cursor_op,
   99|       |}
  100|       |
  101|       |impl<'txn> Iterator for RepWeightIterator<'txn> {
  102|       |    type Item = (PublicKey, Amount);
  103|       |
  104|      0|    fn next(&mut self) -> Option<Self::Item> {
  105|      0|        match self.cursor.get(None, None, self.operation) {
  106|      0|            Err(lmdb::Error::NotFound) => None,
  107|      0|            Ok((Some(k), v)) => {
  108|      0|                self.operation = MDB_NEXT;
  109|      0|                Some((
  110|      0|                    PublicKey::from_slice(k).unwrap(),
  111|      0|                    Amount::from_be_bytes(v.try_into().unwrap()),
  112|      0|                ))
  113|       |            }
  114|      0|            Ok(_) => unreachable!(),
  115|      0|            Err(_) => unreachable!(),
  116|       |        }
  117|      0|    }
  118|       |}
  119|       |
  120|       |pub struct ConfiguredRepWeightDatabaseBuilder {
  121|       |    database: ConfiguredDatabase,
  122|       |}
  123|       |
  124|       |impl ConfiguredRepWeightDatabaseBuilder {
  125|      0|    pub fn new() -> Self {
  126|      0|        Self {
  127|      0|            database: ConfiguredDatabase::new(REP_WEIGHT_TEST_DATABASE, "rep_weights"),
  128|      0|        }
  129|      0|    }
  130|       |
  131|      0|    pub fn entry(mut self, account: PublicKey, weight: Amount) -> Self {
  132|      0|        self.database
  133|      0|            .entries
  134|      0|            .insert(account.as_bytes().to_vec(), weight.to_be_bytes().to_vec());
  135|      0|        self
  136|      0|    }
  137|       |
  138|      0|    pub fn build(self) -> ConfiguredDatabase {
  139|      0|        self.database
  140|      0|    }
  141|       |
  142|      0|    pub fn create(hashes: Vec<(PublicKey, Amount)>) -> ConfiguredDatabase {
  143|      0|        let mut builder = Self::new();
  144|      0|        for (account, weight) in hashes {
  145|      0|            builder = builder.entry(account, weight);
  146|      0|        }
  147|      0|        builder.build()
  148|      0|    }
  149|       |}
  150|       |
  151|       |#[cfg(test)]
  152|       |mod tests {
  153|       |    use lmdb::WriteFlags;
  154|       |
  155|       |    use super::*;
  156|       |    use crate::{DeleteEvent, LmdbEnv, PutEvent};
  157|       |
  158|       |    #[test]
  159|       |    fn count() {
  160|       |        let fixture =
  161|       |            Fixture::with_stored_data(vec![(1.into(), 100.into()), (2.into(), 200.into())]);
  162|       |        let txn = fixture.env.tx_begin_read();
  163|       |
  164|       |        assert_eq!(fixture.store.count(&txn), 2);
  165|       |    }
  166|       |
  167|       |    #[test]
  168|       |    fn put() {
  169|       |        let fixture = Fixture::new();
  170|       |        let mut txn = fixture.env.tx_begin_write();
  171|       |        let put_tracker = txn.track_puts();
  172|       |        let account = PublicKey::from(1);
  173|       |        let weight = Amount::from(42);
  174|       |
  175|       |        fixture.store.put(&mut txn, account, weight);
  176|       |
  177|       |        assert_eq!(
  178|       |            put_tracker.output(),
  179|       |            vec![PutEvent {
  180|       |                database: REP_WEIGHT_TEST_DATABASE.into(),
  181|       |                key: account.as_bytes().to_vec(),
  182|       |                value: weight.to_be_bytes().to_vec(),
  183|       |                flags: WriteFlags::empty()
  184|       |            }]
  185|       |        );
  186|       |    }
  187|       |
  188|       |    #[test]
  189|       |    fn load_weight() {
  190|       |        let account = PublicKey::from(1);
  191|       |        let weight = Amount::from(42);
  192|       |        let fixture = Fixture::with_stored_data(vec![(account, weight)]);
  193|       |        let txn = fixture.env.tx_begin_read();
  194|       |
  195|       |        let result = fixture.store.get(&txn, &account);
  196|       |
  197|       |        assert_eq!(result, Some(weight));
  198|       |    }
  199|       |
  200|       |    #[test]
  201|       |    fn delete() {
  202|       |        let fixture = Fixture::new();
  203|       |        let mut txn = fixture.env.tx_begin_write();
  204|       |        let delete_tracker = txn.track_deletions();
  205|       |        let account = PublicKey::from(1);
  206|       |
  207|       |        fixture.store.del(&mut txn, &account);
  208|       |
  209|       |        assert_eq!(
  210|       |            delete_tracker.output(),
  211|       |            vec![DeleteEvent {
  212|       |                database: REP_WEIGHT_TEST_DATABASE.into(),
  213|       |                key: account.as_bytes().to_vec()
  214|       |            }]
  215|       |        )
  216|       |    }
  217|       |
  218|       |    #[test]
  219|       |    fn iter_empty() {
  220|       |        let fixture = Fixture::new();
  221|       |        let txn = fixture.env.tx_begin_read();
  222|       |        let mut iter = fixture.store.iter(&txn);
  223|       |        assert_eq!(iter.next(), None);
  224|       |    }
  225|       |
  226|       |    #[test]
  227|       |    fn iter() {
  228|       |        let account1 = PublicKey::from(1);
  229|       |        let account2 = PublicKey::from(2);
  230|       |        let weight1 = Amount::from(100);
  231|       |        let weight2 = Amount::from(200);
  232|       |        let fixture = Fixture::with_stored_data(vec![(account1, weight1), (account2, weight2)]);
  233|       |
  234|       |        let txn = fixture.env.tx_begin_read();
  235|       |        let mut iter = fixture.store.iter(&txn);
  236|       |        assert_eq!(iter.next(), Some((account1, weight1)));
  237|       |        assert_eq!(iter.next(), Some((account2, weight2)));
  238|       |        assert_eq!(iter.next(), None);
  239|       |    }
  240|       |
  241|       |    struct Fixture {
  242|       |        env: Arc<LmdbEnv>,
  243|       |        store: LmdbRepWeightStore,
  244|       |    }
  245|       |
  246|       |    impl Fixture {
  247|       |        pub fn new() -> Self {
  248|       |            Self::with_stored_data(Vec::new())
  249|       |        }
  250|       |
  251|       |        pub fn with_stored_data(entries: Vec<(PublicKey, Amount)>) -> Self {
  252|       |            let env = LmdbEnv::new_null_with()
  253|       |                .configured_database(ConfiguredRepWeightDatabaseBuilder::create(entries))
  254|       |                .build();
  255|       |            let env = Arc::new(env);
  256|       |            Self {
  257|       |                env: env.clone(),
  258|       |                store: LmdbRepWeightStore::new(env).unwrap(),
  259|       |            }
  260|       |        }
  261|       |    }
  262|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/store.rs:
    1|       |use crate::{
    2|       |    EnvOptions, LmdbAccountStore, LmdbBlockStore, LmdbConfirmationHeightStore, LmdbDatabase,
    3|       |    LmdbEnv, LmdbFinalVoteStore, LmdbOnlineWeightStore, LmdbPeerStore, LmdbPendingStore,
    4|       |    LmdbPrunedStore, LmdbReadTransaction, LmdbRepWeightStore, LmdbVersionStore,
    5|       |    LmdbWriteTransaction, NullTransactionTracker, TransactionTracker, STORE_VERSION_CURRENT,
    6|       |    STORE_VERSION_MINIMUM,
    7|       |};
    8|       |use lmdb::{DatabaseFlags, WriteFlags};
    9|       |use lmdb_sys::{MDB_CP_COMPACT, MDB_SUCCESS};
   10|       |use rsnano_core::utils::UnixTimestamp;
   11|       |use serde::{Deserialize, Serialize};
   12|       |use std::{
   13|       |    ffi::CString,
   14|       |    path::{Path, PathBuf},
   15|       |    sync::{
   16|       |        atomic::{AtomicU64, Ordering},
   17|       |        Arc,
   18|       |    },
   19|       |};
   20|       |use tracing::{debug, error, info, warn};
   21|       |
   22|       |#[derive(PartialEq, Eq)]
   23|       |pub enum Vacuuming {
   24|       |    Needed,
   25|       |    NotNeeded,
   26|       |}
   27|       |
   28|       |pub struct LedgerCache {
   29|       |    pub cemented_count: AtomicU64,
   30|       |    pub block_count: AtomicU64,
   31|       |    pub pruned_count: AtomicU64,
   32|       |    pub account_count: AtomicU64,
   33|       |}
   34|       |
   35|       |impl LedgerCache {
   36|     59|    pub fn new() -> Self {
   37|     59|        Self {
   38|     59|            cemented_count: AtomicU64::new(0),
   39|     59|            block_count: AtomicU64::new(0),
   40|     59|            pruned_count: AtomicU64::new(0),
   41|     59|            account_count: AtomicU64::new(0),
   42|     59|        }
   43|     59|    }
   44|       |
   45|      0|    pub fn reset(&self) {
   46|      0|        self.cemented_count.store(0, Ordering::SeqCst);
   47|      0|        self.block_count.store(0, Ordering::SeqCst);
   48|      0|        self.pruned_count.store(0, Ordering::SeqCst);
   49|      0|        self.account_count.store(0, Ordering::SeqCst);
   50|      0|    }
   51|       |}
   52|       |
   53|       |pub struct LmdbStore {
   54|       |    pub env: Arc<LmdbEnv>,
   55|       |    pub cache: Arc<LedgerCache>,
   56|       |    pub block: Arc<LmdbBlockStore>,
   57|       |    pub account: Arc<LmdbAccountStore>,
   58|       |    pub pending: Arc<LmdbPendingStore>,
   59|       |    pub online_weight: Arc<LmdbOnlineWeightStore>,
   60|       |    pub pruned: Arc<LmdbPrunedStore>,
   61|       |    pub rep_weight: Arc<LmdbRepWeightStore>,
   62|       |    pub peer: Arc<LmdbPeerStore>,
   63|       |    pub confirmation_height: Arc<LmdbConfirmationHeightStore>,
   64|       |    pub final_vote: Arc<LmdbFinalVoteStore>,
   65|       |    pub version: Arc<LmdbVersionStore>,
   66|       |}
   67|       |
   68|       |pub struct LmdbStoreBuilder<'a> {
   69|       |    path: &'a Path,
   70|       |    options: Option<&'a EnvOptions>,
   71|       |    tracker: Option<Arc<dyn TransactionTracker>>,
   72|       |    backup_before_upgrade: bool,
   73|       |}
   74|       |
   75|       |impl<'a> LmdbStoreBuilder<'a> {
   76|      5|    fn new(path: &'a Path) -> Self {
   77|      5|        Self {
   78|      5|            path,
   79|      5|            options: None,
   80|      5|            tracker: None,
   81|      5|            backup_before_upgrade: false,
   82|      5|        }
   83|      5|    }
   84|       |
   85|      3|    pub fn options(mut self, options: &'a EnvOptions) -> Self {
   86|      3|        self.options = Some(options);
   87|      3|        self
   88|      3|    }
   89|       |
   90|      3|    pub fn txn_tracker(mut self, tracker: Arc<dyn TransactionTracker>) -> Self {
   91|      3|        self.tracker = Some(tracker);
   92|      3|        self
   93|      3|    }
   94|       |
   95|      3|    pub fn backup_before_upgrade(mut self, backup: bool) -> Self {
   96|      3|        self.backup_before_upgrade = backup;
   97|      3|        self
   98|      3|    }
   99|       |
  100|      5|    pub fn build(self) -> anyhow::Result<LmdbStore> {
  101|      5|        let default_options = Default::default();
  102|      5|        let options = self.options.unwrap_or(&default_options);
  103|      5|
  104|      5|        let txn_tracker = self
  105|      5|            .tracker
  106|      5|            .unwrap_or_else(|| Arc::new(NullTransactionTracker::new()));
                                             ^2
  107|      5|
  108|      5|        LmdbStore::new(self.path, options, txn_tracker, self.backup_before_upgrade)
  109|      5|    }
  110|       |}
  111|       |
  112|       |impl LmdbStore {
  113|      2|    pub fn new_null() -> Self {
  114|      2|        Self::new_with_env(LmdbEnv::new_null()).unwrap()
  115|      2|    }
  116|       |
  117|      5|    pub fn open(path: &Path) -> LmdbStoreBuilder<'_> {
  118|      5|        LmdbStoreBuilder::new(path)
  119|      5|    }
  120|       |
  121|      5|    fn new(
  122|      5|        path: impl AsRef<Path>,
  123|      5|        options: &EnvOptions,
  124|      5|        txn_tracker: Arc<dyn TransactionTracker>,
  125|      5|        backup_before_upgrade: bool,
  126|      5|    ) -> anyhow::Result<Self> {
  127|      5|        let path = path.as_ref();
  128|      5|        upgrade_if_needed(path, backup_before_upgrade)?;
                                                                    ^0
  129|       |
  130|      5|        let env = LmdbEnv::new_with_txn_tracker(path, options, txn_tracker)?;
                                                                                         ^0
  131|      5|        Self::new_with_env(env)
  132|      5|    }
  133|       |
  134|      7|    fn new_with_env(env: LmdbEnv) -> anyhow::Result<Self> {
  135|      7|        let env = Arc::new(env);
  136|      7|        Ok(Self {
  137|      7|            cache: Arc::new(LedgerCache::new()),
  138|      7|            block: Arc::new(LmdbBlockStore::new(env.clone())?),
                                                                          ^0
  139|      7|            account: Arc::new(LmdbAccountStore::new(env.clone())?),
                                                                              ^0
  140|      7|            pending: Arc::new(LmdbPendingStore::new(env.clone())?),
                                                                              ^0
  141|      7|            online_weight: Arc::new(LmdbOnlineWeightStore::new(env.clone())?),
                                                                                         ^0
  142|      7|            pruned: Arc::new(LmdbPrunedStore::new(env.clone())?),
                                                                            ^0
  143|      7|            rep_weight: Arc::new(LmdbRepWeightStore::new(env.clone())?),
                                                                                   ^0
  144|      7|            peer: Arc::new(LmdbPeerStore::new(env.clone())?),
                                                                        ^0
  145|      7|            confirmation_height: Arc::new(LmdbConfirmationHeightStore::new(env.clone())?),
                                                                                                     ^0
  146|      7|            final_vote: Arc::new(LmdbFinalVoteStore::new(env.clone())?),
                                                                                   ^0
  147|      7|            version: Arc::new(LmdbVersionStore::new(env.clone())?),
                                                                              ^0
  148|      7|            env,
  149|       |        })
  150|      7|    }
  151|       |
  152|      0|    pub fn copy_db(&self, destination: &Path) -> anyhow::Result<()> {
  153|      0|        copy_db(&self.env, destination)
  154|      0|    }
  155|       |
  156|      0|    pub fn rebuild_db(&self, txn: &mut LmdbWriteTransaction) -> anyhow::Result<()> {
  157|      0|        let tables = [
  158|      0|            self.account.database(),
  159|      0|            self.block.database(),
  160|      0|            self.pruned.database(),
  161|      0|            self.confirmation_height.database(),
  162|      0|            self.pending.database(),
  163|      0|        ];
  164|      0|        for table in tables {
  165|      0|            rebuild_table(&self.env, txn, table)?;
  166|       |        }
  167|       |
  168|      0|        Ok(())
  169|      0|    }
  170|       |
  171|      0|    pub fn memory_stats(&self) -> anyhow::Result<MemoryStats> {
  172|      0|        let stats = self.env.environment.stat()?;
  173|      0|        Ok(MemoryStats {
  174|      0|            branch_pages: stats.branch_pages(),
  175|      0|            depth: stats.depth(),
  176|      0|            entries: stats.entries(),
  177|      0|            leaf_pages: stats.leaf_pages(),
  178|      0|            overflow_pages: stats.overflow_pages(),
  179|      0|            page_size: stats.page_size(),
  180|      0|        })
  181|      0|    }
  182|       |
  183|      0|    pub fn vendor(&self) -> String {
  184|      0|        // fake version! TODO: read version
  185|      0|        format!("lmdb-rkv {}.{}.{}", 0, 14, 0)
  186|      0|    }
  187|       |
  188|    172|    pub fn tx_begin_read(&self) -> LmdbReadTransaction {
  189|    172|        self.env.tx_begin_read()
  190|    172|    }
  191|       |
  192|     74|    pub fn tx_begin_write(&self) -> LmdbWriteTransaction {
  193|     74|        self.env.tx_begin_write()
  194|     74|    }
  195|       |}
  196|       |
  197|      5|fn upgrade_if_needed(path: &Path, backup_before_upgrade: bool) -> Result<(), anyhow::Error> {
  198|      5|    let upgrade_info = LmdbVersionStore::check_upgrade(path)?;
                                                                          ^0
  199|      5|    if upgrade_info.is_fully_upgraded {
  200|      0|        debug!("No database upgrade needed");
  201|      0|        return Ok(());
  202|      5|    }
  203|       |
  204|      5|    let env = Arc::new(LmdbEnv::new(path)?);
                                                       ^0
  205|      5|    if !upgrade_info.is_fresh_db && backup_before_upgrade {
                                                  ^0
  206|      0|        create_backup_file(&env)?;
  207|      5|    }
  208|       |
  209|      5|    info!("Upgrade in progress...");
                        ^0
  210|      5|    let vacuuming = do_upgrades(env.clone())?;
                                                          ^0
  211|      5|    info!("Upgrade done!");
                        ^0
  212|       |
  213|      5|    if vacuuming == Vacuuming::Needed {
  214|      0|        info!("Preparing vacuum...");
  215|      0|        match vacuum_after_upgrade (env, path){
  216|      0|                Ok(_) => info!("Vacuum succeeded."),
  217|      0|                Err(_) => warn!("Failed to vacuum. (Optional) Ensure enough disk space is available for a copy of the database and try to vacuum after shutting down the node"),
  218|       |            }
  219|      5|    }
  220|      5|    Ok(())
  221|      5|}
  222|       |
  223|      0|fn rebuild_table(
  224|      0|    env: &LmdbEnv,
  225|      0|    rw_txn: &mut LmdbWriteTransaction,
  226|      0|    db: LmdbDatabase,
  227|      0|) -> anyhow::Result<()> {
  228|      0|    let temp = unsafe {
  229|      0|        rw_txn
  230|      0|            .rw_txn_mut()
  231|      0|            .create_db(Some("temp_table"), DatabaseFlags::empty())
  232|      0|    }?;
  233|      0|    copy_table(env, rw_txn, db, temp)?;
  234|      0|    crate::Transaction::refresh(rw_txn);
  235|      0|    rw_txn.clear_db(db)?;
  236|      0|    copy_table(env, rw_txn, temp, db)?;
  237|      0|    unsafe { rw_txn.rw_txn_mut().drop_db(temp) }?;
  238|      0|    crate::Transaction::refresh(rw_txn);
  239|      0|    Ok(())
  240|      0|}
  241|       |
  242|      0|fn copy_table(
  243|      0|    env: &LmdbEnv,
  244|      0|    rw_txn: &mut LmdbWriteTransaction,
  245|      0|    source: LmdbDatabase,
  246|      0|    target: LmdbDatabase,
  247|      0|) -> anyhow::Result<()> {
  248|      0|    let ro_txn = env.tx_begin_read();
  249|       |    {
  250|      0|        let mut cursor = ro_txn.txn().open_ro_cursor(source)?;
  251|      0|        for x in cursor.iter_start() {
  252|      0|            let (k, v) = x?;
  253|      0|            rw_txn.put(target, k, v, WriteFlags::APPEND)?;
  254|       |        }
  255|       |    }
  256|      0|    if ro_txn.txn().count(source) != rw_txn.rw_txn_mut().count(target) {
  257|      0|        bail!("table count mismatch");
  258|      0|    }
  259|      0|    Ok(())
  260|      0|}
  261|       |
  262|      5|fn do_upgrades(env: Arc<LmdbEnv>) -> anyhow::Result<Vacuuming> {
  263|      5|    let version_store = LmdbVersionStore::new(env.clone())?;
                                                                        ^0
  264|      5|    let mut txn = env.tx_begin_write();
  265|       |
  266|      5|    let version = match version_store.get(&txn) {
  267|      0|        Some(v) => v,
  268|       |        None => {
  269|      5|            let new_version = STORE_VERSION_MINIMUM;
  270|      5|            info!("Setting db version to {}", new_version);
                                ^0
  271|      5|            version_store.put(&mut txn, new_version);
  272|      5|            new_version
  273|       |        }
  274|       |    };
  275|       |
  276|      5|    if version < STORE_VERSION_MINIMUM {
  277|      0|        error!("The version of the ledger ({}) is lower than the minimum ({}) which is supported for upgrades. Either upgrade to a v24 node first or delete the ledger.", version, STORE_VERSION_MINIMUM);
  278|      0|        bail!("version too low");
  279|      5|    }
  280|      5|
  281|      5|    if version > STORE_VERSION_CURRENT {
  282|      0|        error!(
  283|      0|            "The version of the ledger ({}) is too high for this node",
  284|       |            version
  285|       |        );
  286|      0|        bail!("version too high");
  287|      5|    }
  288|      5|
  289|      5|    // most recent version
  290|      5|    Ok(Vacuuming::NotNeeded)
  291|      5|}
  292|       |
  293|      0|fn vacuum_after_upgrade(env: Arc<LmdbEnv>, path: &Path) -> anyhow::Result<()> {
  294|      0|    // Vacuum the database. This is not a required step and may actually fail if there isn't enough storage space.
  295|      0|    let mut vacuum_path = path.to_owned();
  296|      0|    vacuum_path.pop();
  297|      0|    vacuum_path.push("vacuumed.ldb");
  298|      0|
  299|      0|    match copy_db(&env, &vacuum_path) {
  300|       |        Ok(_) => {
  301|       |            //todo don't use Arc here! Env must be dropped!
  302|      0|            drop(env);
  303|      0|
  304|      0|            // Replace the ledger file with the vacuumed one
  305|      0|            std::fs::rename(&vacuum_path, path)?;
  306|      0|            Ok(())
  307|       |        }
  308|      0|        Err(e) => {
  309|      0|            // The vacuum file can be in an inconsistent state if there wasn't enough space to create it
  310|      0|            let _ = std::fs::remove_file(&vacuum_path);
  311|      0|            Err(e)
  312|       |        }
  313|       |    }
  314|      0|}
  315|      0|fn copy_db(env: &LmdbEnv, destination: &Path) -> anyhow::Result<()> {
  316|      0|    let c_path = CString::new(destination.as_os_str().to_str().unwrap()).unwrap();
  317|      0|    let status =
  318|      0|        unsafe { lmdb_sys::mdb_env_copy2(env.environment.env(), c_path.as_ptr(), MDB_CP_COMPACT) };
  319|      0|    ensure_success(status)
  320|      0|}
  321|       |
  322|      0|fn ensure_success(status: i32) -> Result<(), anyhow::Error> {
  323|      0|    if status == MDB_SUCCESS {
  324|      0|        Ok(())
  325|       |    } else {
  326|      0|        Err(anyhow!("lmdb returned status code {}", status))
  327|       |    }
  328|      0|}
  329|       |
  330|      0|#[derive(Serialize, Deserialize)]
  331|       |pub struct MemoryStats {
  332|       |    pub branch_pages: usize,
  333|       |    pub depth: u32,
  334|       |    pub entries: usize,
  335|       |    pub leaf_pages: usize,
  336|       |    pub overflow_pages: usize,
  337|       |    pub page_size: u32,
  338|       |}
  339|       |
  340|       |/// Takes a filepath, appends '_backup_<timestamp>' to the end (but before any extension) and saves that file in the same directory
  341|      0|pub fn create_backup_file(env: &LmdbEnv) -> anyhow::Result<()> {
  342|      0|    let source_path = env.file_path()?;
  343|      0|    let backup_path = backup_file_path(&source_path)?;
  344|       |
  345|      0|    info!(
  346|      0|        "Performing {:?} backup before database upgrade...",
  347|       |        source_path
  348|       |    );
  349|       |
  350|      0|    let backup_path_cstr = CString::new(
  351|      0|        backup_path
  352|      0|            .as_os_str()
  353|      0|            .to_str()
  354|      0|            .ok_or_else(|| anyhow!("invalid backup path"))?,
  355|      0|    )?;
  356|      0|    let status =
  357|      0|        unsafe { lmdb_sys::mdb_env_copy(env.environment.env(), backup_path_cstr.as_ptr()) };
  358|      0|    if status != MDB_SUCCESS {
  359|      0|        error!("{:?} backup failed", source_path);
  360|      0|        Err(anyhow!("backup failed"))
  361|       |    } else {
  362|      0|        info!("Backup created: {:?}", backup_path);
  363|      0|        Ok(())
  364|       |    }
  365|      0|}
  366|       |
  367|      0|fn backup_file_path(source_path: &Path) -> anyhow::Result<PathBuf> {
  368|      0|    let extension = source_path
  369|      0|        .extension()
  370|      0|        .ok_or_else(|| anyhow!("no extension"))?
  371|      0|        .to_str()
  372|      0|        .ok_or_else(|| anyhow!("invalid extension"))?;
  373|       |
  374|      0|    let mut backup_path = source_path
  375|      0|        .parent()
  376|      0|        .ok_or_else(|| anyhow!("no parent path"))?
  377|      0|        .to_owned();
  378|       |
  379|      0|    let file_stem = source_path
  380|      0|        .file_stem()
  381|      0|        .ok_or_else(|| anyhow!("no file stem"))?
  382|      0|        .to_str()
  383|      0|        .ok_or_else(|| anyhow!("invalid file stem"))?;
  384|       |
  385|      0|    let backup_filename = format!(
  386|      0|        "{}_backup_{}.{}",
  387|      0|        file_stem,
  388|      0|        UnixTimestamp::now(),
  389|      0|        extension
  390|      0|    );
  391|      0|    backup_path.push(&backup_filename);
  392|      0|    Ok(backup_path)
  393|      0|}
  394|       |
  395|       |#[cfg(test)]
  396|       |mod tests {
  397|       |    use super::*;
  398|       |    use crate::TestDbFile;
  399|       |
  400|       |    #[test]
  401|       |    fn create_store() -> anyhow::Result<()> {
  402|       |        let file = TestDbFile::random();
  403|       |        let _ = LmdbStore::open(&file.path).build()?;
  404|       |        Ok(())
  405|       |    }
  406|       |
  407|       |    #[test]
  408|       |    fn version_too_high_for_upgrade() -> anyhow::Result<()> {
  409|       |        let file = TestDbFile::random();
  410|       |        set_store_version(&file, i32::MAX)?;
  411|       |        assert_upgrade_fails(&file.path, "version too high");
  412|       |        Ok(())
  413|       |    }
  414|       |
  415|       |    #[test]
  416|       |    fn version_too_low_for_upgrade() -> anyhow::Result<()> {
  417|       |        let file = TestDbFile::random();
  418|       |        set_store_version(&file, STORE_VERSION_MINIMUM - 1)?;
  419|       |        assert_upgrade_fails(&file.path, "version too low");
  420|       |        Ok(())
  421|       |    }
  422|       |
  423|       |    #[test]
  424|       |    fn writes_db_version_for_new_store() {
  425|       |        let file = TestDbFile::random();
  426|       |        let store = LmdbStore::open(&file.path).build().unwrap();
  427|       |        let txn = store.tx_begin_read();
  428|       |        assert_eq!(store.version.get(&txn), Some(STORE_VERSION_MINIMUM));
  429|       |    }
  430|       |
  431|       |    fn assert_upgrade_fails(path: &Path, error_msg: &str) {
  432|       |        match LmdbStore::open(path).build() {
  433|       |            Ok(_) => panic!("store should not be created!"),
  434|       |            Err(e) => {
  435|       |                assert_eq!(e.to_string(), error_msg);
  436|       |            }
  437|       |        }
  438|       |    }
  439|       |
  440|       |    fn set_store_version(file: &TestDbFile, current_version: i32) -> Result<(), anyhow::Error> {
  441|       |        let env = Arc::new(LmdbEnv::new(&file.path)?);
  442|       |        let version_store = LmdbVersionStore::new(env.clone())?;
  443|       |        let mut txn = env.tx_begin_write();
  444|       |        version_store.put(&mut txn, current_version);
  445|       |        Ok(())
  446|       |    }
  447|       |}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/version_store.rs:
    1|       |use crate::{LmdbDatabase, LmdbEnv, LmdbWriteTransaction, Transaction, STORE_VERSION_CURRENT};
    2|       |use core::panic;
    3|       |use lmdb::{DatabaseFlags, WriteFlags};
    4|       |use std::{path::Path, sync::Arc};
    5|       |
    6|       |pub struct LmdbVersionStore {
    7|       |    _env: Arc<LmdbEnv>,
    8|       |
    9|       |    /// U256 (arbitrary key) -> blob
   10|       |    db_handle: LmdbDatabase,
   11|       |}
   12|       |
   13|       |pub struct UpgradeInfo {
   14|       |    pub is_fresh_db: bool,
   15|       |    pub is_fully_upgraded: bool,
   16|       |}
   17|       |
   18|       |impl LmdbVersionStore {
   19|     32|    pub fn new(env: Arc<LmdbEnv>) -> anyhow::Result<Self> {
   20|     32|        let db_handle = env
   21|     32|            .environment
   22|     32|            .create_db(Some("meta"), DatabaseFlags::empty())?;
                                                                          ^0
   23|     32|        Ok(Self {
   24|     32|            _env: env,
   25|     32|            db_handle,
   26|     32|        })
   27|     32|    }
   28|       |
   29|      5|    pub fn try_read_version(env: &LmdbEnv) -> Option<i32> {
   30|      5|        match env.environment.open_db(Some("meta")) {
   31|      0|            Ok(db) => {
   32|      0|                let txn = env.tx_begin_read();
   33|      0|                load_version(&txn, db)
   34|       |            }
   35|      5|            Err(_) => None,
   36|       |        }
   37|      5|    }
   38|       |
   39|      5|    pub fn check_upgrade(path: &Path) -> anyhow::Result<UpgradeInfo> {
   40|      5|        let env = LmdbEnv::new(path)?;
                                                  ^0
   41|      5|        let info = match LmdbVersionStore::try_read_version(&env) {
   42|      0|            Some(version) => UpgradeInfo {
   43|      0|                is_fresh_db: false,
   44|      0|                is_fully_upgraded: version == STORE_VERSION_CURRENT,
   45|      0|            },
   46|      5|            None => UpgradeInfo {
   47|      5|                is_fresh_db: true,
   48|      5|                is_fully_upgraded: false,
   49|      5|            },
   50|       |        };
   51|      5|        Ok(info)
   52|      5|    }
   53|       |
   54|     10|    pub fn db_handle(&self) -> LmdbDatabase {
   55|     10|        self.db_handle
   56|     10|    }
   57|       |
   58|      5|    pub fn put(&self, txn: &mut LmdbWriteTransaction, version: i32) {
   59|      5|        let db = self.db_handle();
   60|      5|
   61|      5|        let key_bytes = version_key();
   62|      5|        let value_bytes = value_bytes(version);
   63|      5|
   64|      5|        txn.put(db, &key_bytes, &value_bytes, WriteFlags::empty())
   65|      5|            .unwrap();
   66|      5|    }
   67|       |
   68|      5|    pub fn get(&self, txn: &dyn Transaction) -> Option<i32> {
   69|      5|        let db = self.db_handle();
   70|      5|        load_version(txn, db)
   71|      5|    }
   72|       |}
   73|       |
   74|      5|fn load_version(txn: &dyn Transaction, db: LmdbDatabase) -> Option<i32> {
   75|      5|    let key_bytes = version_key();
   76|      5|    match txn.get(db, &key_bytes) {
   77|      0|        Ok(value) => Some(i32::from_be_bytes(value[28..].try_into().unwrap())),
   78|      5|        Err(lmdb::Error::NotFound) => None,
   79|      0|        Err(_) => panic!("Error while loading db version"),
   80|       |    }
   81|      5|}
   82|       |
   83|     15|fn value_bytes(version: i32) -> [u8; 32] {
   84|     15|    let mut value_bytes = [0; 32];
   85|     15|    value_bytes[28..].copy_from_slice(&version.to_be_bytes());
   86|     15|    value_bytes
   87|     15|}
   88|       |
   89|     10|fn version_key() -> [u8; 32] {
   90|     10|    value_bytes(1)
   91|     10|}

/home/gustav/code/nano/rsnano-node/store_lmdb/src/wallet_store.rs:
    1|       |use crate::{Fan, LmdbDatabase, LmdbRangeIterator, LmdbWriteTransaction, Transaction};
    2|       |use anyhow::bail;
    3|       |use lmdb::{DatabaseFlags, WriteFlags};
    4|       |use rsnano_core::{
    5|       |    deterministic_key,
    6|       |    utils::{
    7|       |        BufferReader, BufferWriter, Deserialize, FixedSizeSerialize, MutStreamAdapter, Serialize,
    8|       |        Stream, StreamExt,
    9|       |    },
   10|       |    Account, KeyDerivationFunction, PublicKey, RawKey,
   11|       |};
   12|       |use std::{
   13|       |    fs::{set_permissions, File, Permissions},
   14|       |    os::unix::prelude::PermissionsExt,
   15|       |    path::Path,
   16|       |    sync::{Mutex, MutexGuard},
   17|       |};
   18|       |use std::{io::Write, ops::RangeBounds};
   19|       |
   20|       |pub struct Fans {
   21|       |    pub password: Fan,
   22|       |    pub wallet_key_mem: Fan,
   23|       |}
   24|       |
   25|       |impl Fans {
   26|      0|    pub fn new(fanout: usize) -> Self {
   27|      0|        Self {
   28|      0|            password: Fan::new(RawKey::zero(), fanout),
   29|      0|            wallet_key_mem: Fan::new(RawKey::zero(), fanout),
   30|      0|        }
   31|      0|    }
   32|       |}
   33|       |
   34|       |pub struct WalletValue {
   35|       |    pub key: RawKey,
   36|       |    pub work: u64,
   37|       |}
   38|       |
   39|       |impl WalletValue {
   40|      0|    pub fn new(key: RawKey, work: u64) -> Self {
   41|      0|        Self { key, work }
   42|      0|    }
   43|       |
   44|      0|    pub fn to_bytes(&self) -> [u8; 40] {
   45|      0|        let mut buffer = [0; 40];
   46|      0|        let mut stream = MutStreamAdapter::new(&mut buffer);
   47|      0|        self.serialize(&mut stream);
   48|      0|        buffer
   49|      0|    }
   50|       |}
   51|       |
   52|       |impl Serialize for WalletValue {
   53|      0|    fn serialize(&self, writer: &mut dyn BufferWriter) {
   54|      0|        self.key.serialize(writer);
   55|      0|        writer.write_u64_ne_safe(self.work);
   56|      0|    }
   57|       |}
   58|       |
   59|       |impl FixedSizeSerialize for WalletValue {
   60|      0|    fn serialized_size() -> usize {
   61|      0|        RawKey::serialized_size()
   62|      0|    }
   63|       |}
   64|       |
   65|       |impl Deserialize for WalletValue {
   66|       |    type Target = Self;
   67|       |
   68|      0|    fn deserialize(stream: &mut dyn Stream) -> anyhow::Result<Self::Target> {
   69|      0|        let key = RawKey::deserialize(stream)?;
   70|      0|        let work = stream.read_u64_ne()?;
   71|      0|        Ok(WalletValue::new(key, work))
   72|      0|    }
   73|       |}
   74|       |
   75|      0|#[derive(FromPrimitive)]
   76|       |pub enum KeyType {
   77|       |    NotAType,
   78|       |    Unknown,
   79|       |    Adhoc,
   80|       |    Deterministic,
   81|       |}
   82|       |
   83|       |pub struct LmdbWalletStore {
   84|       |    db_handle: Mutex<Option<LmdbDatabase>>,
   85|       |    pub fans: Mutex<Fans>,
   86|       |    kdf: KeyDerivationFunction,
   87|       |}
   88|       |
   89|       |impl LmdbWalletStore {
   90|       |    pub const VERSION_CURRENT: u32 = 4;
   91|      0|    pub fn new(
   92|      0|        fanout: usize,
   93|      0|        kdf: KeyDerivationFunction,
   94|      0|        txn: &mut LmdbWriteTransaction,
   95|      0|        representative: &PublicKey,
   96|      0|        wallet: &Path,
   97|      0|    ) -> anyhow::Result<Self> {
   98|      0|        let store = Self {
   99|      0|            db_handle: Mutex::new(None),
  100|      0|            fans: Mutex::new(Fans::new(fanout)),
  101|      0|            kdf,
  102|      0|        };
  103|      0|        store.initialize(txn, wallet)?;
  104|      0|        let handle = store.db_handle();
  105|      0|        if let Err(lmdb::Error::NotFound) = txn.get(handle, Self::version_special().as_bytes()) {
  106|      0|            store.version_put(txn, Self::VERSION_CURRENT);
  107|      0|            let salt = RawKey::random();
  108|      0|            store.entry_put_raw(txn, &Self::salt_special(), &WalletValue::new(salt, 0));
  109|      0|            // Wallet key is a fixed random key that encrypts all entries
  110|      0|            let wallet_key = RawKey::random();
  111|      0|            let password = RawKey::zero();
  112|      0|            let mut guard = store.fans.lock().unwrap();
  113|      0|            guard.password.value_set(password);
  114|      0|            let zero = RawKey::zero();
  115|      0|            // Wallet key is encrypted by the user's password
  116|      0|            let encrypted = wallet_key.encrypt(&zero, &salt.initialization_vector_low());
  117|      0|            store.entry_put_raw(
  118|      0|                txn,
  119|      0|                &Self::wallet_key_special(),
  120|      0|                &WalletValue::new(encrypted, 0),
  121|      0|            );
  122|      0|            let wallet_key_enc = encrypted;
  123|      0|            guard.wallet_key_mem.value_set(wallet_key_enc);
  124|      0|            drop(guard);
  125|      0|            let check = zero.encrypt(&wallet_key, &salt.initialization_vector_low());
  126|      0|            store.entry_put_raw(txn, &Self::check_special(), &WalletValue::new(check, 0));
  127|      0|            let rep = RawKey::from_bytes(*representative.as_bytes());
  128|      0|            store.entry_put_raw(
  129|      0|                txn,
  130|      0|                &Self::representative_special(),
  131|      0|                &WalletValue::new(rep, 0),
  132|      0|            );
  133|      0|            let seed = RawKey::random();
  134|      0|            store.set_seed(txn, &seed);
  135|      0|            store.entry_put_raw(
  136|      0|                txn,
  137|      0|                &Self::deterministic_index_special(),
  138|      0|                &WalletValue::new(RawKey::zero(), 0),
  139|      0|            );
  140|      0|        }
  141|      0|        {
  142|      0|            let key = store.entry_get_raw(txn, &Self::wallet_key_special()).key;
  143|      0|            let mut guard = store.fans.lock().unwrap();
  144|      0|            guard.wallet_key_mem.value_set(key);
  145|      0|        }
  146|      0|        Ok(store)
  147|      0|    }
  148|       |
  149|      0|    pub fn new_from_json(
  150|      0|        fanout: usize,
  151|      0|        kdf: KeyDerivationFunction,
  152|      0|        txn: &mut LmdbWriteTransaction,
  153|      0|        wallet: &Path,
  154|      0|        json: &str,
  155|      0|    ) -> anyhow::Result<Self> {
  156|      0|        let store = Self {
  157|      0|            db_handle: Mutex::new(None),
  158|      0|            fans: Mutex::new(Fans::new(fanout)),
  159|      0|            kdf,
  160|      0|        };
  161|      0|        store.initialize(txn, wallet)?;
  162|      0|        let handle = store.db_handle();
  163|      0|        match txn.get(handle, Self::version_special().as_bytes()) {
  164|      0|            Ok(_) => panic!("wallet store already initialized"),
  165|      0|            Err(lmdb::Error::NotFound) => {}
  166|      0|            Err(e) => panic!("unexpected wallet store error: {:?}", e),
  167|       |        }
  168|       |
  169|      0|        let json: serde_json::Value = serde_json::from_str(json)?;
  170|      0|        if let serde_json::Value::Object(map) = json {
  171|      0|            for (k, v) in map.iter() {
  172|      0|                if let serde_json::Value::String(v_str) = v {
  173|      0|                    let key = PublicKey::decode_hex(k)?;
  174|      0|                    let value = RawKey::decode_hex(v_str)?;
  175|      0|                    store.entry_put_raw(txn, &key, &WalletValue::new(value, 0));
  176|       |                } else {
  177|      0|                    bail!("expected string value");
  178|       |                }
  179|       |            }
  180|       |        } else {
  181|      0|            bail!("invalid json")
  182|       |        }
  183|       |
  184|      0|        store.ensure_key_exists(txn, &Self::version_special())?;
  185|      0|        store.ensure_key_exists(txn, &Self::wallet_key_special())?;
  186|      0|        store.ensure_key_exists(txn, &Self::salt_special())?;
  187|      0|        store.ensure_key_exists(txn, &Self::check_special())?;
  188|      0|        store.ensure_key_exists(txn, &Self::representative_special())?;
  189|      0|        let mut guard = store.fans.lock().unwrap();
  190|      0|        guard.password.value_set(RawKey::zero());
  191|      0|        let key = store.entry_get_raw(txn, &Self::wallet_key_special()).key;
  192|      0|        guard.wallet_key_mem.value_set(key);
  193|      0|        drop(guard);
  194|      0|        Ok(store)
  195|      0|    }
  196|       |
  197|      0|    pub fn password(&self) -> RawKey {
  198|      0|        self.fans.lock().unwrap().password.value()
  199|      0|    }
  200|       |
  201|      0|    fn ensure_key_exists(&self, txn: &dyn Transaction, key: &PublicKey) -> anyhow::Result<()> {
  202|      0|        txn.get(self.db_handle(), key.as_bytes())?;
  203|      0|        Ok(())
  204|      0|    }
  205|       |
  206|       |    /// Wallet version number
  207|      0|    pub fn version_special() -> PublicKey {
  208|      0|        PublicKey::from(0)
  209|      0|    }
  210|       |
  211|       |    /// Random number used to salt private key encryption
  212|      0|    pub fn salt_special() -> PublicKey {
  213|      0|        PublicKey::from(1)
  214|      0|    }
  215|       |
  216|       |    /// Key used to encrypt wallet keys, encrypted itself by the user password
  217|      0|    pub fn wallet_key_special() -> PublicKey {
  218|      0|        PublicKey::from(2)
  219|      0|    }
  220|       |
  221|       |    /// Check value used to see if password is valid
  222|      0|    pub fn check_special() -> PublicKey {
  223|      0|        PublicKey::from(3)
  224|      0|    }
  225|       |
  226|       |    /// Representative account to be used if we open a new account
  227|      0|    pub fn representative_special() -> PublicKey {
  228|      0|        PublicKey::from(4)
  229|      0|    }
  230|       |
  231|       |    /// Wallet seed for deterministic key generation
  232|      0|    pub fn seed_special() -> PublicKey {
  233|      0|        PublicKey::from(5)
  234|      0|    }
  235|       |
  236|       |    /// Current key index for deterministic keys
  237|      0|    pub fn deterministic_index_special() -> PublicKey {
  238|      0|        PublicKey::from(6)
  239|      0|    }
  240|       |
  241|      0|    pub fn special_count() -> PublicKey {
  242|      0|        PublicKey::from(7)
  243|      0|    }
  244|       |
  245|      0|    pub fn initialize(&self, txn: &mut LmdbWriteTransaction, path: &Path) -> anyhow::Result<()> {
  246|      0|        let path_str = path
  247|      0|            .as_os_str()
  248|      0|            .to_str()
  249|      0|            .ok_or_else(|| anyhow!("invalid path"))?;
  250|      0|        let db = unsafe {
  251|      0|            txn.rw_txn_mut()
  252|      0|                .create_db(Some(path_str), DatabaseFlags::empty())
  253|      0|        }?;
  254|      0|        *self.db_handle.lock().unwrap() = Some(db);
  255|      0|        Ok(())
  256|      0|    }
  257|       |
  258|      0|    pub fn db_handle(&self) -> LmdbDatabase {
  259|      0|        self.db_handle.lock().unwrap().unwrap().clone()
  260|      0|    }
  261|       |
  262|      0|    pub fn entry_get_raw(&self, txn: &dyn Transaction, pub_key: &PublicKey) -> WalletValue {
  263|      0|        match txn.get(self.db_handle(), pub_key.as_bytes()) {
  264|      0|            Ok(bytes) => {
  265|      0|                let mut stream = BufferReader::new(bytes);
  266|      0|                WalletValue::deserialize(&mut stream).unwrap()
  267|       |            }
  268|      0|            _ => WalletValue::new(RawKey::zero(), 0),
  269|       |        }
  270|      0|    }
  271|       |
  272|      0|    pub fn entry_put_raw(
  273|      0|        &self,
  274|      0|        txn: &mut LmdbWriteTransaction,
  275|      0|        pub_key: &PublicKey,
  276|      0|        entry: &WalletValue,
  277|      0|    ) {
  278|      0|        txn.put(
  279|      0|            self.db_handle(),
  280|      0|            pub_key.as_bytes(),
  281|      0|            &entry.to_bytes(),
  282|      0|            WriteFlags::empty(),
  283|      0|        )
  284|      0|        .unwrap();
  285|      0|    }
  286|       |
  287|      0|    pub fn check(&self, txn: &dyn Transaction) -> RawKey {
  288|      0|        self.entry_get_raw(txn, &Self::check_special()).key
  289|      0|    }
  290|       |
  291|      0|    pub fn salt(&self, txn: &dyn Transaction) -> RawKey {
  292|      0|        self.entry_get_raw(txn, &Self::salt_special()).key
  293|      0|    }
  294|       |
  295|      0|    pub fn wallet_key(&self, txn: &dyn Transaction) -> RawKey {
  296|      0|        let guard = self.fans.lock().unwrap();
  297|      0|        self.wallet_key_locked(&guard, txn)
  298|      0|    }
  299|       |
  300|      0|    fn wallet_key_locked(&self, guard: &MutexGuard<Fans>, txn: &dyn Transaction) -> RawKey {
  301|      0|        let wallet = guard.wallet_key_mem.value();
  302|      0|        let password = guard.password.value();
  303|      0|        let iv = self.salt(txn).initialization_vector_low();
  304|      0|        wallet.decrypt(&password, &iv)
  305|      0|    }
  306|       |
  307|      0|    pub fn seed(&self, txn: &dyn Transaction) -> RawKey {
  308|      0|        let value = self.entry_get_raw(txn, &Self::seed_special());
  309|      0|        let password = self.wallet_key(txn);
  310|      0|        let iv = self.salt(txn).initialization_vector_high();
  311|      0|        value.key.decrypt(&password, &iv)
  312|      0|    }
  313|       |
  314|      0|    pub fn set_seed(&self, txn: &mut LmdbWriteTransaction, prv: &RawKey) {
  315|      0|        let password_l = self.wallet_key(txn);
  316|      0|        let iv = self.salt(txn).initialization_vector_high();
  317|      0|        let ciphertext = prv.encrypt(&password_l, &iv);
  318|      0|        self.entry_put_raw(txn, &Self::seed_special(), &WalletValue::new(ciphertext, 0));
  319|      0|        self.deterministic_clear(txn);
  320|      0|    }
  321|       |
  322|      0|    pub fn deterministic_key(&self, txn: &dyn Transaction, index: u32) -> RawKey {
  323|      0|        debug_assert!(self.valid_password(txn));
  324|      0|        let seed = self.seed(txn);
  325|      0|        deterministic_key(&seed, index)
  326|      0|    }
  327|       |
  328|      0|    pub fn deterministic_index_get(&self, txn: &dyn Transaction) -> u32 {
  329|      0|        let value = self.entry_get_raw(txn, &Self::deterministic_index_special());
  330|      0|        value.key.number().low_u32()
  331|      0|    }
  332|       |
  333|      0|    pub fn deterministic_index_set(&self, txn: &mut LmdbWriteTransaction, index: u32) {
  334|      0|        let index = RawKey::from(index as u64);
  335|      0|        let value = WalletValue::new(index, 0);
  336|      0|        self.entry_put_raw(txn, &Self::deterministic_index_special(), &value);
  337|      0|    }
  338|       |
  339|      0|    pub fn set_password(&self, password: RawKey) {
  340|      0|        self.fans.lock().unwrap().password.value_set(password);
  341|      0|    }
  342|       |
  343|      0|    pub fn valid_password(&self, txn: &dyn Transaction) -> bool {
  344|      0|        let wallet_key = self.wallet_key(txn);
  345|      0|        self.check_wallet_key(txn, &wallet_key)
  346|      0|    }
  347|       |
  348|      0|    pub fn valid_password_locked(&self, guard: &MutexGuard<Fans>, txn: &dyn Transaction) -> bool {
  349|      0|        let wallet_key = self.wallet_key_locked(guard, txn);
  350|      0|        self.check_wallet_key(txn, &wallet_key)
  351|      0|    }
  352|       |
  353|      0|    fn check_wallet_key(&self, txn: &dyn Transaction, wallet_key: &RawKey) -> bool {
  354|      0|        let zero = RawKey::zero();
  355|      0|        let iv = self.salt(txn).initialization_vector_low();
  356|      0|        let check = zero.encrypt(wallet_key, &iv);
  357|      0|        self.check(txn) == check
  358|      0|    }
  359|       |
  360|      0|    pub fn derive_key(&self, txn: &dyn Transaction, password: &str) -> RawKey {
  361|      0|        let salt = self.salt(txn);
  362|      0|        self.kdf.hash_password(password, salt.as_bytes())
  363|      0|    }
  364|       |
  365|      0|    pub fn rekey(&self, txn: &mut LmdbWriteTransaction, password: &str) -> anyhow::Result<()> {
  366|      0|        let mut guard = self.fans.lock().unwrap();
  367|      0|        if self.valid_password_locked(&guard, txn) {
  368|      0|            let password_new = self.derive_key(txn, password);
  369|      0|            let wallet_key = self.wallet_key_locked(&guard, txn);
  370|      0|            guard.password.value_set(password_new);
  371|      0|            let iv = self.salt(txn).initialization_vector_low();
  372|      0|            let encrypted = wallet_key.encrypt(&password_new, &iv);
  373|      0|            guard.wallet_key_mem.value_set(encrypted);
  374|      0|            self.entry_put_raw(
  375|      0|                txn,
  376|      0|                &Self::wallet_key_special(),
  377|      0|                &WalletValue::new(encrypted, 0),
  378|      0|            );
  379|      0|            Ok(())
  380|       |        } else {
  381|      0|            Err(anyhow!("invalid password"))
  382|       |        }
  383|      0|    }
  384|       |
  385|      0|    pub fn iter<'tx>(
  386|      0|        &self,
  387|      0|        tx: &'tx dyn Transaction,
  388|      0|    ) -> impl Iterator<Item = (PublicKey, WalletValue)> + 'tx {
  389|      0|        self.iter_range(tx, Self::special_count()..)
  390|      0|    }
  391|       |
  392|      0|    pub fn iter_range<'txn>(
  393|      0|        &self,
  394|      0|        tx: &'txn dyn Transaction,
  395|      0|        range: impl RangeBounds<PublicKey> + 'static,
  396|      0|    ) -> impl Iterator<Item = (PublicKey, WalletValue)> + 'txn {
  397|      0|        let cursor = tx.open_ro_cursor(self.db_handle()).unwrap();
  398|      0|        LmdbRangeIterator::new(cursor, range)
  399|      0|    }
  400|       |
  401|      0|    pub fn find<'txn>(
  402|      0|        &self,
  403|      0|        txn: &'txn dyn Transaction,
  404|      0|        pub_key: &PublicKey,
  405|      0|    ) -> Option<WalletValue> {
  406|      0|        let mut result = self.iter_range(txn, *pub_key..);
  407|      0|        if let Some((key, value)) = result.next() {
  408|      0|            if key == *pub_key {
  409|      0|                return Some(value);
  410|      0|            }
  411|      0|        }
  412|       |
  413|      0|        None
  414|      0|    }
  415|       |
  416|      0|    pub fn erase(&self, txn: &mut LmdbWriteTransaction, pub_key: &PublicKey) {
  417|      0|        txn.delete(self.db_handle(), pub_key.as_bytes(), None)
  418|      0|            .unwrap();
  419|      0|    }
  420|       |
  421|      0|    pub fn get_key_type(&self, txn: &dyn Transaction, pub_key: &PublicKey) -> KeyType {
  422|      0|        let value = self.entry_get_raw(txn, pub_key);
  423|      0|        Self::key_type(&value)
  424|      0|    }
  425|       |
  426|      0|    pub fn key_type(value: &WalletValue) -> KeyType {
  427|      0|        let number = value.key.number();
  428|      0|        if number > u64::MAX.into() {
  429|      0|            KeyType::Adhoc
  430|      0|        } else if (number >> 32).low_u32() == 1 {
  431|      0|            KeyType::Deterministic
  432|       |        } else {
  433|      0|            KeyType::Unknown
  434|       |        }
  435|      0|    }
  436|       |
  437|      0|    pub fn deterministic_clear(&self, txn: &mut LmdbWriteTransaction) {
  438|      0|        {
  439|      0|            let mut it = self.iter_range(txn, PublicKey::zero()..);
  440|      0|            while let Some((account, value)) = it.next() {
  441|      0|                match Self::key_type(&value) {
  442|      0|                    KeyType::Deterministic => {
  443|      0|                        drop(it);
  444|      0|                        self.erase(txn, &account);
  445|      0|                        it = self.iter_range(txn, account..);
  446|      0|                    }
  447|      0|                    _ => {}
  448|       |                }
  449|       |            }
  450|       |        }
  451|       |
  452|      0|        self.deterministic_index_set(txn, 0);
  453|      0|    }
  454|       |
  455|      0|    pub fn valid_public_key(&self, key: &PublicKey) -> bool {
  456|      0|        key.number() >= Self::special_count().number()
  457|      0|    }
  458|       |
  459|      0|    pub fn exists(&self, txn: &dyn Transaction, key: &PublicKey) -> bool {
  460|      0|        self.valid_public_key(key) && self.find(txn, key).is_some()
  461|      0|    }
  462|       |
  463|      0|    pub fn deterministic_insert(&self, txn: &mut LmdbWriteTransaction) -> PublicKey {
  464|      0|        let mut index = self.deterministic_index_get(txn);
  465|      0|        let mut prv = self.deterministic_key(txn, index);
  466|      0|        let mut result = PublicKey::try_from(&prv).unwrap();
  467|      0|        while self.exists(txn, &result) {
  468|      0|            index += 1;
  469|      0|            prv = self.deterministic_key(txn, index);
  470|      0|            result = PublicKey::try_from(&prv).unwrap();
  471|      0|        }
  472|       |
  473|      0|        let mut marker = 1u64;
  474|      0|        marker <<= 32;
  475|      0|        marker |= index as u64;
  476|      0|        self.entry_put_raw(txn, &result, &WalletValue::new(marker.into(), 0));
  477|      0|        index += 1;
  478|      0|        self.deterministic_index_set(txn, index);
  479|      0|        result
  480|      0|    }
  481|       |
  482|      0|    pub fn deterministic_insert_at(&self, txn: &mut LmdbWriteTransaction, index: u32) -> PublicKey {
  483|      0|        let prv = self.deterministic_key(txn, index);
  484|      0|        let result = PublicKey::try_from(&prv).unwrap();
  485|      0|        let mut marker = 1u64;
  486|      0|        marker <<= 32;
  487|      0|        marker |= index as u64;
  488|      0|        self.entry_put_raw(txn, &result, &WalletValue::new(marker.into(), 0));
  489|      0|        result
  490|      0|    }
  491|       |
  492|      0|    pub fn version(&self, txn: &dyn Transaction) -> u32 {
  493|      0|        let value = self.entry_get_raw(txn, &Self::version_special());
  494|      0|        value.key.as_bytes()[31] as u32
  495|      0|    }
  496|       |
  497|      0|    pub fn attempt_password(&self, txn: &dyn Transaction, password: &str) -> bool {
  498|      0|        let is_valid = {
  499|      0|            let mut guard = self.fans.lock().unwrap();
  500|      0|            let password_key = self.derive_key(txn, password);
  501|      0|            guard.password.value_set(password_key);
  502|      0|            self.valid_password_locked(&guard, txn)
  503|      0|        };
  504|      0|
  505|      0|        if is_valid && self.version(txn) != 4 {
  506|      0|            panic!("invalid wallet store version!");
  507|      0|        }
  508|      0|
  509|      0|        is_valid
  510|      0|    }
  511|       |
  512|      0|    pub fn lock(&self) {
  513|      0|        self.fans.lock().unwrap().password.value_set(RawKey::zero());
  514|      0|    }
  515|       |
  516|      0|    pub fn accounts(&self, txn: &dyn Transaction) -> Vec<Account> {
  517|      0|        self.iter(txn).map(|(key, _)| key.into()).collect()
  518|      0|    }
  519|       |
  520|      0|    pub fn representative(&self, txn: &dyn Transaction) -> PublicKey {
  521|      0|        let value = self.entry_get_raw(txn, &Self::representative_special());
  522|      0|        PublicKey::from_bytes(*value.key.as_bytes())
  523|      0|    }
  524|       |
  525|      0|    pub fn representative_set(&self, txn: &mut LmdbWriteTransaction, representative: &PublicKey) {
  526|      0|        let rep = RawKey::from_bytes(*representative.as_bytes());
  527|      0|        self.entry_put_raw(
  528|      0|            txn,
  529|      0|            &Self::representative_special(),
  530|      0|            &WalletValue::new(rep, 0),
  531|      0|        );
  532|      0|    }
  533|       |
  534|      0|    pub fn insert_adhoc(&self, txn: &mut LmdbWriteTransaction, prv: &RawKey) -> PublicKey {
  535|      0|        debug_assert!(self.valid_password(txn));
  536|      0|        let pub_key = PublicKey::try_from(prv).unwrap();
  537|      0|        let password = self.wallet_key(txn);
  538|      0|        let ciphertext = prv.encrypt(&password, &pub_key.initialization_vector());
  539|      0|        self.entry_put_raw(txn, &pub_key, &WalletValue::new(ciphertext, 0));
  540|      0|        pub_key
  541|      0|    }
  542|       |
  543|      0|    pub fn insert_watch(
  544|      0|        &self,
  545|      0|        txn: &mut LmdbWriteTransaction,
  546|      0|        pub_key: &PublicKey,
  547|      0|    ) -> anyhow::Result<()> {
  548|      0|        if !self.valid_public_key(pub_key) {
  549|      0|            bail!("invalid public key");
  550|      0|        }
  551|      0|
  552|      0|        self.entry_put_raw(txn, pub_key, &WalletValue::new(RawKey::zero(), 0));
  553|      0|        Ok(())
  554|      0|    }
  555|       |
  556|      0|    pub fn fetch(&self, txn: &dyn Transaction, pub_key: &PublicKey) -> anyhow::Result<RawKey> {
  557|      0|        if !self.valid_password(txn) {
  558|      0|            bail!("invalid password");
  559|      0|        }
  560|      0|
  561|      0|        let value = self.entry_get_raw(txn, pub_key);
  562|      0|        if value.key.is_zero() {
  563|      0|            bail!("pub key not found");
  564|      0|        }
  565|       |
  566|      0|        let prv = match Self::key_type(&value) {
  567|       |            KeyType::Deterministic => {
  568|      0|                let index = value.key.number().low_u32();
  569|      0|                self.deterministic_key(txn, index)
  570|       |            }
  571|       |            KeyType::Adhoc => {
  572|       |                // Ad-hoc keys
  573|      0|                let password = self.wallet_key(txn);
  574|      0|                value
  575|      0|                    .key
  576|      0|                    .decrypt(&password, &pub_key.initialization_vector())
  577|       |            }
  578|      0|            _ => bail!("invalid key type"),
  579|       |        };
  580|       |
  581|      0|        let compare = PublicKey::try_from(&prv)?;
  582|      0|        if compare != *pub_key {
  583|      0|            bail!("expected pub key does not match");
  584|      0|        }
  585|      0|        Ok(prv)
  586|      0|    }
  587|       |
  588|      0|    pub fn serialize_json(&self, tx: &dyn Transaction) -> String {
  589|      0|        let mut map = serde_json::Map::new();
  590|       |
  591|       |        // include special keys...
  592|      0|        for (k, v) in self.iter_range(tx, PublicKey::zero()..) {
  593|      0|            map.insert(
  594|      0|                k.encode_hex(),
  595|      0|                serde_json::Value::String(v.key.encode_hex()),
  596|      0|            );
  597|      0|        }
  598|       |
  599|      0|        serde_json::Value::Object(map).to_string()
  600|      0|    }
  601|       |
  602|      0|    pub fn write_backup(&self, txn: &dyn Transaction, path: &Path) -> anyhow::Result<()> {
  603|      0|        let mut file = File::create(path)?;
  604|      0|        set_permissions(path, Permissions::from_mode(0o600))?;
  605|      0|        write!(file, "{}", self.serialize_json(txn))?;
  606|      0|        Ok(())
  607|      0|    }
  608|       |
  609|      0|    pub fn move_keys(
  610|      0|        &self,
  611|      0|        txn: &mut LmdbWriteTransaction,
  612|      0|        other: &LmdbWalletStore,
  613|      0|        keys: &[PublicKey],
  614|      0|    ) -> anyhow::Result<()> {
  615|      0|        debug_assert!(self.valid_password(txn));
  616|      0|        debug_assert!(other.valid_password(txn));
  617|      0|        for k in keys {
  618|      0|            let prv = other.fetch(txn, k)?;
  619|      0|            self.insert_adhoc(txn, &prv);
  620|      0|            other.erase(txn, k);
  621|       |        }
  622|       |
  623|      0|        Ok(())
  624|      0|    }
  625|       |
  626|      0|    pub fn import(
  627|      0|        &self,
  628|      0|        txn: &mut LmdbWriteTransaction,
  629|      0|        other: &LmdbWalletStore,
  630|      0|    ) -> anyhow::Result<()> {
  631|      0|        debug_assert!(self.valid_password(txn));
  632|      0|        debug_assert!(other.valid_password(txn));
  633|       |
  634|       |        enum KeyType {
  635|       |            Private((PublicKey, RawKey)),
  636|       |            WatchOnly(PublicKey),
  637|       |        }
  638|       |
  639|      0|        let mut keys = Vec::new();
  640|       |        {
  641|      0|            for (k, _) in other.iter(txn) {
  642|      0|                let prv = other.fetch(txn, &k)?;
  643|      0|                if !prv.is_zero() {
  644|      0|                    keys.push(KeyType::Private((k, prv)));
  645|      0|                } else {
  646|      0|                    keys.push(KeyType::WatchOnly(k));
  647|      0|                }
  648|       |            }
  649|       |        }
  650|       |
  651|      0|        for k in keys {
  652|      0|            match k {
  653|      0|                KeyType::Private((pub_key, priv_key)) => {
  654|      0|                    self.insert_adhoc(txn, &priv_key);
  655|      0|                    other.erase(txn, &pub_key);
  656|      0|                }
  657|      0|                KeyType::WatchOnly(pub_key) => {
  658|      0|                    self.insert_watch(txn, &pub_key).unwrap();
  659|      0|                    other.erase(txn, &pub_key);
  660|      0|                }
  661|       |            }
  662|       |        }
  663|       |
  664|      0|        Ok(())
  665|      0|    }
  666|       |
  667|      0|    pub fn work_get(&self, txn: &dyn Transaction, pub_key: &PublicKey) -> anyhow::Result<u64> {
  668|      0|        let entry = self.entry_get_raw(txn, pub_key);
  669|      0|        if !entry.key.is_zero() {
  670|      0|            Ok(entry.work)
  671|       |        } else {
  672|      0|            Err(anyhow!("not found"))
  673|       |        }
  674|      0|    }
  675|       |
  676|      0|    pub fn version_put(&self, txn: &mut LmdbWriteTransaction, version: u32) {
  677|      0|        let entry = RawKey::from(version as u64);
  678|      0|        self.entry_put_raw(txn, &Self::version_special(), &WalletValue::new(entry, 0));
  679|      0|    }
  680|       |
  681|      0|    pub fn work_put(&self, txn: &mut LmdbWriteTransaction, pub_key: &PublicKey, work: u64) {
  682|      0|        let mut entry = self.entry_get_raw(txn, pub_key);
  683|      0|        debug_assert!(!entry.key.is_zero());
  684|      0|        entry.work = work;
  685|      0|        self.entry_put_raw(txn, pub_key, &entry);
  686|      0|    }
  687|       |
  688|      0|    pub fn destroy(&self, txn: &mut LmdbWriteTransaction) {
  689|      0|        unsafe {
  690|      0|            txn.rw_txn_mut().drop_db(self.db_handle()).unwrap();
  691|      0|        }
  692|      0|        *self.db_handle.lock().unwrap() = None;
  693|      0|    }
  694|       |
  695|      0|    pub fn is_open(&self) -> bool {
  696|      0|        self.db_handle.lock().unwrap().is_some()
  697|      0|    }
  698|       |}